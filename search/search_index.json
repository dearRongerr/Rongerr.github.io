{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udf43 Welcome","text":""},{"location":"#welcome","title":"\ud83c\udf43 Welcome","text":"<p> \u7ea6 408 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> \u751f\u5982\u9006\u65c5 \u4e00\u82c7\u4ee5\u822a <ul> <li> <p> Rongerr's notebook</p> <p>\u8bb0\u5f55\u4e86\u7814\u7a76\u751f\u4ee5\u6765\u5404\u65b9\u9762\u7684\u5b66\u4e60\u5185\u5bb9\uff0c\u4f9b\u81ea\u5df1\u67e5\u9605\uff0c\u80fd\u5e2e\u52a9\u5230\u522b\u4eba\u4e0d\u80dc\u8363\u5e78 \ud83d\ude1b</p> <p>\u8fb9\u5b66\u8fb9\u8bb0\u8fb9\u601d\u8003\uff0c\u5b66\u8fc7\u7684\u4e1c\u897f\u53cd\u590d\u9a8c\u8bc1\uff0c\u8bb0\u4e0b\u601d\u8003\u7684\u8fc7\u7a0b\uff0c\u8bb0\u6027\u597d\u5dee\u52b2 \ud83e\udee3 \uff0c\u770b\u6211\u7684\u7b14\u8bb0\u65f6\u4e00\u5b9a\u8981\u5e26\u7740\u6279\u5224\u6027\u601d\u7ef4\uff0c\u56e0\u4e3a\u53ef\u80fd\u6211\u4e0b\u4e00\u7bc7\u6587\u7ae0\u5199\u5f97\u65f6\u5019\u4e5f\u53d8\u4e86\u7406\u89e3 \ud83e\udd79</p> <p>\u652f\u6301\u4e00\u5207\u5408\u7406\u4e14\u53cb\u597d\u7684\u8ba8\u8bba \ud83d\ude06</p> <p>\u7814\u4e09\u8001\u963f\u59e8\uff0c  \u03b5\uff1d\u03b5\uff1d\u03b5\uff1d(#&gt;\u0434&lt;)\uff89 \ud83e\udee2 \u6539\u4ee3\u7801\u624d\u662f\u6700\u4fee\u8eab\u517b\u6027\u7684\u5427 \ud83d\ude02</p> <p>\u6c38\u8fdc\u4fdd\u6301\u8c26\u5351 \ud83d\udc7e</p> <p>\u8fd9\u662f\u8ff7\u832b\u7684\u4e00\u5e74\uff0c</p> <p>Concat me:  1939472345@qq.com </p> </li> </ul> <ul> <li> <p> Statistics</p> <ul> <li> \u9875\u9762\u6570\uff1a 150 </li> <li> \u603b\u5b57\u6570\uff1a306236 </li> <li> \u4ee3\u7801\u884c\u6570\uff1a11013 </li> <li> \u56fe\u7247\u6570\u91cf\uff1a2027</li> <li> \u7f51\u7ad9\u521b\u5efa\u65e5\u671f\uff1a2024 \u5e74 11 \u6708 14 \u65e5</li> <li> \u7f51\u7ad9\u8fd0\u884c\u65f6\u95f4\uff1a  </li> <li> \u672c\u7ad9\u603b\u8bbf\u95ee\u91cf\uff1a\u6b21  </li> <li> \u672c\u7ad9\u8bbf\u5ba2\u6570\uff1a\u4eba\u6b21  </li> </ul> </li> <li> <p> Link</p> <ul> <li> \u672c\u7ad9\u6837\u5f0f\u7279\u522b\u9e23\u8c22:<ul> <li>amaranth</li> <li>Wcowin</li> <li>TonyCrane</li> </ul> </li> <li> \u66f4\u591a\u53cb\u94fe</li> <li> \u6700\u8fd1\u66f4\u65b0</li> <li> \u7559\u8a00\u677f</li> </ul> </li> </ul>"},{"location":"CodeRepo/","title":"Intro","text":""},{"location":"CodeRepo/#intro","title":"Intro","text":"2025-04-18 15:33:402025-09-28 12:54:03 <p> \u7ea6 61 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>Abstract</p> <p>\u4e5f\u662f\u597d\u8d77\u6765\u4e86\uff0c\u5c45\u7136\u9700\u8981\u4e3a\u81ea\u5df1\u5e38\u7528\u7684\u4ee3\u7801\u7247\u65b0\u5efa\u4e00\u4e2a\u9875\u9762\u4e86\u3001 \u5173\u4e8e\u4e00\u4e9b\u5e38\u7528\u7684 python \u547d\u4ee4\u3001\u4ee3\u7801\u7247\u3001\u5907\u5fd8\u5f55\u3001\u6742\u4e03\u6742\u516b\u7684\u5907\u5fd8\u89c1 \u4fbf\u7b7e\u3001\u6709\u5173python\u7684\u5de5\u5177\u7bb1</p>"},{"location":"CodeRepo/1_model/","title":"\u67e5\u770b pytorch \u7f51\u7edc\u7ed3\u6784","text":""},{"location":"CodeRepo/1_model/#pytorch","title":"\u67e5\u770b pytorch \u7f51\u7edc\u7ed3\u6784","text":"2025-04-18 15:33:402025-09-28 12:54:03 <p> \u7ea6 41 \u4e2a\u5b57  417 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 5 \u5206\u949f</p>"},{"location":"CodeRepo/1_model/#1print","title":"\u6cd5\u2460\uff1a<code>print()</code>","text":"<p>\u5b9e\u4f8b\u5316\u597d\u6a21\u578b\u5373\u53ef <code>print()</code></p> Python<pre><code># \u5b9e\u4f8b\u5316\u6a21\u578b\nmodel = Model(configs)\nprint(\"\u6a21\u578b\u7ed3\u6784:\")\nprint(model)\n# \u8ba1\u7b97\u6a21\u578b\u53c2\u6570\u6570\u91cf\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"\u6a21\u578b\u53c2\u6570\u6570\u91cf: {total_params}\")\n</code></pre> <p>\u8f93\u51fa\uff1a</p> \u8f93\u51fa\uff1a <p> </p>Python<pre><code>\u6a21\u578b\u7ed3\u6784:\nModel(\n  (revin_layer): RevIN()\n  (Maxpools): ModuleList(\n    (0-3): 4 x AvgPool1d(kernel_size=(3,), stride=(2,), padding=(1,))\n  )\n  (down_blocks): ModuleList(\n    (0): block_model(\n      (Linear_channel): ModuleList(\n        (0-6): 7 x Linear(in_features=96, out_features=720, bias=True)\n      )\n      (ln): LayerNorm((720,), eps=1e-05, elementwise_affine=True)\n      (relu): ReLU(inplace=True)\n    )\n    (1): block_model(\n      (Linear_channel): ModuleList(\n        (0-6): 7 x Linear(in_features=48, out_features=360, bias=True)\n      )\n      (ln): LayerNorm((360,), eps=1e-05, elementwise_affine=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): block_model(\n      (Linear_channel): ModuleList(\n        (0-6): 7 x Linear(in_features=24, out_features=180, bias=True)\n      )\n      (ln): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): block_model(\n      (Linear_channel): ModuleList(\n        (0-6): 7 x Linear(in_features=12, out_features=90, bias=True)\n      )\n      (ln): LayerNorm((90,), eps=1e-05, elementwise_affine=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (dct_models): ModuleList(\n    (0): dct_channel_block(\n      (fc): Sequential(\n        (0): Linear(in_features=96, out_features=192, bias=False)\n        (1): Dropout(p=0.5, inplace=False)\n        (2): ReLU(inplace=True)\n        (3): Linear(in_features=192, out_features=96, bias=False)\n        (4): Dropout(p=0.5, inplace=False)\n        (5): Sigmoid()\n      )\n      (dct_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n    )\n    (1): dct_channel_block(\n      (fc): Sequential(\n        (0): Linear(in_features=48, out_features=96, bias=False)\n        (1): Dropout(p=0.5, inplace=False)\n        (2): ReLU(inplace=True)\n        (3): Linear(in_features=96, out_features=48, bias=False)\n        (4): Dropout(p=0.5, inplace=False)\n        (5): Sigmoid()\n      )\n      (dct_norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n    )\n    (2): dct_channel_block(\n      (fc): Sequential(\n        (0): Linear(in_features=24, out_features=48, bias=False)\n        (1): Dropout(p=0.5, inplace=False)\n        (2): ReLU(inplace=True)\n        (3): Linear(in_features=48, out_features=24, bias=False)\n        (4): Dropout(p=0.5, inplace=False)\n        (5): Sigmoid()\n      )\n      (dct_norm): LayerNorm((24,), eps=1e-06, elementwise_affine=True)\n    )\n    (3): dct_channel_block(\n      (fc): Sequential(\n        (0): Linear(in_features=12, out_features=24, bias=False)\n        (1): Dropout(p=0.5, inplace=False)\n        (2): ReLU(inplace=True)\n        (3): Linear(in_features=24, out_features=12, bias=False)\n        (4): Dropout(p=0.5, inplace=False)\n        (5): Sigmoid()\n      )\n      (dct_norm): LayerNorm((12,), eps=1e-06, elementwise_affine=True)\n    )\n  )\n  (icbs): ModuleList(\n    (0): ICB(\n      (conv1): Conv1d(270, 270, kernel_size=(1,), stride=(1,))\n      (conv3): Conv1d(270, 270, kernel_size=(3,), stride=(1,), padding=(1,))\n      (conv5): Conv1d(270, 270, kernel_size=(5,), stride=(1,), padding=(2,))\n      (conv7): Conv1d(270, 270, kernel_size=(7,), stride=(1,), padding=(3,))\n      (conv_out): Conv1d(1080, 180, kernel_size=(1,), stride=(1,))\n      (drop): Dropout(p=0.5, inplace=False)\n      (act): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU()\n    )\n    (1): ICB(\n      (conv1): Conv1d(540, 540, kernel_size=(1,), stride=(1,))\n      (conv3): Conv1d(540, 540, kernel_size=(3,), stride=(1,), padding=(1,))\n      (conv5): Conv1d(540, 540, kernel_size=(5,), stride=(1,), padding=(2,))\n      (conv7): Conv1d(540, 540, kernel_size=(7,), stride=(1,), padding=(3,))\n      (conv_out): Conv1d(2160, 360, kernel_size=(1,), stride=(1,))\n      (drop): Dropout(p=0.5, inplace=False)\n      (act): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU()\n    )\n    (2): ICB(\n      (conv1): Conv1d(1080, 1080, kernel_size=(1,), stride=(1,))\n      (conv3): Conv1d(1080, 1080, kernel_size=(3,), stride=(1,), padding=(1,))\n      (conv5): Conv1d(1080, 1080, kernel_size=(5,), stride=(1,), padding=(2,))\n      (conv7): Conv1d(1080, 1080, kernel_size=(7,), stride=(1,), padding=(3,))\n      (conv_out): Conv1d(4320, 720, kernel_size=(1,), stride=(1,))\n      (drop): Dropout(p=0.5, inplace=False)\n      (act): Tanh()\n      (sigmoid): Sigmoid()\n      (relu): ReLU()\n    )\n  )\n  (channel_mixer): ChebyKANLayer(\n    (fc1): ChebyKANLinear()\n  )\n)\n\u6a21\u578b\u53c2\u6570\u6570\u91cf: 29289904\n\u8f93\u5165\u5f62\u72b6: torch.Size([16, 96, 7])\n\u8f93\u51fa\u5f62\u72b6: torch.Size([16, 720, 7])\n\u9884\u671f\u8f93\u51fa\u5f62\u72b6: [batch_size=16, pred_len=720, enc_in=7]\n</code></pre> <p></p>"},{"location":"CodeRepo/1_model/#2torchinfo-summary","title":"\u6cd5\u2461\uff1a<code>torchinfo summary()</code>","text":"<p>\u6ce8\u610f\u5728\u540c\u4e00\u4e2a\u8bbe\u5907\u4e0a</p> Python<pre><code>pip install torchinfo\nfrom torchinfo import summary\nmodel = Model(configs)\nx = torch.randn(batch_size, seq_len, enc_in)\nsummary(model, input_data=x)\n</code></pre> \u8f93\u51fa\uff1a <p> </p>Python<pre><code>==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nModel                                    [16, 720, 7]              --\n\u251c\u2500RevIN: 1-1                             [16, 96, 7]               14\n\u251c\u2500ChebyKANLayer: 1-2                     [16, 96, 7]               --\n\u2502    \u2514\u2500ChebyKANLinear: 2-1               [1536, 7]                 196\n\u251c\u2500ModuleList: 1-12                       --                        (recursive)\n\u2502    \u2514\u2500block_model: 2-2                  [16, 7, 720]              1,440\n\u2502    \u2502    \u2514\u2500ModuleList: 3-1              --                        488,880\n\u251c\u2500ModuleList: 1-13                       --                        (recursive)\n\u2502    \u2514\u2500dct_channel_block: 2-3            [16, 7, 96]               1\n\u2502    \u2502    \u2514\u2500LayerNorm: 3-2               [16, 7, 96]               192\n\u2502    \u2502    \u2514\u2500Sequential: 3-3              [16, 7, 96]               36,864\n\u2502    \u2502    \u2514\u2500LayerNorm: 3-4               [16, 7, 96]               (recursive)\n\u251c\u2500ModuleList: 1-14                       --                        --\n\u2502    \u2514\u2500AvgPool1d: 2-4                    [16, 7, 48]               --\n\u251c\u2500ModuleList: 1-12                       --                        (recursive)\n\u2502    \u2514\u2500block_model: 2-5                  [16, 7, 360]              720\n\u2502    \u2502    \u2514\u2500ModuleList: 3-5              --                        123,480\n\u251c\u2500ModuleList: 1-13                       --                        (recursive)\n\u2502    \u2514\u2500dct_channel_block: 2-6            [16, 7, 48]               1\n\u2502    \u2502    \u2514\u2500LayerNorm: 3-6               [16, 7, 48]               96\n\u2502    \u2502    \u2514\u2500Sequential: 3-7              [16, 7, 48]               9,216\n\u2502    \u2502    \u2514\u2500LayerNorm: 3-8               [16, 7, 48]               (recursive)\n\u251c\u2500ModuleList: 1-14                       --                        --\n\u2502    \u2514\u2500AvgPool1d: 2-7                    [16, 7, 24]               --\n\u251c\u2500ModuleList: 1-12                       --                        (recursive)\n\u2502    \u2514\u2500block_model: 2-8                  [16, 7, 180]              360\n\u2502    \u2502    \u2514\u2500ModuleList: 3-9              --                        31,500\n\u251c\u2500ModuleList: 1-13                       --                        (recursive)\n\u2502    \u2514\u2500dct_channel_block: 2-9            [16, 7, 24]               1\n\u2502    \u2502    \u2514\u2500LayerNorm: 3-10              [16, 7, 24]               48\n\u2502    \u2502    \u2514\u2500Sequential: 3-11             [16, 7, 24]               2,304\n\u2502    \u2502    \u2514\u2500LayerNorm: 3-12              [16, 7, 24]               (recursive)\n\u251c\u2500ModuleList: 1-14                       --                        --\n\u2502    \u2514\u2500AvgPool1d: 2-10                   [16, 7, 12]               --\n\u251c\u2500ModuleList: 1-12                       --                        (recursive)\n\u2502    \u2514\u2500block_model: 2-11                 [16, 7, 90]               180\n\u2502    \u2502    \u2514\u2500ModuleList: 3-13             --                        8,190\n\u251c\u2500ModuleList: 1-13                       --                        (recursive)\n\u2502    \u2514\u2500dct_channel_block: 2-12           [16, 7, 12]               1\n\u2502    \u2502    \u2514\u2500LayerNorm: 3-14              [16, 7, 12]               24\n\u2502    \u2502    \u2514\u2500Sequential: 3-15             [16, 7, 12]               576\n\u2502    \u2502    \u2514\u2500LayerNorm: 3-16              [16, 7, 12]               (recursive)\n\u251c\u2500ModuleList: 1-14                       --                        --\n\u2502    \u2514\u2500AvgPool1d: 2-13                   [16, 7, 6]                --\n\u251c\u2500ChebyKANLayer: 1-15                    [16, 90, 7]               (recursive)\n\u2502    \u2514\u2500ChebyKANLinear: 2-14              [1440, 7]                 (recursive)\n\u251c\u2500ModuleList: 1-16                       --                        --\n\u2502    \u2514\u2500ICB: 2-15                         [16, 7, 180]              --\n\u2502    \u2502    \u2514\u2500Conv1d: 3-17                 [16, 270, 7]              73,170\n\u2502    \u2502    \u2514\u2500Conv1d: 3-18                 [16, 270, 7]              218,970\n\u2502    \u2502    \u2514\u2500Conv1d: 3-19                 [16, 270, 7]              364,770\n\u2502    \u2502    \u2514\u2500Conv1d: 3-20                 [16, 270, 7]              510,570\n\u2502    \u2502    \u2514\u2500Tanh: 3-21                   [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-22                [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500ReLU: 3-23                   [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500Tanh: 3-24                   [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-25                [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500ReLU: 3-26                   [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500Tanh: 3-27                   [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-28                [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500ReLU: 3-29                   [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500Tanh: 3-30                   [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-31                [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500ReLU: 3-32                   [16, 270, 7]              --\n\u2502    \u2502    \u2514\u2500Dropout: 3-33                [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500Conv1d: 3-34                 [16, 180, 7]              194,580\n\u2502    \u2514\u2500ICB: 2-16                         [16, 7, 360]              --\n\u2502    \u2502    \u2514\u2500Conv1d: 3-35                 [16, 540, 7]              292,140\n\u2502    \u2502    \u2514\u2500Conv1d: 3-36                 [16, 540, 7]              875,340\n\u2502    \u2502    \u2514\u2500Conv1d: 3-37                 [16, 540, 7]              1,458,540\n\u2502    \u2502    \u2514\u2500Conv1d: 3-38                 [16, 540, 7]              2,041,740\n\u2502    \u2502    \u2514\u2500Tanh: 3-39                   [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-40                [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500ReLU: 3-41                   [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500Tanh: 3-42                   [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-43                [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500ReLU: 3-44                   [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500Tanh: 3-45                   [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-46                [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500ReLU: 3-47                   [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500Tanh: 3-48                   [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-49                [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500ReLU: 3-50                   [16, 540, 7]              --\n\u2502    \u2502    \u2514\u2500Dropout: 3-51                [16, 2160, 7]             --\n\u2502    \u2502    \u2514\u2500Conv1d: 3-52                 [16, 360, 7]              777,960\n\u2502    \u2514\u2500ICB: 2-17                         [16, 7, 720]              --\n\u2502    \u2502    \u2514\u2500Conv1d: 3-53                 [16, 1080, 7]             1,167,480\n\u2502    \u2502    \u2514\u2500Conv1d: 3-54                 [16, 1080, 7]             3,500,280\n\u2502    \u2502    \u2514\u2500Conv1d: 3-55                 [16, 1080, 7]             5,833,080\n\u2502    \u2502    \u2514\u2500Conv1d: 3-56                 [16, 1080, 7]             8,165,880\n\u2502    \u2502    \u2514\u2500Tanh: 3-57                   [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-58                [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500ReLU: 3-59                   [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500Tanh: 3-60                   [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-61                [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500ReLU: 3-62                   [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500Tanh: 3-63                   [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-64                [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500ReLU: 3-65                   [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500Tanh: 3-66                   [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500Sigmoid: 3-67                [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500ReLU: 3-68                   [16, 1080, 7]             --\n\u2502    \u2502    \u2514\u2500Dropout: 3-69                [16, 4320, 7]             --\n\u2502    \u2502    \u2514\u2500Conv1d: 3-70                 [16, 720, 7]              3,111,120\n\u251c\u2500RevIN: 1-17                            [16, 720, 7]              (recursive)\n==========================================================================================\nTotal params: 29,289,904\nTrainable params: 29,289,904\nNon-trainable params: 0\nTotal mult-adds (G): 3.21\n==========================================================================================\nInput size (MB): 0.04\nForward/backward pass size (MB): 10.82\nParams size (MB): 117.15\nEstimated Total Size (MB): 128.01\n==========================================================================================\n</code></pre> <p></p>"},{"location":"CodeRepo/1_model/#3torchsummary-summary","title":"\u6cd5\u2462\uff1atorchsummary summary()","text":"Python<pre><code>from torchsummary import summary\n# \u5b9e\u4f8b\u5316\u6a21\u578b\nmodel = Model(configs)\n# \u751f\u6210\u968f\u673a\u8f93\u5165\u6570\u636e\nbatch_size = 16\nseq_len = configs.seq_len\nenc_in = configs.enc_in\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nx = torch.randn(batch_size, seq_len, enc_in).to(device)\nmodel = model.to(device)\n# summary(model, input_data=x)\nsummary(model, input_size=(configs.seq_len, configs.enc_in), batch_size=batch_size, device=device.type)\n</code></pre> \u8f93\u51fa\uff1a Python<pre><code>----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n             RevIN-1                [16, 96, 7]               0\n    ChebyKANLinear-2                    [16, 7]               0\n     ChebyKANLayer-3                [16, 96, 7]               0\n            Linear-4                  [16, 720]          69,840\n            Linear-5                  [16, 720]          69,840\n            Linear-6                  [16, 720]          69,840\n            Linear-7                  [16, 720]          69,840\n            Linear-8                  [16, 720]          69,840\n            Linear-9                  [16, 720]          69,840\n           Linear-10                  [16, 720]          69,840\n      block_model-11               [16, 7, 720]               0\n        LayerNorm-12                [16, 7, 96]             192\n           Linear-13               [16, 7, 192]          18,432\n          Dropout-14               [16, 7, 192]               0\n             ReLU-15               [16, 7, 192]               0\n           Linear-16                [16, 7, 96]          18,432\n          Dropout-17                [16, 7, 96]               0\n          Sigmoid-18                [16, 7, 96]               0\n        LayerNorm-19                [16, 7, 96]             192\ndct_channel_block-20                [16, 7, 96]               0\n        AvgPool1d-21                [16, 7, 48]               0\n           Linear-22                  [16, 360]          17,640\n           Linear-23                  [16, 360]          17,640\n           Linear-24                  [16, 360]          17,640\n           Linear-25                  [16, 360]          17,640\n           Linear-26                  [16, 360]          17,640\n           Linear-27                  [16, 360]          17,640\n           Linear-28                  [16, 360]          17,640\n      block_model-29               [16, 7, 360]               0\n        LayerNorm-30                [16, 7, 48]              96\n           Linear-31                [16, 7, 96]           4,608\n          Dropout-32                [16, 7, 96]               0\n             ReLU-33                [16, 7, 96]               0\n           Linear-34                [16, 7, 48]           4,608\n          Dropout-35                [16, 7, 48]               0\n          Sigmoid-36                [16, 7, 48]               0\n        LayerNorm-37                [16, 7, 48]              96\ndct_channel_block-38                [16, 7, 48]               0\n        AvgPool1d-39                [16, 7, 24]               0\n           Linear-40                  [16, 180]           4,500\n           Linear-41                  [16, 180]           4,500\n           Linear-42                  [16, 180]           4,500\n           Linear-43                  [16, 180]           4,500\n           Linear-44                  [16, 180]           4,500\n           Linear-45                  [16, 180]           4,500\n           Linear-46                  [16, 180]           4,500\n      block_model-47               [16, 7, 180]               0\n        LayerNorm-48                [16, 7, 24]              48\n           Linear-49                [16, 7, 48]           1,152\n          Dropout-50                [16, 7, 48]               0\n             ReLU-51                [16, 7, 48]               0\n           Linear-52                [16, 7, 24]           1,152\n          Dropout-53                [16, 7, 24]               0\n          Sigmoid-54                [16, 7, 24]               0\n        LayerNorm-55                [16, 7, 24]              48\ndct_channel_block-56                [16, 7, 24]               0\n        AvgPool1d-57                [16, 7, 12]               0\n           Linear-58                   [16, 90]           1,170\n           Linear-59                   [16, 90]           1,170\n           Linear-60                   [16, 90]           1,170\n           Linear-61                   [16, 90]           1,170\n           Linear-62                   [16, 90]           1,170\n           Linear-63                   [16, 90]           1,170\n           Linear-64                   [16, 90]           1,170\n      block_model-65                [16, 7, 90]               0\n        LayerNorm-66                [16, 7, 12]              24\n           Linear-67                [16, 7, 24]             288\n          Dropout-68                [16, 7, 24]               0\n             ReLU-69                [16, 7, 24]               0\n           Linear-70                [16, 7, 12]             288\n          Dropout-71                [16, 7, 12]               0\n          Sigmoid-72                [16, 7, 12]               0\n        LayerNorm-73                [16, 7, 12]              24\ndct_channel_block-74                [16, 7, 12]               0\n        AvgPool1d-75                 [16, 7, 6]               0\n   ChebyKANLinear-76                    [16, 7]               0\n    ChebyKANLayer-77                [16, 90, 7]               0\n           Conv1d-78               [16, 270, 7]          73,170\n           Conv1d-79               [16, 270, 7]         218,970\n           Conv1d-80               [16, 270, 7]         364,770\n           Conv1d-81               [16, 270, 7]         510,570\n             Tanh-82               [16, 270, 7]               0\n          Sigmoid-83               [16, 270, 7]               0\n             ReLU-84               [16, 270, 7]               0\n             Tanh-85               [16, 270, 7]               0\n          Sigmoid-86               [16, 270, 7]               0\n             ReLU-87               [16, 270, 7]               0\n             Tanh-88               [16, 270, 7]               0\n          Sigmoid-89               [16, 270, 7]               0\n             ReLU-90               [16, 270, 7]               0\n             Tanh-91               [16, 270, 7]               0\n          Sigmoid-92               [16, 270, 7]               0\n             ReLU-93               [16, 270, 7]               0\n          Dropout-94              [16, 1080, 7]               0\n           Conv1d-95               [16, 180, 7]         194,580\n              ICB-96               [16, 7, 180]               0\n           Conv1d-97               [16, 540, 7]         292,140\n           Conv1d-98               [16, 540, 7]         875,340\n           Conv1d-99               [16, 540, 7]       1,458,540\n          Conv1d-100               [16, 540, 7]       2,041,740\n            Tanh-101               [16, 540, 7]               0\n         Sigmoid-102               [16, 540, 7]               0\n            ReLU-103               [16, 540, 7]               0\n            Tanh-104               [16, 540, 7]               0\n         Sigmoid-105               [16, 540, 7]               0\n            ReLU-106               [16, 540, 7]               0\n            Tanh-107               [16, 540, 7]               0\n         Sigmoid-108               [16, 540, 7]               0\n            ReLU-109               [16, 540, 7]               0\n            Tanh-110               [16, 540, 7]               0\n         Sigmoid-111               [16, 540, 7]               0\n            ReLU-112               [16, 540, 7]               0\n         Dropout-113              [16, 2160, 7]               0\n          Conv1d-114               [16, 360, 7]         777,960\n             ICB-115               [16, 7, 360]               0\n          Conv1d-116              [16, 1080, 7]       1,167,480\n          Conv1d-117              [16, 1080, 7]       3,500,280\n          Conv1d-118              [16, 1080, 7]       5,833,080\n          Conv1d-119              [16, 1080, 7]       8,165,880\n            Tanh-120              [16, 1080, 7]               0\n         Sigmoid-121              [16, 1080, 7]               0\n            ReLU-122              [16, 1080, 7]               0\n            Tanh-123              [16, 1080, 7]               0\n         Sigmoid-124              [16, 1080, 7]               0\n            ReLU-125              [16, 1080, 7]               0\n            Tanh-126              [16, 1080, 7]               0\n         Sigmoid-127              [16, 1080, 7]               0\n            ReLU-128              [16, 1080, 7]               0\n            Tanh-129              [16, 1080, 7]               0\n         Sigmoid-130              [16, 1080, 7]               0\n            ReLU-131              [16, 1080, 7]               0\n         Dropout-132              [16, 4320, 7]               0\n          Conv1d-133               [16, 720, 7]       3,111,120\n             ICB-134               [16, 7, 720]               0\n           RevIN-135               [16, 720, 7]               0\n================================================================\nTotal params: 29,287,350\nTrainable params: 29,287,350\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.04\nForward/backward pass size (MB): 39.54\nParams size (MB): 111.72\nEstimated Total Size (MB): 151.30\n----------------------------------------------------------------\n\u8f93\u5165\u5f62\u72b6: torch.Size([16, 96, 7])\n</code></pre>"},{"location":"CodeRepo/2_0_tensorboad/","title":"tensorboard\u53ef\u89c6\u5316","text":""},{"location":"CodeRepo/2_0_tensorboad/#tensorboard","title":"tensorboard\u53ef\u89c6\u5316","text":"2025-04-18 17:57:252025-09-28 12:54:03 <p> \u7ea6 224 \u4e2a\u5b57  6 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u5728Pytorch\u4e2d\u4f7f\u7528Tensorboard\u53ef\u89c6\u5316\u8bad\u7ec3\u8fc7\u7a0b </p> <ul> <li>\u53ef\u89c6\u5316\u8bad\u7ec3\u8fc7\u7a0b</li> <li>\u5b98\u65b9 pytorch\u3001tensorboard \u53ef\u89c6\u5316</li> <li>\u8fdb\u5165PyTorch\u5b98\u7f51</li> <li>\u5de6\u4fa7 <code>Learning PyTorch</code></li> <li><code>Visualiazing Models,DATA...</code> </li> <li>tensorboard \u53ef\u4ee5\u5e72\u4ec0\u4e48\uff1f</li> <li>\u4fdd\u5b58\u7f51\u7edc\u7ed3\u6784\u56fe <code>GRAPHS</code></li> <li>\u8bad\u7ec3\u96c6\u4e0a\u7684\u635f\u5931 loss\u3001learning_rate\u3001\u9a8c\u8bc1\u96c6\u4e0a\u7684 accuracy <code>SCALARS</code></li> <li>\u4fdd\u5b58\u6743\u91cd\u6570\u503c\u5206\u5e03 <code>HISTOGRAMS</code></li> <li>\u9884\u6d4b\u56fe\u7247\u4fe1\u606f <code>IMAGES</code></li> </ul>"},{"location":"CodeRepo/2_0_tensorboad/#_1","title":"\u5173\u4e8e\u542f\u52a8","text":"<p>\u573a\u666f\u63cf\u8ff0\uff1a\u8ba9\u4e00\u4e2aTensorBoard\u5b9e\u4f8b\u6301\u7eed\u8fd0\u884c\uff0c\u76d1\u89c6\u6240\u6709\u5b9e\u9a8c</p> <p>\uff081\uff09\u4e00\u6b21\u6027\u542f\u52a8\u957f\u671f\u8fd0\u884c\u7684TensorBoard:</p> Python<pre><code>screen -S tensorboard_permanent\ncd /home/student2023/xiehr2023/UnetTSF\ntensorboard --logdir=runs --bind_all --reload_interval=5\n# Ctrl+A D \u5206\u79bbscreen\n</code></pre> <p>\uff082\uff09\u6bcf\u6b21\u53ea\u9700\u8fd0\u884c\u60a8\u7684Python\u811a\u672c\uff0c\u65e0\u9700\u7ba1\u7406TensorBoard:</p> Bash<pre><code>python module_3.py\n</code></pre> <p>\uff083\uff09\u4e00\u76f4\u4f7f\u7528\u76f8\u540c\u7684URL\u67e5\u770b\u7ed3\u679c:</p> Bash<pre><code>http://localhost:6006\n</code></pre> <p>add\uff081\uff09vscode\u81ea\u52a8\u8f6c\u53d1\u7aef\u53e3\uff1a</p> <p></p> <p>add\uff082\uff09\u53ef\u4ee5\u5728 python \u811a\u672c\u4e2d\u52a0\u5165\u542f\u52a8 tensorboard</p> <p>\u597d\u5904\uff1a\u53ea\u9700\u8fd0\u884c\u811a\u672c\uff0c\u7136\u540e\u5728VSCode\u4e2d\u6253\u5f00\u7aef\u53e3\u8f6c\u53d1\uff0c\u5373\u53ef\u8bbf\u95ee\u6700\u65b0\u7684TensorBoard\u7ed3\u679c\u3002\u4e0d\u518d\u9700\u8981\u5355\u72ec\u542f\u52a8TensorBoard\u3001\u8bb0\u4f4f\u65e5\u5fd7\u8def\u5f84\u7b49</p>"},{"location":"CodeRepo/2_SHHtensorboard/","title":"\u8fdc\u7a0b\u670d\u52a1\u5668&amp;tensorboard","text":""},{"location":"CodeRepo/2_SHHtensorboard/#tensorboard","title":"\u8fdc\u7a0b\u670d\u52a1\u5668&amp;tensorboard","text":"2025-04-18 17:57:252025-09-28 12:54:03 <p> \u7ea6 226 \u4e2a\u5b57  6 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u8fdc\u7a0b\u670d\u52a1\u5668\uff08Linux\uff09\u4e0aTensorBoard\u67e5\u770b\u8bad\u7ec3\u8fc7\u7a0b</p> <p>\uff081\uff09SSH \u8fde\u63a5\u8fdc\u7a0b\u670d\u52a1\u5668\uff0c\u8fdb\u5165\u81ea\u5df1\u7684\u9879\u76ee\u6587\u4ef6\u5939\uff0c\u6253\u5f00\u7ec8\u7aef</p> <p>\uff082\uff09screen -r </p> <p>\uff083\uff09\u6fc0\u6d3b\u81ea\u5df1\u7684 python \u865a\u62df\u73af\u5883</p> <p>\uff084 \uff09 \u7ec8\u7aef\u8fd0\u884c tensorboard \u547d\u4ee4\uff1a</p> Bash<pre><code>tensorboard --logdir \u9879\u76ee\u6587\u4ef6\u8def\u5f84 -- --bind_all\n</code></pre> <p>\u7ec8\u7aef\u51fa\u73b0 </p> Bash<pre><code>http://worker01:6006/\n</code></pre> <p>\u5c06\u4e2d\u95f4\u7684 woker01 \u6362\u6210\u670d\u52a1\u5668\u7684 ip \u5730\u5740\uff0c\u7aef\u53e3\u53f7\u4e0d\u53d8</p> Bash<pre><code>http://192.168.58.195:6006/\n</code></pre> <p>\u5173\u4e8e\u6b65\u9aa4 \uff084\uff09\u7684\u8be6\u7ec6\u8fc7\u7a0b\uff1a</p> <p>\uff084\uff09\u7ec8\u7aef\u8fd0\u884c tensorboard \u547d\u4ee4\uff1a</p> Bash<pre><code>tensorboard --logdir \u9879\u76ee\u6587\u4ef6\u8def\u5f84\n</code></pre> <p>\u7ed9\u51fa\u672c\u5730\u8bbf\u95ee\u5730\u5740   <code>http://localhost:6006/</code> \uff1a\u70b9\u51fb\u5373\u53ef</p> <p>\u6b64\u65f6\u70b9\u51fb\u4f1a\u51fa\u73b0\u65e0\u6cd5\u8bbf\u95ee\u7684\u60c5\u51b5\uff0c\u5728\u7ec8\u7aef\u547d\u4ee4\u884c\u7a97\u53e3\u7ed9\u51fa\u4e86\u63d0\u793a\uff0c\u52a0\u4e0a <code>--bind_all</code> \u5f00\u653e\u6240\u6709\u6743\u9650\uff1a</p> <p></p> <p>\u7ec8\u7aef\u91cd\u65b0\u8f93\u5165\uff1a</p> Bash<pre><code>tensorboard --logdir \u9879\u76ee\u6587\u4ef6\u8def\u5f84 --bind_all\n</code></pre> <p></p> <p>\u6b64\u65f6\u7ed9\u51fa\u7684\u8bbf\u95ee\u547d\u4ee4\u53d8\u4e3a\uff1a<code>http://worker01:6006/</code>\uff0c\u4f9d\u7136\u662f\u65e0\u6cd5\u8bbf\u95ee\u7684\u72b6\u6001</p> <p>\u6b64\u65f6\u628a worker01\u6362\u6210\u81ea\u5df1\u7684\u670d\u52a1\u5668 ip \u5373\u53ef\uff0c\u7aef\u53e3\u53f7 <code>6006</code> \u4fdd\u6301\u4e0d\u53d8\uff0c\u5373\u6b63\u786e\u7684\u8bbf\u95ee\u5730\u5740\uff1a</p> Bash<pre><code>http://192.168.58.195:6006/\n</code></pre> <p>\u53ef\u4ee5\u770b\u5230 loss\u3001\u7f51\u7edc\u7ed3\u6784\u56fe\u7b49</p>"},{"location":"CodeRepo/3_args/","title":"\u7c7b\u7684\u521d\u59cb\u5316\u4f20\u5165\u547d\u4ee4\u884c\u53c2\u6570","text":""},{"location":"CodeRepo/3_args/#_1","title":"\u7c7b\u7684\u521d\u59cb\u5316\u4f20\u5165\u547d\u4ee4\u884c\u53c2\u6570","text":"2025-04-18 17:57:252025-09-28 12:54:03 <p> \u7ea6 209 \u4e2a\u5b57  288 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 5 \u5206\u949f</p> <p>\u4e3b\u51fd\u6570\u4f20\u5165\u547d\u4ee4\u884c\u53c2\u6570\uff0c\u8c03\u7528\u7684\u7c7b\u5c31\u80fd\u8c03\u7528\u8fd9\u4e2a\u547d\u4ee4\u884c\u53c2\u6570</p> Python<pre><code>import argparse\n\ndef main(args):\n    device = torch.device(args.device if torch.cuda.is_available() else \"cpu\")\n    print(args)\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--epochs\",type=int,default=30)\n    img_root = 'http://... or \u672c\u5730\u8def\u5f84'\n    parser.add_argument(\"--data_path\",type=str,default=img_toor)\n    parser.add_argument(\"device\",default=\"cuda\",help=\"\u5224\u65ad\u5f53\u524d\u8bbe\u5907\u662f\u5426\u80fd\u4f7f\u7528 cuda\")\n\n    opt = parser.parse_args()\n    main(opt) # \u4f20\u7684\u53c2\u6570\u662f\u5b9e\u4f8b\u5316\u7684\u7c7b\n</code></pre> <p>\u573a\u666f\u63cf\u8ff0\uff1a\u5982\u679c\u53ea\u662f\u60f3\u7b80\u5355\u7684\u6d4b\u8bd5 \u4f7f\u7528\u547d\u4ee4\u884c\u53c2\u6570\u7684\u7c7b\u5462\uff1f\u907f\u514d\u91cd\u590d\u7684\u4ece\u5927\u9879\u76ee\u7684 main \u5f00\u59cb\u6267\u884c</p> Python<pre><code>class Model(nn.Module):\n    def __init__(self, configs):\n        super(Model, self).__init__()\n\n        self.input_channels = configs.enc_in\n        self.input_len = configs.seq_len\n        self.out_len = configs.pred_len\n        self.individual = configs.individual\n        # \u4e0b\u91c7\u6837\u8bbe\u5b9a\n        self.stage_num = configs.stage_num\n    def forward(self, x):\n        '''\n            [B,T,C] -&gt; [B,P,C]\n\n        '''\n        x = self.revin_layer(x, 'norm')  # [B,T,C]\n        return x\n\nif __name__ == '__main__':    \n    # \u521b\u5efa\u4e00\u4e2a\u7b80\u5355\u7684\u914d\u7f6e\u5bf9\u8c61\n    class SimpleConfig:\n        def __init__(self):\n            self.enc_in = 7        # ETT\u6570\u636e\u96c6\u7279\u5f81\u7ef4\u5ea6\n            self.seq_len = 96      # \u8f93\u5165\u5e8f\u5217\u957f\u5ea6\n            self.pred_len = 720    # \u9884\u6d4b\u5e8f\u5217\u957f\u5ea6\n            self.individual = True # \u662f\u5426\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u901a\u9053\n            self.stage_num = 4     # U-Net\u7684\u6df1\u5ea6\n            self.stage_pool_kernel = 3  # \u6c60\u5316\u6838\u5927\u5c0f\n            self.stage_pool_stride = 2  # \u6c60\u5316\u6b65\u957f\n            self.stage_pool_padding = 1 # \u6c60\u5316\u586b\u5145\n            self.trend_kernel = 13  # \u8d8b\u52bf\u5206\u89e3\u7a97\u53e3\u5927\u5c0f\n\n    # \u521b\u5efa\u914d\u7f6e\n    configs = SimpleConfig()\n\n    # \u65e0\u9700\u4f20\u9012\u7684\u53c2\u6570\uff0c\u4f5c\u7528\u4e8e\u4ec5\u5728\u5f53\u524d\u51fd\u6570\n    batch_size = 16\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    # \u901a\u8fc7\u5b9e\u4f8b\u5316\u7684\u7c7b \u7d22\u5f15\u53c2\u6570\uff0c\u76f8\u5f53\u4e8e\u5b9a\u4e49\u5f53\u524d\u4f5c\u7528\u4e8e\u7684\u53d8\u91cf\u503c\n    seq_len = configs.seq_len\n    enc_in = configs.enc_in\n\n    # \u5b9e\u4f8b\u5316\u6a21\u578b\n    model = Model(configs).to(device)\n    # \u751f\u6210\u968f\u673a\u8f93\u5165\u6570\u636e\n    x = torch.randn(batch_size, seq_len, enc_in).to(device)\n    # \u524d\u5411\u4f20\u64ad\n    output = model(x)    \n    print(\"\u6a21\u578b\u7ed3\u6784:\",model)\n    print(f\"\u8f93\u5165\u5f62\u72b6: {x.shape}\")\n    print(f\"\u8f93\u51fa\u5f62\u72b6: {output.shape}\")\n    print(f\"\u9884\u671f\u8f93\u51fa\u5f62\u72b6: [batch_size={batch_size}, pred_len={configs.pred_len}, enc_in={enc_in}]\")\n</code></pre> <ul> <li>\u60f3\u8bf4\u7684\u662f\uff0c\u53ef\u4ee5\u7b80\u5355\u7684\u5b9a\u4e49\u4e00\u4e2a\u914d\u7f6e\u7c7b <code>SimpleConfig()</code> \uff0c\u5c06\u8fd9\u4e2a\u7c7b\u7684\u5b9e\u4f8b <code>configs=SimpleConfig()</code> \uff0c\u4f20\u5165\u521d\u59cb\u5316\u9700\u8981\u547d\u4ee4\u884c\u53c2\u6570\u7684\u7c7b  <code>model = Model(configs)</code></li> <li>\u8fd9\u4e2a\u7b80\u5355\u7684\u914d\u7f6e\u7c7b\u4e0d\u63a5\u6536\u4efb\u4f55\u53c2\u6570\uff0c\u53ea\u9700\u8981\u4e00\u4e2a init \u5b9a\u4e49\u53c2\u6570\u5373\u53ef\uff0c\u5b9e\u73b0\u5728\u7c7b\u4e0e\u7c7b\u4e4b\u95f4\u4f20\u9012\u53c2\u6570\uff0c\u907f\u514d\u521d\u59cb\u5316\u7684\u65f6\u5019\uff0c\u9700\u8981\u4e00\u5927\u5806\u53c2\u6570\uff0c\u9700\u8981\u54ea\u4e2a <code>configs.</code>  \u7d22\u5f15\u5373\u53ef</li> </ul> <p>\u6216\u8005\u5c31\u8fd9\u6837\uff1a\uff08\u5176\u5b9e\u6211\u4e5f\u8fd8\u662f\u6709\u70b9\u6655</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport argparse\nimport sys\n\n# \u7b80\u5316\u7684\u6a21\u578b\u5b9a\u4e49\nclass Model(nn.Module):\n    def __init__(self, configs):\n        super(Model, self).__init__()\n        self.input_channels = configs.enc_in\n        self.input_len = configs.seq_len\n        self.out_len = configs.pred_len\n        self.individual = configs.individual\n        self.stage_num = configs.stage_num\n        # \u7b80\u5316\u8d77\u89c1\uff0c\u53ea\u5b9a\u4e49\u4e00\u4e2a\u7b80\u5355\u7684\u5c42\n        self.revin_layer = nn.LayerNorm([self.input_len, self.input_channels])\n\n    def forward(self, x):\n        '''\n            [B,T,C] -&gt; [B,P,C]\n        '''\n        x = self.revin_layer(x)  # [B,T,C]\n        # \u7b80\u5316\u7684\u524d\u5411\u4f20\u64ad\uff0c\u53ea\u8fd4\u56de\u4e00\u4e2a\u8c03\u6574\u5f62\u72b6\u7684\u5f20\u91cf\u6a21\u62df\u8f93\u51fa\n        return x[:, :self.out_len, :]\n\n\n\nif __name__ == '__main__':\n    # \u521b\u5efa\u547d\u4ee4\u884c\u53c2\u6570\u89e3\u6790\u5668\n    parser = argparse.ArgumentParser(description='Time-Unet\u6a21\u578b\u6d4b\u8bd5')\n\n    # \u6dfb\u52a0\u547d\u4ee4\u884c\u53c2\u6570\n    parser.add_argument('--enc_in', type=int, default=7, help='\u8f93\u5165\u7279\u5f81\u7ef4\u5ea6')\n    parser.add_argument('--seq_len', type=int, default=96, help='\u8f93\u5165\u5e8f\u5217\u957f\u5ea6')\n    parser.add_argument('--pred_len', type=int, default=720, help='\u9884\u6d4b\u5e8f\u5217\u957f\u5ea6')\n    parser.add_argument('--individual', action='store_true', help='\u662f\u5426\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u901a\u9053')\n    parser.add_argument('--stage_num', type=int, default=4, help='U-Net\u6df1\u5ea6')\n    parser.add_argument('--batch_size', type=int, default=16, help='\u6279\u6b21\u5927\u5c0f')\n    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu', \n                        help='\u8ba1\u7b97\u8bbe\u5907 (cuda/cpu)')\n    parser.add_argument('--print_model', action='store_true', help='\u662f\u5426\u6253\u5370\u6a21\u578b\u7ed3\u6784')\n\n    # \u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570\n    args = parser.parse_args()\n\n    # \u8bbe\u7f6e\u8bbe\u5907\n    device = torch.device(args.device)\n\n    # \u5b9e\u4f8b\u5316\u6a21\u578b\u5e76\u79fb\u81f3\u6307\u5b9a\u8bbe\u5907\n    model = Model(args).to(device)\n\n    # \u751f\u6210\u968f\u673a\u8f93\u5165\u6570\u636e\n    x = torch.randn(args.batch_size, args.seq_len, args.enc_in).to(device)\n\n    # \u524d\u5411\u4f20\u64ad\n    with torch.no_grad():\n        output = model(x)\n\n    # \u6253\u5370\u4fe1\u606f\n    if args.print_model:\n        print(\"\u6a21\u578b\u7ed3\u6784:\", model)\n\n    print(f\"\u8f93\u5165\u5f62\u72b6: {x.shape}\")\n    print(f\"\u8f93\u51fa\u5f62\u72b6: {output.shape}\")\n    print(f\"\u9884\u671f\u8f93\u51fa\u5f62\u72b6: [batch_size={args.batch_size}, pred_len={args.pred_len}, enc_in={args.enc_in}]\")\n</code></pre> <p>\u8be5\u8bf4\u4e0d\u8bf4\uff0c\u5c01\u88c5\u7684\u597d\u62bd\u8c61\uff1a</p> Python<pre><code>import argparse\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    \"\"\"\n    \u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u7ee7\u627f\u81eann.Module\n    \u7528\u4e8e\u6f14\u793a\u6a21\u5757\u5316\u4ee3\u7801\u7ed3\u6784\n    \"\"\"\n    def __init__(self, args):\n        \"\"\"\n        \u6a21\u578b\u521d\u59cb\u5316\n        \u53c2\u6570:\n            args: \u5305\u542b\u6a21\u578b\u914d\u7f6e\u7684\u53c2\u6570\u5bf9\u8c61\n        \"\"\"\n        super(Model, self).__init__()\n        # \u4eceargs\u83b7\u53d6\u914d\u7f6e\u53c2\u6570\n        self.input_channels = args.enc_in\n        self.input_len = args.seq_len\n        self.out_len = args.pred_len\n        self.individual = getattr(args, 'individual', False)\n\n        # \u5b9a\u4e49\u7f51\u7edc\u5c42\n        self.norm_layer = nn.LayerNorm([self.input_len, self.input_channels])\n        self.fc = nn.Linear(self.input_len, self.out_len)\n\n    def forward(self, x):\n        \"\"\"\n        \u524d\u5411\u4f20\u64ad\n        \u53c2\u6570:\n            x: \u8f93\u5165\u5f20\u91cf, \u5f62\u72b6\u4e3a [batch_size, seq_len, enc_in]\n        \u8fd4\u56de:\n            \u8f93\u51fa\u5f20\u91cf, \u5f62\u72b6\u4e3a [batch_size, pred_len, enc_in]\n        \"\"\"\n        # \u7b80\u5355\u5904\u7406: \u5f52\u4e00\u5316\u3001\u8f6c\u7f6e\u3001\u7ebf\u6027\u53d8\u6362\u3001\u518d\u8f6c\u7f6e\n        x = self.norm_layer(x)  # [batch, seq_len, enc_in]\n        x_t = x.transpose(1, 2)  # [batch, enc_in, seq_len]\n        out = self.fc(x_t)  # [batch, enc_in, pred_len]\n        return out.transpose(1, 2)  # [batch, pred_len, enc_in]\n\ndef parse_args():\n    \"\"\"\n    \u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570\n\n    \u8fd4\u56de:\n        args: \u89e3\u6790\u540e\u7684\u53c2\u6570\u5bf9\u8c61\n    \"\"\"\n    parser = argparse.ArgumentParser(description='\u6a21\u5757\u5316\u6a21\u578b\u6d4b\u8bd5\u793a\u4f8b')\n\n    # \u6dfb\u52a0\u547d\u4ee4\u884c\u53c2\u6570\n    parser.add_argument('--enc_in', type=int, default=7, help='\u8f93\u5165\u7279\u5f81\u7ef4\u5ea6')\n    parser.add_argument('--seq_len', type=int, default=96, help='\u8f93\u5165\u5e8f\u5217\u957f\u5ea6')\n    parser.add_argument('--pred_len', type=int, default=48, help='\u9884\u6d4b\u5e8f\u5217\u957f\u5ea6')\n    parser.add_argument('--individual', action='store_true', help='\u662f\u5426\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u901a\u9053')\n    parser.add_argument('--batch_size', type=int, default=16, help='\u6279\u6b21\u5927\u5c0f')\n    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu', \n                        help='\u8ba1\u7b97\u8bbe\u5907')\n    parser.add_argument('--print_model', action='store_true', help='\u662f\u5426\u6253\u5370\u6a21\u578b\u7ed3\u6784')\n\n    return parser.parse_args()\n\ndef build_model(args):\n    \"\"\"\n    \u6784\u5efa\u5e76\u521d\u59cb\u5316\u6a21\u578b\n\n    \u53c2\u6570:\n        args: \u5305\u542b\u6a21\u578b\u914d\u7f6e\u7684\u53c2\u6570\u5bf9\u8c61\n\n    \u8fd4\u56de:\n        model: \u6784\u5efa\u7684\u6a21\u578b\n        device: \u8ba1\u7b97\u8bbe\u5907\n    \"\"\"\n    device = torch.device(args.device)\n    model = Model(args).to(device)\n    print(f\"\u6a21\u578b\u5df2\u6784\u5efa\uff0c\u4f7f\u7528\u8bbe\u5907: {device}\")\n    return model, device\n\ndef generate_data(args, device):\n    \"\"\"\n    \u751f\u6210\u6d4b\u8bd5\u6570\u636e\n\n    \u53c2\u6570:\n        args: \u5305\u542b\u6570\u636e\u914d\u7f6e\u7684\u53c2\u6570\u5bf9\u8c61\n        device: \u8ba1\u7b97\u8bbe\u5907\n\n    \u8fd4\u56de:\n        data: \u751f\u6210\u7684\u968f\u673a\u6570\u636e\n    \"\"\"\n    data = torch.randn(args.batch_size, args.seq_len, args.enc_in).to(device)\n    print(f\"\u5df2\u751f\u6210\u968f\u673a\u6570\u636e\uff0c\u5f62\u72b6: {data.shape}\")\n    return data\n\ndef evaluate_model(model, data):\n    \"\"\"\n    \u6a21\u578b\u8bc4\u4f30\n\n    \u53c2\u6570:\n        model: \u5f85\u8bc4\u4f30\u7684\u6a21\u578b\n        data: \u8f93\u5165\u6570\u636e\n\n    \u8fd4\u56de:\n        output: \u6a21\u578b\u9884\u6d4b\u7ed3\u679c\n    \"\"\"\n    print(\"\u5f00\u59cb\u6a21\u578b\u8bc4\u4f30...\")\n    with torch.no_grad():\n        output = model(data)\n    print(\"\u8bc4\u4f30\u5b8c\u6210\uff01\")\n    return output\n\ndef print_results(args, data, output):\n    \"\"\"\n    \u6253\u5370\u7ed3\u679c\n\n    \u53c2\u6570:\n        args: \u53c2\u6570\u5bf9\u8c61\n        data: \u8f93\u5165\u6570\u636e\n        output: \u6a21\u578b\u8f93\u51fa\n    \"\"\"\n    print(\"\\n----- \u7ed3\u679c\u62a5\u544a -----\")\n    print(f\"\u8f93\u5165\u5f62\u72b6: {data.shape}\")\n    print(f\"\u8f93\u51fa\u5f62\u72b6: {output.shape}\")\n    print(f\"\u9884\u671f\u8f93\u51fa\u5f62\u72b6: [batch_size={args.batch_size}, pred_len={args.pred_len}, enc_in={args.enc_in}]\")\n    print(\"-------------------\\n\")\n\ndef main():\n    \"\"\"\n    \u4e3b\u51fd\u6570\uff1a\u534f\u8c03\u6574\u4e2a\u7a0b\u5e8f\u7684\u6267\u884c\u6d41\u7a0b\n    \"\"\"\n    print(\"===== \u5f00\u59cb\u6267\u884c\u6a21\u578b\u6d4b\u8bd5 =====\\n\")\n\n    # \u6b65\u9aa41: \u89e3\u6790\u53c2\u6570\n    print(\"\u6b65\u9aa41: \u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570\")\n    args = parse_args()\n\n    # \u6b65\u9aa42: \u6784\u5efa\u6a21\u578b\n    print(\"\\n\u6b65\u9aa42: \u6784\u5efa\u6a21\u578b\")\n    model, device = build_model(args)\n\n    # \u6b65\u9aa43: \u751f\u6210\u6570\u636e\n    print(\"\\n\u6b65\u9aa43: \u751f\u6210\u6d4b\u8bd5\u6570\u636e\")\n    data = generate_data(args, device)\n\n    # \u6b65\u9aa44: \u8bc4\u4f30\u6a21\u578b\n    print(\"\\n\u6b65\u9aa44: \u8bc4\u4f30\u6a21\u578b\")\n    output = evaluate_model(model, data)\n\n    # \u6b65\u9aa45: \u6253\u5370\u7ed3\u679c\n    print(\"\\n\u6b65\u9aa45: \u6253\u5370\u7ed3\u679c\")\n    if args.print_model:\n        print(\"\u6a21\u578b\u7ed3\u6784:\", model)\n    print_results(args, data, output)\n\n    print(\"===== \u6d4b\u8bd5\u5b8c\u6210 =====\")\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>\u4e5f\u8fd8\u884c\u5427\u3002</p>"},{"location":"CodeRepo/4_PreTrained/","title":"\u9884\u8bad\u7ec3\u6743\u91cd","text":""},{"location":"CodeRepo/4_PreTrained/#_1","title":"\u9884\u8bad\u7ec3\u6743\u91cd","text":"2025-04-20 14:04:312025-09-28 12:54:03 <p> \u7ea6 114 \u4e2a\u5b57  9 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p></p> <p></p> <p></p> <p></p> <p>\u95ee\u9898\u5728\u4e8e\u4e0d\u80fd\u4e00\u4e00\u5bf9\u5e94\uff1a</p> <p><code>load_state_dict</code> \u4e2d\u7684 <code>strict = True</code></p> <p></p>"},{"location":"CodeRepo/4_PreTrained/#1","title":"\u89e3\u51b3\u529e\u6cd51","text":"<p><code>torch.load_state_dict</code>\uff0c\u52a0\u53c2\u6570\uff0c<code>strict=False</code></p>"},{"location":"CodeRepo/4_PreTrained/#2","title":"\u89e3\u51b3\u65b9\u6cd5 2","text":"<p>\u52a0\u5224\u65ad\u8bed\u53e5</p> <p></p> <p><code>model_dict</code>  \u662f\u81ea\u5df1\u6539\u7684</p> <p><code>ckpt</code> \u539f\u59cb\u7684</p> <ul> <li>\u5728\u54ea\u513f\u6539\uff1f</li> </ul> <p></p> <p>\u627e\u5230\u6e90\u7801\u4e2d \u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u7684\u5730\u65b9 \uff0c\u4fee\u6539\u4e3a\u4e0a\u9762\u7684\u5224\u65ad\u8bed\u53e5\u4ee3\u7801</p>"},{"location":"CodeRepo/4_PreTrained/#gpu-gpu","title":"\u5355 GPU \u548c\u591a GPU","text":"<p>\u628a <code>module.</code> \u66ff\u6362\u6210 <code>''</code> \u7a7a\uff0c\u4fdd\u8bc1\u540d\u5b57\u662f\u4e00\u81f4\u7684\uff0c\u53ef\u4ee5\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\u3002</p>"},{"location":"Error/Typora_1/","title":"PicGo+Typora+Github\u56fe\u5e8a\u8bbe\u7f6e","text":""},{"location":"Error/Typora_1/#picgotyporagithub","title":"PicGo+Typora+Github\u56fe\u5e8a\u8bbe\u7f6e","text":"2025-04-20 14:04:312025-09-28 12:54:03 <p> \u7ea6 218 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u2753PicGo \u547d\u4ee4\u884c\u3001GUI\u63d2\u4ef6\u5b89\u88c5</p> <p>\u2705[Solved]\u5f53\u8bbe\u7f6e\u63d2\u5165\u56fe\u7247\u65f6\u4e0a\u4f20\uff0c\u4f1a\u81ea\u52a8\u5f39\u51fa PicGo \u4e3b\u7a97\u53e3</p> <p>\ud83d\udea9[Update]\u5728\u5199 markdown\u65f6\uff0c\u56fe\u7247\u9009\u62e9\u672c\u5730\u5b58\u50a8\uff0c\u540e\u9762\u5199\u5b8c\u4e86\uff0c\u53ef\u4ee5\u5728 Typora \u4e2d\u8bbe\u7f6e\u4e0a\u4f20\u6240\u6709\u56fe\u7247</p> <p><code>Typora -\u300b\u683c\u5f0f -\u300b \u56fe\u50cf -\u300b \u4e0a\u4f20\u6240\u6709\u672c\u5730\u56fe\u7247</code></p> <p>\u2753\u90a3\u672c\u5730\u56fe\u7247\u8fd8\u7559\u7740\u4e0d</p> <p>\u2705[Solved]\u5df2\u7ecf\u4e0a\u4f20\u7684\u4f1a\u91cd\u590d\u4e0a\u4f20\u5417\uff1f\u4e0d\u4f1a\uff0c\u5df2\u6d4b\u8bd5\uff0c\u4f1a\u663e\u793a <code>\u6587\u6863\u672a\u5305\u542b\u672c\u5730\u56fe\u7247</code> </p> <p>\ud83d\udea9 [Update] \u8fd9\u4e2a\u94fe\u63a5\u53ef\u4ee5\u914d\u7f6e\u963f\u91cc\u4e91\u56fe\u5e8a\u7ba1\u7406\uff0c\u5176\u5b9e\u6211\u73b0\u5728\u7528\u7684 Github+PicGo\uff0c\u4f46\u662f\u8003\u8651\u5230\u540e\u9762\u53ef\u80fd\u4f1a\u5f04\u4e00\u4e2a\u56fd\u5185\u9759\u6001\u7f51\u9875\u6258\u7ba1\uff0c\u6240\u4ee5\u8fd8\u662f\u963f\u91cc\u4e91\u817e\u8baf\u4e91\u66f4\u597d\uff0c\u4e0d\u8d35\u3002</p> <p>\ud83d\udea9 [Update] \u4ece\u5934\u7684\u914d\u7f6e\u6211\u5fd8\u4e86\uff0c\u4f46\u662f\u7528\u5230\u73b0\u5728\u5e38\u7528\u7684\u8bbe\u7f6e\u3002</p>"},{"location":"Error/Typora_1/#_1","title":"\u4e0a\u4f20\u56fe\u7247","text":"<p>\u573a\u666f\uff1a\u4f7f\u7528\u4e86\u56fe\u5e8a\uff0c\u76f4\u63a5\u4e0d\u5728\u672c\u5730\u5b58\u50a8\uff0c\u6b64\u65f6\uff1a</p> <p></p> <p>\uff1a2025-04-19 Saturday </p>"},{"location":"Error/docker/","title":"docker","text":""},{"location":"Error/docker/#docker","title":"docker","text":"2025-02-26 16:43:322025-09-28 12:54:03 <p> \u7ea6 323 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <ul> <li> \u670d\u52a1\u5668\u62c9\u53d6\u4e0d\u4e86 docker \u955c\u50cf</li> </ul> <p>Error response from daemon: Get \"https://registry-1.docker.io/v2/\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</p> <p></p> <ul> <li> \u670d\u52a1\u5668\u4e5f build \u4e0d\u4e86\u955c\u50cf</li> </ul> <p></p> <ul> <li> \u95ee\u9898\u63cf\u8ff0</li> </ul> <p>\u8bf4\u5b9e\u8bdd\uff0c\u6211\u771f\u7684\u70b8\u88c2\uff0c\u73b0\u5728\u662f\u60f3\u8981\u4e00\u4e2a docker \u80fd\u591f\u8dd1\u901a\u81ea\u5df1\u7684\u7a0b\u5e8f\uff0c\u4e3a\u4e86\u589e\u52a0\u53ef\u79fb\u690d\u6027\uff0c\u60f3\u521b\u5efa\u4e00\u4e2a docker \u7684\u955c\u50cf\uff0c\u672c\u6765\u60f3\u7740\u76f4\u63a5\u62c9\u53d6\u4e00\u4e2a\u57fa\u7840\u7684\u955c\u50cf\uff0c\u7136\u540e\u66f4\u6539\uff0c\u6bd4\u5982 \u8fd9\u4e2a\u94fe\u63a5 \uff0c\u7ed3\u679c\u5462\uff0c\u670d\u52a1\u5668\u4ee3\u7406\u51fa\u95ee\u9898\uff0c\u62c9\u53d6\u4e0d\u4e0b\u6765\uff1b</p> <p>\u90a3\u5c31\u60f3\u7740\u672c\u5730\u62c9\u53d6\u7136\u540e\u4e0a\u4f20\u670d\u52a1\u5668\uff0c\u62c9\u53d6\u662f\u53ef\u4ee5\u7684\uff0c\u4f46\u662f\u955c\u50cf\u662f\u955c\u50cf\uff0c\u5bb9\u5668\u662f\u5bb9\u5668\uff0c\u62c9\u53d6\u4e0b\u6765\u7684\u5bb9\u5668\u9700\u8981\u5b9e\u4f8b\u5316\u4e3a\u955c\u50cf\uff0c\u4e5f\u662f\u9700\u8981 run \u4e00\u4e2a\uff0c\u7ed3\u679c\u672c\u5730\u6ca1\u6709 cuda\uff0c\u62a5\u9519 \u5bbf\u4e3b\u673a\u786c\u4ef6\u4e0d\u591f\u7684\u610f\u601d\uff0c\u4e0d\u884c\uff1b</p> <p>\u5b9e\u5728\u4e0d\u884c\uff0c\u5c31\u81ea\u5df1\u5199 dockerfile \u628a\uff0c\u5361\u5230\u4e86\u6784\u5efa\u955c\u50cf docker build \u4e00\u6b65\uff0c\u53c8\u53cc\u53d2\u62a5\u9519\u4e86\uff0c\u4ed4\u7ec6\u770b\u90fd\u662f\u670d\u52a1\u5668\u4ee3\u7406\u7684\u95ee\u9898\u3002</p> <p>\u8be5\u600e\u4e48\u529e\uff0c\u5fc3\u70e6\u610f\u4e71\uff0c\u8fd8\u662f\u95ee\u95ee\u540c\u5b66\uff0c\u600e\u4e48\u56de\u4e8b\u3002\u95ee\u4e86</p> <p>\uff081\uff09\u672c\u5730\u7f51\u7edc\u6709\u4ee3\u7406\uff0c\u4e0d\u4ee3\u8868\u670d\u52a1\u5668\u4e5f\u6709\u4ee3\u7406</p> <p>\uff082\uff09\u672c\u5730\u4e0b\u8f7d\u4e0b\u6765\uff0c\u53bb\u4e0a\u4f20\u5230\u672c\u5730\uff0c\u90a3\u5c31\u4e0d\u4e0b\u6709 cuda \u7684</p> <p>\u5fc3\u6001\uff0c\u6bcf\u4e2a\u4eba\u90fd\u4f1a\u9047\u5230\u95ee\u9898\uff0c\u6bcf\u4e2a\u4eba\u90fd\u5728\u89e3\u51b3\u95ee\u9898</p> <p>\u5df2\u89e3\u51b3\u3002</p>"},{"location":"Error/github/","title":"github","text":""},{"location":"Error/github/#github","title":"github","text":"2024-11-15 11:05:582025-09-28 12:54:03 <p> \u7ea6 362 \u4e2a\u5b57  9 \u884c\u4ee3\u7801  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p>"},{"location":"Error/github/#_1","title":"\u7ebf\u4e0a\u548c\u672c\u5730\u4e0d\u540c\u6b65\u95ee\u9898","text":"<p>Git: fatal: unable to access 'https://github.com/dearRongerr/Rongerr.github.io.git/': Failure when receiving data from the peer</p> <p>\u5148\u5c06\u8fdc\u7a0b\u5206\u652f\u7684\u66f4\u6539\u5408\u5e76\u5230\u672c\u5730\u5206\u652f\uff0c\u7136\u540e\u518d\u63a8\u9001\u3002\u8bf7\u6309\u7167\u4ee5\u4e0b\u6b65\u9aa4\u64cd\u4f5c\uff1a</p> <ul> <li>\u62c9\u53d6\u8fdc\u7a0b\u5206\u652f\u7684\u66f4\u6539\u5e76\u5408\u5e76\u5230\u672c\u5730\u5206\u652f\uff1a</li> </ul> Bash<pre><code>  git pull origin main --rebase\n</code></pre> <ul> <li>\u89e3\u51b3\u4efb\u4f55\u53ef\u80fd\u7684\u51b2\u7a81\u3002\u5982\u679c\u6709\u51b2\u7a81\uff0cGit \u4f1a\u63d0\u793a\u4f60\u89e3\u51b3\u51b2\u7a81\u3002\u89e3\u51b3\u51b2\u7a81\u540e\uff0c\u7ee7\u7eed\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a</li> </ul> Bash<pre><code>  git rebase --continue\n</code></pre> <ul> <li>\u6700\u540e\uff0c\u63a8\u9001\u672c\u5730\u5206\u652f\u5230\u8fdc\u7a0b\u4ed3\u5e93\uff1a</li> </ul> Bash<pre><code>git push -u origin main\n</code></pre>"},{"location":"Error/github/#couldnt-connect-to-server","title":"Couldn't connect to server","text":"<p>Git: fatal: unable to access 'https://github.com/dearRongerr/Rongerr.github.io.git/': Failed to connect to github.com port 443 after 75002 ms: Couldn't connect to server</p> <ul> <li>\u7f51\u7edc\u95ee\u9898\uff0c\u5173\u4ee3\u7406\uff0c\u5982\u679c\u8fd8\u4e0d\u80fd\u89e3\u51b3\uff1a</li> <li>\uff08\u7b2c\u4e00\u79cd\u60c5\u51b5\uff09\u4f7f\u7528 vpn\uff0c\u7f51\u9875\u53ef\u4ee5\u6253\u5f00github\uff0c\u8fd9\u79cd\u60c5\u51b5\u8bf4\u660e\u547d\u4ee4\u884c\u5728\u62c9\u53d6\u3001\u63a8\u9001\u4ee3\u7801\u65f6\u6ca1\u6709\u4f7f\u7528 vpn \u6253\u5f00\u4ee3\u7406\uff0c\u89e3\u51b3\u65b9\u6cd5\uff1a</li> </ul> <p>\u914d\u7f6e socks5 \u4ee3\u7406\u3001\u914d\u7f6ehttp\u4ee3\u7406</p> Bash<pre><code>git config --global http.proxy socks5 127.0.0.1:7890\ngit config --global https.proxy socks5 127.0.0.1:7890\ngit config --global http.proxy 127.0.0.1:7890\ngit config --global https.proxy 127.0.0.1:7890\n</code></pre> <ul> <li>\uff08\u7b2c\u4e8c\u79cd\u60c5\u51b5\uff09\u5982\u679c\u672a\u4f7f\u7528 vpn\uff0c\u6b64\u65f6\u89e3\u51b3\u65b9\u6cd5\uff0c\u53d6\u6d88\u4ee3\u7406\uff0c\u7ec8\u7aef\u8f93\u5165\uff1a</li> </ul> Bash<pre><code>git config --global --unset http.proxy\ngit config --global --unset https.proxy\n</code></pre> <p></p>"},{"location":"Error/github/#github_1","title":"\u5b89\u88c5 github \u4e0a\u7684\u5e93","text":"<p>setup.py</p> <p></p>"},{"location":"Error/github/#_2","title":"\u4e0d\u5c0f\u5fc3\u8bef\u70b9\u8fde\u63a5\u8fdc\u7a0b\u4ed3\u5e93","text":"<p>\u7ec8\u7aef\uff1a<code>rm -rf .git</code>  \u5220\u9664.git\u6587\u4ef6</p>"},{"location":"Error/github/#_3","title":"\u95ee\u9898\u63cf\u8ff0","text":"<ul> <li> git clone \u672c\u5730\u7684\u9879\u76ee\u603b\u662f\u8fde\u7740\u8fdc\u7a0b\u4ed3\u5e93\uff08\u597d\u50cf\uff09</li> </ul> <p>\u89e3\u51b3\uff1a\u4f60\u628a ==.git\u6587\u4ef6\u5220\u4e86==\u4e0d\u5c31\u5f97\u4e86\uff0c\u5e94\u8be5\u662f \u81ea\u5e26\u7684.git\u4ed3\u5e93\uff0c\u540c\u6b65\u5230\u4e86\u672c\u5730\uff0c\u6240\u4ee5\u672c\u5730\u4e5f\u5b58\u4e86\u7248\u672c\u5e93\uff0c\u4f46\u662f\u6ca1\u6709\u8fde\u63a5\u5230\u8fdc\u7a0b\u4ed3\u5e93\uff1f\u4f46\u8fd8\u662f\u4e0d\u6562push\uff0c\u4e07\u4e00\u4f20\u5230\u4e86\u5927\u4f6c\u4f5c\u8005\u7684\u4ed3\u5e93\u3002</p> <p>\u590d\u5236\uff1arm -rf .git</p> <p></p>"},{"location":"Error/latex/","title":"Latex","text":""},{"location":"Error/latex/#latex","title":"Latex","text":"2024-12-19 18:20:132025-09-28 12:54:03 <p> \u7ea6 77 \u4e2a\u5b57  17 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <ul> <li> overleaf\u5168\u662f\u7ea2\u7ebf</li> </ul> <p>menu\u2014speak cheak\uff1aoff</p> <ul> <li> <code>% \u53bb\u6389thebibliography\u73af\u5883\u81ea\u5e26\u7684\u201c\u53c2\u8003\u6587\u732e\u201d\u6807\u9898</code></li> </ul> <p>\u95ee\u9898\u63cf\u8ff0\uff1a<code>.cls</code>\u6587\u4ef6\u4e2d\u7684\u58f0\u660e\uff0c\u5728\u6587\u6863\u6e32\u67d3\u7684\u65f6\u5019\uff0c\u81ea\u52a8\u51fa\u73b0\u201c\u53c2\u8003\u6587\u732e\u201d\u5b57\u6837\uff0c\u6ca1\u6709\u7f16\u53f7\u4e14\u4e0d\u5728\u76ee\u5f55\u4e2d\u7f16\u53f7</p> Text Only<pre><code>\\bibliographystyle{IEEEtran}\n</code></pre> <p>\u89e3\u51b3\uff1a</p> Python<pre><code>\\renewcommand{\\refname}{\\section{\u53c2\u8003\u6587\u732e}}\n\\bibliography{books}\n</code></pre> <ul> <li> section\u683c\u5f0f\u8bbe\u7f6e</li> </ul> <p></p> TeX<pre><code>\\setcounter{page}{1}\n\n\\CTEXsetup[format={\\Large\\bfseries}]{section}\n\n\\begin{center}\n\\section*{\\textbf{\u5f00 \u9898 \u62a5 \u544a \u6b63 \u6587}}\n\\end{center}\n\n\u5b66\u4f4d\u8bba\u6587\u7814\u7a76\u8bfe\u9898\uff1a\n\n\\textbf{\u8bfe\u9898\u6765\u6e90\uff1a}1.\u7eb5\u5411\u8bfe\u9898\uff08  \uff09\uff1b2.\u6a2a\u5411\u8bfe\u9898\uff08  \uff09\uff1b3.\u81ea\u7531\u9009\u9898\uff08\u221a  \uff09\uff1b4.\u5176\u4ed6\uff08  \uff09\u3002\u8bf7\u6253\u201c\u221a\u201d\u3002\n\n\\section{\u7acb\u9898\u4f9d\u636e}\n\n\\subsection{\u7814\u7a76\u80cc\u666f\u53ca\u610f\u4e49}\n</code></pre> <p></p>"},{"location":"Error/macos/","title":"macOS","text":""},{"location":"Error/macos/#macos","title":"macOS","text":"2025-02-24 10:39:202025-09-28 12:54:03 <p> \u7ea6 12 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <ul> <li> \u5df2\u89e3\u51b3</li> </ul> <p> </p> <p>https://baijiahao.baidu.com/s?id=1821450409666781335&amp;wfr=spider&amp;for=pc</p> <p>\u89e3\u51b3\uff1a</p> <p>https://docs.docker.com/desktop/cert-revoke-solution/ </p> <p></p> <p></p>"},{"location":"Error/python/","title":"python","text":""},{"location":"Error/python/#python","title":"python","text":"2025-02-22 22:04:482025-09-28 12:54:03 <p> \u7ea6 119 \u4e2a\u5b57  17 \u884c\u4ee3\u7801  4 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p>"},{"location":"Error/python/#address-already-in-use","title":"Address already in use","text":"<p>\u95ee\u9898\uff1aRuntimeError: Can't listen for client connections: [Errno 98] Address already in use</p> <p>\u8fd9\u8fb9\u5efa\u8bae\u60a8\u8fd8\u662f\u6b63\u5e38\u7684\u65ad\u5f00\u8fde\u63a5\u3001\u9000\u51fa\u8c03\u8bd5\uff0c\u522b\u610f\u5916\u4e2d\u65ad\u3002</p>"},{"location":"Error/python/#cuda-pytorch","title":"cuda \u4e0e pytorch \u7248\u672c\u4e0d\u517c\u5bb9","text":"Python<pre><code>    File \"/home/student2023/xiehr2023/GeCo-main/geco_test/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 552, in build_extensions\n      _check_cuda_version(compiler_name, compiler_version)\n    File \"/home/student2023/xiehr2023/GeCo-main/geco_test/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 447, in _check_cuda_version\n      raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))\n  RuntimeError:\n  The detected CUDA version (12.3) mismatches the version that was used to compile\n  PyTorch (11.8). Please make sure to use the same CUDA versions.\n\n  [end of output]\n</code></pre> Python<pre><code>pip uninstall torch torchvision torchaudio\npip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu123\n</code></pre>"},{"location":"Error/python/#github-python","title":"\u4ece github \u4e0a\u5b89\u88c5 python \u5e93","text":"<p>\u672c\u5730\u4f7f\u7528 git \u5b89\u88c5</p> <p>\u7b2c\u4e00\u6b65\uff0c\u5b89\u88c5 git</p> Bash<pre><code>apt-get update\napt-get install -y git\n</code></pre> <p>\ud83d\udfe2 \u7b2c\u4e8c\u6b65\uff0c\u514b\u9686\u8fdc\u7a0b\u4ed3\u5e93\u5230\u672c\u5730\uff1a</p> <p></p>Bash<pre><code>git clone https://github.com/facebookresearch/detectron2.git\n</code></pre> \u7b2c\u4e09\u6b65\uff0c\u8fdb\u5165\u76ee\u5f55\uff08github \u4e0a\u7684\u6839\u76ee\u5f55\uff09\u5e76\u5b89\u88c5<p></p> Bash<pre><code>cd detectron2\n</code></pre> <p> </p> Bash<pre><code>python setup.py install\n</code></pre> <p>\u8865\u5145\uff1a\u5982\u679c zip \u4e0b\u8f7d\u4e0b\u6765\u7684\uff0c\u9700\u8981\u8fdb\u5165</p> <p></p> <p>\u53e6\u5916\u4e00\u79cd\u5b89\u88c5\u3002</p> Bash<pre><code>python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n</code></pre>"},{"location":"Reproduction/","title":"\u8bba\u6587\u590d\u73b0","text":""},{"location":"Reproduction/#_1","title":"\u8bba\u6587\u590d\u73b0","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 94 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u7b2c\u4e00\u7bc7\u590d\u73b0\u7684\u8bba\u6587\u662f\uff1aloca</p> <p>\u7b2c\u4e8c\u7bc7\u590d\u73b0\u7684\u8bba\u6587\u662f\uff1aGeco</p> <p>\u7b2c\u4e09\u7bc7\u590d\u73b0\u7684\u662f\uff1aSegRNN</p> <p>\u5931\u8d25\uff1aDave \u7684\u4ee3\u7801\u6570\u636e\u6587\u4ef6\u6709\u95ee\u9898\uff0c\u662f \u6e90\u7801\u4e2ddataloade\u6570\u636e\u52a0\u8f7d\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u5728 issue \u4e2d\u56de\u7b54\u4e86\u522b\u4eba\u7684\u95ee\u9898\uff0c\u6211\u6ca1\u770b\u61c2\uff0c\u540e\u9762\u5c31\u6ca1\u770b\u4e86\u3002</p> <p>\u7b2c\u4e09\u7bc7\u4f1a\u597d\u597d\u6574\u7406\u4e00\u4e0b\u590d\u73b0\u8fc7\u7a0b\u3002</p>"},{"location":"Reproduction/1/","title":"\u4e00\u4e9b\u6a21\u5757","text":""},{"location":"Reproduction/1/#_1","title":"\u4e00\u4e9b\u6a21\u5757","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 4015 \u4e2a\u5b57  1415 \u884c\u4ee3\u7801  49 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 38 \u5206\u949f</p>"},{"location":"Reproduction/1/#_2","title":"\u901a\u9053\u6ce8\u610f\u529b\u53ca\u5176\u53d8\u4f53","text":""},{"location":"Reproduction/1/#senet","title":"\u221a SENet","text":"Python<pre><code>import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import init\n\n\"Squeeze-and-Excitation Networks\"\n\nclass SEAttention(nn.Module):\n\n    def __init__(self, channel=512,reduction=16):\n        super().__init__()\n        # \u5728\u7a7a\u95f4\u7ef4\u5ea6\u4e0a,\u5c06H\u00d7W\u538b\u7f29\u4e3a1\u00d71\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        # \u5305\u542b\u4e24\u5c42\u5168\u8fde\u63a5,\u5148\u964d\u7ef4,\u540e\u5347\u7ef4\u3002\u6700\u540e\u63a5\u4e00\u4e2asigmoid\u51fd\u6570\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel, bias=False),\n            nn.Sigmoid()\n        )\n\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        # (B,C,H,W)\n        B, C, H, W = x.size()\n        # Squeeze: (B,C,H,W)--&gt;avg_pool--&gt;(B,C,1,1)--&gt;view--&gt;(B,C)\n        y = self.avg_pool(x).view(B, C)\n        # Excitation: (B,C)--&gt;fc--&gt;(B,C)--&gt;(B, C, 1, 1)\n        y = self.fc(y).view(B, C, 1, 1)\n        # scale: (B,C,H,W) * (B, C, 1, 1) == (B,C,H,W)\n        out = x * y\n        return out\n\n\nif __name__ == '__main__':\n    # (B,C,H,W)\n    input=torch.randn(1,512,7,7)\n    # \u5b9a\u4e49\u901a\u9053\u6ce8\u610f\u529b\n    Model = SEAttention(channel=512,reduction=8)\n    output=Model(input)\n    print(output.shape) \n</code></pre> Python<pre><code>import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import init\n\nclass SEAttention(nn.Module):\n    # \u521d\u59cb\u5316SE\u6a21\u5757\uff0cchannel\u4e3a\u901a\u9053\u6570\uff0creduction\u4e3a\u964d\u7ef4\u6bd4\u7387\n    def __init__(self, channel=512, reduction=16):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # \u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316\u5c42\uff0c\u5c06\u7279\u5f81\u56fe\u7684\u7a7a\u95f4\u7ef4\u5ea6\u538b\u7f29\u4e3a1x1\n        self.fc = nn.Sequential(  # \u5b9a\u4e49\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u4f5c\u4e3a\u6fc0\u52b1\u64cd\u4f5c\uff0c\u901a\u8fc7\u964d\u7ef4\u548c\u5347\u7ef4\u8c03\u6574\u901a\u9053\u91cd\u8981\u6027\n            nn.Linear(channel, channel // reduction, bias=False),  # \u964d\u7ef4\uff0c\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u548c\u8ba1\u7b97\u91cf\n            nn.ReLU(inplace=True),  # ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u5f15\u5165\u975e\u7ebf\u6027\n            nn.Linear(channel // reduction, channel, bias=False),  # \u5347\u7ef4\uff0c\u6062\u590d\u5230\u539f\u59cb\u901a\u9053\u6570\n            nn.Sigmoid()  # Sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u8f93\u51fa\u6bcf\u4e2a\u901a\u9053\u7684\u91cd\u8981\u6027\u7cfb\u6570\n        )\n\n    # \u6743\u91cd\u521d\u59cb\u5316\u65b9\u6cd5\n    def init_weights(self):\n        for m in self.modules():  # \u904d\u5386\u6a21\u5757\u4e2d\u7684\u6240\u6709\u5b50\u6a21\u5757\n            if isinstance(m, nn.Conv2d):  # \u5bf9\u4e8e\u5377\u79ef\u5c42\n                init.kaiming_normal_(m.weight, mode='fan_out')  # \u4f7f\u7528Kaiming\u521d\u59cb\u5316\u65b9\u6cd5\u521d\u59cb\u5316\u6743\u91cd\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)  # \u5982\u679c\u6709\u504f\u7f6e\u9879\uff0c\u5219\u521d\u59cb\u5316\u4e3a0\n            elif isinstance(m, nn.BatchNorm2d):  # \u5bf9\u4e8e\u6279\u5f52\u4e00\u5316\u5c42\n                init.constant_(m.weight, 1)  # \u6743\u91cd\u521d\u59cb\u5316\u4e3a1\n                init.constant_(m.bias, 0)  # \u504f\u7f6e\u521d\u59cb\u5316\u4e3a0\n            elif isinstance(m, nn.Linear):  # \u5bf9\u4e8e\u5168\u8fde\u63a5\u5c42\n                init.normal_(m.weight, std=0.001)  # \u6743\u91cd\u4f7f\u7528\u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)  # \u504f\u7f6e\u521d\u59cb\u5316\u4e3a0\n\n    # \u524d\u5411\u4f20\u64ad\u65b9\u6cd5\n    def forward(self, x):\n        b, c, _, _ = x.size()  # \u83b7\u53d6\u8f93\u5165x\u7684\u6279\u91cf\u5927\u5c0fb\u548c\u901a\u9053\u6570c\n        y = self.avg_pool(x).view(b, c)  # \u901a\u8fc7\u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316\u5c42\u540e\uff0c\u8c03\u6574\u5f62\u72b6\u4ee5\u5339\u914d\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u5165\n        y = self.fc(y).view(b, c, 1, 1)  # \u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u8ba1\u7b97\u901a\u9053\u91cd\u8981\u6027\uff0c\u8c03\u6574\u5f62\u72b6\u4ee5\u5339\u914d\u539f\u59cb\u7279\u5f81\u56fe\u7684\u5f62\u72b6\n        return x * y.expand_as(x)  # \u5c06\u901a\u9053\u91cd\u8981\u6027\u7cfb\u6570\u5e94\u7528\u5230\u539f\u59cb\u7279\u5f81\u56fe\u4e0a\uff0c\u8fdb\u884c\u7279\u5f81\u91cd\u65b0\u6821\u51c6\n\n# \u793a\u4f8b\u4f7f\u7528\nif __name__ == '__main__':\n    input = torch.randn(50, 512, 7, 7)  # \u968f\u673a\u751f\u6210\u4e00\u4e2a\u8f93\u5165\u7279\u5f81\u56fe\n    se = SEAttention(channel=512, reduction=8)  # \u5b9e\u4f8b\u5316SE\u6a21\u5757\uff0c\u8bbe\u7f6e\u964d\u7ef4\u6bd4\u7387\u4e3a8\n    output = se(input)  # \u5c06\u8f93\u5165\u7279\u5f81\u56fe\u901a\u8fc7SE\u6a21\u5757\u8fdb\u884c\u5904\u7406\n    print(output.shape)  # \u6253\u5370\u5904\u7406\u540e\u7684\u7279\u5f81\u56fe\u5f62\u72b6\uff0c\u9a8c\u8bc1SE\u6a21\u5757\u7684\u4f5c\u7528\n</code></pre> <ul> <li>SE\u6a21\u5757\u9996\u5148\u901a\u8fc7\u5168\u5c40\u5e73\u5747\u6c60\u5316\u64cd\u4f5c\u5bf9\u8f93\u5165\u7279\u5f81\u56fe\u7684\u7a7a\u95f4\u7ef4\u5ea6\uff08\u9ad8\u5ea6H\u548c\u5bbd\u5ea6W\uff09\u8fdb\u884c\u805a\u5408\uff0c\u4e3a\u6bcf\u4e2a\u901a\u9053\u751f\u6210\u4e00\u4e2a\u901a\u9053\u63cf\u8ff0\u7b26\u3002\u8fd9\u4e00\u6b65\u6709\u6548\u5730\u5c06\u5168\u5c40\u7a7a\u95f4\u4fe1\u606f\u538b\u7f29\u6210\u4e00\u4e2a\u901a\u9053\u5411\u91cf\uff0c\u6355\u83b7\u4e86\u901a\u9053\u7279\u5f81\u54cd\u5e94\u7684\u5168\u5c40\u5206\u5e03\u3002\u8fd9\u4e00\u5168\u5c40\u4fe1\u606f\u5bf9\u4e8e\u63a5\u4e0b\u6765\u7684\u91cd\u65b0\u6821\u51c6\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\u3002</li> <li>\u5728\u538b\u7f29\u6b65\u9aa4\u4e4b\u540e\uff0c\u5e94\u7528\u4e00\u4e2a\u6fc0\u52b1\u673a\u5236\uff0c\u8be5\u673a\u5236\u672c\u8d28\u4e0a\u662f\u7531\u4e24\u4e2a\u5168\u8fde\u63a5\uff08FC\uff09\u5c42\u548c\u4e00\u4e2a\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff08\u901a\u5e38\u662fsigmoid\uff09\u7ec4\u6210\u7684\u81ea\u95e8\u63a7\u673a\u5236\u3002\u7b2c\u4e00\u4e2aFC\u5c42\u964d\u4f4e\u4e86\u901a\u9053\u63cf\u8ff0\u7b26\u7684\u7ef4\u5ea6\uff0c\u5e94\u7528ReLU\u975e\u7ebf\u6027\u6fc0\u6d3b\uff0c\u968f\u540e\u7b2c\u4e8c\u4e2aFC\u5c42\u5c06\u5176\u6295\u5f71\u56de\u539f\u59cb\u901a\u9053\u7ef4\u5ea6\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u5efa\u6a21\u4e86\u901a\u9053\u95f4\u7684\u975e\u7ebf\u6027\u4ea4\u4e92\uff0c\u5e76\u4ea7\u751f\u4e86\u4e00\u7ec4\u901a\u9053\u6743\u91cd\u3002</li> <li>\u6fc0\u52b1\u64cd\u4f5c\u7684\u8f93\u51fa\u7528\u4e8e\u91cd\u65b0\u6821\u51c6\u539f\u59cb\u8f93\u5165\u7279\u5f81\u56fe\u3002\u8f93\u5165\u7279\u5f81\u56fe\u7684\u6bcf\u4e2a\u901a\u9053\u90fd\u7531\u6fc0\u52b1\u8f93\u51fa\u4e2d\u5bf9\u5e94\u7684\u6807\u91cf\u8fdb\u884c\u7f29\u653e\u3002\u8fd9\u4e00\u6b65\u9aa4\u6709\u9009\u62e9\u5730\u5f3a\u8c03\u4fe1\u606f\u4e30\u5bcc\u7684\u7279\u5f81\uff0c\u540c\u65f6\u6291\u5236\u4e0d\u592a\u6709\u7528\u7684\u7279\u5f81\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u4e13\u6ce8\u4e8e\u4efb\u52a1\u4e2d\u6700\u76f8\u5173\u7684\u7279\u5f81\u3002</li> </ul> <p>SE Net\u7684\u6838\u5fc3\u8d21\u732e\u662f\u901a\u8fc7SE\u5757\u663e\u5f0f\u5efa\u6a21\u901a\u9053\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb</p>"},{"location":"Reproduction/1/#sknet","title":"\u221a SKNet","text":"Python<pre><code>import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import init\nfrom collections import OrderedDict\n\n\"Selective Kernel Networks\"\n\nclass SKAttention(nn.Module):\n\n    def __init__(self, channel=512,kernels=[1,3,5,7],reduction=8,group=1,L=32):\n        super().__init__()\n        self.d=max(L,channel//reduction)\n        self.convs=nn.ModuleList([])\n        # \u6709\u51e0\u4e2a\u5377\u79ef\u6838,\u5c31\u6709\u51e0\u4e2a\u5c3a\u5ea6, \u6bcf\u4e2a\u5c3a\u5ea6\u5bf9\u5e94\u7684\u5377\u79ef\u5c42\u7531Conv-bn-relu\u5b9e\u73b0\n        for k in kernels:\n            self.convs.append(\n                nn.Sequential(OrderedDict([\n                    ('conv',nn.Conv2d(channel,channel,kernel_size=k,padding=k//2,groups=group)),\n                    ('bn',nn.BatchNorm2d(channel)),\n                    ('relu',nn.ReLU())\n                ]))\n            )\n        # \u5c06\u5168\u5c40\u5411\u91cf\u964d\u7ef4\n        self.fc=nn.Linear(channel,self.d)\n        self.fcs=nn.ModuleList([])\n        for i in range(len(kernels)):\n            self.fcs.append(nn.Linear(self.d,channel))\n        self.softmax=nn.Softmax(dim=0)\n\n\n\n    def forward(self, x):\n        # (B, C, H, W)\n        B, C, H, W = x.size()\n        # \u5b58\u653e\u591a\u5c3a\u5ea6\u7684\u8f93\u51fa\n        conv_outs=[]\n        # Split: \u6267\u884cK\u4e2a\u5c3a\u5ea6\u5bf9\u5e94\u7684\u5377\u79ef\u64cd\u4f5c\n        for conv in self.convs:\n            scale = conv(x)  #\u6bcf\u4e00\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fashape\u90fd\u662f: (B, C, H, W),\u662f\u56e0\u4e3a\u4f7f\u7528\u4e86padding\u64cd\u4f5c\n            conv_outs.append(scale)\n        feats=torch.stack(conv_outs,0) # \u5c06K\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa\u5728\u7b2c0\u4e2a\u7ef4\u5ea6\u4e0a\u62fc\u63a5: (K,B,C,H,W)\n\n        # Fuse: \u9996\u5148\u5c06\u591a\u5c3a\u5ea6\u7684\u4fe1\u606f\u8fdb\u884c\u76f8\u52a0,sum()\u9ed8\u8ba4\u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u6c42\u548c\n        U=sum(conv_outs) #(K,B,C,H,W)--&gt;(B,C,H,W)\n        # \u5168\u5c40\u5e73\u5747\u6c60\u5316\u64cd\u4f5c: (B,C,H,W)--&gt;mean--&gt;(B,C,H)--&gt;mean--&gt;(B,C)  \u3010mean\u64cd\u4f5c\u7b49\u4ef7\u4e8e\u5168\u5c40\u5e73\u5747\u6c60\u5316\u7684\u64cd\u4f5c\u3011\n        S=U.mean(-1).mean(-1)\n        # \u964d\u4f4e\u901a\u9053\u6570,\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387: (B,C)--&gt;(B,d)\n        Z=self.fc(S)\n\n        # \u5c06\u7d27\u51d1\u7279\u5f81Z\u901a\u8fc7K\u4e2a\u5168\u8fde\u63a5\u5c42\u5f97\u5230K\u4e2a\u5c3a\u5ea6\u5bf9\u5e94\u7684\u901a\u9053\u63cf\u8ff0\u7b26\u8868\u793a, \u7136\u540e\u57fa\u4e8eK\u4e2a\u901a\u9053\u63cf\u8ff0\u7b26\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\n        weights=[]\n        for fc in self.fcs:\n            weight=fc(Z) #\u6062\u590d\u9884\u8f93\u5165\u76f8\u540c\u7684\u901a\u9053\u6570: (B,d)--&gt;(B,C)\n            weights.append(weight.view(B,C,1,1)) # (B,C)--&gt;(B,C,1,1)\n        scale_weight=torch.stack(weights,0) #\u5c06K\u4e2a\u901a\u9053\u63cf\u8ff0\u7b26\u57280\u4e2a\u7ef4\u5ea6\u4e0a\u62fc\u63a5: (K,B,C,1,1)\n        scale_weight=self.softmax(scale_weight) #\u5728\u7b2c0\u4e2a\u7ef4\u5ea6\u4e0a\u6267\u884csoftmax,\u83b7\u5f97\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u6743\u91cd: (K,B,C,1,1)\n\n        # Select\n        V=(scale_weight*feats).sum(0) # \u5c06\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u6743\u91cd\u4e0e\u5bf9\u5e94\u7684\u7279\u5f81\u8fdb\u884c\u52a0\u6743\u6c42\u548c,\u7b2c\u4e00\u6b65\u662f\u52a0\u6743\uff0c\u7b2c\u4e8c\u6b65\u662f\u6c42\u548c\uff1a(K,B,C,1,1) * (K,B,C,H,W) = (K,B,C,H,W)--&gt;sum--&gt;(B,C,H,W)\n        return V\n\n\n\nif __name__ == '__main__':\n    # (B,C,H,W)\n    input=torch.randn(1,512,7,7)\n    Model = SKAttention(channel=512,reduction=8)\n    output=Model(input)\n    print(output.shape)\n</code></pre>"},{"location":"Reproduction/1/#cbam","title":"\u221a CBAM","text":"<p>\u8bba\u6587\u300aCBAM: Convolutional Block Attention Module\u300b</p> <p></p> <p></p> <p></p> <p>\u4f5c\u7528\uff1a</p> <p>\u662f\u4e3a\u4e86\u63d0\u5347\u524d\u9988\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\u800c\u63d0\u51fa\u7684\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u6ce8\u610f\u529b\u6a21\u5757\u3002CBAM\u901a\u8fc7\u987a\u5e8f\u5730\u63a8\u65ad\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u6ce8\u610f\u529b\u56fe\uff08\u901a\u9053\u548c\u7a7a\u95f4\uff09\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u6ce8\u610f\u529b\u56fe\u4e58\u4ee5\u8f93\u5165\u7279\u5f81\u56fe\u8fdb\u884c\u81ea\u9002\u5e94\u7279\u5f81\u7cbe\u70bc\u3002</p> <p>1\u3001\u901a\u9053\u6ce8\u610f\u529b\u6a21\u5757\uff08Channel Attention Module\uff09\uff1a</p> <p>\u901a\u8fc7\u5229\u7528\u7279\u5f81\u4e4b\u95f4\u7684\u901a\u9053\u5173\u7cfb\u6765\u751f\u6210\u901a\u9053\u6ce8\u610f\u529b\u56fe\u3002\u6bcf\u4e2a\u901a\u9053\u7684\u7279\u5f81\u56fe\u88ab\u89c6\u4e3a\u4e00\u4e2a\u7279\u5f81\u63a2\u6d4b\u5668\uff0c\u901a\u9053\u6ce8\u610f\u529b\u5173\u6ce8\u4e8e\u7ed9\u5b9a\u8f93\u5165\u56fe\u50cf\u4e2d\u201c\u4ec0\u4e48\u201d\u662f\u6709\u610f\u4e49\u7684\u3002\u4e3a\u4e86\u6709\u6548\u5730\u8ba1\u7b97\u901a\u9053\u6ce8\u610f\u529b\uff0cCBAM\u9996\u5148\u5bf9\u8f93\u5165\u7279\u5f81\u56fe\u7684\u7a7a\u95f4\u7ef4\u5ea6\u8fdb\u884c\u538b\u7f29\uff0c\u540c\u65f6\u4f7f\u7528\u5e73\u5747\u6c60\u5316\u548c\u6700\u5927\u6c60\u5316\u64cd\u4f5c\u6765\u6355\u83b7\u4e0d\u540c\u7684\u7a7a\u95f4\u4e0a\u4e0b\u6587\u63cf\u8ff0\u7b26\uff0c\u8fd9\u4e9b\u88ab\u9001\u5165\u5171\u4eab\u7684\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u4ee5\u4ea7\u751f\u901a\u9053\u6ce8\u610f\u529b\u56fe\u3002</p> <p>2\u3001\u7a7a\u95f4\u6ce8\u610f\u529b\u6a21\u5757\uff08Spatial Attention Module\uff09\uff1a</p> <p>\u5229\u7528\u7279\u5f81\u4e4b\u95f4\u7684\u7a7a\u95f4\u5173\u7cfb\u6765\u751f\u6210\u7a7a\u95f4\u6ce8\u610f\u529b\u56fe\u3002\u4e0e\u901a\u9053\u6ce8\u610f\u529b\u4e0d\u540c\uff0c\u7a7a\u95f4\u6ce8\u610f\u529b\u5173\u6ce8\u4e8e\u201c\u5728\u54ea\u91cc\u201d\u662f\u4e00\u4e2a\u6709\u4fe1\u606f\u7684\u90e8\u5206\uff0c\u8fd9\u4e0e\u901a\u9053\u6ce8\u610f\u529b\u662f\u4e92\u8865\u7684\u3002\u4e3a\u4e86\u8ba1\u7b97\u7a7a\u95f4\u6ce8\u610f\u529b\uff0cCBAM\u9996\u5148\u6cbf\u7740\u901a\u9053\u8f74\u5e94\u7528\u5e73\u5747\u6c60\u5316\u548c\u6700\u5927\u6c60\u5316\u64cd\u4f5c\uff0c\u7136\u540e\u5c06\u5b83\u4eec\u8fde\u63a5\u8d77\u6765\u751f\u6210\u4e00\u4e2a\u9ad8\u6548\u7684\u7279\u5f81\u63cf\u8ff0\u7b26\u3002\u5728\u8be5\u63cf\u8ff0\u7b26\u4e0a\u5e94\u7528\u4e00\u4e2a\u5377\u79ef\u5c42\u6765\u751f\u6210\u7a7a\u95f4\u6ce8\u610f\u529b\u56fe\u3002</p> <p>\u597d\u5904\uff1a</p> <p>\u53cc\u91cd\u6ce8\u610f\u529b\u673a\u5236\uff1a</p> <p>CBAM\u9996\u6b21\u5c06 \u901a\u9053\u6ce8\u610f\u529b\uff08Channel Attention\uff09\u548c\u7a7a\u95f4\u6ce8\u610f\u529b\uff08Spatial Attention\uff09\u987a\u5e8f \u7ed3\u5408\u8d77\u6765\uff0c\u5bf9\u8f93\u5165\u7279\u5f81\u8fdb\u884c\u4e24\u9636\u6bb5\u7684\u7cbe\u70bc\u3002\u8fd9\u79cd\u8bbe\u8ba1\u8ba9\u6a21\u578b\u5148\u5173\u6ce8\u4e8e\u201c\u54ea\u4e9b\u901a\u9053\u662f\u91cd\u8981\u7684\u201d\uff0c\u7136\u540e\u518d\u5173\u6ce8\u4e8e\u201c\u7a7a\u95f4\u4e0a\u54ea\u4e9b\u4f4d\u7f6e\u662f\u91cd\u8981\u7684\u201d\uff0c\u4ece\u800c\u66f4\u52a0\u5168\u9762\u5730\u6355\u83b7\u7279\u5f81\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u3002</p> Python<pre><code>import torch\nfrom torch import nn\n\n# \u901a\u9053\u6ce8\u610f\u529b\u6a21\u5757\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # \u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316\n        self.max_pool = nn.AdaptiveMaxPool2d(1)  # \u81ea\u9002\u5e94\u6700\u5927\u6c60\u5316\n\n        # \u4e24\u4e2a\u5377\u79ef\u5c42\u7528\u4e8e\u4ece\u6c60\u5316\u540e\u7684\u7279\u5f81\u4e2d\u5b66\u4e60\u6ce8\u610f\u529b\u6743\u91cd\n        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)  # \u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u964d\u7ef4\n        self.relu1 = nn.ReLU()  # ReLU\u6fc0\u6d3b\u51fd\u6570\n        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)  # \u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\uff0c\u5347\u7ef4\n        self.sigmoid = nn.Sigmoid()  # Sigmoid\u51fd\u6570\u751f\u6210\u6700\u7ec8\u7684\u6ce8\u610f\u529b\u6743\u91cd\n\n    def forward(self, x):\n        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))  # \u5bf9\u5e73\u5747\u6c60\u5316\u7684\u7279\u5f81\u8fdb\u884c\u5904\u7406\n        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))  # \u5bf9\u6700\u5927\u6c60\u5316\u7684\u7279\u5f81\u8fdb\u884c\u5904\u7406\n        out = avg_out + max_out  # \u5c06\u4e24\u79cd\u6c60\u5316\u7684\u7279\u5f81\u52a0\u6743\u548c\u4f5c\u4e3a\u8f93\u51fa\n        return self.sigmoid(out)  # \u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\n\n# \u7a7a\u95f4\u6ce8\u610f\u529b\u6a21\u5757\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'  # \u6838\u5fc3\u5927\u5c0f\u53ea\u80fd\u662f3\u62167\n        padding = 3 if kernel_size == 7 else 1  # \u6839\u636e\u6838\u5fc3\u5927\u5c0f\u8bbe\u7f6e\u586b\u5145\n\n        # \u5377\u79ef\u5c42\u7528\u4e8e\u4ece\u8fde\u63a5\u7684\u5e73\u5747\u6c60\u5316\u548c\u6700\u5927\u6c60\u5316\u7279\u5f81\u56fe\u4e2d\u5b66\u4e60\u7a7a\u95f4\u6ce8\u610f\u529b\u6743\u91cd\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)  \n        self.sigmoid = nn.Sigmoid()  # Sigmoid\u51fd\u6570\u751f\u6210\u6700\u7ec8\u7684\u6ce8\u610f\u529b\u6743\u91cd\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)  # \u5bf9\u8f93\u5165\u7279\u5f81\u56fe\u6267\u884c\u5e73\u5747\u6c60\u5316\n        max_out, _ = torch.max(x, dim=1, keepdim=True)  # \u5bf9\u8f93\u5165\u7279\u5f81\u56fe\u6267\u884c\u6700\u5927\u6c60\u5316\n        x = torch.cat([avg_out, max_out], dim=1)  # \u5c06\u4e24\u79cd\u6c60\u5316\u7684\u7279\u5f81\u56fe\u8fde\u63a5\u8d77\u6765\n        x = self.conv1(x)  # \u901a\u8fc7\u5377\u79ef\u5c42\u5904\u7406\u8fde\u63a5\u540e\u7684\u7279\u5f81\u56fe\n        return self.sigmoid(x)  # \u4f7f\u7528sigmoid\u6fc0\u6d3b\u51fd\u6570\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\n\n# CBAM\u6a21\u5757\nclass CBAM(nn.Module):\n    def __init__(self, in_planes, ratio=16, kernel_size=7):\n        super(CBAM, self).__init__()\n        self.ca = ChannelAttention(in_planes, ratio)  # \u901a\u9053\u6ce8\u610f\u529b\u5b9e\u4f8b\n        self.sa = SpatialAttention(kernel_size)  # \u7a7a\u95f4\u6ce8\u610f\u529b\u5b9e\u4f8b\n\n    def forward(self, x):\n        out = x * self.ca(x)  # \u4f7f\u7528\u901a\u9053\u6ce8\u610f\u529b\u52a0\u6743\u8f93\u5165\u7279\u5f81\u56fe\n        result = out * self.sa(out)  # \u4f7f\u7528\u7a7a\u95f4\u6ce8\u610f\u529b\u8fdb\u4e00\u6b65\u52a0\u6743\u7279\u5f81\u56fe\n        return result  # \u8fd4\u56de\u6700\u7ec8\u7684\u7279\u5f81\u56fe\n\n# \u793a\u4f8b\u4f7f\u7528\nif __name__ == '__main__':\n    block = CBAM(64)  # \u521b\u5efa\u4e00\u4e2aCBAM\u6a21\u5757\uff0c\u8f93\u5165\u901a\u9053\u4e3a64\n    input = torch.rand(1, 64, 64, 64)  # \u968f\u673a\u751f\u6210\u4e00\u4e2a\u8f93\u5165\u7279\u5f81\u56fe\n    output = block(input)  # \u901a\u8fc7CBAM\u6a21\u5757\u5904\u7406\u8f93\u5165\u7279\u5f81\u56fe\n    print(input.size(), output.size())  # \u6253\u5370\u8f93\u5165\u548c\u8f93\u51fa\u7684\n</code></pre>"},{"location":"Reproduction/1/#eca","title":"\u221aECA","text":"<p>\u8bba\u6587\u300aECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks\u300b</p> <p></p> <p></p> <p>\u4f5c\u7528\uff1a</p> <p>ECA\u6a21\u5757\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u9ad8\u6548\u7684\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\u6765\u589e\u5f3a\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u7279\u5f81\u8868\u793a\u80fd\u529b\u3002\u5b83\u7740\u91cd\u4e8e\u6355\u83b7\u901a\u9053\u95f4\u7684\u52a8\u6001\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ece\u800c\u4f7f\u7f51\u7edc\u80fd\u591f\u66f4\u52a0\u7cbe\u786e\u5730\u91cd\u89c6\u5bf9\u5f53\u524d\u4efb\u52a1\u66f4\u91cd\u8981\u7684\u7279\u5f81\uff0c\u63d0\u5347\u6a21\u578b\u5728\u5404\u79cd\u89c6\u89c9\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002</p> <p>\u673a\u5236\uff1a</p> <p>ECA\u6a21\u5757\u7684\u6838\u5fc3\u673a\u5236\u662f\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u800c\u9ad8\u6548\u7684**\u4e00\u7ef4\u5377\u79ef**\u6765\u81ea\u9002\u5e94\u5730\u6355\u6349\u901a\u9053\u4e4b\u95f4\u7684\u4f9d\u8d56\u6027\uff0c\u800c**\u65e0\u9700\u964d\u7ef4\u548c\u5347\u7ef4**\u7684\u8fc7\u7a0b\u3002\u8fd9\u79cd\u8bbe\u8ba1\u907f\u514d\u4e86\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u590d\u6742\u7684\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u7ed3\u6784\uff0c\u51cf\u5c11\u4e86\u6a21\u578b\u590d\u6742\u5ea6\u548c\u8ba1\u7b97\u8d1f\u62c5\u3002ECA\u901a\u8fc7\u8ba1\u7b97\u4e00\u4e2a\u81ea\u9002\u5e94\u7684\u6838\u5927\u5c0f\uff0c\u76f4\u63a5\u5728\u901a\u9053\u7279\u5f81\u4e0a\u5e94\u7528\u4e00\u7ef4\u5377\u79ef\uff0c\u4ece\u800c\u5b66\u4e60\u5230\u6bcf\u4e2a\u901a\u9053\u76f8\u5bf9\u4e8e\u5176\u4ed6\u901a\u9053\u7684\u91cd\u8981\u6027\u3002</p> Python<pre><code>import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import init\nfrom collections import OrderedDict\n\n\"ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks\"\n\nclass ECAAttention(nn.Module):\n\n    def __init__(self, kernel_size=3):\n        super().__init__()\n        self.gap=nn.AdaptiveAvgPool2d(1)\n        self.conv=nn.Conv1d(1,1,kernel_size=kernel_size,padding=(kernel_size-1)//2)\n        '''\n            \u53c2\u6570\u8bf4\u660e\uff1a\n            in_channels=1\uff1a\u8f93\u5165\u901a\u9053\u6570\u4e3a1\n            out_channels=1\uff1a\u8f93\u51fa\u901a\u9053\u6570\u4e3a1\n            kernel_size=kernel_size\uff1a\u5377\u79ef\u6838\u7684\u5927\u5c0f\uff0c\u8fd9\u91cc\u7531\u6784\u9020\u51fd\u6570\u7684\u53c2\u6570 kernel_size \u6307\u5b9a\n            padding=(kernel_size-1)//2\uff1a\u586b\u5145\u5927\u5c0f\uff0c\u8fd9\u91cc\u4f7f\u7528\u4e86\u5bf9\u79f0\u586b\u5145\uff0c\u4f7f\u5f97\u5377\u79ef\u64cd\u4f5c\u540e\u8f93\u51fa\u7684\u957f\u5ea6\u4e0e\u8f93\u5165\u7684\u957f\u5ea6\u76f8\u540c\n            \u95ee\u9898\uff1a1D \u5377\u79ef\u548c 2D\u5377\u79ef\u7684\u533a\u522b\u662f\u4ec0\u4e48\uff1f\n            \u7b54\uff1a1D \u5377\u79ef\u548c 2D \u5377\u79ef\u90fd\u6709\u901a\u9053\u7684\u6982\u5ff5\uff0c\u4e0d\u540c\u7684\u662f\uff0c1D \u5377\u79ef\uff0c\u5377\u79ef\u7684\u662f\u5e8f\u5217\uff0c2D \u5377\u79ef\u5377\u79ef\u7684\u56fe\n            \u533a\u522b\u5c31\u662f\u5377\u79ef\u7684\u5bf9\u8c61\u4e0d\u540c\n\n            \u8fd9\u4e2a padding = \uff08kernel_size - 1\uff09//2 \u4e5f\u662f\u4e0d\u53d8\u5377\u79ef\n        '''\n        self.sigmoid=nn.Sigmoid()\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        y=self.gap(x)  # \u5728\u7a7a\u95f4\u65b9\u5411\u6267\u884c\u5168\u5c40\u5e73\u5747\u6c60\u5316: (B,C,H,W)--&gt;(B,C,1,1)\n        y=y.squeeze(-1).permute(0,2,1)  # \u5c06\u901a\u9053\u63cf\u8ff0\u7b26\u53bb\u6389\u4e00\u7ef4,\u4fbf\u4e8e\u5728\u901a\u9053\u4e0a\u6267\u884c\u5377\u79ef\u64cd\u4f5c:(B,C,1,1)--&gt;(B,C,1)--&gt;(B,1,C)\n        y=self.conv(y)  # \u5728\u901a\u9053\u7ef4\u5ea6\u4e0a\u6267\u884c1D\u5377\u79ef\u64cd\u4f5c,\u5efa\u6a21\u5c40\u90e8\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u5173\u6027: (B,1,C)--&gt;(B,1,C) 1: \u8868\u793a\u5355\u901a\u9053\uff0cC : \u8868\u793a\u6bcf\u4e2a\u901a\u9053 C \u4e2a\u5143\u7d20\n        y=self.sigmoid(y) # \u751f\u6210\u6743\u91cd\u8868\u793a: (B,1,C) \u5bf9\u6240\u6709\u5143\u7d20 sigmoid\uff0c\u56e0\u4e3a sigmoid \u751f\u6210\u7684\u662f\u7edd\u5bf9\u6743\u91cd\n        y=y.permute(0,2,1).unsqueeze(-1)  # \u91cd\u5851shape: (B,1,C)--&gt;(B,C,1)--&gt;(B,C,1,1)\n        return x*y.expand_as(x)  # \u6743\u91cd\u5bf9\u8f93\u5165\u7684\u901a\u9053\u8fdb\u884c\u91cd\u65b0\u52a0\u6743: (B,C,H,W) * (B,C,1,1) = (B,C,H,W)\n\n\n\n\nif __name__ == '__main__':\n    # (B, C, H, W)\n    input=torch.randn(1,512,7,7)\n    Model = ECAAttention(kernel_size=3)\n    output=Model(input)\n    print(output.shape)\n</code></pre> <p>\u4f18\u52bf\uff1a</p> <p>1\u3001\u65e0\u9700\u964d\u7ef4\u5347\u7ef4\uff1a</p> <p>\u4e0e\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u673a\u5236\u76f8\u6bd4\uff0cECA\u6a21\u5757\u65e0\u9700\u8fdb\u884c\u964d\u7ef4\u548c\u5347\u7ef4\u7684\u64cd\u4f5c\uff0c\u8fd9\u6837\u4e0d\u4ec5\u4fdd\u7559\u4e86\u539f\u59cb\u901a\u9053\u7279\u5f81\u7684\u4fe1\u606f\u5b8c\u6574\u6027\uff0c\u8fd8\u8fdb\u4e00\u6b65\u51cf\u5c11\u4e86\u6a21\u578b\u590d\u6742\u5ea6\u3002</p> <p>\u3001\u81ea\u9002\u5e94\u6838\u5927\u5c0f\uff1a</p> <p>ECA\u6a21\u5757\u6839\u636e\u901a\u9053\u6570\u81ea\u9002\u5e94\u5730\u8c03\u6574\u4e00\u7ef4\u5377\u79ef\u7684\u6838\u5927\u5c0f\uff0c\u4f7f\u5176\u80fd\u591f\u7075\u6d3b\u5730\u6355\u6349\u4e0d\u540c\u8303\u56f4\u5185\u7684\u901a\u9053\u4f9d\u8d56\u6027\uff0c\u8fd9\u79cd\u81ea\u9002\u5e94\u673a\u5236\u4f7f\u5f97ECA\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u7f51\u7edc\u548c\u4e0d\u540c\u6df1\u5ea6\u7684\u5c42\u6b21\u4e2d\u90fd\u80fd\u6709\u6548\u5de5\u4f5c\u3002</p> Python<pre><code>import torch\nfrom torch import nn\nfrom torch.nn import init\n\n# \u5b9a\u4e49ECA\u6ce8\u610f\u529b\u6a21\u5757\u7684\u7c7b\nclass ECAAttention(nn.Module):\n\n    def __init__(self, kernel_size=3):\n        super().__init__()\n        self.gap = nn.AdaptiveAvgPool2d(1)  # \u5b9a\u4e49\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\uff0c\u5c06\u7a7a\u95f4\u7ef4\u5ea6\u538b\u7f29\u4e3a1x1\n        # \u5b9a\u4e49\u4e00\u4e2a1D\u5377\u79ef\uff0c\u7528\u4e8e\u5904\u7406\u901a\u9053\u95f4\u7684\u5173\u7cfb\uff0c\u6838\u5927\u5c0f\u53ef\u8c03\uff0cpadding\u4fdd\u8bc1\u8f93\u51fa\u901a\u9053\u6570\u4e0d\u53d8\n        self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n        self.sigmoid = nn.Sigmoid()  # Sigmoid\u51fd\u6570\uff0c\u7528\u4e8e\u6fc0\u6d3b\u6700\u7ec8\u7684\u6ce8\u610f\u529b\u6743\u91cd\n\n    # \u6743\u91cd\u521d\u59cb\u5316\u65b9\u6cd5\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')  # \u5bf9Conv2d\u5c42\u4f7f\u7528Kaiming\u521d\u59cb\u5316\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)  # \u5982\u679c\u6709\u504f\u7f6e\u9879\uff0c\u5219\u521d\u59cb\u5316\u4e3a0\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)  # \u6279\u5f52\u4e00\u5316\u5c42\u6743\u91cd\u521d\u59cb\u5316\u4e3a1\n                init.constant_(m.bias, 0)  # \u6279\u5f52\u4e00\u5316\u5c42\u504f\u7f6e\u521d\u59cb\u5316\u4e3a0\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)  # \u5168\u8fde\u63a5\u5c42\u6743\u91cd\u4f7f\u7528\u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)  # \u5168\u8fde\u63a5\u5c42\u504f\u7f6e\u521d\u59cb\u5316\u4e3a0\n\n    # \u524d\u5411\u4f20\u64ad\u65b9\u6cd5\n    def forward(self, x):\n        y = self.gap(x)  # \u5bf9\u8f93\u5165x\u5e94\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\uff0c\u5f97\u5230bs,c,1,1\u7ef4\u5ea6\u7684\u8f93\u51fa\n        y = y.squeeze(-1).permute(0, 2, 1)  # \u79fb\u9664\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u5e76\u8f6c\u7f6e\uff0c\u4e3a1D\u5377\u79ef\u51c6\u5907\uff0c\u53d8\u4e3abs,1,c\n        y = self.conv(y)  # \u5bf9\u8f6c\u7f6e\u540e\u7684y\u5e94\u75281D\u5377\u79ef\uff0c\u5f97\u5230bs,1,c\u7ef4\u5ea6\u7684\u8f93\u51fa\n        y = self.sigmoid(y)  # \u5e94\u7528Sigmoid\u51fd\u6570\u6fc0\u6d3b\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u6ce8\u610f\u529b\u6743\u91cd\n        y = y.permute(0, 2, 1).unsqueeze(-1)  # \u518d\u6b21\u8f6c\u7f6e\u5e76\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u4ee5\u5339\u914d\u539f\u59cb\u8f93\u5165x\u7684\u7ef4\u5ea6\n        return x * y.expand_as(x)  # \u5c06\u6ce8\u610f\u529b\u6743\u91cd\u5e94\u7528\u5230\u539f\u59cb\u8f93\u5165x\u4e0a\uff0c\u901a\u8fc7\u5e7f\u64ad\u673a\u5236\u6269\u5c55\u7ef4\u5ea6\u5e76\u6267\u884c\u9010\u5143\u7d20\u4e58\u6cd5\n\n# \u793a\u4f8b\u4f7f\u7528\nif __name__ == '__main__':\n    block = ECAAttention(kernel_size=3)  # \u5b9e\u4f8b\u5316ECA\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u6307\u5b9a\u6838\u5927\u5c0f\u4e3a3\n    input = torch.rand(1, 64, 64, 64)  # \u751f\u6210\u4e00\u4e2a\u968f\u673a\u8f93\u5165\n    output = block(input)  # \u5c06\u8f93\u5165\u901a\u8fc7ECA\u6a21\u5757\u5904\u7406\n    print(input.size(), output.size())  # \u6253\u5370\u8f93\u5165\u548c\u8f93\u51fa\u7684\u5c3a\u5bf8\uff0c\u9a8c\u8bc1ECA\u6a21\u5757\u7684\u4f5c\u7528\n</code></pre>"},{"location":"Reproduction/1/#coordinate-attention","title":"\u221a Coordinate Attention","text":"<p>\u8bba\u6587\u300aCoordinate Attention for Efficient Mobile Network Design\u300b</p> <p></p> <p></p> <ul> <li>Coordinate Attention\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u5728\u79fb\u52a8\u7f51\u7edc\u4e2d\u5d4c\u5165\u4f4d\u7f6e\u4fe1\u606f\u5230\u901a\u9053\u6ce8\u610f\u529b\u4e2d\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u5173\u6ce8\u201c\u54ea\u4e9b\u901a\u9053\u662f\u91cd\u8981\u7684\u201d\uff0c\u800c\u4e14\u5173\u6ce8\u201c\u5728\u54ea\u91cc\u201d\u5173\u6ce8\uff0c\u901a\u8fc7\u66f4\u7cbe\u7ec6\u5730\u63a7\u5236\u7a7a\u95f4\u9009\u62e9\u6027\u6ce8\u610f\u529b\u56fe\u7684\u751f\u6210\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002</li> </ul> <p>\u673a\u5236\uff1a</p> <p>1\u3001\u5750\u6807\u4fe1\u606f\u5d4c\u5165\uff1a</p> <p>\u4e0e\u4f20\u7edf\u7684\u901a\u9053\u6ce8\u610f\u529b\u901a\u8fc72D\u5168\u5c40\u6c60\u5316\u5c06\u7279\u5f81\u5f20\u91cf\u8f6c\u6362\u4e3a\u5355\u4e00\u7279\u5f81\u5411\u91cf\u4e0d\u540c\uff0cCoordinate Attention\u5c06\u901a\u9053\u6ce8\u610f\u529b\u5206\u89e3\u4e3a\u4e24\u4e2a1D\u7279\u5f81\u7f16\u7801\u8fc7\u7a0b\uff0c\u5206\u522b\u6cbf\u4e24\u4e2a\u7a7a\u95f4\u65b9\u5411\u805a\u5408\u7279\u5f81\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u6355\u6349\u6cbf\u4e00\u4e2a\u7a7a\u95f4\u65b9\u5411\u7684\u957f\u7a0b\u4f9d\u8d56\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u6cbf\u53e6\u4e00\u4e2a\u7a7a\u95f4\u65b9\u5411\u7684\u7cbe\u786e\u4f4d\u7f6e\u4fe1\u606f\u3002</p> <p>2\u3001\u5750\u6807\u6ce8\u610f\u529b\u751f\u6210\uff1a</p> <p>\u5c06\u6cbf\u5782\u76f4\u548c\u6c34\u5e73\u65b9\u5411\u805a\u5408\u7684\u7279\u5f81\u56fe\u7f16\u7801\u6210\u4e00\u5bf9\u65b9\u5411\u611f\u77e5\u548c\u4f4d\u7f6e\u654f\u611f\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u8fd9\u4e24\u4e2a\u6ce8\u610f\u529b\u56fe\u88ab\u4e92\u8865\u5730\u5e94\u7528\u5230\u8f93\u5165\u7279\u5f81\u56fe\u4e0a\uff0c\u589e\u5f3a\u4e86\u5bf9\u5174\u8da3\u5bf9\u8c61\u7684\u8868\u793a\u3002</p> <p>\u4f18\u52bf\uff1a </p> <p>1\u3001\u65b9\u5411\u611f\u77e5\u548c\u4f4d\u7f6e\u654f\u611f\uff1a</p> <p>Coordinate Attention\u901a\u8fc7\u751f\u6210\u65b9\u5411\u611f\u77e5\u548c\u4f4d\u7f6e\u654f\u611f\u7684\u6ce8\u610f\u529b\u56fe\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u66f4\u51c6\u786e\u5730\u5b9a\u4f4d\u548c\u8bc6\u522b\u5174\u8da3\u5bf9\u8c61\u3002\u8fd9\u79cd\u6ce8\u610f\u529b\u56fe\u80fd\u591f\u7cbe\u786e\u5730\u9ad8\u4eae\u5174\u8da3\u533a\u57df\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u7a7a\u95f4\u7ed3\u6784\u7684\u7406\u89e3\u80fd\u529b\u3002</p> <p>2\u3001\u7075\u6d3b\u6027\u548c\u8f7b\u91cf\u7ea7\uff1a</p> <p>Coordinate Attention\u7684\u8bbe\u8ba1\u7b80\u6d01\u800c\u9ad8\u6548\uff0c\u53ef\u4ee5\u8f7b\u677e\u5d4c\u5165\u5230\u7ecf\u5178\u7684\u79fb\u52a8\u7f51\u7edc\u7ed3\u6784\u4e2d\uff0c\u5982MobileNetV2\u3001MobileNeXt\u548cEfficientNet\uff0c\u51e0\u4e4e\u4e0d\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\uff0c\u9002\u7528\u4e8e\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u3002</p> <p>3\u3001\u8de8\u4efb\u52a1\u6027\u80fd\u63d0\u5347\uff1a</p> <p>Coordinate Attention\u4e0d\u4ec5\u5728ImageNet\u5206\u7c7b\u4efb\u52a1\u4e0a\u6709\u6548\uff0c\u66f4\u5728\u4e0b\u6e38\u4efb\u52a1\u5982\u5bf9\u8c61\u68c0\u6d4b\u548c\u8bed\u4e49\u5206\u5272\u4e0a\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002\u8fd9\u8bc1\u660e\u4e86\u5176\u5bf9\u4e8e\u6355\u6349\u5173\u952e\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u5c24\u5176\u5728\u9700\u8981\u5bc6\u96c6\u9884\u6d4b\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002</p> <p>\u4f18\u8d28\u6ce8\u91ca\u300b \u8bb0\u5f97\u5b66\u5b66</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\"Coordinate Attention for Efficient Mobile Network Design\"\n\nclass h_sigmoid(nn.Module):\n    def __init__(self, inplace=True):\n        super(h_sigmoid, self).__init__()\n        self.relu = nn.ReLU6(inplace=inplace)\n\n    def forward(self, x):\n        return self.relu(x + 3) / 6\n\nclass h_swish(nn.Module):\n    def __init__(self, inplace=True):\n        super(h_swish, self).__init__()\n        self.sigmoid = h_sigmoid(inplace=inplace)\n\n    def forward(self, x):\n        return x * self.sigmoid(x)\n\nclass CoordAtt(nn.Module):\n    def __init__(self, inp, oup, reduction=32):\n        super(CoordAtt, self).__init__()\n        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))\n\n        '''\n            \u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316\uff1a\n            \u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316\u4e0d\u9700\u8981\u6307\u5b9a\u6c60\u5316\u7a97\u53e3\u7684\u5927\u5c0f\u548c\u6b65\u5e45\uff0c\u800c\u662f\u76f4\u63a5\u6307\u5b9a\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u5927\u5c0f\n            (None, 1)\n            None: \u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff08\u901a\u5e38\u662f\u9ad8\u5ea6\uff09\u4e0a\uff0c\u8f93\u51fa\u7684\u5c3a\u5bf8\u5c06\u81ea\u52a8\u8c03\u6574\u4ee5\u5339\u914d\u8f93\u5165\u7684\u9ad8\u5ea6\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u8f93\u5165\u7684\u9ad8\u5ea6\u662f\u591a\u5c11\uff0c\u8f93\u51fa\u7684\u9ad8\u5ea6\u5c31\u662f\u591a\u5c11\n            1: \u5728\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\uff08\u901a\u5e38\u662f\u5bbd\u5ea6\uff09\u4e0a\uff0c\u8f93\u51fa\u7684\u5bbd\u5ea6\u5c06\u88ab\u8c03\u6574\u4e3a 1\u3002\n            \u7ecf\u8fc7 nn.AdaptiveAvgPool2d((None, 1)) \u64cd\u4f5c\u540e\uff0c\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u5927\u5c0f\u5c06\u53d8\u4e3a (C, H, 1)\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u5bbd\u5ea6\u88ab\u538b\u7f29\u4e3a 1\uff0c\u800c\u9ad8\u5ea6\u4fdd\u6301\u4e0d\u53d8\n        '''\n        self.pool_w = nn.AdaptiveAvgPool2d((1, None))\n        mip = max(8, inp // reduction)\n\n        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)\n        self.bn1 = nn.BatchNorm2d(mip)\n        self.act = h_swish()\n        self.relu = nn.ReLU()\n\n        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n\n\n    def forward(self, x):\n        identity = x\n\n        B,C,H,W = x.size()\n        x_h = self.pool_h(x) # \u538b\u7f29\u6c34\u5e73\u65b9\u5411: (B, C, H, W) --&gt; (B, C, H, 1)\n        x_w = self.pool_w(x).permute(0, 1, 3, 2) # \u538b\u7f29\u5782\u76f4\u65b9\u5411: (B, C, H, W) --&gt; (B, C, 1, W) --&gt; (B,C,W,1)\n\n        # \u5750\u6807\u6ce8\u610f\u529b\u751f\u6210\n        y = torch.cat([x_h, x_w], dim=2) # \u62fc\u63a5\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u5411\u91cf: (B,C,H+W,1)\n        y = self.conv1(y) # \u901a\u8fc7Conv\u8fdb\u884c\u53d8\u6362,\u5e76\u964d\u7ef4: (B,C,H+W,1)--&gt; (B,d,H+W,1)\n        y = self.bn1(y)   # BatchNorm\u64cd\u4f5c: (B,d,H+W,1)\n        y = self.relu(y)  # Relu\u64cd\u4f5c: (B,d,H+W,1)\n\n        x_h, x_w = torch.split(y, [H, W], dim=2) # \u6cbf\u7740\u7a7a\u95f4\u65b9\u5411\u91cd\u65b0\u5206\u5272\u4e3a\u4e24\u90e8\u5206: (B,d,H+W,1)--&gt; x_h:(B,d,H,1); x_w:(B,d,W,1)\n        x_w = x_w.permute(0, 1, 3, 2) # x_w: (B,d,W,1)--&gt; (B,d,1,W)\n\n        a_h = self.conv_h(x_h).sigmoid() # \u6062\u590d\u4e0e\u8f93\u5165\u76f8\u540c\u7684\u901a\u9053\u6570,\u5e76\u751f\u6210\u5782\u76f4\u65b9\u5411\u7684\u6743\u91cd: (B,d,H,1)--&gt;(B,C,H,1)\n        a_w = self.conv_w(x_w).sigmoid() # \u6062\u590d\u4e0e\u8f93\u5165\u76f8\u540c\u7684\u901a\u9053\u6570,\u5e76\u751f\u6210\u6c34\u5e73\u65b9\u5411\u7684\u6743\u91cd: (B,d,1,W)--&gt;(B,C,1,W)\n        '''\n            \u95ee\u9898\uff1asigmoid \u5728\u54ea\u4e2a\u65b9\u5411\u8fdb\u884c\uff1f\n            \u7b54\uff1a\n                sigmoid \u662f\u9010\u5143\u7d20\u5e94\u7528\u7684\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u65b9\u5411\n                \u5bf9\u6bcf\u4e2a\u8f93\u5165\u5143\u7d20\u72ec\u7acb\u5730\u8fdb\u884c\u8ba1\u7b97\uff0c\u800c\u4e0d\u662f\u5728\u67d0\u4e2a\u7279\u5b9a\u7684\u65b9\u5411\u4e0a\u8fdb\u884c\n        '''\n\n        out = identity * a_w * a_h # \u5c06\u5782\u76f4\u3001\u6c34\u5e73\u65b9\u5411\u6743\u91cd\u5e94\u7528\u4e8e\u8f93\u5165,\u4ece\u800c\u53cd\u6620\u611f\u5174\u8da3\u7684\u5bf9\u8c61\u662f\u5426\u5b58\u5728\u4e8e\u76f8\u5e94\u7684\u884c\u548c\u5217\u4e2d: (B,C,H,W) * (B,C,1,W) * (B,C,H,1) = (B,C,H,W)\n        '''\n        \u5e7f\u64ad\u673a\u5236\uff1a\n            identity \u662f\u4e00\u4e2a\u5f62\u72b6\u4e3a (M, N) \u7684\u6570\u7ec4\n            a_w \u662f\u4e00\u4e2a\u5f62\u72b6\u4e3a (M, 1) \u7684\u6570\u7ec4 \u2192 a_w \u7684\u5f62\u72b6\u4f1a\u88ab\u5e7f\u64ad\u4e3a (M, N)\uff0c\u5373\u5728\u5217\u65b9\u5411\u4e0a\u590d\u5236 N \u6b21\n            a_h \u662f\u4e00\u4e2a\u5f62\u72b6\u4e3a (1, N) \u7684\u6570\u7ec4 \u2192 a_h \u7684\u5f62\u72b6\u4f1a\u88ab\u5e7f\u64ad\u4e3a (M, N)\uff0c\u5373\u5728\u884c\u65b9\u5411\u4e0a\u590d\u5236 M \u6b21\n            \u6700\u540e\uff1a\u9010\u5143\u7d20\u76f8\u4e58\u3002identity\u3001a_w \u548c a_h \u7684\u5f62\u72b6\u90fd\u53d8\u4e3a (M, N)\uff0c\u53ef\u4ee5\u8fdb\u884c\u9010\u5143\u7d20\u76f8\u4e58\n        '''\n\n        return out\n\nif __name__ == '__main__':\n    # (B, C, H, W)\n    input=torch.randn(1,512,7,7)\n    Model = CoordAtt(inp=512,oup=512) # input_channel,output_channel\n    output=Model(input)\n    print(output.shape)\n</code></pre> <p>\u6ce8\u91ca</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# \u5b9a\u4e49h_sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u8fd9\u662f\u4e00\u79cd\u786cSigmoid\u51fd\u6570\nclass h_sigmoid(nn.Module):\n    def __init__(self, inplace=True):\n        super(h_sigmoid, self).__init__()\n        self.relu = nn.ReLU6(inplace=inplace)  # \u4f7f\u7528ReLU6\u5b9e\u73b0\n\n    def forward(self, x):\n        return self.relu(x + 3) / 6  # \u516c\u5f0f\u4e3aReLU6(x+3)/6\uff0c\u6a21\u62dfSigmoid\u6fc0\u6d3b\u51fd\u6570\n\n# \u5b9a\u4e49h_swish\u6fc0\u6d3b\u51fd\u6570\uff0c\u8fd9\u662f\u57fa\u4e8eh_sigmoid\u7684Swish\u51fd\u6570\u53d8\u4f53\nclass h_swish(nn.Module):\n    def __init__(self, inplace=True):\n        super(h_swish, self).__init__()\n        self.sigmoid = h_sigmoid(inplace=inplace)  # \u4f7f\u7528\u4e0a\u9762\u5b9a\u4e49\u7684h_sigmoid\n\n    def forward(self, x):\n        return x * self.sigmoid(x)  # \u516c\u5f0f\u4e3ax * h_sigmoid(x)\n\n# \u5b9a\u4e49Coordinate Attention\u6a21\u5757\nclass CoordAtt(nn.Module):\n    def __init__(self, inp, oup, reduction=32):\n        super(CoordAtt, self).__init__()\n        # \u5b9a\u4e49\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316\n        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))  # \u6c34\u5e73\u65b9\u5411\n        self.pool_w = nn.AdaptiveAvgPool2d((1, None))  # \u5782\u76f4\u65b9\u5411\n\n        mip = max(8, inp // reduction)  # \u8ba1\u7b97\u4e2d\u95f4\u5c42\u7684\u901a\u9053\u6570\n\n        # 1x1\u5377\u79ef\u7528\u4e8e\u964d\u7ef4\n        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)\n        self.bn1 = nn.BatchNorm2d(mip)  # \u6279\u5f52\u4e00\u5316\n        self.act = h_swish()  # \u6fc0\u6d3b\u51fd\u6570\n\n        # \u4e24\u4e2a1x1\u5377\u79ef\uff0c\u5206\u522b\u5bf9\u5e94\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\n        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, x):\n        identity = x  # \u4fdd\u5b58\u8f93\u5165\u4f5c\u4e3a\u6b8b\u5dee\u8fde\u63a5\n\n        n, c, h, w = x.size()  # \u83b7\u53d6\u8f93\u5165\u7684\u5c3a\u5bf8\n        x_h = self.pool_h(x)  # \u6c34\u5e73\u65b9\u5411\u6c60\u5316\n        x_w = self.pool_w(x).permute(0, 1, 3, 2)  # \u5782\u76f4\u65b9\u5411\u6c60\u5316\u5e76\u4ea4\u6362\u7ef4\u5ea6\u4ee5\u9002\u5e94\u62fc\u63a5\n\n        y = torch.cat([x_h, x_w], dim=2)  # \u62fc\u63a5\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u7684\u7279\u5f81\n        y = self.conv1(y)  # \u901a\u8fc71x1\u5377\u79ef\u964d\u7ef4\n        y = self.bn1(y)  # \u6279\u5f52\u4e00\u5316\n        y = self.act(y)  # \u6fc0\u6d3b\u51fd\u6570\n\n        x_h, x_w = torch.split(y, [h, w], dim=2)  # \u5c06\u7279\u5f81\u62c6\u5206\u56de\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\n        x_w = x_w.permute(0, 1, 3, 2)  # \u6062\u590dx_w\u7684\u539f\u59cb\u7ef4\u5ea6\n\n        a_h = self.conv_h(x_h).sigmoid()  # \u901a\u8fc71x1\u5377\u79ef\u5e76\u5e94\u7528Sigmoid\u83b7\u53d6\u6c34\u5e73\u65b9\u5411\u7684\u6ce8\u610f\u529b\u6743\u91cd\n        a_w = self.conv_w(x_w).sigmoid()  # \u901a\u8fc71x1\u5377\u79ef\u5e76\u5e94\u7528Sigmoid\u83b7\u53d6\u5782\u76f4\u65b9\u5411\u7684\u6ce8\u610f\u529b\u6743\u91cd\n\n        out = identity * a_w * a_h  # \u5e94\u7528\u6ce8\u610f\u529b\u6743\u91cd\u5230\u8f93\u5165\u7279\u5f81\uff0c\u5e76\u4e0e\u6b8b\u5dee\u8fde\u63a5\u76f8\u4e58\n\n        return out  # \u8fd4\u56de\u8f93\u51fa\n\n# \u793a\u4f8b\u4f7f\u7528\nif __name__ == '__main__':\n    block = CoordAtt(64, 64)  # \u5b9e\u4f8b\u5316Coordinate Attention\u6a21\u5757\n    input = torch.rand(1, 64, 64, 64)  # \u521b\u5efa\u4e00\u4e2a\u968f\u673a\u8f93\u5165\n    output = block(input)  # \u901a\u8fc7\u6a21\u5757\u5904\u7406\u8f93\u5165\n    print(output.shape())  # \u6253\u5370\u8f93\u5165\u548c\u8f93\u51fa\u7684\u5c3a\u5bf8\n</code></pre>"},{"location":"Reproduction/1/#cotattention","title":"CoTAttention","text":"<p>\u8bba\u6587\u300aContextual Transformer Networks for Visual Recognition\u300b</p> <p></p> <p></p> <p></p> <p>\u4f5c\u7528</p> <p>Contextual Transformer (CoT) block \u8bbe\u8ba1\u4e3a\u89c6\u89c9\u8bc6\u522b\u7684\u4e00\u79cd\u65b0\u9896\u7684 Transformer \u98ce\u683c\u6a21\u5757\u3002\u8be5\u8bbe\u8ba1\u5145\u5206\u5229\u7528\u8f93\u5165\u952e\u4e4b\u95f4\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u6307\u5bfc\u52a8\u6001\u6ce8\u610f\u529b\u77e9\u9635\u7684\u5b66\u4e60\uff0c\u4ece\u800c\u52a0\u5f3a\u89c6\u89c9\u8868\u793a\u7684\u80fd\u529b\u3002CoT block \u9996\u5148\u901a\u8fc7 3x3 \u5377\u79ef\u5bf9\u8f93\u5165\u952e\u8fdb\u884c\u4e0a\u4e0b\u6587\u7f16\u7801\uff0c\u5f97\u5230\u8f93\u5165\u7684\u9759\u6001\u4e0a\u4e0b\u6587\u8868\u793a\u3002\u7136\u540e\uff0c\u5c06\u7f16\u7801\u540e\u7684\u952e\u4e0e\u8f93\u5165\u67e5\u8be2\u5408\u5e76\uff0c\u901a\u8fc7\u4e24\u4e2a\u8fde\u7eed\u7684 1x1 \u5377\u79ef\u5b66\u4e60\u52a8\u6001\u591a\u5934\u6ce8\u610f\u529b\u77e9\u9635\u3002\u5b66\u4e60\u5230\u7684\u6ce8\u610f\u529b\u77e9\u9635\u4e58\u4ee5\u8f93\u5165\u503c\uff0c\u5b9e\u73b0\u8f93\u5165\u7684\u52a8\u6001\u4e0a\u4e0b\u6587\u8868\u793a\u3002\u6700\u7ec8\u5c06\u9759\u6001\u548c\u52a8\u6001\u4e0a\u4e0b\u6587\u8868\u793a\u7684\u878d\u5408\u4f5c\u4e3a\u8f93\u51fa\u3002</p> <p>\u673a\u5236</p> <p>1\u3001\u4e0a\u4e0b\u6587\u7f16\u7801\uff1a</p> <p>\u901a\u8fc7 3x3 \u5377\u79ef\u5728\u6240\u6709\u90bb\u5c45\u952e\u5185\u90e8\u7a7a\u95f4\u4e0a\u4e0b\u6587\u5316\u6bcf\u4e2a\u952e\u8868\u793a\uff0c\u6355\u83b7\u952e\u4e4b\u95f4\u7684\u9759\u6001\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002</p> <p>2\u3001\u52a8\u6001\u6ce8\u610f\u529b\u5b66\u4e60\uff1a</p> <p>\u57fa\u4e8e\u67e5\u8be2\u548c\u4e0a\u4e0b\u6587\u5316\u7684\u952e\u7684\u8fde\u63a5\uff0c\u901a\u8fc7\u4e24\u4e2a\u8fde\u7eed\u7684 1x1 \u5377\u79ef\u4ea7\u751f\u6ce8\u610f\u529b\u77e9\u9635\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u81ea\u7136\u5730\u5229\u7528\u6bcf\u4e2a\u67e5\u8be2\u548c\u6240\u6709\u952e\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u8fdb\u884c\u81ea\u6211\u6ce8\u610f\u529b\u5b66\u4e60\uff0c\u5e76\u7531\u9759\u6001\u4e0a\u4e0b\u6587\u6307\u5bfc\u3002</p> <p>3\u3001\u9759\u6001\u548c\u52a8\u6001\u4e0a\u4e0b\u6587\u7684\u878d\u5408\uff1a</p> <p>\u5c06\u9759\u6001\u4e0a\u4e0b\u6587\u548c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5316\u81ea\u6ce8\u610f\u529b\u5f97\u5230\u7684\u52a8\u6001\u4e0a\u4e0b\u6587\u7ed3\u5408\uff0c\u4f5c\u4e3a CoT block \u7684\u6700\u7ec8\u8f93\u51fa\u3002</p> <p>\u4f18\u52bf</p> <p>1\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\uff1a</p> <p>CoT \u901a\u8fc7\u5728\u81ea\u6ce8\u610f\u529b\u5b66\u4e60\u4e2d\u63a2\u7d22\u8f93\u5165\u952e\u4e4b\u95f4\u7684\u5bcc\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6355\u83b7\u89c6\u89c9\u5185\u5bb9\u7684\u7ec6\u5fae\u5dee\u5f02\u3002</p> <p>2\u3001\u52a8\u9759\u6001\u4e0a\u4e0b\u6587\u7684\u7edf\u4e00\uff1a</p> <p>CoT \u8bbe\u8ba1\u5de7\u5999\u5730\u5c06\u4e0a\u4e0b\u6587\u6316\u6398\u4e0e\u81ea\u6ce8\u610f\u529b\u5b66\u4e60\u7edf\u4e00\u5230\u5355\u4e00\u67b6\u6784\u4e2d\uff0c\u65e2\u5229\u7528\u952e\u4e4b\u95f4\u7684\u9759\u6001\u5173\u7cfb\u53c8\u63a2\u7d22\u52a8\u6001\u7279\u5f81\u4ea4\u4e92\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u3002</p> <p>3\u3001\u7075\u6d3b\u66ff\u6362\u4e0e\u4f18\u5316\uff1a</p> <p>CoT block \u53ef\u4ee5\u76f4\u63a5\u66ff\u6362\u73b0\u6709 ResNet \u67b6\u6784\u4e2d\u7684\u6807\u51c6\u5377\u79ef\uff0c\u4e0d\u589e\u52a0\u53c2\u6570\u548c FLOP \u9884\u7b97\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8f6c\u6362\u4e3a Transformer \u98ce\u683c\u7684\u9aa8\u5e72\u7f51\u7edc\uff08CoTNet\uff09\uff0c\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u79cd\u5e94\u7528\uff08\u5982\u56fe\u50cf\u8bc6\u522b\u3001\u76ee\u6807\u68c0\u6d4b\u548c\u5b9e\u4f8b\u5206\u5272\uff09\u4e2d\u7684\u4f18\u8d8a\u6027\u3002</p> Python<pre><code># \u5bfc\u5165\u5fc5\u8981\u7684PyTorch\u6a21\u5757\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nclass CoTAttention(nn.Module):\n    # \u521d\u59cb\u5316CoT\u6ce8\u610f\u529b\u6a21\u5757\n    def __init__(self, dim=512, kernel_size=3):\n        super().__init__()\n        self.dim = dim  # \u8f93\u5165\u7684\u901a\u9053\u6570\n        self.kernel_size = kernel_size  # \u5377\u79ef\u6838\u5927\u5c0f\n\n        # \u5b9a\u4e49\u7528\u4e8e\u952e(key)\u7684\u5377\u79ef\u5c42\uff0c\u5305\u62ec\u4e00\u4e2a\u5206\u7ec4\u5377\u79ef\uff0cBatchNorm\u548cReLU\u6fc0\u6d3b\n        self.key_embed = nn.Sequential(\n            nn.Conv2d(dim, dim, kernel_size=kernel_size, padding=kernel_size//2, groups=4, bias=False),\n            nn.BatchNorm2d(dim),\n            nn.ReLU()\n        )\n\n        # \u5b9a\u4e49\u7528\u4e8e\u503c(value)\u7684\u5377\u79ef\u5c42\uff0c\u5305\u62ec\u4e00\u4e2a1x1\u5377\u79ef\u548cBatchNorm\n        self.value_embed = nn.Sequential(\n            nn.Conv2d(dim, dim, 1, bias=False),\n            nn.BatchNorm2d(dim)\n        )\n\n        # \u7f29\u5c0f\u56e0\u5b50\uff0c\u7528\u4e8e\u964d\u4f4e\u6ce8\u610f\u529b\u5d4c\u5165\u7684\u7ef4\u5ea6\n        factor = 4\n        # \u5b9a\u4e49\u6ce8\u610f\u529b\u5d4c\u5165\u5c42\uff0c\u7531\u4e24\u4e2a\u5377\u79ef\u5c42\u3001\u4e00\u4e2aBatchNorm\u5c42\u548cReLU\u6fc0\u6d3b\u7ec4\u6210\n        self.attention_embed = nn.Sequential(\n            nn.Conv2d(2*dim, 2*dim//factor, 1, bias=False),\n            nn.BatchNorm2d(2*dim//factor),\n            nn.ReLU(),\n            nn.Conv2d(2*dim//factor, kernel_size*kernel_size*dim, 1)\n        )\n\n    def forward(self, x):\n        # \u524d\u5411\u4f20\u64ad\u51fd\u6570\n        bs, c, h, w = x.shape  # \u8f93\u5165\u7279\u5f81\u7684\u5c3a\u5bf8\n        k1 = self.key_embed(x)  # \u751f\u6210\u952e\u7684\u9759\u6001\u8868\u793a\n        v = self.value_embed(x).view(bs, c, -1)  # \u751f\u6210\u503c\u7684\u8868\u793a\u5e76\u8c03\u6574\u5f62\u72b6\n\n        y = torch.cat([k1, x], dim=1)  # \u5c06\u952e\u7684\u9759\u6001\u8868\u793a\u548c\u539f\u59cb\u8f93\u5165\u8fde\u63a5\n        att = self.attention_embed(y)  # \u751f\u6210\u52a8\u6001\u6ce8\u610f\u529b\u6743\u91cd\n        att = att.reshape(bs, c, self.kernel_size*self.kernel_size, h, w)\n        att = att.mean(2, keepdim=False).view(bs, c, -1)  # \u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\u7684\u5747\u503c\u5e76\u8c03\u6574\u5f62\u72b6\n        k2 = F.softmax(att, dim=-1) * v  # \u5e94\u7528\u6ce8\u610f\u529b\u6743\u91cd\u5230\u503c\u4e0a\n        k2 = k2.view(bs, c, h, w)  # \u8c03\u6574\u5f62\u72b6\u4ee5\u5339\u914d\u8f93\u51fa\n\n        return k1 + k2  # \u8fd4\u56de\u952e\u7684\u9759\u6001\u548c\u52a8\u6001\u8868\u793a\u7684\u603b\u548c\n\n# \u5b9e\u4f8b\u5316CoTAttention\u6a21\u5757\u5e76\u6d4b\u8bd5\nif __name__ == '__main__':\n    block = CoTAttention(64)  # \u521b\u5efa\u4e00\u4e2a\u8f93\u5165\u901a\u9053\u6570\u4e3a64\u7684CoTAttention\u5b9e\u4f8b\n    input = torch.rand(1, 64, 64, 64)  # \u521b\u5efa\u4e00\u4e2a\u968f\u673a\u8f93\u5165\n    output = block(input)  # \u901a\u8fc7CoTAttention\u6a21\u5757\u5904\u7406\u8f93\u5165\n    print(output.shape)  # \u6253\u5370\u8f93\u5165\u548c\u8f93\u51fa\u7684\u5c3a\u5bf8\n</code></pre>"},{"location":"Reproduction/1/#tripletattention","title":"\u221a TripletAttention","text":"<p>\u8bba\u6587\u300aRotate to Attend: Convolutional Triplet Attention Module\u300b\u4e09\u5206\u652f\u6ce8\u610f\u529b</p> <p></p> <p></p> <p></p> <p>Triplet Attention\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b83\u901a\u8fc7**\u6355\u83b7\u8de8\u7ef4\u5ea6\u4ea4\u4e92**\uff0c\u5229\u7528**\u4e09\u5206\u652f\u7ed3\u6784**\u6765\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\u3002\u5bf9\u4e8e\u8f93\u5165\u5f20\u91cf\uff0cTriplet Attention\u901a\u8fc7**\u65cb\u8f6c\u64cd\u4f5c**\u5efa\u7acb\u7ef4\u5ea6\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u968f\u540e\u901a\u8fc7\u6b8b\u5dee\u53d8\u6362\u5bf9\u4fe1\u9053\u548c\u7a7a\u95f4\u4fe1\u606f\u8fdb\u884c\u7f16\u7801\uff0c\u5b9e\u73b0\u4e86\u51e0\u4e4e\u4e0d\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u589e\u5f3a\u89c6\u89c9\u8868\u5f81\u7684\u80fd\u529b\u3002</p> <p>\u673a\u5236</p> <p>1\u3001\u4e09\u5206\u652f\u7ed3\u6784\uff1a</p> <p>Triplet Attention\u5305\u542b\u4e09\u4e2a\u5206\u652f\uff0c\u6bcf\u4e2a\u5206\u652f\u8d1f\u8d23\u6355\u83b7\u8f93\u5165\u7684\u7a7a\u95f4\u7ef4\u5ea6H\u6216W\u4e0e\u4fe1\u9053\u7ef4\u5ea6C\u4e4b\u95f4\u7684\u4ea4\u4e92\u7279\u5f81\u3002</p> <p>2\u3001\u8de8\u7ef4\u5ea6\u4ea4\u4e92\uff1a</p> <p>\u901a\u8fc7\u5728\u6bcf\u4e2a\u5206\u652f\u4e2d\u5bf9\u8f93\u5165\u5f20\u91cf\u8fdb\u884c\u6392\u5217\uff08permute\uff09\u64cd\u4f5c\uff0c\u5e76\u901a\u8fc7Z-pool\u548ck\u00d7k\u7684\u5377\u79ef\u5c42\u5904\u7406\uff0c\u4ee5\u6355\u83b7\u8de8\u7ef4\u5ea6\u7684\u4ea4\u4e92\u7279\u5f81\u3002</p> <p>3\u3001\u6ce8\u610f\u529b\u6743\u91cd\u7684\u751f\u6210\uff1a</p> <p>\u5229\u7528sigmoid\u6fc0\u6d3b\u5c42\u751f\u6210\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u5e76\u5e94\u7528\u4e8e\u6392\u5217\u540e\u7684\u8f93\u5165\u5f20\u91cf\uff0c\u7136\u540e\u5c06\u5176\u6392\u5217\u56de\u539f\u59cb\u8f93\u5165\u5f62\u72b6\u3002</p> <p>\u72ec\u7279\u4f18\u52bf</p> <p>1\u3001\u8de8\u7ef4\u5ea6\u4ea4\u4e92\uff1a</p> <p>Triplet Attention\u901a\u8fc7\u6355\u83b7\u8f93\u5165\u5f20\u91cf\u7684\u8de8\u7ef4\u5ea6\u4ea4\u4e92\uff0c\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u5224\u522b\u7279\u5f81\u8868\u5f81\uff0c\u8f83\u4e4b\u524d\u7684\u6ce8\u610f\u529b\u673a\u5236\uff08\u5982SENet\u3001CBAM\u7b49\uff09\u80fd\u591f\u66f4\u6709\u6548\u5730\u589e\u5f3a\u7f51\u7edc\u7684\u6027\u80fd\u3002</p> <p>2\u3001\u51e0\u4e4e\u65e0\u8ba1\u7b97\u6210\u672c\u589e\u52a0\uff1a</p> <p>\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0cTriplet Attention\u5728\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u7684\u540c\u65f6\uff0c\u51e0\u4e4e\u4e0d\u589e\u52a0\u989d\u5916\u7684\u8ba1\u7b97\u6210\u672c\u548c\u53c2\u6570\u6570\u91cf\uff0c\u4f7f\u5f97\u5b83\u53ef\u4ee5\u8f7b\u677e\u5730\u96c6\u6210\u5230\u7ecf\u5178\u7684\u9aa8\u5e72\u7f51\u7edc\u4e2d\u3002</p> <p>3\u3001\u65e0\u9700\u964d\u7ef4\uff1a</p> <p>\u4e0e\u5176\u4ed6\u6ce8\u610f\u529b\u673a\u5236\u4e0d\u540c\uff0cTriplet Attention\u4e0d\u8fdb\u884c\u7ef4\u5ea6\u964d\u4f4e\u5904\u7406\uff0c\u8fd9\u907f\u514d\u4e86\u56e0\u964d\u7ef4\u53ef\u80fd\u5bfc\u81f4\u7684\u4fe1\u606f\u4e22\u5931\uff0c\u4fdd\u8bc1\u4e86\u4fe1\u9053\u4e0e\u6743\u91cd\u95f4\u7684\u76f4\u63a5\u5bf9\u5e94\u5173\u7cfb\u3002</p> <p>\u4f18\u8d28\u6ce8\u91ca\uff1a</p> Python<pre><code>import torch\nimport torch.nn as nn\n\n\"Rotate to Attend: Convolutional Triplet Attention Module\"\n\nclass BasicConv(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n        super(BasicConv, self).__init__()\n        self.out_channels = out_planes\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n        self.relu = nn.ReLU() if relu else None\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.bn is not None:\n            x = self.bn(x)\n        if self.relu is not None:\n            x = self.relu(x)\n        return x\n\nclass ZPool(nn.Module):\n    def forward(self, x):\n        # \u4ee5\u5efa\u7acbCW\u4e4b\u95f4\u7684\u4ea4\u4e92\u4e3a\u4f8b, x:(B, H, C, W)\n        a = torch.max(x,1)[0].unsqueeze(1) # \u5168\u5c40\u6700\u5927\u6c60\u5316: (B, H, C, W)-&gt;(B, 1, C, W);  torch.max\u8fd4\u56de\u7684\u662f\u6570\u7ec4:[\u6700\u5927\u503c,\u5bf9\u5e94\u7d22\u5f15]\n        '''\n            torch.max \u8ba1\u7b97\u5f20\u91cf\u7684\u6700\u5927\u503c\n            x \u662f \u8f93\u5165\u5f20\u91cf\n            1 \u662f dim \u53c2\u6570\uff0c\u8868\u793a\u6cbf\u7740\u7b2c 1 \u7ef4\u5ea6\uff08\u901a\u5e38\u662f\u884c\u65b9\u5411\uff09\u8ba1\u7b97\u6700\u5927\u503c\n            torch.max(x, 1) \u8fd4\u56de\u4e00\u4e2a\u5143\u7ec4 (values, indices)\uff0c\u5176\u4e2d values \u662f\u6bcf\u884c\u7684\u6700\u5927\u503c\uff0cindices \u662f\u5bf9\u5e94\u7684\u7d22\u5f15\n            [0] : [0] \u53d6\u51fa\u5143\u7ec4\u4e2d\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\uff0c\u5373 values\uff0c\u4e5f\u5c31\u662f\u6700\u5927\u503c\n            .unsqueeze(1) \u5728\u6307\u5b9a\u7ef4\u5ea6\u4e0a\u589e\u52a0\u4e00\u4e2a\u5927\u5c0f\u4e3a 1 \u7684\u7ef4\u5ea6\n            values \u7684\u5f62\u72b6\u662f (n,)\uff0c\u90a3\u4e48 values.unsqueeze(1) \u7684\u5f62\u72b6\u5c06\u53d8\u4e3a (n, 1)\n\n            \u6211\u61c2\u4e86\uff0c\u60f3\u8c61\u7684\u65f6\u5019\uff0c\u8981\u60f3\u6210\u4e00\u5f20\u5f69\u8272\u7684 RGB \u56fe\uff0c\u4e0d\u8981\u60f3\u6210\u6570\u8868\uff0c\u56e0\u6b64 torch.max(x,1)[0]\u7684\u5f62\u72b6\u662f (B, 1, C, W)\uff1b\u5bf9\u4e8e\u4e00\u5f20\u56fe\u7247\u6765\u8bf4\u6709 W\u00d7C \u4e2a\u6700\u5927\u503c\uff0c\u672c\u6765\u662f\u5f69\u8272\u7684 RGB \u56fe\uff0c\u53d8\u6210\u4e86\u4e00\u5f20\u7070\u5ea6\u56fe\uff0c\u6cbf\u7740\u901a\u9053\u65b9\u5411\u53d6\u6700\u5927\u503c\n        '''\n        b = torch.mean(x,1).unsqueeze(1)   # \u5168\u5c40\u5e73\u5747\u6c60\u5316: (B, H, C, W)-&gt;(B, 1, C, W);\n        c = torch.cat((a, b), dim=1)       # \u5728\u5bf9\u5e94\u7ef4\u5ea6\u62fc\u63a5\u6700\u5927\u548c\u5e73\u5747\u7279\u5f81: (B, 2, C, W)\n        return c\n\nclass AttentionGate(nn.Module):\n    def __init__(self):\n        super(AttentionGate, self).__init__()\n        kernel_size = 7\n        self.compress = ZPool()\n        self.conv = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n    def forward(self, x):\n        # \u4ee5\u5efa\u7acbCW\u4e4b\u95f4\u7684\u4ea4\u4e92\u4e3a\u4f8b, x:(B, H, C, W)\n        x_compress = self.compress(x) # \u5728\u5bf9\u5e94\u7ef4\u5ea6\u4e0a\u6267\u884c\u6700\u5927\u6c60\u5316\u548c\u5e73\u5747\u6c60\u5316,\u5e76\u5c06\u5176\u62fc\u63a5: (B, H, C, W) --&gt; (B, 2, C, W);\n        x_out = self.conv(x_compress) # \u901a\u8fc7conv\u64cd\u4f5c\u5c06\u6700\u5927\u6c60\u5316\u548c\u5e73\u5747\u6c60\u5316\u7279\u5f81\u6620\u5c04\u5230\u4e00\u7ef4: (B, 2, C, W) --&gt; (B, 1, C, W);\n        scale = torch.sigmoid_(x_out) # \u901a\u8fc7sigmoid\u51fd\u6570\u751f\u6210\u6743\u91cd: (B, 1, C, W);\n        return x * scale              # \u5bf9\u8f93\u5165\u8fdb\u884c\u91cd\u65b0\u52a0\u6743\u8868\u793a: (B, H, C, W) * (B, 1, C, W) = (B, H, C, W) \u5e7f\u64ad\uff0c\u590d\u5236\uff0c\u6cbf\u7740\u901a\u9053\u65b9\u5411\u590d\u5236\u6210\u4e00\u6837\u7684\n\nclass TripletAttention(nn.Module):\n    def __init__(self, no_spatial=False):\n        super(TripletAttention, self).__init__()\n        self.cw = AttentionGate()\n        self.hc = AttentionGate()\n        self.no_spatial=no_spatial\n        if not no_spatial:\n            self.hw = AttentionGate()\n    def forward(self, x):\n        # \u5efa\u7acbC\u548cW\u4e4b\u95f4\u7684\u4ea4\u4e92:\n        x_perm1 = x.permute(0,2,1,3).contiguous() # (B, C, H, W)--&gt; (B, H, C, W);  \u6267\u884c\u201c\u65cb\u8f6c\u64cd\u4f5c\u201d,\u5efa\u7acbC\u548cW\u4e4b\u95f4\u7684\u4ea4\u4e92,\u6240\u4ee5\u8981\u5728H\u7ef4\u5ea6\u4e0a\u538b\u7f29\n        x_out1 = self.cw(x_perm1) # (B, H, C, W)--&gt;(B, H, C, W);  \u5728H\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u538b\u7f29\u3001\u62fc\u63a5\u3001Conv\u3001sigmoid\u64cd\u4f5c, \u7136\u540e\u901a\u8fc7\u6743\u91cd\u91cd\u65b0\u52a0\u6743\n        x_out11 = x_out1.permute(0,2,1,3).contiguous() # \u6062\u590d\u4e0e\u8f93\u5165\u76f8\u540c\u7684shape,\u4e5f\u5c31\u662f\u91cd\u65b0\u65cb\u8f6c\u56de\u6765: (B, H, C, W)--&gt;(B, C, H, W)\n\n        # \u5efa\u7acbH\u548cC\u4e4b\u95f4\u7684\u4ea4\u4e92:\n        x_perm2 = x.permute(0,3,2,1).contiguous() # (B, C, H, W)--&gt; (B, W, H, C); \u6267\u884c\u201c\u65cb\u8f6c\u64cd\u4f5c\u201d,\u5efa\u7acbH\u548cC\u4e4b\u95f4\u7684\u4ea4\u4e92,\u6240\u4ee5\u8981\u5728W\u7ef4\u5ea6\u4e0a\u538b\u7f29\n        x_out2 = self.hc(x_perm2) # (B, W, H, C)--&gt;(B, W, H, C);  \u5728W\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u538b\u7f29\u3001\u62fc\u63a5\u3001Conv\u3001sigmoid\u64cd\u4f5c, \u7136\u540e\u901a\u8fc7\u6743\u91cd\u91cd\u65b0\u52a0\u6743\n        x_out21 = x_out2.permute(0,3,2,1).contiguous() # \u6062\u590d\u4e0e\u8f93\u5165\u76f8\u540c\u7684shape,\u4e5f\u5c31\u662f\u91cd\u65b0\u65cb\u8f6c\u56de\u6765: (B, W, H, C)--&gt;(B, C, H, W)\n\n        # \u5efa\u7acbH\u548cW\u4e4b\u95f4\u7684\u4ea4\u4e92:\n        if not self.no_spatial:\n            x_out = self.hw(x) # (B, C, H, W)--&gt;(B, C, H, W);  \u5728C\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u538b\u7f29\u3001\u62fc\u63a5\u3001Conv\u3001sigmoid\u64cd\u4f5c, \u7136\u540e\u901a\u8fc7\u6743\u91cd\u91cd\u65b0\u52a0\u6743\n            x_out = 1/3 * (x_out + x_out11 + x_out21) # \u53d6\u4e09\u90e8\u5206\u7684\u5e73\u5747\u503c\u8fdb\u884c\u8f93\u51fa\n        else:\n            x_out = 1/2 * (x_out11 + x_out21)\n        return x_out\n\nif __name__ == '__main__':\n    # (B, C, H, W)\n    input=torch.randn(1,512,7,7)\n    Model = TripletAttention()\n    output=Model(input)\n    print(output.shape)\n</code></pre> <p>\u6ce8\u91ca</p> Python<pre><code>import torch\nimport torch.nn as nn\n\n# \u5b9a\u4e49\u4e00\u4e2a\u57fa\u672c\u7684\u5377\u79ef\u6a21\u5757\uff0c\u5305\u62ec\u5377\u79ef\u3001\u6279\u5f52\u4e00\u5316\u548cReLU\u6fc0\u6d3b\nclass BasicConv(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n        super(BasicConv, self).__init__()\n        self.out_channels = out_planes\n        # \u5b9a\u4e49\u5377\u79ef\u5c42\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        # \u6761\u4ef6\u6027\u5730\u6dfb\u52a0\u6279\u5f52\u4e00\u5316\u5c42\n        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5, momentum=0.01, affine=True) if bn else None\n        # \u6761\u4ef6\u6027\u5730\u6dfb\u52a0ReLU\u6fc0\u6d3b\u51fd\u6570\n        self.relu = nn.ReLU() if relu else None\n\n    def forward(self, x):\n        x = self.conv(x)  # \u5e94\u7528\u5377\u79ef\n        if self.bn is not None:\n            x = self.bn(x)  # \u5e94\u7528\u6279\u5f52\u4e00\u5316\n        if self.relu is not None:\n            x = self.relu(x)  # \u5e94\u7528ReLU\n        return x\n\n# \u5b9a\u4e49ZPool\u6a21\u5757\uff0c\u7ed3\u5408\u6700\u5927\u6c60\u5316\u548c\u5e73\u5747\u6c60\u5316\u7ed3\u679c\nclass ZPool(nn.Module):\n    def forward(self, x):\n        # \u7ed3\u5408\u6700\u5927\u503c\u548c\u5e73\u5747\u503c\n        return torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n\n# \u5b9a\u4e49\u6ce8\u610f\u529b\u95e8\uff0c\u7528\u4e8e\u6839\u636e\u8f93\u5165\u7279\u5f81\u751f\u6210\u6ce8\u610f\u529b\u6743\u91cd\nclass AttentionGate(nn.Module):\n    def __init__(self):\n        super(AttentionGate, self).__init__()\n        kernel_size = 7  # \u8bbe\u5b9a\u5377\u79ef\u6838\u5927\u5c0f\n        self.compress = ZPool()  # \u4f7f\u7528ZPool\u6a21\u5757\n        self.conv = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size - 1) // 2, relu=False)  # \u901a\u8fc7\u5377\u79ef\u8c03\u6574\u901a\u9053\u6570\n\n    def forward(self, x):\n        x_compress = self.compress(x)  # \u5e94\u7528ZPool\n        x_out = self.conv(x_compress)  # \u901a\u8fc7\u5377\u79ef\u751f\u6210\u6ce8\u610f\u529b\u6743\u91cd\n        scale = torch.sigmoid_(x_out)  # \u5e94\u7528Sigmoid\u6fc0\u6d3b\n        return x * scale  # \u5c06\u6ce8\u610f\u529b\u6743\u91cd\u4e58\u4ee5\u539f\u59cb\u7279\u5f81\n\n# \u5b9a\u4e49TripletAttention\u6a21\u5757\uff0c\u7ed3\u5408\u4e86\u4e09\u79cd\u4e0d\u540c\u65b9\u5411\u7684\u6ce8\u610f\u529b\u95e8\nclass TripletAttention(nn.Module):\n    def __init__(self, no_spatial=False):\n        super(TripletAttention, self).__init__()\n        self.cw = AttentionGate()  # \u5b9a\u4e49\u5bbd\u5ea6\u65b9\u5411\u7684\u6ce8\u610f\u529b\u95e8\n        self.hc = AttentionGate()  # \u5b9a\u4e49\u9ad8\u5ea6\u65b9\u5411\u7684\u6ce8\u610f\u529b\u95e8\n        self.no_spatial = no_spatial  # \u662f\u5426\u5ffd\u7565\u7a7a\u95f4\u6ce8\u610f\u529b\n        if not no_spatial:\n            self.hw = AttentionGate()  # \u5b9a\u4e49\u7a7a\u95f4\u65b9\u5411\u7684\u6ce8\u610f\u529b\u95e8\n\n    def forward(self, x):\n        # \u5e94\u7528\u6ce8\u610f\u529b\u95e8\u5e76\u7ed3\u5408\u7ed3\u679c\n        x_perm1 = x.permute(0, 2, 1, 3).contiguous()  # \u8f6c\u7f6e\u4ee5\u5e94\u7528\u5bbd\u5ea6\u65b9\u5411\u7684\u6ce8\u610f\u529b\n        x_out1 = self.cw(x_perm1)\n        x_out11 = x_out1.permute(0, 2, 1, 3).contiguous()  # \u8fd8\u539f\u8f6c\u7f6e\n        x_perm2 = x.permute(0, 3, 2, 1).contiguous()  # \u8f6c\u7f6e\u4ee5\u5e94\u7528\u9ad8\u5ea6\u65b9\u5411\u7684\u6ce8\u610f\u529b\n        x_out2 = self.hc(x_perm2)\n        x_out21 = x_out2.permute(0, 3, 2, 1).contiguous()  # \u8fd8\u539f\u8f6c\u7f6e\n        if not self.no_spatial:\n            x_out = self.hw(x)  # \u5e94\u7528\u7a7a\u95f4\u6ce8\u610f\u529b\n            x_out = 1 / 3 * (x_out + x_out11 + x_out21)  # \u7ed3\u5408\u4e09\u4e2a\u65b9\u5411\u7684\u7ed3\u679c\n        else:\n            x_out = 1 / 2 * (x_out11 + x_out21)  # \u7ed3\u5408\u4e24\u4e2a\u65b9\u5411\u7684\u7ed3\u679c\uff08\u5982\u679cno_spatial\u4e3aTrue\uff09\n        return x_out\n\n# \u793a\u4f8b\u4ee3\u7801\nif __name__ == '__main__':\n    input = torch.randn(50, 512, 7, 7)  # \u751f\u6210\u968f\u673a\u8f93\u5165\n    triplet = TripletAttention()  # \u5b9e\u4f8b\u5316TripletAttention\n    output = triplet(input)  # \u5e94\u7528TripletAttention\n    print(output.shape)  # \u6253\u5370\u8f93\u51fa\u5f62\u72b6\n</code></pre>"},{"location":"Reproduction/1/#danet","title":"\u221aDANet","text":"<p>\u6807\u9898\uff1aDual Attention Network for Scene Segmentation</p> <p>\u53cc\u91cd\u6ce8\u610f\u529b\u7f51\u7edc</p> <p></p> <p></p> <p></p> <p>\u6211\u5e94\u8be5\u4e5f\u5b66\u4e00\u4e0b \u81ea\u5df1\u7ed8\u5236 \u8ba1\u7b97\u6d41\u7a0b\u56fe</p> <p></p> <p></p> <p></p> <p></p> <p>\u4f18\u8d28\u6ce8\u91ca</p> Python<pre><code>import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import init\n\n\"Dual Attention Network for Scene Segmentation\"\n\n\nclass ScaledDotProductAttention(nn.Module):\n    '''\n    Scaled dot-product attention\n    '''\n\n    def __init__(self, d_model, d_k, d_v, h,dropout=.1):\n        ''' \u8c03\u7528init\uff1aself.pa=ScaledDotProductAttention(d_model,d_k=d_model,d_v=d_model,h=1)\n        :param d_model: Output dimensionality of the model\n        :param d_k: Dimensionality of queries and keys\n        :param d_v: Dimensionality of values\n        :param h: Number of heads  \u4e5f\u8bb8\u6211\u5173\u4e8e QKV \u7684\u7406\u89e3\u6709\u8bef\uff1and ///  n_q\u00d7d_q . d_q \u00d7 n_k . n_k \u00d7 d_v\n        '''\n        super(ScaledDotProductAttention, self).__init__()\n        self.fc_q = nn.Linear(d_model, h * d_k)\n        self.fc_k = nn.Linear(d_model, h * d_k)\n        self.fc_v = nn.Linear(d_model, h * d_v)\n        self.fc_o = nn.Linear(h * d_v, d_model)\n        self.dropout=nn.Dropout(dropout)\n\n        self.d_model = d_model\n        self.d_k = d_k\n        self.d_v = d_v\n        self.h = h\n\n        self.init_weights()\n\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, queries, keys, values, attention_mask=None, attention_weights=None):\n        '''\u8fd9\u91cc\u7684\u8c03\u7528 y=B,N(HW),C \u2192 y=self.pa(y,y,y) \u2192 self.pa=ScaledDotProductAttention(d_model,d_k=d_model,d_v=d_model,h=1)\n        Computes\n        :param queries: Queries (b_s, nq, d_model) == (B,N,C)\n        :param keys: Keys (b_s, nk, d_model) == (B,N,C)\n        :param values: Values (b_s, nk, d_model) == (B,N,C)\n        :param attention_mask: Mask over attention values (b_s, h, nq, nk); C=h*nk. True indicates masking.\n        :param attention_weights: Multiplicative weights for attention values (b_s, h, nq, nk).\n        :return:\n        '''\n        b_s, nq = queries.shape[:2] # n_q \u662f query \u7684\u5e8f\u5217\u957f\u5ea6\n        nk = keys.shape[1] # n_k key \u548c value \u7684\u5e8f\u5217\u957f\u5ea6=\u50cf\u7d20\u4e2a\u6570=HW\uff1b\u518d\u6b21\u5f3a\u8c03\uff0cQKV \u5d4c\u5165\u7ef4\u5ea6\u76f8\u540c\uff0c\u5e8f\u5217\u957f\u5ea6\u53ef\u4ee5\u4e0d\u540c\n\n        # \u6ce8\u610f\u529b\u4e0e\u5377\u79ef\u76f8\u7ed3\u5408\u662f\u6211\u7684\u4e0d\u660e\u767d\n        # QK^TV Q n1\u00d7d K=V n2\u00d7d \n        # Q\u7684\u6765\u6e90\u53ef\u4ee5\u548c KV \u4e0d\u540c\uff0cKV \u7684\u6765\u6e90 shape \u5fc5\u987b\u4e00\u6837\uff0c\u4f46\u662f\u5d4c\u5165\u7a7a\u95f4\u5fc5\u987b\u4e00\u81f4\n        # n1\u00d7d . d\u00d7n2 . n2\u00d7d = n1\u00d7d\n\n        q = self.fc_q(queries).view(b_s, nq, self.h, self.d_k).permute(0, 2, 1, 3)  # (b_s, h, nq, d_k) \u5176\u5b9e\u8fd9\u91cc\u7684d_k \u5d4c\u5165\u7ef4\u5ea6 \u5e94\u8be5\u662f embedding_dim//h \u56e0\u4e3a head=1\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684  d_k = embedding_dim // \u2192 self.fc_q = nn.Linear(d_model, h * d_k) \u2192 self.pa=ScaledDotProductAttention(d_model,d_k=d_model,d_v=d_model,h=1) \n        k = self.fc_k(keys).view(b_s, nk, self.h, self.d_k).permute(0, 2, 3, 1)  # (b_s, h, d_k, nk)\n        v = self.fc_v(values).view(b_s, nk, self.h, self.d_v).permute(0, 2, 1, 3)  # (b_s, h, nk, d_v) \u8fd9\u51e0\u4e2a\u5f62\u72b6\u7684\u6ce8\u91ca\u5f88\u51c6\u786e\uff0c\u751a\u81f3\u8fc7\u5206\u51c6\u786e\u4e86\n\n        att = torch.matmul(q, k) / np.sqrt(self.d_k)  # (b_s, h, nq, nk)\n        if attention_weights is not None:\n            att = att * attention_weights\n        if attention_mask is not None:\n            att = att.masked_fill(attention_mask, -np.inf)\n        att = torch.softmax(att, -1)\n        att=self.dropout(att)\n\n        out = torch.matmul(att, v).permute(0, 2, 1, 3).contiguous().view(b_s, nq, self.h * self.d_v)  # (b_s, nq, h*d_v)\n        out = self.fc_o(out)  # (b_s, nq, d_model) \u518d\u628a\u5d4c\u5165\u7ef4\u5ea6\u964d\u56de\u53bb \u6062\u590d\u539f\u6765\u7684\u5d4c\u5165\u7ef4\u5ea6\n        return out\n\n\nclass SimplifiedScaledDotProductAttention(nn.Module):\n    '''\n    Scaled dot-product attention\n    '''\n\n    def __init__(self, d_model, h,dropout=.1):\n        '''\n        :param d_model: Output dimensionality of the model\n        :param d_k: Dimensionality of queries and keys\n        :param d_v: Dimensionality of values\n        :param h: Number of heads\n        '''\n        super(SimplifiedScaledDotProductAttention, self).__init__()\n\n        self.d_model = d_model\n        self.d_k = d_model//h\n        self.d_v = d_model//h\n        self.h = h\n\n        self.fc_o = nn.Linear(h * self.d_v, d_model)\n        self.dropout=nn.Dropout(dropout)\n\n\n\n        self.init_weights()\n\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, queries, keys, values, attention_mask=None, attention_weights=None):\n        '''\n        Computes\n        :param queries: Queries (b_s, nq, d_model)\n        :param keys: Keys (b_s, nk, d_model)\n        :param values: Values (b_s, nk, d_model)\n        :param attention_mask: Mask over attention values (b_s, h, nq, nk). True indicates masking.\n        :param attention_weights: Multiplicative weights for attention values (b_s, h, nq, nk).\n        :return:\n        '''\n        b_s, nq = queries.shape[:2]\n        nk = keys.shape[1]\n\n        q = queries.view(b_s, nq, self.h, self.d_k).permute(0, 2, 1, 3)  # (b_s, h, nq, d_k)\n        k = keys.view(b_s, nk, self.h, self.d_k).permute(0, 2, 3, 1)  # (b_s, h, d_k, nk)\n        v = values.view(b_s, nk, self.h, self.d_v).permute(0, 2, 1, 3)  # (b_s, h, nk, d_v)\n\n        att = torch.matmul(q, k) / np.sqrt(self.d_k)  # (b_s, h, nq, nk)\n        if attention_weights is not None:\n            att = att * attention_weights\n        if attention_mask is not None:\n            att = att.masked_fill(attention_mask, -np.inf)\n        att = torch.softmax(att, -1)\n        att=self.dropout(att)\n\n        out = torch.matmul(att, v).permute(0, 2, 1, 3).contiguous().view(b_s, nq, self.h * self.d_v)  # (b_s, nq, h*d_v)\n        out = self.fc_o(out)  # (b_s, nq, d_model)\n        return out\n\n\nclass PositionAttentionModule(nn.Module):\n\n    def __init__(self,d_model=512,kernel_size=3,H=7,W=7):\n        super().__init__()\n        self.cnn=nn.Conv2d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-1)//2) # \u4e0d\u53d8\u5377\u79ef\uff0c\u901a\u9053\u6570\u76f8\u5f53\u4e8e\u5d4c\u5165\u7ef4\u5ea6 512\uff1bin_channel=d_modle out_channel=d_model;\u8fd9\u4e00\u6b65\u5c31\u662f\u805a\u5408\u4e00\u4e0b\u5c40\u90e8\u7279\u5f81\n        self.pa=ScaledDotProductAttention(d_model,d_k=d_model,d_v=d_model,h=1)\n\n    def forward(self,x):\n        # (B, C, H, W)\n        B, C, H, W=x.shape # (B, C, H, W)\n        y=self.cnn(x) # (B, C, H, W) --&gt; (B, C, H, W)\n        y=y.view(B,C,-1).permute(0,2,1) # (B, C, H, W) --&gt; (B,C,N)--&gt;(B,N,C)   N=H*W \u5e8f\u5217\u957f\u5ea6\u5c31\u662f H*W\n        y=self.pa(y,y,y) #(B,N,C)\n        return y\n\n\nclass ChannelAttentionModule(nn.Module):\n\n    def __init__(self,d_model=512,kernel_size=3,H=7,W=7):\n        super().__init__()\n        self.cnn=nn.Conv2d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-1)//2)\n        self.pa=SimplifiedScaledDotProductAttention(H*W,h=1) # \u533a\u522b\u5728\u54ea\u513f\uff1f\u4e3a\u4ec0\u4e48\u6ca1\u6709\u590d\u7528\n\n    def forward(self,x):\n        # (B, C, H, W)\n        B,C,H,W=x.shape\n        y=self.cnn(x) # (B, C, H, W) --&gt; (B, C, H, W)\n        y=y.view(B,C,-1)  # (B, C, H, W)--&gt;(B, C, N)  N=H*W\n        y=self.pa(y,y,y)  # (B, C, N) \u56fe\u50cf\u6570\u636e\u5728\u8fdb\u5165\u5230\u6ce8\u610f\u529b\u8ba1\u7b97\u4e4b\u524d\u5c31\u5df2\u7ecf\u5c55\u5e73\u7ef4\u5ea6\u4e86\u3002\n        return y\n\n\n\n\nclass DAModule(nn.Module):\n\n    def __init__(self,d_model=512,kernel_size=3,H=7,W=7):\n        super().__init__()\n        # \u4f4d\u7f6e\u6ce8\u610f\u529b\u548c\u901a\u9053\u6ce8\u610f\u529b\u7684\u533a\u522b\u5c31\u662f\uff1a\u901a\u9053\u6ce8\u610f\u529b\u6ca1\u6709\u901a\u8fc7\u5377\u79ef\u64cd\u4f5c\u751f\u6210qkv\n        self.position_attention_module=PositionAttentionModule(d_model=512,kernel_size=3,H=7,W=7)\n        self.channel_attention_module=ChannelAttentionModule(d_model=512,kernel_size=3,H=7,W=7)\n\n    def forward(self,input):\n        # (B, C, H, W)\n        B,C,H,W=input.shape # (B, C, H, W)\n        p_out=self.position_attention_module(input) # \u6267\u884c\u4f4d\u7f6e\u6ce8\u610f\u529b: (B, C, H, W)--&gt;(B,N,C) \u4f4d\u7f6e\u6ce8\u610f\u529b\u548c\u7a7a\u95f4\u6ce8\u610f\u529b\u5f88\u50cf\n        c_out=self.channel_attention_module(input)  # \u6267\u884c\u901a\u9053\u6ce8\u610f\u529b:(B, C, H, W)--&gt; (B, C, N)\n        p_out=p_out.permute(0,2,1).view(B,C,H,W) #(B,N,C)--&gt;(B,C,N)--&gt;(B,C,H,W)\n        c_out=c_out.view(B,C,H,W) # (B,C,N)--&gt;(B,C,H,W)\n\n        p_out = input + 0.5 * p_out\n        c_out = input + 0.2 * c_out\n\n        return p_out+c_out\n\n\n# \u4e24\u4e2a\u6ce8\u610f\u529b\u673a\u5236\u5c31\u4e0d\u7ec6\u8bb2\u4e86\u54e6, \u57fa\u672c\u4e00\u6a21\u4e00\u6837,\u53ea\u4e0d\u8fc7\u901a\u9053\u6ce8\u610f\u529b\u6ca1\u6709\u901a\u8fc7\u5377\u79ef\u751f\u6210\u65b0\u7684qkv,\u4f5c\u8005\u8bf4\u4f1a\u7834\u574f\u539f\u6709\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\nif __name__ == '__main__':\n    # (B, C, H, W)\n    input=torch.randn(1,512,7,7)\n    Model=DAModule(d_model=512,kernel_size=3,H=7,W=7)\n    output = Model(input)\n    print(output.shape)\n</code></pre>"},{"location":"Reproduction/1/#_3","title":"\u7279\u5f81\u878d\u5408","text":""},{"location":"Reproduction/1/#asff","title":"\u221a\u2b50ASFF \u4e0d\u540c\u5c3a\u5ea6\u7279\u5f81\u878d\u5408","text":"<p>\u8bba\u6587\u300aLearning Spatial Fusion for Single-Shot Object Detection\u300b</p> <p>\u81ea\u9002\u5e94\u7a7a\u95f4\u7279\u5f81\u878d\u5408</p> <p>ASFF</p> <p></p> <p></p> <p></p> <p>\u4e3b\u8981\u89e3\u51b3\uff1a\u4e0d\u540c\u7279\u5f81\u5c3a\u5ea6\u4e0d\u4e00\u81f4\u7684\u95ee\u9898 </p> <p>softmax\uff1a</p> <p></p> <p></p> <p>\uff08\u5b9e\u8df5\u51fa\u771f\u77e5\uff09</p> <p>\u4f18\u8d28\u6ce8\u91ca</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef autopad(k, p=None):  # kernel, padding\n    # Pad to 'same'\n    if p is None:\n        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n    return p\n\n\nclass Conv(nn.Module):\n    # Standard convolution\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n        super(Conv, self).__init__()\n        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)\n        self.bn = nn.BatchNorm2d(c2)\n        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())\n\n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))\n\n    def forward_fuse(self, x):\n        return self.act(self.conv(x))\n\n\nclass ASFF(nn.Module):\n    def __init__(self, level, multiplier=1, rfb=False, vis=False, act_cfg=True):\n        \"\"\"\n        multiplier should be 1, 0.5\n        which means, the channel of ASFF can be\n        512, 256, 128 -&gt; multiplier=0.5\n        1024, 512, 256 -&gt; multiplier=1\n        For even smaller, you need change code manually.\n        \"\"\"\n        # init asff_module = ASFF(level=1, multiplier=1, rfb=False, vis=False)\n        super(ASFF, self).__init__()\n        self.level = level\n        self.dim = [int(1024 * multiplier), int(512 * multiplier),\n                    int(256 * multiplier)]\n        # print(self.dim)\n\n        self.inter_dim = self.dim[self.level]\n        if level == 0:\n            self.stride_level_1 = Conv(int(512 * multiplier), self.inter_dim, 3, 2)\n\n            self.stride_level_2 = Conv(int(256 * multiplier), self.inter_dim, 3, 2)\n\n            self.expand = Conv(self.inter_dim, int(\n                1024 * multiplier), 3, 1)\n        elif level == 1:\n            self.compress_level_0 = Conv(\n                int(1024 * multiplier), self.inter_dim, 1, 1)\n            self.stride_level_2 = Conv(\n                int(256 * multiplier), self.inter_dim, 3, 2)\n            self.expand = Conv(self.inter_dim, int(512 * multiplier), 3, 1)\n        elif level == 2:\n            self.compress_level_0 = Conv(\n                int(1024 * multiplier), self.inter_dim, 1, 1)\n            self.compress_level_1 = Conv(\n                int(512 * multiplier), self.inter_dim, 1, 1)\n            self.expand = Conv(self.inter_dim, int(\n                256 * multiplier), 3, 1)\n\n        # when adding rfb, we use half number of channels to save memory\n        compress_c = 8 if rfb else 16\n        self.weight_level_0 = Conv(\n            self.inter_dim, compress_c, 1, 1)\n        self.weight_level_1 = Conv(\n            self.inter_dim, compress_c, 1, 1)\n        self.weight_level_2 = Conv(\n            self.inter_dim, compress_c, 1, 1)\n\n        self.weight_levels = Conv(\n            compress_c * 3, 3, 1, 1)\n        self.vis = vis\n\n    def forward(self, x):  # l,m,s\n        \"\"\"\n        #\n        256, 512, 1024\n        from small -&gt; large\n        \"\"\"\n        # forward output_feature = asff_module([level_2_feature, level_1_feature, level_0_feature])\n        x_level_0 = x[2]  # \u6700\u5927\u7279\u5f81\u5c42 level_0_feature = (1, 1024, 20, 20)  # \u5927\u5c3a\u5bf8\u7279\u5f81\u56fe \u5c3a\u5bf8\u5c0f\u901a\u9053\u591a\n        x_level_1 = x[1]  # \u4e2d\u95f4\u7279\u5f81\u5c42 level_1_feature = (1, 512, 40, 40)   # \u4e2d\u5c3a\u5bf8\u7279\u5f81\u56fe\n        x_level_2 = x[0]  # \u6700\u5c0f\u7279\u5f81\u5c42 level_2_feature = (1, 256, 80, 80)   # \u5c0f\u5c3a\u5bf8\u7279\u5f81\u56fe\n\n        if self.level == 0:\n            level_0_resized = x_level_0\n            level_1_resized = self.stride_level_1(x_level_1)\n            level_2_downsampled_inter = F.max_pool2d(\n                x_level_2, 3, stride=2, padding=1)\n            level_2_resized = self.stride_level_2(level_2_downsampled_inter)\n        elif self.level == 1:\n            level_0_compressed = self.compress_level_0(x_level_0) # (1, 1024, 20, 20) \u2192 self.compress_level_0 =  Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) \u2192 (1, 512, 20, 20)\n\n            level_0_resized = F.interpolate(\n                level_0_compressed, scale_factor=2, mode='nearest') # (1, 512, 20, 20) \u2192 F.interpolate\u2192 [1, 512, 40, 40]\n            level_1_resized = x_level_1 #  [1, 512, 40, 40] \u2192 = \u2192 [1, 512, 40, 40]\n            level_2_resized = self.stride_level_2(x_level_2) # [1, 256, 80, 80] \u2192 self.stride_level_2 = Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) \u2192 [1, 512, 40, 40]\n        elif self.level == 2:\n            level_0_compressed = self.compress_level_0(x_level_0)\n            level_0_resized = F.interpolate(\n                level_0_compressed, scale_factor=4, mode='nearest')\n            x_level_1_compressed = self.compress_level_1(x_level_1)\n            level_1_resized = F.interpolate(\n                x_level_1_compressed, scale_factor=2, mode='nearest')\n            level_2_resized = x_level_2\n\n        level_0_weight_v = self.weight_level_0(level_0_resized) # [1, 512, 40, 40] \u2192 self.weight_level_0 = (conv): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) \u2192 [1, 16, 40, 40]\n        level_1_weight_v = self.weight_level_1(level_1_resized) # [1, 512, 40, 40] \u2192 self.weight_level_1 = Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) \u2192 [1, 16, 40, 40]\n        level_2_weight_v = self.weight_level_2(level_2_resized) # [1, 512, 40, 40] \u2192 self.weight_level_2 = Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) \u2192 [1, 16, 40, 40]\n\n        levels_weight_v = torch.cat(\n            (level_0_weight_v, level_1_weight_v, level_2_weight_v), 1) # [1, 16, 40, 40],[1, 16, 40, 40],[1, 16, 40, 40] \u2192 cat \u2192 [1, 48, 40, 40]\n        levels_weight = self.weight_levels(levels_weight_v) # [1, 48, 40, 40] \u2192 self.weight_levels = (conv): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1), bias=False) \u2192 [1, 3, 40, 40]\n        levels_weight = F.softmax(levels_weight, dim=1) # [1, 3, 40, 40] \u2192 F.softmax \u2192 [1, 3, 40, 40]\n\n        fused_out_reduced = level_0_resized * levels_weight[:, 0:1, :, :] + \\\n                            level_1_resized * levels_weight[:, 1:2, :, :] + \\\n                            level_2_resized * levels_weight[:, 2:, :, :]\n        # [1, 512, 40, 40] * [1, 1, 40, 40] + [1, 512, 40, 40] * [1, 1, 40, 40] + [1, 512, 40, 40] * [1, 1, 40, 40] \u2192  [1, 512, 40, 40]\n        out = self.expand(fused_out_reduced) # [1, 512, 40, 40] \u2192 self.expand = (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \u2192 [1, 512, 40, 40]\n\n        if self.vis:# self.vis = False\n            return out, levels_weight, fused_out_reduced.sum(dim=1)\n        else:\n            return out\n\n\nif __name__ == \"__main__\":\n    # \u6a21\u62df\u7684\u8f93\u5165\u7279\u5f81\u56fe\uff0c\u6a21\u62df\u4e09\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe\uff0c\u4f8b\u5982\u6765\u81ea\u4e00\u4e2a\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u7684\u8f93\u51fa\n    level_0_feature = torch.randn(1, 1024, 20, 20)  # \u5927\u5c3a\u5bf8\u7279\u5f81\u56fe\n    level_1_feature = torch.randn(1, 512, 40, 40)   # \u4e2d\u5c3a\u5bf8\u7279\u5f81\u56fe\n    level_2_feature = torch.randn(1, 256, 80, 80)   # \u5c0f\u5c3a\u5bf8\u7279\u5f81\u56fe\n\n    # \u521d\u59cb\u5316ASFF\u6a21\u5757\uff0clevel\u8868\u793a\u5f53\u524dASFF\u6a21\u5757\u5904\u7406\u7684\u662f\u54ea\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\u5c42\uff0c\u8fd9\u91cc\u4ee5\u5904\u7406\u4e2d\u5c3a\u5bf8\u7279\u5f81\u5c42\u4e3a\u4f8b\n    # multiplier\u7528\u4e8e\u8c03\u6574\u901a\u9053\u6570\uff0crfb\u548cvis\u5206\u522b\u8868\u793a\u662f\u5426\u4f7f\u7528\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u8868\u793a\u548c\u662f\u5426\u53ef\u89c6\u5316\n    asff_module = ASFF(level=1, multiplier=1, rfb=False, vis=False)\n\n    # \u901a\u8fc7ASFF\u6a21\u5757\u4f20\u9012\u7279\u5f81\u56fe\n    output_feature = asff_module([level_2_feature, level_1_feature, level_0_feature])\n\n    # \u6253\u5370\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5f62\u72b6\uff0c\u786e\u4fddASFF\u6a21\u5757\u6b63\u5e38\u5de5\u4f5c\n    print(f\"Output feature shape: {output_feature.shape}\")\n\n# TODO \u8ba1\u7b97\u6d41\u7a0b\u56fe\u3001\u539f\u6587\u6846\u67b6\u56fe\u3001\u516c\u5f0f\u8868\u793a\n</code></pre>"},{"location":"Reproduction/1/#fpn","title":"\u221a FPN \u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc","text":"<p>Feature Pyramid Network\uff08FPN\uff09</p> <p></p> <p></p> <p></p> <p>\u8bb2\u89e3</p> <p></p> <p>2016 \u5e74\u8bba\u6587</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>\u4ee3\u7801\uff08\u5df2\u6ce8\u91ca\uff09\uff1a</p> Python<pre><code>import torch.nn as nn\nimport torch\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom torchvision.ops import nms\n# from retinanet.utils import BasicBlock, Bottleneck, BBoxTransform, ClipBoxes\n# from retinanet.anchors import Anchors\n# from retinanet import losses\n\nclass PyramidFeatures(nn.Module):\n    def __init__(self, C3_size, C4_size, C5_size, feature_size=256):\n        super(PyramidFeatures, self).__init__()\n\n        # upsample C5 to get P5 from the FPN paper\n        self.P5_1 = nn.Conv2d(C5_size, feature_size, kernel_size=1, stride=1, padding=0)\n        self.P5_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n        #\u5c06C5\u7684\u7279\u5f81\u56fe\u5c3a\u5bf8\u653e\u59272\u500d\u7528\u4e8e\u8ddfC4\u76f8\u52a0\n        self.P5_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1)\n\n        # add P5 elementwise to C4\n        self.P4_1 = nn.Conv2d(C4_size, feature_size, kernel_size=1, stride=1, padding=0)\n        self.P4_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n        self.P4_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1)\n\n        # add P4 elementwise to C3\n        self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=1, stride=1, padding=0)\n        self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1)\n\n        # \"P6 is obtained via a 3x3 stride-2 conv on C5\"\n        self.P6 = nn.Conv2d(C5_size, feature_size, kernel_size=3, stride=2, padding=1)\n\n        # \"P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6\"\n        self.P7_1 = nn.ReLU()\n        self.P7_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=2, padding=1)\n\n    def forward(self, inputs):\n        #\u6ce8\u610f\u7406\u89e3\u8fd9\u91cc\u7684inputs\uff0c\u5176\u8868\u793a\u7684\u662f\u4e00\u4e2a\u5217\u8868\n        C3, C4, C5 = inputs\n        # input = [torch.randn(1, 32, 640, 640), torch.randn(1, 64, 320, 320), torch.randn(1, 96, 160, 160)]\n        # \u7279\u70b9\uff1achannel\uff1a32\u219264\u219296\uff08\u65e0\u660e\u663e\u89c4\u5f8b\uff09\uff0cfeature_sizw\uff1a640*640\u2192320*320\u2192160*160\n\n        P5_x = self.P5_1(C5) #  conv \u5347\u7ef4\uff0c\u5c3a\u5bf8\u4e0d\u53d8 torch.Size([1, 96, 160, 160])\u2192 Conv2d \u2192torch.Size([1, 256, 160, 160]) /// (96, 256, kernel_size=(1, 1), stride=(1, 1))\n        P5_upsampled_x = self.P5_upsampled(P5_x) # \u4e0a\u91c7\u6837\uff0c\u7ef4\u5ea6\u4e0d\u53d8\uff0c\u5c3a\u5bf8\u7ffb\u500d [1, 256, 160, 160] \u2192 [1, 256, 320, 320] // Upsample(scale_factor=2.0, mode='nearest')\n        P5_x = self.P5_2(P5_x) # 311conv \u7ef4\u5ea6\u4e0d\u53d8\uff0c\u5c3a\u5bf8\u4e0d\u53d8 [1, 256, 160, 160] \u2192 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\u5c3a\u5bf8\u4e0d\u53d8\u5377\u79ef \u2192 [1, 256, 160, 160]\n\n        P4_x = self.P4_1(C4) #1x1conv \u5347\u7ef4 \u5c3a\u5bf8\u4e0d\u53d8  [1, 64, 320, 320] \u2192 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1)) \u2192 [1, 256, 320, 320]\n        P4_x = P5_upsampled_x + P4_x # [1, 256, 320, 320] + [1, 256, 320, 320] \u2192 [1, 256, 320, 320]\n        P4_upsampled_x = self.P4_upsampled(P4_x) # \u4e0a\u91c7\u6837\uff0c\u7ef4\u5ea6\u4e0d\u53d8\uff0c\u5c3a\u5bf8\u7ffb\u500d [1, 256, 320, 320] \u2192 Upsample(scale_factor=2.0, mode='nearest') \u2192 [1, 256, 640, 640]\n        P4_x = self.P4_2(P4_x) # 3x3 311conv \u5377\u79ef\u64cd\u4f5c\uff0c\u7ef4\u5ea6\u4e0d\u53d8\uff0c\u5c3a\u5bf8\u4e0d\u53d8\u3002[1, 256, 320, 320] \u2192 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) \u2192 torch.Size([1, 256, 320, 320]) ksp 311\u5377\u79ef\u6838\u4e3a 3 \u7684\u4e0d\u53d8\u5377\u79ef\n\n        P3_x = self.P3_1(C3) # \u5377\u79ef\u5347\u7ef4\uff0c\u5c3a\u5bf8\u4e0d\u53d8 [1, 32, 640, 640] Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1)) [1, 256, 640, 640]\n        P3_x = P3_x + P4_upsampled_x # add \u6df7\u5408 [1, 256, 640, 640] + [1, 256, 640, 640] --&gt; [1, 256, 640, 640]\n        P3_x = self.P3_2(P3_x) # 3x3conv  \u7ef4\u5ea6\u4e0d\u53d8\uff0c\u5c3a\u5bf8\u4e0d\u53d8 [1, 256, 640, 640] Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) [1, 256, 640, 640]\n\n        P6_x = self.P6(C5) # 3x3 conv(ksp=321) \u5347\u7ef4\uff0c\u7279\u5f81\u56fe\u5c3a\u5bf8\u51cf\u534a [1, 96, 160, 160] Conv2d(96, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) [1, 256, 80, 80]\n\n        P7_x = self.P7_1(P6_x) # \u975e\u7ebf\u6027\u53d8\u6362 ReLU\u6fc0\u6d3b\u5c42  [1, 256, 80, 80] ReLU() [1, 256, 80, 80]\n        P7_x = self.P7_2(P7_x) # 3x3conv(ksp=321)\u7ef4\u5ea6\u4e0d\u53d8\uff0c\u7279\u5f81\u56fe\u5c3a\u5bf8\u51cf\u534a [1, 256, 80, 80] Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)) [1, 256, 40, 40]\n\n        return [P3_x, P4_x, P5_x, P6_x, P7_x] # [P3_x [1, 256, 640, 640],P4_x [1, 256, 320, 320],P5_x [1, 256, 160, 160],P6_x [1, 256, 80, 80],P7_x [1, 256, 40, 40]]\n\n\nif __name__ == '__main__':\n    model = PyramidFeatures(32, 64, 96)\n    # print(model)\n    ##\u8fd9\u91cc\u5047\u8bbe\u8f93\u5165\u662f\u4e09\u5c42\u4e0d\u540c\u5c3a\u5bf8\u7684\u7279\u5f81\u56fe\uff0c\u8f93\u5165\u7684\u5f62\u72b6\u662f[batch_size, 256, height, width]\n    input = [torch.randn(1, 32, 640, 640), torch.randn(1, 64, 320, 320), torch.randn(1, 96, 160, 160)]\n    out = model(input)\n    print(out) # \u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5217\u8868\n</code></pre>"},{"location":"Reproduction/1/#panet","title":"PANet","text":"<p>PANet\uff08Path Aggregation Network\uff09</p> <p>ICCV 2019</p> <p>\u5c0f\u6837\u672c\u56fe\u50cf\u5206\u5272</p> <p>PANet: Few-Shot Image Semantic Segmentation with Prototype Alignment</p>"},{"location":"Reproduction/1/#_4","title":"\u7a7a\u95f4\u6ce8\u610f\u529b\u53ca\u53d8\u4f53","text":""},{"location":"Reproduction/1/#attention","title":"\u221aAttention","text":"<p>QKV \u662f X \u5728\u4e09\u79cd\u4e0d\u540c\u5411\u91cf\u7a7a\u95f4\u7684\u8868\u793a\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b</p> <p></p> <p>\u4e3a\u4ec0\u4e48 QK \u4e4b\u95f4\u505a\u4e58\u6cd5\uff1f</p> <ul> <li>\u5411\u91cf\u4e58\u6cd5\u53ef\u4ee5\u7528\u6765\u8861\u91cf\u5411\u91cf\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6</li> <li>\u5411\u91cfA\u548c\u5411\u91cfB\u7684\u70b9\u79ef\u7b49\u4e8e\u5411\u91cfA\u7684\u6a21\u4e58\u4e0a\u5411\u91cfB\u7684\u6a21\u4e58\u4e0a\u5939\u89d2\u7684\u4f59\u5f26\u503c</li> <li>\u5f53\u7ed9\u5b9a\u4e24\u4e2a\u786e\u5b9a\u5411\u91cf\u7684\u65f6\u5019\uff0c\u4e5f\u5c31\u662f\u5f53\u7ed9\u5b9a\u4e00\u4e2aA\u5411\u91cf\u548cB\u5411\u91cf\u7684\u65f6\u5019\uff1a</li> </ul> <p>\u5982\u679c\u5b83\u4eec\u4e4b\u95f4\u7684\u5939\u89d2\u8d8a\u5c0f\uff0c\u90a3 \\(cos\\theta\\) \u5c31\u8d8a\u5927\uff0c\u90a3\u4e48\u76f8\u5e94\u7684\u8fd9\u4e2a\u70b9\u79ef\u7684\u503c\u5c31\u8d8a\u5927</p> <p>\u90a3\u4e48\u5982\u679c\u5b83\u4eec\u7684\u5939\u89d2\u8d8a\u5927\uff0c\u8fd9\u4e2a \\(cos\\theta\\) \u8d8a\u5c0f\uff0c\u76f8\u5e94\u7684\u70b9\u51fb\u503c\u5c31\u8d8a\u5c0f</p> <ul> <li>\u4ece\u6574\u4f53\u4e0a\u6765\u770b\u5440\uff0c\u70b9\u79ef\u64cd\u4f5c\uff0c\u65e2\u6709\u957f\u5ea6\u4fe1\u606f\uff0c\u4e5f\u5c31\u662f\u6a21\u957f\uff0c\u4e5f\u6709\u65b9\u5411\u4fe1\u606f\uff0c\u5c31\u662f \\(cos\\theta\\)</li> </ul> <p>\u6240\u4ee5\uff0c\u7528\u5411\u91cf\u70b9\u79ef\u6765\u8861\u91cf\u5411\u91cf\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6</p> <p>\u4e3a\u4ec0\u4e48\u4e0d\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5462\uff1f </p> <p>\u8981\u8ba1\u7b97\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u5f97\u6c42\u5411\u91cfA\u548c\u5411\u91cfB\u7684\u6a21\uff0c\u8ba1\u7b97\u662f\u975e\u5e38\u8017\u65f6\u8017\u529b\u7684</p> <p>\u70b9\u79ef\u7684\u8bdd\u5c31\u975e\u5e38\u7684\u9ad8\u6548\uff0c\u53ea\u9700\u8981\u5bf9\u5e94\u5143\u7d20\u76f8\u4e58\u5e76\u6c42\u548c\u5373\u53ef</p> <p>\u4e3a\u4ec0\u4e48\u8981\u6267\u884c\u7f29\u653e\u64cd\u4f5c</p> <p>\u628a\u5411\u91cf\u7684\u7ef4\u5ea6\u8bbe\u7f6e\u4e3a64\u548c\u8bbe\u7f6e\u4e3a512</p> <p>\u5728\u8ba1\u7b97\u70b9\u79ef\u7684\u65f6\u5019\uff0c\u7ef4\u5ea6\u8d8a\u5927\u70b9\u79ef\u7684\u6570\u503c\u8d8a\u5927\uff0c\u6b64\u65f6\u5728\u8ba1\u7b97 softmax \u4e5f\u5c31\u662f e \u7684 x \u6b21\u65b9\u7684\u65f6\u5019\uff0c\u6307\u6570\u51fd\u6570\u7684\u6570\u503c\u4f1a\u53d8\u5927\uff0c\u4f1a\u9020\u6210\u68af\u5ea6\u4e0d\u7a33\u5b9a\uff0c\u6240\u4ee5\u9664\u4ee5\u4e00\u4e2a\u7f29\u653e\u56e0\u5b50\uff0c\u4e5f\u5c31\u662f\u6839\u53f7\u4e0b\\(D_k\\)\uff0c\u65e2\u53ef\u4ee5\u4fdd\u6301\u6570\u503c\u4e0a\u7684\u7a33\u5b9a\u6027\uff0c\u4e5f\u53ef\u4ee5\u4fdd\u6301\u68af\u5ea6\u4e0a\u7684\u7a33\u5b9a\u6027\u3002</p> <p>\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236</p> <p></p> <p>\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u662f\u7531\u591a\u4e2a\u81ea\u6ce8\u610f\u3001\u591a\u4e2a\u7f29\u653e\u70b9\u51fb\u6ce8\u610f\u529b\u6784\u6210\u7684\uff0c\u5927\u5bb6\u5404\u8ba1\u7b97\u5404\u7684\u4e92\u4e0d\u76f8\u5e72\uff0c\u6700\u540e\u53ea\u8981\u5c06\u6bcf\u4e2a\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e00\u4e2a\u8f93\u51fa\u8fdb\u884c\u4e00\u4e2a\u62fc\u63a5\uff0c\u518d\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\u878d\u5408\u5c31\u53ef\u4ee5\u4e86</p> <p>\u7b2c\u4e00\u4e2a\u70b9\uff0c\u5982\u4f55\u5212\u5206\u591a\u5934\uff1f</p> <p>\u6700\u7b80\u5355\u7684\u65b9\u5f0f\uff0c\u5f53\u7ed9\u5b9a\u4e00\u4e2aBCHW\u77e9\u9635\u7684\u65f6\u5019\uff0c\u5728\u8fd9\u4e2a\u901a\u9053C\u4e0a\u5e73\u5747\u5212\u5206\u4e3aM\u7ec4\uff0c\u6bcf\u7ec4\u901a\u9053\u6570\u91cf\u662fK\uff0cM\u4e58K\u7b49\u4e8eC</p> <p>\u4e3a\u4e86\u4fbf\u4e8e\u8ba1\u7b97\uff0c\u901a\u5e38\u4f1a\u5c06M\uff0c\u8fc1\u79fb\u5230\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u9762\uff0c\u7136\u540e\u8ba9\u5b83\u91cd\u65b0\u53d8\u4e3a\u4e00\u4e2a\u56db\u7ef4\u77e9\u9635\uff0c\u6bcf\u4e00\u7ec4\u7684\u8ba1\u7b97\uff0c\u90fd\u662f\u72ec\u7acb\u7684</p> <p>\u7b2c\u4e8c\u4e2a\u70b9\u5728\u8f93\u51fa\u7684\u65f6\u5019\uff0cconcat\u548c Linear\uff1f</p> <p>\u5728\u8fd9\u4e2a\u8f93\u51fa\u7684\u65f6\u5019\uff0c\u9996\u5148 \u591a\u4e2a\u5934\u7684\u8f93\u51fa\uff0c\u5728\u901a\u9053\u4e0a\u8fdb\u884c\u4e00\u4e2a\u62fc\u63a5\uff0c\u5e76\u4e14\u6062\u590d\u548c\u8f93\u5165\u76f8\u540c\u7684shape\uff0c\u7136\u540e\u518d\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42</p> <p>\u5173\u4e8e \u62fc\u63a5\u548c\u7ebf\u6027\u5c42 </p> <p>\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6bcf\u4e00\u4e2a\u5934\u90fd\u5728\u4e0d\u540c\u7684\u5411\u91cf\u7a7a\u95f4\u8fdb\u884c\u8ba1\u7b97\uff0c\u5728\u4e0d\u540c\u7684\u5411\u91cf\u7a7a\u95f4\u63d0\u53d6\u6709\u7528\u7684\u7279\u5f81\u3002</p> <p>\u4f8b\u5982\u8981\u63d0\u53d6\u4e00\u4e2a\u4eba\u7684\u7279\u5f81\uff0c\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u4ee5\u770b\u4f5c\u662f\u5728\u4e0d\u540c\u7684\u5934\uff0c\u5206\u522b\u5173\u6ce8\u8eab\u9ad8\u5e74\u9f84\u957f\u76f8\u5de5\u4f5c\u7b49\u7279\u5f81\uff0c\u6700\u540e\uff0c\u5c06\u8fd9\u4e9b\u4e0d\u540c\u5411\u91cf\u7a7a\u95f4\u7684\u7279\u5f81\u8fdb\u884c\u62fc\u63a5\uff0c\u7136\u540e\u518d\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\u8fdb\u884c\u878d\u5408\uff0c\u5f97\u5230\u66f4\u65b0\u540e\u7684\u7279\u5f81\u3002</p> <p>\u4ee3\u7801</p> Python<pre><code>import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import init\n\n\"Attention Is All You Need\"\n\nclass ScaledDotProductAttention(nn.Module):\n    '''\n    Scaled dot-product attention\n    '''\n\n    def __init__(self, d_model, d_k, d_v, h,dropout=.1):\n        '''\n        :param d_model: Output dimensionality of the model\n        :param d_k: Dimensionality of queries and keys\n        :param d_v: Dimensionality of values\n        :param h: Number of heads\n        '''\n        super(ScaledDotProductAttention, self).__init__()\n        self.fc_q = nn.Linear(d_model, h * d_k)\n        self.fc_k = nn.Linear(d_model, h * d_k)\n        self.fc_v = nn.Linear(d_model, h * d_v)\n        self.fc_o = nn.Linear(h * d_v, d_model)\n        self.dropout=nn.Dropout(dropout)\n\n        self.d_model = d_model\n        self.d_k = d_k\n        self.d_v = d_v\n        self.h = h\n\n        self.init_weights()\n\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, queries, keys, values, attention_mask=None, attention_weights=None):\n        '''\n        Computes\n        :param queries: Queries (b_s, nq, d_model)\n        :param keys: Keys (b_s, nk, d_model)\n        :param values: Values (b_s, nk, d_model)\n        :param attention_mask: Mask over attention values (b_s, h, nq, nk). True indicates masking.\n        :param attention_weights: Multiplicative weights for attention values (b_s, h, nq, nk).\n        :return:\n        '''\n        # (B, N, C), N=nq\n        B, nq = queries.shape[:2] # B=2\uff0cnq=50\n        nk = keys.shape[1] # nk=50\n\n        q = self.fc_q(queries).view(B, nq, self.h, self.d_k).permute(0, 2, 1, 3)  \n        # (B,N,C)--&gt;(B,nq,h*d_k)--&gt;(B,nq,h,d_k)--&gt;(B,h,nq,d_k)  h:\u6ce8\u610f\u529b\u5934\u7684\u4e2a\u6570, d_k:QK\u6bcf\u4e00\u4e2a\u6ce8\u610f\u529b\u5934\u7684\u901a\u9053\u6570\n        # [2, 50, 64]-&gt; self.fc_q=Linear(in_features=64, out_features=512, bias=True)-&gt;[2,50,512]-&gt;view-&gt;(2,50,8,64)-&gt;premute-&gt;(2,8,50,64)\n\n        k = self.fc_k(keys).view(B, nk, self.h, self.d_k).permute(0, 2, 3, 1)  \n        #  (B,N,C)--&gt;(B,nq,h*d_k)--&gt;(B,nk,h,d_k)--&gt;(B,h,d_k,nk)\n        # [2, 50, 64]-&gt;Linear(in_features=64, out_features=512, bias=True)-&gt;[2,50,512]-&gt;view-&gt;[2,50,8,64]-&gt;permute-&gt;[2,8,64,50]\n\n        v = self.fc_v(values).view(B, nk, self.h, self.d_v).permute(0, 2, 1, 3)  \n        # (B,N,C)--&gt;(B,nk,h*d_v)--&gt;(B,nk,h,d_v)--&gt;(B,h,nk,d_v)      \n        # [2, 50, 64]-&gt;Linear(in_features=64, out_features=512, bias=True)-&gt;[2,50,512]-&gt;view-&gt;[2,50,8,64]-&gt;[2,8,50,64]\n\n        att = torch.matmul(q, k) / np.sqrt(self.d_k)  # (B, h, nq, nk)\n        # q (2,8,50,64) k [2,8,64,50] -&gt; torch.matmul -&gt; [2, 8, 50, 50]\n\n        # \u5982\u679c\u9700\u8981\u4e3a\u6ce8\u610f\u529b\u77e9\u9635\u989d\u5916\u6dfb\u52a0\u4e00\u4e2a\u53c2\u6570\u77e9\u9635,\u90a3\u4e48\u6267\u884c\u9010\u70b9\u76f8\u4e58\u5373\u53ef\n        if attention_weights is not None: # attention_weights = None\n            att = att * attention_weights\n        # \u5982\u679c\u9700\u8981\u4e3a\u6ce8\u610f\u529b\u77e9\u9635\u6dfb\u52a0mask,\u90a3\u4e48\u5728\u5bf9\u5e94\u9700\u8981mask\u7684\u5730\u65b9\u586b\u5145\u4e3a\u8d1f\u65e0\u7a77\u6570\u503c,\u8fd9\u6837\u5728\u8ba1\u7b97softmax\u7684\u65f6\u5019,\u8d1f\u65e0\u7a77\u7684\u5f52\u4e00\u5316\u5f97\u5206\u5c06\u8d8b\u8fd1\u4e8e0\n        if attention_mask is not None: # attention_mask = None\n            att = att.masked_fill(attention_mask, -np.inf)\n        att = torch.softmax(att, -1) \n        # [2, 8, 50, 50] -&gt; torch.softmax -&gt; [2, 8, 50, 50]\n        # attn n_q d_q \u00d7 d_k n_k = n_q \u00d7 n_k \u5728 n_k \u5217\u8fdb\u884csoftmax\n\n        att=self.dropout(att)\n\n\n        out = torch.matmul(att, v).permute(0, 2, 1, 3).contiguous().view(B, nq, self.h * self.d_v)  \n        # (B,h,nq,nk)@(B,h,nk,d_v)=(B,h,nq,d_v)--&gt;(B,nq,h,d_v)--&gt;(B,nq,h*d_v)\n        # [2, 8, 50, 50] @ [2, 8, 50, 64] -&gt; [2, 8, 50, 64] -&gt; permute -&gt; [2,50,8,64] -&gt; contiguous -&gt; view -&gt; [2,50,512]\n        # \u8fd9\u91cc\u6709\u591a\u5934\u6ce8\u610f\u529b\u9700\u8981\u6ce8\u610f\u7684\u70b9\uff1a\u4e3a\u4ec0\u4e48\u8981\u8fdb\u884c concat \u548c Linear \u56e0\u4e3a\u6bcf\u4e2a\u5934\u5206\u522b\u5b66\u4e60\u4eba\u7684\u4e00\u4e2a\u7279\u5f81\uff0c\u6700\u540e\u7684\u6ce8\u610f\u529b\u662f\u9700\u8981\u4ea4\u4e92\u7684\n\n        out = self.fc_o(out)  # (B,nq,C) [2, 50, 512]-&gt;Linear(in_features=512, out_features=64, bias=True) -&gt; [2, 50, 64]\n        return out\n\n\nif __name__ == '__main__':\n    # (B, N, C)\n    input=torch.randn(2,50,64)\n    Model = ScaledDotProductAttention(d_model=64, d_k=64, d_v=64, h=8)\n    output=Model(input,input,input)\n    print(output.shape)\n</code></pre>"},{"location":"Reproduction/1/#attention_1","title":"Attention \u62d3\u5c55","text":""},{"location":"Reproduction/1/#cot","title":"\u4e0a\u4e0b\u6587 CoT","text":"<ul> <li>\u9996\u5148 query \u5e76\u6ca1\u6709\u7ecf\u8fc7 1x1 \u7684 conv \u53d8\u6362\uff08\u4e5f\u5c31\u662f\u5bf9\u5e94\u5e8f\u5217\u7684 linear\uff09\uff0c\u800c\u662f\u76f4\u63a5 x = query</li> <li>key \u662f\u805a\u5408\u4e86 3 x 3 \u7a97\u53e3\u8303\u56f4\u5185\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f</li> <li>query \u548c key \u5728\u901a\u9053\u4e0a\u8fdb\u884c\u62fc\u63a5\uff0c\u7ecf\u8fc7\u4e24\u4e2a 1x1 \u7684\u5377\u79ef\uff0c\u5f97\u5230\u6743\u91cd\u77e9\u9635</li> </ul> <p>\u96be\u70b9\uff1a\u600e\u4e48\u7406\u89e3 query \u548c key \u5728\u901a\u9053\u4e0a\u8fdb\u884c\u62fc\u63a5\uff0c\u7ecf\u8fc7\u4e24\u4e2a 1x1 \u7684\u5377\u79ef\uff0c\u5f97\u5230\u6743\u91cd\u77e9\u9635\uff1f </p> <p>\u4e00\u4e2a\u62fc\u63a5\u540e\u7684\u5411\u91cf\uff0c\u5b83\u600e\u4e48\u5c31\u80fd\u53d8\u6210\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\uff1f</p> <p></p> Python<pre><code>import numpy as np\nimport torch\nfrom torch import flatten, nn\nfrom torch.nn import init\nfrom torch.nn.modules.activation import ReLU\nfrom torch.nn.modules.batchnorm import BatchNorm2d\nfrom torch.nn import functional as F\n\n\"Contextual Transformer Networks for Visual Recognition\"\n\nclass CoTAttention(nn.Module):\n\n    def __init__(self, dim=512,kernel_size=3):\n        super().__init__()\n        self.dim=dim\n        self.kernel_size=kernel_size\n\n        self.key_embed=nn.Sequential(\n            nn.Conv2d(dim,dim,kernel_size=kernel_size,padding=kernel_size//2,groups=4,bias=False),\n            nn.BatchNorm2d(dim),\n            nn.ReLU()\n        )\n        self.value_embed=nn.Sequential(\n            nn.Conv2d(dim,dim,1,bias=False),\n            nn.BatchNorm2d(dim)\n        )\n\n        factor=4\n        self.attention_embed=nn.Sequential(\n            nn.Conv2d(2*dim,2*dim//factor,1,bias=False),\n            nn.BatchNorm2d(2*dim//factor),\n            nn.ReLU(),\n            nn.Conv2d(2*dim//factor,kernel_size*kernel_size*dim,1)\n        )\n\n\n    def forward(self, x):\n        # \u9664\u4e86\u8981\u660e\u767d\u5f62\u72b6\u53d8\u5316\uff0c\u8fd8\u8981\u660e\u767d\u4e3a\u4ec0\u4e48\u505a\u8fd9\u4e00\u6b65\n        bs,c,h,w=x.shape # [1, 512, 7, 7]\n\n        k1=self.key_embed(x)  \n        # 311\u5206\u7ec4\u5377\u79ef\uff0c\u805a\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5f97\u5230\u9759\u6001\u4e0a\u4e0b\u6587\u8868\u793a [1, 512, 7, 7] Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False) [1, 512, 7, 7]\n        # \u7f16\u7801\u9759\u6001\u4e0a\u4e0b\u6587\u4fe1\u606fkey,\u8868\u793a\u4e3ak1: (B,C,H,W) --&gt; (B,C,H,W)\n\n        v=self.value_embed(x).view(bs,c,-1)  \n        # 1\u00d71 \u5377\u79ef\u5f97\u5230 value \u5e76 reshape [1, 512, 7, 7]  Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) [1, 512, 7, 7] .view(bs,c,-1) [1,512,49]\n        # \u7f16\u7801value\u77e9\u9635: (B,C,H,W) --&gt; (B,C,H,W) --&gt; (B,C,HW)\n\n        y=torch.cat([k1,x],dim=1)  \n        # [1, 512, 7, 7] [1, 512, 7, 7] torch.cat [1,1024,7,7]\n        # \u5c06\u4e0a\u4e0b\u6587\u4fe1\u606fkey\u548cquery\u5728\u901a\u9053\u4e0a\u8fdb\u884c\u62fc\u63a5: (B,2C,H,W) [\u4eba\u5bb6\u7684\u6ce8\u91ca\u771f\u7684\u5199\u5f97\u597d] x=query \u800c\u6ca1\u6709\u8fdb\u884c\u53d8\u6362\n\n        att=self.attention_embed(y) \n        # \u4e24\u4e2a\u8fde\u7eed\u7684 1x1 \u5377\u79ef\uff0c\u5f97\u5230 \u6bcf\u4e2a \u5bf9\u4e8e\u5750\u6807(i,j) \u7684\u4f4d\u7f6e\uff0c\u5b83\u7684\u7b2c Ch \u4e2a\u6ce8\u610f\u2f12\u5934\u7684\u7684\u5c40\u90e8\u6ce8\u610f\u2f12\u77e9\u9635\u4e3a 3x3\n        # [1,1024,7,7]-&gt; 1x1conv-&gt;[1,256,7,7]-&gt;1x1conv-&gt;[1,4608=512\uff08\u5934\u7684\u4e2a\u6570\uff09*3*3,7,7]\n        # \u901a\u8fc7\u4e24\u4e2a\u8fde\u7eed\u76841\u00d71\u5377\u79ef\u64cd\u4f5c: (B,2C,H,W)--&gt;(B,D,H,W)--&gt;(B,C\u00d7k\u00d7k,H,W)   4608/512 = 9\n        # \u8fd9\u91cc\u7684C:\u628a\u5b83\u770b\u4f5c\u662f\u6ce8\u610f\u529b\u5934\u7684\u4e2a\u6570\n        # \u4e0d\u7ba1\u600e\u4e48\u60f3 \u8fd9\u91cc\u628a C\u00d7k\u00d7k\u5168\u90e8\u653e\u5230 \u7b2c 1 \u7ef4\u90fd\u662f\u60f3\u4e0d\u901a\u7684\uff0cHW \u50cf\u7d20\u7684\u8bed\u4e49\u4fe1\u606f\u88ab\u5d4c\u5165\u4e86 512*3*3 \u7684\u8fd9\u4e48\u591a\u7ef4\u4e0a...(9\u4e2a 512 \u8fd9\u4e48\u7406\u89e3\uff0c\u4f3c\u61c2\u975e\u61c2)\n\n        att=att.reshape(bs,c,self.kernel_size*self.kernel_size,h,w) \n        # \u4e2d\u6587\u8bf4\u660e\u76ee\u7684?\uff08\u6bcf\u4e2a\u5934\u90fd\u5b66\u5230\u4e86 3x3 \u5c0f\u683c\u5b50\u7684\u5c40\u90e8\u6ce8\u610f\u529b\uff0c\u4e3a\u540e\u9762\u53d6\u5e73\u5747\u805a\u5408 \u6ce8\u610f\u529b\u503c\u505a\u51c6\u5907\uff09\n        #  [1,4608,7,7] -&gt; reshape -&gt; [1,512,9,7,7] \n        # (B,C\u00d7k\u00d7k,H,W) --&gt; (B,C,k\u00d7k,H,W)\n\n        # (B,C,k\u00d7k,H,W) --&gt; (B,C,H,W) --&gt; (B,C,HW)   \n        # \u6bcf\u4e2a\u5750\u6807\u70b9\u5728\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u7684\u7684\u6ce8\u610f\u529b\u77e9\u9635\u4e3a\uff1ak\u00d7k, \u7136\u540e\u5bf9\u7a97\u53e3\u5185\u7684\u503c\u53d6\u5e73\u5747, \u56e0\u6b64: (k\u00d7k,HW)-&gt; (1,HW), \u6bcf\u4e2a\u5750\u6807\u70b9\u53ea\u6709\u4e00\u4e2a\u503c \uff08\u5ffd\u7565BC\u7ef4\u5ea6\uff09\n        # [1,512,9,7,7] -&gt; mean -&gt; [1,512,7,7]-&gt; view -&gt; [1,512,49]\n        att=att.mean(2,keepdim=False).view(bs,c,-1)\n\n        # \u5bf9N=HW\u4e2a\u5750\u6807\u70b9(\u867d\u7136\u6bcf\u4e2a\u5750\u6807\u70b9\u73b0\u5728\u53ea\u6709\u4e00\u4e2a\u503c,\u4f46\u662f\u662f\u901a\u8fc7k\u00d7k\u7a97\u53e3\u5185\u7684\u503c\u5171\u540c\u83b7\u5f97\u7684,\u5229\u7528\u4e86\u4e0a\u4e0b\u6587\u4fe1\u606f),\u4f7f\u7528softmax\u6c42\u6743\u91cd, \u7136\u540e\u4f7f\u7528\u6743\u91cd\u4e0eValue\u76f8\u4e58\uff0c\u751f\u6210\u52a8\u6001\u4e0a\u4e0b\u6587\u8868\u793a\n        k2=F.softmax(att,dim=-1)*v  # [1, 512, 49] * [1, 512, 49] -&gt; [1, 512, 49]\n        # \u5f97\u5230\u52a8\u6001\u4e0a\u4e0b\u6587\u8868\u793ak2: (B,C,HW) * (B,C,HW) =  (B,C,HW)    \u6743\u91cd*Value \u8fd9\u91cc\u7684 * \u8868\u793a element-wise \u9010\u5143\u7d20\u76f8\u4e58\n        k2=k2.view(bs,c,h,w) # [1, 512, 49] -&gt; [1,512,7,7]\n\n        return k1+k2 # \u878d\u5408\u9759\u6001\u4e0a\u4e0b\u6587\u4fe1\u606fk1 \u548c \u52a8\u6001\u4e0a\u4e0b\u6587\u4fe1\u606fk2 [1, 512, 7, 7] + [1, 512, 7, 7]\n\n\n# \u7b80\u5355\u6765\u8bb2, 43-49\u884c\u4ee3\u7801\u7684\u542b\u4e49\u5c31\u662f: \u878d\u5408\u9759\u6001\u4e0a\u4e0b\u6587\u4fe1\u606fk1\u548cquery\u4fe1\u606f,\u6765\u751f\u6210\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u6743\u91cd\u3002 \u8fd9\u4e2a\u6743\u91cd\u662f\u57fa\u4e8e\u4e0a\u4e0b\u6587\u4fe1\u606f\u83b7\u5f97\u7684,\u6240\u4ee5\u662f\u6709\u6548\u7684\u3002\nif __name__ == '__main__':\n    # (B,C,H,W)\n    input=torch.randn(1,512,7,7)\n    Model = CoTAttention(dim=512,kernel_size=3)\n    output=Model(input)\n    print(output.shape) # [1, 512, 7, 7]\n</code></pre>"},{"location":"Reproduction/1/#temporal-conv","title":"Temporal Conv \u95e8\u63a7\u673a\u5236","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport math\n\n\"Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks\"\n\n\nclass dilated_inception(nn.Module):\n    def __init__(self, cin, cout, dilation_factor,seq_len):\n        super(dilated_inception, self).__init__()\n        self.tconv = nn.ModuleList()\n        self.padding=0\n        self.seq_len = seq_len\n        self.kernel_set = [2,3,6,7]\n        # \u5c06\u901a\u9053\u5e73\u5747\u5206\u4e3aN\u7ec4. N\u662f\u5377\u79ef\u5c42\u7684\u4e2a\u6570\n        cout = int(cout/len(self.kernel_set))\n        # k\u4e2a1D\u56e0\u679c\u81a8\u80c0\u5377\u79ef\n        for kern in self.kernel_set:\n            self.tconv.append(nn.Conv2d(cin,cout,(1,kern),dilation=(1,dilation_factor)))\n\n        # \u5982\u679cdilation_factor=1, out=input-k+1\n        # \u5982\u679cdilation_factor&gt;=1, out=[input-d*(k-1)+2*p-1]/stride+1  d:dilation_factor; p:padding  \u8ba1\u7b97\u516c\u5f0f\u89c1pytorch\u5b98\u7f51\uff1ahttps://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d\n        # \u8fd9\u91cc\u662f\u4e24\u5c42\u5168\u8fde\u63a5,\u5148\u6620\u5c04\u5230\u9ad8\u7ef4,\u518d\u6620\u5c04\u56de\u4e0e\u8f93\u5165\u76f8\u540c\u7684\u65f6\u95f4\u7ef4\u6570,\u589e\u52a0\u8868\u8fbe\u80fd\u529b\n        self.out = nn.Sequential(\n            nn.Linear(self.seq_len-dilation_factor*(self.kernel_set[-1]-1)+self.padding*2-1+1, cin),\n            nn.ReLU(),\n            nn.Linear(cin, self.seq_len)\n        )\n    def forward(self,input):\n        # input: (B, C, N, T)\n\n        x = []\n        for i in range(len(self.kernel_set)):\n            x.append(self.tconv[i](input)) # \u6267\u884ck==4\u4e2a1D\u56e0\u679c\u81a8\u80c0\u5377\u79ef\u64cd\u4f5c: 1th:(B,C,N,T)--&gt;(B,C/4,N,T1); 2th:(B,C,N,T)--&gt;(B,C/4,N,T2); 3th:(B,C,N,T)--&gt;(B,C/4,N,T3); 4th:(B,C,N,T)--&gt;(B,C/4,N,T4);\n        for i in range(len(self.kernel_set)):\n            x[i] = x[i][...,-x[-1].size(3):]  #\u4ee5\u65f6\u95f4\u7ef4\u5ea6\u6700\u5c11\u7684\u7279\u5f81\u4e3a\u6807\u51c6, \u622a\u53d6\u5176\u4ed6\u7279\u5f81\u7684\u65f6\u95f4\u7ef4\u6570\u4ee5\u4fdd\u6301\u4e00\u81f4, \u7531\u4e8e\u5377\u79ef\u6838\u9010\u6e10\u589e\u5927,\u56e0\u6b64T4\u6700\u5c0f: x=[(B,C/4,N,T4),(B,C/4,N,T4),(B,C/4,N,T4),(B,C/4,N,T4)]\n\n        x = torch.cat(x,dim=1) # \u5c06k==4\u4e2a1D\u56e0\u679c\u81a8\u80c0\u5377\u79ef\u5c42\u7684\u8f93\u51fa\u5728\u901a\u9053\u4e0a\u8fdb\u884c\u62fc\u63a5: (B,C,N,T4)\n        x = self.out(x) # \u4e24\u5c42\u7ebf\u6027\u5c42\u6620\u5c04,\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u5148\u5347\u7ef4,\u540e\u964d\u7ef4: (B,C,N,T4)--&gt;(B,C,N,C)--&gt;(B,C,N,T)\n        return x\n\n\nclass temporal_conv(nn.Module):\n    def __init__(self, cin, cout, dilation_factor,seq_len):\n        super(temporal_conv, self).__init__()\n\n        self.filter_convs = dilated_inception(cin=cin, cout=cout, dilation_factor=dilation_factor, seq_len=seq_len)\n        self.gated_convs = dilated_inception(cin=cin, cout=cout, dilation_factor=dilation_factor, seq_len=seq_len)\n\n    def forward(self, X):\n        # X:(B,C,N,T)\n        filter = self.filter_convs(X)  # \u6267\u884c\u5de6\u8fb9\u7684DIL\u5c42: (B,C,N,T)--&gt;(B,C,N,T)\n        filter = torch.tanh(filter)  # \u5de6\u8fb9\u7684DIL\u5c42\u540e\u63a5\u4e00\u4e2atanh\u6fc0\u6d3b\u51fd\u6570,\u751f\u6210\u8f93\u51fa:(B,C,N,T)--&gt;(B,C,N,T)\n        gate = self.gated_convs(X) # \u6267\u884c\u53f3\u8fb9\u7684DIL\u5c42: (B,C,N,T)--&gt;(B,C,N,T)\n        gate = torch.sigmoid(gate) # \u53f3\u8fb9\u7684DIL\u5c42\u540e\u63a5\u4e00\u4e2asigmoid\u95e8\u63a7\u51fd\u6570,\u751f\u6210\u6743\u91cd\u8868\u793a:(B,C,N,T)--&gt;(B,C,N,T)\n        out = filter * gate  # \u6267\u884c\u9010\u5143\u7d20\u4e58\u6cd5: (B,C,N,T) * (B,C,N,T) = (B,C,N,T)\n        return out\n\n\n\nif __name__ == '__main__':\n    # (B,C,N,T)  N:\u5e8f\u5217\u7684\u4e2a\u6570  T:\u5e8f\u5217\u7684\u957f\u5ea6  C:\u901a\u9053\u6570  B: batchsize\n    X = torch.randn(1, 32, 1, 24)\n    Model = temporal_conv(cin=32, cout=32, dilation_factor=1,seq_len=24)\n    out = Model(X)\n    print(out.shape)\n</code></pre> Text Only<pre><code>\u8f93\u5165 X: (1,32,1,24)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 filter_convs \u2502         \u2502 gated_convs \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502                       \u2502\n               \u2193                       \u2193\n     filter: (1,32,1,24)       gate: (1,32,1,24)\n               \u2502                       \u2502\n               \u2193                       \u2193\n       tanh\u6fc0\u6d3b\u51fd\u6570              sigmoid\u51fd\u6570\n               \u2502                       \u2502\n               \u2193                       \u2193\n     filter: (1,32,1,24)       gate: (1,32,1,24)\n               \u2502                       \u2502\n               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2193\n                 \u9010\u5143\u7d20\u4e58\u6cd5 (Hadamard\u79ef)\n                           \u2193\n                    out: (1,32,1,24)\n</code></pre>"},{"location":"Reproduction/1/#dilated_inception","title":"dilated_inception","text":"Text Only<pre><code>\u8f93\u5165 input: (1,32,1,24)\n         |\n         \u2193\n    \u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2510\n    \u2193    \u2193    \u2193    \u2193    \u2193\n kernel=2  kernel=3  kernel=6  kernel=7\n dilation=1 dilation=1 dilation=1 dilation=1\n    \u2193    \u2193    \u2193    \u2193    \u2193\n (1,8,1,23) (1,8,1,22) (1,8,1,19) (1,8,1,18)\n    |         |         |         |\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 |\n                 \u2193\n     \u622a\u53d6\u5230\u6700\u77ed\u7684\u957f\u5ea6 T4=18\n    \u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2510\n    \u2193    \u2193    \u2193    \u2193    \u2193\n (1,8,1,18) (1,8,1,18) (1,8,1,18) (1,8,1,18)\n    |         |         |         |\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2193\n      \u901a\u9053\u7ef4\u5ea6\u62fc\u63a5 dim=1\n              \u2193\n         (1,32,1,18)\n              |\n              \u2193\n     \u7ebf\u6027\u5c421: 18 \u2192 32\n              \u2193\n          ReLU\u6fc0\u6d3b\n              \u2193\n     \u7ebf\u6027\u5c422: 32 \u2192 24\n              \u2193\n         (1,32,1,24)\n</code></pre> <p>\u590d\u8ff0\uff1a\u65f6\u7a7a\u5377\u79ef Inception \u6a21\u5757</p>"},{"location":"Reproduction/10_UNetTSF/","title":"UNetTSF","text":""},{"location":"Reproduction/10_UNetTSF/#unettsf","title":"UNetTSF","text":"2025-04-16 23:10:442025-09-28 12:54:03 <p> \u7ea6 428 \u4e2a\u5b57  70 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>\u5f00\u59cb\u90e8\u5206\u89c1 2025-04-16 Wednesday \uff0cokay\uff0c\u7ee7\u7eed</p> <p><code>block_model</code></p> <p>```python\u00a0 if self.individual:     self.Linear_channel = nn.ModuleList()</p> Text Only<pre><code>for i in range(self.channels):\n    self.Linear_channel.append(nn.Linear(self.input_len, self.out_len))\n</code></pre> <p>else:     self.Linear_channel = nn.Linear(self.input_len, self.out_len) self.ln = nn.LayerNorm(out_len) self.relu = nn.ReLU(inplace=True) <code>\u901a\u8fc7 individual \u63a7\u5236\u521d\u59cb\u5316\u51e0\u4e2a\u7ebf\u6027\u5c42\uff0c\u5224\u65ad\u662f\u901a\u9053\u72ec\u7acb\u8fd8\u662f\u5171\u4eab\u53c2\u6570\uff0c\u8fd9\u91cc\u5c31\u5168\u662f\u5e93\u51fd\u6570\uff0c\u4e0d\u7528\u518d\u6252\u4e86\u3002  \u5176\u5b9e\u539f\u59cb block \u5e94\u8be5\u662f 96\u2192720 \u8fd9\u6837\uff0c\u8fd9\u91cc\uff08\u597d\u50cf\uff09\u6709\u70b9\u95ee\u9898\u3002  \u67e5\u4e86\u4e00\u4e0b\uff1a`self.Linear_channel`</code>python Linear(in_features=96, out_features=192, bias=True) ```</p> <p>emm\uff0c\u597d\u50cf\u662f\u4e00\u6837\u7684\u3002\u770b\u4e0b\u9762\uff0c\u8fdb\u884c\u8d8b\u52bf\u5206\u89e3\uff1a</p> Python<pre><code>trend, cyclic = self.decomposer(base_output)\n</code></pre> <p>\u4e0d\u770b\u521d\u59cb\u5316\u4e86\uff0c\u76f4\u63a5\u67e5\u8fd9\u4e2a\u4e1c\u897f\u662f\u5565\uff1a</p> Text Only<pre><code>self.decomposer\nTrendCyclicDecomposition(\n  (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(12,))\n)\n</code></pre> <ul> <li>padding &amp; kernel size\uff0c\u5f88\u660e\u663e\u5c31\u662f\u4e00\u4e2a \u79fb\u52a8\u5e73\u5747\u3002</li> <li>\u7b2c\u4e00\u4e2a\u8fd4\u56de\u503c\uff1a\u8d8b\u52bf\u9879\uff0c\u7b2c\u4e8c\u4e2a\u8fd4\u56de\u503c\uff1a\u6b8b\u5dee\u9879</li> <li>\u63a5\u4e0b\u6765 \u8fdb\u5165 forward</li> </ul> Python<pre><code>    def forward(self, x):\n        \"\"\"\n        \u8f93\u5165 x: [B, C, L]\n        \u8f93\u51fa: trend [B, C, L], cyclic [B, C, L]\n        \"\"\"\n        # \u63d0\u53d6\u8d8b\u52bf\u9879(\u901a\u8fc7\u79fb\u52a8\u5e73\u5747)\n        trend = self.avg(x)\n\n        # \u8ba1\u7b97\u5468\u671f\u9879(\u539f\u59cb\u4fe1\u53f7\u51cf\u53bb\u8d8b\u52bf)\n        cyclic = x - trend\n\n        return trend, cyclic\n</code></pre> <p>\u8fd9\u91cc\u7684 forward \u4e5f\u633a\u7b80\u5355\u7684</p> <p>\u4e00\u4e2a self.avg\uff0c\u53c2\u6570</p> Python<pre><code>AvgPool1d(kernel_size=(25,), stride=(1,), padding=(12,))\n</code></pre> <p>\u4e5f\u6ca1\u5565\u597d\u8bf4\u7684\uff0c\u4e0a\u9762\u67e5 <code>self.decomposer</code> \u4e5f\u80fd\u770b\u5230\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f\u5bf9 <code>AvgPool1d</code> \u7684\u5b9e\u4f8b\u5316\u3002</p> <ul> <li>\u5230\u4e86\u5e93\u51fd\u6570\u4e0d\u7528\u6b65\u8fdb\u4e86</li> <li>\u4e0b\u9762\u5c31\u662f \u539f\u59cb\u5e8f\u5217 \u51cf\u53bb \u8d8b\u52bf\u9879 \u5f97\u5230\u5b63\u8282\u6027\u6210\u5206\uff0c\u8fd4\u56de\u3002</li> </ul> Python<pre><code>trend, cyclic = self.decomposer(base_output)\n</code></pre> <p>\u8f93\u5165\u8f93\u51fa\uff0c\u5f62\u72b6\u90fd\u662f\uff1aBCL\uff08\u901a\u9053\u4f18\u5148\u7684\u683c\u5f0f\uff09</p> Python<pre><code>freq_bands = self.freq_decomposer(cyclic)\n</code></pre> <p>\u63a5\u4e0b\u6765\u5904\u7406\uff0c\u9ad8\u9891\u6210\u5206\uff0c\u4e5f\u5c31\u662f\u5b63\u8282\u6027\u6210\u5206\u3002</p> <p>\u67e5\u4e00\u4e0b\uff1a<code>self.freq_decomposer</code>  \u8fd9\u662f\u5565\u4e1c\u897f</p> Python<pre><code>FrequencyDecomposer(\n  (wavelet_decomposers): ModuleList(\n    (0): SimpleWaveletDecomposition(\n      (low_pass): Sequential(\n        (0): ReflectionPad1d((2, 1))\n        (1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n        (2): GELU()\n        (3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      )\n      (high_pass): Sequential(\n        (0): ReflectionPad1d((2, 1))\n        (1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n        (2): GELU()\n        (3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      )\n    )\n    (1): SimpleWaveletDecomposition(\n      (low_pass): Sequential(\n        (0): ReflectionPad1d((2, 1))\n        (1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n        (2): GELU()\n        (3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      )\n      (high_pass): Sequential(\n        (0): ReflectionPad1d((2, 1))\n        (1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n        (2): GELU()\n        (3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      )\n    )\n  )\n)\n</code></pre> <p>\u5185\u5bb9\u6709\u70b9\u591a\uff0c\u4f46\u5df2\u7ecf\u597d\u591a\u4e86\uff0c\u4e00\u70b9\u70b9\u6252\u62c9\u628a</p> <ul> <li>self.freq_decomposer \u662f\u5b9e\u4f8b\u5316\u7684 FrequencyDecomposer \u8fd9\u4e2a\u7c7b</li> <li> <p>FrequencyDecomposer \u8fd9\u4e2a\u7c7b\u91cc\u9762\u7b2c\u4e00\u4e2a\u662f <code>(wavelet_decomposers)</code></p> </li> <li> <p>(wavelet_decomposers)\u8fd9\u4e2a\u4e1c\u897f\u662f ModuleList \u7684\u5b9e\u4f8b\u5316</p> </li> <li>ModuleList\u7c7b\u91cc\u9762\u662f\u4e24\u4e2a  (0): SimpleWaveletDecomposition  \u548c (1): SimpleWaveletDecomposition \u65e2\u7136\u5982\u6b64\uff0c\u53ea\u770b\u4e00\u4e2a</li> <li>(0): SimpleWaveletDecomposition\u662f (low_pass) \u548c (high_pass) \u7684\u5b9e\u4f8b\u5316</li> <li>(low_pass) \u548c (high_pass) \u5206\u522b\u662f\u4e24\u4e2a Sequential \u7684\u5b9e\u4f8b\u5316</li> <li>\u5230\u5e93\u51fd\u6570\u4e86\uff0c\u4e0d\u7528\u6252\u4e86</li> <li>\u5982\u679c\u4ed4\u7ec6\u770b\u7684\u8bdd\uff0c(low_pass) \u548c (high_pass)  \u4f4e\u901a\u548c\u9ad8\u901a\u4e24\u4e2a \u5185\u90e8\u662f\u4e00\u6837\u7684</li> <li>\u62ff\u51fa\u6765\u770b\u770b</li> </ul> Python<pre><code>(low_pass): Sequential(\n(0): ReflectionPad1d((2, 1))\n(1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n(2): GELU()\n(3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n)\n(high_pass): Sequential(\n(0): ReflectionPad1d((2, 1))\n(1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n(2): GELU()\n(3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n)\n</code></pre> <ul> <li>\u753b\u4e2a\u56fe\u628a\uff1a</li> </ul> <p></p> <p>\u8fd8\u597d\u4e86\uff0c\u6a59\u8272\u8868\u793a\u662f\u4e00\u6837\u7684\u4e1c\u897f\u3002</p>"},{"location":"Reproduction/2/","title":"\u7279\u5f81\u878d\u5408\u65b9\u5f0f","text":""},{"location":"Reproduction/2/#_1","title":"\u7279\u5f81\u878d\u5408\u65b9\u5f0f","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 104 \u4e2a\u5b57  594 \u884c\u4ee3\u7801  9 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 8 \u5206\u949f</p> <p>\u589e\uff1aattention\uff0cskip connection</p> <p>\u5220</p> <p>\u6539\uff1aconv\uff0cPooling\uff08up\uff0cdown\uff09</p> <p>\u67e5\uff1a\u67e5\u770b\u522b\u4eba\u7684\u8fde\u63a5\u65b9\u5f0f</p>"},{"location":"Reproduction/2/#_2","title":"\u95e8\u63a7\u878d\u5408\u673a\u5236","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n# DONE\nclass gatedFusion(nn.Module):\n\n    def __init__(self, dim):\n        super(gatedFusion, self).__init__()\n        self.fc1 = nn.Linear(dim, dim, bias=True)\n        self.fc2 = nn.Linear(dim, dim, bias=True)\n\n    def forward(self, x1, x2):\n        print(\"x1.shape\",x1.shape)\n        print(\"x2.shape\",x2.shape)\n\n        x11 = self.fc1(x1)\n        print(\"x11.shape\",x11.shape)\n\n        x22 = self.fc2(x2)\n        print(\"x22.shape\",x22.shape)\n\n        # \u901a\u8fc7\u95e8\u63a7\u5355\u5143\u751f\u6210\u6743\u91cd\u8868\u793a\n        z = torch.sigmoid(x11+x22)\n        print(\"z.shape\",z.shape)\n\n        # \u5bf9\u4e24\u90e8\u5206\u8f93\u5165\u6267\u884c\u52a0\u6743\u548c\n        out = z*x1 + (1-z)*x2\n        return out\n\n\n\nif __name__ == '__main__':\n    # \u65f6\u95f4\u5e8f\u5217: (B, N, T, C)\n    # x1 = torch.randn(1, 10, 24, 64)\n    # x2 = torch.randn(1, 10, 24, 64)\n\n    # \u56fe\u50cf\uff1a(B,H,W,C)\n    x1 = torch.randn(1,224,224,64)\n\n    x2 = torch.randn(1,224,224,64)\n\n\n    Model = gatedFusion(dim=64)\n    out = Model(x1,x2)\n    print(\"out.shape\",out.shape)\n</code></pre>"},{"location":"Reproduction/2/#_3","title":"\u591a\u5c3a\u5ea6\u9009\u62e9\u6027\u878d\u5408","text":"Python<pre><code>import math\nimport torch.nn as nn\nimport torch\nimport math\nimport torch.nn.functional as F\n\n\"\"\"SHISRCNet: Super-resolution And Classification Network For Low-resolution Breast Cancer Histopathology Image\"\"\"\n# DONE \u8fd9\u4e2a\u7ed3\u6784\u8fd8\u884c\uff0c\u4e5f\u53ef\u4ee5\u6539\u5965\uff0c\u5f88\u591a\u5730\u65b9\u90fd\u53ef\u4ee5\u6539\uff0c\u52a0\u4e2a\u4e32\u5e76\u8054\u4ec0\u4e48\u7684\uff0c\u6216\u8005\u628a 6_1 \u5957\u8fdb\u6765\uff0c\u91cd\u65b0\u753b\u4e2a\u56fe\nclass oneConv(nn.Module):\n    # \u5377\u79ef+ReLU\u51fd\u6570\n    def __init__(self, in_channels, out_channels, kernel_sizes, paddings, dilations):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size = kernel_sizes, padding = paddings, dilation = dilations, bias=False),###, bias=False\n            # nn.BatchNorm2d(out_channels),\n            # nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\nclass MSFblock(nn.Module):\n    def __init__(self, in_channels):\n        super(MSFblock, self).__init__()\n        out_channels = in_channels\n\n        self.project = nn.Sequential(\n            nn.Conv2d(out_channels, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),)\n            #nn.Dropout(0.5))\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.softmax = nn.Softmax(dim = 2)\n        self.Sigmoid = nn.Sigmoid()\n        self.SE1 = oneConv(in_channels,in_channels,1,0,1)\n        self.SE2 = oneConv(in_channels,in_channels,1,0,1)\n        self.SE3 = oneConv(in_channels,in_channels,1,0,1)\n        self.SE4 = oneConv(in_channels,in_channels,1,0,1)\n\n    def forward(self, x0,x1,x2,x3):\n        # x1/x2/x3/x4: (B,C,H,W)\n        y0 = x0\n        y1 = x1\n        y2 = x2\n        y3 = x3\n\n        # \u901a\u8fc7\u6c60\u5316\u805a\u5408\u5168\u5c40\u4fe1\u606f,\u7136\u540e\u901a\u8fc71\u00d71conv\u5efa\u6a21\u901a\u9053\u76f8\u5173\u6027: (B,C,H,W)--&gt;GAP--&gt;(B,C,1,1)--&gt;SE1--&gt;(B,C,1,1)\n        print(self.gap(x0))\n        y0_weight = self.SE1(self.gap(x0))\n        print(y0_weight)\n\n        y1_weight = self.SE2(self.gap(x1))\n        y2_weight = self.SE3(self.gap(x2))\n        y3_weight = self.SE4(self.gap(x3))\n\n        # \u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u5168\u5c40\u4fe1\u606f\u8fdb\u884c\u62fc\u63a5: (B,C,4,1) # \u5c0f\u62ec\u53f7\u91cc\u9762\u67091\u4e2a\u6570\uff0c\u6709 4 \u4e2a\u5c0f\u62ec\u53f7\uff0cC \u4e2a 4\u00d71 \u7684\u77e9\u9635\n        weight = torch.cat([y0_weight,y1_weight,y2_weight,y3_weight],2)\n        print(weight)\n\n        # \u9996\u5148\u901a\u8fc7sigmoid\u51fd\u6570\u83b7\u5f97\u901a\u9053\u63cf\u8ff0\u7b26\u8868\u793a, \u7136\u540e\u901a\u8fc7softmax\u51fd\u6570,\u6c42\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u6743\u91cd: (B,C,4,1)--&gt; (B,C,4,1)\n        # \u6bcf\u4e2a\u901a\u9053 4 \u79cd\u8868\u793a\uff0c\u5148\u5f97\u5230\u6bcf\u79cd\u8868\u793a\u7684\u7edd\u5bf9\u5927\u5c0f\uff0c\u7136\u540e\u5f97\u5230\u76f8\u5bf9\u5927\u5c0f\n        # sigmoid \u7edd\u5bf9\u7684\u5927\u5c0f\uff0csoftmax\u76f8\u5bf9\u5927\u5c0f\n        weight = self.softmax(self.Sigmoid(weight))\n        print(weight.shape) # torch.Size([4, 3, 4, 1]) # \u5f97\u5230 3 \u4e2a\u901a\u9053 4 \u79cd\u8868\u793a\u7684\u6743\u91cd\n\n\n        # weight[:,:,0]:(B,C,1); (B,C,1)--&gt;unsqueeze--&gt;(B,C,1,1)\n        y0_weight = torch.unsqueeze(weight[:,:,0],2)\n        print(y0_weight) # unsqueeze \u540e\u76841 \u4e2a\u6570\u8868\u793a\u4e00\u5f20\u56feH\u548c W \u7684\u6743\u91cd\uff08\u5b8c\u5168\u53ef\u4ee5\u6539\u6210\u5750\u6807\u6ce8\u610f\u529b\uff09\n        # \u901a\u9053\u63cf\u8ff0\u7b26\u53ea\u5efa\u6a21\u4e86\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u5173\u6027\n        print(y0_weight.shape) # torch.Size([4, 3, 1, 1])\n        # \u5c0f\u62ec\u53f7\u91cc\u9762\u6709 1 \u4e2a\u6570\uff0c\u6709 1 \u4e2a\u5c0f\u62ec\u53f7\uff0c\u6709 3 \u4e2a\u77e9\u9635\u3002\n        y1_weight = torch.unsqueeze(weight[:,:,1],2)\n        y2_weight = torch.unsqueeze(weight[:,:,2],2)\n        y3_weight = torch.unsqueeze(weight[:,:,3],2)\n        # \u6bcf\u5f20\u56fe\uff0c3 \u4e2a\u7279\u5f81\uff0c4 \u4e2a\u7279\u5f81\u8868\u793a\u7684\u91cd\u8981\u6027\u6743\u91cd\n        # \u4e00\u5802\u8bfe\uff0c3 \u4e2a\u8001\u5e08\uff0c\u6bcf\u4e2a\u8001\u5e08\u7684\u4e0d\u540c\u4fa7\u91cd\u70b9\uff0c\u5b66\u751f\u5b66\u5230\u7684=class*teacher1_attn1+......\n\n        # \u5c06\u6743\u91cd\u4e0e\u5bf9\u5e94\u7684\u8f93\u5165\u8fdb\u884c\u9010\u5143\u7d20\u4e58\u6cd5: (B,C,1,1) * (B,C,H,W)= (B,C,H,W), \u7136\u540e\u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa\u8fdb\u884c\u76f8\u52a0\n        x_att = y0_weight*y0+y1_weight*y1+y2_weight*y2+y3_weight*y3\n        return self.project(x_att)\n\n\nif __name__ == '__main__':\n    # (B,C,H,W)\n    # x0 = torch.rand(1, 64, 192, 192)\n    # x1 = torch.rand(1, 64, 192, 192)\n    # x2 = torch.rand(1, 64, 192, 192)\n    # x3 = torch.rand(1, 64, 192, 192)\n\n    # Model = MSFblock(in_channels=64)\n\n    x0 = torch.rand(4, 3, 2, 2)\n    x1 = torch.rand(4, 3, 2, 2)\n    x2 = torch.rand(4, 3, 2, 2)\n    x3 = torch.rand(4, 3, 2, 2)\n    # bs=4\uff0cchannel=RGB=3\uff0csize=(2,2)\n\n    Model = MSFblock(in_channels=3)\n\n    # print(Model)\n\n    out = Model(x0,x1,x2,x3)\n    print(out.shape)\n</code></pre>"},{"location":"Reproduction/2/#_4","title":"\u591a\u5c3a\u5ea6\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6","text":"Python<pre><code>import math\nimport torch.nn as nn\nimport torch\nimport math\nimport torch.nn.functional as F\n\n\"\"\"SHISRCNet: Super-resolution And Classification Network For Low-resolution Breast Cancer Histopathology Image\"\"\"\n# \u591a\u5c3a\u5ea6\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\n# DONE \u5148\u7a7a\u95f4\uff08conv\uff09\u5efa\u6a21\uff0c\u53c8\u901a\u9053\u5efa\u6a21\uff08Channel\uff09\nclass oneConv(nn.Module):\n    # \u5377\u79ef+ReLU\u51fd\u6570\n    def __init__(self, in_channels, out_channels, kernel_sizes, paddings, dilations):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size = kernel_sizes, padding = paddings, dilation = dilations, bias=False),###, bias=False\n            # nn.BatchNorm2d(out_channels),\n            # nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\nclass ASPPConv(nn.Sequential):\n    def __init__(self, in_channels, out_channels, dilation):\n        modules = [\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=dilation, dilation=dilation, bias=False),#groups = in_channels\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU()\n        ]\n        super(ASPPConv, self).__init__(*modules)\n\n\nclass MFEblock(nn.Module):\n    def __init__(self, in_channels, atrous_rates):\n        super(MFEblock, self).__init__()\n        out_channels = in_channels\n        # modules = []\n        # modules.append(nn.Sequential(\n            # nn.Conv2d(in_channels, out_channels, 1, bias=False),\n            # nn.BatchNorm2d(out_channels),\n            # nn.ReLU()))\n        rate1, rate2, rate3 = tuple(atrous_rates)\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1, dilation=1, bias=False),#groups = in_channels , bias=False\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU())\n        self.layer2 = ASPPConv(in_channels, out_channels, rate1)\n        self.layer3 = ASPPConv(in_channels, out_channels, rate2)\n        self.layer4 = ASPPConv(in_channels, out_channels, rate3)\n        self.project = nn.Sequential(\n            nn.Conv2d(out_channels, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),)\n            #nn.Dropout(0.5))\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.softmax = nn.Softmax(dim = 2)\n        self.Sigmoid = nn.Sigmoid()\n        self.SE1 = oneConv(in_channels,in_channels,1,0,1)\n        self.SE2 = oneConv(in_channels,in_channels,1,0,1)\n        self.SE3 = oneConv(in_channels,in_channels,1,0,1)\n        self.SE4 = oneConv(in_channels,in_channels,1,0,1)\n    def forward(self, x):\n        # x: (B,C,H,W)\n        print(\"x.shape\")\n        print(x.shape)\n\n        ### \u591a\u7279\u5f81\u63d0\u53d6: Multi-Features Extraction block, MFEblock\n        y0 = self.layer1(x)    # \u7b2c\u4e00\u4e2a\u5206\u652f\u7684\u8f93\u5165\u53ea\u6709x: (B,C,H,W)--&gt;(B,C,H,W)\n        y1 = self.layer2(y0+x) # \u7b2c\u4e8c\u4e2a\u5206\u652f\u7684\u8f93\u5165\u662fy0\u548cx: (B,C,H,W)--&gt;(B,C,H,W)\n        y2 = self.layer3(y1+x) # \u7b2c\u4e09\u4e2a\u5206\u652f\u7684\u8f93\u5165\u662fy1\u548cx: (B,C,H,W)--&gt;(B,C,H,W)\n        y3 = self.layer4(y2+x) # \u7b2c\u56db\u4e2a\u5206\u652f\u7684\u8f93\u5165\u662fy2\u548cx: (B,C,H,W)--&gt;(B,C,H,W)\n\n        # \u5148\u63d0\u53d6\u591a\u7279\u5f81\uff08kerkel_size\uff09\uff0c\u518d\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408(\u52a0\u6743\u91cd)\n\n        ###  \u591a\u5c3a\u5ea6\u878d\u5408, multi-scale selective fusion, MSF\n        # \u901a\u8fc7\u6c60\u5316\u805a\u5408\u5168\u5c40\u4fe1\u606f,\u7136\u540e\u901a\u8fc71\u00d71conv\u5efa\u6a21\u901a\u9053\u76f8\u5173\u6027: (B,C,H,W)--&gt;GAP--&gt;(B,C,1,1)--&gt;SE1--&gt;(B,C,1,1)\n        y0_weight = self.SE1(self.gap(y0))\n        y1_weight = self.SE2(self.gap(y1))\n        y2_weight = self.SE3(self.gap(y2))\n        y3_weight = self.SE4(self.gap(y3))\n\n        # \u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u5168\u5c40\u4fe1\u606f\u8fdb\u884c\u62fc\u63a5: (B,C,4,1)\n        weight = torch.cat([y0_weight,y1_weight,y2_weight,y3_weight],2)\n        # \u9996\u5148\u901a\u8fc7sigmoid\u51fd\u6570\u83b7\u5f97\u901a\u9053\u63cf\u8ff0\u7b26\u8868\u793a, \u7136\u540e\u901a\u8fc7softmax\u51fd\u6570,\u6c42\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u6743\u91cd: (B,C,4,1)--&gt; (B,C,4,1)\n        weight = self.softmax(self.Sigmoid(weight))\n\n        # weight[:,:,0]:(B,C,1); (B,C,1)--&gt;unsqueeze--&gt;(B,C,1,1)\n        y0_weight = torch.unsqueeze(weight[:,:,0],2)\n        y1_weight = torch.unsqueeze(weight[:,:,1],2)\n        y2_weight = torch.unsqueeze(weight[:,:,2],2)\n        y3_weight = torch.unsqueeze(weight[:,:,3],2)\n\n        # \u5c06\u6743\u91cd\u4e0e\u5bf9\u5e94\u7684\u8f93\u5165\u8fdb\u884c\u9010\u5143\u7d20\u4e58\u6cd5: (B,C,1,1) * (B,C,H,W)= (B,C,H,W), \u7136\u540e\u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa\u8fdb\u884c\u76f8\u52a0\n        x_att = y0_weight*y0+y1_weight*y1+y2_weight*y2+y3_weight*y3\n        return self.project(x_att+x) # \u52a0\u4e86\u4e00\u4e2a\u6b8b\u5dee\u8fde\u63a5\n\n\nif __name__ == '__main__':\n    # (B,C,H,W)\n    x = torch.rand(1, 64, 192, 192)\n\n    # atrous_rates: \u6269\u5f20\u7387\n    Model = MFEblock(in_channels = 64,atrous_rates = [2,4,8])\n    out = Model(x)\n    print(\"out.shape\")\n    print(out.shape) # torch.Size([1, 64, 192, 192])\n</code></pre>"},{"location":"Reproduction/2/#_5","title":"\u591a\u5c3a\u5ea6\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\"Spatially-Adaptive Feature Modulation for Efficient Image Super-Resolution\"\n# DONE \u5377\u79ef\uff0c\u91c7\u6837\uff0c\u63d2\u503c\uff0c\u6a21\u5757\u53ef\u4ee5\u6539\uff0c\u53ef\u4ee5\u52a0\u6ce8\u610f\u529b\n# \u589e\u5220\u6539\u67e5\uff0c\u67e5\uff1a\u501f\u9274\u8fd9\u4e2a\u6846\u67b6\uff0c\u5c01\u81ea\u5df1\u7684\u6a21\u5757\uff0c\u518d\u91cd\u65b0\u753b\u56fe\n# SAFM\nclass SAFM(nn.Module):\n    def __init__(self, dim, n_levels=4):\n        super().__init__()\n        # \u8868\u793a\u6709\u591a\u5c11\u4e2a\u5c3a\u5ea6\n        self.n_levels = n_levels\n        # \u6bcf\u4e2a\u5c3a\u5ea6\u7684\u901a\u9053\u662f\u591a\u5c11\n        chunk_dim = dim // n_levels\n\n        # Spatial Weighting\n        self.mfr = nn.ModuleList([nn.Conv2d(chunk_dim, chunk_dim, 3, 1, 1, groups=chunk_dim) for i in range(self.n_levels)])\n\n        # Feature Aggregation\n        self.aggr = nn.Conv2d(dim, dim, 1, 1, 0)\n\n        # Activation\n        self.act = nn.GELU()\n\n    def forward(self, x):\n        # (B,C,h,w)\n        h, w = x.size()[-2:]\n        print(\"x.shape:\",x.shape)\n        print(\"\u5206\u6210\u51e0\u4efd\uff1a\",self.n_levels)\n\n        # \u5c06\u901a\u9053\u5e73\u5747\u5206\u4e3an_levels\u4efd,n_levels\u662f\u5c3a\u5ea6\u7684\u4e2a\u6570: (B,C,h,w) --chunk--&gt; (B,C/n_levels,h,w)\n        xc = x.chunk(self.n_levels, dim=1)\n        print(\"xc[0].shape:\",xc[0].shape)\n        print(\"xc[1].shape:\",xc[1].shape)\n        print(\"xc[2].shape:\",xc[2].shape)\n        print(\"xc[3].shape:\",xc[3].shape)\n        # \u6ce8\u610f\u4e00\u4e0b\u600e\u4e48\u7d22\u5f15\u7684\n\n        out = []\n        # \u904d\u5386\u591a\u4e2a\u5c3a\u5ea6,\u56db\u4e2a\u5c3a\u5ea6\u7684\u4e0b\u91c7\u6837\u6bd4\u4f8b\u662f[1,2,4,8],\u7b2c\u4e00\u4e2a\u5c3a\u5ea6\u4fdd\u6301\u539f\u6709\u5206\u8fa8\u7387,\u56e0\u6b64\u4ece\u7b2c\u4e8c\u4e2a\u5c3a\u5ea6\u5f00\u59cb\u904d\u5386\n        for i in range(self.n_levels):\n            if i &gt; 0:\n                p_size = (h// 2**i, w//2**i)  \n                # 1th: p_size=(h/2,w/2);\n                # 2th: p_size=(h/4,w/4); \n                # 3th: p_size=(h/8,w/8)\n\n                s = F.adaptive_max_pool2d(xc[i], p_size) \n                 # \u4ee51th\u4e3a\u4f8b, \u6267\u884c\u6700\u5927\u6c60\u5316: (B,C/n_levels,h,w) --&gt; (B,C/n_levels,h/2,w/2)\n\n                s = self.mfr[i](s) \n                # \u6267\u884c3\u00d73\u7684\u6df1\u5ea6\u5377\u79ef: (B,C/n_levels,h/2,w/2) --&gt; (B,C/n_levels,h/2,w/2)\n\n                s = F.interpolate(s, size=(h, w), mode='nearest')\n                #\u901a\u4e0a\u91c7\u6837\u6062\u590d\u4e0e\u8f93\u5165\u76f8\u540c\u7684shape:(B,C/n_levels,h/2,w/2) --&gt; (B,C/n_levels,h,w)\n            else:\n                s = self.mfr[i](xc[i]) \n                # 0th: \u7b2c\u4e00\u4e2a\u5c3a\u5ea6\u4fdd\u6301\u539f\u6709\u5206\u8fa8\u7387(h,w), \u7136\u540e\u6267\u884c3\u00d73\u7684\u6df1\u5ea6\u5377\u79ef:  (B,C/n_levels,h,w)--&gt; (B,C/n_levels,h,w)\n            out.append(s)\n\n        # \u5c06\u56db\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa\u5728\u901a\u9053\u4e0a\u62fc\u63a5,\u6062\u590d\u539fshape: (B,C,h,w), \u7136\u540e\u901a\u8fc71\u00d71Conv\u6765\u805a\u5408\u591a\u4e2a\u5b50\u7a7a\u95f4\u7684\u4e0d\u540c\u5c3a\u5ea6\u7684\u901a\u9053\u7279\u5f81:\n        out = self.aggr(torch.cat(out, dim=1))\n\n        # \u901a\u8fc7gelu\u6fc0\u6d3b\u51fd\u6570\u8fdb\u884c\u89c4\u8303\u5316,\u6765\u5f97\u5230\u6ce8\u610f\u529b\u56fe,\u7136\u540e\u4e0e\u539f\u59cb\u8f93\u5165\u6267\u884c\u9010\u5143\u7d20\u4e58\u6cd5\uff08\u7a7a\u95f4\u4e0a\u7684\u591a\u5c3a\u5ea6\u6c60\u5316\u4f1a\u9020\u6210\u7a7a\u95f4\u4e0a\u7684\u4fe1\u606f\u4e22\u5931\uff0c\u901a\u8fc7\u4e0e\u539f\u59cb\u8f93\u5165\u76f8\u4e58\u80fd\u591f\u4fdd\u7559\u4e00\u4e9b\u7a7a\u95f4\u4e0a\u7684\u7ec6\u8282\uff09, \u5f97\u5230\u6700\u7ec8\u8f93\u51fa\n        out = self.act(out) * x\n        return out\n\nif __name__ == '__main__':\n    # (B,C,H,W)\n    x = torch.randn(1, 36, 224, 224)\n    Model = SAFM(dim=36)\n    out = Model(x)\n    print(out.shape)\n</code></pre>"},{"location":"Reproduction/2/#_6","title":"\u91cd\u53e0\u7a7a\u95f4\u7f29\u51cf\u6ce8\u610f\u529b","text":"Python<pre><code>import math\nimport torch.nn as nn\nimport torch\nimport itertools\nimport torch.nn.functional as F\n# from mmcv.cnn.bricks import ConvModule\n\n\"TransXNet: Learning Both Global and Local Dynamics with a Dual Dynamic Token Mixer for Visual Recognition\"\n\n\nclass OSRAttention(nn.Module):  ### OSRA\n    def __init__(self, dim,\n                 num_heads=8,\n                 qk_scale=None,\n                 attn_drop=0,\n                 sr_ratio=2,):\n        super().__init__()\n        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n        self.dim = dim\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = qk_scale or head_dim ** -0.5\n        self.sr_ratio = sr_ratio\n        self.q = nn.Conv2d(dim, dim, kernel_size=1)\n        self.kv = nn.Conv2d(dim, dim*2, kernel_size=1)\n        # \u5bf9\u4e8e\u56fe\u6765\u8bf4\uff0cqkv \u662f\u5377\u79ef\u5f97\u5230\u7684\uff0c\u5e76\u4e14\u5377\u79ef\u6838\u5c3a\u5bf8\u90fd\u662f 1 \u00d7 1 \u7684\uff0c\u4e0d\u6539\u53d8 \u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\uff0c\u4e5f\u5c31\u662f\u4e0d\u6539\u53d8\u8bcd\u7684\u4e2a\u6570\n        # \u4f46\u8fd9\u4e2a\u6a21\u5757\u6709\u70b9\u7279\u6b8a\uff0c\u5bf9\u4e8e kv \u964d\u7ef4\u4e86\n        self.attn_drop = nn.Dropout(attn_drop)\n        if sr_ratio &gt; 1:\n            #  sr_ratio=2  2+3//2=2\n            # output_size = h-k+s+2p/s = 7-5+2+2*2/2=8/2=4\n            # x.shape = [1, 64, 7, 7]\n            # \u5206\u7ec4\u4e0d\u5f71\u54cd \u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5927\u5c0f\uff0c\u5f71\u54cd\u5377\u79ef\u6838\u7684\u901a\u9053\u6570\uff0c\u4e5f\u5c31\u662f\u5f71\u54cd\u5377\u79ef\u8fd0\u7b97\u7684\u53c2\u6570\u91cf\n            self.sr = nn.Sequential(\n                nn.Conv2d(dim, dim,kernel_size=sr_ratio+3,stride=sr_ratio,padding=(sr_ratio+3)//2,groups=dim,bias=False),\n                nn.BatchNorm2d(dim),\n                nn.ReLU(),\n                # ConvModule(dim, dim,\n                #            kernel_size=sr_ratio+3,\n                #            stride=sr_ratio,\n                #            padding=(sr_ratio+3)//2,\n                #            groups=dim,\n                #            bias=False,\n                #            norm_cfg=dict(type='BN2d'),\n                #            act_cfg=dict(type='GELU')),\n                # ConvModule(dim, dim,\n                #            kernel_size=1,\n                #            groups=dim,\n                #            bias=False,\n                #            norm_cfg=dict(type='BN2d'),\n                #            act_cfg=None,),)\n                nn.Conv2d(dim, dim, kernel_size=1, groups=dim, bias=False),# \u5206\u7ec4\u5377\u79ef\u4e0d\u4f1a\u6539\u53d8\u8f93\u51fa\u7279\u5f81\u7684\u5c3a\u5bf8\uff0c\u53ea\u4f1a\u5f71\u54cd\u5355\u4e2a\u5377\u79ef\u6838\u7684\u901a\u9053\u6570\uff0c\u4e5f\u5c31\u662f\u51cf\u5c11\u5355\u4e2a\u5377\u79ef\u7684\u53c2\u6570\u91cf\uff0c\u4ece\u800c\u5f71\u54cd\u6574\u4e2a\u5377\u79ef\u64cd\u4f5c\u7684\u53c2\u6570\u91cf\n                nn.BatchNorm2d(dim),)\n        else:\n            self.sr = nn.Identity()\n        self.local_conv = nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim)\n\n    def forward(self, x, relative_pos_enc=None):\n        B, C, H, W = x.shape\n\n        # print(x.shape) # torch.Size([1, 64, 7, 7])\n\n        # \u56fe\u7684\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236 \u62c6\u5206\u7684\u662f\u901a\u9053\n        q = self.q(x).reshape(B, self.num_heads, C//self.num_heads, -1).transpose(-1, -2)\n        # print(self.q(x).shape) # torch.Size([1, 64, 7, 7])\n\n        # B = 1; self.num_heads = 8; C=64; C//self.num_heads=8;\n        # print(self.q(x).reshape(B, self.num_heads, C//self.num_heads, -1).shape) \n        #   # torch.Size([1, 8, 8, 49]) \u2192 1 \u4e2a batch size;\n        #   8\u4e2a\u5934\uff08\u6bcf\u4e2a\u5934\u5206\u522b\u5b66\u4e60\u4e0d\u91cd\u53e0\u7684\u901a\u9053\uff0c8 \u4e2a\u8001\u5e08\uff0c\u8bfe\u672c\u5206\u6210 8 \u7ae0\uff0c\u6bcf\u4e2a\u8001\u5e08\u6559\u4e00\u7ae0\uff09;\n        #   \u6bcf\u4e2a\u5934\u5b66\u4e60 8 \u4e2a\u901a\u9053\uff1b\u6bcf\u4e2a\u901a\u9053\u5b66\u4e60\u7684\u5185\u5bb9 H*W=7*7 = 49\n\n        # print(q.shape)  # torch.Size([1, 8, 49, 8])\n        # \u5bf9\u8f93\u5165x\u8fdb\u884c\u53d8\u6362\u5f97\u5230q,\u7136\u540e\u901a\u8fc7reshape\u91cd\u5851shape: \n        # (B,C,H,W)--q()-&gt;(B,C,H,W)--reshape--&gt;(B,h,d,HW) --transpose--&gt; (B,h,HW,d);  C=h*d\n        # self.q = nn.Conv2d(dim, dim, kernel_size=1) \n        # 1\u00d71 \u5377\u79ef\u4e0d\u6539\u53d8\u7279\u5f81\u56fe\u5927\u5c0f padding=kernel_size // 2 \u2192 \u4e0d\u53d8\u5377\u79ef\n        # \u5b57\u6bcd\u8bf4\u660e\uff1aB: batch size\n        # h = num_heads \n        # d = head_dim = C // self.num_heads \u6bcf\u4e2a\u5934\u7684\u7ef4\u5ea6\uff0c\u76f8\u5f53\u4e8e\u6bcf\u4e2a\u5934\u5206\u914d\u7684\u901a\u9053\u6570\uff0c\u5bf9\u4e8e\u56fe\u6765\u8bf4\uff0c\u901a\u9053\u6570 \u76f8\u5f53\u4e8e\u7279\u5f81\u6570\n        # HW \u56fe\u7684\u9ad8\u5ea6\u4e58\u4ee5\u5bbd\u5ea6\u76f8\u5f53\u4e8e\u5e8f\u5217\u957f\u5ea6 \u76f8\u5f53\u4e8e\u6bcf\u4e2a pixel \u8868\u8fbe\u8bed\u4e49\n        # (\u73b0\u5b9e\u542b\u4e49)\u6240\u4ee5\u8fd9\u91cc q.shape = [1,8,49,8]\u7684\u610f\u601d\u662f\uff0cbs=1\uff0cheads=8(8\u53e5\u8bdd)\uff0c\u6bcf\u53e5\u8bdd 49 \u4e2a\u8bcd\uff08pixel\uff09\uff0c\u6bcf\u4e2a pixel(\u8bcd),\u7684\u7279\u5f81\u7ef4 8\n\n        # \u901a\u8fc7OSR\u64cd\u4f5c\u5f97\u5230k/v\u8868\u793a\n        kv = self.sr(x) \n        # \u6267\u884c\u7a7a\u95f4\u7f29\u51cf(spatial reduction)\u64cd\u4f5c,\u4e5f\u5c31\u662f\u901a\u8fc7\u5377\u79ef\u6765\u5b9e\u73b0\u4e0b\u91c7\u6837,\u5f97\u5230kv: (B,C,H,W)--&gt;(B,C,H\u2018,W\u2019)\n        # print(x.shape) # torch.Size([1, 64, 7, 7])\n        # self.sr = nn.Sequential \n        # print(kv.shape) # torch.Size([1, 64, 4, 4]) \n        #  self.sr\u5b9e\u73b0\u4e86\u4ec0\u4e48\u529f\u80fd \u7b54:\uff08\u7a7a\u95f4\u7f29\u51cf\uff0c\u51cf\u5c0f\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\uff09\n        # \u4e3a\u4ec0\u4e48\u8981 \u51cf\u5c11\u7279\u5f81\u56fe\u5c3a\u5bf8\uff1f\n\n\n        kv = self.local_conv(kv) + kv  \n        # \u901a\u8fc73\u00d73\u5377\u79ef\u5bf9\u5c40\u90e8\u7a7a\u95f4\u5efa\u6a21,\u5e76\u6dfb\u52a0\u6b8b\u5dee\u8fde\u63a5: (B,C,H\u2018,W\u2019)--&gt;(B,C,H\u2018,W\u2019)\n        # self.local_conv = nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim)\n        # padding = 1 = 3//2 = 1 \u6240\u4ee5\u8fd9\u4e2a\u662f\u4e0d\u53d8\u5377\u79ef\uff0c\u4e5f\u5c31\u662f\u8f93\u5165\u7279\u5f81\u56fe\u5c3a\u5bf8\u548c\u8f93\u51fa\u7279\u5f81\u56fe\u5c3a\u5bf8\u76f8\u540c\n        # \u5904\u7406\u540e\u7684 kv.shape =  torch.Size([1, 64, 4, 4]) \n        # \u4e3a\u4ec0\u4e48\u8981\u6709\u8fd9\u4e00\u6b65\uff1f  \uff08\u7f29\u51cf\u7a7a\u95f4\uff0c\u770b\u6a21\u5757\u7684\u8bbe\u8ba1\u52a8\u673a\uff09\n\n        k, v = torch.chunk(self.kv(kv), chunks=2, dim=1) \n        #\u5206\u5272\u4e3ak\u3001v: (B,C,H\u2018,W\u2019)--kv()--&gt;(B,2C,H\u2018,W\u2019)--chunk--&gt; k:(B,C,H\u2018,W\u2019); v:(B,C,H\u2018,W\u2019)\n        # self.kv = nn.Conv2d(dim, dim*2, kernel_size=1) \u5377\u79ef\u6838\u5c3a\u5bf8\u4e3a 1\uff0c\u4e0d\u6539\u53d8\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5927\u5c0f\uff0c\u901a\u9053\u6570\u7ffb\u500d\n        # \u901a\u9053\u6570\u7ffb\u500d\u4ee5\u540e\uff0c\u53c8\u5212\u5206\u6210 2 \u7ec4\uff0c\u53c8\u6062\u590d\u901a\u9053\u6570 C\uff0c\u5206\u522b\u5206\u914d\u7ed9k,v\n        # chunk\u540e\u7684 k.shape =  1,64,4,4 ; v.shape =  1,64,4,4\n\n        k = k.reshape(B, self.num_heads, C//self.num_heads, -1) \n        # (B,C,H\u2018,W\u2019) --reshape--&gt; (B,h,d,H'W');  c=h*d\n        # \u5206\u7ed9\u591a\u5934\uff0c8 \u4e2a\u5934\uff0c\u6bcf\u4e2a\u5934 8 \u901a\u9053\n        # reshape\u540e\u7684 k.shape = 1,8,8,16  bs=1\uff0cheads=8\uff0chead_dim=8,H'W'=16 16\u4e2a\u8bcd\uff0c\u6bcf\u4e2a\u8bcd\u7528 head_dim =8 \u957f\u5ea6\u4e3a 8 \u7684\u5411\u91cf\u8868\u8fbe\n\n        v = v.reshape(B, self.num_heads, C//self.num_heads, -1).transpose(-1, -2)  \n        #(B,C,H\u2018,W\u2019)--reshape--&gt;(B,h,d,H'W')--transpose--&gt;(B,h,H'W',d)\n        # reshape &amp; transpose \u540e\u7684 v.shape = torch.Size([1, 8, 16, 8])\n\n        attn = (q @ k) * self.scale \n        # \u5bf9qk\u8ba1\u7b97\u6ce8\u610f\u529b\u77e9\u9635: (B,h,HW,d) @ (B,h,d,H'W') = (B,h,HW,H'W')\n        # q\u548c kv \u7684\u6765\u6e90\u53ef\u4ee5\u4e0d\u540c\uff0c\u5f62\u72b6\u4e5f\u53ef\u4ee5\u4e0d\u540c\uff0c\u4f46\u662f kv \u7684\u6765\u6e90\u5fc5\u987b\u4e00\u81f4\uff0c\u4e14\u5f62\u72b6\u76f8\u540c\uff0c\u6700\u540e\u7684 attn \u8f93\u51fa\u5f62\u72b6\u5fc5\u987b\u548c q \u4fdd\u6301\u4e00\u81f4 \n        # q.shape = torch.Size([1, 8, 49, 8])   49 \u4e2a\u8bcd\n        # k.shape = torch.Size([1, 8, 8, 16])  16 \u4e2a\u8bcd\n        # v.shape = torch.Size([1, 8, 16, 8]) \n        # attn.shape = torch.Size([1, 8, 49, 16])\n        # QK^T = attn.shape = torch.Size([1, 8, 49, 16]) \u8fd9 49 \u4e2a\u8bcd \u5bf9\u5e94\u7684\u4e0e 16 \u4e2a\u8bcd\u4e4b\u95f4 \u4e24\u4e24\u7684\u76f8\u5173\u6027\uff08pixel\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff09\n        # heads=8\uff0c\u662f\u5206\u6210\u4e86 8 \u4efd\uff0c\u4e0d\u76f8\u4ea4\u7684 8 \u4efd\uff0c\u4e00\u8d77\u5b66\u4e60\u76f8\u5173\u6027\uff08\u8868\u793a\u66f4\u591a\u591a\u6837\u5316\uff09\n\n        # \u4e3a\u6ce8\u610f\u529b\u77e9\u9635\u6dfb\u52a0\u4f4d\u7f6e\u7f16\u7801\n        if relative_pos_enc is not None:\n            # relative_pos_enc = None,\u9ed8\u8ba4\u4e3a None\uff0c\u800c\u4e14\u4e5f\u6ca1\u6709\u4f20\u8fdb\u6765\uff0c\u6240\u4ee5\u4e0d\u6267\u884c if \u8bed\u53e5\n            # def forward(self, x, relative_pos_enc=None):\n            if attn.shape[2:] != relative_pos_enc.shape[2:]:\n                relative_pos_enc = F.interpolate(relative_pos_enc, size=attn.shape[2:],\n                                                 mode='bicubic', align_corners=False)\n            attn = attn + relative_pos_enc\n\n        attn = torch.softmax(attn, dim=-1) \n        # \u5bf9\u6ce8\u610f\u529b\u77e9\u9635\u8fdb\u884c\u5f52\u4e00\u5316\n        # \u5bf9 QK^T = attn.shape = torch.Size([1, 8, 49, 16])\uff0c16 \u8fd9\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u76f8\u5f53\u4e8e LayerNorm\n\n        attn = self.attn_drop(attn)\n        x = (attn @ v).transpose(-1, -2) \n        # \u901a\u8fc7\u6ce8\u610f\u529b\u77e9\u9635\u5bf9value\u8fdb\u884c\u52a0\u6743: (B,h,HW,H'W') @ (B,h,H'W',d) = (B,h,HW,d); \n        #  (B,h,HW,d)--transpose--&gt;(B,h,d,HW)\n        # \u5bf9 value \u8fdb\u884c\u52a0\u6743 \uff1av.shape = torch.Size([1, 8, 16, 8])  \n        # QK^T = attn.shape = torch.Size([1, 8, 49, 16])\n        # Q.shape = torch.Size([1, 8, 49, 8]) \n        # x.shape = 1,8,49,8  \u4e0e q \u7684\u5f62\u72b6\u76f8\u540c\uff0c\u4f46\u8fd9\u6b21\u662f\u753b\u4e86\u91cd\u70b9\u7684 q\n\n        return x.reshape(B, C, H, W) \n        # \u5bf9x\u8fdb\u884creshape,\u91cd\u5851\u4e3a\u4e0e\u8f93\u5165\u76f8\u540c\u7684shape: (B,h,HW,d) --&gt; (B, C, H, W)\n        # \u6ce8\u610f\u529b\u673a\u5236\u4f5c\u7528\u5728\u6bcf\u4e2a\u50cf\u7d20\u4e0a\n\n\nif __name__ == '__main__':\n    # (B,C,H,W)\n    x = torch.randn(1, 64, 7, 7)\n    Model = OSRAttention(dim=64)\n    out = Model(x)\n    # print(out.shape)\n</code></pre> <p>\u5bf9\u4e8e 2 \u7ef4\u56fe\u50cf\u6765\u8bf4\uff0cLinear \u5c31\u76f8\u5f53\u4e8e 1\u00d71 \u7684\u5377\u79ef</p>"},{"location":"Reproduction/2/#_7","title":"\u591a\u5c3a\u5ea6\u6ce8\u610f\u529b\u805a\u5408","text":""},{"location":"Reproduction/2/#_8","title":"\u878d\u5408\u901a\u9053\u8868\u793a\u7684\u7a7a\u95f4\u6ce8\u610f\u2f12","text":"Python<pre><code>import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import init\n\n\"CBAM: Convolutional Block Attention Module \"\n\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super().__init__()\n        self.maxpool = nn.AdaptiveMaxPool2d(1)\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.se = nn.Sequential(\n            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n            nn.ReLU(),\n            nn.Conv2d(channel // reduction, channel, 1, bias=False)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        max_result = self.maxpool(x)  # \u901a\u8fc7\u6700\u5927\u6c60\u5316\u538b\u7f29\u5168\u5c40\u7a7a\u95f4\u4fe1\u606f: (B,C,H,W)--&gt; (B,C,1,1)\n        avg_result = self.avgpool(x)  # \u901a\u8fc7\u5e73\u5747\u6c60\u5316\u538b\u7f29\u5168\u5c40\u7a7a\u95f4\u4fe1\u606f: (B,C,H,W)--&gt; (B,C,1,1)\n        max_out = self.se(max_result)  # \u5171\u4eab\u540c\u4e00\u4e2aMLP: (B,C,1,1)--&gt; (B,C,1,1)\n        avg_out = self.se(avg_result)  # \u5171\u4eab\u540c\u4e00\u4e2aMLP: (B,C,1,1)--&gt; (B,C,1,1)\n        output = max_out + avg_out  # (B,C,1,1)\n        return output\n\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super().__init__()\n        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # x:(B,C,H,W)\n        max_result, _ = torch.max(x, dim=1, keepdim=True)  # \u901a\u8fc7\u6700\u5927\u6c60\u5316\u538b\u7f29\u5168\u5c40\u901a\u9053\u4fe1\u606f:(B,C,H,W)--&gt;(B,1,H,W); \u8fd4\u56de\u901a\u9053\u7ef4\u5ea6\u4e0a\u7684: \u6700\u5927\u503c\u548c\u5bf9\u5e94\u7684\u7d22\u5f15.\n        avg_result = torch.mean(x, dim=1, keepdim=True)  # \u901a\u8fc7\u5e73\u5747\u6c60\u5316\u538b\u7f29\u5168\u5c40\u901a\u9053\u4fe1\u606f:(B,C,H,W)--&gt;(B,1,H,W); \u8fd4\u56de\u901a\u9053\u7ef4\u5ea6\u4e0a\u7684: \u5e73\u5747\u503c\n        result = torch.cat([max_result, avg_result], 1)  # \u5728\u901a\u9053\u4e0a\u62fc\u63a5\u4e24\u4e2a\u77e9\u9635:(B,2,H,W)\n        output = self.conv(result)  # \u7136\u540e\u91cd\u65b0\u964d\u7ef4\u4e3a1\u7ef4:(B,1,H,W); \u5728\u8fd9\u91cc\u5e76\u6ca1\u6709\u6309\u7167\u6a21\u578b\u91cc\u7684\u7684\u65b9\u5f0f\u5148MLP,\u7136\u540e\u518dAdd; \u800c\u662f\u5148concat,\u518dConv; \u5b9e\u9645\u542b\u4e49\u662f\u4e00\u81f4\u7684,\u5c31\u662f\u5b9e\u73b0\u65b9\u5f0f\u4e0d\u4e00\u81f4\u3002\n        return output\n\n\nclass CBAMBlock(nn.Module):\n\n    def __init__(self, channel=512, reduction=16, kernel_size=49, HW=None):\n        super().__init__()\n        self.ChannelAttention = ChannelAttention(channel=channel, reduction=reduction)\n        self.SpatialAttention = SpatialAttention(kernel_size=kernel_size)\n        self.joint_channel = channel + HW\n        self.MLP = nn.Sequential(\n            nn.Conv2d(self.joint_channel, channel // reduction, 1, bias=False),\n            nn.ReLU(),\n            nn.Conv2d(channel // reduction, self.joint_channel, 1, bias=False)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        # (B,C,H,W)\n        B, C, H, W = x.size()\n        residual = x\n        Channel_x = self.ChannelAttention(x).reshape(B,C,1,1) # (B,C,1,1)--&gt;(B,C,1,1)\n        Spatial_x = self.SpatialAttention(x).reshape(B,H*W,1,1) # (B,1,H,W)--&gt;(B,HW,1,1)\n\n        # \u62fc\u63a5,\u7136\u540e\u901a\u8fc7MLP\u5efa\u7acb\u76f8\u5173\u6027\n        CS_x = torch.cat([Channel_x, Spatial_x], 1) # (B,C,1,1)-Conca-&gt;(B,HW,1,1)--&gt;(B,C+HW,1,1)\n        CS_xx = self.MLP(CS_x) # (B,C+HW,1,1)-\u964d\u7ef4-&gt;(B,M,1,1)-\u5347\u7ef4-&gt;(B,C+HW,1,1)\n\n        # \u62c6\u5206,\u7136\u540e\u901a\u8fc7sigmoid\u5f97\u5230\u6743\u91cd\u8868\u793a\n        Channel_x = CS_xx[:,:C,:].reshape(B,C,1,1)  # (B,C,1,1)--&gt;(B,C,1,1)\n        Spatial_x = CS_xx[:,C:,:].reshape(B,1,H,W) # (B,HW,1,1)--&gt;(B,1,H,W)\n        Channel_weight = self.sigmoid(Channel_x)\n        Spatial_weight = self.sigmoid(Spatial_x)\n\n        # \u5206\u522b\u5f97\u5230\u901a\u9053\u548c\u7a7a\u95f4\u6743\u91cd\u4e4b\u540e,\u65e2\u53ef\u4ee5\u5355\u72ec\u76f8\u4e58\u5f97\u5230\u4e24\u4e2a\u8f93\u51fa, \u4e5f\u53ef\u4ee5\u4e00\u5757\u4e0eX\u76f8\u4e58\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa,\u89c6\u81ea\u5df1\u7684\u4efb\u52a1\u6765\u5b9a\u4e49\n        out1 = x * Channel_weight  # \u5c06\u8f93\u5165\u4e0e\u901a\u9053\u6ce8\u610f\u529b\u6743\u91cd\u76f8\u4e58: (B,C,H,W) * (B,C,1,1) = (B,C,H,W)\n        out2 = x * Spatial_weight  # \u5c06\u66f4\u65b0\u540e\u7684\u8f93\u5165\u4e0e\u7a7a\u95f4\u6ce8\u610f\u529b\u6743\u91cd\u76f8\u4e58:(B,C,H,W) * (B,1,H,W) = (B,C,H,W)\n        return out1,out2\n\n\nif __name__ == '__main__':\n    # (B,C,H,W)  \u6ce8\u610f: \u56e0\u4e3a\u5728\u6a21\u578b\u4e2d\u9700\u8981\u5c06HW\u548cC\u62fc\u63a5\u8d77\u6765,\u6240\u5728\u5728\u8f93\u5165\u5230\u6a21\u578b\u7684\u65f6\u5019,\u6700\u597d\u628a\u901a\u9053C\u548cHW\u505a\u4e2a\u964d\u7ef4(\u6c60\u5316\u3001\u4e0b\u91c7\u6837\u5747\u53ef),\u7136\u540e\u5728\u8f93\u5165\u5230\u6a21\u578b\u4e2d\u53bb,\u8f93\u51fa\u4e4b\u540e\u518d\u6062\u590dshape\u5c31\u53ef\u4ee5\u4e86\uff01\n    input = torch.randn(1, 64, 7, 7)\n    B,C,H,W=input.shape\n    Model = CBAMBlock(channel=64, reduction=8, kernel_size=7, HW=H*W)\n    out1,out2 = Model(input)\n    print(out1.shape,out2.shape)\n</code></pre>"},{"location":"Reproduction/3/","title":"\u4e00\u4e9b\u611f\u609f","text":""},{"location":"Reproduction/3/#_1","title":"\u4e00\u4e9b\u611f\u609f","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 12172 \u4e2a\u5b57  37 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 61 \u5206\u949f</p> <ul> <li>\u57fa\u672c\u7ec4\u4ef6</li> <li>\uff08\u5e76\u884c Pool\uff09MaxPool \u63d0\u53d6\u5230\u6700\u91cd\u8981\u7684\u7279\u5f81\uff0c\u4e22\u5931\u6b21\u8981\u4fe1\u606f\uff0cAvgPool \u8865\u5145</li> <li>\u7ea7\u8054\u5e76\u8054\u5377\u79ef</li> <li>\u878d\u5408\u901a\u9053\u4fe1\u606f\u3001\u7a7a\u95f4\u4fe1\u606f\uff08CBAM \u5377\u79ef\u5757block\u6ce8\u610f\u529b\u6a21\u5757module\uff09</li> </ul> <p></p> <ul> <li>MLP \uff08H\u00d7W\u00d72 \u2192 H\u00d7W\u00d71\uff09\u964d\u7ef4\uff0c\u805a\u5408\u7a7a\u95f4\u7279\u5f81</li> <li>SKNets(selective kernels)</li> </ul> <p></p> <ul> <li>\u5750\u6807\u6ce8\u610f\u529b\uff0c\u4f4d\u7f6e\u4fe1\u606f\u5d4c\u5165\u5230\u7a7a\u95f4\u4fe1\u606f\uff0c\u4e24\u4e2a\u65b9\u5411\u611f\u77e5\u7279\u5f81\u56fe\uff0c\u8f93\u5165\u7279\u5f81\u6cbf\u7740\u7a7a\u95f4\u65b9\u5411\u7684\u957f\u7a0b\u4f9d\u8d56</li> </ul> <p></p> <p></p> <ul> <li>\uff08\u4e09\u5206\u652f\u6ce8\u610f\u529b\uff09\u6a21\u5757\u56fe\u3001\u8ba1\u7b97\u6d41\u7a0b\u56fe\u3001\u6709\u989c\u8272\u7684\u6a21\u5757\u56fe\uff0c\u516c\u5f0f\uff0c\u4ee3\u7801</li> </ul> <p></p> <p></p> <p></p>"},{"location":"Reproduction/3/#_2","title":"\u8ba1\u7b97\u6d41\u7a0b\u56fe","text":"<p>SENet</p> <p></p> <p>CBAM </p> <p></p> <p></p> <p></p> <p>\u6539\u81ea CBAM </p> <p></p> <p>SKNet</p> <p></p> <ul> <li>\u5750\u6807\u6ce8\u610f\u529b\u4e00\u5b9a\u8981\u8bd5\u8bd5</li> </ul> <p></p> <p>\u53cc\u91cd\u6ce8\u610f\u529b\u7f51\u7edc\uff08DANet</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Reproduction/3/#_3","title":"\u591a\u7279\u5f81\u878d\u5408\u7b56\u7565","text":"<p>\u95e8\u63a7\u7684\u4e09\u79cd\u5e94\u7528\uff0c\u901a\u8fc7\u95e8\u63a7\u5355\u5143sigmoid \u51fd\u6570\u6765\u5f97\u5230\u6743\u91cd\uff0c\u6743\u91cd\u53ef\u4ee5\u7528\u6765\u8c03\u6574\u901a\u9053\u7684\u91cd\u8981\u6027\uff0c\u7528\u6765\u9009\u62e9\u4e00\u90e8\u5206\u91cd\u8981\u7684\u4fe1\u606f\u8fdb\u884c\u8f93\u51fa\uff0c\u4e5f\u6709\u6548\u5730\u878d\u5408\u4e24\u4e2a\u7279\u5f81</p> <p>\u800c\u7a0d\u590d\u6742\u70b9\u7684\u878d\u5408\u6a21\u5757\uff0c\u4e0d\u4ec5\u5c40\u9650\u4e8e\u4e24\u4e2a\u7279\u5f81\u8d8a\u591a\u8d8a\u597d</p> <p>\u7ed9\u5b9a\u56db\u4e2a\u4e0d\u540c\u7684\u7279\u5f81\u8868\u793a\uff0c\u7136\u540e\u5e94\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u64cd\u4f5c\uff0c\u5c06\u5b83\u538b\u7f29\u52301\u00d71\u00d7C\uff0c \u8fd9\u6837\u7c7b\u4f3c\u4e8e\u901a\u9053\u6ce8\u610f\u529b\u4e2d\u7684\u64cd\u4f5c\uff0c\u7136\u540e\u518d\u7528sigmoid \u51fd\u6570\u5f97\u5230\u81ea\u8eab\u7684\u6743\u91cd\uff0c\u8c03\u6574\u6743\u91cd\u8fd9\u4e2a\u8fc7\u7a0b\u7ef4\u5ea6\u662f\u4e0d\u4f1a\u53d8\u5316\u7684\uff0c \u4f9d\u7136\u662f1\u00d71\u00d7C</p> <p>\u8865\u5145\uff1aself-gating\u81ea\u8eab\u95e8\u63a7\u662f\u5f88\u5e38\u89c1\u7684\u4e00\u79cd\u505a\u6cd5,\u901a\u5e38\u60c5\u51b5\u4e0b\u662f\u53ef\u4ee5\u7a33\u5b9a\u6da8\u70b9\u7684\uff0c\u5c31\u662f\u8bf4\u5bf9\u8f93\u5165\u901a\u8fc7sigmoid\u51fd\u6570\u5f97\u5230\u6743\u91cd\u4e4b\u540e\uff0c\u518d\u4e0e\u8f93\u5165\u8fdb\u884c\u76f8\u4e58\uff0c\u7528\u81ea\u5df1\u7684\u6743\u91cd\u6765\u8c03\u6574\u81ea\u5df1\uff0c==\u4f46\u662f==\u5728\u6d89\u53ca\u5230\u591a\u4e2a\u8f93\u5165\u7684\u65f6\u5019\uff0cself-gating\u663e\u7136\u662f\u6bd4\u8f83\u6b20\u7f3a\u7684\uff0c\u56e0\u4e3a\u53ea\u8003\u8651\u4e86\u5404\u81ea\u7684\u7279\u5f81\uff0c\u800c\u6ca1\u6709\u8003\u8651\u5230\u591a\u4e2a\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92</p> <p>\u56e0\u6b64\uff0c\u4f5c\u8005\u5c06\u8fd9\u56db\u4e2a\u6743\u91cd\u8fdb\u884c\u4e00\u4e2a\u62fc\u63a5\uff0c\u7136\u540e\u7528==softmax==\u51fd\u6570\u91cd\u65b0\u5206\u914d\u6743\u91cd\uff0c\u770b\u770b\u5230\u5e95\u8c01\u624d\u662f\u6700\u91cd\u8981\u7684\u90a3\u4e2a\uff0c\u4ee5\u8fd9\u6837\u7684\u65b9\u5f0f\u65e2\u8003\u8651\u4e86==\u81ea\u8eab==\u7684\u7279\u5f81\uff0c\u4e5f\u8003\u8651\u4e86\u7279\u5f81\u4e4b\u95f4\u7684\u4e00\u4e2a==\u4ea4\u4e92== \uff0c \u6700\u540e\uff0c\u901a\u8fc7\u6743\u91cd\u8c03\u6574\u5bf9\u5e94\u8f93\u5165\u7684\uff0c\u6bcf\u4e2a\u901a\u9053\u7684\u4e00\u4e2a\u91cd\u8981\u6027\uff0c\u5e76\u5c06\u5b83\u4eec\u6700\u540e\u8fdb\u884c\u76f8\u52a0\uff0c\u975e\u5e38\u9002\u5408\u7528\u4e8e\u591a\u4e2a\u7279\u5f81\u8fdb\u884c\u878d\u5408\u7684\u573a\u666f\u4e0b</p> <ul> <li>sigmoid\u81ea\u8eab\u95e8\u63a7</li> <li>softmax\u6743\u91cd\u4ea4\u4e92</li> </ul> <p>\u5173\u4e8e\u95e8\u63a7\uff1a</p> <p></p> <p>\u81ea\u8eab\u95e8\u63a7\uff1a</p> <p></p> <p> </p>"},{"location":"Reproduction/3/#_4","title":"\u95e8\u63a7\u5355\u5143\u7684\u4e09\u79cd\u5e94\u7528","text":"<p>\u95e8\u63a7\u5355\u5143\u7684\u4e09\u79cd\u5e94\u7528</p> <p>\u6700\u5178\u578b\u7684\u5e94\u7528\uff1a\u2460LSTM \u2461 GRU</p> <p>LSTM </p> <ul> <li>\u8f93\u5165\u95e8</li> <li>\u9057\u5fd8\u95e8</li> <li>\u8f93\u51fa\u95e8</li> </ul> <p>GRU</p> <ul> <li>\u66f4\u65b0\u95e8</li> <li>\u91cd\u7f6e\u95e8</li> </ul> <p>\u76ee\u7684\u662f\u901a\u8fc7\u95e8\u6765\u63a7\u5236\uff0c\u8c01\u6709\u8d44\u683c\u8fdb\u53bb\uff0c\u8c01\u6ca1\u8d44\u683c\u8fdb\u53bb\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u8fd9\u4e2a\u95e8\uff0c\u4ea7\u751f\u4e00\u4e2a0~1\u4e4b\u95f4\u7684\u6570\u503c</p> <ul> <li>0 \u8868\u793a\u8c01\u4e5f\u4e0d\u51c6\u8fdb\u53bb</li> <li>1 \u8868\u793a\u5168\u90e8\u90fd\u8fdb\u53bb</li> <li>\u4e2d\u95f4\u7684\u6570\u503c\u8868\u793a\u90e8\u5206\u53ef\u4ee5\u8fdb\u53bb</li> </ul> <p>\\(\\rightarrow \\mathrm{Sigmoid()}\\) </p> <p>\u53ef\u4ee5\u770bLSTM\u548cGRU\u4e2d\u7684\u95e8\u63a7\u5355\u5143\uff0c\u5728\u751f\u6210\u6743\u91cd\u4e4b\u540e\u5440\uff0c\u4f1a\u548c\u5176\u4ed6\u7684\u7279\u5f81\u5462\u8fdb\u884c\u76f8\u4e58\uff0c\u8fd9\u5c31\u662f\u7d27\u63a5\u7740\u7684\u4fe1\u606f\u9009\u62e9\u7684\u8fc7\u7a0b</p> <p>\u63a5\u4e0b\u6765\u91cd\u70b9\u6765\u770b\u770b\u95e8\u63a7\u5355\u5143\u7684\u4e09\u4e2a\u5e94\u7528\uff0c\u7740\u91cd\u5173\u6ce8\u770b\u770b\u95e8\u63a7\u5355\u5143\u901a\u5e38\u5728\u54ea\u4e9b\u5730\u65b9\u51fa\u73b0</p> <ul> <li>\u7b2c\u4e00\u4e2a\uff1a\u901a\u9053\u6ce8\u610f\u529b\uff0c\u9996\u5148\u8f93\u5165\u901a\u8fc7\u538b\u7f29\u64cd\u4f5c\uff0c\u4e5f\u5c31\u662f\u5728\u7a7a\u95f4\u7ef4\u5ea6H\u4e58W\u4e0a\uff0c\u901a\u8fc7\u5168\u5c40\u6c60\u5316\u64cd\u4f5c\u805a\u5408\u7279\u5f81\uff0c\u4ece\u800c\u751f\u6210\u7a7a\u95f4\u4e0a\u7684\u5168\u5c40\u7279\u5f81\u8868\u793a\uff0c\u7136\u540e\u901a\u8fc7\u4e00\u7cfb\u5217\u7684\u53d8\u5316\uff0c\u6765\u5b66\u4e60\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u6700\u540e\u901a\u8fc7\u4e00\u4e2asigmoid\u51fd\u6570\uff0c\u6765\u751f\u6210\u6743\u91cd\u8868\u793a\uff0c\u90a3\u4e48\u8fd9\u79cd\u83b7\u53d6\u8f93\u5165\u4e0a\u7684\u5168\u5c40\u4fe1\u606f\u8868\u793a\uff0c\u7136\u540e\u518d\u548c\u539f\u59cb\u7684\u8f93\u5165\u76f8\u4e58\uff0c\u6765\u589e\u5f3a\u6216\u8005\u524a\u5f31\u67d0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u5b83\u5728\u4e0d\u540c\u901a\u9053\u4e0a\u7684\u4e00\u4e2a\u91cd\u8981\u6027\uff0c\u8fd9\u5c31\u662f\u95e8\u63a7\u5355\u5143\u7684\u7b2c\u4e00\u4e2a\u5e94\u7528\uff0c\u751f\u6210\u6743\u91cd\u6765\u63a7\u5236\u4e0d\u540c\u901a\u9053\u7684\u91cd\u8981\u6027 \uff081 \u4e2a\u8f93\u5165\uff0c\u591a\u4e2a\u901a\u9053\uff0c\u901a\u8fc7\u901a\u9053\u8c03\u6574\u7ef4\u5ea6\uff09</li> <li>\u7b2c\u4e8c\u4e2a\uff1a\u53ef\u4ee5\u770b\u5230\u8f93\u5165\u5206\u522b\u901a\u8fc7\u4e24\u4e2a\u5206\u652f\uff0c\u5e76\u4e14\u8fd9\u4e24\u4e2a\u5206\u652f\u7684\u64cd\u4f5c\u662f\u4e00\u81f4\u7684\uff0c\u4f46\u662f\u5728\u7b2c\u4e8c\u4e2a\u5206\u652f\u4e2d\u989d\u5916\u6dfb\u52a0\u4e86\u4e00\u4e2a\u95e8\u63a7\u5355\u5143\uff0c\u4e5f\u5c31\u662fSigmoid \u51fd\u6570\u6765\u751f\u6210\u6743\u91cd\uff0c\u8868\u793a\u8fd9\u4e2a\u6743\u91cd\u548c\u7b2c\u4e00\u4e2a\u5206\u652f\u7684\u8f93\u51fa\u8fdb\u884c\u76f8\u4e58\uff0c\u6765\u9009\u62e9\u4e00\u90e8\u5206\u4fe1\u606f\u8fdb\u884c\u8f93\u51fa\uff0c\u8fd9\u662f\u95e8\u63a7\u5355\u5143\u7684\u7b2c\u4e8c\u4e2a\u5e94\u7528\u751f\u6210\u6743\u91cd\u6765\u9009\u62e9\u4e00\u90e8\u5206\u6709\u7528\u7684\u4fe1\u606f\uff081\u4e2a\u8f93\u5165\uff0c\u81ea\u8eab\u95e8\u63a7\uff09</li> <li> <p>\u7b2c\u4e09\u4e2a\uff1a\u95e8\u63a7\u5355\u5143\u7528\u4e8e\u878d\u5408\uff0c\u53ef\u4ee5\u770b\u5230\u95e8\u63a7\u5355\u5143\u63a5\u53d7\u4e24\u4e2a\u4e0d\u540c\u6a21\u5757\u7684\u8f93\u51fa\u6765\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f9d\u9760\u4e24\u90e8\u5206\u7684\u4fe1\u606f\u6765\u751f\u6210\u6743\u91cd $a(0&lt;a&lt;1) $ \uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e2a\u6743\u91cd \\(a\\) \u4e0e\u7b2c\u4e00\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\u8fdb\u884c\u76f8\u4e58\uff0c\u4f7f\u7528 \\((1-a)\\) \u4e0e\u7b2c\u4e8c\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\u8fdb\u884c\u76f8\u4e58\uff0c\u7136\u540e\u4e24\u90e8\u5206\u518d\u8fdb\u884c\u62fc\u63a5(add)\u6216\u8005\u76f8\u4e58\uff0c\u5f97\u5230\u878d\u5408\u540e\u7684\u4fe1\u606f\u8868\u793a\uff0c\u8fd9\u662f\u95e8\u63a7\u5355\u5143\u7684\u7b2c\u4e09\u4e2a\u5e94\u7528\uff0c\u751f\u6210\u6743\u91cd\u6765\u878d\u5408\u4e24\u90e8\u5206\u7684\u4fe1\u606f\u8868\u793a\uff082 \u4e2a\u8f93\u5165\uff09</p> </li> <li> <p>\u7b2c\u56db\u4e2a\uff1a\uff08\u591a\u4e2a\u8f93\u5165\uff0csigmoid \u6743\u91cd\uff0csoftmax \u6743\u91cd\u4ea4\u4e92\uff09</p> </li> </ul>"},{"location":"Reproduction/3/#agent-attention","title":"Agent attention","text":"<p>\u7ebf\u6027\u6ce8\u610f\u529b\u76f8\u5173</p> <p>\\(\\text{agent\\ attention}\\) \uff1asoftmax\u548c\u7ebf\u6027\u6ce8\u610f\u529b\u7684\u96c6\u6210</p> <p>\u672c\u6587\u7684\u7814\u7a76\u52a8\u673a\u662f \u81ea\u6ce8\u610f\u529b\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u9650\u5236\u4e86\u5176\u5728\u5404\u79cd\u573a\u666f\u4e2d\u7684\u9002\u7528\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6ce8\u610f\u529b\u8303\u5f0f\uff0c\u4ee3\u7406\u6ce8\u610f\u529b\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u8868\u793a\u80fd\u529b\u4e4b\u95f4\u53d6\u5f97\u6709\u5229\u7684\u5e73\u8861\u3002</p> <p>\u7ebf\u6027\u6ce8\u610f\u529b\u7684\u52a8\u673a\u90fd\u662f\u4e00\u81f4\u7684\uff0c\u90a3\u5c31\u662f\u4f20\u7edf\u6ce8\u610f\u529b\u7684\u4e8c\u6b21\u590d\u6742\u5ea6</p> <p>\u90a3\u4e48\u80fd\u505a\u7684\u6539\u8fdb\u5462\uff1f \u5c31\u662f\u5728\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5177\u4f53\u800c\u8a00\uff0c\u8868\u793a\u4e3a\u56db\u5143\u7ec4(Q,A,K,V)\u7684agent\u6ce8\u610f\u529b\uff0c\u5c06\u4e00\u7ec4\u989d\u5916\u7684agent tokens\uff0c\u5f15\u5165\u5230\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u6a21\u5757\u4e2d\uff0c\u4f20\u7edf\u7684\u6ce8\u610f\u529b\uff0c\u662f (Q,K,V)\uff0cQ\u548cK\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5\uff0c\u5f97\u5230\u6743\u91cd\u77e9\u9635\uff0c\u7136\u540e\u6839\u636e\u8fd9\u4e2a\u6743\u91cd\u77e9\u9635\uff0c\u5bf9\u8fd9\u4e2avalue\u77e9\u9635\u8fdb\u884c\u52a0\u6743</p> <p>\\(\\text{agent\\ attention}\\) \u662f\u5728QKV\u7684\u57fa\u7840\u4e0a\u6dfb\u52a0\u4e86\u4e00\u4e2aA\u77e9\u9635\uff0c\u4e5f\u5c31\u662f\u4f5c\u8005\u5728\u8fd9\u91cc\u63d0\u5230\u7684agent tokens\uff0c\u8fd9\u4e2aagent tokens\uff0c\u9996\u5148\u5145\u5f53 Q \u77e9\u9635\u7684\u4ee3\u7406\uff0c\u4ee5\u805a\u5408\u6765\u81eaK\u548cV\u7684\u4fe1\u606f\uff0c\u7136\u540e\u5c06\u4fe1\u606f\u5e7f\u64ad\u56de Q</p> <p>\u4ee5\u4e0a\u6d89\u53ca\u5230\u4e86\u4e24\u4e2a\u64cd\u4f5c\uff1a\u805a\u5408\u548c\u5e7f\u64ad</p> <p>\u4e3e\u4e2a\u6700\u7b80\u5355\u7684\u4f8b\u5b50\uff0c\uff08\u805a\u5408\uff09 \u4f8b\u5982\u6709\u4e09\u4e2a\u5411\u91cfABC\uff0c\u6211\u4eec\u628a\u5b83\u4eec\u8fdb\u884c\u76f8\u52a0\u6216\u8005\u8bf4\u662f\u52a0\u6743\u6c42\u548c\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u5411\u91cfD\uff0c\u8fd9\u6837\u7684\u8fc7\u7a0b\u53eb\u505a\u805a\u5408\u3002==\uff08\u5e7f\u64ad\uff09==\u90a3\u4e48\u76f8\u53cd\uff0c\u5982\u679c\u6211\u4eec\u628a\u5411\u91cfD\u5206\u522b\u6dfb\u52a0\u5230\u5411\u91cfABC\u4e0a\uff0c\u4f7f\u8fd9\u4e09\u4e2a\u5411\u91cf\u5440\u90fd\u5177\u6709\u4e86D\u5411\u91cf\u7684\u4fe1\u606f\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5c31\u53eb\u505a\u5e7f\u64ad\u3002</p> <p>\u90a3\u4e48\u76f4\u89c2\u4e0a\u7b80\u5355\u6765\u8bf4\u5c31\u662f\uff1a\u5728M\u8fdc\u8fdc\u5927\u4e8eN\u7684\u60c5\u51b5\u4e0b\uff0c</p> <p>\uff08 1\uff09 \u4fe1\u606f\u4eceM\u4e2a\u6c60\u5b50\u5f15\u5165N\u4e2a\u6c60\u5b50\u53eb\u505a\u805a\u5408</p> <p>\uff082\uff09\u4fe1\u606f\u4eceN\u4e2a\u6c60\u5b50\u5f15\u5165M\u4e2a\u6c60\u5b50\u53eb\u505a\u5e7f\u64ad</p> <p>\u90a3\u4e48\u805a\u5408\u548c\u5e7f\u64ad\u548c\u6ce8\u610f\u529b\u600e\u4e48\u8054\u7cfb\u5728\u4e00\u5757\u5462\uff0c\u6211\u4eec\u6765\u770b\u8fd9\u4e2a\u56fe</p> <p></p> <p>\u6ce8\u610f\u529b\u6709\u4e24\u79cd\u7c7b\u578b\u2460 \u4e00\u79cd\u662f\u81ea\u6ce8\u610f\u529b \u2461 \u4e00\u79cd\u662f\u4ea4\u53c9\u6ce8\u610f\u529b</p> <ul> <li>\u81ea\u6ce8\u610f\u529bQKV\u7684\u7ef4\u5ea6\u5e94\u5f53\u662f\u4e00\u81f4\u7684\uff0c\u8fd9\u6837\u7684\u8bdd\u5c31\u505a\u4e0d\u5230\u805a\u5408\u548c\u5e7f\u64ad</li> <li>\u4f46\u662f\u4ea4\u53c9\u6ce8\u610f\u529b\uff0cQ\u7684\u7ef4\u5ea6\u548cKV\u53ef\u4ee5\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u4f46\u662fKV\u7684\u6765\u6e90\u662f\u76f8\u540c\u7684\uff0c\u800c\u4e14\u6700\u91cd\u8981\u7684\u4e00\u70b9\u662f\u6ce8\u610f\u529b\u7684\u8f93\u51fa\u548cQ\u77e9\u9635\u7684shape\u662f\u4e00\u81f4\u7684</li> </ul> <p>\uff081\uff09\u5f53Q\u77e9\u9635\u7684token\u7684\u6570\u91cf\uff0c\u4e5f\u5c31\u662f\u8fd9\u4e2a==M\u5c0f\u4e8eKV==\u7684\u65f6\u5019\uff0c\u90a3\u4e48\u8fd9\u4e2a\u6ce8\u610f\u529b\u5c31\u53ef\u4ee5\u770b\u4f5c\u662f\u4e00\u4e2a==\u805a\u5408==\u64cd\u4f5c\uff0c\u6839\u636e\u8fd9\u4e2a\u6ce8\u610f\u529b\u77e9\u9635\u6765\u805a\u5408\u6765\u81eavalue\u77e9\u9635\u7684\u4fe1\u606f \uff082\uff09\u5f53\u8fd9\u4e2aQ\u77e9\u9635\u7684token\u6570\u91cf\u5927\u4e8eKV\u7684\u65f6\u5019\uff0c\u8fd9\u4e2a\u6ce8\u610f\u529b\u77e9\u9635\u5c31\u53ef\u4ee5\u770b\u4f5c\u662f\u4e00\u4e2a\u5e7f\u64ad\u64cd\u4f5c\uff0c\u6839\u636e\u8fd9\u4e2a\u6ce8\u610f\u529b\u77e9\u9635\uff0c\u628avalue\u4fe1\u606f\u5e7f\u64ad\u5230M\u4e2atoken\u4e2d</p> <p>\u4f5c\u8005\u5728\u8fd9\u91cc\u63d0\u5230\u4e86\u805a\u5408\u548c\u5e7f\u64ad\uff0c\u5c31\u610f\u5473\u7740\u53ef\u80fd\u5b58\u5728\u4e24\u9636\u6bb5\u6ce8\u610f\u529b</p> <p>\u4f5c\u8005\u63d0\u5230\u9274\u4e8eagent\u7684tokens\u7684\u6570\u91cf\u53ef\u4ee5\u8bbe\u8ba1\u4e3a\u6bd4Q\u77e9\u9635token\u7684\u6570\u91cf\u5c0f\u5f97\u591a\uff0cagent\u7684\u6ce8\u610f\u529b\uff0c\u660e\u663e\u6bd4\u5e7f\u6cdb\u91c7\u7528\u7684softmax\u6ce8\u610f\u529b\u66f4\u6709\u6548\uff0c\u540c\u65f6\u4fdd\u7559\u5168\u5c40\u4e0a\u4e0b\u6587\u7684\u5efa\u6a21\u80fd\u529b</p> <p>\u9996\u5148\u770b\u8ba1\u7b97\u8fc7\u7a0b\uff1a\u5982\u679cagent\u7684tokens\u7684\u6570\u91cf\u5f88\u5c11\uff0c\u90a3\u4e48\u8fd9\u4e2a\\(N\u00d7N\\)\u7684\u6ce8\u610f\u529b\u77e9\u9635\uff0c\u5c31\u53ef\u4ee5\u964d\u4f4e\u4e3aN\u4e58M\uff0c\u8fd9\u4e2aM\u662f\u8fdc\u8fdc\u5c0f\u4e8eN\u7684\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u590d\u6742\u5ea6\u662f\u964d\u4f4e\u4e86\uff0c\u6211\u4eec\u6765\u5bf9\u6bd4\u4e00\u4e0bsoftmax\u7684\u6ce8\u610f\u529b\u3001\u7ebf\u6027\u6ce8\u610f\u529b\u3001\u672c\u6587\u63d0\u51fa\u7684 \\(\\text{agent attention}\\)</p> <p></p> <p>case1 softmax \u6ce8\u610f\u529b \uff1a\u8fd9\u4e2asoftmax\u6ce8\u610f\u529b\u5c31\u662f\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0cQ\u548cK\u5148\u6267\u884c\u77e9\u9635\u4e58\u6cd5\uff0c\u7136\u540esoftmax\u64cd\u4f5c\uff0c\u8fd9\u662f\u6700\u8017\u65f6\u7684\u64cd\u4f5c\u4e86\uff0c\u5e76\u4e14\u5177\u6709\u4e8c\u6b21\u65b9\u7684\u8ba1\u7b97\u590d\u6742\u5ea6</p> <p>case2 \u7ebf\u6027\u6ce8\u610f\u529b\uff1a\u8ba9K\u548cV\u5148\u505a\u77e9\u9635\u4e58\u6cd5\uff0c\u7136\u540e\u518d\u4e0e\u8fd9\u4e2aK\u505a\u77e9\u9635\u4e58\u6cd5\uff0c\u8fd9\u6837\u7684\u8bdd\uff0c\u5c31\u5de7\u5999\u7684\u907f\u5f00\u4e86\u4e8c\u6b21\u65b9\u7684\u8ba1\u7b97\u548csoftmax\u64cd\u4f5c</p> <p>case3     \\(\\text{agent attention}\\) \u6709\u4e09\u70b9\u9996\u5148\u6ce8\u610f\uff1a</p> <p>\u2460 \u7b2c\u4e00\u70b9\u6709\u56db\u4e2a\u8f93\u5165\uff0c\u5206\u522b\u662fQKV\u4ee5\u53ca\u8fd9\u4e2aA\u77e9\u9635\uff0c\u9996\u5148\uff0cQKV\u7684\u7ef4\u5ea6\u662f\u76f8\u540c\u7684\uff0c\u5e76\u4e14\u548c\u8fd9\u4e2aA\u77e9\u9635\u7684\u7ef4\u5ea6\u4e0d\u540c\uff0c\u5176\u4e2d A\u77e9\u9635\u4e2d\u7684token\u6570\u91cf $ n \\ll N$ </p> <p>N\u662f Q \u77e9\u9635\u7684 token \u6570\u91cf</p> <p>\u2461 \u7b2c\u4e8c\u70b9\u53ef\u4ee5\u770b\u5230\u8fd9\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6ce8\u610f\u529b\uff0c\u5de6\u4fa7\u4e00\u4e2a\uff0c\u53f3\u4fa7\u4e00\u4e2a\uff0c\u5e76\u4e14\u90fd\u662f\u5e26\u6709softmax\u64cd\u4f5c\u7684</p> <p>\u2462 \u7b2c\u4e09\u70b9\u5982\u56fe\u6240\u793a\uff0c\u662f\u53ea\u6709\u4e00\u4e2a\u8f93\u51fa\u7684\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u4e24\u4e2a\u6ce8\u610f\u529b\uff0c\u662f\u8054\u52a8\u7684</p> <p>\uff08\u53f3\u8fb9\u6ce8\u610f\u529b\uff09\u7136\u540e\u6211\u4eec\u6765\u4ed4\u7ec6\u770b\u4e00\u4e0b\u53f3\u8fb9\u6ce8\u610f\u529b\uff0c\u63a5\u53d7\u7684\u662fAKV\u4f5c\u4e3a\u8f93\u5165\uff0c\u5176\u4e2d\u4f5c\u8005\u5728\u8fd9\u91cc\u6807\u6ce8A\u77e9\u9635\u662f\u5145\u5f53Q\u77e9\u9635\u7684\uff0c\u90a3\u4e48\u5f88\u663e\u7136\u8fd9\u5e94\u5f53\u662f\u4e00\u4e2a\u805a\u5408\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u805a\u5408value\u77e9\u9635\u4e2dN\u4e2atoken\u4fe1\u606f\u7684</p> <p>\uff08\u5de6\u8fb9\u6ce8\u610f\u529b\uff09\u5de6\u8fb9\u6ce8\u610f\u529b\u4e5f\u63a5\u6536\u4e86\u4e09\u4e2a\u8f93\u5165\uff0c\u5206\u522b\u662fQA\u4ee5\u53ca\u53f3\u4fa7\u6ce8\u610f\u529b\u7684\u8f93\u51fa\uff0c\u4f5c\u4e3avalue\u77e9\u9635\uff0c\u6b64\u65f6A\u77e9\u9635\u5728\u5de6\u4fa7\u6ce8\u610f\u529b\u4e2d\u5145\u5f53K\u77e9\u9635\uff0c\u8fd9\u662f\u4e00\u4e2a\u5e7f\u64ad\u6ce8\u610f\u529b\uff0c\u5c06 A \u77e9\u9635\u7684\u4e2d n\u4e2atoken\u7684\u4fe1\u606f\u5e7f\u64ad\u56deQ \u77e9\u9635\u4e2d\u7684 N \u4e2a\u7684token\u4e2d\u53bb\uff08\u8fd9\u4e2a\u601d\u60f3\u975e\u5e38\u5e38\u89c1\uff1a\u56de\u987e\u4e00\u4e0b\u901a\u9053\u6ce8\u610f\u529b\uff0c\u4f7f\u7528\u4e24\u5c42\u5168\u8fde\u63a5\u6765\u5efa\u6a21\u901a\u9053\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5148\u964d\u7ef4\u540e\u5347\u7ef4\u5ea6\uff0c\u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u4f7f\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u5462\uff0c\u56e0\u4e3a\u590d\u6742\u5ea6\u9ad8\uff0c\u5148\u964d\u7ef4\u540e\u5347\u4e3a\u53c2\u6570\u91cf\u66f4\u5c11\uff0c\u8ba1\u7b97\u66f4\u5feb\uff0c\u8fd9\u91cc\u7684 \\(\\text{agent attention}\\)  \u548c  \\(\\text{SE net}\\)   \u5b9e\u9645\u662f\u4e00\u4e2a\u9053\u7406\uff09</p> <p>\u4ee5\u4e0a\u662f Agent \u6ce8\u610f\u529b\u7684\u601d\u60f3\u3002</p> <p>\u8fd8\u6709\u4e09\u4e2a\u95ee\u9898\u9700\u8981\u8003\u8651\uff1a \ud83d\udd34 \u7b2c\u4e00\u4e2a\u95ee\u9898\uff1aA\u77e9\u9635\u662f\u600e\u4e48\u6765\u7684\uff1f</p> <p>Agent\u6ce8\u610f\u529b\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6ce8\u610f\u529b\u5148\u805a\u5408\u518d\u5e7f\u64ad\uff0c\u90a3\u4e48\u8fd9\u4e2aA\u77e9\u9635\uff0c\u5b83\u5728\u805a\u5408value\u77e9\u9635\u4fe1\u606f\u7684\u65f6\u5019\uff0c\u5b83\u9700\u8981\u81ea\u8eab\u542b\u6709\u4e00\u5b9a\u7684\u4fe1\u606f\u5417\uff1f\u4e5f\u4e0d\u4e00\u5b9a\uff0c1\ufe0f\u20e3 \u6240\u4ee5\u8bf4\u5b83\u53ef\u4ee5\u662f\u968f\u673a\u521d\u59cb\u5316\u5f97\u5230\u7684\uff0c2\ufe0f\u20e3 \u90a3\u4e48\u5f53\u7136\u4e5f\u53ef\u4ee5\u4e8b\u5148\u5305\u542b\u4e00\u90e8\u5206\u5148\u9a8c\u4fe1\u606f\uff0c\u53ef\u4ee5\u4f7f\u7528\u805a\u7c7b\u6216\u8005\u8bf4\u662f\u6c60\u5316\u4e0b\u91c7\u6837\u64cd\u4f5c\uff0c\u53ef\u4ee5\u4ece\u539f\u59cb\u7279\u5f81\u4e2d\u91c7\u96c6\u4e00\u90e8\u5206\u4fe1\u606f\u6765\u4f5c\u4e3aA\u77e9\u9635</p> <p>\ud83d\udd34 \u7b2c\u4e8c\u4e2a\u95ee\u9898\uff1a\u7ebf\u6027\u6ce8\u610f\u529b\u7684\u6027\u80fd\u771f\u7684\u597d\u5417\uff1f</p> <p>\u5728ReLu\u7ebf\u6027\u6ce8\u610f\u529b\u4e2d\uff0c\u6709\u4e00\u53e5\u8bdd\u662f\u8fd9\u6837\u63cf\u8ff0\u7684\uff0c\u7531\u4e8e\u7f3a\u4e4f\u5c40\u90e8\u4fe1\u606f\u63d0\u53d6\u548c\u591a\u5c3a\u5ea6\u7684\u5b66\u4e60\u80fd\u529b\uff0cReLu \u5355\u72ec\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u80fd\u529b\u6709\u9650\uff0c\u56e0\u6b64\u4f5c\u8005\u63d0\u51fa\u7528\u5377\u79ef\u6765\u589e\u5f3a ReLu \u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u5e76\u5f15\u5165\u4e86\u591a\u5c3a\u5ea6\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u6765\u89e3\u51b3 ReLu \u7ebf\u6027\u6ce8\u610f\u529b\u7684\u80fd\u529b\u9650\u5236\uff0c\u90a3\u4e48\u8fd9\u4e2aAgent \u6ce8\u610f\u529b\u662f\u5426\u6709\u540c\u6837\u7684\u95ee\u9898\uff1f\u5f88\u76f8\u4f3c\uff0cAgent \u6ce8\u610f\u529b\u539f\u6587\u4e2d\u6709\u7c7b\u4f3c\u7684\u4e00\u53e5\u8bdd\uff1a<code>\u5c3d\u7ba1Agent\u7684\u6ce8\u610f\u529b\u53d7\u76ca\u4e8e\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u9ad8\u6a21\u578b\u8868\u8fbe\u6027\uff0c\u4f46\u4f5c\u4e3a\u5e7f\u4e49\u7684\u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u4e5f\u53d7\u5230\u4e86\u7279\u5f81\u591a\u6837\u6027\u4e0d\u8db3\u7684\u5f71\u54cd</code></p> <p>\u4f5c\u4e3a\u8865\u6551\u63aa\u65bd\uff0cAgent \u6ce8\u610f\u529b \u91c7\u7528\u6df1\u5ea6\u5377\u79ef\u64cd\u4f5c\u6765\u4fdd\u6301\u7279\u5f81\u591a\u6837\u6027</p> <p>\u5b8c\u6574\u7684\u6d41\u7a0b\u56fe\uff1a</p> <p></p> <p>\u8c28\u8bb0\uff1a \\(softmax(QK^T)V\\) </p> <p>Agent \u6ce8\u610f\u529b\u56fe\u63cf\u8ff0\uff1a\u9996\u5148\u901a\u8fc7\u4e09\u4e2a\u7ebf\u6027\u53d8\u6362 \\(W_Q\u3001W_K\u3001W_V\\) \u5f97\u5230  \\(Q\u3001K\u3001V\\) \uff0c\u63a5\u4e0b\u6765\u5bf9 Q \u77e9\u9635\u8fdb\u884c\u4e0b\u91c7\u6837Pooling\u5f97\u5230Agent Tokens \\(A\\) \uff0c\u2460 \u9996\u5148\u8fd9\u4e2a Agent tokens \u5145\u5f53 query \u4e0e\u539f\u59cb\u662f KV \u8fdb\u884c softmax \u548c\u6ce8\u610f\u529b\u64cd\u4f5c\uff0c\u4e5f\u5c31\u662f  \\(V_A = softmax(AK^T)V\\)  \uff08A \u77e9\u9635\u805a\u5408 Vlaue \u7684\u4fe1\u606f\uff09\u2461  \\(V_A\\) \u77e9\u9635\u5145\u5f53 key\uff0c\u8fdb\u884c softmax\uff0c\u4e5f\u5c31\u662f \\(softmax(QA^T)V_A\\)    \uff08A \u77e9\u9635\u5e7f\u64ad Value \u7684\u4fe1\u606f\uff09</p> <p>\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff1a</p> <p>\u4f5c\u8005\u6dfb\u52a0\u4e86\u6df1\u5ea6\u5377\u79ef\u64cd\u4f5cDWC\uff0c\u4ee5\u53ca\u901a\u8fc7\u6c60\u5316\u5462\u6765\u6784\u9020A\u77e9\u9635</p> <p>\ud83d\udd34 \u7b2c\u4e09\u4e2a\u95ee\u9898\uff1a\u5728\u8fd9\u4e2a\u56fe\u4e2d\uff0c\u8fd8\u6709\u4e00\u4e2a\u6ca1\u6709\u63d0\u5230\u7684\u6a21\u5757agent bias</p> <p>\u4f5c\u8005\u7684\u51fa\u53d1\u70b9\uff0c\u662f\u4e3a\u4e86\u66f4\u597d\u7684\u5229\u7528\u4f4d\u7f6e\u4fe1\u606f\uff0c\u4ece\u800c\u4e3aagent\u7684\u6ce8\u610f\u529b\u7684\u4e24\u9636\u6bb5\u5206\u522b\u6dfb\u52a0\u4e86agent bias\uff0c\u4ece\u865a\u7ebf\u6307\u5411\u53ef\u4ee5\u770b\u5230\u5b83\u4eec\u662f\u5206\u522b\u6dfb\u52a0\u5230\u6ce8\u610f\u529b\u77e9\u9635\u4e0a\u7684\uff0c \u6240\u4ee5 \\(shape\\in N\u00d7 n\\)\uff0c\u4f5c\u8005\u6ca1\u6709\u968f\u673a\u521d\u59cb\u5316\u8fd9\u4e2a\u504f\u7f6e\u77e9\u9635\uff0c\u800c\u662f\u901a\u8fc7\u4e09\u4e2a\u5206\u91cf\u6765\u6784\u5efa\u7684\uff0c\u540e\u9762\u53bb\u770b\u4ee3\u7801\u628a\u3002</p> <p>\u603b\u7ed3\u4e00\u4e0b\uff0cAgent \u6ce8\u610f\u529b\u7684\u601d\u60f3\uff1a\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5f15\u5165\u805a\u5408\u548c\u5e7f\u64ad\u7684\u6982\u5ff5\uff0c\u5bf9\u539f\u59cb Query \u77e9\u9635\u8fdb\u884c\u4e0b\u91c7\u6837\uff0c\u5f97\u5230 Agent\uff0c\u4e0e\u539f\u59cb KV \u8fdb\u884c\u6ce8\u610f\u529b\u8ba1\u7b97\u805a\u5408 V \u7684\u4fe1\u606f\uff0c\u5f97\u5230\u7684\u662f \\(V_A\\) \uff0c\u540c\u65f6\u8fd9\u4e2a Agent \u8fd8\u4f5c\u4e3a key\uff0c\u518d\u7ed3\u5408\u805a\u5408\u5f97\u5230\u7684 \\(V_A\\) \uff0c\u5f97\u5230\u4e86\u8f93\u51fa\u3002\u8fd8\u6709\u63d0\u4e86\u4e00\u5634\u7684 DWC \u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u548c Agent Bias</p>"},{"location":"Reproduction/3/#relu","title":"ReLU \u7ebf\u6027\u6ce8\u610f\u529b","text":"<p>ICCV2023</p> <p>\u8fd9\u662f\u4e00\u4e2a\u591a\u5c3a\u5ea6\u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u7b97\u6cd5\u7684\u6838\u5fc3\u662f\u591a\u5c3a\u5ea6\u6027\u548c\u590d\u6742\u6027</p> \u968f\u624b\u8865\u5145 <p> \u901a\u7528\u4e94\u5927\u6027\u8d28\uff1a\u5c40\u90e8\u6027\u3001\u5168\u5c40\u6027\u3001\u7a00\u758f\u6027\u3001\u591a\u5c3a\u5ea6\u6027\u3001\u590d\u6742\u6027 </p> <p>\u672c\u6587\u6307\u51fa\uff0c\u4e0e\u4f9d\u8d56\u4e8esoftmax\u6ce8\u610f\u529b\uff0c\u786c\u4ef6\u4f4e\u6548\u7684\u5927\u6838\u5377\u79ef\u6216\u590d\u6742\u62d3\u6251\u7ed3\u6784\uff0c\u6765\u83b7\u5f97\u826f\u597d\u6027\u80fd\u7684\u73b0\u6709\u9ad8\u5206\u8fa8\u7387\u5bc6\u96c6\u9884\u6d4b\u6a21\u578b\u4e0d\u540c</p> \u968f\u624b\u8865\u5145 <p> \u4f5c\u8005\u63d0\u5230\u4e4b\u524d\u7684\u65b9\u6cd5\uff0c\u8981\u4e0d\u7136\u662f\u57fa\u4e8esoftmax\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8981\u4e48\u662f\u5177\u6709\u5927\u5377\u79ef\u6838\u7684\u5377\u79ef\u7f51\u7edc\uff0c\u8981\u4e0d\u7136\u5c31\u662f\u5927\u529b\u51fa\u5947\u8ff9\u7684\u6a21\u578b \u4f17\u6240\u5468\u77e5\uff0csoftmax\uff0c\u6307\u6570\u8ba1\u7b97\u5f88\u8017\u8d39\u65f6\u95f4\uff0c\u786c\u4ef6\u5bf9\u4e8e\u5927\u6838\u5377\u79ef\u662f\u4f4e\u6548\u7684 (\u53ef\u80fd\u6ca1\u6709\u4e13\u95e8\u7684\u4f18\u5316\uff0c\u5927\u6982\u662f\u8fd9\u4e2a\u610f\u601d)\uff0c\u5177\u6709\u590d\u6742\u62d3\u6251\u7ed3\u6784\u7684\u6a21\u578b\uff0c\u5c31\u662f\u4f7f\u52b2\u5806\u6a21\u5757\uff0c\u7ed9\u6a21\u578b\u4e0a\u5f3a\u5ea6\uff0c\u8fd9\u6837\u7684\u6a21\u578b\u4e00\u822c\u6027\u80fd\u8fd8\u4e0d\u9519\uff0c\u4f46\u662f\u590d\u6742\u5ea6\u53ef\u80fd\u4f1a\u5f88\u9ad8 </p> <p>\u4f5c\u8005\u63d0\u51fa\u7684\u591a\u5c3a\u5ea6\u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u4ec5\u901a\u8fc7\u8f7b\u91cf\u7ea7\u548c\u786c\u4ef6\u9ad8\u6548\u7684\u64cd\u4f5c\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u611f\u53d7\u91ce\u548c\u591a\u5c3a\u5ea6\u5b66\u4e60\uff0c\u8fd9\u662f\u9ad8\u5206\u8fa8\u7387\u5bc6\u96c6\u9884\u6d4b\u7684\u4e24\u4e2a\u7406\u60f3\u7279\u5f81\u3002</p> <p>\u5168\u5c40\u611f\u53d7\u91ce &amp; \u591a\u5c3a\u5ea6\u5b66\u4e60</p> <p>\u6765\u770b\u6a21\u578b\u56fe\uff1a</p> <p></p> <p>\u5de6\u8fb9\u662f\u4e00\u4e2a\u6574\u4f53\u67b6\u6784\uff0c\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u4e00\u4e2a\u591a\u5c3a\u5ea6\u7684\u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u7136\u540e\u63a5\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u548cDW\u5377\u79ef\u5f97\u5230\u8f93\u51fa</p> <p>\u53f3\u56fe\u662f\u591a\u5c3a\u5ea6\u7ebf\u6027\u6ce8\u610f\u529b\u6709\u4e09\u4e2a\u5206\u652f\uff0c\u6bcf\u4e2a\u5206\u652f\u90fd\u6709\u4e00\u4e2aReLU\u7ebf\u6027\u6ce8\u610f\u529b</p> <p></p> <p>\u77e5\u4e4e\u4e0a\u4f5c\u8005\u7684\u8be6\u89e3\uff0c\u6700\u5de6\u8fb9\u662f\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b83\u4e3b\u8981\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u6765\u6e90\u4e8eQ\u77e9\u9635\u548cK\u77e9\u9635\u7684\u76f8\u4e58\uff0c \u8ba1\u7b97\u6210\u672c\u662f\\(N^2\\)\uff0c\u60f3\u8981\u964d\u4f4e\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5e76\u4e14\u8981\u4fdd\u6301QKV\u6574\u4f53\u6846\u67b6\u4e0d\u53d8\uff0c\u53ef\u4ee5\u4ece\u8fd9\u4e2a\u6ce8\u610f\u529b\u77e9\u9635\u7684\u8ba1\u7b97\u5165\u624b\u3002</p> <p>\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u4f7f\u7528\u7684\u662fQ\u548cK\u7684\u70b9\u79ef\uff0c\u7136\u540e\u63a5\u4e00\u4e2asoftmax\u64cd\u4f5c\uff0c\u8fd9\u91cc\u8981\u505a\u7684\u5c31\u662f\u66ff\u6362\u70b9\u79ef\u548csoftmax\u64cd\u4f5c\uff0c\u5728\u8fd9\u91cc\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u91cd\u65b0\u5b9a\u4e49\u5173\u4e8eQ\u548cK\u7684\u76f8\u4f3c\u5ea6\u51fd\u6570</p> <p>\u770b\u4e2d\u95f4\u7b49\u5f0f\uff1a $$ Sim(Q,K)=ReLU(Q)ReLU(K)^T $$ \u770b\u8fd9\u4e2a\u7b49\u5f0f\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u6ce8\u610f\u529b\uff0c\u5b9e\u9645\u5c31\u662f\u4e3aQ\u548cK\u6dfb\u52a0\u4e86 ReLU \u64cd\u4f5c\uff0c\u5e76\u4e14\u53bb\u6389\u4e86softmax\u64cd\u4f5c\uff0c\u770b\u89c1\u8fd9\u4e2a\u8fd8\u633a\u8ff7\u7cca\u7684\uff0c\u597d\u50cf\u53d8\u4e86\u53c8\u597d\u50cf\u6ca1\u6709\u53d8</p> <p>\u7b2c\u4e09\u4e2a\u56fe\uff0c\u4f5c\u8005\u5229\u7528\u77e9\u9635\u4e58\u6cd5\u7684\u6027\u8d28\uff0c(ab)c = a(bc)\uff0c\u53d8\u6210K\u548cV \u5148\u8ba1\u7b97\uff0cQ \u6458\u51fa\u6765\uff0c\u5206\u5b50\u5206\u6bcd\u90fd\u662f\u7684\uff0c\u90fd\u662f\u628a Q \u6458\u51fa\u6765\u4e86\u3002</p> <p>\u7ecf\u8fc7\u4ee5\u4e0a\u4e24\u4e2a\u64cd\u4f5c\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u6539\u53d8\u6ce8\u610f\u529b\u529f\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c \u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u5185\u5b58\u5360\u7528\u4ece\u4e8c\u6b21\u964d\u4f4e\u5230\u4e86\u7ebf\u6027\uff0c\u7b80\u5355\u70b9\u8bf4\u5c31\u662f\uff1a\u5148\u8ba1\u7b97K\u548cV\u7684\u4e58\u79ef\uff0c\u518d\u8ba1\u7b97\u5b83\u4eec\u4e0e Q  \u7684\u4e58\u79ef</p> <p>\u518d\u770b\uff1a</p> <p> </p> <p>\u518d\u6765\u770b\u8fd9\u4e2a\u591a\u5c3a\u5ea6\u7ebf\u6027\u6ce8\u610f\u529b\uff0c \ud83d\udd34 \u5728\u8fd9\u91cc\u4e3a\u4ec0\u4e48\u8981\u8bbe\u7f6e\u4e09\u4e2a\u5206\u652f\u5462\uff1f\u5176\u4e2d\u4e24\u4e2a\u5206\u652f\u8fd8\u5e26\u67093\u00d73\u548c5\u00d75\u7684\u5377\u79ef</p> <p>\u4f5c\u8005\u5728\u8bba\u6587\u4e2d\u7528\u5b9e\u9a8c\u8bc1\u660e\u4e86\uff0c\u7531\u4e8e\u6539\u8fdb\u540e\u7684\u8fd9\u4e2a \\(ReLU\\) \u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u4e0d\u518d\u662fQ\u548cK\u4e4b\u95f4\u7684\u70b9\u51fb\u64cd\u4f5c\u4e86\uff0c\u5b83\u7f3a\u5931\u4e86\u975e\u7ebf\u6027\u7684\u56e0\u7d20\uff0c\u6240\u4ee5\u8bf4\u5b83\u5728\u63d0\u53d6\u5c40\u90e8\u7279\u5f81\u65b9\u9762\u4e5f\u662f\u6bd4\u8f83\u5dee\u7684\uff0c\u56e0\u6b64\u4f5c\u8005\u5728\u8fd9\u4e24\u4e2a\u5206\u652f\u4e2d\u8865\u5145\u4e86\u5377\u79ef\u64cd\u4f5c\uff08\u5e94\u8be5\u662f\u505a\u4e86\u5f88\u591a\u5b9e\u9a8c\u8bd5\u51fa\u6765\u7684\uff09\uff0c\u6765\u589e\u5f3a\u5c40\u90e8\u5efa\u6a21\u7684\u80fd\u529b\u4ee5\u53ca\u591a\u5c3a\u5ea6\u5efa\u6a21\u7684\u80fd\u529b</p> \u8865\u5145\u4e00\u4e2a\u77e5\u8bc6\u70b9\uff1a\u4e3a\u4ec0\u4e48\u5927\u5bb6\u4e00\u76f4\u5728\u9b54\u6539\u8fd9\u4e2a\u6ce8\u610f\u529b\uff0c\u800c\u4e0d\u5bf9\u540e\u9762\u7684FFN\u8fdb\u884c\u9b54\u6539 <p> \u539f\u56e0\uff1a\u6ce8\u610f\u529b\u673a\u5236\u4e3b\u8981\u662ftoken\u5c42\u6b21\u7684\u878d\u5408\uff0cFFN\u662f\u901a\u9053\u5c42\u6b21\u7684\u878d\u5408\uff0c\u4e24\u8005\u662f\u4e92\u8865\u7684 \u4e0d\u8fc7\uff0c\u4e4b\u524d\u6709\u8bba\u6587\u8bc1\u5b9e\u8fc7\uff0c\u5c06\u8fd9\u4e2a\u6ce8\u610f\u529b\u673a\u5236\u6362\u6210MLP\u6216\u8005\u6c60\u5316\uff0c\u6548\u679c\u4e5f\u8fd8\u4e0d\u9519\uff0c\u4f46\u76ee\u524d\u666e\u904d\u8ba4\u540c\u7684\uff0c\u6ce8\u610f\u529b\u673a\u5236\u7ec8\u5f52\u662f\u5728token\u5c42\u6b21\u4e0a\u505a\u878d\u5408\uff0c\u6548\u679c\u4e5f\u8fd8\u4e0d\u9519\uff0c\u4e24\u8005\u662f\u7f3a\u4e00\u4e0d\u53ef\u7684 </p>"},{"location":"Reproduction/3/#swiftformer","title":"SwiftFormer","text":"<p>ICCV2023</p> <p>\u5f15\u5165\uff1a\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u8ba1\u7b97\uff0c\u590d\u6742\u6027\u6027\u9650\u5236\u4e86\u5176\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\uff0c\u6307\u51fa\u52a8\u673a \u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u3002</p> \u968f\u624b\u8865\u5145 <p>     \u5bf9\u6ce8\u610f\u529b\u673a\u5236\u7684\u6539\u8fdb\uff1a\u590d\u6742\u6027\u3001\u5c40\u90e8\u6027\u3001\u5168\u5c40\u6027\u3001\u7a00\u758f\u6027\u3001\u591a\u5c3a\u5ea6\u6027 </p> <p>\u4f5c\u8005\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6709\u6548\u7684\u52a0\u6cd5\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u7ebf\u6027\u5143\u7d20\u4e58\u6cd5\u6709\u6548\u5730\u66ff\u6362\u4e86\u4e8c\u6b21\u77e9\u9635\u4e58\u6cd5\u8fd0\u7b97\u663e\u8457\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u6355\u83b7\uff0c\u5b9e\u9a8c\u8868\u660e K &amp; Value \u7684\u4ea4\u4e92\u53ef\u4ee5\u7528\u7ebf\u6027\u5c42\u66ff\u4ee3\uff0c\u800c\u4e0d\u4f1a\u6709\u4efb\u4f55\u7cbe\u5ea6\u635f\u5931</p> <p>\ud83d\udccc \u5728\u8fd9\u91cc\u662f\u7528\u7ebf\u6027\u5143\u7d20\u4e58\u6cd5\u66ff\u6362\u4e86\u4e8c\u6b21\u77e9\u9635\u4e58\u6cd5</p> <p>\u7ebf\u6027\u5143\u7d20\u4e58\u6cd5\uff1a\u4e00\u4e2a\u6570\u5b57\u548c\u4e00\u4e2a\u5411\u91cf\u6216\u8005\u77e9\u9635\u76f8\u4e58</p> <p>\u77e9\u9635\u4e58\u6cd5\uff1a\u77e9\u9635\u548c\u77e9\u9635\u7684\u4e58\u6cd5</p> <p>\u56e0\u6b64\u8fd9\u91cc\u4f5c\u8005\u6307\u51fa\u7528\u7ebf\u6027\u5143\u7d20\u4e58\u6cd5\u4ee3\u66ff\u77e9\u9635\u4e58\u6cd5\uff0c\u5149\u770b\u8fd9\u4e2a\u5b9a\u4e49\uff0c\u5c31\u77e5\u9053\u590d\u6742\u5ea6\u80af\u5b9a\u66f4\u4f4e\u7684\u3002</p> <p>\ud83d\udd34\u63a5\u4e0b\u6765\u9700\u8981\u601d\u8003\uff1a\u8fd9\u4e2a\u7ebf\u6027\u5143\u7d20\u4e58\u6cd5\u4e2d\u7684\u6570\u5b57\u662f\u8c01\uff0c\u77e9\u9635\u662f\u8c01</p> <p>\u52a0\u6cd5\u6ce8\u610f\u529b\u7684\u6a21\u578b\u56fe\uff1a</p> <p></p> <p>\u63cf\u8ff0\u56fe\uff1a\u7ed9\u5b9a\u4e00\u4e2a\u8f93\u5165X\uff0c\u901a\u8fc7\u4e24\u4e2a\u7ebf\u6027\u53d8\u6362\u53ef\u4ee5\u5f97\u5230Q\u77e9\u9635\u548cK\u77e9\u9635\uff0c\u6ce8\u610f\u8fd9\u91cc\u9762\u662f\u6ca1\u6709Value\u77e9\u9635\uff0cK\u77e9\u9635\u548cQ\u77e9\u9635\u7684\u7ef4\u5ea6\u90fd\u662f\\(n\\times D\\) </p> <ul> <li> <p>n\u662ftoken\u7684\u6570\u91cf </p> </li> <li> <p>D\u662f\u6bcf\u4e2a\u7279\u5f81\u7684\u901a\u9053\u6570</p> </li> </ul> <p>\u770b Q \u77e9\u9635\u53d8\u6362\uff0c\u53ef\u4ee5\u770b\u5230\u4f5c\u8005\u4e3a\u6bcf\u4e00\u4e2atoken\uff0c \u90fd\u5206\u914d\u4e86\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u5411\u91cf \\(W_{a_1}\u3001W_{a_2},...,W_{a_N} \\in R ^{1 \\times d}\\)</p> <p>\u66f4\u76f4\u89c2\u7684\u8bf4\u660e\uff1a\u5c06 \\(Q\\in R^{n \\times d}\\) \u5212\u5206\u6210n\u4e2a \\(d \\times 1\\) \u7684\u5217\u5411\u91cf\uff0c\u7136\u540e\u5206\u914d n \u4e2a \\(d \\times 1\\) \u7684\u884c\u5411\u91cf \\(W_{a_1}\u3001W_{a_2},...,W_{a_N} \\in R ^{1 \\times d}\\) \u5b66\u4e60\u5b83\u4eec\u7684\u8868\u793a\uff0c\u7136\u540e\u805a\u5408\uff08\u76f8\u4e58\uff09\u6210\u4e00\u4e2a\u6570\uff0c\u5f97\u5230\u5355\u4e2a\u6570\u503c\u8868\u793a\uff0c\u4e5f\u5c31\u662f \\(\\alpha_1\u3001\\alpha_2\u3001......\u3001\\alpha_N\\)\uff0c\u4f5c\u8005\u79f0\u4e3a\u6ce8\u610f\u529b\u6743\u91cd\u3002</p> <p>\u7136\u540e\u8fd9\u4e9b\u6743\u91cd\u4e0e\u5bf9\u5e94\u7684token\u5411\u91cf\u8fdb\u884c\u76f8\u4e58\uff0c\u6700\u540e\u518d\u628a\u8fd9n\u4e2a\u8c03\u6574\u8fc7\u7684token\u5411\u91cf\u8fdb\u884c\u76f8\u52a0</p> <p>\u5176\u5b9e\u8fd9\u4e2a\u8fc7\u7a0b\u5c31\u662f\u4e00\u4e2a\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230\u6743\u91cd\uff0c\u901a\u8fc7\u5e7f\u64ad\u4e0e\u539f\u59cb\u5411\u91cf\u76f8\u4e58</p> <p>\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230\u4e00\u4e2a\u5168\u5c40query\u5411\u91cf\uff0cshape\u662f 1\u00d7d</p> <p>\u4ed4\u7ec6\u8bf4\u660e\u4e00\u4e0b\uff0c\u8fd9\u91cc\u52a0\u6743\u6c42\u548c\u7684\u8fc7\u7a0b\u3002\u6211\u89c9\u5f97\u4e0d\u5fc5\u7ea0\u7ed3\u8fd9\u91cc\u7684\u8f6c\u7f6e\u64cd\u4f5c\u3002\u91cd\u8981\u7684\u662f\u5c31\u662f\u5f97\u5230\u7684\u6743\u91cd\u53c8\u548c\u539f\u6765\u7684\u5411\u91cf\u76f8\u4e58\uff0c\u672c\u6765\u662f n \u4e2a\u6ca1\u6709\u6743\u91cd\u7684\u5217\u5411\u91cf\uff0c\u73b0\u5728\u53d8\u6210 n \u4e2a\u6709\u6743\u91cd\u7684\u5217\u5411\u91cf\uff0c\u518d\u76f8\u52a0\u5c31\u597d\u54af\u3002\u53d8\u6210\u4e00\u4e2a\u5217\u5411\u91cf\uff0c\u53ea\u4e0d\u8fc7\u8fd9\u91cc\u53c8\u8f6c\u7f6e\u4ec0\u4e48\u7684\u3002\u5176\u5b9e\u4f60\u8bf4\u5982\u679c\u539f\u77e9\u9635\u5f0f n\u00d7d \u7684\uff0c\u90a3\u4f60\u60f3\u5212\u5206\u6210 n \u4e2a d\u00d71 \u7684\u5217\u5411\u91cf\uff0c\u4e0d\u4e5f\u662f\u6709\u8f6c\u7f6e\u64cd\u4f5c\uff1f\u5965\uff0c\u6ca1\u6709\uff0c\u8111\u5b50\u91cc\u60f3\u4e00\u4e0b\u5f62\u72b6\u53d8\u5316\u5c31\u8f6c\u8fc7\u6765\u4e86\u3002\u592a\u7ec6\u679d\u672b\u8282\u7684\u3002</p> <p>\u7136\u540e\u8fd9\u4e2a\u5168\u5c40query\u5411\u91cf\uff0c\u4e0e\u8fd9\u4e2aK\u77e9\u9635\u8fdb\u884c\u76f8\u4e58\uff0c\u5f97\u5230\u7684\u8fd8\u662fn\u00d7D\u7684\u77e9\u9635\u3002</p> <p>\u8fd9\u4e00\u6b65\u7c7b\u4f3c\u4e8e\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u6fc0\u52b1\u64cd\u4f5c\uff0c\u4f7f\u7528\u7684\u662f \\(1\u00d71\u00d7C\\)\u7684\u901a\u9053\u63cf\u8ff0\u7b26\uff0c\u6765\u8c03\u6574\u56fe\u50cf\u4e2d\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u901a\u9053\u91cd\u8981\u6027\uff0c\u5728\u8fd9\u91cc\u662f\u540c\u6837\u7684\u610f\u601d\uff0c\u4f7f\u7528\u7684\u662f\u5177\u6709\u5168\u5c40\u7279\u5f81\u8868\u793a\u7684query\u5411\u91cf\uff08\u53c8\u52a0\u6743\u53c8\u6c42\u548c\uff09\uff0c\u8c03\u6574K\u77e9\u9635\u4e2d\u6bcf\u4e2atoken\u7684\u6bcf\u4e2a\u901a\u9053\u7684\u4e00\u4e2a\u91cd\u8981\u6027\uff0c\u8fd9\u6837\u7684\u8bdd\u5c31\u53ef\u4ee5\u5f97\u5230\u5168\u5c40\u4e0a\u4e0b\u6587\u8868\u793a\uff0cshape\u662fn\u00d7D\uff0c\u4e0e\u8f93\u5165X\u7684shape\u4fdd\u6301\u4e00\u81f4\u7684\uff0c\u6700\u540e\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\uff0c\u7136\u540e\u518d\u63a5\u4e00\u4e2a\u6b8b\u5dee\u8fde\u63a5\uff0c\u5f97\u5230\u6574\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\u3002</p> <p>\ud83d\udea9 \u603b\u7ed3\uff1a  \u8fd9\u4e2a\u7ebf\u6027\u6ce8\u610f\u529b\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\u3002\u7b2c\u4e00\u4e2a\u90e8\u5206\u662f\u5de6\u8fb9\u5206\u652f\uff0c\u76ee\u7684\u662f\u6784\u9020\u4e00\u4e2a\u5168\u5c40\u5411\u91cf\uff0c\u662f\u901a\u8fc7\u5bf9n\u4e2atoken\u7684\u52a0\u6743\u6c42\u548c\u6765\u5b9e\u73b0\u7684\uff1b\u7b2c\u4e8c\u4e2a\u90e8\u5206\u662f\u53f3\u8fb9\u5206\u652f\uff0c\u901a\u8fc7\u5168\u5c40\u5411\u91cf\u6765\u66f4\u65b0K\u77e9\u9635\u4e2d\u6bcf\u4e2atoken\u7684\u8868\u793a\u3002</p> <p>\u8fd9\u4e2a\u601d\u60f3\u548c\u901a\u9053\u6ce8\u610f\u529b\u5f88\u50cf</p> <p>\u8fd9\u91cc\u8fd8\u6709\u4e00\u70b9\uff1a\u4f5c\u8005\u4e3a\u8fd9n\u4e2atoken\uff0c\u4f7f\u7528\u7684\u662f\u540c\u4e00\u4e2a\u5411\u91cf\uff1b\u4e5f\u5c31\u662f\u8bf4\u8fd9n\u4e2atoken\uff0c\u5171\u4eab\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u5411\u91cf</p>"},{"location":"Reproduction/3/#unettsf","title":"UNetTSF","text":"<p>arxiv2024</p> <ul> <li>\u719f\u7684\u4e0d\u80fd\u518d\u719f\u4e86</li> <li>\u901a\u9053\u72ec\u7acb\u7684\u7b56\u7565</li> <li>\u6bcf\u4e00\u5c42\uff1a\u5e76\u884c\u7684\uff0c\u4e00\u4e2a\u4e0b\u91c7\u6837\uff0c\u4e00\u4e2a\u7ebf\u6027\u6620\u5c04\u3002</li> <li>\u6062\u590d\u7ef4\u5ea6\uff0c\u662f cat\uff0c\u518d\u7ee7\u7eed Linear</li> </ul> <p> </p>"},{"location":"Reproduction/3/#t-conv","title":"T-Conv","text":"<p>\u4e3b\u9898\uff1a\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b</p> <p>\u591a\u5143\uff1a\u6307\u7684\u662f\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217</p> <p>KDD2020</p> <ul> <li>\u65f6\u95f4\u5377\u79ef\u6a21\u5757\uff1aTemporal convolution module</li> <li>DIL\uff1aDilated Inception Layer </li> </ul> <p>\u4ecb\u7ecd\uff1a\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65f6\u95f4\u5377\u79ef\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u7531\u4e24\u4e2a\u81a8\u80c0\u7684inception\u5c42\u7ec4\u6210(DIL)\uff0c\u4e00\u4e2a DIL\u540e\u9762\u8ddf\u4e00\u4e2atanh\u7684\u6fc0\u6d3b\u51fd\u6570\u7528\u4f5c\u6ee4\u6ce2\u5668\uff1b\u53e6\u4e00\u5c42\u540e\u9762\u662f\u4e00\u4e2aSigmoid\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u4f5c\u4e3a\u4e00\u4e2a\u95e8\u6765\u63a7\u5236 \u6ee4\u6ce2\u5668\u53ef\u4ee5\u4f20\u9012\u7ed9\u4e0b\u4e00\u6a21\u5757\u7684\u4fe1\u606f\u91cf</p> <ul> <li>tanh \u6fc0\u6d3b\u51fd\u6570\uff1a\u7279\u5f81\u63d0\u53d6\u3001\u589e\u52a0\u975e\u7ebf\u6027\u53d8\u6362</li> <li>sigmoid \u51fd\u6570\uff1a\u7279\u5f81\u9009\u62e9\u3001\u63a7\u5236\u4fe1\u606f\u6d41\u901a</li> </ul> <p>\u6539\u8fdb\u7684\u65b9\u5411\uff1a\u7279\u5f81\u63d0\u53d6 &amp; \u7279\u5f81\u9009\u62e9</p> <p>\u6b64\u5916\u6bcf\u4e2aDIL\u5c42\u7528\u4e00\u7ec4\u6807\u51c6\u7684==1D\u81a8\u80c0\u56e0\u679c\u5377\u79ef==\u6765\u53d1\u73b0\u5404\u79cd\u8303\u56f4\u7684\u65f6\u95f4\u6a21\u5f0f\u3002</p> <p>\u5404\u79cd\u8303\u56f4\u7684\u65f6\u95f4\u6a21\u5f0f\u5c31\u662f\u591a\u5c3a\u5ea6\uff0c\u4e5f\u5c31\u662f\u8bf4\u4f5c\u8005\u5728\u8fd9\u91cc\u7528\u591a\u4e2a\u4e0d\u540c\u7684\u5377\u79ef\u5c42\u5b9e\u73b0\u4e86\u591a\u5c3a\u5ea6\u7684\u65f6\u95f4\u5efa\u6a21\u3002</p> <p>\u901a\u8fc7\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u4e24\u79cd\u5e7f\u6cdb\u7684\u5e94\u7528\u7b56\u7565\uff0c Inception\u5c42\u4ee5\u53ca1D\u81a8\u80c0\u5377\u79ef\uff0c\u8be5\u6a21\u5757\u4e0d\u4ec5\u80fd\u591f\u5904\u7406\u5f88\u957f\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u8fd8\u80fd\u591f\u63d0\u53d6\u591a\u5c3a\u5ea6\u7684\u65f6\u95f4\u7279\u5f81</p> <p>\u8be5\u6a21\u5757\u7684\u4f18\u70b9\uff1a</p> <ul> <li>\u80fd\u591f\u5904\u7406\u5f88\u957f\u7684\u65f6\u95f4\u5e8f\u5217</li> <li>\u63d0\u53d6\u591a\u5c3a\u5ea6\u7684\u65f6\u95f4\u7279\u5f81</li> </ul> <p>\u6a21\u5757\u56fe\uff1a</p> <p></p> <p>\u5de6\u56fe\uff1a\u5c31\u662f\u6240\u63d0\u51fa\u7684\u65f6\u95f4\u5377\u79ef\u6a21\u5757\uff0c\u6709\u4e24\u4e2a\u5206\u652f\uff0c\u4e3b\u5e72\u7f51\u7edc\u90fd\u662f\u8fd9\u4e2a\u6269\u6563inception\u5c42\uff0c\u533a\u522b\u5c31\u662f\u5de6\u8fb9\u8fd9\u4e2a\u4e3b\u5e72\u7f51\u7edc\u4e4b\u540e\uff0c\u63a5\u4e86\u4e00\u4e2atanh\u7684\u6fc0\u6d3b\u51fd\u6570\uff1b\u53f3\u8fb9\u8fd9\u4e2a\u4e3b\u5e72\u7f51\u7edc\u4e4b\u540e\uff0c\u63a5\u4e86\u4e00\u4e2a Sigmoid \u6fc0\u6d3b\u51fd\u6570\u3002</p> <p>\u663e\u7136tanh\u662f\u7279\u5f81\u63d0\u53d6\u5c42\uff0cSigmoid \u662f\u7279\u5f81\u9009\u62e9\u5c42\u3002</p> <p>\u6269\u6563inception\u5c42\u7684\u5185\u90e8\u5b9e\u9645\u4e5f\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u591a\u4e2a\u5177\u6709\u4e0d\u540c\u5377\u79ef\u6838\u5927\u5c0f\u7684\u5377\u79ef\u5c42\u6765\u5b9e\u73b0\u7684\uff0c\u6700\u540e\u5c06\u5b83\u4eec\u8fdb\u884c\u62fc\u63a5\uff0c\u5f97\u5230\u591a\u5c3a\u5ea6\u7684\u7279\u5f81\u8868\u793a</p> <p>\u5377\u79ef\u5c42\u7684\u5b9e\u73b0\u65e2\u53ef\u4ee5padding\uff0c\u4e5f\u53ef\u4ee5\u4e0d padding</p> <p>\uff081\uff09\u4e0d padding \u7684\u597d\u5904\u662f\u5377\u79ef\u5c42\u4e4b\u540e\u5e8f\u5217\u957f\u5ea6\u4f1a\u53d8\u5c0f\uff0c\u76f8\u5e94\u7684\u8ba1\u7b97\u6548\u7387\u5c31\u4f1a\u63d0\u9ad8\uff0c\u5728\u62fc\u63a5\u4e4b\u540e\u53ea\u9700\u8981\u901a\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u6062\u590d\u4e0e\u8fd9\u4e2a\u8f93\u5165\u76f8\u540c\u7684shape\u5c31\u53ef\u4ee5\u4e86</p> <p>\uff082\uff09padding \u7684\u597d\u5904\u662f\u6bcf\u4e2a\u5377\u79ef\u5c42\u7684\u8f93\u5165\u4ee5\u53ca\u8f93\u51fa\u7684shape\u662f\u4e00\u81f4\u7684\uff0c\u8fd9\u6837\u53ef\u4ee5\u786e\u4fdd\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u4fe1\u606f\u662f\u5bf9\u9f50\u7684\uff0c\u6b64\u65f6\u62fc\u63a5\u4e0d\u662f\u5fc5\u987b\u7684\u4e86\uff0c\u76f4\u63a5\u76f8\u52a0\u5c31\u53ef\u4ee5\u5b9e\u73b0\u76f8\u540c\u7684\u6548\u679c\u3002</p> <p>\u540c\u65f6\uff0c\u5982\u679c\u8bbe\u7f6e\u4e863\u4e2a\u4ee5\u4e0a\u76841D\u56e0\u679c\u5377\u79ef\u5c42\uff0c\u90a3\u4e48\u5c31\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e2asoftmax\u51fd\u6570\u6765\u5206\u914d\u6743\u91cd\uff0c\u7136\u540e\u8fdb\u884c\u52a0\u6743\u6c42\u548c\uff0c\u8fd9\u6837\u770b\u8d77\u6765\u4f1a\u66f4\u597d\u770b\u4e00\u4e9b\uff08\u662f\uff09</p> \u968f\u624b\u8865\u5145 <p> \u5728\u8fd9\u4e2a\u65f6\u95f4\u5377\u79ef\u6a21\u5757\u7684\u573a\u666f\u4e0b\uff0c\u7ee7\u7eed\u5957\u7528\u4e94\u5927\u6027\u8d28\uff0c\u5c40\u90e8\u6027\uff0c\u5168\u5c40\u6027\uff0c\u7a00\u758f\u6027\uff0c\u591a\u5c3a\u5ea6\u6027\uff0c\u590d\u6742\u6027 \u8fd9\u4e2a\u6269\u6563inception\u5c42\u9996\u5148\u5b9e\u73b0\u7684\u5c31\u662f\u5c40\u90e8\u6027\u3001\u7a00\u758f\u6027\u3001\u591a\u5c3a\u5ea6\u6027  \u56e0\u4e3a1D\u6269\u6563\u5377\u79ef\uff0c\u5377\u79ef\u6838\u7684\u5927\u5c0f\u5c31\u8868\u793a\u5c40\u90e8\u8303\u56f4\uff0c\u6269\u6563\u5c31\u662f\u7a00\u758f\u6027\uff0c\u591a\u4e2a\u5377\u79ef\u5c42\u5c31\u8868\u793a\u591a\u5c3a\u5ea6\u6027\uff0c\u8fd9\u91cc\u7684\u590d\u6742\u6027\uff0c\u56e0\u4e3a\u5377\u79ef\u64cd\u4f5c\u7684\u590d\u6742\u5ea6\u5f88\u5c0f\uff0c\u6240\u4ee5\u5b9e\u9645\u4e0a\u4e5f\u6ee1\u8db3\u590d\u6742\u6027\u3002  \u90a3\u4e48\u5c31\u53ea\u5269\u4e0b\u4e00\u4e2a\u5168\u5c40\u6027\u4e86\uff0c\u5982\u679c\u628a\u5377\u79ef\u6838\u7684\u5927\u5c0f\uff0c\u8bbe\u7f6e\u4e3a\u548c\u8fd9\u4e2a\u5e8f\u5217\u957f\u5ea6\u662f\u4e00\u81f4\u7684\uff0c\u5b9e\u9645\u4e5f\u7b97\u662f\u5168\u5c40\u6027\u3002  \u56de\u987e\u901a\u9053\u6ce8\u610f\u529b\uff0c\u901a\u8fc7\u538b\u7f29\u7a7a\u95f4\u8868\u793a\u6765\u751f\u6210\u4e00\u4e2a\u901a\u9053\u63cf\u8ff0\u7b26\uff0c\u7136\u540e\u5bf9\u4e0d\u540c\u7684\u901a\u9053\u8fdb\u884c\u52a0\u6743\uff0c\u5728\u8fd9\u91cc\u5df2\u7ecf\u5bf9\u8fd9\u4e2a\u5e8f\u5217\u8fdb\u884c\u5904\u7406\u4e86\uff0c\u90a3\u53ef\u4e0d\u53ef\u4ee5\u518d\u8054\u5408\u901a\u9053\u4e00\u5757\u5efa\u6a21\uff0c\u76ee\u7684\u662f\u4ec0\u4e48\uff1f\u662f\u4e3a\u4e86\u8c03\u6574\u6bcf\u4e2a\u5c3a\u5ea6\u4e0b\u7684\u901a\u9053\u7279\u5f81\u8868\u793a\uff0c\u5728\u6bcf\u4e2a\u5377\u79ef\u5c42\u8f93\u51fa\u7684\u57fa\u7840\u4e0a\uff0c\u53ef\u4ee5\u5728\u8fd9\u4e2a\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u9762\u538b\u7f29\u5b83\u4eec\uff0c\u538b\u7f29\u53ef\u4ee5\u901a\u8fc7\u5377\u79ef\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u6c60\u5316\u6765\u5b9e\u73b0\uff0c\u7136\u540e\u6211\u4eec\u5f97\u5230\u4e86\u4e00\u4e2a$1\u00d7C$\u7684\u901a\u9053\u63cf\u8ff0\u7b26\u8868\u793a\uff0c  \u7136\u540e\u8fd9\u4e2a\u901a\u9053\u63cf\u8ff0\u7b26\uff0c\u518d\u548c\u8fd9\u4e2a\u8f93\u5165\u8fdb\u884c\u76f8\u4e58\uff0c\u8fdb\u800c\u6765\u8c03\u6574\u901a\u9053\u7684\u91cd\u8981\u6027\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u8981\u5728\u8fd9\u4e2a\u6bcf\u4e2a\u5377\u79ef\u5c42\u7684\u540e\u9762\u90fd\u8981\u6dfb\u52a0\u4e0a\u3002 </p>"},{"location":"Reproduction/3/#m-gtu","title":"M-GTU","text":"<p>ICML2022</p> <p>\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5c3a\u5ea6\u95e8\u63a7tanh\u5355\u5143\uff1aMGTU\uff0c\u9996\u5148\u5229\u7528\u591a\u4e2a1D\u56e0\u679c\u5377\u79ef\uff0c\u63d0\u53d6\u65f6\u95f4\u5e8f\u5217\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\uff0c\u9996\u5148\u5f15\u51fa\u4e00\u4e2a\u591a\u5c3a\u5ea6\u6784\u9020\uff0c\u591a\u5c3a\u5ea6\u7684\u65b9\u6cd5\u6709\u54ea\u4e9b\u5462\uff0c\u4e00\u822c\u90fd\u662f\u901a\u8fc7\u5377\u79ef\u6216\u8005\u6c60\u5316\uff0c\u56e0\u4e3a\u901f\u5ea6\u6700\u5feb\uff0c\u6027\u80fd\u6700\u597d\u3002\u7136\u540e\u901a\u8fc7\u95e8\u63a7\u5355\u5143\u63a7\u5236\u4fe1\u606f\u6d41\u5411\u4e0b\u4e00\u6a21\u5757\u7684\u6bd4\u4f8b</p> \u968f\u624b\u8865\u5145\uff1aAbout \u95e8\u63a7\u5355\u5143 <p> \u95e8\u63a7\u5355\u5143\u662f\u4e00\u4e2a\u540d\u5b57\uff0c\u901a\u5e38\u7531 Sigmoid \u51fd\u6570\u5b9e\u73b0\uff0c\u751f\u6210 0~1 \u4e4b\u95f4\u7684\u6743\u91cd\u8868\u793a\uff0c\u9009\u62e9\u4fe1\u606f\u6765\u6d41\u5411\u4e0b\u4e00\u4e2a\u6a21\u5757\u7684\u6bd4\u4f8b </p> <p>\u7528\u95e8\u63a7\u5355\u5143\u63a7\u5236\u4fe1\u606f\u6d41\u5411\u4e0b\u4e00\u6a21\u5757\u7684\u6bd4\u4f8b\uff0c\u90a3\u4e48\u5e94\u8be5\u9009\u62e9\u54ea\u4e9b\u4fe1\u606f\u6765\u6d41\u5411\u4e0b\u4e00\u4e2a\u6a21\u5757\u5462\uff1f\u5e94\u8be5\u8ba9\u6a21\u578b\u6765\u81ea\u9002\u5e94\u9009\u62e9\uff0c\u6240\u4ee5\u5728\u8fd9\u91cc\u901a\u8fc7Sigmoid\u51fd\u6570\uff0c\u6839\u636e\u4e0d\u540c\u7684\u8f93\u5165\u6765\u751f\u6210\u4e0d\u540c\u7684\u6743\u91cd\uff0c\u7136\u540e\u4e24\u8005\u76f8\u4e58\u5f97\u5230\u4e00\u4e2a\u8fc7\u6ee4\u540e\u7684\u7279\u5f81\u3002</p> <p>\u4e3a\u6bcf\u4e2aGTU\u5355\u5143\u7684\u8f93\u51fa\uff0c\u5e94\u7528\u6c60\u5316\u5c42\uff0c\u4ee5\u4fdd\u7559\u91cd\u8981\u7684\u5c40\u90e8\u4fe1\u606f</p> \u968f\u624b\u8865\u5145 <p> \u6c60\u5316\u5c42\u4e0d\u4ec5\u80fd\u591f\u964d\u4f4e\u7ef4\u5ea6\u8fd8\u80fd\u591f\u63d0\u53d6\u4e0d\u540c\u7c7b\u522b\u7684\u4fe1\u606f  \u4f8b\u5982\u6700\u5927\u6c60\u5316\u53ef\u4ee5\u63d0\u53d6\u6700\u6709\u7528\u6216\u8005\u8bf4\u662f\u8fa8\u8bc6\u5ea6\u6700\u597d\u7684\u7279\u5f81  \u5e73\u5747\u6c60\u5316\u4e00\u822c\u662f\u63d0\u53d6\u901a\u7528\u7684\u7279\u5f81  \u4e00\u822c\u60c5\u51b5\u4e0b\u6765\u8bf4\uff0c\u6700\u5927\u6c60\u5316\u53ef\u80fd\u66f4\u597d\u7528\u4e00\u4e9b  \u4e0d\u8fc7\u4e5f\u8981\u6839\u636e\u5177\u4f53\u7684\u4efb\u52a1\u6765\u6d4b\u8bd5  </p> <p>\u6700\u540e\u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u4fe1\u606f\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u62fc\u63a5\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u5c42\u4ee5\u6062\u590d\u548c\u8f93\u5165\u76f8\u540c\u7684shape\uff0c\u6700\u540e\u901a\u8fc7\u6dfb\u52a0\u6b8b\u5dee\u8fde\u63a5\u548c ReLU \u6fc0\u6d3b\u51fd\u6570\uff0c\u4f5c\u4e3a\u6574\u4e2a\u6a21\u5757\u7684\u8f93\u51fa</p> <p>\u5c3a\u5ea6\u7684\u4e2a\u6570\u4e0d\u786e\u5b9a\uff0c\u5c3a\u5ea6\u7684\u5927\u5c0f\u4e5f\u4e0d\u662f\u56fa\u5b9a\u4e0d\u53d8\u7684</p> <p>\u90a3\u4e48\u5728\u62fc\u63a5\u4e4b\u540e\uff0c\u6211\u4eec\u5f97\u5230\u7684\u5e8f\u5217\u957f\u5ea6\u548c\u6700\u5f00\u59cb\u8f93\u5165\u7684\u5e8f\u5217\u957f\u5ea6\u5f88\u6709\u53ef\u80fd\u662f\u4e0d\u76f8\u540c\u7684\uff0c\u6240\u4ee5\u9700\u8981\u8bbe\u7f6e\u4e00\u4e2a\u7ebf\u6027\u5c42\u6765\u628a\u5e8f\u5217\u957f\u5ea6\u53d8\u6362\u4e3a\u6211\u4eec\u6240\u9700\u8981\u7684\u957f\u5ea6\u3002\u6700\u540e\u63a5\u4e00\u4e2a\u6b8b\u5dee\u8fde\u63a5\u548cReLU\u6fc0\u6d3b\u51fd\u6570\u4f5c\u4e3a\u6574\u4e2a\u6a21\u5757\u7684\u8f93\u51fa</p> <p>\u6a21\u578b\u56fe\uff1a</p> <p> </p> <p>\u7ed9\u5b9a\u4e00\u4e2a\u8f93\u5165Z\uff0c\u5728\u8fd9\u91cc\u662f\u5b9a\u4e49\u4e86\u4e09\u4e2a\u5c3a\u5ea6\uff0c\u5e76\u4e14\u6bcf\u4e2a\u5c3a\u5ea6\u90fd\u662f\u901a\u8fc7\u4e00\u7ef4\u7684\u5377\u79ef\u5c42\uff0c\uff08\u6ce8\u610f \u4e00\u7ef4\u5377\u79ef \u662f 1D \u5377\u79ef\uff0c \u4e0d\u4ee3\u8868\u5377\u79ef\u6838\u5927\u5c0f=1\uff09 </p> <p>\u5206\u522b\u662f1\u00d7S1\u30011\u00d7S2\u30011\u00d7S3\uff0c\u901a\u8fc7\u5377\u79ef\u5c42\u4e4b\u540e\u6709\u4e24\u4e2a\u5206\u652f\uff0c\u4e00\u4e2a\u662fTanh\u7684\u51fd\u6570\uff0c\u4e00\u4e2a\u662fSigmoid\u7684\u51fd\u6570</p> <ul> <li>tan\u7684\u51fd\u6570\uff1a\u662f\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\u51fa\u73b0\u7684\uff0c\u589e\u52a0\u975e\u7ebf\u6027\u64cd\u4f5c</li> <li>Sigmoid \u51fd\u6570\uff1a\u7528\u6765\u751f\u6210\u6743\u91cd\uff0c\u4e0e\u975e\u7ebf\u6027\u7684\u8f93\u51fa\u8fdb\u884c\u76f8\u4e58\uff0c\u5f97\u5230\u5f53\u524d\u5c3a\u5ea6\u7684\u8f93\u51fa\uff0c\u7136\u540e\u518d\u901a\u8fc7\u4e00\u4e2a\u6700\u5927\u6c60\u5316\u64cd\u4f5c\uff0c\u63d0\u53d6\u7a97\u53e3\u5185\u6700\u91cd\u8981\u7684\u4e00\u4e2a\u7279\u5f81</li> </ul> <p>\u6700\u540e\u5c06\u591a\u4e2a\u5c3a\u5ea6\u7684\u8f93\u51fa\u8fdb\u884c\u4e00\u4e2a\u62fc\u63a5\uff0c\u7136\u540e\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\u6062\u590d\uff0c\u548c\u8f93\u5165\u76f8\u540c\u7684shape\uff0c\u5e76\u6dfb\u52a0\u6b8b\u5dee\u8fde\u63a5\u548cReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u5f97\u5230\u6574\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\u3002</p> \u968f\u624b\u8865\u5145\uff1a\u601d\u8003\u5982\u4f55\u6539\u8fdb <p> \u5c40\u90e8\u6027\u3001\u5168\u5c40\u6027\u3001\u7a00\u758f\u6027\u3001\u591a\u5c3a\u5ea6\u6027\u3001\u590d\u6742\u6027  \uff081\uff091D\u5377\u79ef \u64cd\u4f5c\u6362\u6210\u6269\u6563\u5377\u79ef\uff0c\u63d0\u53d6\u7a00\u758f\u7684\u5c40\u90e8\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u56e0\u4e3a\u90bb\u63a5\u7684\u51e0\u4e2a\u65f6\u95f4\u6b65\uff0c\u5f88\u6709\u53ef\u80fd\u5b58\u5728\u5197\u4f59\u4fe1\u606f\u3002\u6240\u4ee5\u8bf4\u5728\u8fd9\u91cc\u53ef\u4ee5\u4f7f\u7528\u6269\u6563\u5377\u79ef\u6765\u907f\u514d\u8fd9\u79cd\u73b0\u8c61\u3002  \uff082\uff09\u66f4\u6362\u95e8\u63a7\u64cd\u4f5c\uff0c\u6362\u6210\u6ce8\u610f\u529b\uff0c\u6bd4\u5982\u6362\u6210\u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u6765\u63d0\u53d6\u5168\u5c40\u76f8\u5173\u6027  $\\rightarrow$ \u52a8\u673a\uff1a\u5c40\u90e8\u6027 \u52a0\u7a00\u758f\u6027\uff0c\u52a0\u6ce8\u610f\u529b\u7684\u5168\u5c40\u6027\uff0c\u8fd8\u6709\u591a\u5c3a\u5ea6\u6027\uff0c\u8fd8\u6709\u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u5173\u6ce8\u7684\u662f\u590d\u6742\u6027  \uff083\uff09\u2753 \u4e00\u4e9b\u7ec6\u8282\u65b9\u9762\uff1a\u4f7f\u7528\u5377\u79ef\u548c\u6c60\u5316\uff0c\u5171\u540c\u6765\u63d0\u53d6\u5c40\u90e8\u6027\uff0c\u5728\u6700\u540e\u7684\u8fd9\u4e2a\u8f93\u51fa\u5c42\uff0c\u6dfb\u52a0\u4e00\u4e2a\u5143\u7d20\u70b9\u79ef\u64cd\u4f5c\uff0c\u8fd9\u91cc\u7684\u601d\u60f3\u662f\uff0c\u5c06\u8f93\u51fa\u4e0e\u8f93\u5165\u8fdb\u884c\u5143\u7d20\u70b9\u79ef\u64cd\u4f5c  </p>"},{"location":"Reproduction/3/#trend-aware-attention","title":"Trend-aware Attention","text":"<p>TKDE2021</p> <p>\u5b66\u4e60\u7684\u65f6\u5019\u4e00\u5b9a\u8981\u6ce8\u610f\u5b66\u4e60\u7684\u4e0d\u4ec5\u662f\u7b97\u6cd5\u8fd8\u6709\u6f14\u53d8\u7684\u8fc7\u7a0b\u3002\u6839\u636e\u522b\u4eba\u7684\u521b\u65b0\u70b9\uff0c\u5bfb\u627e\u4e00\u4e2a\u81ea\u5df1\u7684\u5207\u5165\u70b9</p> <p>\u5f15\u5165\uff1a\u4f20\u7edf\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u9010\u70b9\u8ba1\u7b97query\u548cK\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u800c\u6ca1\u6709\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f\u3002\u4f9d\u7136\u662f\u5148\u70b9\u51fa\u666e\u901a\u6ce8\u610f\u529b\u7684\u7f3a\u70b9\uff0c\u6ca1\u6709\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4ec0\u4e48\u6837\u7684\u95ee\u9898\u5462\uff1f\u5982\u679c\u67d0\u4e2a\u65f6\u95f4\u6b65\u7684\u89c2\u5bdf\u503c\u662f\u4e2a\u5f02\u5e38\u503c\uff0c\u4f1a\u9519\u8bef\u7684\u5339\u914d\u76f8\u5173\u70b9\uff0c\u4ece\u800c\u4e3a\u81ea\u6ce8\u610f\u529b\u5e26\u6765\u6f5c\u5728\u7684\u4f18\u5316\u95ee\u9898\u3002</p> <p>\u9996\u5148\uff0c\u6ce8\u610f\u529b\u5c31\u662f\u4e00\u4e2a\u52a0\u6743\u6c42\u548c\uff0c \u5982\u679c\u6709\u5f02\u5e38\u503c\u51fa\u73b0\uff0c\uff08\u6240\u4ee5\u6ce8\u610f\u529b\u673a\u5236\u5176\u5b9e\u662f\u5f02\u5e38\u503c\u654f\u611f\u7684\uff09\uff0c\u5c31\u4f1a\u5bfc\u81f4\u6743\u91cd\u7684\u8ba1\u7b97\u9519\u8bef\uff0c\u81ea\u7136\u800c\u7136\u6c42\u548c\u7684\u8fc7\u7a0b\u5c31\u4f1a\u4ea7\u751f\u8bef\u5dee\uff0c\u57fa\u4e8e\u6b64\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u65f6\u95f4\u8d8b\u52bf\u611f\u77e5\u6ce8\u610f\u529b\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u8282\u70b9\u63d0\u53d6\u5c40\u90e8\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4ece\u800c\u4f7f\u6bcf\u4e2a\u8282\u70b9\u62e5\u6709\u611f\u77e5\u4e0a\u4e0b\u6587\u73af\u5883\u7684\u80fd\u529b \uff0c\u7136\u540e\u901a\u8fc7\u5c40\u90e8\u8d8b\u52bf\u7684\u5f62\u5f0f\uff0c\u6765\u6784\u5efa\u6ce8\u610f\u529b\u77e9\u9635</p> <p>\u89e3\u91ca\u8fd9\u91cc\u8d8b\u52bf\u7684\u6982\u5ff5\uff1a\u9996\u5148\uff0c\u539f\u59cb\u7684\u65f6\u95f4\u5e8f\u5217\u662f\u4ee5\u6bcf\u4e2a\u65f6\u95f4\u70b9\u4f5c\u4e3a\u57fa\u672c\u5355\u4f4d\u7684\uff0c\u5f53\u63d0\u53d6\u6bcf\u4e2a\u65f6\u95f4\u70b9\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e4b\u540e\uff0c\u5c31\u76f8\u5f53\u4e8e\u5177\u5907\u4e86\u8fde\u7eed\u7684\u51e0\u4e2a\u65f6\u95f4\u70b9\u7684\u4fe1\u606f\uff08\u8fd8\u662f\u5f88\u597d\u5947\uff0c\u600e\u4e48\u5b9e\u73b0\u7684\uff09\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u638c\u63e1\u8fd9\u4e00\u6bb5\u65f6\u95f4\u5185\u7684\u8d8b\u52bf\u8d70\u5411\uff0c\u7136\u540e\u518d\u4ee5\u8d8b\u52bf\u4f5c\u4e3a\u57fa\u672c\u5355\u4f4d\uff0c\u8ba1\u7b97\u8d8b\u52bf\u548c\u8d8b\u52bf\u4e4b\u95f4\u7684\u6027\u76f8\u5173\u6027\u3002</p> <p>\u6700\u540e\u4e00\u53e5\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u673a\u5236\u6240\u63d0\u51fa\u7684\u8d8b\u52bf\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u7684\u9884\u6d4b\uff0c\u5e76\u4e14\u7a33\u5b9a\u6027\u66f4\u5f3a\uff0c\u76f4\u89c2\u4e0a\u8bf4\uff0c\u8d8b\u52bf\u548c\u8d8b\u52bf\u7684\u5339\u914d\uff0c\u786e\u5b9e\u8981\u6bd4\u70b9\u548c\u70b9\u4e4b\u95f4\u7684\u5339\u914d\u597d\u3002</p> <p>\u4f5c\u8005\u5728\u95ee\u9898\u7684\u5f15\u5165\u7ed9\u51fa\u4e86\u66f4\u5177\u4f53\u7684\u56fe\uff1a</p> <p> </p> <p>\u8fd9\u662f\u4f5c\u8005\u7ed9\u51fa\u7684\u4e00\u4e2a\u4f8b\u5b50\uff0c\u56fe\u4e2d\u7684\u8fd9\u4e2a\u66f2\u7ebf\uff0c\u8868\u793a\u4ea4\u901a\u4fe1\u53f7\u5e8f\u5217\uff0cA\uff0cB\uff0cC\u8868\u793a\u5728\u4e0d\u540c\u65f6\u95f4\u6b65\u7684\u4e00\u4e2a\u6570\u636e\u70b9\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4f20\u7edf\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f1a\u9519\u8bef\u7684\u5c06A\u70b9\u548cB\u70b9\u8fdb\u884c\u5339\u914d\uff0c\u56e0\u4e3a\u5b83\u4eec\u5177\u6709\u76f8\u540c\u7684\u6570\u503c\u70b9\uff0c\u53ef\u662f\u5b9e\u9645\u4e0a\uff0cA\u548cB\u5177\u6709\u4e0d\u540c\u7684\u5c40\u90e8\u8d8b\u52bf\uff1a</p> <p>\u5728\u5de6\u56fe\u4e2d\uff0cA\u5904\u4e8e\u4e00\u4e2a\u5e73\u53f0\u671f\uff0c\u800cB\u5904\u4e8e\u6ce2\u5cf0\u6ce2\u52a8\u7684\u5cf0\u503c\uff0c\u4e5f\u5c31\u662f\u8bf4\u8fd9\u91cc\u7684A\u548cB\u8fd1\u671f\u7684\u5386\u53f2\u8d70\u52bf\u660e\u663e\u4e0d\u540c\u3002\u56e0\u6b64\u5982\u679c\u5c06\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e94\u7528\u5230\u8fd9\u6bb5\u5e8f\u5217\u4e2d\uff0c\u53ef\u80fd\u5c31\u4f1a\u4e3a\u5e8f\u5217\u4e2d\u7684\u6570\u636e\u70b9\uff0c\u9519\u8bef\u7684\u5206\u914d\u76f8\u5173\u5f3a\u5ea6\uff0c\u90a3\u53ef\u80fd\u5c31\u4f1a\u5f97\u5230\u4e00\u4e2a\u4e0d\u597d\u7684\u5e8f\u5217\u8868\u793a\uff0c\u6700\u7ec8\u4f1a\u5f71\u54cd\u9884\u6d4b\u6027\u80fd\u3002</p> <p>\u57fa\u4e8e\u8fd9\u6837\u7684\u89c2\u5bdf\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u8003\u8651\u5c40\u90e8\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u65f6\u95f4\u8d8b\u52bf\u611f\u77e5\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3002\u5b83\u662f\u5377\u79ef\u6ce8\u610f\u529b\u7684\u4e00\u79cd\u53d8\u4f53\uff0c\u4f7f\u75281D\u5377\u79ef\u6765\u53d6\u4ee3query\u548cK\u539f\u672c\u7684\u7ebf\u6027\u5c42\u64cd\u4f5c\uff0c\u7531\u4e8e\u8fd9\u4e2a\u5377\u79ef\u64cd\u4f5c\uff0c\u80fd\u591f\u5c06\u6bcf\u4e2a\u70b9\u7684\u5c40\u90e8\u4e0a\u4e0b\u6587\u4fe1\u606f\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u7684\u8f93\u5165\u6765\u8ba1\u7b97\u4e24\u4e24\u8d8b\u52bf\u4e4b\u95f4\u7684\u4e00\u4e2a\u76f8\u5173\u6027\uff0c\u8fd9\u6837\u7684\u8bdd\u5c31\u80fd\u591f\u4f7f\u6a21\u578b\u610f\u8bc6\u5230\u9690\u85cf\u5728\u8fd9\u4e2a\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u4e00\u4e2a\u5c40\u90e8\u53d8\u5316\u8d8b\u52bf</p> <p>\u5389\u5bb3\uff0c\u7528\u5377\u79ef\u4ee3\u66ff\u7ebf\u6027\u64cd\u4f5c\uff0c\u5f97\u5230\u5c40\u90e8\u611f\u77e5\u3002</p> <p>\u4ee5\u4e0a\u662f\u5377\u79ef\u6ce8\u610f\u529b\u7684\u601d\u60f3\uff08\u55ef\uff01\uff09</p> <p>\u8865\u5145\uff1a\u5377\u79ef\u6ce8\u610f\u529b\u7684\u601d\u60f3\u53d1\u8868\u5728Nips2019\uff0c\u65f6\u95f4\u5f88\u65e9\u4e86\uff0c\u4f46\u662f\u601d\u60f3\u4e0d\u8fc7\u65f6\u3002\u63a5\u4e0b\u6765 \u770b \u539f\u6587\uff1a</p> <p> </p> <p>\u4f5c\u8005\u8bf4\uff0c\u7531\u4e8e\u5404\u79cd\u4e8b\u4ef6\u4f8b\u5982\u5047\u671f\u548c\u6781\u7aef\u5929\u6c14\uff0c\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6a21\u5f0f\u53ef\u80fd\u4f1a\u968f\u65f6\u95f4\u663e\u8457\u53d8\u5316\uff0c\u56e0\u6b64\u89c2\u6d4b\u70b9\u662f\u5f02\u5e38\u70b9\uff0c\u53d8\u5316\u70b9\u8fd8\u662f\u6a21\u5f0f\u4e2d\u7684\u4e00\u90e8\u5206\uff0c\u90fd\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5176\u5468\u56f4\u7684\u73af\u5883\uff0c\u7136\u800c\u5728\u89c4\u8303transformer\u6a21\u578b\u7684\u81ea\u6ce8\u610f\u529b\u5c42\u4e2dquery\u548cK\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u662f\u57fa\u4e8e\u5b83\u4eec\u4e4b\u95f4\u7684\u9010\u70b9\u503c\u6765\u8ba1\u7b97\u7684\uff0c\u800c\u6ca1\u6709\u5145\u5206\u5229\u7528\u5c40\u90e8\u4e0a\u4e0b\u6587\uff08\u4ece\u8fd9\u4e2a\u56fe\u4e2d\u5c31\u53ef\u4ee5\u770b\u51fa\uff09\uff0c\u800c\u8fd9\u79cd\u4e0e\u5c40\u90e8\u4e0a\u4e0b\u6587\u65e0\u5173\u7684QK\u7684\u5339\u914d\uff0c\u53ef\u80fd\u5c31\u4f1a\u5728\u89c2\u5bdf\u70b9\u662f\u5f02\u5e38\u70b9\uff0c\u53d8\u5316\u70b9\u8fd8\u662f\u6a21\u5f0f\u7684\u4e00\u90e8\u5206\u65b9\u9762\u6df7\u6dc6\u81ea\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5e76\u5e26\u6765\u6f5c\u5728\u7684\u4f18\u5316\u95ee\u9898\uff0c</p> <p>\u7b80\u5355\u6765\u8bf4\uff0c\u5c31\u662f\u6a21\u578b\u8bc6\u522b\u4e0d\u4e86\u8fd9\u4e2a\u70b9\uff0c\u65e0\u6cd5\u5224\u65ad\u8fd9\u4e2a\u70b9\u662f\u662f\u6b63\u5e38\u7684\u8fd8\u662f\u4e0d\u6b63\u5e38\u7684\u3002</p> <p>\ud83d\udea9 \u8fd9\u91cc\u60f3\u5f3a\u8c03\u7684\u662f \u5c40\u90e8\u4e0a\u4e0b\u6587 </p> <p>\u63a5\u4e0b\u6765\u6269\u5c55\u6539\u8fdb\u7684\u601d\u8def\uff1a\u5c40\u90e8\u6027\u3001 \u5168\u5c40\u6027\u3001\u7a00\u758f\u6027\u3001\u591a\u5c3a\u5ea6\u6027\u3001\u590d\u6742\u6027</p> <p>\uff081\uff09\u4ece\u5c40\u90e8\u6027\u548c\u591a\u5c3a\u5ea6\u6027\u7684\u89d2\u5ea6\uff1a</p> <p>\u4ee5\u4e0a\u53ea\u8003\u8651\u5c40\u90e8\u6027\uff0c\u5f88\u663e\u7136\u53ef\u4ee5\u628a\u5c40\u90e8\u6027\u548c\u591a\u5c3a\u5ea6\u6027\u8054\u5408\u8d77\u6765\u3002</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u8bbe\u7f6e\u4e0d\u540c\u7684\u5377\u79ef\u6838\u5927\u5c0f\uff0c\u5982\u8bbe\u7f6e\u4e3a3\u30015\u30017\u3002\u4e5f\u5c31\u662f\u57fa\u4e8e\u4e0d\u540c\u7684\u5c3a\u5ea6\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u6765\u8ba1\u7b97\u8d8b\u52bf\u548c\u8d8b\u52bf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u7136\u540e\u8fd9\u4e09\u4e2a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u4ee5\u5e76\u884c\u4e32\u884c\u90fd\u53ef\u4ee5</p> <p>\uff082\uff09\u5176\u6b21\u628a\u5c40\u90e8\u6027\u548c\u7a00\u758f\u6027\u7ed3\u5408\u8d77\u6765\uff0c \u7531\u4e8e\u5c40\u90e8\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5728\u5185\u90e8\u7684\u4fe1\u606f\u7684\u76f8\u4f3c\u5ea6\uff0c\u53ef\u80fd\u6bd4\u8f83\u9ad8\uff0c\u901a\u8fc7\u4e00\u4e2a1D\u6269\u6563\u5377\u79ef\uff0c\u6765\u63d0\u53d6\u7a00\u758f\u7684\u5c40\u90e8\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u907f\u514d\u5197\u4f59\u4fe1\u606f</p> <p>\uff083\uff09\u8fd8\u53ef\u4ee5\u52a0\u5165\u95e8\u63a7\u5355\u5143\u7b49</p>"},{"location":"Reproduction/3/#airformerct-msa","title":"(AirFormer)CT-MSA","text":"<p>AAAI2023</p> <p>Air former\u4f7f\u7528transformer\u6765\u9884\u6d4b\u5168\u56fd\u7684\u7a7a\u6c14\u8d28\u91cf\u3002</p> <p>\u65f6\u7a7a\u9884\u6d4b\u3001\u7a7a\u6c14\u8d28\u91cf\u9884\u6d4b</p> <p>\u5f15\u5165\uff1a\u4f5c\u8005\u8bbe\u8ba1\u4e86\u56e0\u679c\u65f6\u95f4\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u6765\u5b66\u4e60\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u9996\u5148\u786e\u4fdd\u65f6\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5373\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u72b6\u6001\u603b\u662f\u548c\u4e4b\u524d\u7684\u7d27\u5bc6\u76f8\u5173\uff0c\u800c\u65e0\u6cd5\u7aa5\u63a2\u5230\u672a\u6765\u7684\u72b6\u51b5\uff0c\u8fd9\u610f\u5473\u7740T\u65f6\u95f4\u7684\u7279\u5f81\uff0c\u53ea\u80fd\u901a\u8fc7 <code>1</code> \u5230<code>{T-1}</code>\u65f6\u95f4\u8303\u56f4\u5185\u7684\u52a0\u6743\u548c\u6765\u8868\u793a\u3002</p> <p>\u56e0\u679c\u662f\u65f6\u5e8f\u91cc\u9762\u7279\u6709\u7684\uff0c\u56e0\u4e3a\u6211\u4eec\u65e0\u6cd5\u7aa5\u63a2\u5230\u672a\u6765\u7684\u4fe1\u606f\uff0c\u8fd9\u662f\u76f4\u89c2\u4e0a\u7684\u611f\u89c9\uff0c\u6240\u4ee5\u8bf4\u5728\u505a\u6ce8\u610f\u529b\u6216\u8005\u5377\u79ef\u7684\u65f6\u5019\uff0c\u6211\u4eec\u901a\u5e38\u4f1a\u52a0\u4e0a\u56e0\u679c\u7684\u6982\u5ff5\u3002</p> <p>\u73b0\u5728\u7684\u8bba\u6587\u6709\u4e24\u4e2a\u505a\u6cd5\uff1a</p> <p>\uff081\uff09\u52a0\u56e0\u679c</p> <p>\uff082\uff09\u4e0d\u52a0\u56e0\u679c\uff0c\u4e0d\u52a0\u56e0\u679c\u7684\u51fa\u53d1\u70b9\u662f\uff1a\u5982\u679c\u7ed9\u7684\u662ft\u4e2a\u5386\u53f2\u65f6\u95f4\u6b65\u7684\u6570\u636e\uff0c\u90a3\u7ed9\u4e86\u5c31\u662f\u7ed9\u4e86\uff0c\u600e\u4e48\u7528\u5c31\u662f\u53e6\u4e00\u56de\u4e8b\u4e86\u3002\u53ea\u8981\u4e0d\u6d89\u53ca\u6570\u636e\u6cc4\u9732\u5373\u53ef\u3002</p> <p>\u55ef\uff0c\u6240\u4ee5\u52a0\u8fd8\u662f\u4e0d\u52a0\uff0c\u770b\u6da8\u4e0d\u6da8\u70b9\u3002</p> <p>\u56de\u5230\u539f\u6587\uff1a\u5176\u6b21\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u4f5c\u8005\u8003\u8651\u4e86\u65f6\u95f4\u6ce8\u610f\u529b\u7684\u5c40\u90e8\u6027\uff0c\u4e5f\u5c31\u662f\u7a97\u53e3\u6ce8\u610f\u529b\uff0c\u5047\u8bbe\u8f93\u5165\u7684\u5e8f\u5217\u957f\u5ea6\u4e3a8\uff0c\u5728\u6ce8\u610f\u529b\u673a\u5236\u7684\u7b2c\u4e00\u5c42\uff0c\u4ee4\u7a97\u53e3\u5927\u5c0f\u4e3a2\uff0c\u5728\u7b2c\u4e8c\u5c42\u4ee4\u7a97\u53e3\u5927\u5c0f\u4e3a4\uff0c\u5728\u7b2c3\u5c42\u4ee4\u7a97\u53e3\u5927\u5c0f\u4e3a8\uff0c\u4ee5\u8fd9\u79cd\u65b9\u5f0f\uff0c\u5728\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd8\u53ef\u4ee5\u63d0\u53d6\u591a\u5c3a\u5ea6\u7684\u65f6\u95f4\u4f9d\u8d56\u6027</p> <p>\u53c8\u662f \u5c40\u90e8\u6027 \u52a0 \u591a\u5c3a\u5ea6\u6027\uff08\u55ef\uff0c\u5b66\u7740\u70b9\uff09\uff0c\u56fe\u50cf\u4e2d\u6709\u8fd9\u65b9\u9762\u7684\u4ee3\u8868\u6027\u5de5\u4f5c\uff1a\u2460DilatedFormer\u2461HiLoAttention\u2462P2TAttention</p> <p>\u5c40\u90e8\u5efa\u6a21\u65b9\u6cd5\uff0c\u7528\u7684\u7ecf\u5178\u7684\u7a97\u53e3\u6ce8\u610f\u529b\u673a\u5236\u3002</p> <p>\u672c\u6587\u7ed3\u6784\u56fe\uff1a </p> <p> </p> <p>\u5de6\u56fe\u662f\u7ecf\u5178\u7684transformer encoder\u67b6\u6784\uff0c\u5148layer normal\u89c4\u8303\u5316\uff0c\u7136\u540e\u63a5\u4e00\u4e2a\u56e0\u679c\u65f6\u95f4\u591a\u5934\u81ea\u6ce8\u610f\u529b\uff0c\u7136\u540e\u518d\u63a5\u4e00\u4e2alayer normal\u548cMLP\uff0c\u8fd9\u5c31\u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u7a97\u53e3\u65f6\u95f4\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5982\u679c\u6211\u4eec\u5806\u53e0\u591a\u4e2a\u8fd9\u6837\u7684\u7a97\u53e3\u65f6\u95f4\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5e76\u4e14\u5728\u6bcf\u4e2a\u6ce8\u610f\u529b\u7684\u5185\u90e8\uff0c\u8bbe\u7f6e\u4e0d\u540c\u7684\u5927\u5c0f\u7a97\u53e3\uff0c\u5c31\u53ef\u4ee5\u63d0\u53d6\u591a\u5c3a\u5ea6\u7684\u5c40\u90e8\u65f6\u95f4\u7279\u5f81\u3002</p> <p>\u53f3\u56fe\u5c55\u793a\u7684\u5c31\u662f\u5728\u591a\u5c3a\u5ea6\u5efa\u6a21\u7684\u65f6\u5019\uff0c\u611f\u53d7\u91ce\u7684\u53d8\u5316\u8303\u56f4\uff1a</p> <p>\u5728\u8fd9\u91cc\u7ed9\u5b9a\u516b\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u5e8f\u5217\uff0c\u90a3\u4e48\u5728\u7b2c\u4e00\u4e2a\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\u5728\u8fd9\u91cc\u7a97\u53e3\u5927\u5c0f\u8bbe\u7f6e\u4e3a2\uff0c\u53ef\u4ee5\u770b\u5230\u67094\u4e2a\u7a97\u53e3\uff0c\u5728\u7a97\u53e3\u5185\u90e8\u6267\u884c\u6ce8\u610f\u529b\u673a\u5236\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u770b\u5230\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65 \\(t_1\\) \uff0c\u66f4\u65b0\u7684\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u53ea\u80fd\u4f9d\u9760\u81ea\u8eab\u7684\u4fe1\u606f\uff0c\u66f4\u65b0\u7684\u7b2c\u4e8c\u4e2a\u65f6\u95f4\u6b65 \\(t_2\\) \uff0c \u5c31\u53ef\u4ee5\u5229\u7528\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u548c\u7b2c\u4e8c\u4e2a\u65f6\u95f4\u6b65\u7684\u4fe1\u606f\u3002\u90a3\u4e48\u5728\u7b2c\u4e8c\u5c42\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff0c\u6bd4\u5982\u8bf4\u7b2c\u4e09\u4e2a\u65f6\u95f4\u6b65\uff0c\u53ef\u4ee5\u5229\u7528\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u3001\u7b2c\u4e8c\u4e2a\u65f6\u95f4\u6b65\u3001\u7b2c\u4e09\u4e2a\u65f6\u95f4\u6b65\u7684\u4fe1\u606f\uff0c\u4f46\u662f\u65e0\u6cd5\u5229\u7528\u7b2c\u56db\u4e2a\u65f6\u95f4\u6b65\u7684\u4fe1\u606f\u3002\u800c\u7b2c\u56db\u4e2a\u65f6\u95f4\u6b65\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u5f53\u524d\u7a97\u53e3\u5185\u7684\u6240\u6709\u65f6\u95f4\u6b65\u7684\u4fe1\u606f\u6765\u8fdb\u884c\u66f4\u65b0</p> \u968f\u624b\u8865\u5145\uff1a\u6269\u5c55\u521b\u65b0\u70b9 <p> \u5c40\u90e8\u6027\u3001\u7a00\u758f\u6027\u3001\u5168\u5c40\u6027\u3001\u591a\u5c3a\u5ea6\u6027\u3001\u590d\u6742\u6027 \u8fd9\u91cc\u8fd8\u6ca1\u6709\u4f7f\u7528\u7a00\u758f\u6027\uff0c\u4ee5 DilatedFormer \u4e3a\u4f8b\uff0c\u5982\u679c\u8f93\u5165\u7684\u5e8f\u5217\u8db3\u591f\u957f\uff0c\u5c31\u53ef\u4ee5\u7a00\u758f\u7684\u9009\u53d6\u7a97\u53e3\u5185\u65f6\u95f4\u6b65\u7684\u4fe1\u606f\uff0c\u800c\u4e0d\u9700\u8981\u4e0e\u7a97\u53e3\u5185\u6240\u6709\u7684\u65f6\u95f4\u6b65\u90fd\u8ba1\u7b97\u76f8\u5173\u6027\uff0c\u53ef\u4ee5\u53d8\u6210\u591a\u5c3a\u5ea6\u6269\u6563\u7a97\u53e3\u6ce8\u610f\u529b\uff0c \u8fd8\u6709\u5168\u5c40\u6027\uff0c\u5982\u679c\u60f3\u8981\u5b9e\u73b0\u5168\u5c40\u7684\u5efa\u6a21\uff0c\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u673a\u5236\u80af\u5b9a\u4e0d\u5408\u9002\u4e86\uff0c \u56e0\u4e3a\u4f7f\u7528\u7a97\u53e3\u6ce8\u610f\u529b\u7684\u672c\u610f\u5c31\u662f\u9664\u4e86\u5efa\u6a21\u5c40\u90e8\u76f8\u5173\u6027\uff0c\u8fd8\u6709\u4e00\u70b9\u5c31\u662f\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u518d\u642d\u914d\u4e2a\u539f\u59cb\u6ce8\u610f\u529b\uff0c\u53c8\u56de\u5230\u539f\u70b9\u4e86\u3002\u53ef\u4ee5\u4f7f\u7528\u5177\u6709\u4f4e\u590d\u6742\u5ea6\u7684\u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u8fdb\u884c\u5168\u5c40\u5efa\u6a21\uff0c\u4f5c\u4e3a\u7a97\u53e3\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e00\u4e2a\u8865\u5145 </p>"},{"location":"Reproduction/3/#pyraformer","title":"Pyraformer","text":"<p>ICLR2022</p> <p>\u5f15\u5165\uff1aPy former\uff0c\u4f4e\u590d\u6742\u5ea6\u7684\u91d1\u5b57\u5854\uff0c\u6ce8\u610f\u529b\u7f51\u7edc\u7528\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0cCV\u91cc\u9762\u4e2d\u7684\u91d1\u5b57\u5854\u5efa\u6a21\u601d\u60f3\uff0c\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u901a\u8fc7\u63a2\u7d22\u65f6\u95f4\u5e8f\u5217\u7684\u591a\u5206\u8fa8\u7387\u8868\u793a\u6765\u63d0\u51faPyraformer\uff0c\u76f4\u63a5\u70b9\u660e\u52a8\u673a\uff0c\u591a\u5206\u8fa8\u7387\u5b9e\u9645\u5c31\u662f\u591a\u5c3a\u5ea6\u7684\u95ee\u9898\uff0c\u5206\u8fa8\u7387\u662f\u56fe\u50cf\u4e2d\u7684\u6982\u5ff5\uff0c\u4f5c\u8005\u76f4\u63a5\u62ff\u5230\u4e86\u65f6\u95f4\u5e8f\u5217\u5f53\u4e2d\uff08\u9886\u57df\u8fc1\u79fb\uff09\u3002</p> <p>\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5c3a\u5ea6\u95f4\u7684\u6570\u636e\u7ed3\u6784\u603b\u7ed3\u4e86\u4e0d\u540c\u5206\u8fa8\u7387\u7684\u7279\u5f81\uff0c\u5c3a\u5ea6\u5185\u7684\u76f8\u90bb\u8fde\u63a5\uff0c\u5efa\u6a21\u4e86\u4e0d\u540c\u8303\u56f4\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u5e76\u4e14\u5176\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e0e\u5e8f\u5217\u957f\u5ea6L\u6210\u7ebf\u6027\u6bd4\u4f8b\uff0c\u4e5f\u5c31\u662f\u8bf4\u91d1\u5b57\u5854\u5305\u542b\u4e24\u4e2a\u90e8\u5206\uff1a</p> <p>\uff081\uff09\u7b2c\u4e00\u4e2a\uff1a\u5c3a\u5ea6\u95f4\u7684\u5efa\u6a21\uff1a\u6307\u7684\u662f\u5728\u4e00\u4e2a\u56fa\u5b9a\u7684\u5e8f\u5217\u5185\u90e8\uff0c\u8ba9\u4e24\u4e24\u65f6\u95f4\u6b65\u8fdb\u884c\u4ea4\u4e92</p> <p>\uff082\uff09\u7b2c\u4e8c\u4e2a\uff1a\u5c3a\u5ea6\u5185\u7684\u5efa\u6a21\uff0c\u5c3a\u5ea6\u95f4\u6307\u7684\u662f\u5177\u6709\u4e0d\u540c\u5c3a\u5ea6\u7684\u5e8f\u5217\u4e4b\u95f4\u8fdb\u884c\u4ea4\u4e92\uff0c\u5b83\u4eec\u53ef\u80fd\u5206\u522b\u5177\u6709\u5927\u7684\u611f\u53d7\u91ce\u548c\u5c0f\u7684\u611f\u53d7\u91ce\uff0c\u5b83\u4eec\u76f8\u4e92\u5b66\u4e60\u5bf9\u65b9\u7684\u4fe1\u606f</p> <p>\u8fd9\u91cc\u8fd8\u63d0\u5230\u4e86\u4e00\u4e2a\u590d\u6742\u5ea6\u7684\u95ee\u9898\u5448\u7ebf\u6027\u6bd4\u4f8b\uff0c\u4e5f\u5c31\u662f\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u6700\u540e\u4e00\u53e5\u4f5c\u8005\u5728\u957f\u5e8f\u5217\u5b9e\u8df5\u9884\u6d4b\uff0c\u9a8c\u8bc1\u4e86Pyraformer\u7684\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\uff0c\u4e5f\u5c31\u662f\u4f18\u70b9\uff1a\u6027\u80fd\u597d\u3001 \u590d\u6742\u5ea6\u4f4e</p> <p> </p> <p>\u9996\u5148\uff0c\u5728\u4ecb\u7ecd\u4e4b\u524d\uff0c\u80af\u5b9a\u8981\u5148\u5bf9\u6bd4\u4f20\u7edf\u7684\uff0c\u4f20\u7edf\u7684\u6ce8\u610f\u529b\uff0c\u5728\u4efb\u610f\u7684\u4e24\u70b9\u65f6\u95f4\u6b65\u4e4b\u95f4\u8ba1\u7b97\u76f8\u5173\u6027\uff0c\u7136\u540e\u5bf9\u5b83\u4eec\u8fdb\u884c\u52a0\u6743\u6c42\u548c\uff0c\u4ece\u800c\u6765\u66f4\u65b0\u6bcf\u4e2a\u65f6\u95f4\u6b65\u65b0\u7684\u7279\u5f81\uff0c\u662f\u4e00\u79cd\u5177\u6709\u5168\u5c40\u611f\u53d7\u91ce\u7684\u65b9\u6cd5\uff0c\u4ee3\u4ef7\u5c31\u662f\u8ba1\u7b97\u590d\u6742\u5ea6\u5f88\u9ad8\uff0c\u662f\u5e8f\u5217\u957f\u5ea6\u7684\u4e8c\u6b21\u65b9</p> <p>\u7b2c\u4e8c\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u5377\u79ef\u6838\u6765\u805a\u5408\u76f8\u90bb\u51e0\u4e2a\u65f6\u95f4\u6b65\u7684\u4fe1\u606f\uff0c\u611f\u53d7\u91ce\u7684\u5927\u5c0f\uff0c\u53d6\u51b3\u4e8e\u5377\u79ef\u6838\u7684\u5927\u5c0f\uff0cCNN\u5728\u5b66\u4e60\u5c40\u90e8\u76f8\u5173\u6027\u65b9\u9762\u662f\u5f88\u4f18\u79c0\u7684\uff0c\u6240\u4ee5\u8bf4\u73b0\u5728\u4e3b\u6d41\u7684\u65b9\u6cd5\u90fd\u662fCNN\u52a0attention\uff0c\u5c40\u90e8 &amp; \u5168\u5c40\u5efa\u6a21</p> <p>\u7b2c\u4e09\u4e2a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u53ea\u80fd\u5faa\u73af\u5904\u7406\u6bcf\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\uff0c\u8d8a\u5f80\u540e\u8d70\uff0c\u4e4b\u524d\u65f6\u95f4\u6b65\u7684\u4fe1\u606f\u4fdd\u7559\u7684\u5c31\u8d8a\u5c11\uff0c\u8ba1\u7b97\u6162\u4e14\u65e0\u6cd5\u5e76\u884c\uff0c\u6b64\u65f6\u6ce8\u610f\u529b\u673a\u5236\u7684\u63d0\u51fa\uff0c\u5c31\u662f\u4e3a\u4e86\u89e3\u51b3\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u65e0\u6cd5\u5e76\u884c\u7684\u95ee\u9898</p> <p>\u63a5\u4e0b\u6765\u770bPyraformer\uff0c\u4e00\u773c\u770b\u4e0a\u53bb\u662f\u4e00\u4e2a\u91d1\u5b57\u5854\u67b6\u6784\uff0c\u6700\u4e0b\u9762\u8fd9\u4e00\u5c42\u662f\u539f\u59cb\u7684\u5e8f\u5217\u8868\u793a\uff0c\u4e5f\u5c31\u662f\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u8d8a\u5f80\u4e0a\u8d70\uff0c\u5e8f\u5217\u8d8a\u77ed\uff0c\u76f8\u5e94\u7684\u6bcf\u4e2a\u8282\u70b9\u5177\u5907\u7684\u611f\u53d7\u91ce\u5c31\u8d8a\u5927\uff0c\u76f4\u5230\u6700\u9ad8\u8fd9\u4e00\u5c42\u4e00\u4e2a\u8282\u70b9\uff0c\u5177\u5907\u4e86\u5168\u5c40\u7684\u611f\u53d7\u91ce\uff0c\u4e5f\u5c31\u662f\u5177\u5907\u4e86\u5168\u5c40\u4fe1\u606f\u8868\u793a</p> <p>\u7136\u540e\u5728\u4e24\u4e24\u8282\u70b9\u4e4b\u95f4\u8fdb\u884c\u4e00\u4e2a\u9009\u62e9\u6027\u7684\u8fde\u63a5\uff0c\u5927\u5bb6\u53ef\u4ee5\u770b\u5230\uff0c\u5b83\u5e76\u4e0d\u662f\u4efb\u610f\u4e24\u70b9\u4e4b\u95f4\u90fd\u6709\u8fde\u63a5\u7684\uff0c\u7136\u540e\u6211\u4eec\u6765\u4ed4\u7ec6\u5206\u6790\u4e00\u4e0b\u91d1\u5b57\u5854\u6ce8\u610f\u529b</p> <p> </p> <p>\uff081\uff09\u9996\u5148\u662f\u591a\u5c3a\u5ea6\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e00\u5c42\u6240\u6240\u5177\u5907\u7684\u611f\u53d7\u4e5f\u5927\u5c0f\u662f\u4e0d\u540c\u7684\uff0c\u9996\u5148\u8981\u660e\u786e\u5b83\u662f\u600e\u4e48\u6765\u7684\u3002</p> <ul> <li>\u9996\u5148\u770b\u5de6\u8fb9\u8fd9\u4e2a\u56fe\uff0c\u5b83\u53eb\u505a \u7c97\u5c3a\u5ea6\u6784\u9020\u6a21\u5757\uff0c\u5f88\u663e\u7136\uff0c\u4ece\u8fd9\u4e2a\u540d\u5b57\u5c31\u53ef\u4ee5\u770b\u51fa\uff0c\u91d1\u5b57\u5854\u4e0a\u9762\u8fd9\u4e9b\u5177\u5907\u5927\u611f\u53d7\u91ce\u7684\u5e8f\u5217\uff0c\u5c31\u662f\u4ece\u8fd9\u4e2a\u6a21\u5757\u6765\u63d0\u53d6\u51fa\u6765\u7684</li> <li>\u7ed9\u5b9a\u4e00\u4e2a\u8f93\u5165 \\(B \\times L \\times D\\)   B\u8868\u793abatch size\u3001L\u662f\u5e8f\u5217\u957f\u5ea6\u3001D\u662f\u7279\u5f81\u7ef4\u5ea6\uff0c\u4e5f\u53eb\u505a\u901a\u9053\u6570\u91cf\uff0c\u5148\u6682\u65f6\u5ffd\u7565\u6389\u8fd9\u4e2aB</li> <li>\u9996\u5148\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\u53d8\u6362\u4e00\u4e0b\uff0c\u5f97\u5230\u8fd9\u4e2a\\(L \\times  D_K\\) \uff0c\u7d27\u63a5\u662f\u4e09\u4e2a\u5377\u79ef\u5c42\uff0c\u5b83\u7684\u5377\u79ef\u6838\u5927\u5c0f\u548c\u8fd9\u4e2a\u6b65\u957f\u90fd\u662f \\(C\\) </li> <li>\u6240\u4ee5\u8bf4\u5728\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\uff0cshape\u5c31\u53d8\u6210\u4e86 \\(\\frac{L}{C} \\times D_K\\) \uff0c \\(\\frac{L}{C}\\)  \u662f\u76ee\u524d\u7684\u5e8f\u5217\u957f\u5ea6\uff0c\\(\\frac{L}{C}\\) \u663e\u7136\u662f\u5c0f\u4e8e\u957f\u5ea6 \\(L\\) \u7684 \uff0c\u4e5f\u5c31\u662f\u8bf4\u660e\u4e86\u73b0\u5728\u7684\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u5177\u6709\u4e86\u66f4\u5927\u7684\u611f\u53d7\u91ce\uff0c\u611f\u53d7\u91ce\u7684\u5927\u5c0f\u662f \\(C\\) </li> <li>\u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\uff0cshape\u5c31\u53d8\u6210\u4e86 \\(\\frac{L}{C^2} \\times D_K\\) \uff0c\u611f\u53d7\u91ce\u7684\u5927\u5c0f\u5c31\u662f $ C^2$ </li> <li>\u7b2c\u4e09\u4e2a\u5377\u79ef\u5c42\u4e4b\u540e\uff0cshape\u5c31\u53d8\u6210\u4e86 \\(\\frac{L}{C^3} \\times D_K\\) \uff0c\u611f\u53d7\u91ce\u7684\u5927\u5c0f\u5c31\u662f $ C^3$ </li> <li>\u5982\u679c\u662f\\(N\\)\u4e2a\u5377\u79ef\u5c42\uff0c shape\u5c31\u53d8\u6210\u4e86 \\(\\frac{L}{C^N} \\times D_K\\) \uff0c\u611f\u53d7\u91ce\u7684\u5927\u5c0f\u5c31\u662f $ C^N $ </li> <li>\u5f88\u663e\u7136\u8fd9\u4e2a\u5377\u79ef\u5c42\uff0c\u8d8a\u5f80\u4e0b\u8d70\uff0c\u8fd9\u4e2a\u5e8f\u5217\u957f\u5ea6\u5c31\u4f1a\u53d8\u5f97\u8d8a\u77ed\uff0c\u76f8\u5e94\u7684\u611f\u53d7\u91ce\u5c31\u4f1a\u8d8a\u6765\u8d8a\u5927\uff0c\u6309\u7167\u4f5c\u8005\u7684\u8bf4\u6cd5\u6765\u8bf4\uff0c\u5c3a\u5ea6\u4f1a\u53d8\u5f97\u8d8a\u6765\u8d8a\u7c97\uff0c\u7136\u540e\u5c06\u8fd9\u4e09\u4e2a\u5377\u79ef\u5c42\u5f97\u5230\u7684\u5e8f\u5217\uff0c\u8fdb\u884c\u4e00\u4e2a\u62fc\u63a5\uff0c\u8fd8\u6709\u539f\u59cb\u7684\u5e8f\u5217 (\u6b8b\u5dee\u8fde\u63a5) \uff0c\u4e00\u8d77\u62fc\u63a5\u540e\uff0c\u518d\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\u5f97\u5230\u8f93\u51fa\uff0c\u8f93\u51fa\u7684\u957f\u5ea6\u4e5f\u5c31\u662f  \\((L+\\frac{L}{C}+\\frac{L}{C^2}+\\frac{L}{C^3} \\times D\\)</li> <li>\u4ee5\u8fd9\u6837\u7684\u65b9\u5f0f\uff0c\u5f97\u5230\u591a\u5c3a\u5ea6\u7684\u5e8f\u5217\u8868\u793a\uff0c\u8fd9\u91cc\u8fd8\u6709\u4e00\u4e2a\u70b9\u9700\u8981\u6ce8\u610f\u4e00\u4e0b\uff0c\u6709\u53ef\u80fd\u5728\u8f93\u5165\u7684\u65f6\u5019\uff0c\u957f\u5e8f\u5217L\u4f1a\u975e\u5e38\u975e\u5e38\u5927\uff0c\u6240\u4ee5\u8bf4\u540e\u9762\u5728\u8ba1\u7b97\u5377\u79ef\u5c42\u591a\u4e2a\u5377\u79ef\u5c42\u7684\u65f6\u5019\uff0c\u53ef\u80fd\u5c31\u4f1a\u63d0\u9ad8\u8ba1\u7b97\u91cf\u548c\u53c2\u6570\u91cf\uff0c\u6240\u4ee5\u4f5c\u8005\u5728\u8fdb\u884c\u7ebf\u6027\u5c42\u4e4b\u524d\u505a\u4e86\u964d\u7ef4\u64cd\u4f5c\uff0c\u964d\u7ef4\u4e4b\u540e\u518d\u505a\u5377\u79ef\u64cd\u4f5c</li> <li>\u6267\u884c\u5b8c\u4e4b\u540e\u518d\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\uff0c\u6062\u590d\u7ef4\u5ea6D\uff0c\u8fd9\u6837\u7684\u8bdd\u4e0d\u4ec5\u80fd\u591f\u663e\u8457\u964d\u4f4e\u53c2\u6570\u91cf\uff0c\u8fd8\u53ef\u4ee5\u9632\u6b62\u8fc7\u62df\u5408\uff08\u8fd9\u91cc\u5148\u964d\u7ef4\u540e\u5347\u7ef4\u7684\u64cd\u4f5c\uff09</li> </ul> <p>\uff082\uff09\u5728\u5f97\u5230\u591a\u4e2a\u5c3a\u5ea6\u7684\u5e8f\u5217\u8868\u793a\u4e4b\u540e\uff0c\u5c31\u5b8c\u6210\u4e86\u6784\u9020\u91d1\u5b57\u5854\u7684\u7b2c\u4e00\u6b65</p> \u968f\u624b\u8865\u5145 <p> \u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u591a\u5c3a\u5ea6\u95ee\u9898  \u5728\u56fe\u50cf\u4e2d\u4e0d\u540c\u7684\u5c3a\u5ea6\u5c31\u4ee3\u8868\u56fe\u50cf\u4e0d\u540c\u7684\u5927\u5c0f\u533a\u57df  \u591a\u5c3a\u5ea6\u6709\u52a9\u4e8e\u6355\u6349\u5404\u7c7b\u56fe\u50cf\u4e2d\u7684\u4e0d\u540c\u76ee\u6807\u5927\u5c0f\u4fe1\u606f  \u8fd9\u4e00\u601d\u60f3\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\u540c\u6837\u9002\u7528\uff0c\u4f8b\u5982\u5728\u539f\u59cb\u7684\u65f6\u95f4\u5e8f\u5217\u4e2d\uff0c\u662f\u6309\u7167\u4e00\u4e2a\u5c0f\u65f6\u7684\u95f4\u95f4\u9694\u6765\u91c7\u6837\u7684\uff0c\u8fd9\u91cc\u6709\u516b\u4e2a\u65f6\u95f4\u6b65\uff0c\u5c31\u662f\u516b\u4e2a\u5c0f\u65f6\u7684\u4fe1\u606f  \u5982\u679c\u5c06\u4e24\u70b9\u65f6\u95f4\u8fdb\u884c\u805a\u5408\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u65f6\u95f4\u6b65\u7279\u5f81\u8868\u793a\uff0c\u90a3\u4e48\u8fd9\u4e2a\u65b0\u7684\u65f6\u95f4\u6b65\uff0c\u5c31\u5177\u5907\u4e862\u4e2a\u5c0f\u65f6\u7684\u4fe1\u606f\uff0c\u518d\u5f80\u4e0a\u8d70\u662f\u5177\u5907\u4e864\u4e2a\u5c0f\u65f6\u7684\u4fe1\u606f\uff0c\u518d\u5f80\u4e0a\u8d70\u5c31\u5177\u5907\u4e86\u5168\u5c40\u76848\u4e2a\u5c0f\u65f6\u7684\u4fe1\u606f    \u5982\u679c\u8fd9\u4e2a\u8f93\u5165\u7684\u5e8f\u5217\u8db3\u591f\u957f\uff0c\u90a3\u4e48\u6bcf\u4e2a\u65b0\u751f\u6210\u7684\u65f6\u95f4\u6b65\uff0c\u53ef\u80fd\u5c31\u5305\u542b\u4e86\u4e00\u5929\u751a\u81f3\u4e00\u5468\u7684\u4fe1\u606f\uff0c\u4ece\u4e0b\u5f80\u4e0a\u8d70\uff0c\u611f\u53d7\u91ce\u8d8a\u6765\u8d8a\u5927\uff0c\u9664\u4e86\u6709\u5229\u4e8e\u63cf\u8ff0\u957f\u671f\u7684\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u8fd8\u80fd\u591f\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6    \u56e0\u4e3a\u6211\u4eec\u628a\u5f88\u591a\u7684\u4fe1\u606f\u538b\u7f29\u5230\u4e86\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\u91cc\u9762    \u4ee5\u4e0a\u662f\u5bf9\u591a\u5c3a\u5ea6\u7684\u65f6\u95f4\u5e8f\u5217\u7684\u8865\u5145\u63cf\u8ff0  </p> <p>\u7ee7\u7eed\u6765\u770b\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u7684\u7b2c\u4e8c\u6b65\uff0c\u5f97\u5230\u6bcf\u4e2a\u5c3a\u5ea6\u7684\u5e8f\u5217\u8868\u793a\u4e4b\u540e\uff0c\u7b2c\u4e00\u4e2a\u3001\u7b2c\u4e8c\u4e2a\u3001\u7b2c\u4e09\u4e2a\u3001\u7b2c\u56db\u4e2a\u5c3a\u5ea6\u5e94\u5f53\u5728\u4e24\u4e24\u8282\u70b9\u4e4b\u95f4\u5efa\u7acb\u8fde\u63a5\uff0c\u5982\u679c\u5728\u4efb\u610f\u4e24\u4e24\u8282\u70b9\u4e4b\u95f4\u5efa\u7acb\u8fde\u63a5\u5c31\u53d8\u6210\u4f20\u7edf\u7684\u6ce8\u610f\u529b\u673a\u5236\u3002</p> <p>\u56e0\u6b64\u4f5c\u8005\u7b2c\u4e8c\u4e2a\u8003\u8651\u7684\u95ee\u9898\u662f\u5728\u54ea\u4e9b\u8282\u70b9\u4e4b\u95f4\u5efa\u7acb\u8fde\u63a5\uff0c\u8fd9\u5f88\u91cd\u8981\uff0c\u8fd9\u91cc\u7684\u8282\u70b9\u548c\u65f6\u95f4\u6b65\u662f\u7b49\u4ef7\u7684</p> <p>\u9996\u5148\u5728\u6bcf\u4e00\u4e2a\u5e8f\u5217\u7684\u5185\u90e8\uff0c\u6bcf\u4e2a\u8282\u70b9\u53ea\u548c\u5b83\u76f8\u90bb\u7684\u5de6\u53f3\u4e24\u4e2a\u8282\u70b9\u8fdb\u884c\u8fde\u63a5\uff0c\u4e5f\u5c31\u662f\u53ea\u5173\u6ce8\u5c40\u90e8\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5f53\u7136\u4e86\u4e0d\u8981\u5fd8\u8bb0\u8fd8\u6709\u81ea\u8eab\u7684\u539f\u6709\u7684\u4fe1\u606f\uff08\u6b8b\u5dee\u8fde\u63a5\uff09</p> <p>\u5728\u6574\u4e2a\u91d1\u5b57\u5854\u67b6\u6784\u4e2d\uff0c\u6240\u6709\u7684\u8282\u70b9\u90fd\u662f\u9ed8\u8ba4\u548c\u81ea\u8eab\u662f\u76f8\u8fde\u7684\uff0c\u5728\u4e0d\u540c\u7684\u5e8f\u5217\u4e4b\u95f4\uff0c\u8fd9\u4e2a\u7236\u8282\u70b9\u548c\u4e24\u4e2a\u5b50\u8282\u70b9\u76f4\u63a5\u76f8\u8fde\u63a5</p> <p>\ud83d\udd34 \u4ec0\u4e48\u662f\u7236\u8282\u70b9\uff0c\u4ec0\u4e48\u662f\u5b50\u8282\u70b9?</p> <p>\u770b\u56fe,\u4ee5\u7b2c\u4e8c\u5c42\u4e3a\u4f8b, \u7b2c\u4e8c\u5c42\u7684\u5e8f\u5217\u662f\u901a\u8fc7\u7b2c\u4e00\u5c42\u7684\u5e8f\u5217,\u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u6838\u5927\u5c0f\u4e3a2, \u6b65\u957f\u4e3a2\u7684\u5377\u79ef\u5c42\u5f97\u5230\u7684, \u4e5f\u5c31\u662f\u8bf4\u5377\u79ef\u6838\u5bf9\u5e94\u7684\u8282\u70b9,\u5c31\u662f\u5b50\u8282\u70b9, \u90a3\u4e48\u5377\u79ef\u5c42\u751f\u6210\u7684\u65b0\u8282\u70b9\u5c31\u662f\u7236\u8282\u70b9, \u5f88\u663e\u7136\u5b50\u8282\u70b9\u7684\u4e2a\u6570\u53d6\u51b3\u4e8e\u5377\u79ef\u6838\u7684\u5927\u5c0f, \u540c\u6837\u7684\u89c4\u5f8b, \u5728\u4efb\u610f\u4e24\u4e24\u4e2a\u76f8\u90bb\u7684\u5c3a\u5ea6\u5e8f\u5217\u4e4b\u95f4\u662f\u4e00\u81f4\u7684,\u6bd4\u5982\u8bf4\u7b2c\u4e8c\u4e2a\u548c\u7b2c\u4e09\u4e2a\u5e8f\u5217\u4e4b\u95f4,\u7b2c\u4e09\u4e2a\u548c\u7b2c\u56db\u4e2a\u5e8f\u5217\u4e4b\u95f4\u90fd\u662f\u8fd9\u6837\u7684\u505a\u6cd5,</p> <p>\u8fd8\u6709\u4e00\u70b9\u9700\u8981\u6ce8\u610f,\u91cc\u9762\u6240\u6709\u7684\u7bad\u5934\u90fd\u662f\u53cc\u5411\u7684,\u56e0\u6b64\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u4e2d\u7684\u6ce8\u610f\u529b\u77e9\u9635\u662f\u4e00\u4e2a\u5bf9\u79f0\u77e9\u9635</p> <p>\u603b\u7ed3 \u91d1\u5b57\u5854\u6ce8\u610f\u529b</p> <p>(1)\u7b2c\u4e00\u4e2a\u7c97\u5c3a\u5ea6\u6784\u9020\u6a21\u5757,\u901a\u8fc7\u591a\u4e2a\u8fde\u7eed\u7684\u5377\u79ef\u5c42,\u6765\u521d\u59cb\u5316\u91d1\u5b57\u5854\u4e2d\u7684\u5404\u5c42\u7684\u8282\u70b9\u8868\u793a\u7684</p> <p>(2)\u7b2c\u4e8c\u6b65\u91d1\u5b57\u5854\u7684\u5185\u90e8,\u8fdb\u884cmask\u64cd\u4f5c,\u8be5\u5efa\u7acb\u8fde\u63a5\u7684\u5c31\u5efa\u7acb\u8fde\u63a5,\u4e0d\u8be5\u6709\u8fde\u63a5\u7684,\u5c31\u628a\u5b83\u4eec\u4e4b\u95f4\u7684\u6743\u91cd\u8bbe\u7f6e\u4e3a\u96f6</p> \u968f\u624b\u8865\u5145 <p> \u9886\u57df\u8fc1\u79fb,\u7136\u540e\u63cf\u8ff0\u65b9\u6cd5,\u91cd\u65b0\u89e3\u6784\u6a21\u578b\u56fe </p>"},{"location":"Reproduction/5_SegRNN_index/","title":"SegRNN","text":""},{"location":"Reproduction/5_SegRNN_index/#segrnn","title":"SegRNN","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 54 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <ul> <li> \u53ef\u9006\u5b9e\u4f8b\u6807\u51c6\u5316 \u5bf9\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u6807\u51c6\u5316</li> </ul> Text Only<pre><code>x = self.revinLayer(x, 'norm').permute(0, 2, 1)\n</code></pre> <p>\u5bf9\u9884\u6d4b\u5e8f\u5217\u8fdb\u884c\u53cd\u6807\u51c6\u5316</p> Text Only<pre><code>y = self.revinLayer(y.permute(0, 2, 1), 'denorm')\n</code></pre> <ul> <li> vscode \u7981\u7528\u65ad\u70b9\u7684\u65b9\u6cd5</li> </ul> <p> </p>"},{"location":"Reproduction/5_SegRNN_v1/","title":"\u590d\u73b0SegRNN","text":""},{"location":"Reproduction/5_SegRNN_v1/#segrnn","title":"\u590d\u73b0SegRNN","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 12975 \u4e2a\u5b57  18 \u884c\u4ee3\u7801  84 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 65 \u5206\u949f</p> <p>\u4e00\u4e9b\u94fe\u63a5\uff1a</p> <p>\u65f6\u5e8f\u9884\u6d4b\u7bc7-SegRNN\u4ee3\u7801\u89e3\u8bfb</p> <p>https://github.com/lss-1138/SegRNN/issues?q=is%3Aissue%20state%3Aclosed</p> <p>https://github.com/lss-1138/SegRNN</p> <p>\u9879\u76ee\u590d\u8ff0\u9010\u5b57\u7a3f\uff0c\u7559\u7740\u8bb2\u7ec4\u4f1a\u7528</p> <p>Hello \u5927\u5bb6\u597d\uff0c\u4eca\u5929\u6211\u7ed9\u5927\u5bb6\u8bb2 SegRNN \u7684\u8bba\u6587\u4ee5\u53ca\u5bf9\u5e94\u7684\u4ee3\u7801\uff0c\u6211\u8fd9\u6b21\u6709\u597d\u597d\u7684\u51c6\u5907\uff0c\u5927\u5bb6\u53ef\u4ee5\u597d\u597d\u542c\uff0c\u7136\u540e\u6211\u4eec\u53ef\u4ee5\u968f\u65f6\u8ba8\u8bba\u54c8\u54c8\u54c8\uff1b</p>"},{"location":"Reproduction/5_SegRNN_v1/#pre","title":"pre","text":"<p>\u9996\u5148\uff0c\u6211\u4eec\u4ece github \u4e0a\u514b\u9686\u4e0b\u6765\u7684\u9879\u76ee\u5230\u4e86\u672c\u5730\uff0c\u9996\u5148\u6309\u7167\u4f5c\u8005\u7684 readme \u4e00\u6b65\u6b65\u914d\u7f6e\u865a\u62df\u73af\u5883\u6309\u7167 requirements \u5b89\u88c5\u5e93\uff0c\u8fd0\u884c\u3002\u4ee5\u6211\u62ff\u5230\u7684\u8fd9\u4e2a SegRNN \u9879\u76ee\u4e3a\u4f8b\uff0c\u770b\u5230\u7684\u662f Shell \u811a\u672c\u8c03\u7528\u7684 python\uff0c\u6211\u770b\u8fc7\u7684\u5f88\u591a\u6df1\u5ea6\u5b66\u4e60\u7684\u9879\u76ee\u90fd\u662f\u7528\u7684 args \u4e5f\u5c31\u662f\u547d\u4ee4\u884c\u53c2\u6570\u6765\u7ed9 python \u4f20\u76f8\u5e94\u7684\u53c2\u6570\uff0c\u800c\u662f\u7528\u7684 shell \u811a\u672c\uff0c\u53ef\u4ee5\u628a \u8981\u901a\u8fc7\u547d\u4ee4\u884c\u4f20\u7ed9 python \u7684\u53c2\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u5728\u811a\u672c\u4e2d\u5b9a\u4e49\u597d\uff0c\u901a\u8fc7\u811a\u672c\u4f20\u3002</p>"},{"location":"Reproduction/5_SegRNN_v1/#python","title":"\u5e26\u53c2\u6570\u7684 python \u6587\u4ef6\u8c03\u8bd5","text":"<p>\u90a3\u8fd9\u4e2a\u65f6\u5019\uff0c\u600e\u4e48\u8c03\u8bd5 python \u5462\uff1f</p> <p>\u6211\u4eec\u6765\u770b\u5230\u8fd9\u4e2a shell \u811a\u672c\u8c03\u7528 python \u7684\u65b9\u6cd5</p> <p>\u4e00\u822c shell \u811a\u672c\u662f\u5b58\u50a8\u5728 scripts \u6587\u4ef6\u5939\u4e0b\u7684\uff0c\u4ee5 .sh \u7ed3\u5c3e\u7684\u6587\u4ef6\u3002\u597d\u6765\u770b\u5230\u8fd9\u4e2a shell \u811a\u672c\u8c03\u7528 python \u7684\u547d\u540d\u662f <code>python -u run_longExp.py</code>  \uff0c<code>-u</code> \u8868\u793a\u76f4\u63a5\u4fee\u6539python \u6587\u4ef6\u4f20\u5165\u53c2\u6570\u7684\u610f\u601d\uff0c\u8fd9\u91cc\u6211\u60f3\u8bf4\u4e00\u4e0b\uff0c\u6211\u6240\u8bb2\u7684\u5185\u5bb9\uff0c\u90fd\u662f\u6211\u6839\u636e\u81ea\u5df1\u8c03\u8bd5\u8fd9\u4e2a\u9879\u76ee\u4ee5\u53ca\u9047\u5230\u7684\u5185\u5bb9\u5b66\u4e60\u5230\u7684\uff0c\u6240\u4ee5\u8bb2\u7684\u4e0d\u5bf9\u7684\u5730\u65b9\u4e00\u5b9a\u8981\u544a\u8bc9\u6211\uff0c\u6211\u4eec\u4e00\u8d77\u8ba8\u8bba\u3002</p> <p> </p> <p>\u597d\uff0c\u56de\u5230\u6b63\u9898\uff0c\u73b0\u5728\u6211\u4eec\u5c31\u8981\u4fee\u6539 shell \u8c03\u7528 python \u6587\u4ef6\u7684\u65b9\u6cd5\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f\u6539\u6210\uff1a<code>python -m debugpy --listen 5998 --wait-for-client run_longExp.py</code></p> <p></p> <p>\u73b0\u5728\u6211\u6765\u4e00\u4e2a\u4e2a\u89e3\u91ca\u8fd9\u884c\u547d\u4ee4\u7684\u610f\u601d\uff1a</p> <p><code>-m debugpy</code> \u7684\u610f\u601d\u5c31\u662f\u8c03\u7528 <code>debugpy</code> \uff0c\u5c31\u662f\u8c03\u7528 <code>python \u8c03\u8bd5\u7a0b\u5e8f</code>\uff0c\u5bf9 python \u8fdb\u884c\u8c03\u8bd5\uff0c\u6ce8\u610f <code>debugpy</code> \u662f python \u7684\u4e00\u4e2a\u5e93\uff0c\u6240\u4ee5\u6211\u4eec\u5728\u4f7f\u7528\u8fd9\u4e2a\u7684\u547d\u4ee4\u7684\u65f6\u5019\uff0c\u9996\u5148\u5c31\u662f <code>pip install debugpy</code></p> <p><code>-listen 5998</code> \u7684\u610f\u601d\u7684\u76d1\u542c <code>5998</code> \u7aef\u53e3\uff0c\u4e5f\u5c31\u662f\u628a <code>python</code> \u7684\u8c03\u8bd5\u7a0b\u5e8f\u8fde\u63a5\u5230 <code>5998</code> \u7aef\u53e3\uff0c\u7136\u540e\u8c03\u8bd5\uff0c\u5f53\u7136\u4f60\u8bbe\u7f6e\u6210\u522b\u7684\u4e5f\u5c31\u662f\u53ef\u4ee5\u7684\uff0c</p> <p>\u90a3\u6211\u4eec\u600e\u4e48\u9009\u62e9\u7aef\u53e3\u5462\uff1f</p> <p>\u5728\u547d\u4ee4\u884c\u7ec8\u7aef\uff0c\u8fd0\u884c\u4ee5\u4e0b\u4ee3\u7801\uff0c\u67e5\u770b\u8bbe\u5907\u7684\u7a7a\u95f2\u7aef\u53e3\uff0c\u7136\u540e\u4f60\u968f\u4fbf\u9009\u4e00\u4e2a\uff0c\u5728 python \u8c03\u8bd5\u7684<code>launch.json</code>\u7684\u6587\u4ef6\u4e2d\u4fee\u6539</p> Text Only<pre><code>for port in {5000..6000}; do\n    (echo &gt; /dev/tcp/localhost/$port) &gt;/dev/null 2&gt;&amp;1 || echo \"$port is free\"\ndone\n</code></pre> <p>\u90a3\u600e\u4e48\u627e\u5230 python \u8c03\u8bd5\u6587\u4ef6\u7684 \u914d\u7f6e\u6587\u4ef6\u5462\uff1f</p> <p>\u5728VSCode\u6309<code>Command+Shift+P</code>, \u8f93\u5165<code>Debug: Add Configuration</code> \u5373\u53ef\u6253\u5f00 <code>launch.json</code>\uff0c\u5f53\u7136\u4e86\u4f60\u4e5f\u53ef\u4ee5\u5728 vscode \u65c1\u8fb9\u7684\u5c0f\u866b\u5b50\uff0c\u70b9 <code>\u65b0\u5efa launch.json</code></p> <p>\u627e\u5230\u4ee5\u540e\uff0c\u6dfb\u52a0\u4ee5\u4e0b\u914d\u7f6e\uff0c\u6ce8\u610f\u662f\u5728 <code>configration</code> \u7684\u5173\u952e\u5b57\u4e0b\u4fee\u6539\u3002</p> Text Only<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"[\u8fd9\u91cc\u66f4\u6362\u4e3a\u4efb\u610f\u540d\u79f0]\",\n            \"type\": \"python\",\n            \"request\": \"attach\",\n            \"connect\": {\n                \"host\": \"localhost\",\n                \"port\": 5998\n            }\n        }\n    ]\n}\n</code></pre> <p>\u8fd9\u662f\u6211\u7684 launch.json\u6587\u4ef6\u7684\u5b8c\u6574\u6837\u5b50\uff1a</p> Text Only<pre><code>{\n    // \u4f7f\u7528 IntelliSense \u4e86\u89e3\u76f8\u5173\u5c5e\u6027\u3002 \n    // \u60ac\u505c\u4ee5\u67e5\u770b\u73b0\u6709\u5c5e\u6027\u7684\u63cf\u8ff0\u3002\n    // \u6b32\u4e86\u89e3\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u8bbf\u95ee: https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n\n        {\n            \"name\": \"[\u8fd9\u91cc\u66f4\u6362\u4e3a\u4efb\u610f\u540d\u79f0]\",\n            \"type\": \"python\",\n            \"request\": \"attach\",\n            \"connect\": {\n                \"host\": \"localhost\",\n                \"port\": 5998\n            }\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (type in script name)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${command:AskForScriptName}\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (select script from list of sh files)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${command:SelectScriptName}\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (hardcoded script name)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${workspaceFolder}/path/to/script.sh\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (simplest configuration)\",\n            \"program\": \"${file}\"\n        }\n    ]\n}\n</code></pre> <p>\u60f3\u8bf4\u660e\u7684\u662f\uff0c\u6211\u8fd9\u91cc\u8fd8\u914d\u7f6e\u4e86\uff0c\u811a\u672c\u7684\u8c03\u8bd5\uff0c\u5206\u522b\u662f\uff1a</p> <p><code>\"Bash-Debug (type in script name)\"</code>  \u8868\u793a\u901a\u8fc7\u8f93\u5165\u811a\u672c\u540d\u79f0\u542f\u52a8\u8c03\u8bd5</p> <p><code>\"Bash-Debug (select script from list of sh files)\",</code> \u901a\u8fc7\u811a\u672c\u5217\u8868\u9009\u62e9\u8c03\u8bd5\u6587\u4ef6\uff0c\u7b49\u7b49\uff0c\u5c31\u4e0d\u8bf4\u4e86\uff0c\u56e0\u4e3a\u6211\u4e5f\u4e0d\u662f\u7279\u522b\u660e\u767d\uff0c\u8fd9\u91cc\u7684\u914d\u7f6e\u4e3b\u8981\u662f\u5bf9 shell \u811a\u672c\u7684\u8c03\u8bd5\uff0c\u914d\u7f6e\u4e86\u8fd9\u4e2a\uff0c\u90a3\u4e48 shell \u811a\u672c\u4e5f\u5c31\u53ef\u4ee5\u8c03\u8bd5\u4e86\u3002</p> <p>\u597d\u4e86\uff0c\u73b0\u5728\u5173\u4e8e <code>--listen</code> \u53c2\u6570\u8bb2\u5b8c\u4e86\uff0c\u8bb2\u4e0b\u4e00\u4e2a\u53c2\u6570  <code>--wait-for-client</code></p> <p>\u8fd9\u4e2a\u7684\u610f\u601d\u662f\u8bf4\uff0c\u6211\u4eec\u5728\u542f\u52a8\u811a\u672c\u7684\u65f6\u5019\uff0c\u8981\u7b49\u5f85\u8fde\u63a5\u8c03\u8bd5\u7a0b\u5e8f\uff0c\u624d\u80fd\u6b63\u5e38\u8c03\u8bd5\uff0c\u610f\u601d\u5c31\u662f \u8fd0\u884c\u811a\u672c\u4ee5\u540e\uff0c\u70b9\u4e00\u4e0b\u5de6\u8fb9\u7684\u5c0f\u866b\u5b50\uff0c\u9009\u62e9 \u6211\u4eec\u914d\u7f6e\u7684 \u8c03\u8bd5\u5668\uff0c\u5c31\u662f\u6211\u4eec\u8bbe\u7f6e\u7684 name\uff0c\u5c31\u9009\u6211\u4eec\u6709\u76d1\u542c\u7a97\u53e3\u7684\u90a3\u4e2a\u3002</p> <p>\u8fd9\u6837\u6211\u4eec\u5728 \u8c03\u7528\u7684python <code>run_longExp.py</code> \u4e0a\uff0c\u6253\u65ad\u70b9\u5e76\u8fd0\u884c\u811a\u672c\uff0c\u5c31\u53ef\u4ee5\u8c03\u8bd5\u4e86\u3002</p> <p>\ud83d\udfe2 \u8fd8\u6709\u53e6\u4e00\u79cd\u65b9\u6cd5\uff0c\u5c31\u662f\u76f4\u63a5\u628a\u811a\u672c\u6587\u4ef6\u4e22\u7ed9 chatgpt\u8bf4\uff1a\u8bf7\u4f60\u6839\u636e\u8fd9\u4e2a\u811a\u672c\u6587\u4ef6\u5199\u4e00\u4e2a\u53ef\u4ee5\u7528\u4e8e\u8c03\u8bd5\u914d\u7f6e\uff0c\u6dfb\u52a0\u5230 <code>launch.json</code></p> <p>\u7c7b\u4f3c\uff1a</p> Text Only<pre><code>       {\n            \"name\": \"Python: run_longExp.py\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"program\": \"${workspaceFolder}/run_longExp.py\",\n            \"args\": [\n                \"--model_id\", \"illness_60_24\",\n                \"--is_training\", \"1\" ,\n                \"--model\", \"SegRNN\", \n                \"--data\", \"custom\",\n                \"--root_path\", \"./dataset/\",\n                \"--data_path\", \"national_illness.csv\",\n                \"--features\", \"M\",\n                \"--seq_len\", \"60\",\n                \"--pred_len\", \"24\",\n                \"--d_model\", \"512\",\n                \"--dropout\", \"0.0\",\n                \"--rnn_type\", \"gru\",\n                \"--dec_way\", \"pmf\",\n                \"--seg_len\", \"12\",\n                \"--loss\", \"mae\",\n                \"--des\", \"test\",\n                \"--itr\", \"1\",\n                \"--train_epochs\", \"2\",\n                \"--num_workers\", \"0\"\n            ],\n            \"console\": \"integratedTerminal\",\n            \"justMyCode\": true,\n            \"cwd\": \"${workspaceFolder}\"\n        },\n</code></pre> <p>\u8fd9\u4e2a\u53eb\u4ee5 \u542f\u52a8\u6a21\u5f0f\u8c03\u8bd5\u6587\u4ef6\uff0c\u521a\u521a\u4ecb\u7ecd\u7684\u53eb\u505a attach \u9644\u52a0\u6a21\u5f0f\u3002\u8fd9\u79cd\u8bbe\u7f6e\u7684\u597d\u5904\u662f\uff0c\u76f4\u63a5\u9009\uff0c\u76f4\u63a5\u8c03\uff0c\u8d85\u65b9\u4fbf\uff1a</p> <p></p> <p>\u54e6\uff0c\u5bf9\u4e86\uff0c\u600e\u4e48\u8fd0\u884c\u811a\u672c\u6587\u4ef6</p> <p>\u5728 vscode \u7684\u547d\u4ee4\u884c\u5c31\u53ef\u4ee5\u76f4\u63a5\u8fd0\u884c\u4e24\u79cd\u65b9\u6cd5\uff0c\u4e00\u4e2a\u662f <code>./\u4f60\u60f3\u8fd0\u884c\u7684\u811a\u672c\u6587\u4ef6\u7684\u8def\u5f84</code>\uff0c\u8fd8\u6709\u5c31\u662f <code>sh \u4f60\u60f3\u8fd0\u884c\u7684\u811a\u672c\u6587\u4ef6\u7684\u8def\u5f84</code>\uff0c\u8fd9\u4e24\u79cd\u65b9\u6cd5\uff0c\u6709\u70b9\u533a\u522b\uff0c\u4f46\u6211\u8fd8\u6ca1\u6709\u53ef\u4ee5\u7684\u533a\u5206\u3002\u54e6\uff0c\u5bf9\u4e86\uff0c\u5982\u679c\u6709\u7684\u65f6\u5019\uff0c\u53ef\u80fd\u9700\u8981\u5148\u6dfb\u52a0\u6743\u9650\uff0c\u624d\u80fd\u6b63\u5e38\u7684\u8fd0\u884c shell \u811a\u672c\uff0c\u5177\u4f53\u5c31\u662f\u5728\u8fd0\u884c\u811a\u672c\u524d\u6267\u884c chang mode \u6dfb\u52a0 \u6267\u884c\u6743\u9650\uff0c\u5177\u4f53\u7684\u547d\u4ee4\u5c31\u662f\u547d\u4ee4\u884c\u76f4\u63a5\u8f93\u5165\uff1a <code>chmod +x \u811a\u672c\u6587\u4ef6\u540d\u79f0</code></p> <p></p> <p>\u4ee5\u4e0a\u662f\u7b2c\u4e00\u90e8\u5206\u7684\u8bb2\u89e3\uff1ashell \u8c03\u7528\u7684python\uff0c\u6211\u4eec\u600e\u4e48\u8fdb\u884c\u8c03\u8bd5\u3002</p> <p>\u73b0\u5728\u6211\u4eec\u7ec8\u4e8e\u53ef\u4ee5\u8c03\u8bd5 \u6211\u4eec\u7684\u9879\u76ee\u4e86\u3002\u5f00\u59cb\u3002</p>"},{"location":"Reproduction/5_SegRNN_v1/#_1","title":"\u8c03\u8bd5\u9879\u76ee\u6587\u4ef6","text":"<p>\u9996\u5148**\u7b2c\u4e00\u4e2a\u65ad\u70b9**\uff0c\u6253\u5230\u8c03\u7528\u7684 python \u6587\u4ef6\u7684\u5f00\u59cb\uff0c</p> <p></p> <p>\u6211\u628a\u8fd9\u4e2a  <code>run_longExp</code>\u6587\u4ef6\uff0c\u53eb\u505a**\u9879\u76ee\u4e3b\u6587\u4ef6**\uff0c\u4e3b\u8981\u5305\u62ec\u7684\u6a21\u578b\u7684\u8fed\u4ee3\u8bad\u7ec3\uff0c\u6574\u4e2a\u9879\u76ee\u7684 python \u53c2\u6570\u8bbe\u7f6e\uff0c\u800c\u7b49\u4e00\u4e0b\u6211\u4eec \u4f1a\u770b\u5230\u8fd9\u4e2a  <code>run_longExp.py</code> \u4f1a\u9891\u7e41\u8c03\u7528 <code>exp_main.py</code>\uff0c\u6211\u628a\u5b83 \u53eb \u6a21\u578b\u4e3b\u6587\u4ef6\uff0c\u4e3b\u8981\u5305\u542b\u7684\u4e1c\u897f\u5c31\u662f\uff0c\u8fd0\u884c\u4e00\u6b21\u6a21\u578b\u6211\u4eec\u9700\u8981\u52a0\u8f7d\u7684\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002</p> <p>\u7136\u540e\u5e94\u8be5\u6253\u7684\u65ad\u70b9\u5c31\u662f <code>\u521d\u59cb\u5316init</code> \u5904\uff0c\u548c<code>\u8bad\u7ec3 forward \u5904\u3001\u6216\u8005 train \u5904\u3001\u6216\u8005\u8c03\u7528\u7684 model(x)\u5904</code>\u3002</p> <p><code>\u521d\u59cb\u5316 init</code> \u5904\uff0c\u53ef\u4ee5\u8ba9\u6211\u4eec\u77e5\u9053 \u6587\u4ef6\u4e4b\u95f4\u7684\u8c03\u7528\u5173\u7cfb\uff0c\u56e0\u4e3a\u8d8a\u597d\u7684\u9879\u76ee\u5c01\u88c5\u7684\u8d8a\u597d\uff0c\u4f46\u662f\u4e5f\u8d8a\u62bd\u8c61\uff0c\u9700\u8981\u4e0d\u65ad\u7684\u634b\u660e\u767d\u7c7b\u4e4b\u95f4\u7684\u8c03\u7528\u5173\u7cfb\uff0c\u800c\u7c7b\u53c8\u5c01\u88c5\u5230\u4e00\u4e2a\u4e2a python \u6587\u4ef6\u4e2d\u3002</p> <p>forward \u7684\u5730\u65b9\uff0c\u80fd\u8ba9\u6211\u4eec\u770b\u5230 \u6570\u636e\u6d41\u52a8\u4ee5\u53ca\u53d8\u5316\uff0c\u8fd9\u662f\u6700\u91cd\u8981\u7684\u90e8\u5206\u4e86\u3002</p> <p>\u8fd8\u6709\u4e00\u4e9b\u4f60\u4e0d\u660e\u767d\u7684\u5730\u65b9\u6216\u8005\u4ec0\u4e48\u7684\uff0c\u60f3\u6253\u65ad\u70b9\u5c31\u6253\u65ad\u70b9\u3002\u597d\u4e86\uff0c\u8fd9\u662f\u6211\u60f3\u8bf4\u7684\u6253\u65ad\u70b9\u7684\u4e00\u4e0b\u7ecf\u9a8c\u3002</p> <p>\u4e0b\u9762\u7ee7\u7eed\u5f00\u59cb\u6211\u7684\u65ad\u70b9 \uff0c\u6211\u7684\u7b2c\u4e8c\u4e2a\u65ad\u70b9\u5728\uff1a</p> Text Only<pre><code>Exp = Exp_Main\n</code></pre> <p>\u8fd9\u4e2a\u65ad\u70b9\u662f\u6211\u60f3\u6253 init \u65ad\u70b9 <code>exp = Exp(args)</code> \u548c forward \u65ad\u70b9 <code>exp.train(setting)</code> \u65f6\uff0c\u9047\u5230\u7b2c\u4e00\u4e2a\u6bd4\u8f83\u4e0d\u660e\u767d\u7684\u5730\u65b9\uff0c\u6211\u4e0d\u660e\u767d\uff0c\u56e0\u4e3a\u6211\u7b2c\u4e00\u6b21\u770b\u5230\u8fd9\u4e48\u505a\u7684\u3002</p> <p>\u8fd9\u91cc\u7684\u903b\u8f91\u662f\u4ec0\u4e48\u5462\uff1f</p> <p>\u8fd9\u91cc\u5176\u5b9e\u662f\u7c7b\u7684\u91cd\u547d\u540d\uff0c\u4e5f\u662f <code>Exp_Main</code> \u672c\u8eab\u5c31\u662f\u4e00\u4e2a\u7c7b\uff0c\u4f46\u662f\u5728\u9879\u76ee\u4e3b\u6587\u4ef6\u7528\u8fd9\u4e2a\u7c7b\u7684\u65f6\u5019\uff0c\u91cd\u547d\u540d\u4e86\u4e00\u4e0b\uff0c\u540e\u9762\u5728\u9879\u76ee\u4e3b\u6587\u4ef6\u7528\u7684\u65f6\u5019\uff0c\u7528\u7684\u90fd\u662f\u8fd9\u4e00\u4e2a\u91cd\u547d\u540d\u7684\u7c7b\uff0c\u7136\u540e\u7528\u8fd9\u4e2a\u91cd\u547d\u540d\u7684\u7c7b\uff0c\u8fdb\u884c\u7684\u5b9e\u4f8b\u5316\u3002</p> <p>\u6211\u73b0\u5728\u60f3\u8bf4\u4e00\u4e0b\uff0c\u8fd9\u4e2a<code>Exp_Main</code>\uff0c\u662f\u4ece\u54ea\u91cc\u6765\u7684\uff1a from exp.exp_main import Exp_Main\uff0c\u662f\u8fd9\u53e5\u8bdd\u3002\u4e5f\u5c31\u662f \u8fd9\u4e2a\u7c7b \u5728 exp \u6587\u4ef6\u5939\u4e0b exp_main.py \u7684 Exp_Main \u7c7b\u3002\u8bb0\u4f4f\u8fd9\u4e2a<code>\u6a21\u578b\u4e3b\u6587\u4ef6 exp_main.py</code>\uff0c\u56e0\u4e3a\u7ecf\u5e38\u7528\u3002</p> <p>\u7136\u540e\u6ca1\u4ec0\u4e48\u60f3\u8bf4\u7684\u4e86\uff0c\u8fdb\u5165\u4e0b\u4e00\u4e2a\u90e8\u5206\uff0c\u7c7b\u7684 \u521d\u59cb\u5316 <code>exp = Exp(args)</code> </p> <p>\u54e6\uff0c\u5bf9\uff0c\u4f60\u770b\u6211\u8fd9\u513f\uff0c\u6211\u8fd8\u5728 setting \u8fd9\u6253\u4e86\u4e00\u4e2a\u8bb0\u5f55\u70b9\uff0c\u5c31\u662f\u6211\u4e0d\u660e\u767d\u7684\u5730\u65b9</p> <p></p> <p>\u65ad\u70b9\u7684\u7c7b\u578b\u8fd8\u662f\u633a\u591a\u7684\uff0c\u76f4\u63a5\u65ad\u70b9\u3001\u8bb0\u5f55\u70b9\uff0c\u6761\u4ef6\u65ad\u70b9\uff0c\u547d\u4e2d\u6b21\u6570\u65ad\u70b9\u3002\u8bb0\u5f55\u70b9\u4e0d\u505c\uff0c\u5c31\u662f\u6253\u5370\u4fe1\u606f\u3002\u6211\u6709\u4e9b\u65ad\u70b9\u4e4b\u524d\u4e0d\u660e\u767d\u5c31\u662f\u666e\u901a\u65ad\u70b9\uff0c\u660e\u767d\u4e86\u5c31\u53d8\u6210\u4e86\u8bb0\u5f55\u70b9\uff0c\u4e0d\u60f3\u505c\u4e86\u4f46\u662f\u505a\u4e2a\u6807\u8bb0\uff0c\u7136\u540e\u4e0d\u660e\u767d\u7684\u5730\u65b9\u4e5f\u6807\u8bb0\u4e00\u4e0b\uff0c\u4e5f\u5f04\u6210\u8bb0\u5f55\u70b9\u3002\u540e\u9762\u518d\u770b\u3002</p> <p>\u597d\uff0c\u7ee7\u7eed\u56de\u5230\uff0c<code>exp = Exp(args)  # set experiments</code></p> <p>\u70b9\uff0c\u6b65\u8fdb\u3002</p> <p>\u6b65\u8fdb\u5c31\u662f\u4e00\u6b65\u6b65\u6267\u884c\uff0c\u4f1a\u8fdb\u5165\u5230\u51fd\u6570\u5185\u90e8\uff0c\u9010\u8fc7\u7a0b\u5c31\u662f\u9010\u6b65\u6267\u884c\uff0c\u4e0d\u4f1a\u8fdb\u5165\u8c03\u7528\u7684\u51fd\u6570\uff0c\u7136\u540e\u8fd8\u6709\u7ee7\u7eed\u6267\u884c\uff0c\u5c31\u662f\u4e00\u76f4\u6267\u884c\uff0c\u76f4\u5230\u9047\u5230 \u4e0b\u4e00\u4e2a\u65ad\u70b9\u3002</p> <p></p> <p>\u56e0\u4e3a\u6211\u5df2\u7ecf\u5b9e\u73b0\u6807\u4e86\u4e00\u4e2a\u8bb0\u5f55\u70b9\uff0c\u7136\u540e\u6b65\u8fdb \u6267\u884c\u5230\u8fd9\u53e5\uff0c\u4e5f\u89e6\u53d1\u4e86\u8bb0\u5f55\u70b9\u3002\u6253\u5370\u4e86\u4fe1\u606f\u3002\u82b1\u62ec\u53f7\u5305\u88f9\u7684\u90e8\u5206\uff0c\u4f1a\u81ea\u52a8\u66ff\u6362\u6210 python \u7a0b\u5e8f\u7684\u53d8\u91cf\uff0c\u8f93\u51fa\u5230\u8c03\u8bd5\u63a7\u5236\u53f0\u3002</p> <p>\u60f3\u8bf4\u660e\u7684\u5c31\u662f\uff0c\u8fd9\u91cc\u80fd\u505c\u6b62\uff0c\u662f\u56e0\u4e3a\u6b65\u8fdb\u5230\u4e86\u8fd9\u91cc\uff0c\u5e76\u4e0d\u662f\u56e0\u4e3a\u6253\u4e86\u8bb0\u5f55\u70b9\u3002</p> <p>\u8bf4\u5b8c\u4e86\u3002\u7136\u540e\u7ee7\u7eed\u56de\u5230 \u9879\u76ee\u7684\u6267\u884c\u3002</p> <p>\u8fd9\u91cc\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u8fdb\u5165\u4e86 <code>Exp_Main</code>\u7684 <code>init</code> \u90e8\u5206\uff0c\u6211\u8bb0\u8fd9\u4e2a\u5c31\u662f\u6253\u5370\u4e00\u4e0b\u8def\u5f84\uff0c\u56e0\u4e3a\u6700\u5f00\u59cb\u770b\u7684\u65f6\u5019\uff0c\u592a\u4e71\u4e86\uff0c\u5404\u79cd\u8c03\u7528\uff0c\u5934\u90fd\u6655\u4e86\u3002</p> <p>\u8fd9\u91cc\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u4ece \u9879\u76ee\u4e3b\u6587\u4ef6 run long exp.py\uff0c\u8fdb\u5165\u4e86 \u6a21\u578b\u4e3b\u6587\u4ef6 exp_main.py \u6a21\u578b\u7684\u7684init \u548c train\u8bad\u7ec3\u8fc7\u7a0b \u90fd\u5728\u8fd9\u91cc\u4e86\u3002</p> <p>\u8f93\u51fa\u7684\u610f\u601d\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u73b0\u5728\u5230\u4e86 <code>exp</code> \u6587\u4ef6\u5939\u4e0b\uff0c<code>exp_main.py</code>\u7684 <code>Exp_Main\u7c7b</code> \u7684 init \u65b9\u6cd5\u3002</p> <p>\u8fd9\u91cc\u6709\u60f3\u8bf4\u7684\u5730\u65b9\uff0c\u662f\u56e0\u4e3apython\u7684\u7ee7\u627f\u7684\uff0c\u4f60\u770b\u8fd9\u4e2a class Exp_Main \u662f\u7ee7\u627f\u7684\u7236\u7c7b</p> <p>\u5173\u4e8e python \u7684\u7ee7\u627f\u548c\u591a\u6001\u60f3\u8bf4\u660e\u7684\u662f\uff1a</p> <p>\u6211\u73b0\u5728\u628a\u7c7b\u7684\u91cd\u547d\u540d\u662f\u7406\u89e3\u4e3a \u591a\u6001\uff08\u9519\uff01\uff09\uff0c\u6709\u7406\u89e3\u66f4\u597d\u7684\u6b22\u8fce\u627e\u6211\u8ba8\u8bba\uff0c\u800c\u7c7b\u7684\u7ee7\u627f\u4e00\u822c\u5c31\u662f \u7c7b\u7684\u540d\u79f0\u5c0f\u62ec\u53f7\u91cc\u7684\u4e1c\u897f <code>class Exp_Main(Exp_Basic):</code>\uff0c\u6216\u8005\u4f60\u770b\u7c7b init \u65b9\u6cd5\u4e0b\u9762\u7684\u7b2c\u4e00\u53e5 super \u4ec0\u4e48\u4ec0\u4e48\u7684<code>super(Exp_Main, self).__init__(args)</code></p> <p>\u7136\u540e\uff0c\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6765\u8bf4\uff0c\u4e00\u822c\u662f\u7ee7\u627f\u81ea <code>nn.Module</code>\u7684\uff0c\u800c\u8fd9\u91cc\u7ee7\u627f\u7684\u662f <code>Exp_Basic</code> \uff0c\u4e5f\u5c31\u662f\u4e5f\u662f\u4e00\u4e2a\u81ea\u5b9a\u4e49\u51fd\u6570\uff0c\u90a3\uff0c\u8bdd\u4e0d\u591a\u8bf4\uff0c</p> <p>\u6b65\u8fdb\uff0c\u770b\u770b\u5b83\u5230\u5e95\u662f\u4ec0\u4e48\u4e1c\u897f\uff0c\u8bf6\uff0c\u7136\u540e\u6211\u4eec\u5c31\u770b\u5230\u4e86\uff0cExp_Main\u6709\u7684\uff0cExp_Basic\u90fd\u6709\uff0c\u65b9\u6cd5\u90fd\u662f\u4e00\u6837\u7684\uff0c\u4f46\u662f Exp_Main \u66f4\u5168\uff0c\u76f8\u5f53\u4e8e Exp_Basic\u662f\u4e00\u4e2a\u6a21\u7248</p> <p></p> <p>\u73b0\u5728\u6211\u4eec\u6b65\u8fdb\u5230\u4e86\u7ee7\u627f\u7684\u7236\u7c7b\u6587\u4ef6\uff0c\u5f00\u59cb\u9010\u6b65\u6267\u884c\u8fd9\u91cc\uff0c\u4e00\u6b65\u6b65\u7684</p> <p></p> <p>\u5230\u8fd9\u91cc\uff0c\u60f3\u8bf4\u7684\u662f\uff0c\u6d89\u53ca\u5230\u4e86 \u65b9\u6cd5\u7684\u91cd\u5199\uff0c\u4e5f\u5c31\u662f \u5b50\u7c7b\u548c\u7236\u7c7b\u4e2d\u90fd\u6709 \u8fd9\u4e2a <code>self._build_model()</code>\uff0c\u4f46\u662f \u5f88\u660e\u663e\u7236\u7c7b\u4e2d\u4ec0\u4e48\u4e5f\u6ca1\u6709\uff0c\u4f46\u662f\u5b50\u7c7b\u66f4\u5168\uff0c\u65b9\u6cd5\u91cd\u5199\u662f\uff0c\u5148\u770b\u5b50\u7c7b\u7684\uff0c\u5b50\u7c7b\u6ca1\u6709\u91cd\u5199\uff0c\u5c31\u6267\u884c\u7236\u7c7b\uff0c\u6240\u4ee5\u5f53\u9010\u6b65\u6267\u884c\u7684\u65f6\u5019\uff0c\u4e0b\u4e00\u6b65\uff0c\u6211\u4eec\u53c8\u8fd4\u56de\u5230\u4e86 \u6a21\u578b\u4e3b\u6587\u4ef6\u7684 <code>._build_model()</code>\uff0c\u65b9\u6cd5\u3002</p> <p>\u65e2\u7136\u56de\u5230\u4e86 \u6a21\u578b\u4e3b\u6587\u4ef6\u7684 <code>build_model</code> \u65b9\u6cd5\uff0c\u90a3\u5c31\u770b\uff0c\u9996\u5148\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5b57\u5178\uff0c\u901a\u8fc7\u5b57\u7b26\u4e32 \u6240\u4ee5\u5230\u5bf9\u5e94\u7684\u7c7b\uff0c\u56e0\u4e3a\u7d22\u5f15\u5230\u4e86\u7c7b\uff0c\u6211\u4eec\u624d\u80fd\u7ee7\u7eed\u64cd\u4f5c\u5440\uff0c\u6bd4\u5982\u5b9e\u4f8b\u5316\uff0cforward\u3002</p> <p>\u7136\u540e\u5c31\u5230\u4e86 model \u7684\u5b9a\u4e49</p> <p><code>model = model_dict[self.args.model].Model(self.args).float()</code></p> <p>\u901a\u8fc7 <code>self.args.model</code> \u53c2\u6570\u53bb\u5b57\u5178\u4e2d <code>model_dict</code> \u4e2d\u7d22\u5f15\u5230\u7c7b\uff0c\u7136\u540e\u8c03\u7528\u8fd9\u4e2a\u7c7b\u7684\u989d <code>.Model()</code> \u65b9\u6cd5\uff0c<code>float</code> \u4e0d\u8bf4\u4e86\uff0c\u5c31\u662f\u8f6c\u6362\u6570\u636e\u7c7b\u578b</p> <p>\u8fd9\u91cc\u4f20\u5165\u7684\u53c2\u6570\uff0c\u4e5f\u5c31\u662f <code>self.args.model=SegRNN</code>\uff0c\u662f\u4e2a\u5b57\u7b26\u4e32\uff0c\u901a\u8fc7\u5b57\u5178\u7d22\u5f15\u5230\u4e86\u7c7b\uff0c\u5e76\u4e14\u662f\u81ea\u5b9a\u4e49\u7684\u7c7b\uff0c\u5e76\u4e14\uff0c\u7c7b\u662f\u5148 <code>init \u521d\u59cb\u5316</code>\uff0c\u7136\u540e forward \u4f20\u5165\u6570\u636e\uff0c\u8fdb\u884c\u6570\u636e\u7684\u6d41\u52a8\uff0c\u6240\u4ee5\u8fd9\u53e5\u5e94\u8be5\u662f\u4e5f\u662f\u5230\u4e86<code>\u67d0\u4e2a init</code> \u4e2d\uff0c\u90a3\u8bdd\u4e0d\u591a\u8bf4\uff0c\u6b65\u8fdb\uff0c\u5982\u6211\u4eec\u6240\u6599\uff0c\u5c31\u662f\u5230\u4e86 SegRNN.py Model\u65b9\u6cd5\u4e2d\u7684 init\uff0c</p> <p></p> <p>\u55ef\uff0c\u56e0\u4e3a\u6211\u4e4b\u524d\u4e5f\u6253\u4e86\u4e00\u4e2a\u8bb0\u5f55\u70b9\uff0c\u6240\u4ee5\u8c03\u8bd5\u63a7\u5236\u53f0\u6709\u8f93\u51fa\u3002\u73b0\u5728\u6211\u4eec\u73b0\u5728\u7684\u4f4d\u7f6e\uff0cmodels \u6587\u4ef6\u4e0b\uff0cSegRNN.py \u7684 Model \u7c7b\u4e2d\uff0c\u5e76\u4e14\u8c03\u7528\u7684\u662f init \u65b9\u6cd5\u3002</p> <p></p> <p>\u4e0d\u4fe1\u4f60\u5c31\u4e00\u4e2a\u4e2a\u70b9\u70b9\u770b\u770b\uff1a</p> <p></p> <p>\uff0c\u4f60\u6309\u4f4f command \u4e5f\u53ef\u4ee5\u8df3\u5230\u5b9a\u4e49\u7684\u5730\u65b9\u3002\u4e00\u6837\u7684\u3002</p> <p>\u63a5\u4e0b\u6765\u5c31\u770b\u8fd9\u4e2a SegRNN \u7684 init \u65b9\u6cd5\uff0c\u76f4\u63a5\u70b9 \u7ee7\u7eed\uff0c\u8df3\u5230\u4e0b\u4e00\u4e2a\u65ad\u70b9\uff0c\u6ce8\u610f\u8fd9\u884c\uff1a</p> <p></p> <p>\u8fd9\u884c\u662f \u53ef\u9006\u5b9e\u4f8b\u5316\u5c42\uff0c\u8fd9\u91cc\u53ef\u4ee5\u63d0\u524d\u8bf4\u4e00\u4e0b\uff0c\u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\u6765\u8bf4\uff0c\u6709\u4e24\u79cd\u5f52\u4e00\u5316\uff0c\u4e4b\u524d\u8bf4\u8fc7 BatchNorm \u548c LayerNorm\uff0c\u4e00\u4e2a\u6309\u5217\u5f52\u4e00\u5316\uff0c\u4e00\u4e2a\u6309\u884c\u5f52\u4e00\u5316\uff1b\u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\u6765\u8bf4\u5206\u522b\u8fdb\u884c\u4e86 \u5168\u5c40\u5f52\u4e00\u5316\uff0c\u5c31\u662f\u6574\u4e2a \u6837\u672c\u96c6\u7ef4\u5ea6\u7684\u5f52\u4e00\u5316\uff0c\u51cf\u5747\u503c\u9664\u4ee5\u65b9\u5dee\uff0c\u76f8\u5f53\u4e8e\u4e0d\u5212\u5206 batch \u7684\u5f52\u4e00\u5316\uff1b\u5b9e\u4f8b\u5f52\u4e00\u5316 \u76f8\u5f53\u4e8e \u5212\u5206\u51fa\u6765\u7684 \u540c\u4e00\u4e2a\u6837\u672c\u5185 \u540c\u4e00\u4e2a\u7279\u5f81\u7684\u5f52\u4e00\u5316\u3002\u5bf9\u4e8e</p>"},{"location":"Reproduction/5_SegRNN_v1/#_2","title":"\u6807\u51c6\u5316\u65b9\u6cd5\u8865\u5145","text":"<p>\u7528\u4ee5\u4e0b\u8fd9\u51e0\u5f20\u56fe\u6765\u76f4\u89c2\u7684\u770b\u4e00\u4e0b\uff1a</p> <p>BatchNorm\uff1a </p> <p></p> <p>LayerNorm</p> <p></p> <p>\u5b9e\u4f8b\u5f52\u4e00\u5316</p> <p> </p> <p>\u9664\u4e86\uff0c\u6279\u5f52\u4e00\u5316\uff0c\u5c42\u5f52\u4e00\u5316\uff0c\u5b9e\u4f8b\u5f52\u4e00\u5316\uff0c\u8fd8\u60f3\u7ed9\u5927\u5bb6\u8865\u5145\u4e00\u4e2a \u5206\u7ec4\u5f52\u4e00\u5316\uff0c\u53ef\u4ee5\u8865\u5145\u4e00\u4e2a\u5c0f\u70b9\u5c31\u662f\u5206\u7ec4\u5377\u79ef\u3002\u610f\u601d\u5c31\u662f\u5bf9\u56fe\u50cf\u4e2d\u7684\u901a\u9053\u5206\u7ec4\uff0c\u5206\u522b\u8bad\u7ec3\u6bcf\u4e00\u4e2a\u7ec4\u5185\u7684\u5377\u79ef\u6838\u3002\u4f20\u7edf\u5377\u79ef\u662f\u4e00\u5f203 \u901a\u9053\u56fe\u7247\u5bf9\u5e94\u4e00\u4e2a\u597d\u51e0\u4e2a 3 \u901a\u9053\u7684\u5377\u79ef\u6838\uff0c\u5bf9\u4e8e\u5206\u7ec4\u6765\u8bf4\uff0c\u53ef\u80fd\u5c31\u662f\u4e00\u5f20 4 \u901a\u9053\u7684\u7279\u5f81\u56fe\uff0c\u5bf9\u524d 2 \u4e2a\u901a\u9053\u7528\u4e00\u4e2a\u5377\u79ef\u6838\uff0c\u5bf9\u540e2\u4e2a\u901a\u9053\u7528\u4e00\u4e2a\u5377\u79ef\u6838\uff0c\u8fd9\u6837\u5b66\u7684\u597d\u5904\u5c31\u662f\u66f4\u7cbe\u7ec6\u7684\u5b66\u4e60\u7279\u5f81\u3002\u7ec4\u5f52\u4e00\u5316\u7684\u56fe\uff1a</p> <p></p> <p>\u54e6\uff0c\u5bf9\uff0c\u8bf4\u5230\u8fd9\u4e2a\u5206\u7ec4\u5377\u79ef\uff0c\u5176\u5b9e\u5377\u79ef\u8fd8\u6709\u81a8\u80c0\u5377\u79ef\uff0c\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\uff0c\u8f6c\u7f6e\u5377\u79ef\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u6240\u8c13\u7684\u8f6c\u7f6e\u5377\u79ef\u662f\u6307\u6062\u590d\u539f\u59cb\u56fe\u7247\u7684\u5f62\u72b6\uff0c\u5e76\u4e0d\u662f\u5b8c\u5168\u6062\u590d\u539f\u59cb\u56fe\u7247\u7b49\uff0c\u597d\uff0c\u80fd\u62d3\u5c55\u7684\u5df2\u7ecf\u62d3\u5c55\u5b8c\u4e86\u3002\u63d0\u4e00\u4e0b\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u5c31\u662f \u6df1\u5ea6\u5377\u79ef\u548c \u9010\u70b9\u5377\u79ef\u3002\u6df1\u5ea6\u5377\u79ef\u5c31\u662f\u4e00\u5f20\u56fe\uff0c\u6709\u51e0\u4e2a\u901a\u9053\u5c31\u7528\u5206\u6210\u51e0\u4e2a\u7ec4\uff0c\u5c31\u7528\u51e0\u4e2a\u5377\u79ef\u6838\u3002\u9010\u70b9\u5377\u79ef\u5c31\u662f 1\u00d71 \u7684\u5377\u79ef\u6838\uff0c\u70b9\u5bf9\u70b9\u7684\u5377\u79ef\u3002</p>"},{"location":"Reproduction/5_SegRNN_v1/#_3","title":"\u5377\u79ef\u8865\u5145","text":"<p>\u8bf6\uff0c\u5bf9\u8fd8\u60f3\u8bf4\u4e00\u70b9\uff0c\u5c31\u662f \u5728\u505a\u56fe\u50cf\u7684\u65f6\u5019\uff0cconv \u5c42\u7684\u5b9a\u4e49\u662f\uff08inputchannel\uff0coutputchannel\uff0ckernelsize\uff0cpadding\uff0cstride\uff09</p> <p>\u5f53\u6211\u4eec\u770b\u5230 kernelsize=3\uff0cpadding=1 \u7684\u65f6\u5019\uff0c\u5c31\u53ef\u4ee5\u76f4\u63a5\u8bf4\u662f\u4e0d\u53d8\u5377\u79ef\uff0c\u5168\u79f0\u5c31\u662f\u4e0d\u53d8\u5f62\u72b6\u5377\u79ef\u3002\u4e0d\u53d8\u5f62\u72b6\u5377\u79ef\u8fd8\u6709 1\u00d71 \u7684\u5377\u79ef\uff0c\u4e5f\u662f\u4e0d\u6539\u53d8\u7279\u5f81\u56fe\u5927\u5c0f\u7684\uff0c\u53ea\u662f\u6539\u53d8\u901a\u9053\u6570\uff0c\u7528\u4e8e\u5347\u7ef4\u548c\u964d\u7ef4\uff0c\u5bf9\u4e8e\u56fe\u7247\u6765\u8bf4\uff0c\u7ef4\u5ea6\u5c31\u662f\u901a\u9053\u6570\u3002\u8fd9\u4e9b\u90fd\u662f\u5728 stride=1 \u7684\u60c5\u51b5\u4e0b\u3002</p> <p></p> <p></p> <p>\u597d\uff0c\u56de\u5230\u8fd9\u4e2a\u5b9e\u4f8b\u5f52\u4e00\u5316\u3002</p>"},{"location":"Reproduction/5_SegRNN_v1/#segrnn-init","title":"SegRNN init","text":"<p>\u7ee7\u7eed\u8c03\u8bd5\u6211\u4eec\u7684\u9879\u76ee\uff0c\u9010\u6b65</p> <p>\u6211\u4eec\u5728 SegRNN.py\u521d\u59cb\u5316\u597d\u7684 model\uff0c\u4f1a\u8fd4\u56de\u7ed9 <code>exp_main.py</code> \u4e2d\u7684 model\uff0c\u8fd9\u8fb9\u6211\u53c8\u6253\u4e86\u4e00\u4e2a\u8bb0\u5f55\u70b9\uff0c\u6253\u5370\u4e86\u6a21\u578b\u7ed3\u6784</p> <p> </p> <p>\u6211\u4eec\u5b9a\u4e49\u7684 SegRNN \u7684\u6a21\u578b\u7ed3\u6784\uff1a\u6709\u4e00\u4e2a valueEmbedding \u5c42\u3001RNN \u5c42\uff0c\u672c\u6587\u7684 RNN \u5c42\u7528\u7684\u662f RNN \u53d8\u4f53GRU \uff0c\u8fd8\u6709\u4e00\u4e2a\u9884\u6d4b\u5c42\u3002\u540e\u9762\u6211\u4eec\u5728 SegRNN \u7684 forward \u5c42\u4e2d\u518d\u8be6\u7ec6\u7684\u770b\u6bcf\u4e00\u6b65\u7684\u6267\u884c\u8fc7\u7a0b\u3002</p> <p>\u597d\uff0c\u6211\u4eec\u4e00\u76f4\u9010\u6b65\u6267\u884c\uff0c\u7136\u540e\u6211\u4eec\u56de\u5230\u4e86 \u9879\u76ee\u4e3b\u6587\u4ef6\uff0c\u53ef\u4ee5\u770b\u5230\u521d\u59cb\u5316\u7684\u6a21\u578b\uff0c\u4f20\u7ed9\u4e86 <code>exp</code></p> <p></p> <p>\u597d\u4e86\uff0c\u6211\u4eec\u70b9 \u7ee7\u7eed \uff0c\u6765\u5230\u6a21\u578b\u7684 \u8bad\u7ec3\u9636\u6bb5</p>"},{"location":"Reproduction/5_SegRNN_v1/#exptrain","title":"exp.train()","text":"<p>\u70b9\u51fb \u6b65\u8fdb\uff0c \u8fdb\u5165\u5230 \u6a21\u578b\u4e3b\u6587\u4ef6 <code>train</code> \u65b9\u6cd5\uff0c\u5f00\u59cb\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u9996\u5148\u52a0\u8f7d\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u6211\u4eec\u53ea\u8c03\u8bd5 train Data set \u7684\u52a0\u8f7d\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u6570\u636e\u96c6\u7684\u52a0\u8f7d\u65b9\u6cd5\u662f\u4e00\u6837\u7684\u3002</p> <p>\u9996\u5148\uff0c\u8bad\u7ec3\u96c6\u8c03\u7528\u7684\u81ea\u5b9a\u4e49\u65b9\u6cd5 <code>self._get_data</code>\uff0c</p> <p></p> <p>\u70b9\u51fb \u6b65\u8fdb \u770b\u600e\u4e48\u83b7\u53d6\u7684\u8bad\u7ec3\u96c6\uff0c\u53c8\u770b\u5230 \u8c03\u7528\u7684 <code>data_provider</code> \uff0c\u53c8\u662f\u81ea\u5b9a\u4e49\u7684\u51fd\u6570\uff0c\u7ee7\u7eed  \u6b65\u8fdb</p> <p></p> <p>\uff0c\u6b65\u8fdb\u4f1a\u8fd0\u884c\u4e00\u6b65\u505c\u4e00\u6b65\uff0c\u6b65\u8fdb\u5230\u8fd9\u4e00\u6b65\uff0c\u540c\u65f6\u89e6\u53d1 \u6211\u63d0\u524d\u6253\u7684\u8bb0\u5f55\u70b9\uff0c\u8c03\u8bd5\u63a7\u5236\u53f0\u8f93\u51fa\u5f53\u524d\u4f4d\u7f6e\uff0c\u770b\u5bfc\u822a\u680f \u4e5f\u662f\u4e00\u6837\u7684</p> <p></p> <p>\u8fd9\u91cc\u6ca1\u6709\u8c03\u7528\u4e86\uff0c\u6211\u4eec==\u9010\u6b65\u6267\u884c==</p> <p>\u56e0\u4e3a\u6211\u4eec\u7684 flag \u662f train\uff0c\u6240\u4ee5\u6267\u884c else\uff0c\u9010\u6b65\u6267\u884c\u5230 dataset\uff0cdataset \u7684\u52a0\u8f7d \u7528\u7684\u662f\u4e00\u4e2a Data \u7c7b\uff0c\u9f20\u6807\u60ac\u505c\uff0c\u53d1\u73b0\u662f\u4e00\u4e2a \u81ea\u5b9a\u4e49\u7c7b dataprovider \u6587\u4ef6\u5939\u4e0b\uff0c<code>data_loader.py</code>\u6587\u4ef6\u4e0b\u7684 <code>Dataset_Custom</code>\u7c7b</p> <p></p> <p>\uff0c\u90a3==\u6b65\u8fdb==</p> <p>\u76f8\u5f53\u4e8e<code>data_factor.py</code> \u63a5\u6536\u52a0\u8f7d\u597d\u7684\u6570\u636e\u96c6</p> <p><code>data_loader.py</code> \u91cc\u9762\u5b9a\u4e49\u7684\u5177\u4f53\u7c7b \u7684\u662f <code>\u771f\u6b63\u7684\u6570\u636e\u52a0\u8f7d\u4e3b\u6587\u4ef6</code>\uff0c\u91cc\u9762\u662f\u6bcf\u4e2a\u6570\u636e\u96c6\u5177\u4f53\u7684\u6570\u636e\u52a0\u8f7d\u65b9\u6cd5</p> <p>\u5728\u8fd9\u4e2a\u7c7b\u4e2d\uff0c\u524d\u9762\u90fd\u662f\u4e00\u4e9b\u6570\u636e\u52a0\u8f7d\u7684\u521d\u59cb\u5316\uff0c\u6700\u540e\u4e00\u53e5 <code>self.__read_data__()</code>\uff0c\u5f00\u59cb\u8bfb\u6570\u636e\u96c6\uff0c\u90a3\u8bdd\u4e0d\u591a\u8bf4\uff0c\u6b65\u8fdb</p> <p>\u6211\u7684\u8bb0\u5f55\u70b9\u8bb0\u5f55\u7684\u65b9\u5f0f\u662f\uff0c\u7bad\u5934\u8868\u793a\u8c03\u7528\uff0c\u8df3\u8fdb\u4e86\u65b0\u7684\u6587\u4ef6\u3002\u8c03\u7528\u4e86\u65b0\u7684\u7c7b\u3002</p> <p></p> <p>\u6765\u770b\u5177\u4f53\u7684\uff0c\u9996\u5148 \u5b9a\u4e49\u4e86\u4e00\u4e2a \u5168\u5c40\u6807\u51c6\u5316\uff0c\u5c31\u662f\u521a\u521a\u8bf4\u7684\u5bf9\u6240\u6709\u7684\u7279\u5f81\u7ef4\u5ea6\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u6d88\u9664\u91cf\u7eb2\u7684\u5f71\u54cd\uff1b</p> <p>\u540e\u9762\u5c31\u662f pandas \u8bfb csv \u6570\u636e\uff0ccols \u62ff\u5230\u6240\u6709\u7684\u7c7b\u540d\uff0c\u7136\u540e\u5c31\u662f\u91cd\u65b0\u6392\u5217\u4e00\u4e0b\u5217\u7684\u987a\u5e8f\uff0c\u540e\u9762\u6309\u7167 7,2,1 \u7684\u987a\u5e8f\u5212\u5206\u8bad\u7ec3\u96c6\u3001\u6d4b\u8bd5\u96c6\u548c\u9a8c\u8bc1\u96c6\uff0c</p> <p></p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u9010\u6b65\u6267\u884c\u5b8c\u4ee5\u540e\u770b\u5de6\u8fb9\u7684\u8c03\u8bd5\u7a97\u53e3\uff0c</p>"},{"location":"Reproduction/5_SegRNN_v1/#_4","title":"\u8c03\u8bd5\u7a97\u53e3","text":"<p>\u8fd9\u91cc\u63d2\u5165\u4e00\u53e5\uff0c\u8c03\u8bd5\u7a97\u53e3\u600e\u4e48\u770b\u3002\u6211\u4eec\u91cd\u70b9\u770b\u8fd9\u4e2a Locals \u5c40\u90e8\u53d8\u91cf\uff0c\u5c31\u662f\u6211\u4eec\u8fd9\u4e2a \u51fd\u6570\u5185\u90e8\u7684\u53d8\u91cf\uff0c\u5c40\u90e8\u53d8\u91cf\u7a97\u53e3\uff0c\u5305\u542b\u4e86\u8fd9\u4e2a\u7c7b\u91cc\u9762\u6240\u6709\u5b9a\u4e49\u7684 \u53d8\u91cf\u3002</p> <p>\u5168\u5c40\u53d8\u91cf\u7a97\u53e3\uff0c\u5c31\u662f\u8fd9\u4e2a\u51fd\u6570\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u6240\u6709\u7c7b\uff0c\u6211\u4eec\u8c03\u7528\u7684\u6240\u6709\u5b98\u65b9\u7684\u5e93\u3001\u81ea\u5b9a\u4e49\u7684\u5e93\u3001\u8fd8\u6709\u51fd\u6570\uff0c\u8fd9\u91cc\u7684\u7279\u6b8a\u53d8\u91cf\u5c31\u4e0d\u662f\u91cd\u70b9\u5173\u6ce8\u5f97\u4e86\uff0c\u56e0\u4e3a\u5c01\u88c5\u7684\u66f4\u62bd\u8c61\uff0c\u4e00\u4e2a\u4e0b\u5212\u7ebf\u662f\u53d7\u4fdd\u62a4\uff0c\u4e24\u4e2a\u4e0b\u5212\u7ebf\u7684\u9690\u79c1\u7684\uff0c\u5916\u90e8\u4e0d\u53ef\u8bbf\u95ee\uff0c\u603b\u4e4b\u8fc7\u4e8e\u62bd\u8c61\uff0c\u5c31\u4e0d\u770b\u4e86\u5427\u3002</p> <p></p> <p>\u603b\u7ed3\u6765\u8bf4\uff0c\u91cd\u70b9\u8fd8\u662f\u770b \u5c40\u90e8\u53d8\u91cf\u7a97\u53e3\uff0c\u5168\u5c40\u53d8\u91cf\u7a97\u53e3\uff0c\u5c31\u770b\u770b\u6211\u4eec\u5b9a\u4e49\u4e86\u4ec0\u4e48\u7c7b\uff0c\u8c03\u7528\u4e86\u4ec0\u4e48\u51fd\u6570\u7b49\u3002</p>"},{"location":"Reproduction/5_SegRNN_v1/#_5","title":"\u6570\u636e\u96c6\u5212\u5206","text":"<p>\u9996\u5148\uff0c\u6309\u7167 721 \u5212\u5206\uff0c\u7406\u8bba\u4e0a\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\uff1a676\uff1b\u9a8c\u8bc1\u96c6\u65f6\u95f4\u6b65\uff1a97\uff1b\u6d4b\u8bd5\u96c6\u65f6\u95f4\u6b65\uff1a193\uff0c\u7528\u56fe\u6765\u8868\u793a\u7684\u8bdd\uff0c\u5c31\u662f\uff1a</p> <p>\u4e5f\u5c31\u662f\u8bf4 \u603b\u5171\u662f 966 \u4e2a\u6570\u636e\u70b9\uff0c8 \u4e2a\u7279\u5f81\uff0c\u5177\u4f53\u5904\u7406\u7684\u65f6\u5019\uff0c\u65f6\u95f4\u6233\u7279\u5f81\u5355\u72ec\u5904\u7406\uff0c7 \u4e2a\u7279\u5f81\u4e00\u8d77\u5904\u7406\u3002</p> <p>\u800c\u4e14\uff0c\u6211\u4eec\u770b\u8fd9\u4e2a python \u6587\u4ef6\uff0c\u5728\u53d6\u8bad\u7ec3\u96c6\u7684\u65f6\u5019\uff0c\u7528\u7684\u662f int\uff08\uff09\u53d6\u6574\u65b9\u6cd5\u53d6\u5f97 \u6570\u636e\u96c6\u957f\u5ea6\u7684 0.7\uff0c\u6d4b\u8bd5\u96c6\u4e5f\u662f\uff0c\u4e3a\u4e86\u4e0d\u4e22\u6837\u672c\uff0c\u9a8c\u8bc1\u96c6\u7528\u7684\u662f\u51cf\u6cd5\uff0c\u6240\u4ee5\u8fd8\u662f\u5f88\u4e25\u8c28\u7684</p>"},{"location":"Reproduction/5_SegRNN_v1/#border1s-border2s","title":"border1s &amp; border2s","text":"<p>\u8fd9\u91cc\u5148\u8bf4\u660e border1s &amp; border2s \u7684\u542b\u4e49\u3002\u540e\u9762\u518d\u4ed4\u7ec6\u7684\u8bb2\u89e3 border1s &amp; border2s \u7684\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\u3002</p> <p>\u9996\u5148 \u5c31\u662f \u6211\u4eec\u7684 border1s\u3001border2s\u662f\u5206\u522b\u5b9a\u4e49\u4e86\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u7684\u5de6\u8fb9\u754c\u548c\u53f3\u8fb9\u754c\uff1b</p> <p></p> <p>border1 \u548c border2\u662f\u6839\u636e \u4f20\u8fdb\u6765\u7684 <code>self.set_type</code>\uff0c\u6765\u62ff\u5230\u5bf9\u5e94\u7684\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u6216\u8005\u6d4b\u8bd5\u96c6\u7684 \u5de6\u53f3\u8fb9\u754c\u7d22\u5f15\u3002\u6211\u4eec\u8fd9\u91cc\u7684 <code>self.set_type=0</code>\uff0c\u8fd9\u4e2a\u53c8\u662f\u600e\u4e48\u6765\u7684\u5462\uff1f</p> <p>\u9f20\u6807 command\uff0c\u8df3\u8f6c  \uff0c\u53ef\u4ee5\u770b\u5230\u662f\u901a\u8fc7\u4e00\u4e2a\u5b57\u5178\u6620\u5c04\u62ff\u5230\u7684\uff0c\u6839\u636e\u6211\u4eec\u4f20\u5165\u7684 <code>flag=train</code>\uff0c\u62ff\u5230\u4e86 \u5de6\u53f3\u8fb9\u754c\u7d22\u5f15 \uff0c\u5206\u522b\u4fdd\u5b58\u8bad\u7ec3\u96c6\u7684\u5de6\u8fb9\u754c\u7d22\u5f15\u548c\u53f3\u8fb9\u754c\u7d22\u5f15\u3002</p> <p>\u6211\u4eec\u5df2\u7ecf\u77e5\u9053 \u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\uff1a676\uff1b\u9a8c\u8bc1\u96c6\u65f6\u95f4\u6b65\uff1a97\uff1b\u6d4b\u8bd5\u96c6\u65f6\u95f4\u6b65\uff1a193\uff1b\u672c\u6765\u5e94\u8be5\u662f\uff1a</p> <p> </p> <p>\u8fd9\u91cc\u60f3\u63d0\u524d\u8bf4\u660e\u7684\u662f\uff1a python \u7d22\u5f15\u7684\u662f\u4e00\u4e2a\u5de6\u95ed\u53f3\u5f00\u7684\u533a\u95f4\uff0c\u5c31\u662f\u8bf4 \u7d22\u5f15 0 \u5230 676\uff0c\u80fd\u591f\u7d22\u5f15\u5230\u7b2c 0 \u884c\uff0c\u4f46\u662f\u6700\u540e\u4e00\u4e2a\u7684\u7d22\u5f15\u662f \u7b2c675 \u884c\uff0c\u5c31\u80fd\u7d22\u5f15\u5230 676 \u4e2a\u65f6\u95f4\u6b65\uff0c\u6240\u4ee5\u540e\u9762\u8bb2\u7684\u65f6\u5019\u4e5f\u4e0d\u505a\u8fc7\u591a\u533a\u5206\u3002 </p> <p>\u4e0b\u9762 \u6211\u4eec\u7279\u5730\u5f3a\u8c03\u4e00\u4e0b\u8fd9\u91cc\u7684\u6570\u636e\u96c6\u5212\u5206 </p> <p>\u4e5f\u5c31\u662f\u8bf4\uff1a  \u672c\u6765\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\u662f\u524d0-676 \u4e2a\u65f6\u95f4\u70b9\uff0c\u9a8c\u8bc1\u96c6\u662f\u7d27\u968f\u5176\u540e\u7684 97 \u4e2a\u65f6\u95f4\u6b65\uff0c\u5bf9\u5e94\u7684\u7d22\u5f15\u5e94\u8be5\u662f 676+97=773,\u6d4b\u8bd5\u96c6\u662f\u662f\u9a8c\u8bc1\u96c6 \u7684\u7ed3\u675f\u7d22\u5f15\u65f6\u95f4\u6b65 773\u5230\u540e\u9762\u7d27\u968f\u5176\u540e\u7684 193 \u4e2a\u65f6\u95f4\u6b65\uff0c\u4e5f\u5c31\u662f 773+193=966 \uff0c\u521a\u597d\u662f\u6570\u636e\u96c6\u957f\u5ea6</p> <p>\u4f46\u662f\uff0c  \u5b9e\u9645\u4e0a\u662f\uff0c borders1 \u548c borders2\u7684 \u5b9a\u4e49\u5728\u6e90\u7801\u4e2d\u662f\uff1a</p> <p></p> <p>\u4e5f\u5c31\u662f </p> <p>\u7528\u56fe\u6765\u8868\u793a\u5c31\u662f\uff1a</p> <p></p> <p>\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\u662f\u524d0-676 \u4e2a\u65f6\u95f4\u70b9\uff0c\u9a8c\u8bc1\u96c6\u662f 616 \u5230 773 \u4e2a\u65f6\u95f4\u70b9\uff0c\u6d4b\u8bd5\u96c6\u662f713 \u5230 966 \u4e2a\u65f6\u95f4\u6b65</p> <p>\u4e3a\u4ec0\u4e48\u662f\u8fd9\u6837\u7684\u5462\uff1f</p> <p>\u8fd9\u6837\u505a\u7684\u610f\u4e49\u662f\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u6bcf\u4e2a\u6837\u672c\u90fd\u6709 60 \u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u5e8f\u5217\u548c 24 \u4e2a\u65f6\u95f4\u6b65\u7684\u9884\u6d4b\u76ee\u6807\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u4e8e\u9a8c\u8bc1\u96c6\u7684\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\uff0c\u5982\u679c\u8ba9\u5b83\u6784\u6210\u4e00\u4e2a\u5b8c\u6210\u7684\u6837\u672c\uff0c\u5c31\u9700\u8981\u5411\u524d\u56de\u9000 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u540c\u6837\u5bf9\u4e8e\u6d4b\u8bd5\u96c6\u7684\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u6765\u8bf4\uff0c\u8ba9\u5b83\u6784\u6210\u4e00\u4e2a\u6837\u672c\uff0c\u4e5f\u9700\u8981\u56de\u9000 60 \u4e2a\u65f6\u95f4\u6b65\u3002</p> <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b9e\u9645\u4e0a\uff0c </p> <p>\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\u6709 676 \u4e2a\uff0c\u9a8c\u8bc1\u96c6\u65f6\u95f4\u6b65\u6709 $773-616=157 $\u4e2a\uff0c\u6216\u8005\u5c31\u662f \\(97+60=157\\) \u4e2a\u65f6\u95f4\u6b65\uff1b\u6d4b\u8bd5\u96c6 \u6709 \\(253\\) \u4e2a\u65f6\u95f4\u6b65\u3002</p> <p>\u5f53\u6211\u4eec\u77e5\u9053\u4e86\u6570\u636e\u96c6\u65f6\u95f4\u6b65\u7684\u5212\u5206\u4ee5\u540e\uff0c\u73b0\u5728\u6211\u4eec\u8ba8\u8bba\uff0c\u8fd9\u4e9b\u65f6\u95f4\u6b65\u80fd\u6784\u6210\u591a\u5c11\u4e2a\u6837\u672c\uff1f\uff0c\u8fd9\u4e2a\u95ee\u9898\u5f53\u4ee3\u7801\u6267\u884c\u5230\u54ea\u4e00\u6b65\u518d\u8bf4\u3002</p>"},{"location":"Reproduction/5_SegRNN_v1/#selffeatures","title":"self.features","text":"<p>\u8fd9\u91cc\u662f\u8bf4 \u65f6\u95f4\u5e8f\u5217\u76843 \u79cd\u4efb\u52a1\uff0c</p> <p>\u591a\u53d8\u91cf\u9884\u6d4b\u591a\u53d8\u91cf\uff0c\u591a\u53d8\u91cf\u9884\u6d4b\u5355\u53d8\u91cf\uff0c\u5355\u53d8\u91cf\u9884\u6d4b\u5355\u53d8\u91cf</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u8fd9\u91cc\u60f3\u989d\u5916\u8bf4\u660e\u7684\u4e00\u70b9\u662f\uff0c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u6211\u4eec\u65e5\u671f\u7279\u5f81\u7684\u63d0\u53d6\u662f\u901a\u8fc7 \u504f\u79fb\u6765\u5904\u7406\u7684\uff0c\u8fd9\u4e2a\u6211\u4eec\u540e\u9762\u4f1a\u8bf4\uff0c\u5bf9\u5e94\u5230\u4ee3\u7801\u4e2d\u53ef\u4ee5\u770b\u5230 \u5728\u4f7f\u7528\u591a\u53d8\u91cf\u7684\u65f6\u5019\uff0c\u90fd\u662f\u4e0d\u62ff\u7b2c 0 \u5217\u7279\u5f81\u7684\uff0c\u56e0\u4e3a\u65e5\u671f\u6211\u4eec\u7b49\u4f1a\u5904\u7406\u3002</p> <ol> <li><code>M</code> (\u591a\u53d8\u91cf/Multiple variables)\uff1a    - \u5f53 self.features == 'M' \u65f6\uff0c\u4ee3\u7801\u9009\u62e9\u9664\u7b2c\u4e00\u5217\uff08\u901a\u5e38\u662f\u65e5\u671f\u5217\uff09\u5916\u7684\u6240\u6709\u5217\u4f5c\u4e3a\u7279\u5f81    - cols_data = df_raw.columns[1:]\u83b7\u53d6\u9664\u7b2c\u4e00\u5217\u5916\u7684\u6240\u6709\u5217\u540d    - df_data = df_raw[cols_data] \u9009\u62e9\u8fd9\u4e9b\u5217\u4f5c\u4e3a\u6a21\u578b\u8f93\u5165\u6570\u636e</li> <li><code>MS</code> (\u591a\u53d8\u91cf\u5230\u5355\u53d8\u91cf\u9884\u6d4b/Multiple to Single)\uff1a    - \u4e0e <code>M</code> \u6a21\u5f0f\u76f8\u540c\u7684\u6570\u636e\u9009\u62e9\u65b9\u5f0f    - \u4f7f\u7528\u6240\u6709\u7279\u5f81\u5217\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f46\u4e3b\u8981\u76ee\u7684\u662f\u9884\u6d4b\u76ee\u6807\u53d8\u91cf</li> <li><code>S</code> (\u5355\u53d8\u91cf/Single variable)\uff1a    - \u5f53 self.features == 'S' \u65f6\uff0c\u53ea\u9009\u62e9\u76ee\u6807\u5217\u4f5c\u4e3a\u7279\u5f81    - df_data = df_raw[[self.target]]\u4ec5\u9009\u62e9\u7531 self.target\u6307\u5b9a\u7684\u5217</li> </ol> <p>\u4e3e\u4e2a\u5b9e\u9645\u7684\u4f8b\u5b50\uff0c\u6765\u8bf4\u660e\u8fd9\u4e09\u79cd\u9884\u6d4b\uff1a</p> <p>\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u7535\u529b\u6d88\u8017\u6570\u636e\u96c6\uff0c\u5305\u542b\u5982\u4e0b\u5217\uff1a</p> <p>[date,HUFL, HULL, MUFL, MULL, LUFL, LULL, OT]</p> <p>date \u8868\u793a\u65f6\u95f4\u6233 \u653e\u5230\u7b2c\u4e00\u5217\uff0c\u76ee\u6807\u5217OT \u653e\u5230\u6700\u540e\u4e00\u5217\uff0c\u8fd9\u662f\u6211\u4eec\u5217\u91cd\u6392\u7684\u7ed3\u679c</p> <p>\u5982\u679c\u6211\u4eec\u8bbe\u7f6e\uff1a</p> <ol> <li>self.features = 'M'\uff1a    - \u6240\u6709\u5217\uff08\u9664\u4e86 date\u90fd\u4f1a\u88ab\u9009\u4e2d\uff1a<code>OT, HUFL, HULL, MUFL, MULL, LUFL, LULL</code>    - \u6a21\u578b\u5c06\u4f7f\u7528\u6240\u6709\u8fd9\u4e9b\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b</li> <li><code>self.features = 'MS'</code>\uff1a    - \u540c\u6837\u9009\u62e9\u6240\u6709\u5217\uff08\u9664\u4e86 <code>date</code>\uff09\uff1a<code>OT, HUFL, HULL, MUFL, MULL, LUFL, LULL</code>    - \u901a\u5e38\u7528\u4e8e\u5229\u7528\u591a\u4e2a\u7279\u5f81\u6765\u9884\u6d4b\u76ee\u6807\u53d8\u91cf</li> <li><code>self.features = 'S'</code> \u4e14 <code>self.target = 'OT'</code>\uff1a    - \u53ea\u9009\u62e9 <code>OT</code> \u5217    - \u6a21\u578b\u5c06\u53ea\u4f7f\u7528\u6cb9\u6e29\u5386\u53f2\u6570\u636e\u6765\u9884\u6d4b\u672a\u6765\u6cb9\u6e29\u503c\uff0c\u4e0d\u8003\u8651\u5176\u4ed6\u53d8\u91cf</li> </ol> <p>\u597d\u4e86\uff0c\u4e0b\u9762\u770b</p>"},{"location":"Reproduction/5_SegRNN_v1/#selfscale","title":"self.scale","text":"<p>\u8fd8\u8bb0\u5f97\u6211\u4eec\u521a\u5f00\u59cb\u5b9a\u4e49\u7684 <code>self.scaler = StandardScaler()</code> \u5168\u5c40\u6570\u636e\u6807\u51c6\u5316\u5668\u561b</p> <p>\u73b0\u5728\u5f00\u59cb\u62df\u5408\uff0c\u6ce8\u610f\u8fd9\u91cc\u62df\u5408\u7684\u65f6\u5019\uff0c\u53ea\u7528\u7684\u662f\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u62df\u5408\uff0c\u56e0\u4e3a\u5728\u771f\u5b9e\u60c5\u51b5\u4e2d \u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u662f\u89c2\u6d4b\u4e0d\u5230\u7684\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684\u6267\u884c\u903b\u8f91\u5c31\u662f\uff0c\u5148\u62ff\u51fa \u8bad\u7ec3\u96c6\u6570\u636e\uff0c\u7136\u540e\u7528\u8bad\u7ec3\u96c6\u6570\u636e\u62df\u5408 \u6807\u51c6\u5316\u5668\uff0c\u7136\u540e\u7528\u62df\u5408\u597d\u7684\u6807\u51c6\u5316\u5668\u6765\u6807\u51c6\u5316\u5168\u5c40\u6570\u636e\u3002\u5ffd\u7136\u89c9\u5f97\u53eb\u5f52\u4e00\u5316\u4e0d\u592a\u5408\u9002\uff0c\u56e0\u4e3a \u662f \u51cf\u5747\u503c  \u9664\u4ee5 \u6807\u51c6\u5dee\u7684 \u6807\u51c6\u5316\uff0c\u5e76\u4e0d\u662f\u5f52\u4e00\u5316\u3002</p>"},{"location":"Reproduction/5_SegRNN_v1/#df_stamp","title":"df_stamp","text":"<p>\u7ec8\u4e8e\u7528\u5230\u4e86\u6211\u4eec\u7684 border1\uff0cborder2\uff0c\u5c31\u662f\u5904\u7406\u6211\u4eec\u73b0\u5728\u60f3\u5904\u7406\u7684\u6570\u636e\u96c6\u4e86\uff0c\u9996\u5148\u5c06\u6211\u4eec\u5148\u5904\u7406\u7684 \u6570\u636e\u96c6\u65f6\u95f4\u6233\u62ff\u51fa\u6765\uff0c\u4f20\u7ed9 <code>df_stamp</code> \uff0c\u4e4b\u524d\u6211\u4eec\u5df2\u7ecf\u8bf4\u8fc7\u4e86\uff0c\u5c31\u662f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u65e5\u671f\u6709\u81ea\u5df1\u7684\u7279\u5f81\u6784\u9020\u65b9\u6cd5\uff0c\u4f7f\u7528\u7684\u7684 <code>offset \u504f\u79fb</code> \u7684\u6982\u5ff5</p> <p>\u5148\u770b\u4e00\u4e0b \u6211\u4eec\u8fd9\u4e2a\u539f\u59cb\u7684\u65f6\u95f4\u6233\u6570\u636e\u957f\u5565\u6837\uff1a</p> <p>\u5728\u8c03\u8bd5\u7a97\u53e3\uff0c\u5c40\u90e8\u53d8\u91cf\u7a97\u53e3\uff0c\u60ac\u505c\uff0c\u5373\u53ef\u67e5\u770b\u3002\u8fd9\u91cc\u56e0\u4e3a\u65f6\u95f4\u90fd\u662f <code>00:00:00</code> \u6240\u4ee5\u7701\u7565\u4e86</p> <p></p> <p>\u8fd9\u662f\u6211\u4eec\u6b63\u5728\u8c03\u8bd5\u4f7f\u7528\u7684\u75be\u75c5\u6570\u636e\u96c6\uff1a</p> <p> </p> <p>\u6807\u51c6\u7684\u65f6\u95f4\u6233\u6570\u636e\uff1a\u5e74\u6708\u65e5\u3001\u65f6\u5206\u79d2</p> <p>\u597d\u4e86\uff0c\u6211\u4eec\u4e3b\u8981\u6765\u770b\u600e\u4e48\u5904\u7406\u7684\u8fd9\u4e2a\u65f6\u95f4\uff0c\u56e0\u4e3a\u8fd9\u91cc\u4f20\u8fdb\u6765 self.timeenc=1\uff0c\u6240\u4ee5\u6267\u884c elif\uff0c\u5e76\u4e14\u53c8\u662f \u8c03\u7528\u7684 \u81ea\u5b9a\u4e49\u51fd\u6570 <code>time_features</code></p> <p>\u5f53\u4f60\u4e0d\u77e5\u9053\u8fd9\u4e2a\u51fd\u6570\u662f\u81ea\u5b9a\u4e49\u7684 \u8fd8\u662f \u5b98\u65b9\u7684\uff0c\u90a3\u5c31 \u6309\u4f4f command+\u9f20\u6807\uff0c\u8df3\u8fdb\u53bb\u770b\u770b\uff0c\u6216\u8005\u770b\u770b <code>\u8c03\u8bd5\u7a97\u53e3</code>\u7684 <code>\u5168\u5c40\u53d8\u91cf\u7a97\u53e3</code>\u7684<code>\u51fd\u6570\u53d8\u91cf</code></p> <p>\u7a0d\u5fae\u6ce8\u610f\u4e00\u4e0b\u5c31\u662f\uff0c\u6211\u4eec\u4f20\u5165\u8fdb\u53bb\u7684\u53c2\u6570\u662f \u65f6\u95f4\u6233\u6570\u636e\uff0c\u4ee5\u53ca \u5468\u671f\u9891\u7387\uff0c<code>h</code> \u8868\u793a\u5c0f\u65f6\u3002\u4f46\u5176\u5b9e\u5bf9\u4e8e\u8fd9\u4e2a\u75be\u75c5\u6570\u636e\u96c6\u6765\u8bf4\uff0c\u65f6\u95f4\u6233\u5468\u671f\u662f \u5468\uff0c\u6709\u70b9\u5c0f\u95ee\u9898\uff0c\u4f46\u5f71\u54cd\u4e0d\u5927\u3002</p> Text Only<pre><code>data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n</code></pre> <p>\u8bdd\u4e0d\u591a\u8bf4\uff0c\u6b65\u8fdb\uff0c</p> <p> </p> <p>\u770b\u5230\u53c8\u662f\u4e00\u4e2a\u8c03\u7528\uff0c\u7ee7\u7eed==\u6b65\u8fdb==\uff0c\u800c\u4e14\u662f==\u540c\u6587\u4ef6\u7684 \u8c03\u7528==\u3002</p> <p>\u6211\u4eec\u5148\u770b\u4e00\u4e0b\u8fd9\u91cc\uff0c<code>&lt;built-in function to_offset&gt;</code> \u8868\u793a\u7684\u662f\u6307\u5411 Pandas \u5e93\u4e2d to_offset\u51fd\u6570\u7684\u5f15\u7528\u3002\uff08\u4e5f\u5c31\u662f \u5185\u7f6e\u51fd\u6570\uff09</p> <p></p> <p>\u597d\uff0c\u7ee7\u7eed\u56de\u5230\u6e90\u4ee3\u7801 </p> <p>\u6b65\u8fdb\u5230 <code>time_features_from_frequency_str</code> \u51fd\u6570\u5185\u90e8\uff0c\u9996\u5148\u6709\u4e00\u4e2a \u7279\u5f81\u504f\u79fb\u5b57\u5178</p> <p></p> <p>\u6765\u5230\u4e0b\u9762\u8fd9\u884c\uff1a</p> <p></p> <p>\u6839\u636e\u7ed9\u5b9a\u7684\u65f6\u95f4\u9891\u7387\u5b57\u7b26\u4e32\u9009\u62e9\u5408\u9002\u7684\u65f6\u95f4\u7279\u5f81</p> <ul> <li><code>to_offset</code> \u662f Pandas \u4e2d\u7684\u51fd\u6570\uff0c\u7528\u4e8e\u5c06\u9891\u7387\u5b57\u7b26\u4e32\uff08\u5982 'H'\u3001'D'\u3001'W' \u7b49\uff09\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684\u504f\u79fb\u5bf9\u8c61</li> <li>\u6bd4\u5982\u6211\u4eec\u8fd9\u91cc\uff0c'H' \u8f6c\u6362\u4e3a  Hour  \u504f\u79fb\u5bf9\u8c61\uff0c</li> </ul> <p></p> <ul> <li>\u8fd9\u6bb5 for \u5faa\u73af\u7684\u4f5c\u7528\u5c31\u662f\u6839\u636e \u8f93\u5165\u7684 freq_str \u4e5f\u5c31\u662f\u9891\u7387\u5b57\u7b26\u4e32\uff0c\u53bb\u504f\u79fb\u7279\u5f81\u5b57\u5178\u4e2d \u7d22\u5f15\u5230\u7279\u5f81\u7c7b\u5217\u8868\uff0c\u6700\u7ec8\u8fd4\u56de\u7c7b\u7684\u5b9e\u4f8b</li> <li>**\u5177\u4f53\u6765\u8bf4\uff0c**\u5c31\u662f\u9996\u5148 <code>offset = to_offset(freq_str)</code>   \u6839\u636e\u4f20\u5165\u7684 <code>'H'</code> \u5b57\u7b26\u4e32\u5f97\u5230 <code>&lt;Hour&gt;</code> \u5bf9\u8c61 </li> <li>\u7136\u540e\u904d\u5386\u904d\u5386\u5b57\u5178\u7684 \u952e \u548c \u503c\uff0c\u5982\u679c offset \u4e5f\u5c31\u662f\u6211\u4eec\u5f97\u5230\u7684 <code>&lt;Hour&gt;</code> \u5bf9\u8c61\u662f\u904d\u5386\u5f97\u5230\u7684 <code>offset_type</code>\uff0c\u4e5f\u5c31\u662f \u5b57\u5178\u7684\u952e\uff0c\u7684\u5b9e\u4f8b\uff0c\u90a3\u4e48\u5bf9\u5e94\u7684\u5b57\u5178\u7684 \u503c \uff0c<code>feature_classes</code> \u5c31\u901a\u8fc7\u4e00\u4e2a\u5217\u8868\u63a8\u5bfc\u5f0f\uff0c\u5bf9\u5f97\u5230\u7684\u7c7b\u4f1a\u52a0\u4e00\u4e2a\u62ec\u53f7 <code>cls()</code> ,\u8868\u793a\u8fd4\u56de\u7c7b\u7684\u5b9e\u4f8b\u3002</li> <li>**\u518d\u4ed4\u7ec6\u91cd\u590d\u4e00\u904d\uff0c**\u5c31\u662f <code>to_offset('H')</code>\u8fd4\u56de\u7684\u662f\u4e00\u4e2a <code>&lt;Hour&gt;</code>\u5bf9\u8c61</li> <li>for\u5faa\u73af\u904d\u5386\u5b57\u5178\u65f6\uff0c\u4f1a\u53d1\u73b0\u8fd9\u4e2a\u5bf9\u8c61\u662f <code>offsets.Hour</code> \u7684\u5b9e\u4f8b</li> <li>\u4ece\u5b57\u5178\u4e2d\u67e5\u627e\u5bf9\u5e94 offsets.Hour\u7684\u7279\u5f81\u7c7b\u5217\u8868\uff1a<code>[HourOfDay, DayOfWeek, DayOfMonth, DayOfYear]</code></li> <li>\u8fd4\u56de\u8fd9\u4e9b\u7c7b\u7684\u5b9e\u4f8b\u5217\u8868\uff1a<code>[HourOfDay(), DayOfWeek(), DayOfMonth(), DayOfYear()]</code></li> </ul> <p>\u63a5\u4e0b\u6765\uff0c\u7ee7\u7eed\u770b  <code>np.vstack</code>  \u8fd9\u4e00\u884c\uff0c</p> <p></p> <p>\u9996\u5148\uff0c<code>time_features_from_frequency_str(freq)</code> \u8fd4\u56de\u7684\u662f <code>[HourOfDay(), DayOfWeek(), DayOfMonth(), DayOfYear()]</code></p> <p>\u7136\u540e\uff0c\u6839\u636e\u5f97\u5230\u7684  <code>[HourOfDay(), DayOfWeek(), DayOfMonth(), DayOfYear()]</code> \u5bf9\u4f20\u5165\u7684 <code>dates</code> \u8fdb\u884c\u5904\u7406\uff0c\u9996\u5148\u6211\u4eec\u4f20\u5165\u7684 dates\uff0c\u662f\u6807\u51c6\u7684\u65e5\u671f\uff0cpandas \u4f1a\u81ea\u52a8\u89e3\u6790\u51fa \u5e74\u3001\u6708\u3001\u65e5\u3001\u5c0f\u65f6\uff0c\u56e0\u4e3a\u5168\u662f 0 \u70b9\uff0c\u6240\u4ee5\u7701\u7565\u4e86\u3002</p> <p></p> <p>\u6839\u5177\u4f53\u6765\u8bf4\u7684\u5904\u7406\u662f\uff1a</p> <p></p> <p>\u70b9\u51fb\u6b65\u8fdb \uff0c\u53ef\u4ee5\u770b\u5230 index.day\uff0c\u81ea\u52a8\u6458\u51fa\u6240\u6709\u7684\u65e5\u671f\uff0c\u8fd9\u91cc\u7684\u7684\u5904\u7406\u662f -1 /30 \u662f\u4e3a\u4e86\u5f52\u4e00\u5316\uff0c\u56e0\u4e3a\u6211\u4eec\u7684\u65e5\u671f\u8bb0\u53f7\u4e3a 1 \u53f7\u5230 31 \u53f7\uff0c\u5bf9\u65e5\u671f\u51cf1\uff0c\u53d8\u6210 0~30\uff0c\u00f730\uff0c\u53d8\u6210 0~1\uff0c\uff0d0.5 \u8868\u793a \u4e2d\u5fc3\u5316\uff0c\u6700\u7ec8\u7684\u6570\u636e\u8303\u56f4\u662f <code>-0.5~0.5</code></p> <p></p> <ul> <li>HourOfDay()\uff1a\u8868\u793a \u4e00\u5929\u4e2d\u7684\u7b2c\u51e0\u4e2a\u5c0f\u65f6</li> <li>DayOfWeek()\uff1a\u8868\u793a\u4e00\u5468\u4e2d\u7684\u661f\u671f\u51e0</li> <li>DayOfMonth()\uff1a\u8868\u793a\u4e00\u4e2a\u6708\u4e2d\u7684\u7b2c\u51e0\u5929</li> <li>DayOfYear()\uff1a\u8868\u793a\u4e00\u5e74\u4e2d\u7684\u7b2c\u51e0\u5929</li> </ul> <p>\u5904\u7406\u903b\u8f91\u90fd\u662f\u5dee\u4e0d\u591a\u7684\uff0c\u90fd\u4e2d\u5fc3\u5316\u4e3a <code>-0.5~0.5</code></p> <p>\u8fd4\u56de\u7684\u5f62\u72b6\u662f <code>[\u7279\u5f81\u6570, \u65e5\u671f\u6570]</code> \u4e5f\u5c31\u662f <code>4 \u00d7 676</code></p> <p>\u8fd9\u91cc np.vstack \u5806\u53e0\u7684\u662f \u5217\u8868\uff0c\u6240\u4ee5\u662f 4 \u884c 676 \u5217\uff0c\u5bf9\u5e94\u7684\u540e\u9762\u662f\uff0c\u6709\u4e00\u4e2a  transpose \u64cd\u4f5c\uff0c<code>data_stamp = data_stamp.transpose(1, 0)</code> \uff0c\u53d8\u6210 <code>676 \u00d74</code> \u7684\u683c\u5f0f</p> <p>\u6700\u7ec8\u5f97\u5230\u7684\u6570\u636e\u548c\u5f62\u72b6\uff1a</p> <p></p>"},{"location":"Reproduction/5_SegRNN_v1/#selfdata_x","title":"self.data_x","text":"<p>\u63a5\u4e0b\u6765\u5c31\u5b8c\u6210\u4e86 dataset \u7c7b\u7684\u5b9e\u73b0\uff0c\u5f97\u5230\u4e86 \u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6 \u6216\u8005\u6d4b\u8bd5\u96c6\uff0c\u8fd9\u91cc\u4e24\u4e2a\u53d8\u91cf\u7684\u610f\u601d\u662f\uff0cx \u5e8f\u5217\u7528\u6765\u7d22\u5f15 \u8f93\u5165\u5e8f\u5217\uff0cy \u5e8f\u5217\u7528\u6765\u7d22\u5f15 \u9884\u6d4b\u5e8f\u5217\uff0c\u5177\u4f53\u7684\u7528\u5904\u5728 <code>__getitem__</code> \u65b9\u6cd5\u4e2d\u3002\u540c\u65f6 <code>self.</code> \u5b9a\u4e49\u7684\u53d8\u91cf\u5728\u7c7b\u5185\u76f8\u5f53\u4e8e\u5168\u5c40\u53d8\u91cf\u3002</p> <p>\u65e2\u7136\u8bf4\u5230\u4e86 \u8fd9\u4e2a  <code>__getitem__</code> \u65b9\u6cd5\uff0c\u90a3\u5c31\u8bf4\u660e\u4e00\u4e0b \u8fd9\u4e2a\u9b54\u6cd5\u65b9\u6cd5\u662f\u600e\u4e48\u8c03\u7528\u548c\u5b9e\u73b0\u7684\u3002</p>"},{"location":"Reproduction/5_SegRNN_v1/#1","title":"\uff08\u5f3a\u8c03 1\uff09\u65f6\u95f4\u5e8f\u5217\u6837\u672c\u6784\u9020\u7684\u5b9e\u73b0","text":"<p>\u4e0a\u8282\u8bfe\u6709\u8df3\u8fc7\u7684\u90e8\u5206\uff0c\u5728\u8fdb\u884c SegRNN \u7684 forward \u8fc7\u7a0b\u4e4b\u524d\uff0c\u4ed4\u7ec6\u8bb2\u8bb2==\u65f6\u95f4\u5e8f\u5217\u4e2d\u65f6\u95f4\u6b65\u4e0e\u6837\u672c\u6784\u9020\u7684\u5173\u7cfb\u3002==</p> <p>\u8fd9\u4e00\u90e8\u5206\u4e3b\u8981\u6d89\u53ca\u7684\u6e90\u7801\u662f  <code>data_factor.py</code> \u6587\u4ef6\u4e2d <code>data_provider</code> \u51fd\u6570\u4e2d \u91cd\u5199\u7684 Dataset \u7c7b\u548c dataloader\u3002</p> <p></p> <p>\u8fd8\u6709\u5c31\u662f dataloader.py\u4e2d\u7684 <code>Dataset_Custom</code>\u7c7b <code>class Dataset_Custom(Dataset):</code> \uff0c\u8fd9\u91cc\u7684 init \u65b9\u6cd5\u3001getitem \u65b9\u6cd5\u8fd8\u6709 len \u65b9\u6cd5\u90fd\u662f\u9700\u8981\u7740\u91cd\u6ce8\u610f\u7684\u3002</p> <p></p>"},{"location":"Reproduction/5_SegRNN_v1/#_6","title":"\u76f4\u89c2\u5730\u7406\u89e3","text":"<p>\u90a3\u5c31\u8bf4\u4e00\u4e0b\u8fd9\u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u6837\u672c\u662f\u600e\u4e48\u5212\u5206\u7684\uff0c\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u8981\u8fd9\u6837\u505a\u3002</p> <p>\u5bf9\u4e8e\u4e00\u5f20\u4e8c\u7ef4\u6570\u8868\uff0c\u65f6\u95f4\u5e8f\u5217\u90fd\u662f\u4e8c\u7ef4\u6570\u8868\uff0c\u884c\u662f\u6bcf\u4e2a\u65f6\u95f4\u70b9\uff0c\u5217\u662f\u6bcf\u4e2a\u65f6\u95f4\u70b9\u91c7\u96c6\u7684\u6570\u636e\uff0c\u6bd4\u5982\u75be\u75c5\u611f\u67d3\u4eba\u6570\uff0c\u8bb0\u5f55\u7684 2002 \u5e74 1 \u6708\u5f00\u59cb\uff0c\u5230 2020 \u5e74 1 \u6708\u7ed3\u675f\uff0c\u6bcf\u5468\u4e00\u91c7\u96c6\u6570\u636e\uff0c\u9664\u4e86\u8bb0\u5f55\u75be\u75c5\u611f\u67d3\u4eba\u6570\uff0c\u8fd8\u53ef\u4ee5\u8bb0\u5f55\u4e00\u4e9b\u4e0e\u611f\u67d3\u75be\u75c5\u4eba\u6570\u7684\u76f8\u5173\u7684\u6bd4\u5982\u5f53\u5730\u5929\u6c14\u4ec0\u4e48\u7684\uff1b</p> <p>\u5177\u4f53\u6765\u8bf4\u5c31\u662f\uff1a</p> <p> </p> <p>Y \u76ee\u6807\u5217\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0e\u5176\u4ed6\u56fe\u50cf\u6216\u8005 NLP \u4efb\u52a1\u4e0d\u540c\u7684\u662f\uff0c\u7279\u5f81\uff0c\u5728\u672a\u6765\u65f6\u95f4\u70b9\uff0c\u6211\u4eec\u662f\u4e0d\u77e5\u9053\u6240\u6709\u7684\u7279\u5f81\u7684\uff0c\u5b8c\u5168\u90fd\u662f\u672a\u77e5\u7684\u3002</p> <p>\u65f6\u95f4\u5e8f\u5217\u6837\u672c\u7684\u6784\u9020\uff1a\u7528\u4e8e\u8bad\u7ec3\u7684\u65f6\u95f4\u6b65\uff0c\u8bb0\u4f5c <code>sequence_length</code>\uff0c\u7528\u4e8e\u9884\u6d4b\u7684\u65f6\u95f4\u6b65 <code>pred_length</code>\uff0c\u8fd8\u6709\u4e00\u4e2a\u6bd4\u8f83\u7279\u6b8a\u7684\u6982\u5ff5 <code>label_length</code> \uff0c\u8868\u793a\u7528\u4e8e\u8bad\u7ec3\u7684\u65f6\u95f4\u6b65\u6709\u591a\u5c11\u7528\u4e8e\u6307\u5bfc\u9884\u6d4b\uff0c\u7528\u4e00\u5f20\u56fe\u8868\u793a\uff1a</p> <p></p> <p>\u6709\u51e0\u4e2a batch \u6211\u4eec\u5c31\u79fb\u52a8\u51e0\u4e2a\u5c0f\u65f6\uff0c\u6784\u9020\u51e0\u4e2a batch\u3002</p> <p></p> <p>\u5f53\u7136\u4e86\uff0c\u8fd9\u91cc\u4e5f\u6709\u4e00\u4e2a\u9057\u7559\u95ee\u9898\uff0c\u5c31\u662f\u8fd9\u6837\u6784\u9020 batch\u7684\u8bdd\uff0c\u4e0d\u5c31\u662f\u6309\u7167\u7279\u5f81\u7684\u987a\u5e8f\u5582\u7ed9\u6a21\u578b\u4e86\u5417\uff0c\u6a21\u578b\u4e0d\u5c31\u4f1a\u4f9d\u8d56\u8fd9\u4e2a\u987a\u5e8f\u4e86\u561b\uff0c\u800c\u4e00\u822c\u6211\u4eec\u5728\u6784\u5efa Dataloader \u7684\u65f6\u5019\uff0c\u4f1a\u8bbe\u7f6e\u4e00\u4e2a\u53c2\u6570 <code>shuffle=True</code> \uff0c\u4e5f\u5c31\u662f \u4f1a\u968f\u673a\u9009\u53d6 batch \u4e2a\u7d22\u5f15 index\uff0c\u4ece\u8fd9\u4e2a\u7d22\u5f15\u5f00\u59cb\u9009\u62e9 sequence length \u4e2a\u65f6\u95f4\u6b65\u4ee5\u53ca\u540e\u9762\u7684 predict length \u8fdb\u884c\u5c01\u88c5\uff0c\u5c01\u88c5\u6210\u4e00\u4e2a\u6837\u672c\u3002</p> <p>\u5728\u8fd9\u4e2a\u9879\u76ee\u7684 illness \u6570\u636e\u96c6\u4e2d\uff0c\u6709 966 \u4e2a\u65f6\u95f4\u70b9\uff0c\u6bcf\u4e2a\u65f6\u95f4\u70b9\u8bb0\u5f55\u4e86 7 \u4e2a\u7279\u5f81\uff0cbatch size=16\uff0csequence length=60\uff0cfeature=7\uff0c\u66f4\u5177\u4f53\u6765\u8bf4\u65f6\u95f4\u5e8f\u5217\u7684\u6570\u636e\u5c01\u88c5\u5c31\u662f\uff1a</p> <p>16 \u4e2a\u72ec\u7acb\u7684\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u6709 60 \u4e2a\u8fde\u7eed\u7684\u65f6\u95f4\u6b65\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c\uff0c\u6bcf\u4e2a\u65f6\u95f4\u6b65\u6709 7 \u4e2a\u7279\u5f81</p> <p>\u6240\u4ee5\u5c31\u662f\u56e0\u4e3a\u6837\u672c\u662f\u968f\u673a\u4ece\u8bad\u7ec3\u96c6\u4e2d\u91c7\u7684\uff0c\u6240\u4ee5\u5c31\u5047\u8bbe\u968f\u673a\u91c7index\u7684\u662f 7\u300138\u30010\u3001129\u7b49\u7b49\u7b49\uff0c\u4e00\u5171 16 \u4e2a\uff08\u8fd9\u5c31\u662f batchsize\uff0c\u8868\u793a\u4e00\u4e2a batch\u4e2d\u5bb9\u7eb3\u7684\u6837\u672c\u6570\uff09</p> <p>\u6bcf\u4e2a\u6837\u672c\u4e2d\u8fde\u7eed\u7684 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u8fd9\u4e2a\u5c31\u5f88\u597d\u7406\u89e3\u4e86\uff1a</p> <p>(0)\u968f\u673a\u751f\u6210\u7b2c 1 \u4e2a index=7\uff0c\u5f97\u5230\u6837\u672c\uff1a\u4ece\u7b2c 7 \u4e2a\u65f6\u95f4\u5f00\u59cb.....\u8ddf\u7740 60 \u4e2a\uff0c\u540e\u9762\u7d27\u8ddf\u7740\u8981\u9884\u6d4b\u7684 24 \u4e2a\u65f6\u95f4\u6b65\uff0cdataloader \u8bfb\u6570\u636e\u65f6\u90fd\u5c01\u88c5\u597d\u4e86\uff0c\u4f1a\u5bf9\u5e94\u4e0a\u7684</p> <p>(1)\u968f\u673a\u751f\u6210\u7b2c 2\u4e2a index=38\uff0c\u5f97\u5230\u6837\u672c\uff1a\u4ece\u7b2c  38 \u4e2a\u65f6\u95f4\u5f00\u59cb.....</p> <p>(2)\u968f\u673a\u751f\u6210\u7b2c 3\u4e2a index=0\uff1a\u4ece\u7b2c 0\u4e2a\u65f6\u95f4\u5f00\u59cb</p> <p>......</p> <p>(15)\u968f\u673a\u751f\u6210\u7b2c 16\u4e2a index=129\uff1a\u4ece\u7b2c 129 \u4e2a\u65f6\u95f4\u5f00\u59cb</p> <p>\u63a5\u4e0b\u6765\u6765\u770b\u5177\u4f53\u7684\u4ee3\u7801\u5b9e\u73b0</p> <p>\u5927\u524d\u63d0\uff1a </p> <p>\u6211\u4eec\u6709\u4e00\u4e2a 966\u00d78\uff081+7\uff09\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff0c1 \u8868\u793a\u65f6\u95f4\u6233\u7279\u5f81\uff0c7 \u8868\u793a\u8bb0\u5f55\u7684\u7279\u5f81\u3002</p>"},{"location":"Reproduction/5_SegRNN_v1/#_7","title":"\u6837\u672c\u7684\u6784\u6210","text":"<p>\u8fd9\u91cc\u6837\u672c\u7684\u6784\u6210\uff0c\u5c31\u770b dataset \u7c7b\u4e2d \u91cd\u5199\u7684 len \u65b9\u6cd5\u3002</p> <p></p> <p>\u8fd9\u4e2a len \u65b9\u6cd5\u5c31\u662f\u7ed9\u51fa\u4e86\u6837\u672c\u6570</p> <p>\u6211\u4eec\u6765\u770b\u8fd9\u4e2a\u6837\u672c\u6570\u662f\u600e\u4e48\u8ba1\u7b97\u7684\uff0c </p> <p>\u9996\u5148  \u8fd9\u4e2a <code>self.data_x</code> \u662f\u600e\u4e48\u6765\u7684\uff1a  <code>self.data_x = data[border1:border2]</code>\uff0c\u901a\u8fc7 borders1 \u548c borders2 \u7d22\u5f15\u6765\u7684\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u4e8e\u8bad\u7ec3\u96c6\u6709 676 \u4e2a\u65f6\u95f4\u6b65\uff0c\u9a8c\u8bc1\u96c6 157 \u4e2a\u65f6\u95f4\u6b65\uff0c\u6d4b\u8bd5\u96c6 253 \u4e2a\u65f6\u95f4\u6b65\uff0c\u4e5f\u5c31\u662f\u5206\u522b\u5bf9\u5e94\u7740 \u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u7684 <code>len(self.data_x)</code> \uff0c\u6240\u4ee5\uff0clen(\u8bad\u7ec3\u96c6)\u3001len(\u9a8c\u8bc1\u96c6)\u3001len(\u6d4b\u8bd5\u96c6) \u7684\u4e5f\u5c31\u662f\u6837\u672c\u6570 \u5206\u522b\u662f <code>676-60-24+1=593 \u3001157-60-24+1=74\u3001253-60-24+1=170</code> \u4e2a\u6837\u672c\u3002</p> <p>\u518d\u89e3\u91ca\u4e00\u4e0b </p> <p>\u5c31\u662f \u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\uff0c\u5e94\u8be5\u4ece\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u5411\u540e\u7559\u51fa 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u6700\u540e\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\u5e94\u8be5\u4ece\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u5411\u524d\u7559\u51fa 24 \u4e2a\u9884\u6d4b\u65f6\u95f4\u6b65\u6784\u6210\u6700\u540e\u4e00\u4e2a\u6837\u672c\u3002\u4e2d\u95f4\u7559\u4e0b\u7684\u5c31\u662f\u6709\u6548\u7d22\u5f15\u3002\u4e5f\u662f\u6837\u672c\u6570\uff0c\u4f46\u662f\u6211\u4eec\u7d22\u5f15\u4e00\u822c\u90fd\u662f\u4ece 0 \u5f00\u59cb\uff0c\u4e2d\u95f4\u7559\u4e0b\u7684\u6709\u6548\u7d22\u5f15\u4e0d\u662f\u4ece 0 \u5f00\u59cb\u7684\u3002\u6240\u4ee5\uff0c\u4e3a\u4e86\u4ece 0 \u5f00\u59cb\uff0c\u90a3\u4e48\u5c31\u628a\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\uff0c \u90a3\u4e48\u540e\u9762\u6700\u540e\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\u5c31\u5e94\u8be5   \u4ece <code>676 \u4e2a\u65f6\u95f4\u6b65-60 \u4e2a\u8f93\u5165\u5e8f\u5217\u65f6\u95f4\u6b65-24 \u4e2a\u9884\u6d4b\u65f6\u95f4\u6b65+1=593\u7d22\u5f15\uff0c\u4e5f\u5c31\u662f\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u7d22\u5f15\u3002</code> </p> <p>\u5c31\u662f\u4e0b\u9762\u8fd9\u5f20\u56fe\u5c55\u793a\u7684\u3002</p> <p></p>"},{"location":"Reproduction/5_SegRNN_v1/#dataset_custom__init__","title":"<code>Dataset_Custom.__init__</code>","text":"<p>\u518d\u5177\u4f53\u7684\uff0c\u6211\u4eec\u6765\u770b\u8fd9\u4e2a <code>Dataset_Custom</code> \u7c7b</p> <ul> <li>\u9996\u5148\u5c31\u662f\uff0c\u6570\u636e\u4e3b\u6587\u4ef6\u4e2d\uff0c\u4ee5\u4e0b\u4ee3\u7801\u662f\u8c03\u7528\u4e86  <code>Dataset_Custom</code> \u7c7b\u7684 init \u65b9\u6cd5\uff0c\u5176\u4e2d\u8fd9\u4e2a init \u65b9\u6cd5\u53c8\u8c03\u7528\u4e86\u7c7b\u4e2d\u9b54\u6cd5\u65b9\u6cd5\u7684  <code>__read_data__</code></li> </ul> Text Only<pre><code>    data_set = Data(\n        root_path=args.root_path,\n        data_path=args.data_path,\n        flag=flag,\n        size=[args.seq_len, args.label_len, args.pred_len],\n        features=args.features,\n        target=args.target,\n        timeenc=timeenc,\n        freq=freq\n    )\n</code></pre> <ul> <li>\u60f3\u8981\u8bf4\u660e\u7684\u4e00\u70b9\u662f\uff0c\u8fd9\u4e2a \u81ea\u5b9a\u4e49\u7684dataset \u7c7b \u662f \u7ee7\u627f\u4e86 pytorch \u5b98\u65b9\u5b9a\u4e49\u7684 Dataset \u7c7b\uff0c\u5e76\u91cd\u5199\u4e86  init \u65b9\u6cd5\u3001getitem \u65b9\u6cd5\u548c len \u65b9\u6cd5\u3002getitem \u9b54\u6cd5\u65b9\u6cd5\u53ef\u4ee5\u4f7f\u5f97\u5b9e\u4f8b\u5316\u4ee5\u540e\u7684\u5bf9\u8c61\u4f7f\u7528\u7d22\u5f15\u8c03\u7528\uff0c\u800c len \u65b9\u6cd5\uff0c\u5728\u4f7f\u7528 <code>len(\u5b9e\u4f8b\u5316\u7684\u5bf9\u8c61)</code> \u65f6 \u8c03\u7528\u3002</li> </ul> <p>\u8fd9\u91cc <code>__read_data__</code>\u7684\u8bb2\u89e3\uff0c\u524d\u9762\u8bb2\u4e86\u4e00\u534a\uff1a\u4e5f\u5c31\u662f\u8fd9\u4e00\u90e8\u5206</p> <p></p>"},{"location":"Reproduction/5_SegRNN_v1/#dataset_custom__len__","title":"<code>Dataset_Custom.__len__</code>","text":"<p>\u7136\u540e\uff0c\u6211\u4eec\u7ee7\u7eed\u770b\u6570\u636e\u4e3b\u6587\u4ef6\u7684\u4e0b\u4e00\u884c</p> Text Only<pre><code>print(flag, len(data_set))\n</code></pre> <p>\u8c03\u7528\u4e86 \u81ea\u5b9a\u4e49 Dataset \u7c7b\u7684 len \u65b9\u6cd5\uff0c\u4e5f\u5c31\u662f\u91cd\u5199\u7684 pytorch Dataset \u7c7b\u7684 len \u65b9\u6cd5\uff0c\u8fd9\u4e2a len \u65b9\u6cd5\u5c31\u662f\u7ed9\u51fa\u4e86\u6837\u672c\u6570</p> Text Only<pre><code>    def __len__(self):\n        return len(self.data_x) - self.seq_len - self.pred_len + 1\n</code></pre> <p>\u6211\u4eec\u6765\u770b\u8fd9\u4e2a\u6837\u672c\u6570\u662f\u600e\u4e48\u8ba1\u7b97\u7684\uff0c\u9996\u5148  \u8fd9\u4e2a <code>self.data_x</code> \u662f\u600e\u4e48\u6765\u7684\uff1a  <code>self.data_x = data[border1:border2]</code>\uff0c\u901a\u8fc7 borders1 \u548c borders2 \u7d22\u5f15\u6765\u7684\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u4e8e\u8bad\u7ec3\u96c6\u6709 676 \u4e2a\u65f6\u95f4\u6b65\uff0c\u9a8c\u8bc1\u96c6 157 \u4e2a\u65f6\u95f4\u6b65\uff0c\u6d4b\u8bd5\u96c6 253 \u4e2a\u65f6\u95f4\u6b65\uff0c\u4e5f\u5c31\u662f\u5206\u522b\u5bf9\u5e94\u7740 \u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u7684 <code>len(self.data_x)</code> \uff0c\u6240\u4ee5\uff0clen(\u8bad\u7ec3\u96c6)\u3001len(\u9a8c\u8bc1\u96c6)\u3001len(\u6d4b\u8bd5\u96c6) \u7684\u4e5f\u5c31\u662f\u6837\u672c\u6570 \u5206\u522b\u662f <code>676-60-24+1=593 \u3001157-60-24+1=74\u3001253-60-24+1=170</code> \u4e2a\u6837\u672c\u3002</p> <p>\u5728\u89e3\u91ca\u4e00\u4e0b\uff0c\u5c31\u662f \u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\uff0c\u5e94\u8be5\u4ece\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u5411\u540e\u7559\u51fa 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u6700\u540e\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\u5e94\u8be5\u4ece\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u5411\u524d\u7559\u51fa 24 \u4e2a\u9884\u6d4b\u65f6\u95f4\u6b65\u6784\u6210\u6700\u540e\u4e00\u4e2a\u6837\u672c\u3002\u4e2d\u95f4\u7559\u4e0b\u7684\u5c31\u662f\u6709\u6548\u7d22\u5f15\u3002\u4e5f\u662f\u6837\u672c\u6570\uff0c\u4f46\u662f\u6211\u4eec\u7d22\u5f15\u4e00\u822c\u90fd\u662f\u4ece 0 \u5f00\u59cb\uff0c\u4e2d\u95f4\u7559\u4e0b\u7684\u6709\u6548\u7d22\u5f15\u4e0d\u662f\u4ece 0 \u5f00\u59cb\u7684\u3002\u6240\u4ee5\uff0c\u4e3a\u4e86\u4ece 0 \u5f00\u59cb\uff0c\u90a3\u4e48\u5c31\u628a\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\uff0c\u90a3\u4e48\u540e\u9762\u6700\u540e\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\u5c31\u5e94\u8be5...</p> <p>\u6216\u8005\u8bf4\uff0c\u5982\u679c\u628a\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\uff0c\u90a3\u4e48\uff0c\u6700\u540e\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\u5c31\u5e94\u8be5 \u4ece <code>676 \u4e2a\u65f6\u95f4\u6b65-60 \u4e2a\u8f93\u5165\u5e8f\u5217\u65f6\u95f4\u6b65-24 \u4e2a\u9884\u6d4b\u65f6\u95f4\u6b65+1=593\u7d22\u5f15\uff0c\u4e5f\u5c31\u662f\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u7d22\u5f15\u3002</code> \u5c31\u662f\u4e0b\u9762\u8fd9\u5f20\u56fe\u5c55\u793a\u7684\u3002</p> <p></p> <p>\u63a5\u4e0b\u6765\u7ee7\u7eed\u770b \u6570\u636e\u4e3b\u6587\u4ef6\u4e2d\u7684  dataloader \u65b9\u6cd5\uff1a</p> Text Only<pre><code>    data_loader = DataLoader(\n        data_set,\n        batch_size=batch_size,\n        shuffle=shuffle_flag,\n        num_workers=args.num_workers,\n        drop_last=drop_last)\n</code></pre>"},{"location":"Reproduction/5_SegRNN_v1/#getitem","title":"getitem","text":"<p>\u8fd9\u91cc\u7684 <code>Dataloader</code> \u7528\u7684\u662f <code>pytorch</code> \u81ea\u5e26\u7684<code>Dataloader</code> \u7c7b\u3002</p> <p>\u6211\u4eec\u77e5\u9053 \u5b9e\u4f8b\u5316\u7684\u7c7b\u52a0==\u4e2d\u62ec\u53f7[\u7d22\u5f15 index]== \u4f1a\u81ea\u52a8\u8c03\u7528 <code>getitem</code> \u65b9\u6cd5\uff0c\u5c31\u662f\u7c7b\u4f3c\u8fd9\u6837\uff1a<code>obj = MyClass([1, 2, 3])\uff0cprint(obj[1])</code>  \uff0c\u5176\u4e2d <code>MyClass([1, 2, 3])</code> \u4f1a\u81ea\u52a8\u8c03\u7528 <code>init</code> \u65b9\u6cd5\uff0c\u800c \u5b9e\u4f8b\u5316\u7684\u7c7b  <code>obj[1]</code> \u5c31\u4f1a\u8c03\u7528 <code>getitem</code> \u65b9\u6cd5\u3002</p> <p>\u8fd9\u91cc\u60f3\u8bf4\u660e\u7684\u662f\uff0cDataloader \u4e5f\u4f1a\u81ea\u52a8\u8c03\u7528 Dataset \u7684 getitem \u65b9\u6cd5\uff0c\u90a3\u8c03\u7528  getitem \u65b9\u6cd5\u5c31\u5f97\u6709\u7d22\u5f15\uff0c\u7d22\u5f15\u600e\u4e48\u6765\u7684\uff1f \u662f\u901a\u8fc7 <code>shuffle</code> \u751f\u6210\u7684\uff0c\u5982\u679c shuffle=True\uff0c\u5c31\u4f1a\u81ea\u52a8\u751f\u6210 batchsize \u4e2a\u968f\u673a\u7d22\u5f15\uff0c\u5e76\u5c06\u8fd9\u4e9b\u7d22\u5f15 \u4f20\u9012\u7ed9 getitem\uff0c\u7136\u540e\u5f97\u5230\u968f\u673a\u6837\u672c\uff0c\u5c01\u88c5\u6210 dataloader\uff0c\u968f\u673a\u7d22\u5f15\u7684\u8303\u56f4\u662f\u901a\u8fc7 Dataset \u7c7b\u7684 len \u65b9\u6cd5\u9650\u5236\u7684\u3002\u5982\u679c shuffle=false \u7684\u8bdd\uff0c\u5c31\u6309\u987a\u5e8f\u9009batchsize \u4e2a\u6837\u672c\u3002</p> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4ed4\u7ec6\u770b\u8fd9\u4e2a  <code>__getitem__</code> \u65b9\u6cd5\uff0c\u53ea\u9700\u8981\u4e00\u4e2a\u53c2\u6570 index \u5373\u53ef\u3002</p> Text Only<pre><code>    def __getitem__(self, index):\n        s_begin = index\n        s_end = s_begin + self.seq_len\n        r_begin = s_end - self.label_len\n        r_end = r_begin + self.label_len + self.pred_len\n\n        seq_x = self.data_x[s_begin:s_end]\n        seq_y = self.data_y[r_begin:r_end]\n        seq_x_mark = self.data_stamp[s_begin:s_end]\n        seq_y_mark = self.data_stamp[r_begin:r_end]\n\n        return seq_x, seq_y, seq_x_mark, seq_y_mark\n</code></pre> <p>\u73b0\u5728\u6211\u4eec\u5c31\u5047\u8bbe\u968f\u673a\u62bd\u53d6\u8bad\u7ec3\u96c6\u7684\u6837\u672c\uff0c\u8bad\u7ec3\u96c6\u7684\u6837\u672c\u6570\u662f 593 \u4e2a\uff0cdataloader \u5728\u751f\u6210\u968f\u673a\u7d22\u5f15\u65f6\u4f1a\u9650\u5236\u5728 len(dataset)\u4e2d\uff0c\u6211\u4eec\u8bbe\u7f6e\u7684 batchsize \u4e3a 16\uff0c\u4e5f\u6211\u4eec\u5047\u8bbe\u751f\u6210\u7684 16 \u4e2a\u968f\u673a\u7d22\u5f15\u5206\u522b\u662f  [0,23, 105, 67, 198, 54,..., 593]\uff08\u603b\u8ba116\u4e2a\u7d22\u5f15\uff09\uff0c\u5982\u679c shuffle=False \u7684\u8bdd\uff0c\u5c31\u662f\u6309\u987a\u5e8f\u53d6\u524d 16 \u4e2a\u7d22\u5f15\u4e5f\u5c31\u662f 0~15\u3002\u5f97\u5230\u7684\u6bcf\u4e2a\u7d22\u5f15\uff0c\u6839\u636e\u6bcf\u4e2a\u7d22\u5f15\u5f97\u5230\u6837\u672c\uff0c\u5411\u540e\u7684 60 \u4e2a\u65f6\u95f4\u6b65\u4f5c\u4e3a\u8f93\u5165\u5e8f\u5217\uff0c\u56e0\u4e3a label_sequence=0\uff0c\u6240\u4ee5\u7d27\u63a5\u7740\u7684 24 \u4e2a\u65f6\u95f4\u6b65\u662f\u9884\u6d4b\u5e8f\u5217\uff1b\u5047\u8bbe\u6211\u4eec\u751f\u6210\u7684\u968f\u673a\u7d22\u5f15\u4e3a\uff1a 23\uff0c\u4e5f\u5c31\u662f <code>index=23</code> \u5c31\u4f1a\u8c03\u7528 <code>dataset</code> \u7684 <code>getitem</code> \u65b9\u6cd5\u3002</p> <p><code>s_begin</code> \u8f93\u5165\u5e8f\u5217\u8d77\u59cb\u70b9\uff1b<code>s_end</code> \u8f93\u5165\u5e8f\u5217\u7ed3\u675f\u70b9\uff1b<code>r_begin</code>\u6807\u7b7e\u5e8f\u5217\u8d77\u70b9\uff1b<code>r_end</code> \u6807\u7b7e+\u9884\u6d4b\u5e8f\u5217\u7ec8\u70b9\uff1b</p> <p></p> <p>\u8f93\u5165\u5e8f\u5217\u8d77\u70b9 <code>=index</code></p> <p>\u8f93\u5165\u5e8f\u5217\u7ec8\u70b9 <code>=index+seq_len</code></p> <p>\u9884\u6d4b\u5e8f\u5217\u8d77\u70b9 <code>=index+seq_len-label_len</code></p> <p>\u9884\u6d4b\u5e8f\u5217\u7ec8\u70b9 <code>=index+seq_len+pred_len</code>  \u8fd9\u91cc\u7701\u7565\u4e86 <code>-label_len+label_len</code></p> <p>\u7136\u540e</p> Text Only<pre><code>        seq_x = self.data_x[s_begin:s_end]\n        seq_y = self.data_y[r_begin:r_end]\n        seq_x_mark = self.data_stamp[s_begin:s_end]\n        seq_y_mark = self.data_stamp[r_begin:r_end]\n\n        return seq_x, seq_y, seq_x_mark, seq_y_mark\n</code></pre> <p>\u6839\u636e\u8f93\u5165\u5e8f\u5217\u7d22\u5f15\u548c\u9884\u6d4b\u5e8f\u5217\u7d22\u5f15\uff0c\u6765\u5f97\u5230 \u8f93\u5165\u7279\u5f81\u5e8f\u5217\u548c\u9884\u6d4b\u7279\u5f81\u5e8f\u5217\u3001\u8f93\u5165\u65f6\u95f4\u6233\u7279\u5f81\u5e8f\u5217\u548c\u9884\u6d4b\u65f6\u95f4\u6233\u7279\u5f81\u5e8f\u5217</p> <p>\u75be\u75c5\u6570\u636e\u96c6\uff1a966\u00d78\uff087 \u4e2a\u7279\u5f81+1 \u4e2a\u65f6\u95f4\u6233\uff0c\u6240\u4ee5\u4e00\u5171 8 \u5217\uff09</p> <p>\u5bf9\u4e8e\u5355\u4e2a\u6837\u672c\u7684 <code>seq_x = self.seq_len \u00d7 7\uff0cseq_y = (label_len + pred_len) \u00d7 7</code>\uff0c<code>seq_x_mark = self.seq_len \u00d7 4 , seq_y_mark = self.seq_len \u00d7 4</code></p> <p>dataloader \u5c01\u88c5\u4e86 <code>batchsize</code> \u4e2a <code>seq_x, seq_y, seq_x_mark, seq_y_mark</code></p> <p></p>"},{"location":"Reproduction/5_SegRNN_v1/#_8","title":"\u6ed1\u52a8\u7a97\u53e3\u548c\u6837\u672c\u5806\u53e0","text":"<p>\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u6ed1\u52a8\u7a97\u53e3\u662f\u5728 <code>__getitem__</code> \u65b9\u6cd5\u4e2d\u901a\u8fc7\u7d22\u5f15\u5207\u7247\u5b9e\u73b0\u7684\uff1a</p> <ul> <li> <p>\u7a97\u53e3\u8d77\u70b9\uff1a\u6bcf\u4e2a\u7d22\u5f15 index \u4ee3\u8868\u4e00\u4e2a\u6ed1\u52a8\u7a97\u53e3\u7684\u8d77\u59cb\u4f4d\u7f6e </p> </li> <li> <p>\u7a97\u53e3\u5212\u5206\uff1a</p> </li> <li>\u8f93\u5165\u7a97\u53e3\uff1a<code>[index:index+seq_len]</code> (60\u4e2a\u65f6\u95f4\u6b65)</li> <li>\u9884\u6d4b\u7a97\u53e3\uff1a<code>[index+seq_len-label_len:index+pred_len]</code> (24\uff08<code>label_len+pred_len</code>\uff09\u4e2a\u65f6\u95f4\u6b65)</li> <li>\u6837\u672c\u91cd\u53e0\uff1a<ul> <li>\u7531\u4e8e\u7d22\u5f15\u5728<code>0\u5230(len(data_x)-seq_len-pred_len)</code>\u4e4b\u95f4\uff0c\u76f8\u90bb\u7d22\u5f15\u7684\u7a97\u53e3\u4f1a\u6709\u5927\u91cf\u91cd\u53e0</li> <li>\u4f8b\u5982\uff0c\u7d22\u5f150\u548c\u7d22\u5f151\u7684\u8f93\u5165\u7a97\u53e3\u5171\u4eab59\u4e2a\u65f6\u95f4\u6b65</li> </ul> </li> </ul> <p>\u7528\u56fe\u6765\u7406\u89e3\u5c31\u662f\u8fd9\u6837\u7684</p> <p></p> <p>\u603b\u7ed3\uff1aDataLoader \u901a\u8fc7\u8c03\u7528 Dataset \u7684 <code>__getitem__</code> \u65b9\u6cd5\u83b7\u53d6\u5355\u4e2a\u6837\u672c\uff0c\u7136\u540e\u5c06\u5b83\u4eec\u5806\u53e0\u6210\u6279\u6b21\u3002\u6837\u672c\u7684\u5b9e\u9645\u7ed3\u6784\u548c\u6ed1\u52a8\u7a97\u53e3\u903b\u8f91\u7531 Dataset \u5b9e\u73b0\uff0cDataLoader \u53ea\u8d1f\u8d23\u7ec4\u88c5\u548c\u6279\u5904\u7406\u3002</p> Python<pre><code>  data_set = Data(\n        root_path=args.root_path, # './dataset/'\n        data_path=args.data_path, # 'national_illness.csv'\n        flag=flag, # flag = 'train'\n        size=[args.seq_len, args.label_len, args.pred_len], # 60,0,24 args.label_len\uff1f =0\uff1b\u89e3\u91ca\uff1aargs.label_len \u7684\u89e3\u91ca\uff1a\u8fd9\u4e2a\u53c2\u6570\u901a\u5e38\u5728\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u4e2d\u4f7f\u7528\uff0c\u8868\u793a\u89e3\u7801\u5668\u8f93\u5165\u4e2d\u5df2\u77e5\u7684\u6807\u7b7e\u957f\u5ea6\u3002\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\u5b83\u662f0\uff0c\u8868\u793a\u89e3\u7801\u5668\u6ca1\u6709\u5df2\u77e5\u6807\u7b7e\u4f5c\u4e3a\u8f93\u5165\uff08\u53ea\u4f9d\u8d56\u7f16\u7801\u5668\u7684\u8f93\u51fa\u8fdb\u884c\u9884\u6d4b\uff09\n        features=args.features, # 'M'\n        target=args.target, # 'OT'\n        timeenc=timeenc, # timeenc = 1\n        freq=freq # freq=\"h\"\n    ) # \u6253\u65ad\u70b9\uff0c\u8df3\u5230 Dataset_Custom init \u3001\u3001\u4e3a\u4ec0\u4e48\u8fd9\u91cc\u80fd\u8bfb\u5230\u6570\u636e\u3002\u7b54\uff1adata_set\u300bData\u300bdata_dict\u300bDataset_Custom\u300bfrom data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Pred--\u300bDataset_Custom init\n    print(flag, len(data_set))\n    data_loader = DataLoader(\n        data_set,\n        batch_size=batch_size, # 16\n        shuffle=shuffle_flag, # True\n        num_workers=args.num_workers, # 10\n        drop_last=drop_last) # True\n    return data_set, data_loader\n</code></pre> <p> </p>"},{"location":"Reproduction/5_SegRNN_v1/#lendata_set","title":"len(data_set)","text":"<p>\u8fd9\u91cc\u6709\u4e00\u4e2a\u95ee\u9898\u9700\u8981\u6ce8\u610f\u4e00\u4e0b\uff0c\u5c31\u662f\u6211\u4eec\u5728\u6253\u5370\u8bad\u7ec3\u96c6\u7684\u65f6\u5019\uff0c\u660e\u660e\u65f6\u95f4\u957f\u5ea6\u662f 676\uff0c\u4e3a\u4ec0\u4e48 <code>len(data_set)=593</code> </p> <p> </p> <p>\u662f\u56e0\u4e3a\uff0cDataset_Custom\u7c7b\uff0c\u91cd\u5199\u4e86 len \u65b9\u6cd5\uff0c\u8fd9\u91cc\u7684 len \u8ba1\u7b97\u65b9\u6cd5\u662f <code>676-60-24+1=593</code>  \u4e3a\u4ec0\u4e48\u8fd9\u6837\u8ba1\u7b97\uff1f</p> <p></p> <p>\u89e3\u91ca\uff1a\u8fd9\u662f\u56e0\u4e3a \u6211\u4eec\u8bad\u7ec3\u96c6\u6709 676 \u4e2a\u65f6\u95f4\u6b65\uff0c\u4e0d\u4ee3\u8868\u6709 676 \u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u4e00\u4e2a\u8bad\u7ec3\u6837\u672c\u8981\u6709 60 \u4e2a\u65f6\u95f4\u6b65\u5bf9\u5e94\u7684\u9884\u6d4b\u65f6\u95f4\u6b65\u662f\u7d27\u968f\u5176\u540e\u7684 24 \u4e2a\u65f6\u95f4\u6b65\uff0c\u4e5f\u5c31\u662f\u7528 60 \u4e2a\u5386\u53f2\u65f6\u95f4\u6b65\u6765\u9884\u6d4b\u672a\u6765\u7684 24 \u4e2a\u65f6\u95f4\u6b65\uff0c\u8fd9\u6837\u6784\u6210\u4e00\u4e2a\u6837\u672c\uff0c\u6240\u4ee5 676 \u4e2a\u65f6\u95f4\u6b65\uff0c\u6700\u540e\u4e00\u4e2a\u6837\u672c\u7684\u7d22\u5f15\u5e94\u8be5\u9884\u7559\u51fa 60+24 \u4e2a\u65f6\u95f4\u6b65\u3002\u4e5f\u5c31\u662f 676 \u4e2a\u65f6\u95f4\u6b65 \u6784\u6210 593 \u4e2a\u8bad\u7ec3\u6837\u672c\u3002\u540c\u6837\u7684\uff0c\u6309\u7167\u8fd9\u4e2a\u903b\u8f91\uff0c\u9a8c\u8bc1\u96c6\u6709 97-60-24+1=14\uff0c \uff0c\u6d4b\u8bd5\u96c6\uff1a193-60-24+1=110\uff1f</p> <p>\u8fd9\u91cc\u4ea7\u751f\u95ee\u9898\u4e86\uff0c\u662f\u56e0\u4e3a\uff0c</p> <p></p> <p>\u8fd9\u91cc\u8fd8\u6ca1\u6709\u6267\u884c\u5b8c\uff0c\u5e94\u8be5 <code>Data\uff08\uff09</code>\u4f1a\u81ea\u52a8\u8c03\u7528 \uff0c\u8fd9\u4e2a <code>Dataset_Custom</code> \u7c7b\u7684  <code>__getitem__</code> \u65b9\u6cd5 </p> <p></p>"},{"location":"Reproduction/5_SegRNN_v1/#_9","title":"\u6a21\u578b\u8bad\u7ec3\u8fed\u4ee3","text":"<p>\u65f6\u95f4\u6b65\u548c\u6837\u672c\uff1a</p> <p></p> <p>\u6a21\u578b\u8fed\u4ee3\u8bad\u7ec3\uff1a</p> <p></p>"},{"location":"Reproduction/5_SegRNN_v1/#segrnn-forward","title":"SegRNN forward","text":""},{"location":"Reproduction/5_SegRNN_v1/#_10","title":"\u7f16\u7801\u5668","text":"<p>\u6211\u4eec\u5c31\u770bSegRNN \u7684\u7f16\u7801\u5668\u90e8\u5206\uff0c\u4e5f\u5c31\u662f\u4e3b\u8981\u662f\u8fd9\u90e8\u5206\uff1a</p> Text Only<pre><code>    def forward(self, x):\n\n        # b:batch_size c:channel_size s:seq_len s:seq_len\n        # d:d_model w:seg_len n:seg_num_x m:seg_num_y\n        batch_size = x.size(0)\n\n        # normalization and permute     b,s,c -&gt; b,c,s\n        if self.revin:\n            x = self.revinLayer(x, 'norm').permute(0, 2, 1)\n        else:\n            seq_last = x[:, -1:, :].detach()\n            x = (x - seq_last).permute(0, 2, 1) # b,c,s\n\n        # segment and embedding    b,c,s -&gt; bc,n,w -&gt; bc,n,d\n        x = self.valueEmbedding(x.reshape(-1, self.seg_num_x, self.seg_len))\n\n        # encoding\n        if self.rnn_type == \"lstm\":\n            _, (hn, cn) = self.rnn(x)\n        else:\n            _, hn = self.rnn(x) # bc,n,d  1,bc,d\n</code></pre> <p>\u5148\u8bf4\u4e00\u4e0b\u8fd9\u91cc\u7684\u601d\u60f3\uff0c\u7136\u540e\u5bf9\u5e94\u5230\u4ee3\u7801\u4e5f\u4f1a\u5f88\u597d\u7406\u89e3\uff1a</p> <p>\u8fd9\u91cc\u7684\u6d41\u7a0b\u56fe\uff1a</p> <p></p> <p>\u9996\u5148\uff0c16 batchsize\uff0c60<code>sequendce_length</code>\uff0c7 \u4e2a\u7279\u5f81\u7684\u901a\u4fd7\u89e3\u91ca</p> <ul> <li> <p>16 \u4e2a\u72ec\u7acb\u7684\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u6709 60 \u4e2a\u8fde\u7eed\u7684\u65f6\u95f4\u6b65\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c\uff0c\u6bcf\u4e2a\u65f6\u95f4\u6b65\u6709 7\u4e2a\u7279\u5f81</p> </li> <li> <p>\u6240\u4ee5\u5c31\u662f\u56e0\u4e3a\u6837\u672c\u662f\u968f\u673a\u4ece\u8bad\u7ec3\u96c6\u4e2d\u91c7\u7684\uff0c\u6240\u4ee5\u5c31\u5047\u8bbe\u91c7\u7684\u662f</p> </li> <li> <p>\u6837\u672c 1\uff0c\u6837\u672c 6\uff0c\u6837\u672c 109\uff0c\u6837\u672c 334\uff0c\u6837\u672c 354\u7b49\u7b49\u7b49\uff0c\u4e00\u5171 16 \u4e2a\uff08\u8fd9\u5c31\u662f batchsize\uff0c\u8868\u793a\u4e00\u4e2a batch\u4e2d\u5bb9\u7eb3\u7684\u6837\u672c\u6570\uff09</p> </li> </ul> <p>\u63a5\u4e0b\u6765\uff0c\u6bcf\u4e2a\u6837\u672c\u4e2d\u8fde\u7eed\u7684 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u8fd9\u4e2a\u5c31\u5f88\u597d\u7406\u89e3\u4e86\uff0c\u4f46\u662f\u8fd9 60 \u4e2a\u8fde\u7eed\u7684\u65f6\u95f4\u6b65\uff1a</p> <ul> <li> <p>16 \u4e2a\u72ec\u7acb\u7684\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u6709 60 \u4e2a\u8fde\u7eed\u7684\u65f6\u95f4\u6b65\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c\uff0c\u6bcf\u4e2a\u65f6\u95f4\u6b65\u6709 7 \u4e2a\u7279\u5f81</p> </li> <li> <p>\u6240\u4ee5\u5c31\u662f\u56e0\u4e3a\u6837\u672c\u662f\u968f\u673a\u4ece\u8bad\u7ec3\u96c6\u4e2d\u91c7\u7684\uff0c\u6240\u4ee5\u5c31\u5047\u8bbe\u968f\u673a\u91c7index\u7684\u662f 7\u300138\u30010\u3001129\u7b49\u7b49\u7b49\uff0c\u4e00\u5171 16 \u4e2a\uff08\u8fd9\u5c31\u662f batchsize\uff0c\u8868\u793a\u4e00\u4e2a batch\u4e2d\u5bb9\u7eb3\u7684\u6837\u672c\u6570\uff09</p> </li> <li> <p>\u6bcf\u4e2a\u6837\u672c\u4e2d\u8fde\u7eed\u7684 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u8fd9\u4e2a\u5c31\u5f88\u597d\u7406\u89e3\u4e86\uff1a</p> </li> <li> <p>(0)\u968f\u673a\u751f\u6210\u7b2c 1 \u4e2a index=7\uff0c\u5f97\u5230\u6837\u672c\uff1a\u4ece\u7b2c 7 \u4e2a\u65f6\u95f4\u5f00\u59cb.....\u8ddf\u7740 60 \u4e2a\uff0c\u540e\u9762\u7d27\u8ddf\u7740\u8981\u9884\u6d4b\u7684 24 \u4e2a\u65f6\u95f4\u6b65\uff0cdataloader \u8bfb\u6570\u636e\u65f6\u90fd\u5c01\u88c5\u597d\u4e86\uff0c\u4f1a\u5bf9\u5e94\u4e0a\u7684</p> </li> <li> <p>(1)\u968f\u673a\u751f\u6210\u7b2c 2\u4e2a index=38\uff0c\u5f97\u5230\u6837\u672c\uff1a\u4ece\u7b2c  38 \u4e2a\u65f6\u95f4\u5f00\u59cb.....</p> </li> <li> <p>(2)\u968f\u673a\u751f\u6210\u7b2c 3\u4e2a index=0\uff1a\u4ece\u7b2c 0\u4e2a\u65f6\u95f4\u5f00\u59cb</p> </li> <li> <p>......</p> </li> <li> <p>(15)\u968f\u673a\u751f\u6210\u7b2c 16\u4e2a index=129\uff1a\u4ece\u7b2c 129 \u4e2a\u65f6\u95f4\u5f00\u59cb</p> </li> </ul> Text Only<pre><code>x = self.revinLayer(x, 'norm').permute(0, 2, 1)\n</code></pre> <p>\u5728\u8fdb\u884c\u8f6c\u7f6e\u4e4b\u524d\u8fdb\u884c\u4e86\u53ef\u9006\u5b9e\u4f8b\u6807\u51c6\u5316\uff0c\u4e5f\u5c31\u662f\u5bf9\u8bad\u7ec3\u6837\u672c\u5185\u7684\u7279\u5f81\u8fdb\u884c\u5b9e\u4f8b\u6807\u51c6\u5316\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u6d88\u9664\u5206\u5e03\u504f\u79fb\uff0c\u7528\u4e00\u4e2a\u4f8b\u5b50\u6765\u89e3\u91ca\uff0c\u5c31\u662f\uff1a</p> <p></p> <p>\u597d\u5904\u662f\uff1a\u6d88\u9664\u7edd\u5bf9\u6c34\u5e73\u548c\u5c3a\u5ea6\u7684\u5f71\u54cd\uff0c\u8ba9\u6a21\u578b\u4e13\u6ce8\u4e8e\u5b66\u4e60\u5e8f\u5217\u7684==\u76f8\u5bf9\u53d8\u5316\u6a21\u5f0f==</p> <p>\u5bf9\u4e8e\u4e24\u6b21\u6807\u51c6\u5316\u66f4\u76f4\u89c2\u7684\u4f8b\u5b50\uff1a</p> <p></p> <p></p> <p></p>"},{"location":"Reproduction/5_SegRNN_v1/#_11","title":"\u4ea4\u6362\u7ef4\u5ea6","text":"<p>\u5728\u8fdb\u884c\u5b8c\u6807\u51c6\u5316\u4ee5\u540e\uff0c\u8fdb\u884c permute\uff0c\u4ea4\u6362\u7b2c1 \u7ef4\u5ea6\u548c 2 \u7ef4\u5ea6\uff0c\u5bf9\u5e94\u5c31\u662f\uff1a</p> <p>\u63a5\u4e0b\u6765 16x60x7 --\u300b 16\u00d77\u00d760</p> <p>\u5c31\u662f\uff1a</p> <p>\uff080\uff09\u6837\u672c 1\uff1a\u7279\u5f81 1[60\u4e2a\u8fde\u7eed\u7684\u65f6\u95f4\u6b65]\uff0c\u7279\u5f81 2\uff0c\u7279\u5f81 3,,,,,\u7279\u5f81 7</p> <p>\uff081\uff09\u6837\u672c 6\uff1a\u7279\u5f81 1\uff0c\u7279\u5f81 2\uff0c\u7279\u5f81 3,,,,,\u7279\u5f81 7</p> <p>\uff082\uff09\u6837\u672c109\uff1a\u7279\u5f81 1\uff0c\u7279\u5f81 2\uff0c\u7279\u5f81 3,,,,,\u7279\u5f81 7</p> <p>......</p> <p>\uff0815\uff09\u6837\u672c 334\uff1a\u7279\u5f81 1\uff0c\u7279\u5f81 2\uff0c\u7279\u5f81 3,,,,,\u7279\u5f81 7</p> <p>\u6bcf\u4e2a\u7279\u5f81\u5206\u522b\u6709 60 \u4e2a\u8fde\u7eed\u7684\u65f6\u95f4\u6b65</p> <p>\u63a5\u4e0b\u6765\u5462\uff0c\u53c8\u5f00\u59cb\u5bf9\u4e8e\u8fd9 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u5206\u6bb5\uff0c\u5206\u6210 5 \u6bb5\uff0c\u6bcf\u6bb5 12 \u4e2a</p> <p>\u7136\u540e\u5462\uff0c\u5c31\u628a\u5206\u51fa\u6765\u7684 \u6bb5\uff0c12 \u7ef4 \u7edf\u7edf\u5582\u5230 linear \u4e2d\uff0c\u5d4c\u5165\u5230 512 \u7ef4\uff0c\u7528\u7684\u4e00\u4e2a\u5d4c\u5165\u7a7a\u95f4\uff0c\u6240\u4ee5\u5d4c\u5165\u65f6\u4f7f\u7528\u6743\u503c\u77e9\u9635\u662f\u4e00\u6837\u7684\uff0c\u6bd5\u7adf\u5f97\u5728\u540c\u4e00\u4e2a\u51c6\u5219\u4e0b\u624d\u6709\u53ef\u6bd4\u6027\uff0c\u8fd9\u4e00\u6b65\u5c31\u662f\u5b66\u4e60\u4e86\u6bcf\u4e00\u4e2a\u5c0f\u6bb5\u5185\uff0c\u65f6\u95f4\u4e4b\u95f4\u7684\u76f8\u5173\u5173\u7cfb</p> <p>\u5bf9\u5e94\u7684\u6e90\u4ee3\u7801\u5c31\u662f\uff1a</p> Text Only<pre><code>x = self.valueEmbedding(x.reshape(-1, self.seg_num_x, self.seg_len))\n</code></pre> <p>\u8fd9\u4e2a\u4ee3\u7801\u7684\u5199\u6cd5\u5176\u5b9e\u4e0d\u592a\u597d\u7406\u89e3\uff0c</p> <p>-1 \u5c31\u662f 16\u00d77=112\uff0c\u5b83\u628a\u6837\u672cbatch \u7ef4\u5ea6\u548c\u7279\u5f81\u7ef4\u5ea6\uff0c\u6df7\u5230\u4e00\u8d77\u5199\uff0creshape \u6210\uff08-1\uff0cseg_num_x,seg_dim\uff09</p> <p>\uff080\uff09\u6837\u672c 1-\u7279\u5f81 1 \uff1a\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011</p> <p>\uff080\uff09\u6837\u672c 1-\u7279\u5f81 2 \uff1a\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011</p> <p>....</p> <p>\uff080\uff09\u6837\u672c 1-\u7279\u5f81 7 \uff1a\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011</p> <p>\uff081\uff09\u6837\u672c 6-\u7279\u5f81 1 \uff1a\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011</p> <p>\uff081\uff09\u6837\u672c 6-\u7279\u5f81 2 \uff1a\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011</p> <p>....</p> <p>\uff081\uff09\u6837\u672c 6-\u7279\u5f81 7 \uff1a\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011</p> <p>\uff0815\uff09\u6837\u672c 334-\u7279\u5f81 1 \uff1a\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011</p> <p>\uff0815\uff09\u6837\u672c 334-\u7279\u5f81 2 \uff1a\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011</p> <p>....</p> <p>\uff0815\uff09\u6837\u672c 334-\u7279\u5f81 7 \uff1a\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011\u301012\u3011</p> <p>\u4e5f\u5c31\u662f 112 \u6761\u5e8f\u5217\u3001\u3001\u3001 112\u00d75\u00d712</p> Text Only<pre><code>Sequential(\n  (0): Linear(in_features=12, out_features=512, bias=True)\n  (1): ReLU()\n)\n</code></pre> <p>linear \u5c31\u662f\u628a\u6240\u6709\u7684 12 \u5168\u90e8\u5d4c\u5165\u5230 512 \u7ef4</p> <p>112\u00d75\u00d7512</p> <p>\uff080\uff09\u6837\u672c 1-\u7279\u5f81 1 \uff1a\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u2192 5\u6b65GRU \u2192 hn[0,0]</p> <p>\uff080\uff09\u6837\u672c 1-\u7279\u5f81 2 \uff1a\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u2192 5\u6b65GRU \u2192 hn[0,1]</p> <p>....</p> <p>\uff080\uff09\u6837\u672c 1-\u7279\u5f81 7 \uff1a\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u2192 5\u6b65GRU \u2192 hn[0,6]</p> <p>\uff081\uff09\u6837\u672c 6-\u7279\u5f81 1 \uff1a\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u2192 5\u6b65GRU \u2192 hn[0,7]</p> <p>\uff081\uff09\u6837\u672c 6-\u7279\u5f81 2 \uff1a\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u2192 5\u6b65GRU \u2192 hn[0,8]</p> <p>....</p> <p>\uff081\uff09\u6837\u672c 6-\u7279\u5f81 7 \uff1a\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011</p> <p>\uff0815\uff09\u6837\u672c 334-\u7279\u5f81 1 \uff1a\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011</p> <p>\uff0815\uff09\u6837\u672c 334-\u7279\u5f81 2 \uff1a\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011</p> <p>....</p> <p>\uff0815\uff09\u6837\u672c 334-\u7279\u5f81 7 \uff1a\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u3010512\u3011\u2192 5\u6b65GRU \u2192 hn[0,111]</p> <p></p> <p>\u8865\u5145\u4e00\u4e0b\uff1a</p> <p></p>"},{"location":"Reproduction/5_SegRNN_v1/#gru","title":"\u4f20\u7edf GRU","text":"<p>\u6574\u4e2a forward \u8fc7\u7a0b\u7684\u56fe\u89e3\uff1a</p> Text Only<pre><code>\u8f93\u5165: x [16, 60, 7]\n(16\u4e2a\u6279\u6b21\uff0c\u6bcf\u4e2a60\u4e2a\u65f6\u95f4\u6b65\uff0c\u6bcf\u6b657\u4e2a\u7279\u5f81)\n            \u2502\n            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      RevIN \u6807\u51c6\u5316 + \u7ef4\u5ea6\u7f6e\u6362     \u2502\n\u2502   x = revinLayer(x, 'norm')   \u2502\n\u2502      .permute(0, 2, 1)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n               \u25bc\n          x [16, 7, 60]\n(16\u4e2a\u6279\u6b21\uff0c7\u4e2a\u7279\u5f81\uff0c\u6bcf\u4e2a\u7279\u5f8160\u4e2a\u65f6\u95f4\u6b65)\n            \u2502\n            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         \u91cd\u5851\u4e3a\u5206\u6bb5\u683c\u5f0f          \u2502\n\u2502 x.reshape(-1, seg_num_x, seg_len) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n               \u25bc\n          x [112, 5, 12]\n(112\u4e2a\u5e8f\u5217=16\u6279\u6b21\u00d77\u7279\u5f81\uff0c\u6bcf\u4e2a\u52065\u6bb5\uff0c\u6bcf\u6bb512\u6b65)\n            \u2502\n            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          \u6bb5\u503c\u5d4c\u5165             \u2502\n\u2502     x = valueEmbedding(x)     \u2502\n\u2502  (Linear: 12 \u2192 512 + ReLU)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n               \u25bc\n          x [112, 5, 512]\n(112\u4e2a\u5e8f\u5217\uff0c5\u4e2a\u6bb5\uff0c\u6bcf\u6bb5\u8868\u793a\u4e3a512\u7ef4\u5411\u91cf)\n            \u2502\n            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           GRU \u7f16\u7801            \u2502\n\u2502      _, hn = self.rnn(x)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n               \u25bc\n          hn [1, 112, 512]\n(1\u5c42GRU\uff0c112\u4e2a\u5e8f\u5217\u7684\u6700\u7ec8\u9690\u85cf\u72b6\u6001)\n            \u2502\n            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    RMF \u89e3\u7801     \u2502    PMF \u89e3\u7801   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \u5faa\u73af\u591a\u6b65\u9884\u6d4b    \u2502  \u2502  \u5e76\u884c\u591a\u6b65\u9884\u6d4b   \u2502\n\u2502(\u9010\u6bb5\u81ea\u56de\u5f52\u9884\u6d4b)  \u2502  \u2502(\u4e00\u6b21\u6027\u9884\u6d4b\u6240\u6709\u6bb5)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502              \u2502\n         \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502       \u2502  \u4f4d\u7f6e\u548c\u901a\u9053\u5d4c\u5165   \u2502\n         \u2502       \u2502   \u7ec4\u5408\u6210\u6761\u4ef6     \u2502\n         \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502              \u2502\n         \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502       \u2502 pos_emb [224, 1, 512] \u2502\n         \u2502       \u2502 (224=16\u00d77\u00d72)   \u2502\n         \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502              \u2502\n         \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502       \u2502   \u6761\u4ef6GRU\u89e3\u7801    \u2502\n         \u2502       \u2502 _, hy = rnn(pos_emb, hn) \u2502\n         \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502              \u2502\n         \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502       \u2502 hy [1, 224, 512] \u2502\n         \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \u9884\u6d4b + \u5806\u53e0\u5404\u6bb5  \u2502 \u2502     \u9884\u6d4b       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 y = predict(hy) \u2502\n         \u2502         \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502              \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n                \u25bc\n           y [16, 7, 24]\n (\u9884\u6d4b\u7ed3\u679c: 16\u4e2a\u6279\u6b21\uff0c7\u4e2a\u7279\u5f81\uff0c\u9884\u6d4b24\u4e2a\u65f6\u95f4\u6b65)\n                \u2502\n                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      \u7ef4\u5ea6\u7f6e\u6362 + RevIN\u53cd\u6807\u51c6\u5316    \u2502\n\u2502   y = revinLayer(y.permute(0, 2, 1), 'denorm')   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n                \u25bc\n       \u6700\u7ec8\u8f93\u51fa y [16, 24, 7]\n(16\u4e2a\u6279\u6b21\uff0c\u9884\u6d4b\u672a\u676524\u4e2a\u65f6\u95f4\u6b65\uff0c\u6bcf\u6b657\u4e2a\u7279\u5f81)\n</code></pre>"},{"location":"Reproduction/5_SegRNN_v1/#_12","title":"\u89e3\u7801\u8fc7\u7a0b","text":"<p>\u5173\u4e8e SegRNN \u7684\u4e24\u4e2a\u6838\u5fc3\u521b\u65b0\u70b9</p> <p>\uff081\uff09\u5206\u6bb5\u7f16\u7801</p> <p>\uff082\uff09\u5e76\u884c\u89e3\u7801</p> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u6765\u770b\u5e76\u884c\u89e3\u7801\u8fc7\u7a0b\uff0c\u56e0\u4e3a\u662f\u4e00\u6b21\u89e3\u7801\uff0c\u6240\u4ee5\u9700\u8981\u4f4d\u7f6e\u7f16\u7801\uff0c\u6765\u770b\u8fd9\u4e2a\u4f4d\u7f6e\u7f16\u7801\u7684\u5b9a\u4e49\uff0c\u6709\u6bb5\u7684\u7f16\u7801\u548c\u901a\u9053\u7279\u5f81\u7f16\u7801\uff0c\u7ecf\u8fc7\u62fc\u63a5\u6784\u6210\u4e86\u5b8c\u6574\u7684\u4f4d\u7f6e\u7f16\u7801\u3002</p> <p></p> <p>\u5177\u4f53\u6765\u8bf4\uff0cself.pos_emb.shape = 2 \u00d7 256\uff1b</p> <p>\u5176\u4e2d\uff0c<code>self.seg_num_y = self.pred_len // self.seg_len = 24 //12</code>\uff0c24 \u662f\u9884\u6d4b\u6b65\u957f\uff0c12 \u662f\u5206\u6bb5\u6b65\u957f\uff0c\u4e5f\u5c31\u662f \u9884\u6d4b\u7684 y \u5206\u6210 2 \u6bb5\uff0c\u6bcf\u6bb5 12 \u4e2a\u6b65\u957f\uff0c\u7528 256 \u7ef4\u7684\u5411\u91cf\u8868\u793a 1 \u4e2a\u4f4d\u7f6e\uff0c2 \u4e2a\u4f4d\u7f6e\uff0c\u5c31\u662f 2 \u4e2a 256 \u7ef4\u7684\u5411\u91cf\uff0c\u5f97\u5230\u6bcf\u4e2a\u6bb5\u7684\u4f4d\u7f6e\u7f16\u7801\uff1b</p> <p>\u7531\u4e8e\u6bcf\u4e2a\u6bb5\u662f\u7528 7 \u4e2a\u7279\u5f81\u8868\u793a\u7684\uff0c\u6240\u4ee5\u8fd8\u9700\u8981\u8868\u793a\u7279\u5f81\u4f4d\u7f6e\u7f16\u7801\uff0c<code>self.channel_emb.shape = 7\u00d7256</code> \u4e5f\u5c31\u662f \u7b2c0 \u7279\u5f81\u4f4d\u7f6e\u662f\u4e00\u4e2a256 \u7ef4\u7684\u5411\u91cf\u8868\u793a\uff0c\u7b2c 1 \u7279\u5f81\u662f\u4e00\u4e2a 256 \u7ef4\u7684\u5411\u91cf\u8868\u793a\uff0c\u4ee5\u6b64\u7c7b\u63a8\u5f97\u5230 \u901a\u9053\u4f4d\u7f6e\u7f16\u7801\uff0c\u63a5\u4e0b\u6765\u7ee7\u7eed\u770b\u4f4d\u7f6e\u7f16\u7801\u600e\u4e48\u52a0\u5230\u5e8f\u5217\u4e0a\u7684\u3002</p> <p></p> <p>\u770b\u6ce8\u91ca\uff0c\u9884\u6d4b\u76842 \u6bb5\u4f4d\u7f6e\u7f16\u7801\uff0c\u662f 2\u00d7256 \u7684\uff0c\u7b2c 0 \u7ef4\u6269\u4e00\u7ef4\uff0c\u53d8\u6210 1\u00d72\u00d7256 \u7684\uff0c\u5728\u7b2c\u4e00\u7ef4\u91cd\u590d 7 \u6b21\uff08\u4e5f\u5c31\u662f\u7279\u5f81\u6570\uff09\uff0c\u6700\u540e\u53d8\u6210 7\u00d72\u00d7256 \u7ef4\u5ea6\u7684\uff1b</p> <p>\u901a\u9053\u4f4d\u7f6e\u7f16\u7801\u662f 7\u00d7256 \u7684\uff0c\u7b2c 1 \u7ef4\u6269 1 \u7ef4\uff0c\u53d8\u6210 7\u00d71\u00d7256 \u7684\uff0c\u7b2c 1 \u7ef4\u91cd\u590d \u9884\u6d4b\u65f6\u95f4\u6b65\u5206\u6bb5\u6b21\u6570\uff0c\u53d8\u6210 7\u00d72\u00d7256 \u7684</p> <p>\u7136\u540e\uff0c\u5728\u6700\u540e\u4e00\u7ef4 \u4e5f\u5c31\u662fdim=-1\u8fdb\u884c\u62fc\u63a5\uff08torch.cat\uff09\uff0c\u53d8\u6210 7\u00d72\u00d7512 \u7684\u5f62\u72b6</p> <p>\u7136\u540e view \u7ef4\u5ea6\u8f6c\u6362\uff08\u8fd9\u4e2a\u7ef4\u5ea6\u8f6c\u6362\u662f\u4fdd\u6301\u5185\u5b58\u4e0d\u53d8\u7684\u610f\u601d\uff0c\u548c permute\u3001transpose \u90fd\u662f\u7ef4\u5ea6\u53d8\u6362\u51fd\u6570\uff0c\u6709\u70b9\u533a\u522b\uff0c\u6211\u4e5f\u4e0d\u592a\u660e\u767d\uff0c\u603b\u4e4b\u5c31\u662f\u7ef4\u5ea6\u53d8\u6362\uff09\uff0cview \u6210<code>\uff08-1,1,512</code> \u7684\uff0c\u4e5f\u5c31\u662f\u5408\u5e76 \u9884\u6d4b\u65f6\u95f4\u6b65\u5206\u6bb5\u4f4d\u7f6e\u7f16\u7801  \u548c \u901a\u9053\u4f4d\u7f6e\u7f16\u7801 \u53d8\u6210 \u5f62\u72b6\u4e3a <code>14\u00d71\u00d7512</code> \u7684\u3002</p> <p>\u6700\u540e\u5c31\u662f repeat\uff0c\u7b2c 0 \u7ef4\u91cd\u590d batchsize \u6b21\uff0c\u6700\u7ec8\u7684 <code>pos_emb</code> \u4e5f\u5c31\u662f 16\u00d714=224 \uff0c\u4e5f\u5c31\u662f 224\u00d71\u00d7512</p> <ul> <li>self.pos_emb.unsqueeze(0).repeat(self.enc_in, 1, 1)\uff1a\u5c06\u4f4d\u7f6e\u7f16\u7801\u6269\u5c55\u4e3a (enc_in, seg_num_y, d_model // 2) \u7684\u5f62\u72b6\u3002</li> <li>self.channel_emb.unsqueeze(1).repeat(1, self.seg_num_y, 1)\uff1a\u5c06\u901a\u9053\u7f16\u7801\u6269\u5c55\u4e3a (enc_in, seg_num_y, d_model // 2) \u7684\u5f62\u72b6\u3002</li> <li>-torch.cat([...], dim=-1)\uff1a\u5c06\u4f4d\u7f6e\u7f16\u7801\u548c\u901a\u9053\u7f16\u7801\u5728\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u62fc\u63a5\uff0c\u5f97\u5230\u5f62\u72b6\u4e3a (enc_in, seg_num_y, d_model) \u7684\u7f16\u7801\u3002</li> <li>.view(-1, 1, self.d_model).repeat(batch_size, 1, 1)\uff1a\u5c06\u7f16\u7801\u5c55\u5e73\u5e76\u6269\u5c55\u4e3a (batch_size * enc_in * seg_num_y, 1, d_model) \u7684\u5f62\u72b6\u3002</li> </ul> <p>\u4f4d\u7f6e\u7f16\u7801\u7684\u4f5c\u7528\u662f\u4e3a\u6bcf\u4e2a\u9884\u6d4b\u6bb5\uff08segment\uff09\u6dfb\u52a0\u552f\u4e00\u7684\u4f4d\u7f6e\u4fe1\u606f\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u533a\u5206\u4e0d\u540c\u4f4d\u7f6e\u7684\u5143\u7d20\u3002\u8fd9\u5bf9\u4e8e\u6355\u6349\u5e8f\u5217\u4e2d\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u987a\u5e8f\u4fe1\u606f\u975e\u5e38\u91cd\u8981\u3002</p> <p>\u63a5\u4e0b\u6765 \u8fdb\u884c\u8bba\u6587\u7684\u8fd9\u4e00\u90e8\u5206\uff1a</p> <p></p> <p>\u4e5f\u5c31\u662f\u6e90\u7801\u4e2d\u7684\u8fd9\u4e00\u53e5\uff1a</p> <p></p> <ul> <li>\u7136\u540e\uff0c\u5c06\u4f4d\u7f6e\u7f16\u7801 pos_emb \u8f93\u5165\u5230 RNN \u4e2d\uff0c\u5e76\u4f7f\u7528\u4e4b\u524d\u7684\u9690\u85cf\u72b6\u6001 hn \u8fdb\u884c==\u521d\u59cb\u5316\uff1b== </li> </ul> <p>\u4f4d\u7f6e\u7f16\u7801 pos_emb\uff1a </p> <ul> <li><code>pos_emb</code> \u662f\u4e00\u4e2a\u5f62\u72b6\u4e3a <code>(batch_size * self.enc_in * self.seg_num_y, 1, self.d_model)</code> \u7684\u5f20\u91cf\uff0c\u5305\u542b\u4e86\u4f4d\u7f6e\u7f16\u7801\u4fe1\u606f\u3002\u3010224,1,512\u3011</li> </ul> <p>\u9690\u85cf\u72b6\u6001 hn \u7684\u5904\u7406\uff1a </p> <ul> <li> <p><code>hn</code> \u662f\u7f16\u7801\u9636\u6bb5\u751f\u6210\u7684\u9690\u85cf\u72b6\u6001\uff0c\u5f62\u72b6\u4e3a <code>(1, batch_size * self.enc_in, self.d_model)</code>\u3002 \u30101,112,512\u3011</p> </li> <li> <p><code>hn.repeat(1, 1, self.seg_num_y)</code>\uff1a\u5c06 hn \u5728\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u91cd\u590d <code>self.seg_num_y</code> \u6b21\uff0c\u5f97\u5230\u5f62\u72b6\u4e3a <code>(1, batch_size * self.enc_in, self.d_model * self.seg_num_y)</code> \u7684\u5f20\u91cf\u3002\u30101,112,1024\u3011</p> </li> <li><code>.view(1, -1, self.d_model)</code>\uff1a\u5c06\u5f20\u91cf\u91cd\u65b0\u8c03\u6574\u5f62\u72b6\u4e3a <code>(1, batch_size * self.enc_in * self.seg_num_y, self.d_model)</code>\u3002\u30101,224,512\u3011</li> </ul> <p>RNN \u7684\u8c03\u7528\uff1a </p> <ul> <li>self.rnn(pos_emb, hn)\uff1a\u5c06\u4f4d\u7f6e\u7f16\u7801 pos_emb \u548c\u9690\u85cf\u72b6\u6001 hn \u8f93\u5165\u5230 RNN \u4e2d\u3002</li> <li>_, hy\uff1aRNN \u7684\u8f93\u51fa\uff0c\u5176\u4e2d _ \u662f\u8f93\u51fa\u5e8f\u5217\uff0chy \u662f\u6700\u540e\u7684\u9690\u85cf\u72b6\u6001\u3002</li> </ul> <p>\u8fd9\u4e00\u6b65\u7684\u5b9e\u9645\u610f\u4e49\u662f\u4ec0\u4e48\uff1f </p> <p>\uff081\uff09\u672c\u6765\u53ea\u7528 h_n \u4f5c\u4e3a\u89e3\u7801\u7684\u521d\u59cb\u72b6\u6001\uff0c\u73b0\u5728\u52a0\u5165\u4e86\u4f4d\u7f6e\u4fe1\u606f\uff0c\u53ef\u4ee5\u8fdb\u884c\u5e76\u884c\u89e3\u7801\uff0c</p> <p>\uff082\uff09hy \u901a\u8fc7 RNN\uff08\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff09\u5904\u7406\u4f4d\u7f6e\u7f16\u7801\uff08pos_emb\uff09\u540e\u5f97\u5230\u7684\u9690\u85cf\u72b6\u6001</p> <p>\uff083\uff09hy \u7684\u5b9e\u9645\u610f\u4e49\u5728\u4e8e\uff0c\u5b83\u5305\u542b\u4e86\u901a\u8fc7 RNN \u5904\u7406\u540e\u7684\u5e8f\u5217\u4fe1\u606f\uff0c\u5e76\u4e14\u53ef\u4ee5\u7528\u4e8e\u8fdb\u4e00\u6b65\u7684\u9884\u6d4b\u6216\u89e3\u7801\u64cd\u4f5c</p>"},{"location":"Reproduction/5_SegRNN_v1/#selfpredict","title":"\u9884\u6d4b self.predict","text":"Text Only<pre><code> # 1,bcm,d -&gt; 1,bcm,w -&gt; b,c,s\n            y = self.predict(hy).view(-1, self.enc_in, self.pred_len)\n</code></pre> <p>\u9996\u5148 self.predict\uff0c\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u7ebf\u6027\u6620\u5c04\u5c42\uff0c\u5c06 512 \u7ef4\u6620\u5c04\u5230 12 \u7ef4\u3002\u8fd9\u4e2a 12 \u7ef4\u662f\u4ec0\u4e48\uff1f\u662f\u89e3\u7801\u9636\u6bb5\uff0c60 \u4e2a\u65f6\u95f4\u6b65\u5206\u6210 5 \u6bb5\u6bcf\u6bb5\u7684\u65f6\u95f4\u6b65 \u6b65\u957f 12 \u6b65\uff0c\u8fd9\u91cc\u7684 12 \u7ef4\u5bf9\u5e94\u7684\u5c31\u662f \u9884\u6d4b\u65f6\u95f4\u6b65\u6b65\u957f 24 \u6b65\uff0c\u5206\u6210 2 \u6bb5\uff0c\u6bcf\u6bb5 12 \u6b65\u3002</p> <p></p> <p>\u4e5f\u5c31\u662f\u524d\u9762 <code>RNN</code> \u7684\u8c03\u7528\uff1a</p> <ul> <li> <p><code>self.rnn(pos_emb, hn)\uff1a</code>\u5c06\u4f4d\u7f6e\u7f16\u7801 pos_emb \u548c\u9690\u85cf\u72b6\u6001 hn \u8f93\u5165\u5230 RNN \u4e2d\u3002</p> </li> <li> <p><code>_, hy</code>\uff1aRNN \u7684\u8f93\u51fa\uff0c\u5176\u4e2d _ \u662f\u8f93\u51fa\u5e8f\u5217\uff0chy \u662f\u6700\u540e\u7684\u9690\u85cf\u72b6\u6001\u3002</p> </li> <li>\u4f7f\u7528 <code>hy</code> \u8fdb\u884c\u9884\u6d4b\uff1a</li> <li><code>y = self.predict(hy).view(-1, self.enc_in, self.pred_len)</code>\uff1a\u4f7f\u7528\u9690\u85cf\u72b6\u6001 hy \u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u5c06\u9884\u6d4b\u7ed3\u679c\u8c03\u6574\u4e3a\u5f62\u72b6\u4e3a <code>(batch_size, self.enc_in, self.pred_len)</code> \u7684\u5f20\u91cf\u3002\uff0816\u00d77\u00d724\uff09</li> </ul> Text Only<pre><code>        if self.revin:\n            y = self.revinLayer(y.permute(0, 2, 1), 'denorm')\n</code></pre> <p>\u6700\u540e\uff0c\u53cd\u5b9e\u4f8b\u6807\u51c6\u5316\uff0c\u56e0\u4e3a\u4e4b\u524d\u8fdb\u884c\u4e86\u5b9e\u4f8b\u6807\u51c6\u5316\uff0c\u73b0\u5728\u628a\u8fd8\u539f\u56de\u53bb\u3002\u5f62\u72b6\u53d8\u6210 <code>16\u00d724\u00d77</code>.</p> <p>\u5bf9\u5e94\u6e90\u7801\uff1a</p> Text Only<pre><code>    def _denormalize(self, x):\n        if self.affine:\n            x = x - self.affine_bias\n            x = x / (self.affine_weight + self.eps*self.eps)\n        x = x * self.stdev\n        if self.subtract_last:\n            x = x + self.last\n        else:\n            x = x + self.mean\n        return x\n</code></pre> <p>\u6700\u91cd\u8981\u7684\u4e24\u6b65\uff1a<code>x = x * self.stdev</code>  \u548c <code>x = x + self.mean</code></p> <p>\u4ee5\u4e0a\u5c31\u662f SegRNN \u7684\u6e90\u7801\u5b9e\u73b0\u7684\u7406\u89e3\u3002</p>"},{"location":"Reproduction/5_SegRNN_v2/","title":"\uff08\u8865\u5145\uff09\u590d\u73b0 SegRNN","text":""},{"location":"Reproduction/5_SegRNN_v2/#segrnn","title":"\uff08\u8865\u5145\uff09\u590d\u73b0 SegRNN","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 6235 \u4e2a\u5b57  28 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 31 \u5206\u949f</p> <p>\u8fd9\u91cc\u4e3b\u8981\u518d\u6b21\u7406\u6e05\u4e86 \u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u7684\u52a0\u8f7d\u8fc7\u7a0b\u3002</p> <ul> <li> \u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u7684\u5b9a\u4e49</li> <li> \u65f6\u95f4\u5e8f\u5217\u6837\u672c\u7684\u52a0\u8f7d</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#exp-exp_main","title":"<code>Exp = Exp_Main</code>","text":"<ul> <li>\u5728\u4e0a\u8282\u8bfe\u7684\u8bb2\u89e3\u4e2d\uff0c\u5df2\u7ecf\u8bb2\u7684\u90e8\u5206\u6709\u5982\u4f55\u8c03\u8bd5\u4f7f\u7528 shell \u811a\u672c\u8c03\u7528\u7684 python \u6587\u4ef6\uff0c\u4ecb\u7ecd\u4e86\u4e24\u79cd\u65b9\u6cd5\uff0c\u603b\u4e4b\u90fd\u662f\u4fee\u6539 launch.json\u6587\u4ef6\u3002</li> <li>\u7136\u540e\u4ecb\u7ecd\u4e86\u7c7b\u7684\u91cd\u547d\u540d <code>Exp = Exp_Main</code> \u3001\u4ece\u8fd9\u4e2a\u7c7b  <code>exp = Exp(args)</code>  \u7684\u521d\u59cb\u5316\uff0c\u6240\u6d89\u5230\u7684\u4e1c\u897f\u6709\uff0c\u7c7b\u7684\u7ee7\u627f <code>class Exp_Main(Exp_Basic)</code>\u3001\u5b50\u7c7b\u91cd\u5199\u7236\u7c7b\u7684\u65b9\u6cd5 <code>self.model = self._build_model().to(self.device)</code>  \uff0c\u5982\u679c \u5b50\u7c7b\u91cd\u5199\u90a3\u4e48\u4f18\u5148\u8c03\u7528\u5b50\u7c7b\u91cd\u5199\u7684\u65b9\u6cd5</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#segrnn-init","title":"SegRNN init","text":"<ul> <li>\u63a5\u7740\u4ecb\u7ecd\u4e86\uff0c\u5b57\u5178\u5b9a\u4e49\u7684\u901a\u8fc7\u5b57\u7b26\u4e32\u5b9e\u4f8b\u5316\u7c7b <code>'SegRNN': SegRNN</code> \uff0c\u8c03\u7528<code>.Model()</code>\u7c7b\u7684 init \u65b9\u6cd5 <code>model = model_dict[self.args.model].Model(self.args).float()</code></li> <li>init\u4e2d\u4e3b\u8981\u5b9e\u73b0\u7684\u662f SegRNN \u7684\u521d\u59cb\u5316\uff0c</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#revin","title":"RevIN","text":"<p>\u8fd9\u91cc\u60f3\u7740\u91cd\u8bf4\u660e\u7684\u662f  \u53ef\u9006\u5b9e\u4f8b\u6807\u51c6\u5316</p> Text Only<pre><code>self.revinLayer = RevIN(self.enc_in, affine=False, subtract_last=False)\n</code></pre> <p>\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\uff0c\u4f1a\u6d89\u53ca\u5230\u4e24\u79cd\u5f52\u4e00\u5316\uff0c\u4e00\u79cd\u662f\u5168\u5c40\u5f52\u4e00\u5316\uff0c\u4e00\u79cd\u662f\u5b9e\u4f8b\u5f52\u4e00\u5316\u3002</p> <p>\u5176\u5b9e\u5f52\u4e00\u5316\u7684\u8bf4\u6cd5\u4e5f\u4e0d\u662f\u5341\u5206\u51c6\u786e\uff0c\u56e0\u4e3a\u8fd9\u91cc\u7684\u5f52\u4e00\u5316\u90fd\u662f  \u51cf \\(\\mu\\) \u9664\u4ee5 \u6807\u51c6\u5dee \\(\\sigma\\) \uff0cNorm \u66f4\u51c6\u786e\u7684\u7406\u89e3\u7406\u89e3\u662f \u6807\u51c6\u5316\u3002\u4e0d\u8fc7\u5f71\u54cd\u4e0d\u5927\u3002</p> <ul> <li>\u5176\u4e2d\u5168\u5c40\u6807\u51c6\u5316\u4e3b\u8981\u7684\u4f5c\u7528\u662f \u6d88\u9664\u91cf\u7eb2\u7684\u5f71\u54cd\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e0d\u5212\u5206 batch \u7684\u6807\u51c6\u5316</li> <li>\u53ef\u9006\u5b9e\u4f8b\u6807\u51c6\u5316\u5c31\u662f\u5bf9\u8bad\u7ec3\u6837\u672c\u5185\u7684\u7279\u5f81\u8fdb\u884c\u5b9e\u4f8b\u6807\u51c6\u5316\uff0c\u76ee\u7684\u662f\u4e3a\u4e86==\u6d88\u9664\u5206\u5e03\u504f\u79fb==\uff0c\u7528\u4e00\u4e2a\u4f8b\u5b50\u6765\u89e3\u91ca\uff0c\u5c31\u662f\uff1a</li> </ul> <p></p> <p>\u597d\u5904\u662f\uff1a\u6d88\u9664\u7edd\u5bf9\u6c34\u5e73\u548c\u5c3a\u5ea6\u7684\u5f71\u54cd\uff0c\u8ba9\u6a21\u578b\u4e13\u6ce8\u4e8e\u5b66\u4e60\u5e8f\u5217\u7684==\u76f8\u5bf9\u53d8\u5316\u6a21\u5f0f==</p> <ul> <li>\u5bf9\u4e8e\u4e24\u6b21\u6807\u51c6\u5316\u66f4\u76f4\u89c2\u7684\u4f8b\u5b50\uff1a</li> </ul> <p></p> <p></p> <p></p> <ul> <li> <p>\u540c\u65f6\u987a\u7740 \u5b9e\u4f8b\u6807\u51c6\u5316\u7ed9\u5927\u5bb6\u8865\u5145\u4e86\u6279\u6807\u51c6\u5316\u3001\u5c42\u6807\u51c6\u5316\u3001\u5206\u7ec4\u6807\u51c6\u5316\uff0c\u4ece\u5206\u7ec4\u6807\u51c6\u5316\u53c8\u62d3\u5c55\u5230\u4e86\u5206\u7ec4\u5377\u79ef\uff0c\u4ece\u5206\u7ec4\u5377\u79ef\u53c8\u6269\u5c55\u4e86\u5377\u79ef\u7684\u51e0\u79cd\u65b9\u5f0f\uff0c\u81a8\u80c0\u5377\u79ef\u3001\u5206\u7ec4\u5377\u79ef\u3001\u8f6c\u7f6e\u5377\u79ef\u3001\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u3001\u9010\u70b9\u5377\u79ef\u7b49\uff0c\u7136\u540e\u56de\u5230\u6211\u4eec\u81ea\u5df1\u7684\u9879\u76ee</p> </li> <li> <p>\u5c06 SegRNN \u521d\u59cb\u5316\u597d\u7684\u6a21\u578b\uff0c\u4f20\u7ed9 model\uff0c\u5e76\u5728\u8c03\u8bd5\u63a7\u5236\u53f0\u6253\u5370\u4e86 model</p> </li> </ul> Text Only<pre><code>(valueEmbedding): Sequential(\n    (0): Linear(in_features=12, out_features=512, bias=True)\n    (1): ReLU()\n  )\n  (rnn): GRU(512, 512, batch_first=True)\n  (predict): Sequential(\n    (0): Dropout(p=0.0, inplace=False)\n    (1): Linear(in_features=512, out_features=12, bias=True)\n  )\n  (revinLayer): RevIN()\n)\n</code></pre> <ul> <li>\u53ef\u4ee5\u770b\u5230 SegRNN \u7684\u4e3b\u8981\u6784\u6210\u5305\u62ec\u4e00\u4e2a \u503c\u5d4c\u5165\u5c42\u3001RNN \u5c42\uff0c\u9884\u6d4b\u5c42\u548c \u53ef\u9006\u5b9e\u4f8b\u6807\u51c6\u5316\u5c42\u3002\u5728 forward \u4e2d\uff0c\u6570\u636e\u4f1a\u901a\u8fc7\u8fd9\u4e9b\u5c42\u8fdb\u884c\u6570\u636e\u6d41\u52a8</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#exptrainsetting","title":"<code>exp.train(setting)</code>","text":"<ul> <li>\u63a5\u4e0b\u6765\u8fdb\u884c\uff0c\u6a21\u578b\u7684\u8bad\u7ec3 <code>exp.train(setting)</code> \uff0c\u8c03\u7528\u7c7b\u7684 <code>.train</code>\u65b9\u6cd5\uff0c\u9996\u5148\u52a0\u8f7d\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\uff0c\u6570\u636e\u96c6\u52a0\u8f7d\u7684\u65b9\u5f0f\u662f\u4e00\u6837\u7684</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#self_get_data-data_provider","title":"<code>self._get_data \u2192 data_provider</code>","text":"<ul> <li> <p>\u4ee5\u8bad\u7ec3\u96c6\u4e3a\u4f8b <code>train_data, train_loader = self._get_data(flag='train')</code>\uff0c\u9996\u5148\u8c03\u7528\u5185\u90e8\u65b9\u6cd5 <code>self._getdata</code>\uff0c\u6b65\u8fdb\uff0c <code>data_set, data_loader = data_provider(self.args, flag)</code>\uff0c\u63a5\u7740\u8c03\u7528<code>data_provider</code> \u65b9\u6cd5\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u662f\u5728 py\u6587\u4ef6\u7684\u5f00\u5934\u8fdb\u884c\u5bfc\u5165\u7684 <code>from data_provider.data_factory import data_provider</code>\uff0c\u65b9\u6cd5\u7684\u4f4d\u7f6e\u5728 <code>data_provider</code> \u6587\u4ef6\u5939\u4e0b\uff0c<code>data_factory.py</code>\u6587\u4ef6\u4e2d\uff0c\u5b9a\u4e49\u7684 <code>data_provider</code> \u51fd\u6570\u3002</p> </li> <li> <p>\u7ee7\u7eed \u6b65\u8fdb\uff0c \u901a\u8fc7 <code>args.data</code> \u7d22\u5f15 \u6570\u636e\u5b57\u5178\uff0c\u5f97\u5230\u91cd\u547d\u540d\u4ee5\u540e\u7684\u7c7b\uff0c\u8fd9\u91cc\u4f20\u5165\u7684 <code>args.data = custom</code> \uff0c\u5728\u6570\u636e\u5b57\u5178\u4e2d \u7d22\u5f15\u5230\u7c7b\u662f <code>Dataset_Custom</code>\uff0c\u8fd9\u91cc\u60f3\u8bf4\u660e\u7684\u4e00\u70b9\u662f\uff0c\u5728\u8fd9\u4e2a\u9879\u76ee\u4e2d\u91cd\u5199\u4e86 pytorch \u5b98\u65b9 dataset \u7c7b\u7684 init \u65b9\u6cd5\u3001len \u65b9\u6cd5\u3001getitem \u65b9\u6cd5\uff0c\u4f7f\u5f97\u8fd9\u4e2a\u6570\u636e\u96c6\u7684\u52a0\u8f7d\u66f4\u9002\u5408\u5904\u7406 \u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u3002</p> </li> <li>\u63a5\u4e0b\u6765\u662f <code>timeenc = 0 if args.embed != 'timeF' else 1</code>  \u65f6\u95f4\u6233\u7684\u5efa\u6a21\u65b9\u6cd5\u3002\u540e\u9762\u4f1a\u6709\u5177\u4f53\u7684\u65f6\u95f4\u6233\u6570\u636e\u5efa\u6a21\u8fc7\u7a0b\u3002\u8fd9\u91cc\u7684 <code>timeenc=1</code></li> <li> <p>\u63a5\u7740\u6839\u636e\u4f20\u5165\u7684 flag \u8bbe\u7f6e\u4e00\u4e9b\u52a0\u8f7d\u6570\u636e\u96c6\u76f8\u5173\u7684\u53c2\u6570\uff0c\u5305\u62ec <code>shuffle_flag = True</code> \u662f\u5426\u968f\u673a\u9009\u53d6\u6837\u672c\u3001\u6700\u540e\u4e00\u7ec4\u6837\u672c\u5982\u679c\u6ca1\u6709\u6784\u6210\u4e00\u4e2a\u5b8c\u6210\u7684 batch \u65f6\u5019\u662f\u5426\u820d\u5f03 <code>drop_last = True</code>\u3001 <code>batch_size = args.batch_size</code> \u4e00\u4e2a batch\u7684\u5927\u5c0f\u3001\u4ee5\u53ca \u65f6\u95f4\u6233\u6570\u636e\u8bb0\u5f55\u9891\u7387 <code>freq = args.freq</code></p> </li> <li> <p>\u770b\u5230\u4e0b\u9762\u7684\u6e90\u4ee3\u7801\uff0c\u8fd9\u4e00\u90e8\u5206 \u6b65\u8fdb</p> </li> </ul> Text Only<pre><code>    data_set = Data(\n        root_path=args.root_path,\n        data_path=args.data_path,\n        flag=flag,\n        size=[args.seq_len, args.label_len, args.pred_len],\n        features=args.features,\n        target=args.target,\n        timeenc=timeenc,\n        freq=freq\n    )\n</code></pre>"},{"location":"Reproduction/5_SegRNN_v2/#dataset_custom","title":"<code>Dataset_Custom</code>","text":"<ul> <li>\u8fdb\u5165 <code>Dataset_Custom</code> \u4e2d\u7684 init \u65b9\u6cd5\uff0c\u52a0\u8f7d\u6570\u636e\uff0c\u9996\u5148\u53c8\u662f\u4e00\u4e9b\u53c2\u6570\u521d\u59cb\u5316</li> </ul> <ul> <li>\u5728\u8fd9\u4e2a\u8c03\u8bd5\u7684\u9879\u76ee\u4e2d\uff0c\u56de\u6eaf\u7a97\u53e3\u662f 60\uff0c\u9884\u6d4b\u7a97\u53e3\u662f 24\uff0c\u4e5f\u5c31\u662f\u4f7f\u7528\u672a\u6765 60 \u4e2a\u65f6\u95f4\u6b65\u76848 \u4e2a\u7279\u5f81\uff0c\u9884\u6d4b\u672a\u6765 24 \u4e2a\u65f6\u95f4\u6b65\u7684\u75be\u75c5\u611f\u67d3\u4eba\u6570\u3002</li> <li>\u5173\u4e8e\u8fd9\u91cc\u7684 8 \u4e2a\u7279\u5f81\uff0c\u60f3\u8bf4\u660e\u7684\u662f\uff08\u5176\u5b9e\u662f 1+7 \u4e2a\u7279\u5f81\uff0c\u65f6\u95f4\u6233\u7279\u5f81\u5355\u72ec\u5904\u7406\uff0c7 \u4e2a\u7279\u5f81\u7684\u5904\u7406\u5c31\u662f\u4e24\u4e2a\u6807\u51c6\u5316\uff0c\u4e00\u79cd\u662f\u5168\u5c40\u6807\u51c6\u5316\u4e00\u79cd\u662f\u5b9e\u4f8b\u6807\u51c6\u5316\uff09</li> <li>\u5728\u8fdb\u884c\u4e00\u4e9b\u53c2\u6570\u521d\u59cb\u5316\u4ee5\u540e\uff0c\u8c03\u7528 \u9b54\u65b9\u65b9\u6cd5<code>self.__read_data__()</code>\u8bfb\u53d6\u6570\u636e\u3002</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#self__read_data__","title":"<code>self.__read_data__()</code>","text":""},{"location":"Reproduction/5_SegRNN_v2/#selfscaler","title":"<code>self.scaler</code>","text":"<ul> <li>\u9996\u5148\u662f\u4e00\u4e2a\u5168\u5c40\u6807\u51c6\u5316\u5668 <code>self.scaler = StandardScaler()</code></li> <li>\u63a5\u7740\u6839\u636e\u4e0a\u9762\u521d\u59cb\u5316\u7684\u6587\u4ef6\u8def\u5f84\uff0c\u8bfb\u6570\u636e</li> </ul> Text Only<pre><code>       df_raw = pd.read_csv(os.path.join(self.root_path,\n                                          self.data_path))\n</code></pre>"},{"location":"Reproduction/5_SegRNN_v2/#_1","title":"\u5217\u91cd\u6392","text":"<ul> <li>\u7136\u540e\u8fdb\u884c\u5217\u91cd\u6392\uff0c\u53d8\u6210\u6807\u51c6\u7684 \u7b2c0 \u5217\u662f \u65e5\u671f\uff0c\u4e2d\u95f4\u662f\u7279\u5f81\uff0c\u6700\u540e\u4e00\u5217\u662f \u76ee\u6807\u5217</li> </ul> Text Only<pre><code>        cols = list(df_raw.columns)\n        cols.remove(self.target)\n        cols.remove('date')\n        df_raw = df_raw[['date'] + cols + [self.target]]\n</code></pre>"},{"location":"Reproduction/5_SegRNN_v2/#_2","title":"\u5212\u5206\u6570\u636e\u96c6","text":"<ul> <li>\u63a5\u4e0b\u6765\u6309\u7167 721 \u7684\u6bd4\u4f8b\u5212\u5206\u6570\u636e\u96c6\uff0c\u6d89\u53ca\u5230\u53d6\u6574\u64cd\u4f5c\uff0c\u4ee5\u53ca\u4e3a\u4e86\u9632\u6b62\u4e22\u5931\u65f6\u95f4\u6b65\uff0c\u9a8c\u8bc1\u96c6\u7684 10% \u662f\u7528\u7684\u51cf\u6cd5\u3002\u5177\u4f53\u7684\u6570\u503c\uff0c\u6574\u4e2a\u6570\u636e\u96c6\u662f 966 \u4e2a\u6570\u636e\u70b9\uff0c8 \u4e2a\u7279\u5f81\uff0c\u4e5f\u5c31\u662f 966\u00d78\uff0c\u6309\u7167 721 \u5212\u5206\uff0c\u5f97\u5230\uff0c\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\uff1a676\uff1b\u9a8c\u8bc1\u96c6\u65f6\u95f4\u6b65\uff1a97\uff1b\u6d4b\u8bd5\u96c6\u65f6\u95f4\u6b65\uff1a193 </li> </ul> Text Only<pre><code>        num_train = int(len(df_raw) * 0.7)\n        num_test = int(len(df_raw) * 0.2)\n        num_vali = len(df_raw) - num_train - num_test\n</code></pre>"},{"location":"Reproduction/5_SegRNN_v2/#border1sborder2s","title":"<code>border1s&amp;border2s</code>","text":"<ul> <li>\u63a5\u4e0b\u6765</li> </ul> Text Only<pre><code>        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n        border2s = [num_train, num_train + num_vali, len(df_raw)]\n</code></pre> <ul> <li>border1s \u548c border2s \u5206\u522b\u5b9a\u4e49\u4e86\u6d4b\u8bd5\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u8bad\u7ec3\u96c6\u7684\u5de6\u53f3\u8fb9\u754c\u3002</li> <li>\u539f\u6587\u7684\u65f6\u95f4\u6b65\u5212\u5206\uff0c\u5e94\u8be5\u662f \u6570\u636e\u884c0-676\u662f\u8bad\u7ec3\u96c6\uff0c676 \u5230 676+97=773 \u662f\u9a8c\u8bc1\u96c6\uff0c966-193=773 \uff0c\u4e5f\u5c31\u662f\u7d22\u5f15 773-966\u662f\u6d4b\u8bd5\u96c6\uff0c\u7528\u56fe\u6765\u8868\u793a\uff0c\u5c31\u662f\u8fd9\u6837\u7684\uff1a  </li> </ul> <ul> <li> <p>\u4f46\u5b9e\u9645\u4e0a\u770b\uff0c\u5de6\u53f3\u8fb9\u754c\u7684\u5b9a\u4e49\uff0c\u5de6\u8fb9\u754c\u90fd\u51cf\u53bb\u4e86\u4e00\u4e2a \u56de\u6eaf\u7a97\u53e3\u957f\u5ea6\uff0c\u4e5f\u5c31\u662f <code>self.seq_len = 60</code> </p> </li> <li> <p>\u4e5f\u5c31\u662f </p> </li> </ul> <p>\u7528\u56fe\u6765\u8868\u793a\u5c31\u662f\uff1a</p> <p></p> <p>\uff081\uff09\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\u662f\u524d0-676 \u4e2a\u65f6\u95f4\u70b9</p> <p>\uff082\uff09\u9a8c\u8bc1\u96c6\u662f 616 \u5230 773 \u4e2a\u65f6\u95f4\u70b9</p> <p>\uff083\uff09\u6d4b\u8bd5\u96c6\u662f713 \u5230 966 \u4e2a\u65f6\u95f4\u6b65</p> <ul> <li>\u4e3a\u4ec0\u4e48\u662f\u8fd9\u6837\u7684\u5462\uff1f</li> </ul> <p>\u8fd9\u6837\u505a\u7684\u610f\u4e49\u662f\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u6bcf\u4e2a\u6837\u672c\u90fd\u6709 60 \u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u5e8f\u5217\u548c 24 \u4e2a\u65f6\u95f4\u6b65\u7684\u9884\u6d4b\u76ee\u6807\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u4e8e\u9a8c\u8bc1\u96c6\u7684\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\uff0c\u5982\u679c\u8ba9\u5b83\u6784\u6210\u4e00\u4e2a\u5b8c\u6210\u7684\u6837\u672c\uff0c\u5c31\u9700\u8981\u5411\u524d\u56de\u9000 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u540c\u6837\u5bf9\u4e8e\u6d4b\u8bd5\u96c6\u7684\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u6765\u8bf4\uff0c\u8ba9\u5b83\u6784\u6210\u4e00\u4e2a\u6837\u672c\uff0c\u4e5f\u9700\u8981\u56de\u9000 60 \u4e2a\u65f6\u95f4\u6b65\u3002</p> <ul> <li>\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b9e\u9645\u4e0a\uff0c </li> </ul> <p>\uff081\uff09\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\u6709 \\(676\\) \u4e2a</p> <p>\uff082\uff09\u9a8c\u8bc1\u96c6\u65f6\u95f4\u6b65\u6709 $773-616=157 $\u4e2a\uff0c\u6216\u8005\u5c31\u662f \\(97+60=157\\) \u4e2a\u65f6\u95f4\u6b65\uff1b</p> <p>\uff083\uff09\u6d4b\u8bd5\u96c6 \u6709 \\(253\\) \u4e2a\u65f6\u95f4\u6b65\uff0c\u5c31\u662f <code>len(df_raw)</code> - <code>len(df_raw) - num_test - self.seq_len</code>\u3002\\(193+60=253\\) </p> <p>\u4ee5\u4e0a\uff0c\u89e3\u91ca\u597d\u5b9e\u9645\u7528\u7684\u5de6\u53f3\u8fb9\u754c\u4ee5\u540e\uff0c</p> <p>\u63a5\u4e0b\u6765\u7ee7\u7eed\u770b\u6e90\u4ee3\u7801</p>"},{"location":"Reproduction/5_SegRNN_v2/#border1border2","title":"border1&amp;border2","text":"Text Only<pre><code>       border1 = border1s[self.set_type]\n       border2 = border2s[self.set_type]\n</code></pre> <ul> <li>\u8fd9\u4e2a border1\u548cborder2\u5c31\u662f\u4fdd\u5b58\u5355\u4e2a\u6570\u636e\u96c6\u7684\u5de6\u53f3\u8fb9\u754c\uff0c\u6bd4\u5982\u73b0\u5728\u6211\u4eec\u4f20\u8fdb\u6765\u7684 <code>flag=train</code></li> <li>\u6839\u636e\u524d\u9762\u521d\u59cb\u5316\u9636\u6bb5\u5b9a\u4e49\u7684 \u6570\u636e\u96c6\u7c7b\u578b\u6620\u5c04\u5b57\u5178  <code>type_map = {'train': 0, 'val': 1, 'test': 2}</code> \u7136\u540e\u7528\u5b57\u7b26\u4e32 <code>flag=train</code>\u7d22\u5f15\u5230 <code>self.set_type = type_map[flag]=0</code></li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#selffeatures","title":"self.features","text":"Text Only<pre><code>        if self.features == 'M' or self.features == 'MS':\n            cols_data = df_raw.columns[1:]\n            df_data = df_raw[cols_data]\n        elif self.features == 'S':\n            df_data = df_raw[[self.target]]\n</code></pre> <ul> <li> <p>\u7ee7\u7eed\u770b\u6e90\u4ee3\u7801\uff0c\u5230 self.feature\u7684\u90e8\u5206</p> </li> <li> <p>\u8fd9\u91cc\u662f\u8bf4 \u65f6\u95f4\u5e8f\u5217\u76843 \u79cd\u4efb\u52a1\uff0c\u591a\u53d8\u91cf\u9884\u6d4b\u591a\u53d8\u91cf\uff0c\u591a\u53d8\u91cf\u9884\u6d4b\u5355\u53d8\u91cf\uff0c\u5355\u53d8\u91cf\u9884\u6d4b\u5355\u53d8\u91cf</p> </li> <li> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u8fd9\u91cc\u60f3\u989d\u5916\u8bf4\u660e\u7684\u4e00\u70b9\u662f\uff0c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u6211\u4eec\u65e5\u671f\u7279\u5f81\u7684\u63d0\u53d6\u662f\u901a\u8fc7 \u504f\u79fb\u6765\u5904\u7406\u7684\uff0c\u8fd9\u4e2a\u6211\u4eec\u540e\u9762\u4f1a\u8bf4\uff0c\u5bf9\u5e94\u5230\u4ee3\u7801\u4e2d\u53ef\u4ee5\u770b\u5230 \u5728\u4f7f\u7528\u591a\u53d8\u91cf\u7684\u65f6\u5019\uff0c\u90fd\u662f\u4e0d\u62ff\u7b2c 0 \u5217\u7279\u5f81\u7684\uff0c\u56e0\u4e3a\u65e5\u671f\u6211\u4eec\u7b49\u4f1a\u5904\u7406\u3002</p> </li> </ul> <ol> <li><code>M</code> (\u591a\u53d8\u91cf/Multiple variables)\uff1a    - \u5f53 self.features == 'M' \u65f6\uff0c\u4ee3\u7801\u9009\u62e9\u9664\u7b2c\u4e00\u5217\uff08\u901a\u5e38\u662f\u65e5\u671f\u5217\uff09\u5916\u7684\u6240\u6709\u5217\u4f5c\u4e3a\u7279\u5f81    - cols_data = df_raw.columns[1:]\u83b7\u53d6\u9664\u7b2c\u4e00\u5217\u5916\u7684\u6240\u6709\u5217\u540d    - df_data = df_raw[cols_data] \u9009\u62e9\u8fd9\u4e9b\u5217\u4f5c\u4e3a\u6a21\u578b\u8f93\u5165\u6570\u636e</li> <li><code>MS</code> (\u591a\u53d8\u91cf\u5230\u5355\u53d8\u91cf\u9884\u6d4b/Multiple to Single)\uff1a    - \u4e0e <code>M</code> \u6a21\u5f0f\u76f8\u540c\u7684\u6570\u636e\u9009\u62e9\u65b9\u5f0f    - \u4f7f\u7528\u6240\u6709\u7279\u5f81\u5217\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f46\u4e3b\u8981\u76ee\u7684\u662f\u9884\u6d4b\u76ee\u6807\u53d8\u91cf</li> <li><code>S</code> (\u5355\u53d8\u91cf/Single variable)\uff1a    - \u5f53 self.features == 'S' \u65f6\uff0c\u53ea\u9009\u62e9\u76ee\u6807\u5217\u4f5c\u4e3a\u7279\u5f81    - df_data = df_raw[[self.target]]\u4ec5\u9009\u62e9\u7531 self.target\u6307\u5b9a\u7684\u5217</li> </ol> <ul> <li>\u4e3e\u4e2a\u5b9e\u9645\u7684\u4f8b\u5b50\uff0c\u6765\u8bf4\u660e\u8fd9\u4e09\u79cd\u9884\u6d4b\uff1a</li> </ul> <p>\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u7535\u529b\u6d88\u8017\u6570\u636e\u96c6\uff0c\u5305\u542b\u5982\u4e0b\u5217\uff1a</p> <p>[date,HUFL, HULL, MUFL, MULL, LUFL, LULL, OT]</p> <p>date \u8868\u793a\u65f6\u95f4\u6233 \u653e\u5230\u7b2c\u4e00\u5217\uff0c\u76ee\u6807\u5217OT \u653e\u5230\u6700\u540e\u4e00\u5217\uff0c\u8fd9\u662f\u6211\u4eec\u5217\u91cd\u6392\u7684\u7ed3\u679c</p> <p>\u5982\u679c\u6211\u4eec\u8bbe\u7f6e\uff1a</p> <ol> <li>self.features = 'M'\uff1a    - \u6240\u6709\u5217\uff08\u9664\u4e86 date\u90fd\u4f1a\u88ab\u9009\u4e2d\uff1a<code>OT, HUFL, HULL, MUFL, MULL, LUFL, LULL</code>    - \u6a21\u578b\u5c06\u4f7f\u7528\u6240\u6709\u8fd9\u4e9b\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3\u548c\u9884\u6d4b</li> <li><code>self.features = 'MS'</code>\uff1a    - \u540c\u6837\u9009\u62e9\u6240\u6709\u5217\uff08\u9664\u4e86 <code>date</code>\uff09\uff1a<code>OT, HUFL, HULL, MUFL, MULL, LUFL, LULL</code>    - \u901a\u5e38\u7528\u4e8e\u5229\u7528\u591a\u4e2a\u7279\u5f81\u6765\u9884\u6d4b\u76ee\u6807\u53d8\u91cf</li> <li><code>self.features = 'S'</code> \u4e14 <code>self.target = 'OT'</code>\uff1a    - \u53ea\u9009\u62e9 <code>OT</code> \u5217    - \u6a21\u578b\u5c06\u53ea\u4f7f\u7528\u6cb9\u6e29\u5386\u53f2\u6570\u636e\u6765\u9884\u6d4b\u672a\u6765\u6cb9\u6e29\u503c\uff0c\u4e0d\u8003\u8651\u5176\u4ed6\u53d8\u91cf</li> </ol>"},{"location":"Reproduction/5_SegRNN_v2/#selfscale","title":"self.scale","text":"<ul> <li>\u63a5\u4e0b\u6765\u770b\u5230\u6e90\u4ee3\u7801\u7684\u5168\u5c40\u6807\u51c6\u5316\u90e8\u5206\uff1a</li> </ul> Text Only<pre><code>        if self.scale:\n            train_data = df_data[border1s[0]:border2s[0]]\n            self.scaler.fit(train_data.values)\n            # print(self.scaler.mean_)\n            # exit()\n            data = self.scaler.transform(df_data.values)\n        else:\n            data = df_data.values\n</code></pre> <ul> <li> <p>\u8fd8\u8bb0\u5f97\u6211\u4eec\u521a\u5f00\u59cb\u5b9a\u4e49\u7684 <code>self.scaler = StandardScaler()</code> \u5168\u5c40\u6570\u636e\u6807\u51c6\u5316\u5668\u561b</p> </li> <li> <p>\u73b0\u5728\u5f00\u59cb\u62df\u5408\uff0c\u6ce8\u610f\u8fd9\u91cc\u62df\u5408\u7684\u65f6\u5019\uff0c\u53ea\u7528\u7684\u662f\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u62df\u5408\uff0c\u56e0\u4e3a\u5728\u771f\u5b9e\u60c5\u51b5\u4e2d \u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u662f\u89c2\u6d4b\u4e0d\u5230\u7684\uff0c\u6240\u4ee5\u8fd9\u91cc\u7684\u6267\u884c\u903b\u8f91\u5c31\u662f\uff0c\u5148\u62ff\u51fa \u8bad\u7ec3\u96c6\u6570\u636e\uff0c\u7136\u540e\u7528\u8bad\u7ec3\u96c6\u6570\u636e\u62df\u5408 \u6807\u51c6\u5316\u5668\uff0c\u7136\u540e\u7528\u62df\u5408\u597d\u7684\u6807\u51c6\u5316\u5668\u6765\u6807\u51c6\u5316\u5168\u5c40\u6570\u636e\u3002</p> </li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#df_stamp","title":"df_stamp","text":"<ul> <li>\u63a5\u4e0b\u6765\u662f\u65f6\u95f4\u6233\u7279\u5f81\u7684\u5904\u7406\uff1a</li> </ul> Text Only<pre><code>        df_stamp = df_raw[['date']][border1:border2]\n        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n</code></pre> <ul> <li>\u770b\u5230 <code>df_stamp = df_raw[['date']][border1:border2]</code>  \u7ec8\u4e8e\u7528\u5230\u4e86\u6211\u4eec\u7684 border1\uff0cborder2\uff0c\u5c31\u662f\u5904\u7406\u6211\u4eec\u73b0\u5728\u60f3\u5904\u7406\u7684\u6570\u636e\u96c6\u4e86\uff0c\u9996\u5148\u5c06\u6211\u4eec\u5148\u5904\u7406\u7684 \u6570\u636e\u96c6\u65f6\u95f4\u6233\u62ff\u51fa\u6765\uff0c\u4f20\u7ed9 <code>df_stamp</code> </li> <li><code>df_stamp['date'] = pd.to_datetime(df_stamp.date)</code> \u8c03\u7528 pandas \u5c06\u65e5\u671f\u6570\u636e\u8f6c\u6362\u6210\u6807\u51c6\u7684\u65f6\u95f4\u65e5\u671f\u6570\u636e</li> <li>\u5728\u6267\u884c\u5b8c\u8fd9\u4e00\u53e5\u540e\uff0c\u770b\u5230\u8c03\u8bd5\u7a97\u53e3\uff0c\u9f20\u6807\u60ac\u505c\uff0c\u67e5\u770b \u65f6\u95f4\u6233\u6570\u636e\u6846\u6570\u636e <code>df_stamp</code></li> </ul> Text Only<pre><code>if self.timeenc == 0:\n            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n            data_stamp = df_stamp.drop(['date'], 1).values\n        elif self.timeenc == 1:\n            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n            data_stamp = data_stamp.transpose(1, 0)\n</code></pre> <ul> <li>\u65f6\u95f4\u6233\u7279\u5f81\u7684\u5efa\u6a21\uff0c\u6211\u4eec\u8fd9\u91cc <code>self.timeenc = 1</code>\uff0c\u6240\u4ee5\u6267\u884c <code>elif</code></li> </ul> Text Only<pre><code>data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n</code></pre> <ul> <li>\u8fd9\u91cc\u7684\u65f6\u95f4\u6233\u7279\u5f81\u5efa\u6a21 \u53c8\u8c03\u7528\u4e86 \u81ea\u5b9a\u4e49\u7684\u51fd\u6570  <code>time_features</code>\uff0c</li> <li>\u9700\u8981\u7684\u53c2\u6570\u6709 \u65f6\u95f4\u6233\u6570\u636e\u6846 \uff0c\u4e5f\u5c31\u662f <code>pd.to_datetime(df_stamp['date'].values)</code>\uff0c</li> <li>\u8fd8\u6709 \u65f6\u95f4\u6233\u6570\u636e\u8bb0\u5f55\u5468\u671f <code>freq=self.freq</code>\uff0c\u65f6\u95f4\u6233\u6570\u636e\u6846\u662f\u6211\u4eec\u4e0a\u9762\u62ff\u5230\u7684\uff0c</li> <li>\u8fd9\u91cc\u7684 \u65f6\u95f4\u6233\u6570\u636e\u8bb0\u5f55\u9891\u7387 <code>freq=self.freq=\"H\"</code> \uff0c\u4f20\u8fdb\u6765\u7684\u53c2\u6570\u662f \"H\"\uff0c\u4f46\u5176\u5b9e\u5bf9\u4e8e\u8fd9\u4e2a\u75be\u75c5\u6570\u636e\u96c6\u6765\u8bf4\uff0c\u65f6\u95f4\u6233\u5468\u671f\u662f \u5468\uff0c\u6709\u70b9\u5c0f\u95ee\u9898\uff0c\u4f46\u5f71\u54cd\u4e0d\u5927\u3002</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#time_features","title":"time_features","text":"<p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec \u6b65\u8fdb \uff0c\u770b\u8fd9\u4e2a\u65f6\u95f4\u6233\u6570\u636e\u662f\u600e\u4e48\u5efa\u6a21\u7684\u3002</p> <p></p> <ul> <li>\u770b\u5230\u53c8\u662f\u4e00\u4e2a\u8c03\u7528\uff0c\u7ee7\u7eed==\u6b65\u8fdb==\uff0c\u800c\u4e14\u662f==\u540c\u6587\u4ef6\u7684 \u8c03\u7528==\u3002</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#time_features_from_frequency_str","title":"<code>time_features_from_frequency_str</code>","text":"<ul> <li>\u6b65\u8fdb \u5230 <code>time_features_from_frequency_str</code> \u51fd\u6570\u5185\u90e8\uff0c\u9996\u5148\u6709\u4e00\u4e2a \u7279\u5f81\u504f\u79fb\u5b57\u5178</li> </ul> <ul> <li>\u6765\u5230\u4e0b\u9762\u8fd9\u884c\uff1a</li> </ul> <ul> <li>\u6839\u636e\u7ed9\u5b9a\u7684\u65f6\u95f4\u9891\u7387\u5b57\u7b26\u4e32\u9009\u62e9\u5408\u9002\u7684\u65f6\u95f4\u7279\u5f81</li> <li>\u6211\u4eec\u5148\u770b\u4e00\u4e0b\u8c03\u8bd5\u7a97\u53e3\u8fd9\u91cc\uff0c<code>&lt;built-in function to_offset&gt;</code> \u8868\u793a\u7684\u662f\u6307\u5411 Pandas \u5e93\u4e2d to_offset\u51fd\u6570\u7684\u5f15\u7528\u3002\uff08\u4e5f\u5c31\u662f \u5185\u7f6e\u51fd\u6570\uff09</li> </ul> <ul> <li><code>to_offset</code> \u662f Pandas \u4e2d\u7684\u51fd\u6570\uff0c\u7528\u4e8e\u5c06\u9891\u7387\u5b57\u7b26\u4e32\uff08\u5982 'H'\u3001'D'\u3001'W' \u7b49\uff09\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684\u504f\u79fb\u5bf9\u8c61</li> <li>\u6bd4\u5982\u6211\u4eec\u8fd9\u91cc\uff0c'H' \u8f6c\u6362\u4e3a  Hour  \u504f\u79fb\u5bf9\u8c61\uff0c</li> </ul> <ul> <li>\u8fd9\u6bb5 for \u5faa\u73af\u7684\u4f5c\u7528\u5c31\u662f\u6839\u636e \u8f93\u5165\u7684 <code>freq_str</code>  \u4e5f\u5c31\u662f\u9891\u7387\u5b57\u7b26\u4e32\uff0c\u53bb<code>\u504f\u79fb\u7279\u5f81\u5b57\u5178</code>\u4e2d \u7d22\u5f15\u5230\u7279\u5f81\u7c7b\u5217\u8868\uff0c\u6700\u7ec8\u8fd4\u56de\u7c7b\u7684\u5b9e\u4f8b</li> <li>**\u5177\u4f53\u6765\u8bf4\uff0c**\u5c31\u662f\u9996\u5148 <code>offset = to_offset(freq_str)</code>   \u6839\u636e\u4f20\u5165\u7684 <code>'H'</code> \u5b57\u7b26\u4e32\u5f97\u5230 <code>&lt;Hour&gt;</code> \u5bf9\u8c61 </li> <li>\u7136\u540e\u904d\u5386\u904d\u5386\u5b57\u5178\u7684 \u952e \u548c \u503c\uff0c\u5982\u679c offset \u4e5f\u5c31\u662f\u6211\u4eec\u5f97\u5230\u7684 <code>&lt;Hour&gt;</code> \u5bf9\u8c61\u662f\u904d\u5386\u5f97\u5230\u7684 <code>offset_type</code>\uff0c\u4e5f\u5c31\u662f \u5b57\u5178\u7684\u952e\uff0c\u7684\u5b9e\u4f8b\uff0c\u90a3\u4e48\u5bf9\u5e94\u7684\u5b57\u5178\u7684 \u503c \uff0c<code>feature_classes</code> \u5c31\u901a\u8fc7\u4e00\u4e2a\u5217\u8868\u63a8\u5bfc\u5f0f\uff0c\u5bf9\u5f97\u5230\u7684\u7c7b\u4f1a\u52a0\u4e00\u4e2a\u62ec\u53f7 <code>cls()</code> ,\u8868\u793a\u8fd4\u56de\u7c7b\u7684\u5b9e\u4f8b\u3002</li> <li>**\u518d\u4ed4\u7ec6\u91cd\u590d\u4e00\u904d\uff0c**\u5c31\u662f <code>to_offset('H')</code>\u8fd4\u56de\u7684\u662f\u4e00\u4e2a <code>&lt;Hour&gt;</code>\u5bf9\u8c61</li> <li>for\u5faa\u73af\u904d\u5386\u5b57\u5178\u65f6\uff0c\u4f1a\u53d1\u73b0\u8fd9\u4e2a\u5bf9\u8c61\u662f <code>offsets.Hour</code> \u7684\u5b9e\u4f8b</li> <li>\u4ece\u5b57\u5178\u4e2d\u67e5\u627e\u5bf9\u5e94 <code>offsets.Hour</code>\u7684\u7279\u5f81\u7c7b\u5217\u8868\uff1a<code>[HourOfDay, DayOfWeek, DayOfMonth, DayOfYear]</code> </li> <li>\u8fd4\u56de\u8fd9\u4e9b\u7c7b\u7684\u5b9e\u4f8b\u5217\u8868\uff1a<code>[HourOfDay(), DayOfWeek(), DayOfMonth(), DayOfYear()]</code></li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#time_feature","title":"\u8fd4\u56de time_feature","text":"<p>\u63a5\u4e0b\u6765\uff0c\u7ee7\u7eed\u770b  <code>np.vstack</code>  \u8fd9\u4e00\u884c\uff0c</p> <p></p> <ul> <li> <p>\u9996\u5148\uff0c<code>time_features_from_frequency_str(freq)</code> \u8fd4\u56de\u7684\u662f <code>[HourOfDay(), DayOfWeek(), DayOfMonth(), DayOfYear()]</code></p> </li> <li> <p>\u7136\u540e\uff0c\u6839\u636e\u5f97\u5230\u7684  <code>[HourOfDay(), DayOfWeek(), DayOfMonth(), DayOfYear()]</code> \u5bf9\u4f20\u5165\u7684 <code>dates</code> \u8fdb\u884c\u5904\u7406</p> </li> <li>\u9996\u5148\u6211\u4eec\u4f20\u5165\u7684 dates\uff0c\u662f\u6807\u51c6\u7684\u65e5\u671f\uff0cpandas \u4f1a\u81ea\u52a8\u89e3\u6790\u51fa \u5e74\u3001\u6708\u3001\u65e5\u3001\u5c0f\u65f6\uff0c\u56e0\u4e3a\u5168\u662f 0 \u70b9\uff0c\u6240\u4ee5\u7701\u7565\u4e86\u3002</li> </ul> <p></p> <ul> <li>\u5177\u4f53\u6765\u8bf4\u7684\u5904\u7406\u662f\uff1a</li> </ul> <p></p> <ul> <li>\u70b9\u51fb\u6b65\u8fdb \uff0c\u53ef\u4ee5\u770b\u5230 <code>index.day</code>\uff0c\u81ea\u52a8\u6458\u51fa\u6240\u6709\u7684\u65e5\u671f\uff0c\u8fd9\u91cc\u7684\u7684\u5904\u7406\u662f -1 /30 \u662f\u4e3a\u4e86\u5f52\u4e00\u5316\uff0c\u56e0\u4e3a\u6211\u4eec\u7684\u65e5\u671f\u8bb0\u53f7\u4e3a 1 \u53f7\u5230 31 \u53f7\uff0c\u5bf9\u65e5\u671f\u51cf1\uff0c\u53d8\u6210 0~30\uff0c\u00f730\uff0c\u53d8\u6210 0~1\uff0c\uff0d0.5 \u8868\u793a \u4e2d\u5fc3\u5316\uff0c\u6700\u7ec8\u7684\u6570\u636e\u8303\u56f4\u662f <code>-0.5~0.5</code></li> </ul> <p></p> <ul> <li>HourOfDay()\uff1a\u8868\u793a \u4e00\u5929\u4e2d\u7684\u7b2c\u51e0\u4e2a\u5c0f\u65f6</li> <li>DayOfWeek()\uff1a\u8868\u793a\u4e00\u5468\u4e2d\u7684\u661f\u671f\u51e0</li> <li>DayOfMonth()\uff1a\u8868\u793a\u4e00\u4e2a\u6708\u4e2d\u7684\u7b2c\u51e0\u5929</li> <li>DayOfYear()\uff1a\u8868\u793a\u4e00\u5e74\u4e2d\u7684\u7b2c\u51e0\u5929</li> </ul> <p>\u5904\u7406\u903b\u8f91\u90fd\u662f\u5dee\u4e0d\u591a\u7684\uff0c\u90fd\u4e2d\u5fc3\u5316\u4e3a <code>-0.5~0.5</code></p> <p>\u8fd4\u56de\u7684\u5f62\u72b6\u662f <code>[\u7279\u5f81\u6570, \u65e5\u671f\u6570]</code> \u4e5f\u5c31\u662f <code>4 \u00d7 676</code></p>"},{"location":"Reproduction/5_SegRNN_v2/#data_stamp","title":"\u8fd4\u56de  <code>data_stamp</code>","text":"<p>\u8fd9\u91cc np.vstack \u5806\u53e0\u7684\u662f \u5217\u8868\uff0c\u6240\u4ee5\u662f 4 \u884c 676 \u5217\uff0c\u5bf9\u5e94\u7684\u540e\u9762\u662f\uff0c\u6709\u4e00\u4e2a  transpose \u64cd\u4f5c\uff0c<code>data_stamp = data_stamp.transpose(1, 0)</code> \uff0c\u53d8\u6210 <code>676 \u00d74</code> \u7684\u683c\u5f0f</p> <ul> <li>\u6700\u7ec8\u5f97\u5230\u7684\u6570\u636e\u548c\u5f62\u72b6\uff1a</li> </ul> <p></p>"},{"location":"Reproduction/5_SegRNN_v2/#_3","title":"\u603b\u7ed3","text":"<ul> <li>\u7ecf\u8fc7\u4ee5\u4e0a\u8fd9\u4e00\u5927\u4e32\uff0c\u7ec8\u4e8e\u5b8c\u6210\u4e86 <code>\u81ea\u5b9a\u4e49Dataset\u7c7b</code>\u7684\u521d\u59cb\u5316 <code>Dataset_Custom(Dataset)</code>\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f\u8c03\u7528\u4e86 <code>init</code> \u65b9\u6cd5\uff0c\u540c\u65f6 <code>init</code> \u65b9\u6cd5\u4e2d\uff0c\u53c8\u8c03\u7528\u4e86 <code>read_data\u65b9\u6cd5</code></li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#data_provider","title":"\u8fd4\u56de data_provider\u51fd\u6570","text":"<ul> <li>\u63a5\u4e0b\u6765\u56de\u5230\u8fd9\u91cc\uff1a</li> </ul> Text Only<pre><code>print(flag, len(data_set))\n</code></pre> <ul> <li>\u6253\u5370\u8bad\u7ec3\u6570\u636e\u96c6\u6837\u672c\u6570\u3002\u70b9\u51fb\u6b65\u8fdb\uff0c\u8c03\u7528\u91cd\u5199\u7684 len \u51fd\u6570</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#len","title":"\u8c03\u7528 len","text":"<ul> <li>\u524d\u9762\u6211\u4eec\u5173\u4e8e\u8fd9\u4e2a\u65f6\u95f4\u6b65\u7684\u53d8\u5316\u6709</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#1","title":"\uff081\uff09\u7b2c\u4e00\u6b65","text":"<p>721 \u5212\u5206\u6570\u636e\u96c6\uff0c\u5f97\u5230\u8fd9\u5f20\u56fe\uff1a</p> <p></p> <p>\u4e5f\u5c31\u662f\u8bf4\u7406\u8bba\u4e0a\uff0c\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\uff1a676\uff1b\u9a8c\u8bc1\u96c6\u65f6\u95f4\u6b65\uff1a97\uff1b\u6d4b\u8bd5\u96c6\u65f6\u95f4\u6b65\uff1a193</p>"},{"location":"Reproduction/5_SegRNN_v2/#2","title":"\uff082\uff09\u7b2c\u4e8c\u6b65","text":"<p>\u4e3a\u4e86\u4fdd\u8bc1\u9a8c\u8bc1\u96c6\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u548c\u6d4b\u8bd5\u96c6\u7684\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u53ef\u4ee5\u6784\u6210\u4e00\u4e2a\u6837\u672c\uff0c\u56de\u6eaf\u4e86 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u5f97\u5230\uff1a</p> <p></p> <p>\u4f46\u5b9e\u9645\u4e0a\u4f7f\u7528\u7684\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\u6709 676 \u4e2a\uff1b\u9a8c\u8bc1\u96c6\u65f6\u95f4\u6b65157 \u4e2a\uff1b\u6d4b\u8bd5\u96c6\u65f6\u95f4\u6b65\u6709 253 \u4e2a </p>"},{"location":"Reproduction/5_SegRNN_v2/#3","title":"\uff083\uff09\u7b2c\u4e09\u6b65","text":"<p>\u63a5\u4e0b\u6765\u662f\u5c31\u662f\u8fd9\u4e48\u4e9b\u4e2a\u65f6\u95f4\u6b65\u80fd\u6784\u6210\u591a\u5c11\u4e2a\u6837\u672c\uff1f</p> <ul> <li>\u4e00\u4e2a\u5b8c\u6574\u7684\u6837\u672c\uff0c\u5e94\u8be5\u662f\u5305\u542b 60 \u4e2a\u5386\u53f2\u8f93\u5165\u5e8f\u5217\u548c\u7d27\u968f\u5176\u540e\u7684 24 \u4e2a\u9884\u6d4b\u65f6\u95f4\u6b65\uff0c\u8fd9\u6837\u5c01\u88c5\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u6837\u672c\uff0c\u5e76\u4e14\u6837\u672c\u7684\u5f00\u59cb\u7d22\u5f15\u662f\u968f\u673a\u7684\uff0c\u4fdd\u8bc1\u6a21\u578b\u8bad\u7ec3\u4e0d\u4f1a\u4f9d\u8d56\u65f6\u95f4\u6b65\u5f00\u59cb\u7684\u987a\u5e8f\u3002</li> </ul>"},{"location":"Reproduction/5_SegRNN_v2/#len_1","title":"\u7ee7\u7eed len","text":"<ul> <li>\u770b\u5230\u6e90\u7801\uff0c\u6837\u672c\u7684\u8ba1\u7b97\uff1a</li> </ul> Text Only<pre><code>   def __len__(self):\n        return len(self.data_x) - self.seq_len - self.pred_len + 1\n</code></pre> <ul> <li>\u9996\u5148  \u8fd9\u4e2a <code>self.data_x</code> \u662f\u600e\u4e48\u6765\u7684\uff1a  <code>self.data_x = data[border1:border2]</code>\uff0c\u901a\u8fc7 border1 \u548c border2 \u7d22\u5f15\u6765\u7684</li> <li>\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u4e8e\u8bad\u7ec3\u96c6\u7684 676 \u4e2a\u65f6\u95f4\u6b65\uff0c\u9a8c\u8bc1\u96c6 157 \u4e2a\u65f6\u95f4\u6b65\uff0c\u6d4b\u8bd5\u96c6 253 \u4e2a\u65f6\u95f4\u6b65\uff0c\u4e5f\u5c31\u662f\u5206\u522b\u5bf9\u5e94\u7740 \u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u7684 <code>len(self.data_x)</code> </li> <li>\u6240\u4ee5\uff0clen(\u8bad\u7ec3\u96c6)\u3001len(\u9a8c\u8bc1\u96c6)\u3001len(\u6d4b\u8bd5\u96c6) \u7684\u4e5f\u5c31\u662f==\u6837\u672c\u6570== \u5206\u522b\u662f <code>676-60-24+1=593 \u3001157-60-24+1=74\u3001253-60-24+1=170</code> \u4e2a\u6837\u672c\u3002</li> </ul> <p>\u6267\u884c\u5b8c\u4ee5\u540e\uff0c\u7ec8\u7aef\u8f93\u51fa\u8bad\u7ec3\u96c6\u6837\u672c\u6570\uff1a</p> <p></p> <p>\u6211\u8bb0\u5f97\u6211\u6700\u5f00\u59cb\u770b\u8fd9\u4e2a\u7684\u65f6\u5019\uff0c\u6211\u4f1a\u6709\u4e00\u4e2a\u7591\u95ee\u5c31\u662f\u7d22\u5f15\u4f1a\u4e0d\u4f1a\u8d85\u51fa\u8303\u56f4\uff1f  \u6240\u4ee5\u8fd9\u91cc\u60f3\u7740\u91cd\u8bf4\u4e00\u4e0b\u8fd9\u4e2a\u95ee\u9898</p> <p>\u5176\u5b9e\u662f\u4e0d\u4f1a\u7684\u3002</p> <p>\u9996\u5148\u8bad\u7ec3\u96c6\u65f6\u95f4\u6b65\u7d22\u5f15\u662f 0~676\uff0c\u9a8c\u8bc1\u96c6\u65f6\u95f4\u6b65\u7d22\u5f15 616~773\uff0c\u6d4b\u8bd5\u96c6\u65f6\u95f4\u6b65\u7d22\u5f15 713~966</p> <p>\u5bf9\u4e8e\u8bad\u7ec3\u96c6\u6765\u8bf4\uff0c\u6700\u5c0f\u7684 index=0\uff0c\u5bf9\u5e94\u7684\u53ef\u4ee5\u62ff\u5230\u4e00\u4e2a\u6837\u672c <code>0~60,61~84</code> \u5c01\u88c5\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u6837\u672c\uff1b\u90a3\u6700\u5927\u7d22\u5f15\u662f\u591a\u5c11\u5462\uff1f\u90a3\u5c31\u53ea\u80fd\u4ece \u7d22\u5f15 676 \u5f00\u59cb\uff0c\u9884\u7559\u51fa 60+24 \u4e2a\u65f6\u95f4\u6b65\uff0c\u4e5f\u5c31\u662f 676-60-24=592 \u7d22\u5f15\uff0c\u6240\u4ee5\u5176\u5b9e\u8bad\u7ec3\u96c6\u6709\u6548\u7d22\u5f15\u8303\u56f4\u662f 0~592\uff0c\u4e5f\u5c31\u662f 593 \u4e2a\u6837\u672c\u3002\u90a3\u4ece 0~592 \u4e2a\u6709\u6548\u7d22\u5f15\u503c \u4e2d\u968f\u673a\u9009\u53d6 \u6837\u672c\u7684 index \u662f\u4e00\u5b9a\u4e0d\u4f1a\u8d85\u51fa\u8303\u56f4\u7684\uff1b\u9a8c\u8bc1\u96c6\u6d4b\u8bd5\u96c6\u662f\u4e00\u6837\u7684\u9053\u7406\u3002</p> <p>\u800c\u4e14\uff0c\u4e4b\u524d \u6211\u4eec\u628a\u9a8c\u8bc1\u96c6\u65f6\u95f4\u6b65\u3001\u6d4b\u8bd5\u96c6\u65f6\u95f4\u6b65\u5411\u591a\u56de\u6eaf\u4e86 60 \u4e2a\u8f93\u5165\u5e8f\u5217\uff0c\u8fd9\u6837\u5c31\u4fdd\u8bc1\u4e86\uff0c\u539f\u59cb\u7684\u9a8c\u8bc1\u96c6\u5f00\u59cb\u7684\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u4e5f\u80fd\u7528\u4e8e\u9884\u6d4b\uff0c\u800c\u4e0d\u4f1a\u635f\u5931\u4efb\u4f55\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u4fe1\u606f\u3002\u5c31\u662f\u4fdd\u8bc1\u4e86\u6bcf\u4e2a\u65f6\u95f4\u6b65\u90fd\u6709\u53ef\u80fd\u4f5c\u4e3a\u8f93\u5165\u5e8f\u5217\uff0c\u4e5f\u6709\u53ef\u80fd\u4f5c\u4e3a\u9884\u6d4b\u5e8f\u5217\u3002</p> <ul> <li>\u63a5\u4e0b\u6765\u8fdb\u5165 dataloader \u7684\uff0c\u4e5f\u5c31\u662f\u6570\u636e\u96c6\u7684\u5c01\u88c5\uff08\u4e0a\u56fe\u6709\u663e\u793a\u4ee3\u7801\uff09</li> <li>\u8fd9\u91cc\u7684 <code>Dataloader</code> \u7528\u7684\u662f <code>pytorch</code> \u81ea\u5e26\u7684<code>Dataloader</code> \u7c7b\u3002</li> <li>\u6211\u4eec\u77e5\u9053 \u5b9e\u4f8b\u5316\u7684\u7c7b\u52a0==\u4e2d\u62ec\u53f7[\u7d22\u5f15 index]== \u4f1a\u81ea\u52a8\u8c03\u7528 <code>getitem</code> \u65b9\u6cd5\uff0c\u5c31\u662f\u7c7b\u4f3c\u8fd9\u6837\uff1a<code>obj = MyClass([1, 2, 3])\uff0cprint(obj[1])</code>  \uff0c\u5176\u4e2d <code>MyClass([1, 2, 3])</code> \u4f1a\u81ea\u52a8\u8c03\u7528 <code>init</code> \u65b9\u6cd5\uff0c\u800c \u5b9e\u4f8b\u5316\u7684\u7c7b  <code>obj[1]</code> \u5c31\u4f1a\u8c03\u7528 <code>getitem</code> \u65b9\u6cd5\u3002</li> <li>\u8fd9\u91cc\u60f3\u8bf4\u660e\u7684\u662f\uff0cDataloader \u4e5f\u4f1a\u81ea\u52a8\u8c03\u7528 Dataset \u7684 getitem \u65b9\u6cd5\uff0c\u90a3\u8c03\u7528  getitem \u65b9\u6cd5\u5c31\u5f97\u6709\u7d22\u5f15\uff0c\u7d22\u5f15\u600e\u4e48\u6765\u7684\uff1f \u662f\u901a\u8fc7 <code>shuffle</code> \u751f\u6210\u7684\uff0c\u5982\u679c shuffle=True\uff0c\u5c31\u4f1a\u81ea\u52a8\u751f\u6210 batchsize \u4e2a\u968f\u673a\u7d22\u5f15\uff0c\u5e76\u5c06\u8fd9\u4e9b\u7d22\u5f15 \u4f20\u9012\u7ed9 getitem\uff0c\u7136\u540e\u5f97\u5230\u968f\u673a\u6837\u672c\uff0c\u5c01\u88c5\u6210 dataloader\uff0c\u968f\u673a\u7d22\u5f15\u7684\u8303\u56f4\u662f\u901a\u8fc7 Dataset \u7c7b\u7684 len \u65b9\u6cd5\u9650\u5236\u7684\u3002\u5982\u679c shuffle=false \u7684\u8bdd\uff0c\u5c31\u6309\u987a\u5e8f\u9009batchsize \u4e2a\u6837\u672c\u3002</li> <li>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4ed4\u7ec6\u770b\u8fd9\u4e2a  <code>__getitem__</code> \u65b9\u6cd5\uff0c\u53ea\u9700\u8981\u4e00\u4e2a\u53c2\u6570 index \u5373\u53ef\u3002</li> </ul> Text Only<pre><code>    def __getitem__(self, index):\n        s_begin = index\n        s_end = s_begin + self.seq_len\n        r_begin = s_end - self.label_len\n        r_end = r_begin + self.label_len + self.pred_len\n\n        seq_x = self.data_x[s_begin:s_end]\n        seq_y = self.data_y[r_begin:r_end]\n        seq_x_mark = self.data_stamp[s_begin:s_end]\n        seq_y_mark = self.data_stamp[r_begin:r_end]\n\n        return seq_x, seq_y, seq_x_mark, seq_y_mark\n</code></pre> <ul> <li>\u73b0\u5728\u6211\u4eec\u5c31\u5047\u8bbe\u968f\u673a\u62bd\u53d6\u8bad\u7ec3\u96c6\u7684\u6837\u672c</li> <li>\u8bad\u7ec3\u96c6\u7684\u6837\u672c\u6570\u662f 593 \u4e2a</li> <li>dataloader \u5728\u751f\u6210\u968f\u673a\u7d22\u5f15\u65f6\u4f1a\u9650\u5236\u5728 len(dataset)\u4e2d\uff0c\u6211\u4eec\u8bbe\u7f6e\u7684 batchsize \u4e3a 16\uff0c\u5047\u8bbe\u751f\u6210\u7684 16 \u4e2a\u968f\u673a\u7d22\u5f15\u5206\u522b\u662f  [0,23, 105, 67, 198, 54,..., 593]\uff08\u603b\u8ba116\u4e2a\u7d22\u5f15\uff09\uff0c\u8fd9\u91cc\u6709\u4e24\u4e2a\u8fb9\u754c\u503c\uff0c\u4e5f\u5c31\u662f\u80fd\u591f\u9009\u53d6\u7684\u6700\u5c0f\u7684\u65f6\u95f4\u6b65\u7d22\u5f15\u662f 0 \uff0c\u6700\u5927\u7684\u65f6\u95f4\u6b65\u7d22\u5f15\u662f 593</li> <li>\u5982\u679c shuffle=False \u7684\u8bdd\uff0c\u5c31\u662f\u6309\u987a\u5e8f\u53d6\u524d 16 \u4e2a\u7d22\u5f15\u4e5f\u5c31\u662f 0~15\u3002</li> <li>\u5f97\u5230\u6bcf\u4e2a\u7d22\u5f15\uff0c\u6839\u636e\u6bcf\u4e2a\u7d22\u5f15\u5f97\u5230\u6837\u672c\uff0c\u5411\u540e\u7684 60 \u4e2a\u65f6\u95f4\u6b65\u4f5c\u4e3a\u8f93\u5165\u5e8f\u5217\uff0c\u56e0\u4e3a label_sequence=0\uff0c\u6240\u4ee5\u7d27\u63a5\u7740\u7684 24 \u4e2a\u65f6\u95f4\u6b65\u662f\u9884\u6d4b\u5e8f\u5217</li> <li>\u5047\u8bbe\u6211\u4eec\u751f\u6210\u7684\u968f\u673a\u7d22\u5f15\u4e3a\uff1a 23\uff0c\u4e5f\u5c31\u662f <code>index=23</code> \u5c31\u4f1a\u8c03\u7528 <code>dataset</code> \u7684 <code>getitem</code> \u65b9\u6cd5\u3002</li> </ul> <p></p> <ul> <li><code>s_begin</code> \u8f93\u5165\u5e8f\u5217\u8d77\u59cb\u70b9\uff1b<code>s_end</code> \u8f93\u5165\u5e8f\u5217\u7ed3\u675f\u70b9\uff1b<code>r_begin</code>\u6807\u7b7e\u5e8f\u5217\u8d77\u70b9\uff1b<code>r_end</code> \u6807\u7b7e+\u9884\u6d4b\u5e8f\u5217\u7ec8\u70b9\uff1b</li> </ul> <p>\uff081\uff09\u8f93\u5165\u5e8f\u5217\u8d77\u70b9 <code>=index</code></p> <p>\uff082\uff09\u8f93\u5165\u5e8f\u5217\u7ec8\u70b9 <code>=index+seq_len</code></p> <p>\uff083\uff09\u9884\u6d4b\u5e8f\u5217\u8d77\u70b9 <code>=index+seq_len-label_len</code></p> <p>\uff084\uff09\u9884\u6d4b\u5e8f\u5217\u7ec8\u70b9 <code>=index+seq_len+pred_len</code>  \u8fd9\u91cc\u7701\u7565\u4e86 <code>-label_len+label_len</code></p> <p>\u7136\u540e\uff0c</p> Text Only<pre><code>        seq_x = self.data_x[s_begin:s_end]\n        seq_y = self.data_y[r_begin:r_end]\n        seq_x_mark = self.data_stamp[s_begin:s_end]\n        seq_y_mark = self.data_stamp[r_begin:r_end]\n\n        return seq_x, seq_y, seq_x_mark, seq_y_mark\n</code></pre> <ul> <li> <p>\u6839\u636e\u8f93\u5165\u5e8f\u5217\u7d22\u5f15\u548c\u9884\u6d4b\u5e8f\u5217\u7d22\u5f15\uff0c\u6765\u5f97\u5230 \u8f93\u5165\u7279\u5f81\u5e8f\u5217\u548c\u9884\u6d4b\u7279\u5f81\u5e8f\u5217\u3001\u8f93\u5165\u65f6\u95f4\u6233\u7279\u5f81\u5e8f\u5217\u548c\u9884\u6d4b\u65f6\u95f4\u6233\u7279\u5f81\u5e8f\u5217</p> </li> <li> <p>\u75be\u75c5\u6570\u636e\u96c6\uff1a966\u00d78\uff087 \u4e2a\u7279\u5f81+1 \u4e2a\u65f6\u95f4\u6233\uff0c\u6240\u4ee5\u4e00\u5171 8 \u5217\uff09</p> </li> <li> <p>\u5bf9\u4e8e\u5355\u4e2a\u6837\u672c\u7684 <code>seq_x = self.seq_len \u00d7 7\uff0cseq_y = (label_len + pred_len) \u00d7 7</code>\uff0c<code>seq_x_mark = self.seq_len \u00d7 4 , seq_y_mark = self.seq_len \u00d7 4</code></p> </li> <li> <p>dataloader \u5c01\u88c5\u4e86 <code>batchsize</code> \u4e2a <code>seq_x, seq_y, seq_x_mark, seq_y_mark</code></p> </li> </ul> <p></p> <p>\u5f53\u6211\u4eec\u6267\u884c\u5b8c\u4e86\u4ee5\u4e0a\u6e90\u7801\u4ee5\u540e\uff0c\u4ece\u54ea\u513f\u6765\u7684\uff0c\u56de\u54ea\u91cc\u53bb</p> <ul> <li>\u9996\u5148 <code>data_provider</code>\u8fd4\u56de\u7684<code>return data_set, data_loader</code></li> <li><code>_get_data</code>\u8c03\u7528\u7684 <code>data_provider</code> \uff0c\u6240\u4ee5 <code>data_provider</code>\u8fd4\u56de\u7684\u7ed3\u679c \u8fd4\u56de\u7ed9 <code>def _get_data(self, flag)</code> \u7684 <code>return data_set, data_loader</code></li> <li>\u6700\u7ec8\u8fd4\u56de\u7ed9 <code>train_data, train_loader = self._get_data(flag='train')</code></li> </ul> <p>\u540e\u9762\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u7684\u52a0\u8f7d\u540c\u7406\u3002\u540e\u9762\u6bd4\u8f83\u91cd\u8981\u7684\u5c31\u662f SegRNN \u7684 forward \u8c03\u7528\uff0c\u4e5f\u5c31\u662f\u8bba\u6587\u7684\u6838\u5fc3\u601d\u60f3\u3002</p>"},{"location":"Reproduction/5_SegRNN_v2/#_4","title":"\u65f6\u95f4\u5e8f\u5217\u6837\u672c","text":"<p>\u4ee5\u4e0a\u662f\u4ee3\u7801\u5c42\u9762\u7684\u7406\u89e3\uff0c\u63a5\u4e0b\u6765\u60f3\u8bf4\u660e\u7684\u5c31\u662f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u5c01\u88c5\u65b9\u5f0f\u3002\u5bf9\u4e8e\u4e0d\u540c\u7684\u4efb\u52a1\uff0c\u6570\u636e\u7684\u7ec4\u7ec7\u5f62\u5f0f\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u6240\u4ee5\u8fd9\u6b21\u76f4\u63a5\u7684\u7406\u89e3\u65f6\u95f4\u5e8f\u5217\u6837\u672c\u7684\u6784\u6210\u3002</p> <p>\u5bf9\u4e8e\u4e00\u5f20\u4e8c\u7ef4\u6570\u8868\uff0c\u65f6\u95f4\u5e8f\u5217\u90fd\u662f\u4e8c\u7ef4\u6570\u8868\uff0c\u884c\u662f\u6bcf\u4e2a\u65f6\u95f4\u70b9\uff0c\u5217\u662f\u6bcf\u4e2a\u65f6\u95f4\u70b9\u91c7\u96c6\u7684\u6570\u636e\uff0c\u6bd4\u5982\u75be\u75c5\u611f\u67d3\u4eba\u6570\uff0c\u8bb0\u5f55\u7684 2002 \u5e74 1 \u6708\u5f00\u59cb\uff0c\u5230 2020 \u5e74 1 \u6708\u7ed3\u675f\uff0c\u6bcf\u5468\u4e00\u91c7\u96c6\u6570\u636e\uff0c\u9664\u4e86\u8bb0\u5f55\u75be\u75c5\u611f\u67d3\u4eba\u6570\uff0c\u8fd8\u53ef\u4ee5\u8bb0\u5f55\u4e00\u4e9b\u4e0e\u611f\u67d3\u75be\u75c5\u4eba\u6570\u7684\u76f8\u5173\u7684\u6bd4\u5982\u5f53\u5730\u5929\u6c14\u4ec0\u4e48\u7684\uff1b</p> <p>\u5177\u4f53\u6765\u8bf4\u5c31\u662f\uff1a</p> <p> </p> <p>Y \u76ee\u6807\u5217\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0e\u5176\u4ed6\u56fe\u50cf\u6216\u8005 NLP \u4efb\u52a1\u4e0d\u540c\u7684\u662f\uff0c\u7279\u5f81\uff0c\u5728\u672a\u6765\u65f6\u95f4\u70b9\uff0c\u6211\u4eec\u662f\u4e0d\u77e5\u9053\u6240\u6709\u7684\u7279\u5f81\u7684\uff0c\u5b8c\u5168\u90fd\u662f\u672a\u77e5\u7684\u3002</p> <p>\u65f6\u95f4\u5e8f\u5217\u6837\u672c\u7684\u6784\u9020\uff1a\u7528\u4e8e\u8bad\u7ec3\u7684\u65f6\u95f4\u6b65\uff0c\u8bb0\u4f5c <code>sequence_length</code>\uff0c\u7528\u4e8e\u9884\u6d4b\u7684\u65f6\u95f4\u6b65 <code>pred_length</code>\uff0c\u8fd8\u6709\u4e00\u4e2a\u6bd4\u8f83\u7279\u6b8a\u7684\u6982\u5ff5 <code>label_length</code> \uff0c\u8868\u793a\u7528\u4e8e\u8bad\u7ec3\u7684\u65f6\u95f4\u6b65\u6709\u591a\u5c11\u7528\u4e8e\u6307\u5bfc\u9884\u6d4b\uff0c\u7528\u4e00\u5f20\u56fe\u8868\u793a\uff1a</p> <p></p> <p>\u6709\u51e0\u4e2a batch \u6211\u4eec\u5c31\u79fb\u52a8\u51e0\u4e2a\u5c0f\u65f6\uff0c\u6784\u9020\u51e0\u4e2a batch\u3002</p> <p></p> <p>\u5f53\u7136\u4e86\uff0c\u8fd9\u91cc\u4e5f\u6709\u4e00\u4e2a\u9057\u7559\u95ee\u9898\uff0c\u5c31\u662f\u8fd9\u6837\u6784\u9020 batch\u7684\u8bdd\uff0c\u4e0d\u5c31\u662f\u6309\u7167\u7279\u5f81\u7684\u987a\u5e8f\u5582\u7ed9\u6a21\u578b\u4e86\u5417\uff0c\u6a21\u578b\u4e0d\u5c31\u4f1a\u4f9d\u8d56\u8fd9\u4e2a\u987a\u5e8f\u4e86\u561b\uff0c\u800c\u4e00\u822c\u6211\u4eec\u5728\u6784\u5efa Dataloader \u7684\u65f6\u5019\uff0c\u4f1a\u8bbe\u7f6e\u4e00\u4e2a\u53c2\u6570 <code>shuffle=True</code> \uff0c\u4e5f\u5c31\u662f \u4f1a\u968f\u673a\u9009\u53d6 batch \u4e2a\u7d22\u5f15 index\uff0c\u4ece\u8fd9\u4e2a\u7d22\u5f15\u5f00\u59cb\u9009\u62e9 sequence length \u4e2a\u65f6\u95f4\u6b65\u4ee5\u53ca\u540e\u9762\u7684 predict length \u8fdb\u884c\u5c01\u88c5\uff0c\u5c01\u88c5\u6210\u4e00\u4e2a\u6837\u672c\u3002</p> <p>966\u00d78\uff081+7\uff09\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff0c1 \u8868\u793a\u65f6\u95f4\u6233\u7279\u5f81\uff0c7 \u8868\u793a\u8bb0\u5f55\u7684\u7279\u5f81\u3002</p> <p>\u5728\u8fd9\u4e2a\u9879\u76ee\u7684 illness \u6570\u636e\u96c6\u4e2d\uff0c\u6709 966 \u4e2a\u65f6\u95f4\u70b9\uff0c\u6bcf\u4e2a\u65f6\u95f4\u70b9\u8bb0\u5f55\u4e86 7 \u4e2a\u7279\u5f81\uff0cbatch size=16\uff0csequence length=60\uff0cfeature=7\uff0c\u66f4\u5177\u4f53\u6765\u8bf4\u65f6\u95f4\u5e8f\u5217\u7684\u6570\u636e\u5c01\u88c5\u5c31\u662f\uff1a</p> <p>16 \u4e2a\u72ec\u7acb\u7684\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u6709 60 \u4e2a\u8fde\u7eed\u7684\u65f6\u95f4\u6b65\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\u503c\uff0c\u6bcf\u4e2a\u65f6\u95f4\u6b65\u6709 7 \u4e2a\u7279\u5f81</p> <p>\u6240\u4ee5\u5c31\u662f\u56e0\u4e3a\u6837\u672c\u662f\u968f\u673a\u4ece\u8bad\u7ec3\u96c6\u4e2d\u91c7\u7684\uff0c\u6240\u4ee5\u5c31\u5047\u8bbe\u968f\u673a\u91c7index\u7684\u662f 7\u300138\u30010\u3001129\u7b49\u7b49\u7b49\uff0c\u4e00\u5171 16 \u4e2a\uff08\u8fd9\u5c31\u662f batchsize\uff0c\u8868\u793a\u4e00\u4e2a batch\u4e2d\u5bb9\u7eb3\u7684\u6837\u672c\u6570\uff09</p> <p>\u6bcf\u4e2a\u6837\u672c\u4e2d\u8fde\u7eed\u7684 60 \u4e2a\u65f6\u95f4\u6b65\uff0c\u8fd9\u4e2a\u5c31\u5f88\u597d\u7406\u89e3\u4e86\uff1a</p> <p>(0)\u968f\u673a\u751f\u6210\u7b2c 1 \u4e2a index=7\uff0c\u5f97\u5230\u6837\u672c\uff1a\u4ece\u7b2c 7 \u4e2a\u65f6\u95f4\u5f00\u59cb.....\u8ddf\u7740 60 \u4e2a\uff0c\u540e\u9762\u7d27\u8ddf\u7740\u8981\u9884\u6d4b\u7684 24 \u4e2a\u65f6\u95f4\u6b65\uff0cdataloader \u8bfb\u6570\u636e\u65f6\u90fd\u5c01\u88c5\u597d\u4e86\uff0c\u4f1a\u5bf9\u5e94\u4e0a\u7684</p> <p>(1)\u968f\u673a\u751f\u6210\u7b2c 2\u4e2a index=38\uff0c\u5f97\u5230\u6837\u672c\uff1a\u4ece\u7b2c  38 \u4e2a\u65f6\u95f4\u5f00\u59cb.....</p> <p>(2)\u968f\u673a\u751f\u6210\u7b2c 3\u4e2a index=0\uff1a\u4ece\u7b2c 0\u4e2a\u65f6\u95f4\u5f00\u59cb</p> <p>......</p> <p>(15)\u968f\u673a\u751f\u6210\u7b2c 16\u4e2a index=129\uff1a\u4ece\u7b2c 129 \u4e2a\u65f6\u95f4\u5f00\u59cb</p>"},{"location":"Reproduction/5_SegRNN_v2/#_5","title":"\u6ed1\u52a8\u7a97\u53e3\u4e0e\u6837\u672c\u5806\u53e0","text":"<p>\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u6ed1\u52a8\u7a97\u53e3\u662f\u5728 <code>__getitem__</code> \u65b9\u6cd5\u4e2d\u901a\u8fc7\u7d22\u5f15\u5207\u7247\u5b9e\u73b0\u7684\uff1a</p> <ul> <li> <p>\u7a97\u53e3\u8d77\u70b9\uff1a\u6bcf\u4e2a\u7d22\u5f15 index \u4ee3\u8868\u4e00\u4e2a\u6ed1\u52a8\u7a97\u53e3\u7684\u8d77\u59cb\u4f4d\u7f6e </p> </li> <li> <p>\u7a97\u53e3\u5212\u5206\uff1a</p> </li> <li>\u8f93\u5165\u7a97\u53e3\uff1a<code>[index:index+seq_len]</code> (60\u4e2a\u65f6\u95f4\u6b65)</li> <li>\u9884\u6d4b\u7a97\u53e3\uff1a<code>[index+seq_len-label_len:index+pred_len]</code> (24\uff08<code>label_len+pred_len</code>\uff09\u4e2a\u65f6\u95f4\u6b65)</li> <li>\u6837\u672c\u91cd\u53e0\uff1a<ul> <li>\u7531\u4e8e\u7d22\u5f15\u5728<code>0\u5230(len(data_x)-seq_len-pred_len)</code>\u4e4b\u95f4\uff0c\u76f8\u90bb\u7d22\u5f15\u7684\u7a97\u53e3\u4f1a\u6709\u5927\u91cf\u91cd\u53e0</li> <li>\u4f8b\u5982\uff0c\u7d22\u5f150\u548c\u7d22\u5f151\u7684\u8f93\u5165\u7a97\u53e3\u5171\u4eab59\u4e2a\u65f6\u95f4\u6b65</li> </ul> </li> </ul> <p>\u7528\u56fe\u6765\u7406\u89e3\u5c31\u662f\u8fd9\u6837\u7684</p> <p></p> <p>\u603b\u7ed3\uff1aDataLoader \u901a\u8fc7\u8c03\u7528 Dataset \u7684 <code>__getitem__</code> \u65b9\u6cd5\u83b7\u53d6\u5355\u4e2a\u6837\u672c\uff0c\u7136\u540e\u5c06\u5b83\u4eec\u5806\u53e0\u6210\u6279\u6b21\u3002\u6837\u672c\u7684\u5b9e\u9645\u7ed3\u6784\u548c\u6ed1\u52a8\u7a97\u53e3\u903b\u8f91\u7531 Dataset \u5b9e\u73b0\uff0cDataLoader \u53ea\u8d1f\u8d23\u7ec4\u88c5\u548c\u6279\u5904\u7406</p>"},{"location":"Reproduction/5_SegRNN_v3/","title":"(\u624b\u5199\u7b14\u8bb0)SegRNN","text":""},{"location":"Reproduction/5_SegRNN_v3/#segrnn","title":"(\u624b\u5199\u7b14\u8bb0)SegRNN","text":"2025-03-21 14:12:102025-09-28 12:54:03 <p> \u7ea6 23 \u4e2a\u5b57  9 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"Reproduction/5_SegRNN_v3/#_1","title":"\u5173\u4e8e\u4e24\u6b21\u6807\u51c6\u5316","text":""},{"location":"Reproduction/5_SegRNN_v3/#dataloader","title":"dataloader \u4e2d\u7684\u6570\u636e","text":""},{"location":"Reproduction/5_SegRNN_v3/#illness","title":"\u5173\u4e8eillness\u6570\u636e\u96c6","text":""},{"location":"Reproduction/5_SegRNN_v4/","title":"SegRNN\u5b9e\u9a8c\u8fc7\u7a0b","text":""},{"location":"Reproduction/5_SegRNN_v4/#segrnn","title":"SegRNN\u5b9e\u9a8c\u8fc7\u7a0b","text":"2025-04-02 15:40:002025-09-28 12:54:03 <p> \u7ea6 2101 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 11 \u5206\u949f</p> <p>\u73b0\u5728\u9700\u8981\u5f04\u6e05\u695a\uff0c\u600e\u4e48\u590d\u73b0\u51fa\u8bba\u6587\u7684\u7ed3\u679c\u3002</p> <p>\u8bba\u6587\u4e2d\u8868 2 \u7ed9\u51fa\u4e86\u6240\u6709\u7528\u5230\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6\u3002</p> <p>https://github.com/lss-1138/SegRNN</p> <p>\u6e90\u7801\u4ed3\u5e93\u7ed9\u4e86\u590d\u73b0\u8bba\u6587\u7ed3\u679c\u7684\u811a\u672c\u547d\u4ee4\uff0c\u6211\u5df2\u7ecf\u7528\u4e86 AutoDL \u8dd1\u4e86\u8fd9\u4e2a\u811a\u672c\uff0c\u6309\u7406\u8bf4\u662f\u5df2\u7ecf\u590d\u73b0\u4e86\u4e00\u90e8\u5206\u7ed3\u679c\u3002</p> <p>\u6211\u73b0\u5728\u5bf9 Electricity \u6570\u636e\u96c6\u8fdb\u884c\u4e86\u6570\u636e\u96c6\u63cf\u8ff0\u3002</p> <p>\u73b0\u5728\u601d\u8003\u600e\u4e48\u628a\u81ea\u5df1\u5df2\u7ecf\u505a\u5f97\u5de5\u4f5c\u878d\u5165\u5230 SegRNN \u4e2d\uff0c\u5e76\u4ee5 SegRNN \u4e3a\u57fa\u7840\uff0c\u8fdb\u4e00\u6b65\u7684\u6539\u8fdb\u6a21\u578b\u3002</p> <p>\u73b0\u5728\u7ee7\u7eed\u770b\u600e\u4e48\u770b\u5df2\u7ecf\u590d\u73b0\u51fa\u7684\u7ed3\u679c\u548c\u8bba\u6587\u4e2d\u7684\u7ed3\u679c\u8fdb\u884c\u5bf9\u6bd4\u3002</p> <ul> <li>checkpoints\u4fdd\u5b58\u7684\u662f\u6a21\u578b\u7684 pth \u53c2\u6570\u6587\u4ef6</li> </ul> <p>\u6570\u636e\u96c6\u6570\u91cf\uff1a</p> <ol> <li>Electricity</li> <li>ETT h1</li> <li>ETT h2</li> <li>ETT m1</li> <li>ETT m2</li> <li>illness</li> <li>traffic</li> <li>weather</li> </ol> <p>\u6c47\u603b\u6bcf\u4e2a\u6570\u636e\u96c6\u505a\u4e86\u51e0\u4e2a\u5b9e\u9a8c </p> <ul> <li>4 \u4e2a\u5b9e\u9a8c||Electricity \u6570\u636e\u96c6\uff1a\u56de\u671b\u7a97\u53e3 96\uff0c\u5206\u522b\u9884\u6d4b 96,192,336,720</li> </ul> Text Only<pre><code>seq_len=96\nfor pred_len in 96 192 336 720\n</code></pre> <ul> <li>\u5bf9\u5e94\u7740\u6709 4 \u4e2a logs \u6587\u4ef6\uff0c\u5b58\u4e86\u7ed3\u679c</li> </ul> <p>\u95ee\u9898\uff1a\u8fd9\u4e2a logs \u6587\u4ef6\u7684\u7ed3\u679c\u600e\u4e48\u9605\u8bfb\uff1f</p> <p>\u5206\u6790\uff0c\u53bb\u770b logs \u6587\u4ef6\u90fd\u5b58\u4e86\u4ec0\u4e48\u5185\u5bb9\uff1f</p> <ul> <li>logs \u6587\u4ef6\u7684\u8d77\u59cb\u70b9</li> </ul> <p>\u5206\u6790\uff1a<code>logs/LongForcasting</code> \u6587\u4ef6\u5939\u4e0b</p> <p><code>logs/LongForecasting/SegRNN_Electricity_720_96.log</code></p> <p><code>logs/LongForecasting/SegRNN_Electricity_720_192.log</code></p> <p><code>logs/LongForecasting/SegRNN_Electricity_720_336.log</code></p> <p><code>logs/LongForecasting/SegRNN_Electricity_720_720.log</code></p> <p>\u4fdd\u5b58\u4e86\u8fd9\u4e2a\u811a\u672c\u7684\u6570\u636e\u6587\u4ef6\uff1a</p> <p><code>/root/SegRNN/scripts/SegRNN/electricity.sh</code></p> <p>\u603b\u7ed3\uff1a\u8fd9\u4e2a\u811a\u672c\u8dd1\u4e86\u56de\u6eaf\u7a97\u53e3 96\uff0c\u5206\u522b\u8fdb\u884c \u672a\u6765 96 \u6b65\u957f\uff0c192 \u6b65\u957f\uff0c336 \u6b65\u957f\uff0c720 \u6b65\u957f\u7684\u9884\u6d4b</p> <p>\u73b0\u5728\u5c31\u5148\u5206\u6790 <code>/root/SegRNN/logs/LongForecasting/SegRNN_Electricity_720_96.log</code>\u8fd9\u4e2a log \u4e2d\u8bb0\u5f55\u7684\u5185\u5bb9</p> <p>\u7b2c\u4e00\u90e8\u5206\uff0c\u4e0d\u7528\u7ba1\uff0c\u662f\u53c2\u6570\u8bbe\u7f6e namespace</p> Electricity Namespace <p> Args in experiment: Namespace(activation='gelu', affine=0, batch_size=16, c_out=7, channel_id=1, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='electricity.csv', dec_in=7, dec_way='pmf', decomposition=0, des='test', devices='0,1', distil=True, do_predict=False, dropout=0.1, e_layers=2, embed='timeF', embed_type=0, enc_in=321, factor=1, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=0, learning_rate=0.0005, loss='mae', lradj='type3', model='SegRNN', model_id='Electricity_720_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=10, pct_start=0.3, pred_len=96, random_seed=2024, revin=0, rnn_type='gru', root_path='./dataset/', seg_len=48, seq_len=720, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=30, use_amp=False, use_gpu=True, use_multi_gpu=False, win_len=48) Use GPU: cuda:0 </p> <p>\u7b2c\u4e8c\u90e8\u5206\uff0c</p> Text Only<pre><code>Electricity_720_96_SegRNN_custom_ftM_sl720_pl96_dm512_dr0.1_rtgru_dwpmf_sl48_mae_test_0&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\ntrain 17597\nval 2537\ntest 5165\n</code></pre> <p>\u533a\u5206 iteration\u548c epoch</p> <p>epoch \u8bbe\u7f6e\u4e3a 30  <code>train_epochs=30</code></p> namespace \u53c2\u6570\u89e3\u91ca <p> </p>Text Only<pre><code>    Electricity_720_96_SegRNN_custom_ftM_sl720_pl96_dm512_dr0.1_rtgru_dwpmf_sl48_mae_test_0\uff1a\u8fd9\u662f\u8bad\u7ec3\u4efb\u52a1\u7684\u6807\u8bc6\u7b26\uff0c\u5305\u542b\u4e86\u6a21\u578b\u548c\u8bad\u7ec3\u8bbe\u7f6e\u7684\u5173\u952e\u53c2\u6570\uff1a\nElectricity\uff1a\u6570\u636e\u96c6\u540d\u79f0\u3002\n720\uff1a\u56de\u6eaf\u957f\u5ea6\uff08seq_len\uff09\u3002\n96\uff1a\u9884\u6d4b\u957f\u5ea6\uff08pred_len\uff09\u3002\nSegRNN_custom\uff1a\u6a21\u578b\u540d\u79f0\u3002\nftM\uff1a\u7279\u5f81\u7c7b\u578b\uff08M \u8868\u793a\u591a\u53d8\u91cf\uff09\u3002\nsl720\uff1a\u5e8f\u5217\u957f\u5ea6\uff08seq_len\uff09\u3002\npl96\uff1a\u9884\u6d4b\u957f\u5ea6\uff08pred_len\uff09\u3002\ndm512\uff1a\u9690\u85cf\u5c42\u7ef4\u5ea6\uff08d_model\uff09\u3002\ndr0.1\uff1a\u4e22\u5f03\u7387\uff08dropout\uff09\u3002\nrtgru\uff1aRNN \u7c7b\u578b\uff08GRU\uff09\u3002\ndwpmf\uff1a\u89e3\u7801\u65b9\u5f0f\uff08Parallel Multi-step Forecasting\uff09\u3002\nsl48\uff1a\u6bb5\u957f\u5ea6\uff08seg_len\uff09\u3002\nmae_test_0\uff1a\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\uff08MAE\uff09\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u6d4b\u8bd5\u96c6\u7f16\u53f7\u4e3a 0\u3002\n</code></pre> <p></p> <p>\u8bad\u7ec3\u96c6\u6837\u672c\uff1a17597\uff0c<code>batch_size=16</code></p> <p>\u6240\u4ee5\uff0c\u6bcf\u4e2a epoch \u7684 iters = $17597/16=1,099.81 $</p> <p>\u4ee5\u4e0a\u662f\u7b2c\u4e00\u4e2a epoch=1 \u7684\u8f93\u51fa</p> Text Only<pre><code>    iters: 100, epoch: 1 | loss: 0.6690567\n    speed: 0.0366s/iter; left time: 1203.1702s\n    iters: 200, epoch: 1 | loss: 0.4867136\n    speed: 0.0277s/iter; left time: 907.4625s\n    iters: 300, epoch: 1 | loss: 0.4125512\n    speed: 0.0258s/iter; left time: 844.1005s\n    iters: 400, epoch: 1 | loss: 0.3804378\n    speed: 0.0270s/iter; left time: 878.8473s\n    iters: 500, epoch: 1 | loss: 0.3569579\n    speed: 0.0235s/iter; left time: 762.6345s\n    iters: 600, epoch: 1 | loss: 0.3551046\n    speed: 0.0255s/iter; left time: 823.9151s\n    iters: 700, epoch: 1 | loss: 0.3524055\n    speed: 0.0240s/iter; left time: 774.8318s\n    iters: 800, epoch: 1 | loss: 0.3217510\n    speed: 0.0227s/iter; left time: 731.5172s\n    iters: 900, epoch: 1 | loss: 0.3337467\n    speed: 0.0229s/iter; left time: 733.8034s\n    iters: 1000, epoch: 1 | loss: 0.3291512\n    speed: 0.0232s/iter; left time: 741.6312s\nEpoch: 1 cost time: 28.068471431732178\nEpoch: 1, Steps: 1099 | Train Loss: 0.4208171 Vali Loss: 0.2863213 Test Loss: 0.3096032\n</code></pre> <p>\u4e0a\u9762\u5df2\u7ecf\u7b97\u4e86\uff0c\u6839\u636e\u8bad\u7ec3\u6837\u672c\u6570\u548c batch \u7684\u5927\u5c0f\uff0c\u4e00\u6b21 epoch \u9700\u8981 1000 \u6b21 iter</p> <p>\u6a21\u578b100 \u6b21 iter \u8bb0\u5f55\u4e00\u6b21\u635f\u5931\uff0c\u6bcf\u6b21\u8fed\u4ee3\u901f\u5ea6\u4ee5\u53ca\u5269\u4f59\u7684\u65f6\u95f4\u3002</p> Text Only<pre><code>    iters: 100, epoch: 1 | loss: 0.6690567\n    speed: 0.0366s/iter; left time: 1203.1702s\n</code></pre> <ul> <li>iters\uff1a\u5f53\u524d\u8fed\u4ee3\u6b21\u6570\u3002</li> <li>epoch\uff1a\u5f53\u524d\u8bad\u7ec3\u8f6e\u6570\u3002</li> <li>loss\uff1a\u5f53\u524d\u8fed\u4ee3\u7684\u635f\u5931\u503c\u3002</li> <li>speed\uff1a\u6bcf\u6b21\u8fed\u4ee3\u7684\u5e73\u5747\u8017\u65f6\uff08\u5355\u4f4d\uff1a\u79d2/\u8fed\u4ee3\uff09\u3002</li> <li>left time\uff1a\u9884\u8ba1\u5269\u4f59\u8bad\u7ec3\u65f6\u95f4\uff08\u5355\u4f4d\uff1a\u79d2\uff09\u3002</li> </ul> <p>\u8bad\u7ec3\u5b8c\u4ee5\u540e\uff0c\u8f93\u51fa\u8bad\u7ec3\u65e5\u5fd7\u4fe1\u606f\uff1a</p> Text Only<pre><code>Epoch: 1 cost time: 28.068471431732178\nEpoch: 1, Steps: 1099 | Train Loss: 0.4208171 Vali Loss: 0.2863213 Test Loss: 0.3096032\n</code></pre> <ul> <li>**Steps: 1099\uff1a **    \uff08\u662f\u7684\uff0c\u8fd9\u4e2a\u662f\u51c6\u786e\u7684\u8fed\u4ee3\u6b65\u6570\u3002</li> </ul> <p>\u8868\u793a\u5728\u7b2c\u4e00\u4e2a epoch \u4e2d\uff0c\u6a21\u578b\u5b8c\u6210\u4e86 1099 \u6b21\u8fed\u4ee3\uff08\u6216\u6b65\u9aa4\uff09\u3002\u8fd9\u901a\u5e38\u662f\u56e0\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\u88ab\u5206\u6210\u4e86 1099 \u4e2a\u6279\u6b21\uff08batches\uff09\u3002</p> <ul> <li>\u8bad\u7ec3\u635f\u5931\uff08Train Loss\uff09 </li> </ul> <p>\u503c\uff1a0.4208171\uff1a\u8bad\u7ec3\u635f\u5931\u8f83\u9ad8\uff0c\u8868\u660e\u6a21\u578b\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u53ef\u80fd\u8fd8\u6709\u6539\u8fdb\u7a7a\u95f4</p> <ul> <li>\u9a8c\u8bc1\u635f\u5931\uff08Vali Loss\uff09</li> </ul> <p>\u503c\uff1a0.2863213\uff1a\u9a8c\u8bc1\u635f\u5931\u4f4e\u4e8e\u8bad\u7ec3\u635f\u5931\uff0c\u8fd9\u53ef\u80fd\u8868\u660e\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u6ca1\u6709\u8fc7\u62df\u5408\u3002</p> <ul> <li>\u6d4b\u8bd5\u635f\u5931\uff08Test Loss\uff09</li> </ul> <p>\u503c\uff1a0.3096032\uff1a\u6d4b\u8bd5\u635f\u5931\u7565\u9ad8\u4e8e\u9a8c\u8bc1\u635f\u5931\uff0c\u8fd9\u662f\u6b63\u5e38\u73b0\u8c61\uff0c\u56e0\u4e3a\u6d4b\u8bd5\u96c6\u901a\u5e38\u5305\u542b\u66f4\u591a\u672a\u89c1\u8fc7\u7684\u6570\u636e\u3002\u6d4b\u8bd5\u635f\u5931\u7684\u503c\u8868\u660e\u6a21\u578b\u5728\u72ec\u7acb\u6d4b\u8bd5\u6570\u636e\u4e0a\u7684\u8868\u73b0\u3002</p> <ul> <li>\u65f6\u95f4\u6d88\u8017 28.07 \u79d2/epoch\uff1a\u5b8c\u6210\u4e00\u4e2a epoch \u7684\u65f6\u95f4\u76f8\u5bf9\u8f83\u77ed\uff0c\u8fd9\u8868\u660e\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u8f83\u9ad8\u3002</li> </ul> <p>\u8fd8\u6709\u8fed\u4ee3\u6700\u540e\u4e00\u90e8\u5206\u7684\u65e5\u5fd7\u4fe1\u606f\uff1a</p> Text Only<pre><code>Validation loss decreased (inf --&gt; 0.286321).  Saving model ...\nUpdating learning rate to 0.0005\n    iters: 100, epoch: 2 | loss: 0.2965542\n    speed: 0.1480s/iter; left time: 4702.0987s\n    iters: 200, epoch: 2 | loss: 0.2877236\n    speed: 0.0264s/iter; left time: 836.8543s\n    iters: 300, epoch: 2 | loss: 0.2788590\n    speed: 0.0271s/iter; left time: 854.0580s\n    iters: 400, epoch: 2 | loss: 0.2706560\n    speed: 0.0276s/iter; left time: 868.6653s\n    iters: 500, epoch: 2 | loss: 0.2822747\n    speed: 0.0263s/iter; left time: 824.1755s\n    iters: 600, epoch: 2 | loss: 0.2616775\n    speed: 0.0269s/iter; left time: 840.6318s\n    iters: 700, epoch: 2 | loss: 0.2763505\n    speed: 0.0262s/iter; left time: 816.8357s\n    iters: 800, epoch: 2 | loss: 0.2719800\n    speed: 0.0259s/iter; left time: 804.4196s\n    iters: 900, epoch: 2 | loss: 0.2634850\n    speed: 0.0263s/iter; left time: 813.3547s\n    iters: 1000, epoch: 2 | loss: 0.2671717\n    speed: 0.0265s/iter; left time: 817.9329s\n</code></pre> <p>\u91cd\u70b9\u770b\u8fd9\u4e2a\uff1a</p> Text Only<pre><code>Validation loss decreased (inf --&gt; 0.286321).  Saving model ...\nUpdating learning rate to 0.0005\n</code></pre> <p>Validation loss decreased\uff1a\u8868\u793a\u9a8c\u8bc1\u635f\u5931\u503c\u4e0b\u964d\u4e86\u3002</p> <p>inf --&gt; 0.286321\uff1a\u8868\u793a\u5728\u4e0a\u4e00\u4e2a epoch \u4e2d\uff0c\u9a8c\u8bc1\u635f\u5931\u503c\u4e3a\u65e0\u7a77\u5927\uff08inf\uff09\uff0c\u73b0\u5728\u4e0b\u964d\u5230\u4e86 0.286321\u3002</p> <p>Saving model\uff1a\u8868\u793a\u7531\u4e8e\u9a8c\u8bc1\u635f\u5931\u503c\u4e0b\u964d\uff0c\u6a21\u578b\u88ab\u4fdd\u5b58\u3002</p> <p>Updating learning rate\uff1a\u8868\u793a\u5b66\u4e60\u7387\u88ab\u66f4\u65b0\u4e86\u3002</p> <p>to 0.0005\uff1a\u8868\u793a\u65b0\u7684\u5b66\u4e60\u7387\u662f 0.0005\u3002</p> Text Only<pre><code>    iters: 100, epoch: 2 | loss: 0.2965542\n    speed: 0.1480s/iter; left time: 4702.0987s\n</code></pre> <p>\u54e6\uff0c\u4e0d\u662f\u554a\uff0c\u8fd9\u5df2\u7ecf\u662f\u7b2c\u4e8c\u6b21\u8fed\u4ee3\u7684\u8bad\u7ec3\u4fe1\u606f\u4e86\u3002</p> <p>\u4ee5\u7b2c\u4e8c\u4e2a epoch \u4e3a\u4f8b\uff0c\u67e5\u770b\u6240\u6709\u7684\u65e5\u5fd7\u4fe1\u606f\uff1a</p> Text Only<pre><code>Updating learning rate to 0.0005\n    iters: 100, epoch: 2 | loss: 0.2965542\n    speed: 0.1480s/iter; left time: 4702.0987s\n    iters: 200, epoch: 2 | loss: 0.2877236\n    speed: 0.0264s/iter; left time: 836.8543s\n    iters: 300, epoch: 2 | loss: 0.2788590\n    speed: 0.0271s/iter; left time: 854.0580s\n    iters: 400, epoch: 2 | loss: 0.2706560\n    speed: 0.0276s/iter; left time: 868.6653s\n    iters: 500, epoch: 2 | loss: 0.2822747\n    speed: 0.0263s/iter; left time: 824.1755s\n    iters: 600, epoch: 2 | loss: 0.2616775\n    speed: 0.0269s/iter; left time: 840.6318s\n    iters: 700, epoch: 2 | loss: 0.2763505\n    speed: 0.0262s/iter; left time: 816.8357s\n    iters: 800, epoch: 2 | loss: 0.2719800\n    speed: 0.0259s/iter; left time: 804.4196s\n    iters: 900, epoch: 2 | loss: 0.2634850\n    speed: 0.0263s/iter; left time: 813.3547s\n    iters: 1000, epoch: 2 | loss: 0.2671717\n    speed: 0.0265s/iter; left time: 817.9329s\nEpoch: 2 cost time: 29.48875856399536\nEpoch: 2, Steps: 1099 | Train Loss: 0.2751775 Vali Loss: 0.2280986 Test Loss: 0.2488164\nValidation loss decreased (0.286321 --&gt; 0.228099).  Saving model ...\n</code></pre> <p>30 \u4e2a epoch\uff0c\u76f4\u63a5\u770b\u5230\u6700\u540e</p> <ul> <li>\u91cc\u9762\u8fd8\u6709\u4e00\u4e2a\u6307\u6807\u9700\u8981\u6ce8\u610f\uff1a<code>\u65e9\u505c</code> EarlyStopping counter: 3 out of 10</li> </ul> \u5173\u4e8e\u65e9\u505c <p> \u65e9\u505c\u673a\u5236\u7684\u8ba1\u6570\u5668\u3002\u5982\u679c\u9a8c\u8bc1\u635f\u5931\u5728\u8fde\u7eed 10 \u4e2a epoch \u4e2d\u6ca1\u6709\u6539\u5584\uff0c\u8bad\u7ec3\u5c06\u63d0\u524d\u505c\u6b62\u3002\u5f53\u524d\u8ba1\u6570\u5668\u503c\u4e3a 3\uff0c\u8868\u793a\u9a8c\u8bc1\u635f\u5931\u5728\u6700\u8fd1 3 \u4e2a epoch \u4e2d\u6ca1\u6709\u6539\u5584\u3002 </p> <ul> <li>\u770b\u5230\u7b2c 30 \u4e2a epoch\uff0c<code>test Loss: 0.2200698</code></li> </ul> <p>\u6700\u540e\u7684\u65e5\u5fd7\u4fe1\u606f\uff1a</p> Text Only<pre><code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;testing : Electricity_720_96_SegRNN_custom_ftM_sl720_pl96_dm512_dr0.1_rtgru_dwpmf_sl48_mae_test_0&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\ntest 5165\nmse:0.12902846932411194, mae:0.22005711495876312, ms/sample:2.1022345181933217\n</code></pre> <ul> <li> \u8fd9\u4e24\u4e2a\u54ea\u4e2a\u662f\u8bba\u6587\u7684\u7ed3\u679c\uff1f\uff08\u6700\u540e\u7684\u6d4b\u8bd5\u62a5\u544a\uff09</li> </ul> <p>\u5e26\u7740\u7ed3\u679c\u53bb\u8bba\u6587\u4e2d\u770b</p> <p>Success</p> <p>you can use </p> <p>\u65e5\u5fd7\u6587\u4ef6\u6700\u540e\u7684\u8f93\u51fa\uff1amse:0.1290, mae:0.2200    \u8bba\u6587\u4e2d\u8868\u683c\u7ed9\u7684\uff1aElectricity \u9884\u6d4b\u6b65\u957f96 MSE\uff0c0.128 &amp; MAE 0.219    \u8be5\u8bf4\u4e0d\u8bf4\uff0c\u786e\u5b9e\u662f\u4e2a\u597d\u7cbe\u5de7\u7684\u6a21\u578b\uff0c\u6211\u5c45\u7136\u5c31\u8fd9\u4e48\u6210\u529f\u7684\u6d6e\u73b0\u4e86\u8036\u3002</p> <ul> <li> <p>\u4ee5\u4e0a\u662f \u8fd9\u4e2a <code>SegRNN_Electricity_720_96.log</code>  log \u6587\u4ef6\u7684\u89e3\u8bfb\u3002\u5b8c\u6210\u4e86\u8bba\u6587\u8868 2 \u7684\u4e24\u683c\u3002</p> </li> <li> <p> \u4e3a\u4ec0\u4e48\u8bad\u7ec3\u65f6\u4e5f\u6709 test loss \uff1f</p> </li> </ul> <p>\u5728\u6bcf\u4e2a epoch \u7ed3\u675f\u65f6\u8ba1\u7b97\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u635f\u5931</p> <ul> <li> <p>checkpoints\uff0c\u5b58\u7684\u5e94\u8be5\u662f\u6700\u597d\u7684\u6a21\u578b\u53c2\u6570\uff0c\u7136\u540e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002</p> </li> <li> <p> \u8fd8\u6709\u6d88\u878d\u5b9e\u9a8c\u7684\u811a\u672c\u6587\u4ef6\u6ca1\u6709\u770b</p> </li> <li> \u6211\u590d\u73b0\u4e86\u8bba\u6587\u7684\u51e0\u683c\u7ed3\u679c\uff1f</li> </ul> <p>\u6211\u4e00\u4e2a\u4e2a\u770b\u4e86 Electricity \u590d\u73b0\u51fa\u6765\u7684\u7ed3\u679c\uff08lookback=720\uff09</p> <p><code>mse:0.19964559376239777, mae:0.28901728987693787</code></p> <p>\u8fd9\u4e2a\u7ed3\u679c 720\u2192720 \u5c45\u7136\u6bd4\u539f\u8bba\u6587\u7684\u7ed3\u679c\u8fd8\u597d\u3002</p> <p>\u522b\u7684\u5728\u5c0f\u6570\u70b9\u540e 3 \u4f4d\u6bd4\u539f\u8bba\u6587\u7ed3\u679c\u5dee\u4e00\u4e9b\u3002</p> <ul> <li> <p>ETT h1 \u7684\u590d\u73b0\u7ed3\u679c\uff0c\u504f\u5dee\u6709\u70b9\u5927\uff0cSegRNN \u5c0f\u6570\u70b9\u540e\u4e24\u4f4d\u6709\u504f\u5dee</p> </li> <li> <p>\u8fd9\u7bc7\u8bba\u6587\u5c5e\u4e8e\u771f\u6b63\u610f\u4e49\u4e0a\u7684\u590d\u73b0\u6210\u529f\u3002\u7ed3\u679c\u8dd1\u5f97\u5927\u5dee\u4e0d\u5dee\uff0c\u8bba\u6587\u4ece\u5934\u5230\u5c3e\u7684 debug\u3002</p> </li> <li>\u8bba\u6587\u7684\u73af\u5883\uff1a2\u5757 T4 \u7684\u663e\u5361\uff0c16GB</li> <li>\u770b\u770b Autoformer\u80fd\u8dd1\u51fa\u51e0\u4e2a\u7ed3\u679c\u3002</li> <li>\u5982\u679c\u6211\u7528\u5b66\u6821\u7684\u670d\u52a1\u5668\uff0c\u4e00\u4e2a\u6570\u636e\u96c6\u4e00\u4e2a\u6570\u636e\u96c6\u7684\u8dd1\uff0c\u4e5f\u80fd\u5f97\u5230\u7ed3\u679c\uff0c\u5927\u6982\u3002</li> </ul> <p>\u4f60\u77e5\u9053\uff0c\u4ec0\u4e48\u662f\u7b97\u529b\u4e0a\u7684\u78be\u538b</p> <p>AutoDL \u4e0a\u7684\u670d\u52a1\u5668 2 \u5757 4090 \u7684\u5361\u3002\uff1a</p> Text Only<pre><code>train 17597\nval 2537\ntest 5165\n    iters: 100, epoch: 1 | loss: 0.6690567\n    speed: 0.0366s/iter; left time: 1203.1702s\n</code></pre> <p>\u5b66\u9662\u7684\u670d\u52a1\u5668\uff1a</p> Text Only<pre><code>train 17597\nval 2537\ntest 5165\n    iters: 100, epoch: 1 | loss: 0.6692066\n    speed: 0.2947s/iter; left time: 9687.1735s\n</code></pre> <p>9000 \u79d2\u548c 1000 \u79d2\u7684\u533a\u522b\u3002</p> <ul> <li>\u6211\u5728\u60f3\uff0cSegRNN \u5982\u679cbaseline \u7684\u7ed3\u679c\u90fd\u662f\u4ece\u8bba\u6587\u4e2d\u6458\u8fc7\u6765\u7684\u90a3\u4e3a\u4ec0\u4e48\u5b8c\u6574\u7684\u9879\u76ee\u6587\u4ef6\u4e2d\u8fd8\u6709 Autoformer \u7684\u5b9e\u73b0</li> </ul>"},{"location":"Reproduction/6_AutoFormer/","title":"Autoformer","text":""},{"location":"Reproduction/6_AutoFormer/#autoformer","title":"Autoformer","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 17665 \u4e2a\u5b57  583 \u884c\u4ee3\u7801  100 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 96 \u5206\u949f</p>"},{"location":"Reproduction/6_AutoFormer/#github","title":"github \u6e90\u7801\u4e3b\u9875","text":"<p>Autoformer (NeurIPS 2021) \u81ea\u52a8\u6210\u578b\u673a (NeurIPS 2021)</p> <p>Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting Autoformer\uff1a\u7528\u4e8e\u957f\u671f\u5e8f\u5217\u9884\u6d4b\u7684\u5177\u6709\u81ea\u76f8\u5173\u7684\u5206\u89e3\u53d8\u538b\u5668</p> <p>Time series forecasting is a critical demand for real applications. Enlighted by the classic time series analysis and stochastic process theory, we propose the Autoformer as a general series forecasting model [paper]. Autoformer goes beyond the Transformer family and achieves the series-wise connection for the first time. \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u662f\u5b9e\u9645\u5e94\u7528\u7684\u5173\u952e\u9700\u6c42\u3002\u53d7\u7ecf\u5178\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u548c\u968f\u673a\u8fc7\u7a0b\u7406\u8bba\u7684\u542f\u53d1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Autoformer \u4f5c\u4e3a\u901a\u7528\u5e8f\u5217\u9884\u6d4b\u6a21\u578b [\u8bba\u6587]\u3002Autoformer**\u8d85\u8d8a\u4e86 Transformer \u5bb6\u65cf\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u5e8f\u5217\u8fde\u63a5\u3002**</p> <p>In long-term forecasting, Autoformer achieves SOTA, with a 38% relative improvement on six benchmarks, covering five practical applications: energy, traffic, economics, weather and disease. \u5728\u957f\u671f\u9884\u6d4b\u4e2d\uff0cAutoformer \u5b9e\u73b0\u4e86 SOTA\uff0c\u5728\u516d\u4e2a\u57fa\u51c6\u4e0a**\u76f8\u5bf9\u63d0\u5347\u4e86 38%** \uff0c\u6db5\u76d6\u4e86**\u80fd\u6e90\u3001\u4ea4\u901a\u3001\u7ecf\u6d4e\u3001\u5929\u6c14\u548c\u75be\u75c5**\u4e94\u4e2a\u5b9e\u9645\u5e94\u7528\u3002</p> <p>News (2023.08) Autoformer has been included in Hugging Face. See blog. \ud83d\udea9\u65b0\u95fb(2023.08) Autoformer \u5df2\u5305\u542b\u5728Hugging Face\u4e2d\u3002\u67e5\u770b\u535a\u5ba2\u3002</p> <p>\ud83d\udea9News (2023.06) The extension version of Autoformer (Interpretable weather forecasting for worldwide stations with a unified deep model) has been published in Nature Machine Intelligence as the Cover Article. \ud83d\udea9\u65b0\u95fb(2023.06) Autoformer \u7684\u6269\u5c55\u7248\u672c (\u4f7f\u7528\u7edf\u4e00\u6df1\u5ea6\u6a21\u578b\u4e3a\u5168\u7403\u7ad9\u70b9\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u5929\u6c14\u9884\u62a5) \u5728\u300a\u81ea\u7136\u673a\u5668\u667a\u80fd\u300b\u6742\u5fd7\u4e0a\u4f5c\u4e3a\u5c01\u9762\u6587\u7ae0\u53d1\u8868\u3002</p> <p>\ud83d\udea9News (2023.02) Autoformer has been included in our [Time-Series-Library], which covers long- and short-term forecasting, imputation, anomaly detection, and classification. \ud83d\udea9\u65b0\u95fb(2023.02) Autoformer \u5df2\u5305\u542b\u5728\u6211\u4eec\u7684[\u65f6\u95f4\u5e8f\u5217\u5e93]\u4e2d\uff0c\u5b83\u6db5\u76d6\u957f\u671f\u548c\u77ed\u671f\u9884\u6d4b\u3001\u5f52\u7eb3\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u5206\u7c7b\u3002</p> <p>\ud83d\udea9News (2022.02-2022.03) Autoformer has been deployed in 2022 Winter Olympics to provide weather forecasting for competition venues, including wind speed and temperature. \ud83d\udea9\u65b0\u95fb\uff082022.02-2022.03\uff09Autoformer \u5df2\u90e8\u7f72\u57282022 \u5e74\u51ac\u5965\u4f1a\uff0c\u4e3a\u6bd4\u8d5b\u573a\u9986\u63d0\u4f9b\u5929\u6c14\u9884\u62a5\uff0c\u5305\u62ec\u98ce\u901f\u3001\u6e29\u5ea6\u7b49\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#_1","title":"\u51c6\u5907","text":""},{"location":"Reproduction/6_AutoFormer/#git-clone","title":"git clone","text":"<p>\u514b\u9686\u8fdc\u7a0b\u4ed3\u5e93\u7684\u65b9\u6cd5\uff1a</p> <p>\uff081\uff09HTTPS\uff0c\u5728\u628a\u672c\u5730\u4ed3\u5e93\u7684\u4ee3\u7801 push \u5230\u8fdc\u7a0b\u4ed3\u5e93\u7684\u65f6\u5019\uff0c\u9700\u8981\u9a8c\u8bc1\u7528\u6237\u540d\u548c\u5bc6\u7801</p> <p>\uff082\uff09SSH\uff0cgit \u5f00\u5934\u7684\u662f SSH \u534f\u8bae\uff0c\u8fd9\u79cd\u65b9\u5f0f\u5728\u63a8\u9001\u7684\u65f6\u5019\uff0c\u4e0d\u9700\u8981\u9a8c\u8bc1\u7528\u6237\u540d\u548c\u5bc6\u7801\uff0c\u4f46\u662f\u9700\u8981\u5728 github \u4e0a\u6dfb\u52a0SSH\u516c\u94a5\u7684\u914d\u7f6e\uff08\u63a8\u8350\uff09</p> <p>\uff083\uff09zip download</p> <p>\u6211\u8fd9\u91cc\u4f7f\u7528\u4e86 SSH \u914d\u7f6e\uff1a</p> <p> </p> <p>\u670d\u52a1\u5668\u76f4\u63a5 git clone \u662f\u5f88\u6162\u3002\u6240\u4ee5\u672c\u5730 git clone\uff0c\u7136\u540e\u518d\u4e0a\u4f20\u670d\u52a1\u5668\u3002</p> <p> </p> <p>\u672c\u5730\u4e0b\u8f7d\u597d\u4ee5\u540e\uff0c\u4f7f\u7528 FileZilla\u4e0a\u4f20\u5230\u8fdc\u7a0b\u670d\u52a1\u5668</p> <p> </p> <p>down\u5230\u672c\u5730\u4ee5\u540e\uff0c\u5220\u9664 .git\u6587\u4ef6\uff0c\u53d6\u6d88\u8fde\u63a5\u7740\u8fdc\u7a0b\u4ed3\u5e93</p> <p> </p> <p> </p>"},{"location":"Reproduction/6_AutoFormer/#readme","title":"readme","text":"<p>\u4e0b\u8f7d\u6570\u636e\u96c6</p> <p>\u8bbe\u7f6e\u6570\u636e\u96c6\u8def\u5f84</p> <p> </p>"},{"location":"Reproduction/6_AutoFormer/#_2","title":"\u8c03\u8bd5\u914d\u7f6e","text":"<p>\u65b0\u5efa\u914d\u7f6e\u6587\u4ef6</p> <p> </p> <p>\u4fee\u6539\u914d\u7f6e\u6587\u4ef6</p> <p> </p> <p>\u4fee\u6539\u914d\u7f6e\u6587\u4ef6</p> Text Only<pre><code>        {\n            \"name\": \"Autoformer\",\n            \"type\": \"python\",\n            \"request\": \"attach\",\n            \"connect\": {\n                \"host\": \"localhost\",\n                \"port\": 5997\n            }\n        },\n</code></pre> <p>\u4fee\u6539 sh \u6587\u4ef6</p> Text Only<pre><code>python -m debugpy --listen 5997 --wait-for-client run.py \\\n</code></pre>"},{"location":"Reproduction/6_AutoFormer/#python","title":"\u65b0\u5efa python \u865a\u62df\u73af\u5883","text":"<p>\u672c\u5b9e\u9a8c\u6240\u9700\u8981\u7684\u5b9e\u9a8c\u73af\u5883</p> <p>Install Python 3.6, PyTorch 1.9.0.</p> <p>\u53c2\u8003\u547d\u4ee4</p> Text Only<pre><code>conda create -n dave python==3.8\nconda activate dave\nconda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=11.8 -c pytorch -c nvidia\nconda install numpy\nconda install scikit-image\nconda install scikit-learn\nconda install tqdm\nconda install pycocotools\n</code></pre> <p>\u6fc0\u6d3b\u3001\u9000\u51fa\uff1a</p> Text Only<pre><code># To activate this environment, use               \n#     $ conda activate Autoformer\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n</code></pre> <p>\u7528 requirements.txt \u5b89\u88c5\u9700\u8981\u7684\u5e93</p> Text Only<pre><code>conda create -n SegRNN python=3.8\nconda activate SegRNN\npip install -r requirements.txt\n</code></pre> <p>\u542f\u52a8 sh \u6587\u4ef6\uff1a</p> Text Only<pre><code>sh run_main.sh\n</code></pre> <p>\u9002\u7528\u4e8e\u672c\u5b9e\u9a8c\u7684\u6240\u6709\u547d\u4ee4 :</p> Python<pre><code>conda create -n Autoformer python=3.6\nconda activate Autoformer\n</code></pre> Python<pre><code>conda env list\nconda actiavte \u73af\u5883\u540d\nconda deactivate\n</code></pre> <p>pytorch \u5b98\u7f51\u67e5\u770b\u6240\u9700\u547d\u4ee4</p> <p> </p> <p></p> Text Only<pre><code>conda install pytorch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 cudatoolkit=10.2 -c pytorch\n</code></pre>"},{"location":"Reproduction/6_AutoFormer/#requirements","title":"requirements","text":"Text Only<pre><code>pip install -r requirements.txt\n</code></pre> <p>\u6216\u8005\uff1a</p> Text Only<pre><code>conda create -n Autoformer python=3.6\nconda activate Autoformer\nconda install pytorch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 cudatoolkit=10.2 -c pytorch\nconda install pandas\nconda install scikit-learn\nconda install debugpy\nconda install matplotlib\nconda install reformer_pytorch\n</code></pre> <p>\u914d\u7f6e\u597d\u4ee5\u540e\uff0c\u6210\u529f\u8fdb\u5165\u8c03\u8bd5\uff1a</p> <p> </p>"},{"location":"Reproduction/6_AutoFormer/#_3","title":"\u5f00\u59cb\u8c03\u8bd5","text":"<p>\u4ee3\u7801\u76f8\u4f3c\u5ea6\u6781\u9ad8\u3002</p> <p>Autoformer init\uff1a36\uff0818\uff09-\u300b24</p> <p></p> <p>setting:</p> Text Only<pre><code>ili_36_24_Autoformer_custom_ftM_sl36_ll18_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0\n</code></pre> <p>model_id  36 \u9884\u6d4b 24 \u6b65\u957f\uff08label=18\uff09\u3001AutoFormer \u6a21\u578b\uff0c\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\uff0c\u9884\u6d4b\u591a\u53d8\u91cf\uff0c\u8f93\u5165\u5e8f\u5217 36\uff0c\u6807\u7b7e\u5e8f\u5217 18\uff0c\u9884\u6d4b\u5e8f\u5217 24\uff0c\u5d4c\u5165\u7ef4\u5ea6 512\uff0c\u6ce8\u610f\u529b\u5934\u6570 8\uff0c2\u5c42\u7f16\u7801\u5c42\uff0c1 \u5c42\u89e3\u7801\u5c42\uff0c</p> Text Only<pre><code>df2048_fc3_ebtimeF_dtTrue_Exp_0\n                args.d_ff,\n                args.factor,\n                args.embed,\n                args.distil,\n                args.des, ii)\n</code></pre> <p>Autoformer model</p> Python<pre><code>Model(\n  (decomp): series_decomp(\n    (moving_avg): moving_avg(\n      (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n    )\n  )\n  (enc_embedding): DataEmbedding_wo_pos(\n    (value_embedding): TokenEmbedding(\n      (tokenConv): Conv1d(7, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n    )\n    (position_embedding): PositionalEmbedding()\n    (temporal_embedding): TimeFeatureEmbedding(\n      (embed): Linear(in_features=4, out_features=512, bias=False)\n    )\n    (dropout): Dropout(p=0.05, inplace=False)\n  )\n  (dec_embedding): DataEmbedding_wo_pos(\n    (value_embedding): TokenEmbedding(\n      (tokenConv): Conv1d(7, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n    )\n    (position_embedding): PositionalEmbedding()\n    (temporal_embedding): TimeFeatureEmbedding(\n      (embed): Linear(in_features=4, out_features=512, bias=False)\n    )\n    (dropout): Dropout(p=0.05, inplace=False)\n  )\n  (encoder): Encoder(\n    (attn_layers): ModuleList(\n      (0): EncoderLayer(\n        (attention): AutoCorrelationLayer(\n          (inner_correlation): AutoCorrelation(\n            (dropout): Dropout(p=0.05, inplace=False)\n          )\n          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n        (decomp1): series_decomp(\n          (moving_avg): moving_avg(\n            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n          )\n        )\n        (decomp2): series_decomp(\n          (moving_avg): moving_avg(\n            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n          )\n        )\n        (dropout): Dropout(p=0.05, inplace=False)\n      )\n      (1): EncoderLayer(\n        (attention): AutoCorrelationLayer(\n          (inner_correlation): AutoCorrelation(\n            (dropout): Dropout(p=0.05, inplace=False)\n          )\n          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n        (decomp1): series_decomp(\n          (moving_avg): moving_avg(\n            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n          )\n        )\n        (decomp2): series_decomp(\n          (moving_avg): moving_avg(\n            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n          )\n        )\n        (dropout): Dropout(p=0.05, inplace=False)\n      )\n    )\n    (norm): my_Layernorm(\n      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (decoder): Decoder(\n    (layers): ModuleList(\n      (0): DecoderLayer(\n        (self_attention): AutoCorrelationLayer(\n          (inner_correlation): AutoCorrelation(\n            (dropout): Dropout(p=0.05, inplace=False)\n          )\n          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attention): AutoCorrelationLayer(\n          (inner_correlation): AutoCorrelation(\n            (dropout): Dropout(p=0.05, inplace=False)\n          )\n          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (conv1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n        (conv2): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n        (decomp1): series_decomp(\n          (moving_avg): moving_avg(\n            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n          )\n        )\n        (decomp2): series_decomp(\n          (moving_avg): moving_avg(\n            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n          )\n        )\n        (decomp3): series_decomp(\n          (moving_avg): moving_avg(\n            (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n          )\n        )\n        (dropout): Dropout(p=0.05, inplace=False)\n        (projection): Conv1d(512, 7, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n      )\n    )\n    (norm): my_Layernorm(\n      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (projection): Linear(in_features=512, out_features=7, bias=True)\n  )\n)\n</code></pre> <p>\u6570\u636e\u96c6\u7684\u52a0\u8f7d\u662f\u5b8c\u5168\u4e00\u6837\u7684\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#encoder-embedding","title":"encoder embedding","text":"<p>\u76ee\u7684\uff1a\u7ed3\u5408\u65f6\u95f4\u7279\u5f81\uff0c\u5c06 \u6570\u636e\u7279\u5f81\u5d4c\u5165\u5230\u6307\u5b9a\u7ef4\u5ea6</p> Python<pre><code>enc_out = self.enc_embedding(x_enc, x_mark_enc)\n</code></pre> Python<pre><code>self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, configs.embed, configs.freq,configs.dropout)\n</code></pre> <p></p> <p></p> <p>\u6d41\u7a0b\u56fe</p> Python<pre><code>\u8f93\u5165:\nx_enc [B, L, D]        x_mark_enc [B, L, time_features]\n    |                        |\n    v                        v\n+-----------------------------------------------+\n|           Model.forward()\u8c03\u7528                  |\n|      self.enc_embedding(x_enc, x_mark_enc)    |\n+-----------------------------------------------+\n            |                |\n            v                v\n+------------------------+  +---------------------------+\n| TokenEmbedding (\u503c\u5d4c\u5165) |  | TemporalEmbedding (\u65f6\u95f4\u5d4c\u5165)|\n+------------------------+  +---------------------------+\n| \u8f93\u5165: x [B, L, D]      |  | \u8f93\u5165: x_mark [B, L, time_f]|\n|                        |  |                           |\n| \u64cd\u4f5c:                  |  | \u64cd\u4f5c:                     |\n| 1.\u8f6c\u7f6e: [B, D, L]      |  | 1.\u8f6c\u6362\u4e3along\u7c7b\u578b          |\n| 2.1D\u5377\u79ef: D -&gt; d_model |  | 2.\u63d0\u53d6\u65f6\u95f4\u7279\u5f81:           |\n| 3.\u8f6c\u7f6e\u56de: [B, L, d_model]|  |   - month_x (x[:,:,0])   |\n|                        |  |   - day_x (x[:,:,1])      |\n| \u8f93\u51fa: [B, L, d_model]  |  |   - weekday_x (x[:,:,2])  |\n|                        |  |   - hour_x (x[:,:,3])     |\n+------------------------+  |   - minute_x (\u53ef\u9009)       |\n            |               |                           |\n            |               | 3.\u67e5\u8868\u83b7\u53d6\u5404\u65f6\u95f4\u7279\u5f81\u7684\u5d4c\u5165  |\n            |               | 4.\u5c06\u6240\u6709\u65f6\u95f4\u5d4c\u5165\u76f8\u52a0       |\n            |               |                           |\n            |               | \u8f93\u51fa: [B, L, d_model]     |\n            |               +---------------------------+\n            |                        |\n            +------------+------------+\n                         v\n            +---------------------------+\n            | \u76f8\u52a0\u5e76\u5e94\u7528Dropout         |\n            | value_emb + temporal_emb |\n            +---------------------------+\n                         |\n                         v\n                  \u8f93\u51fa: enc_out\n                 [B, L, d_model]\n</code></pre> <ol> <li>\u503c\u5d4c\u5165 (TokenEmbedding):    - \u901a\u8fc7\u5377\u79ef\u64cd\u4f5c\u5c06\u539f\u59cb\u7279\u5f81 [B, L, D] \u6620\u5c04\u5230\u66f4\u9ad8\u7ef4\u5ea6\u8868\u793a [B, L, d_model]    - \u4f7f\u7528\u5faa\u73af\u586b\u5145\u76841D\u5377\u79ef\u6355\u83b7\u5c40\u90e8\u7279\u5f81\u6a21\u5f0f</li> <li>\u65f6\u95f4\u5d4c\u5165 (TemporalEmbedding):    - \u5c06\u65f6\u95f4\u6807\u8bb0 [B, L, time_features] \u8f6c\u6362\u4e3a [B, L, d_model] \u7684\u5d4c\u5165\u5411\u91cf    - \u5206\u522b\u4e3a\u6708\u3001\u65e5\u3001\u661f\u671f\u3001\u5c0f\u65f6\u7b49\u65f6\u95f4\u7279\u5f81\u67e5\u8868\u83b7\u53d6\u5d4c\u5165\uff0c\u7136\u540e\u76f8\u52a0    - \u65f6\u95f4\u5d4c\u5165\u5e2e\u52a9\u6a21\u578b\u8bc6\u522b\u65f6\u95f4\u6a21\u5f0f(\u5b63\u8282\u6027\u3001\u6bcf\u65e5/\u6bcf\u5468\u5468\u671f\u7b49)</li> <li>\u7ec4\u5408\u5d4c\u5165:    - \u5c06\u503c\u5d4c\u5165\u548c\u65f6\u95f4\u5d4c\u5165\u76f8\u52a0\uff0c\u5f62\u6210\u6700\u7ec8\u7f16\u7801\u5668\u8f93\u5165 [B, L, d_model]    - \u6ce8\u610f\u6b64\u7248\u672c\u4e0d\u5305\u542b\u4f4d\u7f6e\u5d4c\u5165(DataEmbedding_wo_pos)</li> </ol> <p>\u8fd9\u79cd\u591a\u91cd\u5d4c\u5165\u65b9\u5f0f\u4f7f\u6a21\u578b\u80fd\u540c\u65f6\u5229\u7528\u65f6\u95f4\u5e8f\u5217\u7684\u503c\u4fe1\u606f\u548c\u65f6\u95f4\u7279\u5f81\u4fe1\u606f\uff0c\u4e3a\u540e\u7eed\u7684\u6ce8\u610f\u529b\u673a\u5236\u548c\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u63d0\u4f9b\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#_4","title":"\u6a21\u578b\u5b9a\u4e49","text":""},{"location":"Reproduction/6_AutoFormer/#_5","title":"\u7f16\u7801\u5668 \u89e3\u7801\u5668\u90e8\u5206","text":"<pre><code>classDiagram\n    class Model {\n        +DataEmbedding_wo_pos enc_embedding\n        +DataEmbedding_wo_pos dec_embedding\n        +Encoder encoder\n        +Decoder decoder\n        +series_decomp decomp\n        +forward(x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\n    }\n\n    class Encoder {\n        +List~EncoderLayer~ layers\n        +my_Layernorm norm_layer\n        +forward(x, attn_mask)\n    }\n\n    class EncoderLayer {\n        +AutoCorrelationLayer attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, attn_mask)\n    }\n\n    class AutoCorrelationLayer {\n        +AutoCorrelation attention\n        +Linear query_projection\n        +Linear key_projection\n        +Linear value_projection\n        +Linear out_projection\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class AutoCorrelation {\n        +bool mask_flag\n        +int factor\n        +float scale\n        +Dropout dropout\n        +bool output_attention\n        +time_delay_agg_training(values, corr)\n        +time_delay_agg_inference(values, corr)\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class Decoder {\n        +List~DecoderLayer~ layers\n        +my_Layernorm norm_layer\n        +Linear projection\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    class DecoderLayer {\n        +AutoCorrelationLayer self_attention\n        +AutoCorrelationLayer cross_attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    Model --&gt; Encoder\n    Model --&gt; Decoder\n    Encoder --&gt; EncoderLayer\n    EncoderLayer --&gt; AutoCorrelationLayer\n    EncoderLayer --&gt; Conv1d\n    EncoderLayer --&gt; series_decomp\n    AutoCorrelationLayer --&gt; AutoCorrelation\n    Decoder --&gt; DecoderLayer\n    DecoderLayer --&gt; AutoCorrelationLayer\n    DecoderLayer --&gt; Conv1d\n    DecoderLayer --&gt; series_decomp\n</code></pre>"},{"location":"Reproduction/6_AutoFormer/#_6","title":"\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5f62\u72b6\u53d8\u6362","text":"<p>\uff081\uff09</p> <p>\u4ee3\u7801\uff1a</p> <p> </p> <p>\u9010\u5b57\u8bb2\u89e3\uff1a</p> <p>model \u8bad\u7ec3\u4ece exp_main.py\u7684 train \u51fd\u6570\u5f00\u59cb\uff0cepoch \u8868\u793a\u6574\u4e2a\u8bad\u7ec3\u96c6\u8fed\u4ee3\u51e0\u6b21\uff0cfor batchx\u3001batchy\u3001batch x mark\u3001batch y mark \u4e00\u4e2a\u6279\u6b21\u4e00\u4e2a\u6279\u6b21\u7684\u8bad\u7ec3\uff0c\u7b2c\u4e00\u4e2a for \u8bad\u7ec3\u7684 epoch \u662f\u6211\u4eec\u81ea\u5df1\u53ef\u4ee5\u8bbe\u7f6e\u7684\uff0c\u7b2c\u4e8c\u4e2a for \u8bad\u7ec3\u7684 iteration \u8fed\u4ee3\u6b21\u6570\u662f <code>\u6570\u636e\u96c6\u957f\u5ea6 \u2797 batch size</code></p> <p>\u63a5\u4e0b\u6765\uff0c\u8c03\u7528 <code>self._predict</code> \u65b9\u6cd5\u8fdb\u884c\u9884\u6d4b\uff0c\u8fd9\u91cc predict \u51fd\u6570\u9700\u8981\u7684\u53c2\u6570 batchx\u3001batchy\u3001batch x mark\u3001batch y mark \u5f62\u72b6\u5206\u522b\u662f <code>batch_x = [32,36,7], batch_y = [32,42(18+24),7],batch_x_mark=[32,36,4],batch_y_mark = [32,42,4]</code></p> <p>32 \u8868\u793a \u4e00\u4e2a batch \u6837\u672c\u7684\u4e2a\u6570\uff1b</p> <p>36 \u8868\u793a\u6bcf\u4e2a\u6837\u672c\u7684\u65f6\u95f4\u6b65\uff0c\u4e5f\u53ef\u4ee5\u8bf4\u662f\u56de\u6eaf\u7a97\u53e3\u7684\u5927\u5c0f\uff0c\u6216\u8005\u53eb\u8f93\u5165\u5e8f\u5217\u7684\u957f\u5ea6</p> <p>7 \u8868\u793a illness \u6570\u636e\u96c6\u7684\u7279\u5f81\u6570</p> <p>batchy \u7684 42 \u8868\u793a 18 \u7684 label length\uff0c\u662f\u53d6\u7684 \u539f\u59cb\u8f93\u5165\u5e8f\u5217\u7684 \u4e8c\u5206\u4e4b\u4e00\uff0c\u8fd9\u4e2a\u5728\u8bba\u6587\u4e2d\u6709\u8bf4</p> <p> </p> <p>\u7f16\u7801\u5668\u7684\u8f93\u5165 \u662f <code>I times d</code> \\(I\\) \u8868\u793a \u8f93\u5165\u5e8f\u5217\u957f\u5ea6\uff0c\u5728\u8fd9\u91cc\u4f8b\u5b50\u5c31\u662f 36\uff0c\\(d\\) \u662f\u7279\u5f81\u6570\uff0c\u8fd9\u91cc\u7684\u7279\u5f81\u6570\uff0c\u90fd\u53bb\u6389\u4e86\u65f6\u95f4\u6233\uff0c\u4e5f\u5c31\u662f 7</p> <p>\u89e3\u7801\u5668\u7684\u8f93\u5165\u662f <code>\u4e8c\u5206\u4e4b I + O</code>\uff0c<code>\u4e8c\u5206\u4e4b I</code>\u8868\u793a \u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u7684\u4e00\u534a\uff0c<code>O</code> \u8868\u793a\u9884\u6d4b\u6b65\u957f\uff0c\u4e5f\u5c31\u662f\u8f93\u51fa\u5e8f\u5217\u7684\u957f\u5ea6</p> <p>batch x mark\uff0cbatch y mark \u5c31\u662f\u5904\u7406\u7684\u65f6\u95f4\u6233\u7279\u5f81\u4e86\uff0c\u5305\u542b\u4e00\u5929\u7684\u7b2c\u51e0\u4e2a\u5c0f\u65f6\uff0c\u4e00\u4e2a\u6708\u7684\u7b2c\u51e0\u5929\uff0c\u4e00\u5468\u7684\u7b2c\u51e0\u5929\uff0c\u4e00\u4e2a\u6708\u7684\u7b2c\u51e0\u5929\uff0c\u5c31\u662f\u6211\u4eec\u4e4b\u524d\u8bb2\u8fc7\u7684 SegRNN\uff0c\u8fd9\u91cc\u5904\u7406\u8fd8\u6d89\u53ca\u4e86 \u5f52\u4e00\u5316 \u548c\u4e2d\u5fc3\u5316\uff0c\u4e0d\u518d\u91cd\u590d\u5566\u3002</p> <p>\u597d\u4e86\uff0c\u63a5\u4e0b\u6765\u8fdb\u5165 \u9884\u6d4b\u90e8\u5206\uff0c\u6b65\u8fdb\uff0c\u4e5f\u5c31\u662f predict \u51fd\u6570 </p> <p>\u9996\u5148\uff0c\u6784\u9020\u5b8c\u6574\u7684\u89e3\u7801\u5668\u8f93\u5165\uff0c\u5177\u4f53\u7684\u64cd\u4f5c\u662f\uff0c\u5207\u7247 batch y \u4e2d\u7684\u9884\u6d4b\u6b65\u957f\uff0c\u586b\u5145 0\uff0c\u5e76\u4e0e \u4e4b\u524d\u7684 label length \u8fdb\u884c\u62fc\u63a5\u3002\u4e5f\u5c31\u662f\u8fd9\u4e24\u884c\u4ee3\u7801</p> Python<pre><code># decoder input \n# \u521b\u5efa\u89e3\u7801\u5668\u8f93\u5165\u7684\u96f6\u5f20\u91cf\u90e8\u5206\uff0c\u7528\u4e8e\u9884\u6d4b\u672a\u6765\u65f6\u95f4\u6b65\n# batch_y[B, label_len+pred_len, D] -&gt; \u5207\u7247 -&gt; [B, pred_len, D] -&gt; \u521b\u5efa\u76f8\u540c\u5f62\u72b6\u5168\u96f6\u5f20\u91cf -&gt; dec_inp[B, pred_len, D]\ndec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n\n# \u5c06\u5386\u53f2\u6570\u636e(\u6807\u7b7e\u5e8f\u5217)\u4e0e\u96f6\u5f20\u91cf\u8fde\u63a5\uff0c\u5f62\u6210\u5b8c\u6574\u7684\u89e3\u7801\u5668\u8f93\u5165\uff0c\u5e76\u79fb\u52a8\u5230\u6307\u5b9a\u8bbe\u5907\n# [B, label_len, D] + [B, pred_len, D] -&gt; torch.cat\u6cbf\u7ef4\u5ea61\u62fc\u63a5 -&gt; [B, label_len+pred_len, D] -&gt; to(device) -&gt; \u5728GPU\u4e0a\u7684dec_inp\ndec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n</code></pre> <p>\u6784\u9020\u7684\u5b8c\u6574\u89e3\u7801\u5668\u7684\u8f93\u5165\uff0c\u5f62\u72b6\u8fd8\u662f 32,42,7\u3002</p> <p>\uff08\u8fd9\u91cc\u7684\u4ee3\u7801\u5e76\u4e0d\u662f\u90a3\u4e48\u91cd\u8981\uff0c\u6240\u4ee5\u5c31\u4e0d\u7c98\u8d34\u4e86\uff0c\u5360\u5730\u65b9\uff09\u63a5\u4e0b\u6765\u662f\u4e00\u4e2a\u5185\u90e8\u65b9\u6cd5 run model\uff0c\u7c7b\u4f3c forward\uff0c\u4f46\u56e0\u4e3a\u4e0d\u662f\u4e00\u4e2a\u5177\u4f53\u7684\u6a21\u578b\uff0c\u6240\u4ee5\u5c31\u53eb run model\u4e86\uff0c\u7c7b\u5185\u8c03\u7528\u4e86\u8fd9\u4e2a\u51fd\u6570\uff0c\u624d\u4f1a\u6267\u884c\uff0c\u8fd9\u91cc\u6ca1\u6709\u8c03\u7528\uff0c\u8fdb\u5165\u4e0b\u4e00\u6b65\uff0c\u5224\u65ad\u662f\u5426\u91c7\u7528\u4e86\u81ea\u52a8\u7cbe\u5ea6\u8bad\u7ec3\uff0c\u6211\u4e5f\u4e0d\u660e\u767d\uff0c\u5927\u6982\u662f\u6a21\u578b\u52a0\u901f\u628a\uff0c\u603b\u4e4b\u662f false\uff0c\u6267\u884c else\u3002</p> Python<pre><code>else:\n    # \u4f7f\u7528\u666e\u901a\u7cbe\u5ea6\u6267\u884c\u6a21\u578b\u8ba1\u7b97\n    # _run_model() -&gt; outputs[B, label_len+pred_len, D]\n    outputs = _run_model()\n</code></pre> <p>\u8c03\u7528\u7684\u5185\u90e8\u65b9\u6cd5 <code>_run_model()</code>\uff0c\u6b65\u8fdb\uff0c\u8fdb\u5165\u5230 run model \u5185\u90e8\u3002</p> <p></p> <p>\u9996\u5148\uff0c\u8fd9\u91cc\u7684 self.model \u662f <code>Exp_Basic</code>\u4e2d\u7684 <code>build_model</code> \u5b9a\u4e49\u6765\u7684\uff0c\u800c\u4e14<code>exp_main</code> \uff0c <code>Basic</code> \u7684\u5b50\u7c7b \u91cd\u5199\u4e86 \u7236\u7c7b\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b57\u5178\uff0c\u952e\u662f\u5b57\u7b26\u4e32\uff0c\u503c\u7684\u7c7b\uff0c\u7d22\u5f15\u8fdb\u884c\u7c7b\u7684\u521d\u59cb\u5316\uff0c\u8fd9\u4e2a\u4e5f\u662f SegRNN \u4e2d\u4ecb\u7ecd\u8fc7\u7684\u3002\u603b\u4e4b\uff0c\u8fd9\u91cc\u7684 <code>self.model</code> \u662f <code>Autoformer</code> </p> <p></p> <p>\u70b9\u51fb\u6b65\u8fdb\uff0c\u8fdb\u5165 Autoformer \u7684 forward \u4e2d\u3002\u4e00\u4e2a batch \u4e2d\u6837\u672c\u7684\u5904\u7406 </p>"},{"location":"Reproduction/6_AutoFormer/#autoformer-forward","title":"Autoformer  forward","text":"<p>\u9996\u5148\uff0c\u8fd9\u91ccAutoformer  forward \u63a5\u6536\u7684\u53c2\u6570\uff1a</p> Python<pre><code>def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n            enc_self_mask=None, \n            dec_self_mask=None, \n            dec_enc_mask=None):\n</code></pre> <p>\u5fc5\u987b\u4f20\u5165\u7684\u53c2\u6570 \u662f  <code>x_enc, x_mark_enc, x_dec, x_mark_dec</code> \u6211\u4eec\u8fd9\u91cc\u5c31\u662f <code>batch x\uff0cbatch y\uff0cbatch x mark\uff0cbatch y mark</code>\uff0c\u4e14\u5f62\u72b6\u5206\u522b\u662f <code>[32,36,7]\u3001[32,42,7]\u3001[32,36,4]\u3001[32,42,4]</code></p> <p>\u53ef\u9009\u53c2\u6570\u662f Transformer \u4e2d\u7684 3 \u4e2a mask\uff0c\u9ed8\u8ba4\u662f None\u3002\u89e3\u91ca\u4e00\u4e0b Transformer \u4e2d\u7684\u4e09\u4e2a mask \u5206\u522b\u662f\u4ec0\u4e48\uff1a</p> <p>\u4e09\u4e2amask\u673a\u5236\uff0c\u5206\u522b\u6307\u7684\u662f</p> <ul> <li>\u7b2c\u4e00\u4e2a \u7f16\u7801\u7aef\u8f93\u2f0a \u7531\u4e8epadding\u5b57\u7b26\u7684mask\uff0c\u4e3a\u4e86\u2f00\u4e2abatchsize\u4e2d\uff0c\u6240\u6709\u957f\u5ea6\u4e0d\u76f8\u540c\u7684\u6837\u672c\uff0c\u80fd\u6784\u6210\u2f00\u4e2a\u77e9\u9635\uff0c\u6240\u4ee5\u6709pad\u5b57\u7b26\uff0c\u4f46\u662f\u5728\u540e\u2faf\u8fdb\u2f8finputencoder\u7684\u2f83\u6ce8\u610f\u2f12\u8ba1\u7b97\u65f6\uff0cpad\u5b57\u7b26\u4e0d\u80fd\u5f71\u54cd\u8ba1\u7b97\u7ed3\u679c\uff0c\u6240\u4ee5\u9700\u8981mask\uff1b</li> <li>\u7b2c\u2f06\u4e2amask\u662f\u89e3\u7801\u7aef\u7684mask\uff0c\u8fd9\u4e2amask\u662f\u6d89\u53ca\u5230\u56e0\u679c\u7684mask\uff0c\u56e0\u4e3aTransformer\u662f\u2f00\u4e2a\u2f83\u56de\u5f52\u6a21\u578b\uff0c\u5728\u8fdb\u2f8f\u8fd0\u7b97\u65f6\uff0c\u4e3a\u4e86\u5e76\u2f8f\u8ba1\u7b97\uff0c\u6211\u4eec\u662f\u628ainputs\u548coutputs\u2f00\u8d77\u5582\u7ed9\u6a21\u578b\u7684\uff0cinputs\u76f4\u63a5\u7ed9\u6a21\u578b\u6ca1\u4e8b\uff0c\u4f46\u662foutputs\u5728\u5f97\u5230\u6700\u540e\u7684\u8f93\u51fa\u65f6\uff0c\u4e0d\u80fd\u501f\u52a9\u672a\u6765\u4fe1\u606f\uff0c\u53ea\u80fd\u662f\u5f53\u524d\u65f6\u523b\u53ca\u5176\u4e4b\u524d\u65f6\u523b\u7684\u8f93\u51fa\uff0c\u6240\u4ee5\u9700\u8981\u2f00\u4e2amask\u673a\u5236\uff0c\u8fd9\u4e2amask\u662f\u2f00\u4e2a\u4e0a\u4e09\u89d2\u77e9\u9635\uff0c\u4fdd\u8bc1\u5728\u9884\u6d4b\u5f53\u524d\u8f93\u51fa\u65f6\uff0c\u4e0d\u4f1a\u501f\u52a9\u672a\u6765\u4fe1\u606f\u3002</li> <li>\u7b2c\u4e09\u4e2amask\uff0c\u662f\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684\u4ea4\u4e92\u6ce8\u610f\u2f12\uff0c\u7f16\u7801\u5668\u7684\u8f93\u51fa\u4f5c\u4e3akey\u548cvalue\uff0c\u89e3\u7801\u5668\u7684\u8f93\u51fa\u4f5c\u4e3aquery\uff0c\u56e0\u4e3a\u2f6c\u6807\u5e8f\u5217 \u6bcf\u4e2a\u6837\u672c\u7684\u957f\u5ea6\u662f\u4e0d\u2f00\u6837\u7684\uff0c\u540c\u65f6\u539f\u5e8f\u5217\u7684\u6837\u672c\u957f\u5ea6\u4e5f\u662f\u4e0d\u2f00\u6837\u7684\uff0c\u2f7d\u4e14\u2f00\u5bf9\u4e4b\u95f4 \u957f\u5ea6\u4e5f\u662f\u4e0d\u2f00\u6837\u7684\uff0c\u6240\u4ee5\u9700\u8981\u2f00\u4e2amask \u5c06\u539f\u5e8f\u5217\u4e2d\u67d0\u4e2a\u5355\u8bcd\u67d0\u4e2a\u4f4d\u7f6e \u8ddf \u2f6c\u6807\u5e8f\u5217\u4e2d \u67d0\u4e2a\u4f4d\u7f6e \u5982\u679c\u5b83\u4eec\u4e4b\u95f4 \u6709\u2f00\u4e2apad\u7684\u8bdd \u8bf4\u660e\u662f\u2f46\u6548\u5b57\u7b26\uff0c\u5f97\u5230\u8fd9\u6837\u7684\u63a9\u7801\u77e9\u9635\u3002</li> </ul> <p>\u7f16\u7801\u5668\u4ee5\u53ca \u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684 mask \u662f\u4e3a\u4e86\u4fdd\u8bc1\u957f\u5ea6\u7684\u5bf9\u9f50\uff0c\u89e3\u7801\u5668\u7684 mask \u662f\u4e3a\u4e86\u5728\u9884\u6d4b\u65f6 \u907f\u514d\u770b\u5230\u672a\u6765\u7684\u4fe1\u606f</p> <p>\u56de\u5230 Autoformer \u8fd9\u91cc\uff0c\u770b\u8fd9\u4e2a\u6a21\u578b\u662f\u600e\u4e48\u5904\u7406\uff0c\u8f93\u5165\u6570\u636e\u548c\u8f93\u51fa\u6570\u636e\uff0c\u4ee5\u53ca\u6a21\u578b\u7684\u521b\u65b0\u662f\u600e\u4e48\u5b9e\u73b0\u7684\u3002</p> <p>\u9996\u5148\uff0c\u770b\u5230\u4e0b\u9762\u8fd9\u51e0\u884c\u4ee3\u7801\u3002</p> <p></p> <p>\u8fd9\u51e0\u884c\u4ee3\u7801\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u89e3\u7801\u5668\u7684\u8f93\u5165\u7684\u521d\u59cb\u5316\uff0c\u7f16\u7801\u5668\u9636\u6bb5\u662f\u7528\u4e0d\u5230\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#_7","title":"\u5e8f\u5217\u5206\u89e3","text":"<p>\u770b\u8bba\u6587 \u8f93\u5165\u5e8f\u5217\u7684\u8d8b\u52bf\u5e8f\u5217\u548c\u5b63\u8282\u8d8b\u52bf\u662f\u600e\u4e48\u63d0\u53d6\u7684\u3002 </p> <p>\u672c\u6587\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a \u8d8b\u52bf\u5e8f\u5217\u548c\u5b63\u8282\u5411\u91cf</p> <p></p> <p>\u8d8b\u52bf\u5411\u91cf\u53cd\u6620\u4e86\u6570\u636e\u7684\u957f\u671f\u53d8\u5316\u8d8b\u52bf\u548c\u5b63\u8282\u8d8b\u52bf\u3002\u5e76\u4e14\u8bba\u6587\u4e2d\u63d0\u5230 \u5bf9\u4e8e\u672a\u6765\u5e8f\u5217\u8fdb\u884c\u5206\u89e3\u662f\u4e0d\u73b0\u5b9e\u7684\uff0c\u56e0\u4e3a\u672a\u6765\u7684\u6240\u6709\u5e8f\u5217\u90fd\u662f\u4e0d\u77e5\u9053\u7684\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u539f\u6587\u63d0\u51fa\u4e86 \u5e8f\u5217\u5206\u89e3\u6a21\u5757\uff0c\u601d\u60f3\u662f \u4ece\u9884\u6d4b\u7684\u4e2d\u95f4\u9690\u85cf\u53d8\u91cf\u4e2d \u9010\u6b65\u63d0\u53d6 \u957f\u671f\u7a33\u5b9a\u7684\u8d8b\u52bf \u3002</p> <p>\u5177\u4f53\u7684\u505a\u6cd5\uff0c\u4f7f\u7528\u79fb\u52a8\u5e73\u5747\u6765\u5e73\u6ed1\u5468\u671f\u6027\u6ce2\u52a8\u6765\u7a81\u51fa\u957f\u671f\u8d8b\u52bf\u3002</p> <p>\u6587\u4e2d\u4e5f\u7ed9\u51fa\u4e86\u516c\u5f0f\uff1a</p> <p></p> <p>\u516c\u5f0f\u7684\u89e3\u91ca\uff1a\u5bf9\u4e8e\u957f\u5ea6 \u4e3a L \u7684\u8f93\u5165\u5e8f\u5217 X \uff0c\u5f62\u72b6\u662f L\u00d7d\uff0c\u4f7f\u7528\u5e73\u5747\u6c60\u5316\u8fdb\u884c\u79fb\u52a8\u5e73\u5747\uff0c\u5e76\u4e14\u4f7f\u7528\u586b\u5145\u64cd\u4f5c\u4fdd\u6301\u5e8f\u5217\u957f\u5ea6\u4e0d\u53d8\u3002\u540e\u9762\u7528\u4e00\u4e2a SeriesDecomp(X)\u6765\u8868\u793a \u4e0a\u9762\u7684\u8fc7\u7a0b\uff0c\u7b80\u5316\u4e00\u4e0b\u8bb0\u53f7\u3002</p> <p>\u8bba\u6587\u4e2d\u7684\u6a21\u578b\u7ed3\u6784\u56fe\u4e5f\u6709\u753b\u51fa\u8fd9\u90e8\u5206</p> <p></p> <p>\u9996\u5148 \u7bad\u5934\u6307\u7684\u5730\u65b9\u65f6 \u76f4\u89c2\u5730\u663e\u793a\u4e86 \u8f93\u5165\u5e8f\u5217 \u8d8b\u52bf\u5e8f\u5217 \u548c \u5b63\u8282\u5e8f\u5217\u662f\u600e\u4e48\u6765\u7684\u3002\u8f93\u5165\u5e8f\u5217 \u7684 \u8d8b\u52bf\u5e8f\u5217 \u662f\u5bf9 \u8f93\u5165\u5e8f\u5217 \u53bb\u5747\u503c\uff1b\u5b63\u8282\u4fe1\u606f\uff0c\u4e5f\u5c31\u662f\u5468\u671f\u6ce2\u52a8\u4fe1\u606f\u662f \u8f93\u5165\u5e8f\u5217 - \u5747\u503c \uff0c\u8fd9\u4e2a\u5468\u671f\u6ce2\u52a8\u4fe1\u606f \u662f\u56f4\u7ed5 0 \u8fdb\u884c\u6ce2\u52a8\u7684\u3002\u57fa\u4e8e\u5bf9\u8f93\u5165\u5e8f\u5217\u7684\u5206\u89e3\u7684\u8ba4\u8bc6\uff0c\u5bf9\u4e8e\u89e3\u7801\u5668 \u8d8b\u52bf\u5e8f\u5217 \u548c \u5b63\u8282\u5e8f\u5217\u7684 \u521d\u59cb\u5316\u4e5f\u662f\u5f88\u6709\u9053\u7406\u7684\u3002</p> <p>\u56fe\u7247\u7684\u4e0b\u534a\u90e8\u5206\uff0c\u662f\u89e3\u7801\u5668\u7684\u8f93\u5165\uff0c\u663e\u793a\u4e86 \u9884\u6d4b\u5e8f\u5217 \u8d8b\u52bf\u5e8f\u5217\u548c\u5b63\u8282\u5e8f\u5217\u7684\u521d\u59cb\u5316\uff0c\u5176\u4e2d\u8d8b\u52bf\u5e8f\u5217\u4f7f\u7528\u8f93\u5165\u5e8f\u5217\u7684\u5747\u503c\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u5b63\u8282\u6ce2\u52a8\u4fe1\u606f\u7528 0 \u6765\u521d\u59cb\u5316</p> <p>\u63a5\u4e0b\u6765\uff0c\u770b\u4ee3\u7801\u4e2d\uff0c\u5bf9\u9884\u6d4b\u5e8f\u5217 \u7684 \u8d8b\u52bf\u5e8f\u5217 \u548c \u5b63\u8282\u5e8f\u5217\u7684\u63d0\u53d6\u3002</p> <p>\u9996\u5148 \u6709 \u5386\u53f2\u6570\u636e x_enc [B, L, D]\u7684\uff0c\u9884\u6d4b\u548c\u6807\u7b7e\u6570\u636e x_dec [B, L+P, D]\uff0c\u63a5\u7740\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u5206\u89e3 \u5c06\u5386\u53f2\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u4e24\u4e2a\u6210\u5206</p> Python<pre><code>seasonal_init, trend_init = self.decomp(x_enc)\n</code></pre> <p>\u5f97\u5230 \u8d8b\u52bf\u521d\u59cb\u503c\uff1a\u5386\u53f2\u5e8f\u5217\u5747\u503c\uff0c\u5b63\u8282\u6027\u521d\u59cb\u503c\uff1a\u5168\u96f6\u5f20\u91cf</p> <p>\u57fa\u4e8e \u8f93\u5165\u5e8f\u5217\u7684 \u5e8f\u5217\u5206\u89e3\u7ed3\u679c\uff0c\u6784\u9020 \u89e3\u7801\u5668\u7684\u8f93\u5165\uff0c\u5177\u4f53\u6765\u8bf4\uff1a</p> <ul> <li> <p>\u8f93\u51fa\u5e8f\u5217 \u8d8b\u52bf\u8f93\u5165= \u5386\u53f2\u8d8b\u52bf\u672b\u5c3e + \u8d8b\u52bf\u521d\u59cb\u503c</p> </li> <li> <p>\u8f93\u51fa\u5e8f\u5217 \u5b63\u8282\u6027\u8f93\u5165 = \u5386\u53f2\u5b63\u8282\u6027\u672b\u5c3e + \u5b63\u8282\u6027\u521d\u59cb\u503c(\u96f6)</p> </li> </ul> <p>\u4e5f\u5c31\u662f\u6e90\u7801\u4e2d\u7684\u8fd9\u51e0\u884c\uff1a</p> Python<pre><code>mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\nzeros = torch.zeros([x_dec.shape[0], self.pred_len, x_dec.shape[2]], device=x_enc.device) \ntrend_init = torch.cat([trend_init[:, -self.label_len:, :], mean], dim=1)\nseasonal_init = torch.cat([seasonal_init[:, -self.label_len:, :], zeros], dim=1)\n</code></pre> <p>\u8fd9\u4e2a\u6a21\u578b\u7684\u7ed3\u6784\u7b80\u5355\u6765\u8bf4\u662f \u5229\u7528 **\u7f16\u7801\u5668**\u5904\u7406\u5386\u53f2\u6570\u636e\uff0c**\u89e3\u7801\u5668**\u5229\u7528\u7f16\u7801\u5668\u8f93\u51fa\u548c\u7ec4\u88c5\u7684\u521d\u59cb\u8f93\u5165\u751f\u6210\u9884\u6d4b\uff0c\u5c31\u662f\u4e00\u4e2a\u5f88\u6807\u51c6\u7684 Transformer \u5904\u7406\u6570\u636e\u7684\u67b6\u6784\u3002\u6211\u4eec\u5f97\u5230\u7684\u6700\u7ec8\u8f93\u51fa\u662f \u8d8b\u52bf\u548c\u5b63\u8282\u6027\u9884\u6d4b\u76f8\u52a0\uff0c\u56e0\u4e3a\u6709 label length\uff0c\u6240\u4ee5\u5bf9\u4e8e\u8f93\u51fa \u662f \u63d0\u53d6\u672b\u5c3e pred_len \u957f\u5ea6\u4f5c\u4e3a\u6700\u7ec8\u9884\u6d4b\u7ed3\u679c</p> <p>Autoformer \u7684\u6838\u5fc3\u601d\u60f3\u5c31\u662f \u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u4e0d\u540c\u9891\u7387\u6210\u5206\u5e76\u5206\u522b\u5efa\u6a21\uff0c\u518d\u7ec4\u5408\u751f\u6210\u6700\u7ec8\u9884\u6d4b\u3002</p> <p>\u5148\u6709\u4e2a\u5927\u4f53\u7684\u5370\u8c61\uff0c\u540e\u9762\u770b\u5230\u4ee3\u7801 \u8be6\u7ec6\u7684\u8bb2\u89e3\u3002</p> <p>\u5728\u8fdb\u884c\u540e\u9762\u7684Encoder \u548c Decoder\u4e4b\u524d\uff0c\u5148\u770b \u8d8b\u52bf\u9879 \u548c \u5b63\u8282\u9879 \u7684\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\u3002 \u6709\u70b9\u590d\u6742\uff0c\u4f46\u662f\u4e00\u6b65\u6b65\u6765\u3002</p> <p>\u25b6\ufe0f \u9996\u5148\u662f\u8c03\u7528 \u7684   self.decomp</p> Python<pre><code>seasonal_init, trend_init = self.decomp(x_enc)\n</code></pre> <p>\u25b6\ufe0f \u800c self.decomp \u53c8\u662f \u521d\u59cb\u5316 series_decomp \u7c7b</p> Python<pre><code>self.decomp = series_decomp(kernel_size)\n</code></pre> <p>\u25b6\ufe0f \u770b\u5230 series_decomp \u7c7b\u7684\u5b9a\u4e49</p> Python<pre><code>class series_decomp(nn.Module):\n</code></pre> <p>\ud83d\udfe2 \u7c7b\u7684\u5b9a\u4e49</p> Python<pre><code>class series_decomp(nn.Module):\n    \"\"\"\n    Series decomposition block\n    \"\"\"\n    def __init__(self, kernel_size):\n        super(series_decomp, self).__init__()\n        self.moving_avg = moving_avg(kernel_size, stride=1)\n\n    def forward(self, x):\n\n        # \u8ba1\u7b97\u79fb\u52a8\u5e73\u5747\uff0c\u63d0\u53d6\u5e8f\u5217\u8d8b\u52bf\u5206\u91cf\n        # x \u5f62\u72b6[B, L, D] -&gt; moving_mean\u5f62\u72b6[B, L, D]\n        #  moving_avg\u5185\u90e8\u4f1a\u8fdb\u884c\u586b\u5145\uff0c\u4fdd\u8bc1\u8f93\u51fa\u5f62\u72b6\u4e0e\u8f93\u5165\u76f8\u540c\n        moving_mean = self.moving_avg(x)\n\n        # \u901a\u8fc7\u539f\u59cb\u5e8f\u5217\u51cf\u53bb\u8d8b\u52bf\u5206\u91cf\uff0c\u5f97\u5230\u6b8b\u5dee(\u5b63\u8282\u6027\u5206\u91cf)\uff0c\u9010\u5143\u7d20\u51cf\u6cd5\u64cd\u4f5c\n        # x\u5f62\u72b6[B, L, D] - moving_mean\u5f62\u72b6[B, L, D] -&gt; res\u5f62\u72b6[B, L, D]\n        res = x - moving_mean\n\n        # \u8fd4\u56de\u5b63\u8282\u6027\u5206\u91cf\u548c\u8d8b\u52bf\u5206\u91cf\uff0c\u5747\u4fdd\u6301\u539f\u59cb\u5f62\u72b6[B, L, D]\n        # \u7b2c\u4e00\u4e2a\u8fd4\u56de\u503cres\u662f\u5b63\u8282\u6027\u5206\u91cf\uff0c\u7b2c\u4e8c\u4e2a\u8fd4\u56de\u503cmoving_mean\u662f\u8d8b\u52bf\u5206\u91cf\n        return res, moving_mean\n</code></pre> <p>\u25b6\ufe0f \u7c7b\u5185 \u8c03\u7528 <code>moving_avg</code> </p> <p></p> <p>\u25b6\ufe0f \u770b\u5230 <code>moving_avg</code> \u7c7b\u7684\u5b9a\u4e49</p> Python<pre><code>class moving_avg(nn.Module):\n</code></pre> <p>\ud83d\udfe2 <code>moving_avg</code> \u5b9a\u4e49</p> Python<pre><code>class moving_avg(nn.Module):\n    \"\"\"\n    Moving average block to highlight the trend of time series\n    \"\"\"\n    def __init__(self, kernel_size, stride):\n        super(moving_avg, self).__init__()\n        self.kernel_size = kernel_size\n        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n\n    def forward(self, x):\n        # padding on the both ends of time series\n\n        # \u63d0\u53d6\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u5e76\u91cd\u590d\uff0c\u7528\u4e8e\u524d\u7aef\u586b\u5145\n        #  [B, L, D] -&gt; [B, 1, D] -&gt; [B, (kernel_size-1)//2, D]\n        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1) \n\n        # \u63d0\u53d6\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u5e76\u91cd\u590d\uff0c\u7528\u4e8e\u540e\u7aef\u586b\u5145\n        # [B, L, D] -&gt; [B, 1, D] -&gt; [B, (kernel_size-1)//2, D]\n        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n\n        # \u8fde\u63a5\u586b\u5145\u90e8\u5206\u4e0e\u539f\u5e8f\u5217\n        # [B, (k-1)//2, D] + [B, L, D] + [B, (k-1)//2, D] -&gt; [B, L+(k-1), D]\n        x = torch.cat([front, x, end], dim=1)\n\n        # \u8f6c\u7f6e\u5e76\u5e94\u7528\u4e00\u7ef4\u5e73\u5747\u6c60\u5316\n        # [B, L+(k-1), D] -&gt; [B, D, L+(k-1)] -&gt; [B, D, L]\n        # \u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3akernel_size\uff0c\u6b65\u957f\u4e3a1\uff0c\u8f93\u51fa\u957f\u5ea6\u4e3a(L+(k-1)-k+1)=L \uff08length + 2P - K + 1\uff09\n        x = self.avg(x.permute(0, 2, 1))\n\n        # \u8f6c\u7f6e\u56de\u539f\u59cb\u7ef4\u5ea6\u987a\u5e8f [B, D, L] -&gt; [B, L, D]\n        x = x.permute(0, 2, 1)\n        return x\n</code></pre> <p>\u603b\u7ed3\uff1a\u5c31\u662f 3 \u6b21\u8c03\u7528\uff1a</p> Python<pre><code>seasonal_init, trend_init = self.decomp(x_enc)\n\nself.decomp = series_decomp(kernel_size)\n\nclass series_decomp(nn.Module):\n    def __init__(self, kernel_size):\n        super(series_decomp, self).__init__()\n        self.moving_avg = moving_avg(kernel_size, stride=1)\n\n    def forward(self, x):\n        moving_mean = self.moving_avg(x)\n\nclass moving_avg(nn.Module):\n     def forward(self, x):\n        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1) \n        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n        x = torch.cat([front, x, end], dim=1)\n        x = self.avg(x.permute(0, 2, 1))\n        x = x.permute(0, 2, 1)\n        return x    \n</code></pre> <p>\u7528\u4e00\u5f20\u56fe\u8868\u793a Autoformer \u5e8f\u5217\u5206\u89e3\u7684\u7684\u8fc7\u7a0b\uff0c\u8fd9\u4e2a\u5206\u89e3\u8fc7\u7a0b\u5c06\u539f\u59cb\u5e8f\u5217 x_enc \u5206\u89e3\u4e3a\u4e24\u4e2a\u76f8\u540c\u5f62\u72b6 [B,L,D] \u7684\u5f20\u91cf\uff1a\u8d8b\u52bf\u6210\u5206\u548c\u5b63\u8282\u6027\u6210\u5206\uff1a</p> Text Only<pre><code>                    \u8f93\u5165: x_enc [B, L, D]\n                          |\n                          v\n            +---------------------------+\n            | Model.forward()           |\n            | \u8c03\u7528: self.decomp(x_enc)  |\n            +---------------------------+\n                          |\n                          v\n            +---------------------------+\n            | series_decomp(kernel_size)|\n            | self.decomp\u5b9e\u4f8b           |\n            +---------------------------+\n                          |\n                          v\n            +---------------------------+\n            | series_decomp.forward(x)  |\n            | 1. \u8c03\u7528\u79fb\u52a8\u5e73\u5747\u8ba1\u7b97\u8d8b\u52bf   |\n            | 2. \u539f\u5e8f\u5217\u51cf\u53bb\u8d8b\u52bf\u5f97\u5230\u5b63\u8282\u6027|\n            +---------------------------+\n                          |\n                  +-------+-------+\n                  |               |\n                  v               v\n    +---------------------------+  +---------------------------+\n    | moving_avg.forward(x)     |  | \u5b63\u8282\u6027\u8ba1\u7b97                |\n    | \u6b65\u9aa4:                     |  | res = x - moving_mean     |\n    | 1.\u524d\u540e\u586b\u5145\u5e8f\u5217           |  |                           |\n    | 2.\u5e94\u7528\u5e73\u5747\u6c60\u5316           |  |                           |\n    | 3.\u8fd4\u56de\u8d8b\u52bf\u5206\u91cf           |  |                           |\n    +---------------------------+  +---------------------------+\n                  |               |\n                  v               v\n             \u8d8b\u52bf\u5206\u91cf        \u5b63\u8282\u6027\u5206\u91cf\n          trend_init [B,L,D]  seasonal_init [B,L,D]\n                  |               |\n                  +       +       +\n                          |\n                          v\n                \u8fd4\u56de\u5230Model.forward()\n                \u8fdb\u884c\u540e\u7eed\u5904\u7406\n</code></pre> <p>\u8bb2\u56fe \u9010\u5b57\u7a3f\uff1a</p> <p>\uff081\uff09Model.forward() \u8c03\u7528 self.decomp(x_enc)\u8fdb\u884c\u5e8f\u5217\u5206\u89e3</p> <p>\uff082\uff09series_decomp.forward(x)</p> <p>\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u6b65\u9aa4:</p> <ul> <li>\u8c03\u7528 self.moving_avg(x)\u8ba1\u7b97\u79fb\u52a8\u5e73\u5747\uff0c\u5f97\u5230\u8d8b\u52bf\u5206\u91cf</li> <li>\u8ba1\u7b97\u539f\u5e8f\u5217\u4e0e\u8d8b\u52bf\u5206\u91cf\u7684\u5dee\u503c\uff0c\u5f97\u5230\u5b63\u8282\u6027\u5206\u91cf</li> </ul> <p>\uff083\uff09moving_avg.forward(x)</p> <p>\u6267\u884c\u79fb\u52a8\u5e73\u5747\u8ba1\u7b97:</p> <ul> <li>\u901a\u8fc7\u91cd\u590d\u9996\u5c3e\u5143\u7d20\u8fdb\u884c\u5e8f\u5217\u586b\u5145</li> </ul> Python<pre><code>front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1) \nend = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n x = torch.cat([front, x, end], dim=1)\n</code></pre> <ul> <li>\u5e94\u7528\u4e00\u7ef4\u5e73\u5747\u6c60\u5316\u64cd\u4f5c</li> </ul> Text Only<pre><code>x = self.avg(x.permute(0, 2, 1))\n</code></pre> <p>\u8bf4\u660e \u4e3a\u4ec0\u4e48\u586b\u5145\uff0c\u662f\u4e3a\u4e86 \u4fdd\u8bc1\u5e8f\u5217\u5728\u5e73\u5747\u6c60\u5316\u540e \u957f\u5ea6\u4e0d\u53d8</p> <ul> <li>\u8fd4\u56de\u5e73\u6ed1\u540e\u7684\u8d8b\u52bf\u5206\u91cf</li> </ul> <p>\u8fd9\u90e8\u5206\u7684\u5f62\u72b6\u53d8\u5316\uff1a </p> <p> </p> <p>\u73b0\u5728\u5f00\u59cb \u8fd4\u56de moving_avg.forward(x) \u662f\u5229\u7528 1D \u5e73\u5747\u6c60\u5316 \u5f97\u5230 \u8d8b\u52bf\u5e8f\u5217\uff0c\u5c06\u7ed3\u679c\u8fd4\u56de\u7ed9 series_decomp \uff0c\u4e5f\u5c31\u662f\u8fd9\u53e5\u4ee3\u7801 <code>moving_mean = self.moving_avg(x)</code>\uff0c\u5f97\u5230\u8d8b\u52bf\u5e8f\u5217\u4ee5\u540e\uff0c\u6c38\u8fdc\u5e8f\u5217\u51cf\u8d8b\u52bf\u5e8f\u5217 <code>res = x - moving_mean</code> \uff0c\u5f97\u5230\u5b63\u8282\u5206\u91cf\uff0c\u4e5f\u5c31\u662f\u5468\u671f\u6027\u4fe1\u606f\u3002\u5177\u4f53\u7684\u4ee3\u7801\uff1a</p> <p></p> <p>\u6700\u7ec8 \u5c06\u7ed3\u679c \u8fd4\u56de\u7ed9 Autoformer forward \u4e2d\u7684 seasonal_init, trend_init</p> <p></p> <p>\u5e76\u4e14 \u7528\u8fd9\u4e24\u4e2a init \u521d\u59cb\u5316 \u89e3\u7801\u5668\u7684\u8f93\u5165\u3002</p> <p>\u8fd9\u91cc\u5f97\u6ce8\u610f\u4e00\u4e0b\uff0c\u5bf9\u4e8e \u6807\u7b7e\u5e8f\u5217\uff0c\u4e5f\u5c31\u662f \u8f93\u5165\u5e8f\u5217\u7684\u8d8b\u52bf\u4fe1\u606f\u7684\u63d0\u53d6\u7528\u7684\u662f 1D\u5e73\u5747\u6c60\u5316\uff0c\u800c\u5bf9\u9884\u6d4b predict length \u7684\u8d8b\u52bf\u4fe1\u606f\u521d\u59cb\u5316 \u5c31\u76f4\u63a5\u7528\u7684 \u8f93\u5165\u5e8f\u5217\u7684\u5747\u503c</p> Python<pre><code>mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n</code></pre> <p>\u5468\u671f\u6027\u8d8b\u52bf\u4e5f\u662f\uff0clabel length \u7684\u5b63\u8282\u8d8b\u52bf\u662f \u6b8b\u5dee\uff0c\u4e5f\u5c31\u662f \u539f\u59cb\u5e8f\u5217 \u51cf\u53bb \u8d8b\u52bf\u5e8f\u5217\uff0c\u800c predict length \u7684 \u5b63\u8282\u8d8b\u52bf\u5c31\u662f\u76f4\u63a5\u521d\u59cb\u5316\u4e3a 0 \u4e86\u3002</p> Python<pre><code>zeros = torch.zeros([x_dec.shape[0], self.pred_len, x_dec.shape[2]], device=x_enc.device) \n</code></pre> <p>\u8fd9\u91cc\u662f \u5c0f\u5c0f\u7684\u533a\u522b\uff0c\u5c0f\u5c0f\u7684\u6ce8\u610f\u3002</p> <p>\u597d\u4e86 \u8fd9\u90e8\u5206\uff0c\u5e8f\u5217\u5206\u89e3\u8bf4\u5b8c\u4e86\uff0c\u4ee3\u7801\u8bb2\u4e86\uff0c\u539f\u6587\u8bb2\u4e86\uff0c\u516c\u5f0f\u5bf9\u5e94\u4e0a\u4e86\uff0c\u56fe\u4e5f\u8bf4\u4e86\u3002\u539f\u6587 <code>Series decomposition block</code>  \u5c31\u8fc7\u5566</p> <p> </p> <p>\u5e8f\u5217\u5206\u89e3 over</p>"},{"location":"Reproduction/6_AutoFormer/#model-inputs","title":"model inputs","text":"<p>\u4e0b\u9762\u5f00\u59cb \u6a21\u578b\u7684\u8f93\u5165\uff0c\u5148\u4ece\u8bba\u6587\u5f00\u59cb\u8bb2\u89e3\uff1a</p> <p> </p> <p>\u6a21\u578b\u7684\u8f93\u5165\u90e8\u5206\uff0c\u6a21\u578b\u7684\u8f93\u5165\u5305\u62ec\u7f16\u7801\u5668\u7684\u8f93\u5165\u548c\u89e3\u7801\u5668\u7684\u8f93\u5165\u3002\u5177\u4f53\u6765\u8bf4\uff0c</p> <p>\u7f16\u7801\u5668\u7684\u8f93\u5165\u662f\u8fc7\u53bb \\(I\\) \u4e2a\u65f6\u95f4\u6b65\uff0c\u6587\u4e2d\u7ed9\u51fa\u7684\u7b26\u53f7\u8868\u793a \\(\\mathcal{X}^{I \\times d}\\) \uff0c\\(I\\) \u8868\u793a\u65f6\u95f4\u6b65\u957f\uff0c\\(d\\) \u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\u6570\u3002</p> <p>\u89e3\u7801\u5668\u7684\u8f93\u5165\u5305\u62ec\u4e86 \u5b63\u8282\u6027\u5e8f\u5217 \u548c \u8d8b\u52bf\u6027\u5e8f\u5217\uff0c\u5177\u4f53\u7684\u7b26\u53f7\u8868\u793a\u5206\u522b\u662f \\(\\mathcal{X}_{des}\\)  \u548c \\(\\mathcal{X}_{det}\\)    \u5f62\u72b6\u662f\u4e00\u6837\u7684\uff1a\\((\\frac{I}{2}+O)\\)  \u3001\\(\\frac{I}{2}\\) \u662f label length \u7684\u957f\u5ea6\uff0c\u53d6\u7684\u662f\u539f\u59cb\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u7684 \u4e00\u534a\u3002O \u662f \u9884\u6d4b\u6b65\u957f predict length\u3002d \u540c\u6837\u662f\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\u6570\u3002\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u6765\u770b\u516c\u5f0f\u662f\u600e\u4e48\u8868\u793a\u7684\uff1a</p> <p></p> <p>\\(\\mathcal{X}_{ens}\u3001\\mathcal{X}_{ent}\\)  \u5206\u522b\u8868\u793a \u4ece \u539f\u59cb \u8f93\u5165\u5e8f\u5217 \\(\\mathcal{X}_{en}\\) \u5206\u89e3\u51fa\u7684\u5b63\u8282\u6210\u5206\u548c\u8d8b\u52bf\u6210\u5206\uff0c\u622a\u53d6\u51fa\u540e\u534a\u90e8\u5206 \\(\\frac{I}{2}:I\\) \u4f5c\u4e3a label length\uff0c\u4e0e\u957f\u5ea6\u4e3a predict  length \u7684\u65f6\u95f4\u6b65\u8fdb\u884c\u62fc\u63a5\uff0c\u7528 0 \u586b\u5145\u7684\u957f\u5ea6\u4e3a predict length\u7684\u5411\u91cf\u8bb0\u4f5c \\(\\mathcal{X}_0\\) \uff0c\u7528\u8f93\u5165\u65f6\u95f4\u5e8f\u5217\u65f6\u95f4\u6b65\u5747\u503c\u586b\u5145\u7684\u957f\u5ea6\u4e3a predict length \u7684\u5411\u91cf\u8bb0\u4f5c \\(\\mathcal{X}_{mean}\\)</p> <p>\u7136\u540e\uff0c\\(\\mathcal{X}_{ens}\\) \u4e0e \\(\\mathcal{X}_0\\) \u8fdb\u884c concat \u5f97\u5230 \u89e3\u7801\u5668\u5b63\u8282\u6210\u5206\u7684\u521d\u59cb\u503c  \\(\\mathcal{X}_{des}\\)</p> <p>\u5bf9\u5e94\u7740\u7684 \\(\\mathcal{X}_{ent}\\) \u4e0e \\(\\mathcal{X}_{mean}\\) concat \u5f97\u5230\u89e3\u7801\u5668\u8d8b\u52bf\u6210\u5206\u7684\u521d\u59cb\u503c \\(\\mathcal{X}_{mean}\\)</p> <p>\u518d\u5f3a\u8c03\u4e00\u4e0b\uff0c\u8fd9\u91cc\u6240\u6d89\u53ca\u7684\u5411\u91cf\u7684\u8bb0\u53f7\u548c\u5f62\u72b6\uff1a </p> <ul> <li>\u7f16\u7801\u5668\u7684\u8f93\u5165\u662f \u8fc7\u53bb \\(I\\) \u4e2a\u65f6\u95f4\u6b65\uff0c\u8868\u793a \\(\\mathcal{X}^{I \\times d}\\) \uff0c\\(I\\) \u8868\u793a\u65f6\u95f4\u6b65\u957f\uff0c\\(d\\) \u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\u6570\u3002</li> <li>\u89e3\u7801\u5668\u5b63\u8282\u6210\u5206\u7684\u8f93\u5165\u662f \\(\\mathcal{X}_{des} ^{(\\frac{I}{2}+O)\\times d}\\) \u3001\u89e3\u7801\u5668\u8d8b\u52bf\u6210\u5206\u7684\u8f93\u5165\u662f \\(\\mathcal{X}_{det} ^{(\\frac{I}{2}+O)\\times d}\\) </li> <li>\u6d89\u53ca\u5230\u7684\u4e2d\u95f4\u53d8\u91cf\uff0c\\(\\mathcal{X}^{\\frac{I}{2} \\times d}_{ens}\\) \uff0c\\(\\mathcal{X}^{\\frac{I}{2} \\times d}_{ent}\\) \u53ef\u4ee5\u7406\u89e3\u4e3a\u6807\u7b7e\u5e8f\u5217\u7684\u5b63\u8282\u6210\u5206\u548c\u8d8b\u52bf\u6210\u5206\uff0c\u5c31\u662f\u4ece\u8f93\u5165\u5e8f\u5217\u5206\u89e3\u7684\u5b63\u8282\u6210\u5206\u548c\u8d8b\u52bf\u6210\u5206\u4e2d\u622a\u53d6\u7684\u540e\u534a\u6bb5\u3002</li> <li>\u9884\u6d4b\u5e8f\u5217\u5b63\u8282\u6210\u5206\u7684\u521d\u59cb\u503c\u662f \\(\\mathcal{X}_0 ^{O \\times d}\\) \uff0c\u8d8b\u52bf\u6210\u5206\u521d\u59cb\u503c\u662f \\(\\mathcal{X}^{O \\times d} _{Mean}\\)</li> </ul> <p>\u4e5f\u5c31\u662f\u8bba\u6587\u4e2d\u6a21\u578b\u7ed3\u6784\u56fe\u7684\uff1a</p> <p></p> <p>\u5177\u4f53\u5230\u4ee3\u7801\uff0c\u5c31\u662f autoformer forward\u7684\u524d 5 \u884c\uff0c\u5176\u4e2d self.decomp\u662f\u6211\u4eec\u521a\u521a\u4ed4\u7ec6\u8bb2\u8fc7\u7684 \u5e8f\u5217\u5206\u89e3\u6a21\u5757 Series decomposition block\uff1a</p> <p></p> <p>\u8fd9\u90e8\u5206\u4ee3\u7801\u6bd4\u8f83\u597d\u7406\u89e3\uff0c\u5c31\u8fd9\u6837\uff0c\u4ee5\u4e0a\u90e8\u5206\u5b8c\u6210\u4e86\u5bf9\u539f\u6587 model inputs \u90e8\u5206\u7684\u8bb2\u89e3\uff0c\u4ee3\u7801\uff0c\u8bba\u6587\uff0c\u56fe\uff0c\u516c\u5f0f\u90fd\u8bb2\u4e86\u3002</p> <p></p> <p></p>"},{"location":"Reproduction/6_AutoFormer/#encoder","title":"Encoder","text":"<p>\u63a5\u4e0b\u6765\u8fdb\u5165\u8bba\u6587\u7684 Encoder \u90e8\u5206 </p> <p>\u4f1a\u540c\u6837\u6309\u7167\uff0c\u8bba\u6587\u3001\u56fe\u3001\u516c\u5f0f\u3001\u4ee3\u7801\u4e00\u4e00\u5bf9\u5e94\u7684\u903b\u8f91\u8fdb\u884c\u8bb2\u89e3</p> <p>\u9996\u5148\uff0cAutoformer \u9075\u5faa\u539f\u59cb Transformer \u7684\u7ed3\u6784\uff0c </p> <p></p> <p>\u7f16\u7801\u5668\uff0c\u89e3\u7801\u5668\uff0c\u7f16\u7801\u5668\u63a5\u6536\u7684 input \u662f word embedding + positional embedding\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u3002\u89e3\u7801\u5668\u63a5\u6536\u7684 \u8f93\u5165\u662f output\uff0c\u9884\u6d4b\u90e8\u5206\uff0c\u540c\u6837\u662f word embedding+positional embedding\uff0c\u7136\u540e\u5206\u522b\u7ecf\u8fc7\u89e3\u7801\u5668\u8f93\u5165\u7684 \u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ee5\u53ca\u548c\u7f16\u7801\u5668\u8f93\u51fa \u7684 \u4ea4\u53c9\u6ce8\u610f\u529b\uff0c\u6700\u540e\u7ecf\u8fc7 \u5168\u8fde\u63a5\u5c42\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u3002</p> <p>\u9996\u5148\u5f3a\u8c03\u4e00\u4e0b\u5173\u4e8eTransformer \u4e3a\u4ec0\u4e48\u662f\u6ce8\u610f\u529b\u673a\u5236\u548c\u5168\u8fde\u63a5\u5c42\u7684\u8bbe\u8ba1\uff1f</p> <p>\u9996\u5148\uff0cTransformer \u5728 NLP\u4e2d\u63a5\u6536\u7684\u6570\u636e\u683c\u5f0f \u662f [B,L,D]\uff0cbatch size\uff0c\u4e00\u4e2a batch \u4e2d\u6709\u591a\u5c11\u4e2a\u53e5\u5b50\uff0c\u4e00\u4e2a\u53e5\u5b50\u4e2d\u6709\u51e0\u4e2a\u8bcd L\uff0c\u6bcf\u4e2a\u8bcd\u7684\u5d4c\u5165D\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e2a\u8bcd\u7528\u957f\u5ea6\u4e3a\u591a\u5c11\u7684\u5411\u91cf\u8868\u793a</p> <p>\u6700\u76f4\u89c2\u7684\u8bb2\u89e3\uff0c\u5c31\u662f \u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c L \u5c42\u9762\u7684\u4ea4\u4e92\uff0c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c D \u5c42\u9762\u7684\u4ea4\u4e92\u3002</p> <p>L \u5c42\u9762\u4e5f\u5c31\u662f\u6ce8\u610f\u5230\u4e86 \u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u4ea4\u4e92\uff0cD \u5c42\u9762\u5c31\u662f\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7279\u5f81\u7684\u4ea4\u4e92 </p> <p>\u5728L\u5c42\u9762\uff08\u5355\u8bcd\u5c42\u9762\uff09\u8fdb\u884c\u4ea4\u4e92\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u5bf9\u5176\u4ed6\u5355\u8bcd\u7684\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u6355\u6349\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b</p> <p>\u5728D\u5c42\u9762\uff08\u5373\u5355\u8bcd\u5d4c\u5165\u7684\u7279\u5f81\u5c42\u9762\uff09\u8fdb\u884c\u4ea4\u4e92\uff0c\u5bf9\u6bcf\u4e2a\u5355\u8bcd\u7684\u5d4c\u5165\u5411\u91cf\u8fdb\u884c\u975e\u7ebf\u6027\u53d8\u6362\uff0c\u6355\u6349\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u7279\u5f81\u4ea4\u4e92 </p> <p>\u5bf9\u5e94\u5230\u65f6\u95f4\u5e8f\u5217\u4e2d</p> <p>1\ufe0f\u20e3 \u6807\u51c6 \u8f93\u5165 \u683c\u5f0f\u4e5f\u662f BLD\uff0c\u5177\u4f53\u7684\u89e3\u91ca\uff1a </p> <p>B = 32 (\u6279\u91cf\u5927\u5c0f\uff0c32\u4e2a\u65f6\u95f4\u5e8f\u5217\u6837\u672c) L = 36 (\u6bcf\u4e2a\u6837\u672c\u670936\u4e2a\u65f6\u95f4\u6b65\uff0c\u5982\u8fc7\u53bb36\u5929\u7684\u6570\u636e) D = 7 (\u6bcf\u4e2a\u65f6\u95f4\u6b65\u67097\u4e2a\u7279\u5f81\uff0c\u5982\u5bf9\u4e8e\u80a1\u7968\u53ef\u80fd\u5305\u62ec\u5f00\u76d8\u4ef7\u3001\u6536\u76d8\u4ef7\u3001\u6700\u9ad8\u4ef7\u3001\u6700\u4f4e\u4ef7\u3001\u4ea4\u6613\u91cf\u7b49)</p> <p>2\ufe0f\u20e3 \u5904\u7406   \u6ce8\u610f\u529b\u673a\u5236</p> <p>\u7f16\u7801\u5668\u4e2d\uff0c\u6ce8\u610f\u529b\u5728\u6240\u670936\u4e2a\u65f6\u95f4\u6b65\u4e4b\u95f4\u5efa\u7acb\u8fde\u63a5 \u89e3\u7801\u5668\u4e2d\uff0c\u6ce8\u610f\u529b\u65e2\u5728\u9884\u6d4b\u5e8f\u5217\u5185\u90e8\u5efa\u7acb\u8fde\u63a5\uff0c\u4e5f\u4e0e\u7f16\u7801\u5668\u8f93\u51fa\u5efa\u7acb\u8fde\u63a5</p> <p>\u65f6\u95f4\u6b65\u4e4b\u95f4\u7684\u5efa\u6a21 \u53ef\u4ee5 \u53d1\u73b0\u80a1\u7968\u4ef7\u683c\u6bcf\u5468\u4e94\u53ef\u80fd\u4e0b\u8dcc\uff0c\u6216\u8005\u6bcf\u6708\u521d\u53ef\u80fd\u4e0a\u6da8\u7684\u6a21\u5f0f</p> <p>3\ufe0f\u20e3 \u5904\u7406  \u524d\u9988\u5168\u8fde\u63a5\u5c42</p> <p>\u5904\u7406\u6bcf\u4e2a\u65f6\u95f4\u6b65\u51857\u4e2a\u7279\u5f81\u4e4b\u95f4\u7684\u5173\u7cfb</p> <p>\u4f8b\u5982\uff0c\u4ea4\u6613\u91cf\u4e0e\u4ef7\u683c\u53d8\u52a8\u7684\u5173\u7cfb\uff0c\u6216\u5f00\u76d8\u4ef7\u4e0e\u6536\u76d8\u4ef7\u7684\u5173\u7cfb</p> <p>\u8bf6\uff0c\u8bf4\u8d77\u8fd9\u4e2a\uff0c\u5173\u4e8e\u7528\u73b0\u5b9e\u4f8b\u5b50\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\uff0c</p> <p>\u9996\u5148\uff0c\u5377\u79ef\u662f\u4ec0\u4e48\u610f\u601d\uff1f </p> <p>\u5047\u5982\u6211\u4eec\u8981\u8ba4\u8bc6\u4e00\u4e2a\u4ebaA\uff0cB \u662f A \u7684\u76f4\u63a5\u670b\u53cb\uff0c\u5f62\u6210\u4e86B \u5bf9 A \u7684\u7b2c\u4e00\u6b21\u8ba4\u8bc6\uff0cB \u5c31\u76f8\u5f53\u4e8e\u5377\u79ef\u6838\u4e86\uff0c\u90a3\u76f4\u63a5\u8ba4\u8bc6 A\u7684\u80af\u5b9a\u4e0d\u6b62\u4e00\u4e2a\u4eba\uff0c\u8fd8\u6709B1\uff0cB2\uff0cB3...\u7b49\uff0c\u6bcf\u4e2a\u4eba\u5bf9\u5f62\u6210\u4e86\u5bf9 A \u7684\u7b2c\u4e00\u6b21\u8ba4\u8bc6\uff0c\u7236\u6bcd\u8ba4\u8bc6 A\u66f4\u5173\u6ce8\u751f\u6d3b\u5c42\u9762\uff0c\u5b66\u6821\u4e2d\u76f4\u63a5\u8ba4\u8bc6\u7684 A \u66f4\u5173\u4e8e\u4e3a\u4eba\u5904\u4e8b\u90e8\u5206\uff0c\u5de5\u4f5c\u4e2d\u76f4\u63a5\u8ba4\u8bc6\u7684 A \u66f4\u5173\u4e8e A \u7684\u751f\u4ea7\u6027\u3002\u8fd9\u91cc\u76f4\u63a5\u8ba4\u8bc6 A \u7684B1\uff0cB2\uff0cB3...\u5c31\u662f\u6bcf\u4e00\u5c42\u4e2d \u5377\u79ef\u6838\u7684\u4e2a\u6570\u3002\u9664\u4e86\u76f4\u63a5\u8ba4\u8bc6 A \u7684\uff0c\u8fd8\u6709\u901a\u8fc7\u76f4\u63a5\u8ba4\u8bc6 A \u7684\u4ebaB \u8ba4\u8bc6 A\uff0c\u8fd9\u6ce2\u4eba\u53eb C\uff0c\u90a3\u8fd8\u6709\u901a\u8fc7 C \u8ba4\u8bc6 A \u7684\uff0c\u90a3 C \u53c8\u8ba4\u8bc6 D\uff0cD \u53c8\u901a\u8fc7 C \u8ba4\u8bc6 A\u3002\u9664\u4e86\u522b\u4eba\u8ba4\u8bc6 A\uff0cA \u81ea\u5df1\u4e5f\u6709\u5bf9\u81ea\u5df1\u7684\u8ba4\u8bc6\u3002</p> <p>Transformer\u662f\u4ec0\u4e48\u610f\u601d\uff1f</p> <p>\u9664\u4e86\u521a\u521a\u8bf4\u7684 \u6ce8\u610f\u529b\u673a\u5236\u548c\u524d\u9988\u5168\u8fde\u63a5\u5c42\u7684\u7406\u89e3\uff0c\u8fd8\u6709 Encoder \u3001Decoder \u3001\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u7684\u7406\u89e3\u3002</p> <ul> <li> Encoder&amp;Decoder \u7684\u4ea4\u4e92\u600e\u4e48\u7406\u89e3\uff1f</li> </ul> <p>\u9996\u5148\uff0c\u6574\u4f53\u4e0a\u7684\u8fd9\u4e2a\u56fe\uff1a</p> <p></p> <p>\u7f16\u7801\u5668\u76f8\u5f53\u4e8e\u7532\u65b9\uff0c\u89e3\u7801\u5668\u76f8\u5f53\u4e8e\u4e59\u65b9\uff0c\u7532\u65b9\u6709\u9700\u6c42\uff0c\u81ea\u5df1\u516c\u53f8\u5185\u90e8\u4e00\u7ea7\u4e00\u7ea7\u6c9f\u901a\uff0c\u4ece\u6700\u5f00\u59cb\u7684\u60f3\u6cd5\u6700\u7ec8\u5f62\u6210\u65b9\u6cd5\u4ea4\u7ed9\u6700\u540e\u4e00\u4e2a\u4eba\uff0c\u8fd9\u4e2a\u4eba\u53bb\u548c\u4e59\u516c\u53f8\u6c9f\u901a\uff0c\u4e59\u516c\u53f8\u53c8\u6709\u5f88\u591a\u4e2a\u90e8\u5206\uff0c\u6bcf\u4e2a\u90e8\u5206\u5206\u522b\u5b8c\u6210\u7532\u516c\u53f8\u63d0\u51fa\u7684\u65b9\u6848\u7684\u4e00\u90e8\u5206\uff0c\u8fd9\u4e00\u4e2a\u8fc7\u7a0b\u4e2d\u9700\u8981\u4e0d\u65ad\u7684\u4e0e\u7532\u516c\u53f8\u624b\u62ff\u6700\u7ec8\u65b9\u6848\u7684\u4eba\u4e0d\u65ad\u6c9f\u901a\uff0c\u6700\u7ec8\u4e59\u516c\u53f8\u5b8c\u6210\u65b9\u6848\u3002</p> <ul> <li> \u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u600e\u4e48\u7406\u89e3</li> </ul> <p>\u5bf9\u4e8e BLD \u7684\u5e8f\u5217\uff0c\u9996\u5148\u660e\u767d\u7684\u662f\uff0c\u90a3\u4e2a\u7ef4\u5ea6\u5206\u591a\u5934\u4e86\uff0c\u662f D \u7ef4\u5ea6\u5206\u6210 num head\u7ef4\u5ea6\u548c head dim\uff0c\u5176\u4e2d num head \u00d7 head dim = embedding dim\uff08D\uff09\uff0c\u76f8\u5f53\u4e8e\u4ec0\u4e48\u610f\u601d\uff0c\u4e00\u4e2a\u4eba\u5b66\u77e5\u8bc6\uff08B =1\uff09\uff0cL \u662f\u8981\u5b66\u7684\u51e0\u672c\u4e66\uff0cD \u662f\u6bcf\u672c\u4e66\u6709\u51e0\u4e2a\u7ae0\u8282\uff0c\u4e00\u822c\u662f\u4e00\u4e2a\u8001\u5e08\u6559\u6211\u4eec\u5b66\u4e00\u6574\u672c\u4e66\uff0c\u4f46\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u7684\u610f\u601d\u662f\uff0c\u4e00\u672c\u4e66\u7684\u51e0\u4e2a\u7ae0\u8282\uff0c\u5206\u5f00\uff0c\u6bd4\u5982\u7b2c\u4e00\u4e2a\u8001\u5e08\u6559\u7b2c\u4e00\u7ae0\u548c\u7b2c\u4e8c\u7ae0\uff0c\u7b2c\u4e8c\u4e2a\u8001\u5e08\u6559\u7b2c\u4e09\u7ae0\u548c\u7b2c\u56db\u7ae0\uff0c\u6700\u540e\u4e24\u5f20\u7b2c\u4e09\u4e2a\u8001\u5e08\u6559\uff0c\u8fd9\u6837\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u540c\u6837\u662f\u4e00\u4e2a\u5b66\u671f\uff0c\u4e00\u4e2a\u8001\u5e08\u53ea\u9700\u8981\u5173\u6ce8\u4e24\u7ae0\u7684\u5185\u5bb9\uff0c\u5bf9\u4e8e\u8bfe\u7a0b\u8282\u594f\u7684\u628a\u63e1\u77e5\u8bc6\u7406\u89e3\u7684\u66f4\u900f\u5f7b\uff0c\u6548\u679c\u4f1a\u6bd4\u4e00\u4e2a\u8001\u5e08\u6559\u4e00\u6574\u672c\u4e66\u7684\u5185\u5bb9\u8981\u597d\u4e00\u4e9b\u3002</p> <p>B=3\uff0c\u5c31\u662f\u73ed\u91cc\u7684 3 \u4e2a\u4eba\uff0c\u6bcf\u4e2a\u4eba\u8fd9\u5b66\u671f\u90fd\u8981\u4e0a\u8fd9\u51e0\u672c\u8bfe\uff0c\u540c\u6837\u7684 LD\u3002</p> <p>\u6700\u540e\u4e00\u4e2a linear \u5c42\uff0c\u5e94\u8be5\u662f\u4e3a\u4e86\u8fd8\u539f\u539f\u59cb\u7ef4\u5ea6\u7684\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#_8","title":"\u8bba\u6587","text":"<p>\u597d\u4e86\uff0c\u6269\u5c55\u7684\u8fdc\u4e86\uff0c\u56de\u5230\u8bba\u6587\u4e2dEncoder \u90e8\u5206 </p> <p></p> <p>\u539f\u6587\u4e2d\u8bf4\uff0c\u9996\u5148\u7f16\u7801\u5668\u66f4\u4e13\u6ce8\u5b63\u8282\u90e8\u5206\u7684\u5efa\u6a21\uff0c\u7f16\u7801\u5668\u7684\u8f93\u51fa\u5305\u542b\u8fc7\u53bb\u7684\u5b63\u8282\u6027\u4fe1\u606f\uff0c\u5e76\u5c06\u4f5c\u4e3a\u4ea4\u53c9\u4fe1\u606f\u5e2e\u52a9\u89e3\u7801\u5668\u7ec6\u5316\u9884\u6d4b\u7ed3\u679c\uff0c\u5047\u8bbe\u6709 N \u4e2a\u7f16\u7801\u5668\uff0c\u5219\u7b2c i \u5c42\u7f16\u7801\u5668\u7684\u603b\u4f53\u65b9\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a \\(\\mathcal{X}_{en}^l = Encoder(\\mathcal{X}_{en}^{l-1})\\) \uff0c\u5c31\u662f\u8bf4 \u7b2c \\(l\\) \u5c42\u7f16\u7801\u5668\u63a5\u6536 \u7b2c \\(l-1\\) \u5c42\u7f16\u7801\u5668\u7684\u8f93\u51fa\u4f5c\u4e3a\u8f93\u5165\uff0c\u5177\u4f53\u7684\u7ec6\u8282\u662f\u539f\u6587\u7684\u516c\u5f0f(3)</p> <p>\u4e0b\u9762\u5bf9 \u516c\u5f0f 3 \u8fdb\u884c\u8bb2\u89e3</p> <p>\u9996\u5148\uff0c\u7b49\u53f7\u5de6\u8fb9\uff0c\u4e0b\u5212\u7ebf\u8868\u793a\u5ffd\u7565\u6389\u5b63\u8282\u6210\u5206\uff0c\u53ea\u5173\u6ce8\u5b63\u8282\u6210\u5206\u3002</p> <p>\\(\\mathcal{X}_{en}^l = \\mathcal{S}_{en}^{l,2},l \\in {1,...,N}\\)  \u8868\u793a \u7b2c \\(l\\) \u5c42\u7f16\u7801\u5668\u7684\u8f93\u51fa\u3002</p> <ul> <li> <p>\u521d\u59cb\u503c\uff0c\u4e5f\u5c31\u662f\u7f16\u7801\u5668\u7684\u8f93\u5165\u662f \\(\\mathcal{X}_{en}^0\\) \u662f \u8f93\u5165\u65f6\u95f4\u5e8f\u5217\u7684 \\(\\mathcal{X}_{en}\\) \u7684 word embedding</p> </li> <li> <p> \\(\\mathcal{S}_{en}^{l,i},i \\in {1,2}\\) \u8868\u793a \u7b2c \\(l\\)\u5c42\u4e2d \u7b2c i \u4e2a\u5e8f\u5217\u5206\u89e3\u6a21\u5757\u4e4b\u540e\u7684\u5b63\u8282\u6027\u6210\u5206\uff0c\u7136\u540e\u516c\u5f0f\u4e2d\u7684 Auto-correlation \u540e\u9762\u518d\u8bf4\uff0c\u8fd9\u662f\u672c\u6587\u7684\u4e00\u4e2a\u521b\u65b0\u70b9\u3002\uff08ps\uff0c\u540e\u9762\u8981\u91cd\u70b9\u770b\u8fd9\u4e2a\u662f\u4ec0\u4e48\u610f\u601d\u3002\uff09</p> </li> </ul> <p>\uff08\u6211\u6700\u5f00\u59cb\u770b\u89c1\u8fd9\u91cc\u7684\u7591\u95ee\uff0c\u4e0d\u7528\u8bb2\uff0c\u5ffd\u7565\u6389\u5373\u53ef\uff09\u5148\u770b\u516c\u5f0f\u7b49\u53f7\u7684\u5de6\u8fb9\uff0c \\(\\mathcal{S}_{en}^{l,1}\\) \u9996\u5148\uff0c\u4e0b\u6807 \\(en\\) \u5c31\u662f\u8868\u793a \u7f16\u7801\u5668\uff0c\\(l\\) \u8868\u793a\u7b2c\u51e0\u4e2a\u7f16\u7801\u5668\uff0c\u90a3\u8fd9\u4e2a \\(1\\)\u662f\u4ec0\u4e48\u610f\u601d\uff1f</p> <p>\u539f\u6587\u548c\u516c\u5f0f\u8bf4\u4e86\uff0c\u63a5\u4e0b\u6765\u6765\u770b\u4ee3\u7801\uff0cEncoder \u662f\u600e\u4e48\u5b9e\u73b0\u7684\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#encoder-embedding_1","title":"Encoder Embedding","text":"<p>\u9996\u5148\uff0c\u6784\u9020 Encoder \u7684\u8f93\u5165 \uff0c\u7f16\u7801\u5668\u5d4c\u5165\u3002</p> <p></p> <p>\u5177\u4f53\u600e\u4e48\u505a\u7684\u770bautoformer \u7684 init \u90e8\u5206\uff1a</p> <p></p> <p>\u770b\u5230\u8fd9\u8fb9\u8c03\u7528\u7684 <code>DataEmbedding_wo_pos</code> \u8fd9\u4e2a\u7c7b\uff0c\u5176\u4e2d\u5177\u4f53\u5730 valueEmbedding \u548cTemporaryEmbedding \u53c8\u5206\u522b\u5728 init \u4e2d\u663e\u793a\u8c03\u7528\u4e86 <code>TokenEmbedding</code> \u7c7b\u548c <code>TemporalEmbedding</code> \u7c7b</p> <p></p>"},{"location":"Reproduction/6_AutoFormer/#_9","title":"\u7c7b\u56fe","text":"<p>\u5d4c\u5165\u90e8\u5206\u7684\u8c03\u7528\u5173\u7cfb\u7528\u6d41\u7a0b\u56fe\u6765\u8868\u793a\uff1a</p> <pre><code>classDiagram\n    class DataEmbedding_wo_pos {\n        +TokenEmbedding value_embedding\n        +PositionalEmbedding position_embedding\n        +TemporalEmbedding temporal_embedding\n        +Dropout dropout\n        +forward(x, x_mark)\n    }\n\n    class TokenEmbedding {\n        +Conv1d tokenConv\n        +forward(x)\n    }\n\n    class PositionalEmbedding {\n        +Tensor pe\n        +forward(x)\n    }\n\n    class TemporalEmbedding {\n        +Embedding minute_embed\n        +Embedding hour_embed\n        +Embedding weekday_embed\n        +Embedding day_embed\n        +Embedding month_embed\n        +forward(x)\n    }\n\n    class TimeFeatureEmbedding {\n        +Linear embed\n        +forward(x)\n    }\n\n    DataEmbedding_wo_pos --&gt; TokenEmbedding\n    DataEmbedding_wo_pos --&gt; PositionalEmbedding\n    DataEmbedding_wo_pos --&gt; TemporalEmbedding\n    TemporalEmbedding --&gt; TimeFeatureEmbedding\n</code></pre> <p>\u9996\u5148\uff0c\u8ddf\u5927\u5bb6\u8bf4\u8fd9\u4e2a\u56fe\u600e\u4e48\u753b\uff0c\u9996\u5148\u5728\u8c03\u8bd5\u7684\u8fc7\u7a0b\u4e2d\uff0c\u770b\u5230\u8c03\u7528\u76f8\u5173\u7684\u4ee3\u7801\uff0c\u5c31\u7c98\u8d34\u7ed9 gpt\uff0c\u7136\u540e\u8ba9 gpt \u753b\u3002\u8fd9\u4e2a\u56fe\u5c31\u662f gpt \u7ed9\u6211\u753b\u7684\uff0c\u5b83\u7528\u7684 mermaid \uff0c\u751f\u6210\u4ee3\u7801\uff0c\u7136\u540e\u6211\u7c98\u8d34\u5230\u6211\u7684 markdown \u6587\u6863\u4e2d\uff0c\u6211\u7528\u7684 markdown \u7f16\u8f91\u5668\u662f Typora\uff0c\u53ef\u4ee5\u89e3\u6790 mermaid\uff0c\u7528\u5728\u7ebfmermaid \u4e5f\u53ef\u4ee5\u663e\u793a\u51fa\u56fe\u3002\u76f4\u63a5\u641c \u5728\u7ebf mermaid\u3002\u6216\u8005\u8ddf gpt \u8bf4\uff0c\u7528\u7b80\u5355\u7684\u6d41\u7a0b\u56fe\u753b\uff0c\u4e0d\u7528 mermaid\uff0c\u90fd\u80fd\u5e2e\u4f60\u628a\u81ea\u5df1\u7684\u4ee3\u7801\u7406\u6e05\u695a\u3002</p> <p>mermaid \u753b\u51fa\u7684\u7c7b\u8c03\u7528\u56fe\uff0c\u4e00\u4e2a\u7c7b\u7528\u4e09\u884c\u8868\u793a\uff0c\u7b2c\u4e00\u884c \u7c7b\u540d\u3001\u7b2c\u4e8c\u884c\uff0cinit \u90e8\u5206\u7684\u5b9a\u4e49\u3001\u7b2c\u4e09\u884c\u7c7b\u4e2d\u65b9\u6cd5\u7684\u5b9a\u4e49</p> <p>\u597d\u4e86\uff0c\u73b0\u5728\u5f00\u59cb\u8bb2\u56fe\uff0c </p> <p>\u53ef\u4ee5\u770b\u5230 <code>DataEmbedding_wo_pos</code> \u7c7b \u7684 init \u5206\u522b\u8c03\u7528\u4e86 <code>TokenEmbedding</code>\u7c7b\u3001<code>PositionalEmbedding</code>\u7c7b\u548c <code>TemporalEmbedding</code>\u7c7b\uff0c\u540c\u65f6\u8fd8\u5b9a\u4e49\u4e86\u4e00\u4e2a dropout \u5c42\u3002</p> <p>\ud83d\udd35 \u8c03\u7528 <code>tokenEmbedding</code>\u7c7b\uff0cinit \u90e8\u5206\u662f\u4f7f\u7528\u4e00\u4e2a <code>nn.Conv1d</code> \u521d\u59cb\u5316\u4e86\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u4f20\u7ed9 <code>self.tokenConv</code> \uff0c\u540e\u9762\u5728 \u8fd9\u4e2a\u7c7b\u4e2d\u7684 forward \u65b9\u6cd5\u4e2d\u7528\u3002</p> <p></p> <p>\u901a\u4fd7\u70b9\u8bf4\uff0c\u8fd9\u91cc\u7684 tokenEmbedding \u5c31\u662f\u901a\u8fc7\u4e00\u4e2a1D \u5377\u79ef\u5b9e\u73b0\u7684\uff0c\u5177\u4f53\u7684\u5f62\u72b6\u53d8\u5316\u6ce8\u91ca\u4e2d\u4e5f\u7ed9\u51fa\u4e86\u3002</p> <p>\u600e\u4e48\u751f\u6210\u6ce8\u91ca\uff1f</p> <p>\u9996\u5148\u628a\u4ee3\u7801\u7c98\u7ed9 gpt\uff0c\u7136\u540e\uff0c\u8ddf\u5b83\u8bf4\uff1a<code>\u4e3a\u6bcf\u884c\u4ee3\u7801 \u6dfb\u52a0 \u4e24\u884c\u6ce8\u91ca\uff0c\u4e00\u884c\u8bf4\u660e\u8fd9\u884c\u4ee3\u7801\u7684\u76ee\u7684\uff0c\u4e00\u884c\u8bf4\u660e \u5f62\u72b6\u7684\u53d8\u5316\u548c\u64cd\u4f5c \u5f62\u72b6-&gt;\u64cd\u4f5c-&gt;\u5f62\u72b6\u7684\u683c\u5f0f\uff0c\u64cd\u4f5c\u7684\u683c\u5f0f\u7c7b\u4f3c DecoderLayer.forward \u663e\u793a\u51fa\u8c03\u7528\u7684\u4ec0\u4e48\u7c7b\u540d.\u65b9\u6cd5</code></p> <p>\ud83d\udd35 \u63a5\u4e0b\u6765\u770b \u4f4d\u7f6e\u7f16\u7801 Positional Embedding\uff0c\u7531\u4e8e\u8fd9\u91cc\u6ca1\u6709\u7528\uff0c\u5c31\u4e0d\u8bf4\u4e86\u3002</p> <p>\ud83d\udd35 \u6700\u540e\uff0c\u65f6\u95f4\u6233\u7f16\u7801\uff0c</p> <p></p> <p>\u6ce8\u610f\u8fd9\u91cc\u7684\u65f6\u95f4\u6233\u7f16\u7801\u662f\u6709\u4e00\u4e2a\u5224\u65ad\u7684\uff0c\u7ecf\u8fc7\u8c03\u8bd5\uff0c\u6211\u4eec\u8fd9\u91cc\u8c03\u7528\u7684\u662f <code>TimeFeatureEmbedding</code> \u7c7b\u3002</p> <p>\u4e5f\u5c31\u662f\u8bf4\u4ec0\u4e48\u610f\u601d\uff0c\u8fd9\u4e2a\u56fe\u753b\u7684\u6709\u95ee\u9898\uff0c\u4e0d\u8fc7\u610f\u601d\u4e5f\u662f\u5bf9\u7684\uff0c\u5c31\u4e0d\u6df1\u7a76\u4e86\u3002</p> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u8df3\u5230 <code>TimeFeatureEmbedding</code> \u8fd9\u4e2a\u7c7b\u7684\u5b9a\u4e49\u3002</p> <p> </p> <p>\u5c31\u662f\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\uff0c\u5c06 \u65f6\u95f4\u6233\u7279\u5f81\u5d4c\u5165\u5230\u6307\u5b9a\u7ef4\u5ea6\u3002</p> <p>\u9996\u5148\uff0c\u5d4c\u5165\u5230\u6307\u5b9a\u7ef4\u5ea6\u662f\u56e0\u4e3a\u9ad8\u7ef4\u5411\u91cf\u8868\u793a\u7279\u5f81\u66f4\u7cbe\u7ec6\u3002</p> <p>\u5176\u6b21\uff0c\u6211\u4eec\u8fd9\u91cc\u4f7f\u7528\u7684\u662f\u75be\u75c5\u6570\u636e\u96c6\uff0c\u662f\u5c0f\u65f6\u7684\uff0c\u6240\u4ee5\u7ef4\u5ea6 4\uff0c\u8868\u793a\u7684\u7684\u662f\uff0c\u5c0f\u65f6-\u5929\uff0c\u5929-\u5468\uff0c\u5929-\u6708\uff0c\u5929-\u5e74\u3002\u8fd9\u4e00\u90e8\u5206\u4e5f\u8bf4\u8fc7\u5f88\u591a\u6b21\u4e86\uff0c\u518d\u8bf4\u4e00\u6b21\uff0c\u52a0\u6df1\u5370\u8c61\u3002</p> <p>\u5177\u4f53\u6765\u8bf4\u8f93\u5165\u7684 <code>x_mark.shape=32,36,4 \u2192 nn.Linear \u2192 32,36,512</code></p> <p>\u63a5\u4e0b\u6765\uff0c\u603b\u7ed3\u4e00\u4e0b\u8fd9\u91cc\u7684\u5d4c\u5165\u3002\u9996\u5148 \u672c\u6587\u7528\u5230\u7684\u6240\u6709\u5d4c\u5165\u90fd\u5b9a\u4e49\u5728\u4e86  <code>Embed.py</code>\u6587\u4ef6\u4e2d</p> <p></p> <p>\u800c\u8fd9\u4e2a\u6587\u4ef6\u4e2d\uff0c\u53c8\u5b9a\u4e49\u4e86\u6240\u6709\u7684\u5d4c\u5165\u7c7b\uff0c\u53c8\u6709 8 \u4e2a\u3002</p> <p>\u9898\u5916\u8bdd\uff0c\u8fd9\u4e2a\u600e\u4e48\u770b\uff0c\u662f vscode \u7684\u5927\u7eb2\u89c6\u56fe\uff0c\u627e\u51fa\u6765\uff0c\u5c31\u80fd\u770b\u5230\u4e86</p> <p></p> <p>\u5927\u7eb2\u89c6\u56fe\u4e2d\uff0c\u7acb\u65b9\u4f53\u8868\u793a\u5b9a\u4e49\u7684\u51fd\u6570\uff0c\u5c0f\u6811\u6748\u7684\u4e1c\u897f\u662f\u7c7b\uff0c\u7c7b\u4e2d\u6709\u5c0f\u7acb\u65b9\u4f53\uff0c\u662f\u7c7b\u4e2d\u5b9a\u4e49\u7684\u51fd\u6570\uff0c\u7c7b\u4e2d\u5b9a\u4e49\u7684\u51fd\u6570\uff0c\u4e5f\u5c31\u662f\u5c0f\u7acb\u65b9\u4f53\u4e2d\uff0c\u6298\u53e0\u7684\u90e8\u5206\u662f \u4f7f\u7528\u8fd9\u4e2a\u51fd\u6570\u6216\u8005\u7c7b\u6240\u9700\u8981\u7684\u521d\u59cb\u5316\u53c2\u6570\u3002\u65b9\u62ec\u53f7+\u5c0f\u7acb\u65b9\u4f53\u5305\u62ec\u7684\u90e8\u5206\u662f \u7c7b\u4e2d\u8c03\u7528\u7684\u7c7b\u7684\u5bf9\u8c61\u540d\uff0c\u6bd4\u5982\u8fd9\u91cc\uff1a</p> <p></p> <p>\u4ee5\u8fd9\u4e2a TemporalEmbedding \u7c7b\u4e3a\u4f8b\uff0c \u8fd9\u4e2aTemporalEmbedding \u7c7b\u4e2d\u6709\u4e24\u4e2a\u65b9\u6cd5\u65b9\u6cd5\uff0c\u5206\u522b\u662f init \u548c forward\u3002</p> <p>init \u6298\u53e0\u7684\u90e8\u5206\u662f \u521d\u59cb\u5316\u8fd9\u4e2a\u7c7b\u6240\u9700\u8981\u7684\u53c2\u6570\uff0c forward \u6298\u53e0\u7684\u90e8\u5206\u662f\u8c03\u7528\u8fd9\u4e2a\u65f6\u6240\u9700\u8981\u7684\u53c2\u6570\uff0c\u5176\u4e2d init \u90e8\u5206\u8fd8\u5b9e\u4f8b\u5316\u4e86 5 \u4e2a\u5bf9\u8c61\uff0c\u5bf9\u8c61\u540d\u5206\u522b\u662f mintue_embed\u3001hour_embed\u3001weekday_embed\u3001day_embed\u3001month_embed\uff0c\u4f46\u662f\u8fd9\u91cc\u5177\u4f53\u5b9e\u4f8b\u5316\u7684\u54ea\u4e2a\u7c7b\u3002\u8fd9\u91cc\u662f\u6ca1\u6709\u663e\u793a\u7684\uff0c\u5f97\u70b9\u8fdb\u53bb\u81ea\u5df1\u770b\uff0c\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a\u5bf9\u8c61\u5176\u5b9e\u90fd\u662f\u5b9e\u4f8b\u5316\u7684Embed \u8fd9\u4e2a\u7c7b\uff0c\u5f88\u660e\u663e\u662f\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684\uff0c\u60f3\u770b\u8fd8\u5f97\u6b65\u8fdb\u770b\u5177\u4f53\u5b9e\u4f8b\u5316\u7684\u54ea\u4e2a\u7c7b\u3002</p> <p>\u4ee5\u4e0a\u5b8c\u6210\u4e86 Encoder Input \u7684 Embedding \u90e8\u5206\uff0c\u5206\u522b\u8fdb\u884c\u4e86 token Embedding \u548c TemporaryEmbedding\u6765\u5bf9\u5386\u53f2\u65f6\u95f4\u6b65\u7279\u5f81\u8fdb\u884c\u5d4c\u5165\u548c\u65f6\u95f4\u7279\u5f81\u8fdb\u884c\u5d4c\u5165\u3002</p> <p>\u6c47\u603b\u8fd9\u91cc\u7684\u7ef4\u5ea6\u5f62\u72b6\u53d8\u5316\uff1a</p> Python<pre><code># x [B, L, D] \u2192 permute \u2192 [B, D, L] \u2192 \u5377\u79ef \u2192 [B, d_model, L] \u2192 transpose \u2192 [B, L, d_model]\n# x_mark [B, L, d_inp] \u2192 \u7ebf\u6027\u5c42\u53d8\u6362(\u65f6\u95f4\u7279\u5f81\u6574\u4f53\u6620\u5c04) \u2192 [B, L, d_model]\n# [B, L, d_model] + [B, L, d_model] \u2192 [B, L, d_model]\n</code></pre> <p>\u63a5\u4e0b\u6765\u60f3\u7ed9\u5927\u5bb6\u8bf4\u7684\u662f\uff0c 1D \u5377\u79ef\u600e\u4e48\u8fdb\u884c\u7684 tokenEmbedding\uff1a </p> <p>\u5c0f\u5c0f\u7684\u70b9\uff0c\u5c0f\u5c0f\u7684\u6ce8\u610f\u3002</p> <p>\u63a5\u6536\u7684\u6807\u51c6\u8f93\u5165\u662f BLD</p> <ul> <li>\u9996\u5148\u8fdb\u884c\u7684\u662f permute\uff0c\u5c06\u60f3\u8981\u5d4c\u5165\u7684\u7ef4\u5ea6<code>D</code> \u79fb\u5230\u4e2d\u95f4\uff0c\u7136\u540e\u8fdb\u884c 1D \u5377\u79ef\uff0c\u5d4c\u5165\u5230 <code>d_model</code>  \uff08 <code>Embedding dim</code>\uff09\uff0c\u5bf9\u5e94\u5230 1D \u5377\u79ef\u4e2d\uff0c\u5c31\u662f\u8f93\u5165\u901a\u9053\u662f D\uff0c\u8f93\u51fa\u901a\u9053\u662f <code>d_model</code></li> </ul> <p></p> <ul> <li>\u4e3a\u4ec0\u4e48\u8fd9\u4e48\u505a\uff1f\u56e0\u4e3a\u5377\u79ef\u6700\u5f00\u59cb\u4e3b\u8981\u7528\u4e8e\u56fe\u50cf\uff0c\u56fe\u50cf\u7684\u6807\u51c6\u683c\u5f0f\u662f BCHW\uff0c\u56fe\u50cf\u4e2d\u7684 HW \u5c31\u8868\u793a\u56fe\u50cf\u7684\u7279\u5f81\uff0c\u53ea\u4e0d\u8fc7\u662f\u7528 2D\u7684\u77e9\u9635 \u8868\u793a\u7684\uff0c\u800c\u4e14\u8fd9\u4e2a 2D \u77e9\u9635\u4fdd\u5b58\u4e86\u4f4d\u7f6e\u4fe1\u606f\uff0c\u4e0d\u80fd\u968f\u610f\u5c55\u5e73\u3002\u90a3\u6b64\u65f6\uff0cC \u4e5f\u5c31\u53ef\u4ee5\u7406\u89e3\u4e3a\u6bcf\u4e2a\u50cf\u7d20\u7684\u7279\u5f81\u6570\u3002\u6bd4\u5982\u6bcf\u4e2a\u50cf\u7d20\u7528\u5f69\u8272\u7684 RGB \u4e09\u4e2a\u5143\u7d20\u8868\u793a\u3002</li> <li>\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u7684\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684 1D \u5377\u79ef\uff0c\u4e5f\u4eff\u7167\u56fe\u50cf\u4e2d\u5377\u79ef\u7684\u5b9a\u4e49\uff0c\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\u6570\u653e\u5230\u4e2d\u95f4\uff0c\u8868\u793a\u8f93\u5165\u901a\u9053\u6570\uff0c\u7136\u540e\u5c06\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\uff0c\u6620\u5c04\u5230\u8f93\u51fa\u7ef4\u5ea6\u5927\u5c0f\uff0c\u8fd9\u91cc\u8868\u793a\u4e3a <code>Embedding dim</code>\uff0c\u4e5f\u5c31\u662f <code>d_model</code>\u3002</li> </ul> <p>\u7528\u4e00\u5f20\u56fe\u6765\u8868\u793a\uff0c(\u8fd9\u91cc\u5176\u5b9e\u5f88\u50cf SegRNN \u7684\u89c6\u89d2\u8f6c\u6362)\uff1a</p> <p></p> <p>\u800c \u65f6\u95f4\u6233\u7279\u5f81\u7684 nn.Linear\u5c31\u662f\u76f4\u63a5\u5bf9\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5d4c\u5165\u4e86</p> <p><code>x_mark [B, L, d_inp] \u2192 \u7ebf\u6027\u5c42\u53d8\u6362(\u65f6\u95f4\u7279\u5f81\u6574\u4f53\u6620\u5c04) \u2192 [B, L, d_model]</code></p> <p>pytorch\u4e2d\u5e38\u7528\u7684\u662f\u7ef4\u5ea6\u53d8\u6362\u51fd\u6570 permute\u3001transpose\u3001view \u90fd\u662f\u76f4\u63a5\u5199\u7ef4\u5ea6\u53d8\u6362\u3002</p> <p>\u5e26\u7740\u8d70\u4e00\u904d\u4ee3\u7801\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#encoder-forward","title":"Encoder forward","text":"<p>\u884c\u4e86\uff0c\u5d4c\u5165\u8bb2\u5b8c\u4e86\uff0c\u63a5\u4e0b\u6765\uff0c\u8fdb\u5165\u6b63\u5f0f\u7684 Encoder \u7684\u90e8\u5206\u7684\u6570\u636e\u6d41\u52a8\u3002</p> <p>\uff08\u7ec8\u4e8e\uff09</p> <p></p> <p>\u4ece Autoformer forward \u7684 self.encoder \u8fdb\u5165\u3002</p> <p>\u5728\u6b65\u8fdb\u4e4b\u524d\u770b\u4e00\u773c\u600e\u4e48\u521d\u59cb\u5316\u7684\u3002\u975e\u5e38\u590d\u6742\uff1a</p> <p></p> <p>\u6765\u76f4\u63a5\u770b\u56fe\u5427\uff0c\u5177\u4f53\u600e\u4e48\u590d\u6742\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#_10","title":"\u7c7b\u56fe","text":"<pre><code>classDiagram\n    class Model {\n        +Encoder encoder\n    }\n\n    class Encoder {\n        +List~EncoderLayer~ layers\n        +my_Layernorm norm_layer\n        +forward(x, attn_mask)\n    }\n\n    class EncoderLayer {\n        +AutoCorrelationLayer attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, attn_mask)\n    }\n\n    class AutoCorrelationLayer {\n        +AutoCorrelation attention\n        +Linear query_projection\n        +Linear key_projection\n        +Linear value_projection\n        +Linear out_projection\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class AutoCorrelation {\n        +bool mask_flag\n        +int factor\n        +float scale\n        +Dropout dropout\n        +bool output_attention\n        +time_delay_agg_training(values, corr)\n        +time_delay_agg_inference(values, corr)\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    Model --&gt; Encoder\n    Encoder --&gt; EncoderLayer\n    EncoderLayer --&gt; AutoCorrelationLayer\n    EncoderLayer --&gt; Conv1d\n    EncoderLayer --&gt; series_decomp\n    AutoCorrelationLayer --&gt; AutoCorrelation\n</code></pre> <p>\u9996\u5148\u56fe\u4e2d\u6e05\u695a\u7684\u5c55\u793a\u4e86\uff0c\u5c31\u56fe\u6765\u8bf4\uff1a</p> <p> </p> <p>\u901a\u8fc7 Autoformer \u5b9a\u4e49\u7684 model \u4e2d\uff0c\u5b9a\u4e49\u4e86\u8fd9\u4e2a Encoder \u7c7b\uff0c\u4f20\u7ed9\u4e86 self.encoder \u3002</p> <p>\u63a5\u7740\u770b\u8fd9\u4e2a Encoder \u7c7b\u7684\u5b9a\u4e49\uff0c\u8fd9\u4e2a Encoder \u7684\u521d\u59cb\u5316\u8c03\u7528\u4e86EncoderLayer\u7c7b\uff0c\u4f20\u7ed9\u4e86 layers\uff08\u5c31\u662fEncoderLayer\u7c7b\u7684\u5b9e\u4f8b\u5316\u5bf9\u8c61\uff09\u3002</p> <p>\u5bf9\u5e94\u5230\u4ee3\u7801\uff1a</p> <p></p> <p>\u63a5\u7740\uff0cEncoder \u7c7b\u8c03\u7528\u4e86 EncoderLayer \u7c7b\uff0c\u90a3\u63a5\u4e0b\u6765\u5c31\u770b EncoderLayer \u7684\u5b9a\u4e49\uff1a</p> <p></p> <p>\u770b\u56fe\u4ee5\u53ca\u4ee3\u7801\uff1a</p> <p></p> <p>\uff08\u770b\u4ee3\u7801\uff09\uff1a\u7ea2\u6846\u662f\u4e0a\u9762\u8bb2\u7684\uff0c<code>Encoder</code> \u7684\u521d\u59cb\u5316\u9700\u8981\u8c03\u7528 <code>EncoderLayer</code> \u7c7b</p> <p>\u7b2c\u4e00\u4e2a\u7ea2\u6846\u8868\u793a\uff0c<code>EncoderLayer</code> \u4e2d\u7684 <code>init</code> \u521d\u59cb\u5316\u4e2d\u53c8\u8c03\u7528\u4e86 <code>AutoCorrelationLayer</code> \u7c7b\uff0c\u5e76\u4e14\u4f20\u5165\u4e86  <code>EncoderLayer</code> \u521d\u59cb\u5316\u8fc7\u7a0b\u4e2d\u6240\u9700\u8981\u7684\u53c2\u6570 \uff0c\u53bb <code>EncoderLayer</code> \u8fd9\u4e2a\u7c7b\u3002</p> <p></p> <p>\u7ed3\u5408 \u56fe \u548c \u4ee3\u7801\uff0c\u8fd9\u90e8\u5206\u5c31\u53ef\u4ee5\u7406\u89e3\u4e86\u3002</p> <p> </p> <p>\u4e3b\u8981\u7684\u590d\u6742\u70b9\u5c31\u662f\u521d\u59cb\u5316\u4e00\u4e2a\u7c7b\u7684\u540c\u65f6\u53c8\u9700\u8981\u521d\u59cb\u5316\u53e6\u4e00\u4e2a\u7c7b\uff0c\u521d\u59cb\u5316\u53e6\u4e00\u4e2a\u7c7b\u53c8\u9700\u8981\u521d\u59cb\u5316\u7c7b\u3002\u597d\u597d\u770b\u770b\u662f\u53ef\u4ee5\u7406\u89e3\u7684\u3002</p> <p>\u540e\u9762\u8fd8\u6709 AutoCorrelationLayer \u7684\u521d\u59cb\u5316\uff0c\u53c8\u8981\u8c03\u7528 AutoCorrelation \u7c7b</p> <p></p> <p>\u7406\u89e3\u7684\u903b\u8f91\u662f\u4e00\u6837\u7684\u3002</p> <p>\u9996\u5148\u4ee3\u7801 Autoformer forward Encoder\u7684\u521d\u59cb\u5316\u8fc7\u7a0b\u4e2d\uff0c\u7ed9\u51fa\u4e86\u6bcf\u4e2a\u7c7b\u521d\u59cb\u5316\u6240\u9700\u8981\u7684\u4f20\u5165\u53c2\u6570</p> <p></p> <p>\u800c\u4e0a\u9762 mermaid \u753b\u7684\u56fe\uff0c\u5c55\u793a\u4e86\u6bcf\u4e2a\u7c7b\u4e2d init \u4e2d\u5177\u4f53\u8c03\u7528\u7684\u7c7b\u548c\u5b9e\u4f8b\u5316\u7684\u5bf9\u8c61\u540d\u3002\u4ee5\u53ca\u9664\u4e86 init \u65b9\u6cd5\u5916\uff0c\u8fd8\u6709\u7c7b\u4e2d\u53ef\u4ee5\u8c03\u7528\u7684\u65b9\u6cd5\uff0c\u6bd4\u5982 AutoCorrelation\u4e2d\uff0c\u9664\u4e86 init\u3001forward \u4ee5\u5916\uff0c\u8fd8\u6709 <code>time_delay_agg_training</code>  \u548c <code>time_delay_agg_inference</code> </p> <p></p> <p>\u8fd9\u90e8\u5206\u8c03\u7528\u5173\u7cfb\u5e0c\u671b\u6211\u8bb2\u660e\u767d\u4e86\uff0c\u518d\u7528\u4e00\u5f20\u56fe\u8bf4\u660e\u4e00\u4e0b\uff1a</p> <p></p> <p>\u5c31\u662f\u8bf4\u5728\u6211\u4eec\u5728 Encoder forward \u4e2d\u4f20\u5165\u5230\u7684x\uff0c\u4f1a\u4f20\u5165\u5230 EncoderLayer \u4e2d\u7684 forward \u4e2d\u8fdb\u884c\u5904\u7406\uff0c\u800c   EncoderLayer forward \u4e2d\u53c8\u8c03\u7528\u4e86 AutoCorrelation Layer \u4e2d\u7684 forward\uff0c\u7136\u540e\u5462\uff0cAutoCorrelation Layer \u4e2d\u7684 forward\u53c8\u8c03\u7528\u4e86 AutoCorrelation\u7684 forward\uff0c\u6700\u540eAutoCorrelation\u53c8\u8c03\u7528\u4e86\u81ea\u5df1 AutoCorrelation time delay agg tranning \u6216\u8005 inference\u3002</p> <p>\uff08\u8c01\u61c2\u554a\u3002\u5f53\u521d\u9010\u6b65\u8c03\u8bd5\u7684\u65f6\u5019\uff0c\u6b65\u8fdb\u4e00\u4e2a\u53c8\u6b65\u8fdb\u4e00\u4e2a\uff0c\u90fd\u627e\u4e0d\u5230\u5934 T_T\uff09\uff0c\u4e3a\u4ec0\u4e48\u8bf4\u8fd9\u90e8\u5206\u8c03\u7528\u4e0d\u597d\u7406\u89e3\uff0c\u662f\u56e0\u4e3a\u6309\u7406\u8bf4\uff0cforward \u4e2d\u6709\u8c03\u7528\uff0c\u53bb init \u4e2d\u627e\u3002</p> <p>\u5177\u4f53\u6765\u8bf4\uff0cAutoformer \u7684 forward \u4e2d\u8c03\u7528\u4e86 <code>self.encoder</code> \uff0c\u5728 init \u4e2d\u627e\u5230\u4e86</p> <p></p> <p>\u90a3\u6309\u4f4f command\uff0c\u8df3\u8fdbEncoder \u7684\u5b9a\u4e49\uff0c\u4e0d\u7ba1\u662f init \u8fd8\u662f forward \u4e2d\u90fd\u6ca1\u6709\u663e\u793a\u7684\u8bf4\u660e attn_layer\u662f\u8c03\u7528\u7684\u4ec0\u4e48\u3002</p> <p></p> <p>\u6240\u4ee5\u6700\u5f00\u59cb\u6b65\u8fdb\u8fd9\u91cc\u7684\u65f6\u5019\uff0c\u5c31\u5f88\u6655\u3002\u5176\u5b9e\u8fd9\u91cc\u6240\u6709\u7684\u521d\u59cb\u5316\u4ee5\u53ca\u8c03\u7528\u90fd\u5728\u6700\u6700\u5f00\u59cb\u7684  Autoformer \u7684 self.encoder\u7684\u521d\u59cb\u5316\u4e2d\u7ed9\u4e86\u3002\u5728\u540e\u9762\u5b9a\u4e49\u7684\u7c7b\u4e2d\uff0c\u6309\u4f4f command \u4e0d\u80fd\u8df3\u5230\u7c7b\u7684\u5b9a\u4e49\u3002\u5f97\u4ece\u5934\u5f00\u59cb\u3002\u5f53\u7136\u4e86\uff0c\u6b65\u8fdb\u5c31\u4e0d\u7528\u7ba1\u8fd9\u4e9b\u4e86\u3002\u81ea\u5df1\u5c31\u8df3\u6765\u8df3\u53bb\u4e86\u3002</p> <p>\u597d\u4e86 \u4ee5\u4e0a\u5b8c\u6210\u4e86 self.encoder\u7684\u521d\u59cb\u5316\uff0c\u521a\u521a\u662f\u5bf9 \u7f16\u7801\u5668\u6240\u63a5\u6536\u7684\u8f93\u5165\u8fdb\u884c\u5d4c\u5165\uff0c\u8fd9\u91cc\u662f\u6a21\u578b\u7684\u5b9a\u4e49</p> <p>\u57fa\u4e8e\u4ee5\u4e0a\u7684\u8ba4\u8bc6\uff0c\u63a5\u4e0b\u6765\u8fdb\u5165 forward \u4e2d\uff0c\u770b\u6570\u636e\u7684\u6d41\u52a8\u8fc7\u7a0b\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#encoderlayer","title":"EncoderLayer","text":"<p>\u9996\u5148\uff0c\u4ece \u2b07\ufe0f \u5f00\u59cb\u6b65\u8fdb\u3002</p> Python<pre><code> enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n</code></pre> <p>\u5982\u6211\u4eec\u6240\u6599\uff0c\u6b65\u8fdb\u5230\u4e86 Encoder \u7c7b\u7684 forward\uff1a</p> <p></p> <p>\u7ee7\u7eed\u6b65\u8fdb\uff0c\u4e00\u6b65\u6b65\u6267\u884c\uff1a</p> <p></p> <p>\u6761\u4ef6\u5224\u65ad\u6267\u884c else\uff0c\u8df3\u5230</p> <ul> <li> \u6bcf\u4e00\u6b65\u7684\u73b0\u5b9e\u610f\u4e49\u5728\u505a\u4ec0\u4e48</li> <li> \u5f62\u72b6\u53d8\u5316\u3001\u8c03\u7528\u5173\u7cfb</li> </ul> <p></p> <p>EncoderLayer \u7684 forward \u4e2d\u8c03\u7528\u4e86\u81ea\u76f8\u5173\u673a\u5236\uff08\u81ea\u76f8\u5173\u673a\u5236=AutoCorrelation Layer + AutoCorrelation\uff09\uff0c\u8fd9\u662f\u672c\u6587\u7684\u521b\u65b0\u70b9\uff0c\u540e\u9762\u518d\u8bf4\u3002\u8bba\u6587\u4e2d\u4e5f\u662f\u8bf4\u4e86\u540e\u9762\u518d\u8bf4\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u8fd9\u4e2a\u6a21\u5757\u5c31\u5c31\u662f\u4ee3\u66ff\u4e86\u539f\u59cb Transformer \u7684 self attention \u7684\u8ba1\u7b97\uff0c\u4f60\u770b\u8fd9\u4e2a\u547d\u540d\uff0c\u867d\u7136\u8c03\u7528\u7684\u662fAutoCorrelation Layer\uff0c\u4f46\u662f\u53d8\u91cf\u547d\u540d\u65f6\uff0c\u4ecd\u7136\u662f self.attention \u4e5f\u5c31\u53ef\u4ee5\u7406\u89e3\u4e3a\u4f5c\u8005\u662f\u6539\u8fdb\u4e86\u539f\u59cb Transformer \u4e2d\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3002</p> <p>\u56e0\u6b64\u6211\u4eec\u8fd9\u91cc\u5728\u8c03\u8bd5 Encoder \u7684\u5177\u4f53\u8fc7\u7a0b\u65f6\uff0c\u6682\u65f6\u4e0d\u6b65\u8fdb\u5230 self.attention\u7684\u5177\u4f53\u7684\u6267\u884c\u8fc7\u7a0b\u4e2d\u3002</p> <p>\u5355\u4e2a Encoder \u7684\u6267\u884c\u5c31\u662f \u6267\u884c\u4e00\u6b21 EncoderLayer\uff0c\u6709\u51e0\u4e2a Encoder\u5c31\u6267\u884c\u51e0\u6b21 EncoderLayer\u3002</p> <p>\u73b0\u5728\u8bf4\u660e\u8fd9\u4e2a EncoderLayer \u7684\u6267\u884c\u8fc7\u7a0b\uff1a</p> Text Only<pre><code>def forward(self, x, attn_mask=None)\n</code></pre> <p>\u9996\u5148 EncoderLayer \u63a5\u6536\u7684\u8f93\u5165\u662f x\uff0cmask \u662f\u53ef\u9009\u53c2\u6570\u3002</p> <p>\u8f93\u5165<code>x</code>\u5f62\u72b6\u4e3a[B, L, d_model]</p> Text Only<pre><code>       new_x, attn = self.attention(\n            x, x, x,\n            attn_mask=attn_mask\n        )\n</code></pre> <p>\u63a5\u4e0b\u6765\u8fdb\u884c Encoder \u90e8\u5206\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u8ba1\u7b97\uff0c\u8fd9\u91cc\u5b9e\u9645\u8c03\u7528\u7684\u662f\u4f5c\u8005\u7684\u521b\u65b0\u6a21\u5757\uff0c\u81ea\u76f8\u5173\u5c42\u3002\u540e\u9762\u4e0d\u518d\u533a\u5206\u53eb\u6cd5\u3002</p> <p>\u81ea\u6ce8\u610f\u529b\u673a\u5236==\u63a5\u6536==\u7684\u53c2\u6570 qkv\u90fd\u7b49\u4e8e x\uff0c\u56e0\u4e3a\u662f\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5f62\u72b6\u662f\u4e00\u6837\u7684 [B, L, d_model]\u3002</p> <p>\u8fd9\u91cc\u7684 <code>attn_mask=None</code></p> <p>\u81ea\u6ce8\u610f\u529b\u673a\u5236\u8fd4\u56de\u7684 \u53d8\u91cf\u6709 <code>new_x</code>, <code>attn</code>\uff0c\u5f62\u72b6\u5206\u522b\u662f</p> <p>new_x<code>[B, L, d_model]</code>\u548c\u6ce8\u610f\u529b\u6743\u91cdattn<code>[B, n_heads, L, L]</code></p> <p>\u8fd9\u91cc\u7684 new_x \u610f\u601d\u662f \u6709\u4e86\u5bf9\u5176\u4ed6\u65f6\u95f4\u6b65\u6743\u91cd\u7684 x\uff0cattn \u5b58\u7684\u662f\u4e24\u4e24\u65f6\u95f4\u6b65\u4e4b\u95f4\u7684\u6ce8\u610f\u529b\u5f97\u5206\u3002\uff08\u5f53\u7136\u4e86\uff0c\u8fd9\u662f\u539f\u59cb \u81ea\u6ce8\u610f\u529b\u673a\u5236 \\(softmax(\\frac{QK^T}{\\sqrt{d_k}})V\\) \u7684\u8ba1\u7b97\uff0c\u8bba\u6587\u5b9e\u73b0\u7684\u8fd9\u91cc\u9762\u662f\u5565\u518d\u8bf4\uff09</p> Python<pre><code>x = x + self.dropout(new_x)\n</code></pre> <p>\u63a5\u4e0b\u6765\uff0c\u5355\u4e2a Encoder \u7684\u8f93\u51fa \u662f <code>dropout(new_x)</code> \uff0c\u518d\u7ecf\u8fc7\u6b8b\u5dee\u8fde\u63a5\u3002\u8fd9\u91cc\u5c31\u662f\u539f\u59cb Transformer \u67b6\u6784\u3010\u89c1\u9644\u5f55\u3011\u4e2d\u7684\u4e1c\u897f\uff0c\u4e5f\u5c31\u662f\u7ecf\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u540e\u8fdb\u884c \u6b8b\u5dee\u8fde\u63a5\u548c\u5f52\u4e00\u5316\u3002</p> Python<pre><code>x, _ = self.decomp1(x)\n</code></pre> <p>\u63a5\u4e0b\u6765\uff0c\u662f\u5e8f\u5217\u5206\u89e3</p> <p></p> <p>\u5e8f\u5217\u5206\u89e3\u7684\u7b2c\u4e00\u4e2a\u8fd4\u56de\u503c\u662f\u5b63\u8282\u6210\u5206\uff0c\u7b2c\u4e8c\u4e2a\u8fd4\u56de\u503c\u662f\u4f7f\u7528\u79fb\u52a8\u5e73\u5747\u5f97\u5230\u8d8b\u52bf\u6027\u6210\u5206</p> <p>\u5728 Encoder \u4e2d\u4f7f\u7528\u7684\u5e8f\u5217\u5206\u89e3\u65f6\uff0c\u4e0d\u8981\u8d8b\u52bf\u6210\u5206\uff0c\u53ea\u7559\u4e0b\u5b63\u8282\u6210\u5206</p> <p>\u63a5\u6536\u7684\u53c2\u6570 x \u662f\u8981\u5206\u89e3\u7684\u539f\u59cb\u5e8f\u5217\uff0c\u5f62\u72b6\u662f [B, L, d_model]</p> <p>\u8fd4\u56de\u7684\u53c2\u6570 x \u662f\u5206\u89e3\u4ee5\u540e\u7684\u5b63\u8282\u6210\u5206\uff0c\u5f62\u72b6\u4f9d\u7136\u662f [B, L, d_model]</p> <p> </p> <p>\u8fd9\u90e8\u5206\u4ee3\u7801\u5c31\u662f\u539f\u6587\u516c\u5f0f 3 \u7684\u7b2c\u4e00\u884c\u516c\u5f0f\u3002</p> <p>\u628a\u4ee3\u7801\u8d34\u5230\u8fd9\u91cc\u518d\u4f53\u4f1a\u4e00\u4e0b\uff1a</p> <p></p> <p>\u5bf9\u7b2c <code>l-1</code> \u5c42 Encoder \u7684\u8f93\u51fa\u8fdb\u884c\u81ea\u76f8\u5173\u673a\u5236\u7684\u8ba1\u7b97\uff0c\u5f97\u5230\u7684\u8f93\u51fa\u4e0e\u539f\u59cb\u7684 x \u8fdb\u884c\u6b8b\u5dee\u8fde\u63a5\uff0c\u6700\u540e\u5bf9\u6b8b\u5dee\u8fde\u63a5\u4ee5\u540e\u7684\u8f93\u51fa\u8fdb\u884c\u8d8b\u52bf\u5206\u89e3\uff0c\u540c\u65f6\u53ea\u4fdd\u7559 \u5b63\u8282\u6210\u5206\uff0c\u5ffd\u7565\u6389\u8d8b\u52bf\u6210\u5206\u3002</p> <p>\u63a5\u4e0b\u6765\uff0c\u8fdb\u884c\u516c\u5f0f 3 \u7684\u7b2c\u4e8c\u884c\u516c\u5f0f\u6240\u5bf9\u5e94\u7684\u4ee3\u7801\u8bb2\u89e3\uff1a </p> Python<pre><code>y = x\n</code></pre> <p>\u4e0b\u4e00\u53e5\uff0c\u65b0\u5efa x \u7684\u526f\u672c\uff0c\u4fdd\u5b58\u6210 y\uff0c\u540e\u9762\u90fd\u5bf9 x \u7684\u526f\u672c \u4e5f\u5c31\u662f\u8fd9\u4e2a y \u64cd\u4f5c\uff0cx \u5148\u653e\u7740\u4e0d\u7528\uff0c\u540e\u9762\u7528\u4e8e FFN \u4ee5\u540e\u7684 \u6b8b\u5dee\u8fde\u63a5\u3002</p> <p>\u90a3\u5177\u4f53\u8fd9\u91cc\u7684 FFN \u662f\u600e\u4e48\u505a\u7684\u5462\uff1f</p> <p>\u770b\u5230\u4ee3\u7801</p> <p></p> <p>\u4e0d\u770bdropout \u548c\u6fc0\u6d3b\u5c42\uff0c\u56e0\u4e3a\u8fd9\u4e24\u4e2a\u64cd\u4f5c\u5e76\u4e0d\u4f1a\u6539\u53d8\u8f93\u5165\u5f20\u91cf\u7684\u5f62\u72b6\uff0c\u63a5\u4e0b\u6765\u770b\u5230FFN \u662f\u7531\u4e24\u4e2a 1d \u5377\u79ef\u4e5f\u5c31\u662fconv1d \u5b9e\u73b0\u7684\u3002</p> <p></p> <p>\u63a5\u4e0b\u6765\uff0c\u518d\u770b Encoder \u7684 init \u90e8\u5206\uff0c\u8fd9\u4e24\u4e2a 1d \u5377\u79ef\u662f\u600e\u4e48\u5b9a\u4e49\u7684\uff0c\u8bf6\uff0c\u5c31\u662f\u4e00\u4e2a\u5148\u5347\u7ef4\u540e\u964d\u7ef4\u7684\u64cd\u4f5c\uff0c\u5c31\u5b8c\u6210\u4e86 FFN\u3002</p> <p>\u5c31\u662f\u8bf4 self.conv1\u662f\u5c06\u5355\u4e2a\u65f6\u95f4\u6b65\u5d4c\u5165\u7ef4\u5ea6 <code>d_model</code>\u5347\u7ef4\u5230 <code>d_ff</code>\uff1b\u63a5\u4e0b\u6765 self.conv2\u5c31\u662f\u5c06 <code>d_ff</code> \u53c8\u6062\u590d\u6210\u539f\u59cb\u5f62\u72b6 <code>d_model</code>\u3002\u591a\u8bf4\u4e00\u53e5\uff0c\u597d\u50cf\u6ca1\u610f\u4e49\uff0c\u5176\u5b9e\u6709\u610f\u4e49\uff0c\u7b2c\u4e8c\u6b21\u6062\u590d\u7684 <code>d_model</code> \u5176\u5b9e\u662f\u7cbe\u7ec6\u5316\u7684\u5b66\u4e60\u4e86 \u7279\u5f81\u4e0e\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u5173\u5173\u7cfb\uff0c\u5e76\u8fd4\u56de\u7ed9\u4e86 <code>d_model</code> \u4e2d\u8fdb\u884c\u4fdd\u5b58\u3002</p> <p>\u770b\u5230\u4ee3\u7801\uff1a</p> <p></p> <p>\u5173\u4e8e\u8fd9\u91cc\uff0c\u6211\u6709\u4ee5\u4e0b\u51e0\u70b9\u60f3\u8bf4\uff1a</p> <p>\u7b2c\u4e00\u70b9\uff0c\u5347\u7ef4\u7684\u64cd\u4f5c\uff0c\u7ecf\u8fc7 conv1d \u4ee5\u540e\uff0c\u76f8\u5f53\u4e8e\u8fdb\u884c\u4e86\u5168\u8fde\u63a5\uff0c\u4e5f\u5c31\u662f\u76f8\u5f53\u4e8enn.Linear\u7684\u4f5c\u7528\uff0c\u90a3\u5199\u8fc7\u4ee3\u7801\u7684\u90fd\u662f\u5230\uff0cnn.Linear\u4ee5\u540e\u8fdb\u884c\u6fc0\u6d3b\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u589e\u52a0\u6a21\u578b\u7684\u975e\u7ebf\u6027\u8868\u8fbe\u80fd\u529b\uff0c\u8fd9\u70b9\u674e\u6c90\u7684\u4e66\u4e0a\u4e5f\u63d0\u5230\u8fc7\u3002\u8fd9\u91cc\u5c31\u4eff\u7167\u7740 conv1d \u7684\u8f93\u51fa\u4e5f\u52a0\u4e0a\u4e86\u6fc0\u6d3b\u51fd\u6570\u3002\u52a0\u7684\u6240\u6709 dropout \u90fd\u662f\u4e3a\u4e86\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u968f\u673a\u5931\u6d3b\u4e00\u4e9b\u8282\u70b9\u3002</p> <p>\u6807\u51c6\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7684\u8bbe\u8ba1\u6a21\u5f0f\uff1a\u7ebf\u6027\u53d8\u6362\u2192\u975e\u7ebf\u6027\u6fc0\u6d3b\u2192\u7ebf\u6027\u53d8\u6362\uff1b</p> <p>\u5728Transformer\u539f\u59cb\u8bbe\u8ba1\u4e2d\uff0cFFN\u90e8\u5206\u8868\u793a\u4e3a\uff1a</p> Text Only<pre><code>FFN(x) = max(0, xW\u2081 + b\u2081)W\u2082 + b\u2082\n</code></pre> <p>ReLU \u6fc0\u6d3b\u51fd\u6570\u548c\u4e24\u4e2a nn.Linear</p> <p>\u7b2c\u4e8c\u70b9\uff0c\u524d\u9762\u5df2\u7ecf\u8bf4\u8fc7\uff0c1d \u5377\u79ef\u5347\u7ef4\u964d\u7ef4\u6307\u7684\u662f\u901a\u9053\u7ef4\u5ea6\uff0c\u4e5f\u5c31\u662f dim=1\uff0c\u6240\u4ee5\u8fd9\u91cc\u8fdb\u884c 1d \u5377\u79ef\u4e4b\u524d\u4e5f\u662f\u8fdb\u884c\u4e86 transpose\u3002</p> <p>\u7b2c\u4e09\u70b9\uff0c\u4e3a\u4ec0\u4e48\u8fd9\u91cc\u662f conv1d\uff0c\u800c\u4e0d\u662f nn.Linear\uff0c\u56e0\u4e3a\u65f6\u95f4\u5e8f\u5217\u8981\u4fdd\u6301\u65f6\u95f4\u6b65\u7684\u524d\u540e\u5173\u7cfb\uff0c\u6240\u4ee5\u7528 conv1d\uff0c\u7c7b\u4f3c\u6ed1\u52a8\u7a97\u53e3\uff0c\u6cbf\u7740\u65f6\u95f4\u6b65\u7684\u524d\u540e\u987a\u5e8f\u9010\u6b65\u6ed1\u52a8\uff0c\u6bcf\u6b21\u79fb\u52a8 stride \u4e2a\u6b65\u957f\u3002 \uff08\u6211\u7406\u89e3\u7684\u4e0d\u5bf9\uff09\u529f\u80fd\u4e0a\u5c31\u662f\u4e00\u6837\u7684\uff0c\u53ea\u662f\u6570\u636e\u7684\u7ec4\u7ec7\u5f62\u5f0f\u4e0d\u540c\uff0c\u4e0d\u7528\u523b\u610f\u7684\u533a\u5206\u3002</p> <p>\u7b2c\u56db\u70b9\uff0c\u8fd9\u91cc\u7684 d_ff \u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7684\u5d4c\u5165\u662f 2048\u3002</p> <p>d_ff\u901a\u5e38\u8bbe\u7f6e\u4e3ad_model\u76844\u500d\uff0c\u5bf9\u4e8ed_model=512\u7684\u60c5\u51b5\uff0cd_ff\u5c31\u662f2048\u3002\u8fd9\u4e5f\u662fTransformer\u539f\u59cb\u8bba\u6587\u4e2d\u7684\u8bbe\u7f6e\u3002\u589e\u5927\u4e2d\u95f4\u5c42\u7ef4\u5ea6\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u3002</p> <p>\u7b2c\u4e94\u70b9\uff0cself.conv2d\u7684\u8f93\u51fa\uff0c\u5728\u8fdb\u884c\u5f62\u72b6\u53d8\u6362<code>transpose</code>\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u6062\u590d\u6210\u65f6\u95f4\u5e8f\u5217\u7684\u6807\u51c6\u6570\u636e\u683c\u5f0f\u3002</p> <p>\u5c06\u6570\u636e\u683c\u5f0f\u4ece\u5377\u79ef\u53cb\u597d\u7684<code>[B, C, L]</code>\u8f6c\u56de\u5230Transformer\u67b6\u6784\u901a\u7528\u7684<code>[B, L, D]</code>\u683c\u5f0f</p> <p>\u518d\u6b21\u76f4\u89c2\u5730\u8bf4\u660e\u8fd9\u4e00\u90e8\u5206\u5c31\u662f\u8fd9\u6837\u7684\uff1a</p> Text Only<pre><code># \u7b2c\u4e00\u6b65\uff1a\u8f6c\u7f6e\u4f7f\u7279\u5f81\u7ef4\u5ea6\u6210\u4e3a\u901a\u9053\u7ef4\u5ea6\ny.transpose(-1, 1)  # [B, L, d_model] -&gt; [B, d_model, L]\n\n# \u7b2c\u4e8c\u6b65\uff1a\u5e94\u7528\u7b2c\u4e00\u4e2a\u5377\u79ef\u6269\u5c55\u901a\u9053\u7ef4\u5ea6\nself.conv1(...)  # [B, d_model, L] -&gt; [B, d_ff, L]\n\n# \u7b2c\u4e09\u6b65\uff1a\u5e94\u7528\u7b2c\u4e8c\u4e2a\u5377\u79ef\u6062\u590d\u539f\u59cb\u901a\u9053\u7ef4\u5ea6\nself.conv2(...)  # [B, d_ff, L] -&gt; [B, d_model, L]\n\n# \u7b2c\u56db\u6b65\uff1a\u8f6c\u7f6e\u56de\u539f\u59cb\u5e8f\u5217\u683c\u5f0f\n(...).transpose(-1, 1)  # [B, d_model, L] -&gt; [B, L, d_model]\n</code></pre> <p>\u540e\u8bb0\uff1a </p> <ul> <li> \u4ea7\u751f\u7684\u7591\u95ee\uff1a\u4e3a\u4ec0\u4e48Conv2\u4e4b\u540e\u6ca1\u6709\u8fdb\u884c\u6fc0\u6d3b\u51fd\u6570\u7684\u5e94\u7528 </li> </ul> <p>\u76f4\u89c2\u7684\u7406\u89e3\u6211\u7684\u7591\u95ee\uff1a</p> <p>\u73b0\u6709\u8bbe\u8ba1 (\u7b2c\u4e8c\u5c42\u65e0\u6fc0\u6d3b)\uff1a</p> Text Only<pre><code>y = Conv1 -&gt; ReLU -&gt; Dropout -&gt; Conv2 -&gt; Dropout\n</code></pre> <p>\u66ff\u4ee3\u8bbe\u8ba1 (\u4e24\u5c42\u90fd\u6709\u6fc0\u6d3b) </p> Text Only<pre><code>y = Conv1 -&gt; ReLU -&gt; Dropout -&gt; Conv2 -&gt; ReLU -&gt; Dropout\n</code></pre> <ul> <li> \u4e3a\u4ec0\u4e48\u662f conv1d\uff0c\u800c\u4e0d\u662f nn.Linear</li> </ul> <p>\u6ca1\u5565\u5fc5\u8981\u4e86\uff0c\u4e3b\u8981\u662f\u5728\u6570\u636e\u7ec4\u7ec7\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u6709\u5dee\u5f02\uff0cAutoformer\u9009\u62e9Conv1D\u800c\u975eLinear\uff0c\u662f\u57fa\u4e8e\u67b6\u6784\u4e00\u81f4\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u672a\u6765\u6269\u5c55\u6027\uff08\u8bbe\u7f6e kernel size \u4ee5\u540e\u53ef\u4ee5\u6355\u6349\u65f6\u95f4\u6b65\u4e4b\u95f4\u7684\u5c40\u90e8\u76f8\u5173\u6027\uff09\u7684\u8003\u8651\uff0c\u529f\u80fd\u4e0a\u662f\u5b8c\u5168\u4e00\u6837\u7684\u3002</p> <ul> <li> \u6253\u5370\u4e86\u5355\u4e2a EncoderLayer\u7684\u6a21\u578b\u53c2\u6570</li> </ul> <p> </p> <p>\u6700\u540e\u8fd8\u6709\u4e00\u53e5\uff0c\u5c06\u539f\u59cb\u7279\u5f81x\u4e0e\u53d8\u6362\u540e\u7684\u7279\u5f81y\u76f8\u52a0\uff0c\u518d\u6b21\u5e94\u7528\u5e8f\u5217\u5206\u89e3\u63d0\u53d6\u5b63\u8282\u6027\u90e8\u5206</p> Python<pre><code># \u5c06\u539f\u59cb\u7279\u5f81x\u4e0e\u53d8\u6362\u540e\u7684\u7279\u5f81y\u76f8\u52a0\uff0c\u518d\u6b21\u5e94\u7528\u5e8f\u5217\u5206\u89e3\u63d0\u53d6\u5b63\u8282\u6027\u90e8\u5206\n# (x + y)[B, L, d_model] -&gt; \u5e8f\u5217\u5206\u89e3 -&gt; \u8f93\u51fares[B, L, d_model]\u548c\u672a\u4f7f\u7528\u7684\u8d8b\u52bf\u5206\u91cf_[B, L, d_model]\nres, _ = self.decomp2(x + y)\n</code></pre> <p>\u5230\u4e86\u8fd9\u4e00\u6b65\uff0c\u5176\u5b9e\u4ee3\u7801\u8be5\u8bb2\u7684\u4e5f\u8bb2\u5b8c\u4e86\uff0c\u66f4\u91cd\u8981\u7684\u5728\u4e8e\u5f00\u59cb\u601d\u8003\uff0c\u4e3a\u4ec0\u4e48\u8fd9\u6837\u8bbe\u8ba1\uff1f</p> <ul> <li>\u7c98\u8d34\u81ea gpt \u7684\u7b54\u6848\u8d34\u5728\u9644\u5f55\u4e2d\u4e86\uff0c\u89e3\u91ca\u5f97\u633a\u597d\u7684\uff0c\u8fd8\u6709\u548c\u4f20\u7edf Transformer \u7684\u5bf9\u6bd4</li> <li>\uff08\u6211\u7406\u89e3\u7684\u90e8\u5206\u81ea\u5df1\u590d\u8ff0\uff09\u4f7f\u5f97\u7f16\u7801\u5668\u5728\u9010\u5c42\u7f16\u7801\u7684\u8fc7\u7a0b\u4e2d\uff0c\u66f4\u5173\u6ce8\u9ad8\u9891\u7684\u5b63\u8282\u6210\u5206\uff0c\u6240\u4ee5\u6bcf\u6b21\u4f20\u8fdb\u7f16\u7801\u5668\u7684\u662f\uff0c\u629b\u5f03\u4e86\u8d8b\u52bf\u6210\u5206\u7684\u5b63\u8282\u6210\u5206\u3002</li> </ul> <p>\u7f16\u7801\u5668\u4e2d\u5173\u4e8e\u5b63\u8282\u6210\u5206\u3001\u8d8b\u52bf\u6210\u5206\u7684\u7406\u89e3\uff1a</p> Text Only<pre><code>\u8f93\u5165 x [B,L,D] (\u6df7\u5408\u5b63\u8282\u6027\u548c\u8d8b\u52bf)\n  \u2193\n\u81ea\u6ce8\u610f\u529b\u5904\u7406\n  \u2193\n\u6b8b\u5dee\u8fde\u63a5 x + dropout(new_x) (\u4ecd\u542b\u6df7\u5408\u6210\u5206)\n  \u2193\n\u5e8f\u5217\u5206\u89e31 \n  \u2193          \u2198\n\u5b63\u8282\u6027\u5206\u91cfx    \u8d8b\u52bf\u5206\u91cf (\u4e22\u5f03)\n  \u2193\n\u524d\u9988\u7f51\u7edc\u5904\u7406 (Conv1D \u2192 ReLU \u2192 Conv1D)\n  \u2193\n\u524d\u9988\u8f93\u51fa y (\u5b63\u8282\u6027\u7279\u5f81)\n  \u2193\n\u5b63\u8282\u6027\u5206\u91cfx + \u524d\u9988\u8f93\u51fay (\u6df7\u5408\u5b63\u8282\u6027)\n  \u2193\n\u5e8f\u5217\u5206\u89e32\n  \u2193          \u2198\n\u5b63\u8282\u6027\u5206\u91cfres  \u8d8b\u52bf\u5206\u91cf (\u4e22\u5f03)\n  \u2193\n\u8f93\u51fa\u5230\u4e0b\u4e00\u5c42 res (\u7eaf\u5b63\u8282\u6027)\n</code></pre> <p>\u6700\u540e\u8bb0\u4e0b\u4e24\u53e5\u8bdd\u628a\uff1a</p> <ul> <li>\u9891\u7387\u57df\u5206\u6790\uff1a\u4ece\u9891\u7387\u89d2\u5ea6\u770b\uff0c\u8d8b\u52bf\u5bf9\u5e94\u4f4e\u9891\u6210\u5206\uff0c\u5b63\u8282\u6027\u5bf9\u5e94\u9ad8\u9891\u6210\u5206\uff0c\u5206\u5f00\u5904\u7406\u6709\u52a9\u4e8e\u63d0\u53d6\u5404\u81ea\u7684\u7279\u70b9\u3002</li> <li>\u7f16\u7801\u5668\uff1a\u4e13\u6ce8\u4e8e\u6355\u83b7\u5468\u671f\u6027\u548c\u5b63\u8282\u6027\u6a21\u5f0f\uff08\u9ad8\u9891\u6210\u5206\uff09</li> <li>\u867d\u7136\u5728\u7f16\u7801\u5668\u5c42\u5185\u90e8\u4e22\u5f03\u4e86\u8d8b\u52bf\u4fe1\u606f\uff0c\u4f46Autoformer\u5e76\u6ca1\u6709\u5b8c\u5168\u5ffd\u7565\u8d8b\u52bf\u3002</li> <li>\u901a\u8fc7\u5728\u6bcf\u4e00\u5c42\u90fd\u4e22\u5f03\u8d8b\u52bf\u6210\u5206\uff0c\u6a21\u578b\u80fd\u591f\u5728\u591a\u5c42\u5806\u53e0\u8fc7\u7a0b\u4e2d\u6301\u7eed\u5173\u6ce8\u5b63\u8282\u6027\u53d8\u5316\uff0c\u800c\u4e0d\u88ab\u8d8b\u52bf\u53d8\u5316\u5e72\u6270\u3002</li> <li>\u89e3\u7801\u5668\u4e2d\u5355\u72ec\u7d2f\u79ef\u8d8b\u52bf\uff0c\u907f\u514d\u8d8b\u52bf\u9884\u6d4b\u5bf9\u5b63\u8282\u6027\u9884\u6d4b\u7684\u5e72\u6270</li> <li>\u6e10\u8fdb\u5f0f\u5206\u89e3\u67b6\u6784</li> <li>\u6bcf\u5c42\u90fd\u5e94\u7528\u5e8f\u5217\u5206\u89e3\uff0c\u9010\u6b65\u63d0\u70bc\u5b63\u8282\u6027\u7279\u5f81\uff0c\u591a\u5c42\u5806\u53e0\u53ef\u4ee5\u6355\u83b7\u4e0d\u540c\u5c3a\u5ea6\u7684\u5b63\u8282\u6027\u6a21\u5f0f</li> </ul> <p>\u884c\u4e86\uff0c\u4e0a\u9762\u5173\u4e8e\u7f16\u7801\u5668\u7684\u90e8\u5206\u8bb2\u7684\u5dee\u4e0d\u591a\u4e86</p> <p>\u516c\u5f0f </p> <p></p> <p>\u6700\u5f00\u59cb\u4e0a\u6807\u7684 1 \u548c 2 \u4e0d\u660e\u767d\uff0c\u73b0\u5728\u4e5f\u660e\u767d\u4e86\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a 1 \u662f\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u8f93\u51fa\uff0c\u53ea\u4fdd\u7559\u7684\u5b63\u8282\u6210\u5206\uff1b2 \u662f\u7ecf\u8fc7\u524d\u9988\u7f51\u7684\u8f93\u51fa\uff0c\u53ea\u4fdd\u7559\u4e86\u5b63\u8282\u6210\u5206\u3002</p> <p>\u8fd9\u4e9b\u81ea\u6ce8\u610f\u529b\u673a\u5236 \u548c \u524d\u9988\u7f51 \u540e\u9762\u90fd\u6709\u6b8b\u5dee\u8fde\u63a5\u3002\u8fd9\u4e2d\u95f4\u8fd8\u6709 dropout\u3001\u6fc0\u6d3b\u7b49\u3002</p> <p>\u4ee3\u7801</p> Python<pre><code>def forward(self, x, attn_mask=None):\n\n    new_x, attn = self.attention(\n        x, x, x,\n        attn_mask=attn_mask\n    )\n    x = x + self.dropout(new_x)\n    x, _ = self.decomp1(x)\n    y = x\n\n\n    y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n    y = self.dropout(self.conv2(y).transpose(-1, 1))\n    res, _ = self.decomp2(x + y)\n\n    return res, attn\n</code></pre> <p>\u518d\u6765\u770b\u4e00\u773c**\u6587\u4e2d\u6a21\u578b\u7ed3\u6784\u56fe**\uff1a</p> <p> </p> <p>\u53ef\u4ee5\u770b\u5230 \u90fd\u662f\u4e00\u4e00\u5bf9\u5e94\u7684\u3002</p> <p>\u5bf9\uff0c\u8fd8\u6709\u4e00\u4e2a\uff0c\u539f\u6587\u5806\u53e0 Encoder \u7684\u5c42\u6570=2\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#decoder","title":"Decoder","text":"<p>\u4e0b\u9762\u8fdb\u5165\u89e3\u7801\u5668\u90e8\u5206\uff0c\u7981\u7528\u6240\u6709\u65ad\u70b9\uff0c\u53ea\u4fdd\u7559\u8c03\u7528\u89e3\u7801\u7684\u90e8\u5206\uff1a </p> <p></p> <p>\u542f\u52a8\u547d\u4ee4\uff1a</p> Bash<pre><code>(base) $ conda env list\n\n# conda environments:\n#\nbase                 * /home/student2023/xiehr2023/miniconda3\nAutoformer             /home/student2023/xiehr2023/miniconda3/envs/Autoformer\nSegRNN                 /home/student2023/xiehr2023/miniconda3/envs/SegRNN\ntimesNet               /home/student2023/xiehr2023/miniconda3/envs/timesNet\n\n(base) $ conda activate Autoformer\n(Autoformer) $ sh scripts/ILI_script/Autoformer.sh\n</code></pre> <p>\u5728\u6b65\u8fdb\u4ee3\u7801\u4e4b\u524d\uff0c\u5148\u770bmermaid \u753b\u7684\u7c7b\u56fe\uff0c\u770b\u6e05\u89e3\u7801\u5668\u7684\u8c03\u7528\u6d41\u7a0b\uff1a  </p>"},{"location":"Reproduction/6_AutoFormer/#_11","title":"\u7c7b\u56fe","text":"<pre><code>\nclassDiagram\n    class Model {\n        +int seq_len\n        +int label_len\n        +int pred_len\n        +bool output_attention\n        +series_decomp decomp\n        +DataEmbedding_wo_pos enc_embedding\n        +DataEmbedding_wo_pos dec_embedding\n        +Encoder encoder\n        +Decoder decoder\n        +forward(x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\n    }\n\n    class series_decomp {\n        +moving_avg moving_avg\n        +forward(x) res, moving_mean\n    }\n    class moving_avg {\n        +int kernel_size\n        +AvgPool1d avg\n        +forward(x)\n    }\n\n    class DataEmbedding_wo_pos {\n        +TokenEmbedding value_embedding\n        +PositionalEmbedding position_embedding\n        +TemporalEmbedding temporal_embedding\n        +Dropout dropout\n        +forward(x, x_mark)\n    }\n\n    class Encoder {\n        +List~EncoderLayer~ layers\n        +my_Layernorm norm_layer\n        +forward(x, attn_mask)\n    }\n\n    class EncoderLayer {\n        +AutoCorrelationLayer attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, attn_mask)\n    }\n\n    class AutoCorrelationLayer {\n        +AutoCorrelation attention\n        +Linear query_projection\n        +Linear key_projection\n        +Linear value_projection\n        +Linear out_projection\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class AutoCorrelation {\n        +bool mask_flag\n        +int factor\n        +float scale\n        +Dropout dropout\n        +bool output_attention\n        +time_delay_agg_training(values, corr)\n        +time_delay_agg_inference(values, corr)\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class Decoder {\n        +List~DecoderLayer~ layers\n        +my_Layernorm norm_layer\n        +Linear projection\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    class DecoderLayer {\n        +AutoCorrelationLayer self_attention\n        +AutoCorrelationLayer cross_attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +series_decomp decomp3\n        +Dropout dropout\n        +activation\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    Model --&gt; series_decomp\n    Model --&gt; DataEmbedding_wo_pos\n    Model --&gt; Encoder\n    Model --&gt; Decoder\n    Encoder --&gt; EncoderLayer\n    EncoderLayer --&gt; AutoCorrelationLayer\n    EncoderLayer --&gt; Conv1d\n    EncoderLayer --&gt; series_decomp\n    AutoCorrelationLayer --&gt; AutoCorrelation\n    Decoder --&gt; DecoderLayer\n    DecoderLayer --&gt; AutoCorrelationLayer\n    DecoderLayer --&gt; Conv1d\n    DecoderLayer --&gt; series_decomp   \n    series_decomp --&gt; moving_avg\n    moving_avg --&gt; AvgPool1d\n</code></pre> <p>\u4e0b\u9762\u5f00\u59cb\u8bb2\u56fe\u3002</p> <p>Mode init </p> <p>\u9996\u5148\uff0c\u4ece\u7b2c\u4e00\u6846\u5f00\u59cb\uff0cmodel \u5c31\u662f\u6307\u7684 Autoformer\uff0c\u9996\u5148 Autoformer \u7684 init \u90e8\u5206\u6709 \u8f93\u5165\u5e8f\u5217\u957f\u5ea6\uff0csequence length\uff1b\u6807\u7b7e\u5e8f\u5217\u7684\u957f\u5ea6 label length\uff0c\u6807\u7b7e\u5e8f\u5217\u7528\u4e8e\u6307\u5bfc\u9884\u6d4b\uff0c\u672c\u6587\u622a\u53d6\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u7684\u4e00\u534a\uff1b\u9884\u6d4b\u5e8f\u5217\u957f\u5ea6 predict length\uff0c\u56e0\u4e3a\u672c\u6587\u8bbe\u7f6e\u7684\u6807\u7b7e\u5e8f\u5217\uff0c\u6240\u4ee5\u89e3\u7801\u5668\u5b9e\u9645\u7684\u8f93\u51fa\u65f6\u95f4\u6b65\u662f label length+predict length\uff0c\u6240\u4ee5\u9884\u6d4b\u7684\u90e8\u5206\uff0c\u8fd8\u8981\u628a label length \u622a\u6389\u3002attention \u6682\u65f6\u4e0d\u770b\uff0c\u6211\u4e5f\u4e0d\u660e\u767d\u6709\u5565\u7528\uff0c\u5927\u6982\u5c31\u662f\u4e00\u4e2a\u521d\u59cb\u5316\u5427\u3002</p> <p>\u7136\u540e\u5c31\u662f\u5e8f\u5217\u5206\u89e3\u51fd\u6570\uff0c\u5206\u89e3\u5b63\u8282\u6210\u5206\u548c\u8d8b\u52bf\u6210\u5206\u3002\u8d8b\u52bf\u6210\u5206\u662f\u4f4e\u9891\u6210\u5206\uff0c\u8868\u793a\u65f6\u95f4\u5e8f\u5217\u957f\u671f\u7a33\u5b9a\u7684\u8d8b\u52bf\uff0c\u7528\u7684\u662f\u79fb\u52a8\u5e73\u5747\uff0c\u5728\u4ee3\u7801\u5b9e\u73b0\u4e2d\uff0c\u5177\u4f53\u7528\u7684\u662f 1D \u5e73\u5747\u6c60\u5316\u3002\u5b63\u8282\u6210\u5206\u662f\u9ad8\u9891\u6210\u5206\uff0c\u8868\u793a\u5468\u671f\u6027\u4fe1\u606f\uff0c\u5206\u89e3\u4e2d\u7684\u505a\u6cd5\u662f \u539f\u59cb\u5e8f\u5217\u51cf\u53bb\u5b63\u8282\u6210\u5206\u3002res = \u539f\u59cb\u5e8f\u5217 <code>x</code> - \u8d8b\u52bf\u6210\u5206 <code>move_average</code></p> <p>\u4e0b\u9762\u662f\u4e24\u4e2a\u5d4c\u5165\u5c42\uff0c\u76ee\u7684\u662f\u8fdb\u884c token Embedding \u548c temporal Embedding\uff0c\u5c06\u539f\u59cb\u65f6\u95f4\u6b65\u7279\u5f81\u5d4c\u5165\u5230\u6307\u5b9a\u7ef4\u5ea6\uff0c\u66f4\u7cbe\u7ec6\u7684\u8868\u793a\u7279\u5f81\u3002\u4e3e\u4e2a\u4f8b\u5b50\uff1a\u65f6\u95f4\u6b65\u7279\u5f81[32,36,7] \u2192 [32,36,512]   [32,42,7] \u2192[32,42,512] \uff1b\uff08\u65f6\u95f4\u6b65\uff09\u65f6\u95f4\u7279\u5f81[32,36,4] \u2192 [32,36,512]   [32,42,4] \u2192[32,42,512] </p> <p>\u63a5\u4e0b\u6765\u5c31\u662f Encoder \u548c Decoder\uff0c\u5176\u4e2d Encoder \u4f1a\u5806\u53e0 EncoderLayer\uff0cDecoder \u5806\u53e0 DecoderLayer\uff0c</p> <p>\u5176\u4e2d EncoderLayer \u5806\u53e0\u4e86 2 \u5c42\uff0c\u7ed3\u5408\u56fe\u548c\u4ee3\u7801\uff0c\u770b\u5355\u5c42 EncoderLayer \u548c DecoderLayer \u7684 \u76f8\u540c\u4e0e\u4e0d\u540c\u3002</p> <p>\uff081\uff09Decoder \u6bd4 Encoder \u591a\u4e86\u4e00\u4e2a\u7ebf\u6027\u5c42 <code>nn.Linear</code> \uff08\u9075\u5faa\u4e86\u6807\u51c6 Transformer \u67b6\u6784\uff09</p> <p>\uff082\uff09DecoderLayer \u8c03\u7528\u4e86\u4e24\u6b21 \u81ea\u76f8\u5173\u5c42\uff0c\u8fd9\u662f\u56e0\u4e3a Decoder \u4e2d\u8fdb\u884c\u4e24\u79cd\u6ce8\u610f\u529b\u673a\u5236\u7684\u8fd0\u7b97\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u4ea4\u53c9\u6ce8\u610f\u673a\u5236\uff0c\u5e76\u4e14\u518d\u6b21\u8bf4\u660e\uff0c\u81ea\u6ce8\u610f\u529b\u5c42\u3001\u4ea4\u53c9\u6ce8\u610f\u529b\u5c42\u3001FFN \u4ee5\u540e\uff0c\u4f1a\u8fdb\u884c\u6b8b\u5dee\u8fde\u63a5\u3002</p> <p>\uff083\uff09DecoderLayer \u8fdb\u884c\u4e86\u4e09\u6b21\u5e8f\u5217\u5206\u89e3\uff0c\u731c\u6d4b\uff0c\u5206\u522b\u662f\u5728\u81ea\u6ce8\u610f\u673a\u5236\u3001\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u53ca FFN \u4ee5\u540e\uff0c\u5206\u522b\u8fdb\u884c\u5206\u89e3</p> <p>\uff084\uff09\u540c\u65f6\u5728 DecoderLayer \u4e2d\uff0c\u5e94\u8be5\u5c24\u5176\u6ce8\u610f \u8d8b\u52bf\u6210\u5206\u662f\u600e\u4e48\u5904\u7406\u7684\uff0c\u56e0\u4e3a EncoderLayer \u4e2d\uff0c\u5ffd\u7565\u6389\u4e86\u8d8b\u52bf\u6210\u5206\u3002</p> <p>\uff085\uff09\u63a5\u4e0b\u6765\u5171\u540c\u8c03\u7528\u7684 \u81ea\u76f8\u5173\u5c42\uff0c\u5355\u4e2a\u81ea\u76f8\u5173\u5c42\u3001\u4ee5\u53ca\u5e8f\u5217\u5206\u89e3\u662f\u5b8c\u5168\u4e00\u6837\u7684\u3002</p> <p></p> Python<pre><code>self.encoder = Encoder(\n    [\n        EncoderLayer(\n            AutoCorrelationLayer(\n                AutoCorrelation(False, configs.factor, attention_dropout=configs.dropout,\n                                output_attention=configs.output_attention),\n                configs.d_model, configs.n_heads),\n            configs.d_model,\n            configs.d_ff,\n            moving_avg=configs.moving_avg,\n            dropout=configs.dropout,\n            activation=configs.activation\n        ) for l in range(configs.e_layers)\n    ],\n    norm_layer=my_Layernorm(configs.d_model)\n)\n# Decoder\nself.decoder = Decoder(\n    [\n        DecoderLayer(\n            AutoCorrelationLayer(\n                AutoCorrelation(True, configs.factor, attention_dropout=configs.dropout,\n                                output_attention=False),\n                configs.d_model, configs.n_heads),\n            AutoCorrelationLayer(\n                AutoCorrelation(False, configs.factor, attention_dropout=configs.dropout,\n                                output_attention=False),\n                configs.d_model, configs.n_heads),\n            configs.d_model,\n            configs.c_out,\n            configs.d_ff,\n            moving_avg=configs.moving_avg,\n            dropout=configs.dropout,\n            activation=configs.activation,\n        )\n        for l in range(configs.d_layers)\n    ],\n    norm_layer=my_Layernorm(configs.d_model),\n    projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n)\n</code></pre> <p>\u8bf4\u7740\u8bf4\u7740\u5c31\u8fdc\u4e86</p>"},{"location":"Reproduction/6_AutoFormer/#_12","title":"\u8bba\u6587","text":"<p>\u7ee7\u7eed\u6309\u7167\u8bba\u6587\u3001\u516c\u5f0f\u3001\u4ee3\u7801\u3001\u56fe\u7684\u903b\u8f91\u8fdb\u884c\u8bb2\u89e3</p> <p>\u770b\u8bba\u6587\u628a\u3002</p> <p></p> <p></p> <p>\u4e00\u53e5\u4e00\u53e5\u770b\u5427\uff1a</p> <p>\ud83d\udfe2   </p> <p></p> <p>\u89e3\u7801\u5668</p> <p>\u89e3\u7801\u5668\u5305\u542b\u4e24\u4e2a\u90e8\u5206\uff0c\u8868\u793a\u8d8b\u52bf\u6210\u5206\u7684\u7d2f\u79ef\u7ed3\u6784 \u548c \u5b63\u8282\u6210\u5206\u5806\u53e0\u7684\u81ea\u76f8\u5173\u673a\u5236</p> <p>\u6bcf\u4e2a\u7684DecoderLayer \u5305\u542b\u4e86\u5185\u90e8\u81ea\u76f8\u5173\u673a\u5236(\u81ea\u6ce8\u610f\u529b\u673a\u5236)\u548c\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u76f8\u5173\u673a\u5236(\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236)\uff0c\u76ee\u7684\u662f\u4e3a\u4e86  \u2460 \u7ec6\u5316\u9884\u6d4b \u5e76\u4e14 \u2461 \u5145\u5206\u5229\u7528\u5386\u53f2\u7684\u5b63\u8282\u4fe1\u606f</p> <p>\ud83d\udfe2 </p> <p> </p> <p>\u6ce8\u610f\uff0c\u6a21\u578b\u63d0\u53d6\u6f5c\u5728\u7684\u8d8b\u52bf\u4fe1\u606f\uff0c\u5728\u89e3\u7801\u5668\u4e2d\uff0c\u901a\u8fc7\u4e2d\u95f4\u7684\u9690\u85cf\u53d8\u91cf\u3002</p> <p>\uff08\u6ce8\u610f\uff0c\u5728\u89e3\u7801\u5668\u4e2d\uff0c\u6a21\u578b \u901a\u8fc7\u4e2d\u95f4\u7684\u9690\u85cf\u53d8\u91cf \u63d0\u53d6\u6f5c\u5728\u7684\u8d8b\u52bf\u4fe1\u606f\uff09</p> <p>\u8fd9\u79cd\u673a\u5236 \u4f7f\u5f97Autoformer \u9010\u6b65 \u4f18\u5316 \u8d8b\u52bf\u9884\u6d4b \u5e76\u4e14 \u6d88\u9664 \u5e72\u6270\u4fe1\u606f</p> <p>\u4ee5\u4fbf\u5728\u81ea\u76f8\u5173\u673a\u5236\u4e2d \u53d1\u73b0 \u57fa\u4e8e\u5468\u671f\u7684\u4f9d\u8d56\u5173\u7cfb\u3002</p> <p>\u6211\uff1a\uff08\u5c31\u662f\u8bf4 \u9690\u85cf\u7684\u4e2d\u95f4\u53d8\u91cf\u9884\u6d4b\u8d8b\u52bf\u4fe1\u606f\uff0c\u5728\u81ea\u76f8\u5173\u673a\u5236\u4e2d \u9884\u6d4b\u5b63\u8282\u4fe1\u606f\uff09</p> <p>\u5047\u8bbe \u89e3\u7801\u5668 \u6709 M \u5c42\uff0c\u7ed3\u5408\u6765\u81ea\u7f16\u7801\u5668\u7684\u6f5c\u5728\u53d8\u91cf \\(\\mathcal{X}_{en}^N\\) \uff08\u6211\uff1a\u5e94\u8be5\u662f\u7f16\u7801\u5668\u7684\u6700\u540e\u4e00\u5c42\u8f93\u51fa\uff09\uff0c\u7b2c l \u5c42\u89e3\u7801\u5668\u7684\u65b9\u7a0b\u53ef\u4ee5\u8868\u793a\u4e3a $ \\mathcal{X}{de}^{l} = Decoder(\\mathcal{X}<sup>{l-1},\\mathcal{X}_{en}</sup>N)$ \uff08\u6211\uff1a\u7b2c \\(l\\) \u5c42\u89e3\u7801\u5668\u7684\u8f93\u5165\uff0c\u63a5\u6536\u6765\u81ea==\u4e0a\u4e00\u5c42\u89e3\u7801\u5668\u7684\u8f93\u51fa==  \u548c \u6700\u540e\u4e00\u5c42\u7f16\u7801\u5668\u7684\u8f93\u51fa \u4f5c\u4e3a\u8f93\u5165\uff09</p> <p>\ud83d\udfe2 \u5355\u4e2a DecoderLayer \u7684\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u6982\u62ec\u5982\u4e0b\uff1a</p> <p> </p> <p>\u7b26\u53f7\u89e3\u91ca</p> <p> </p> <ul> <li>\\(\\mathcal{X}_{de}^l = \\mathcal{S}_{de}^{l,3},l \\in \\{1,...,M\\}\\) \u8868\u793a\u7b2c \\(l\\) \u5c42\u89e3\u7801\u5c42\u7684\u8f93\u51fa\uff0cM \u662f DecoderLayer \u7684\u5c42\u6570</li> </ul> <ul> <li> 3 \u662f\u5565\uff1f</li> </ul> <ul> <li>\\(\\mathcal{X}_{de}^0\\) \u662f\u5bf9\u539f\u59cb\u89e3\u7801\u5668\u8f93\u5165 \\(\\mathcal{X}_{des}\\)  \u7684\u5d4c\u5165 \uff08 \\(\\mathcal{X}_{des}\\) \u2192 \u5d4c\u5165\u5c42 \u2192  \\(\\mathcal{X}_{de}^0\\)\uff09 </li> </ul> <p>(outputs)\uff08\u5c31\u662f\u539f\u59cb\u6570\u636e\u8868\u793a\u3001Transformer \u7ed3\u6784\u53f3\u4fa7\u89e3\u7801\u5668\u7684\u8f93\u5165\uff08\u771f\u670d\u4e86\uff0c\u4e3a\u4e86\u6015\u81ea\u5df1\u5fd8\uff0c\u7528\u7740\u8fd9\u4e48\u591a\u89e3\u91caT.T\uff09\uff09</p> <ul> <li>\\(\\mathcal{T}_{de}^0 = \\mathcal{X}_{det}\\) \u7528\u4e8e\u7d2f\u79ef==\uff08\u6240\u4ee5\u5c31\u662f\u8d8b\u52bf\u5206\u91cf\u662f\u7d2f\u52a0\u6765\u7684\uff09==    </li> </ul> <p>\u771f\u6655\u554a\uff0c\u90fd\u5565\u7b26\u53f7\u554a\u3002\u771f\u670d\u4e86\u3002\u7ffb\u628a\u3002\u6bd5\u7adf\u7b26\u53f7\u662f\u7edf\u4e00\u7684\u3002</p> <p>\u627e\u5230\u4e86\uff01</p> <p> </p> <ul> <li>de \u89e3\u7801\u5668 \u3001s \u5b63\u8282\u5206\u91cf\u3001t \u8d8b\u52bf\u5206\u91cf</li> <li>\\(\\mathcal{X}\\) \u539f\u59cb\u6570\u636e\uff0c\u672a\u7ecf\u5d4c\u5165</li> <li>\u4e0a\u6807 0 \u8868\u793a\u521d\u59cb\u503c</li> <li>s \u6210\u5206\uff08\u5b63\u8282\u6210\u5206\uff09\u7684\u521d\u59cb\u5316\u662f 0 \u586b\u5145\u7684\u3001t \u6210\u5206\uff08\u8d8b\u52bf\u6210\u5206\uff09\u7684\u521d\u59cb\u5316\u662f \u5747\u503c\u586b\u5145\u7684</li> <li>\\(\\mathcal{T}\\) \u8868\u793a\u8d8b\u52bf\u5206\u91cf\uff0c\uff08Trend\uff09</li> <li>\\(\\mathcal{S}\\) \u8868\u793a \u5b63\u8282\u5206\u91cf\uff0c\uff08Season\uff09</li> </ul> <p>\u4e0d\u9519\uff0c\u547d\u540d\u8fd8\u633a\u8bb2\u7a76\u7684\u3002\u6765\u81ea\u6211\u7684\u8d85\u9ad8\u8bc4\u4ef7\uff0c\u5bb3\uff0c\u7814\u7a76\u8fd9\u4e2a\u7684\uff0c\u54ea\u6709\u51e0\u4e2a\u7cbe\u795e\u7f8e\u4e3d\u7684\uff0c\u5e72\u6d3b\u4e86\u3002</p> <ul> <li>\\(\\mathcal{S}_{de}^{l,i}\\) \u3001\\(\\mathcal{T}_{de}^{l,i}\\) $   i  \\in {1,2,3}$ \u5206\u522b\u8868\u793a \u7b2c\\(l\\) \u5c42\u7684DecoderLayer \u4e2d\uff0c\u7b2c \\(i\\) \u6b21\u5e8f\u5217\u5206\u89e3\u5feb\u4e4b\u540e\u5f97\u5230\u7684\u5b63\u8282\u6210\u5206\u548c\u8d8b\u52bf\u6210\u5206\u3002(\\(l\\) \u8868\u793a \\(l\\) \u5c42\uff0c\u7f16\u7801\u5668\u89e3\u7801\u5668\u4e2d\u540c\u7406)</li> <li>\\(\\mathcal{W}_{l,i} , i\\in \\{1,2,3\\}\\)  \u8868\u793a \u5bf9 \u7b2c \\(i\\) \u4e2a\u63d0\u53d6\u7684\u8d8b\u52bf\u5206\u91cf \\(\\mathcal{T}_{de}^{l,i}\\) \u7684 \u7ebf\u6027\u6295\u5f71\u3002\uff08W \u662f\u4ec0\u4e48\u7684\u7f29\u5199\uff1f\uff09</li> </ul> <p>\ud83d\udfe2</p> <p> </p> <p>\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c \u662f\u5bf9\u4e24\u4e2a\u5206\u89e3\u6210\u5206\u7684\u52a0\u548c\uff0c\u516c\u5f0f\u8868\u793a\u4e3a \\(\\mathcal{W}_\\mathcal{S} * \\mathcal{X}_{de}^M + \\mathcal{T}_{de}^M\\) </p> <ul> <li>\u8fd9\u91cc\u7684 \\(\\mathcal{W}\\) \u90fd\u8868\u793a\u7ebf\u6027\u6295\u5f71\u3002</li> <li>\\(\\mathcal{W}_\\mathcal{S}\\) \u5c06 \u6700\u540e\u4e00\u5c42 \u89e3\u7801\u5668\u7684\u8f93\u51fa \u6295\u5f71\u5230\u76ee\u6807\u7ef4\u5ea6</li> </ul> <p> </p> <p>\u6211\uff1a\u8fd9\u4e2a\u516c\u5f0f  \\(\\mathcal{X}_{de}^{l} = \\mathcal{S}_{de}^{l,3}\\) \u4e5f\u5c31\u662f\u8868\u793a\u4e86 \u89e3\u7801\u5668\u4e2d\u6570\u636e\u7684\u7684\u6d41\u52a8\u4e5f\u662f\u5b63\u8282\u6210\u5206\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#_13","title":"\u4ee3\u7801","text":"<p>\u597d\u4e86\uff0c\u8bba\u6587\u770b\u5b8c\u4e86\uff0c\u73b0\u5728\u770b\u4ee3\u7801\u3002</p> <ul> <li>\u4ece Autoformer forward \u51fa\u53d1</li> </ul> <p></p> <ul> <li>\u8fdb\u5165 Decoder forward</li> </ul> <p> </p> <ul> <li>Decoder \u7684\u521d\u59cb\u5316</li> </ul> <p></p> <p>\u5176\u4e2d <code>d_layers = 1</code> \uff08\u5168\u5c40\u641c\u7d22\uff09</p> <p>\u5305\u62ec\u4e86\u4e00\u5c42 DecoderLayer\u3001\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3001\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6700\u540e\u7684\u6295\u5f71\u5c42\u662f\u4e3a\u4e86\u628a\u5d4c\u5165\u7ef4\u5ea6 \u8fd8\u539f\u4e3a \u539f\u59cb\u7ef4\u5ea6\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#decoderlayer-forward","title":"DecoderLayer  forward","text":"<ul> <li>\u6b65\u8fdb\uff0c\u679c\u7136\u8fdb\u5165\u4e86 DecoderLayer \u7684 forward</li> </ul> <ul> <li>\u9010\u6b65\u6b65\u8fdb\u6267\u884c\uff0c\u679c\u7136\u8fdb\u5165\u4e86 AutoCorrelationLayer \u7684 forward</li> </ul> <p>\u63a5\u4e0b\u6765\u5c31\u662f qkv \u7684\u8ba1\u7b97\uff0c\u8fd9\u884c\u5173\u952e\uff0c\u4f1a\u6b65\u8fdb\u5230\u5177\u4f53\u7684 AutoCorrelation\u7684\u8ba1\u7b97\u3002\u770b\u7ef4\u5ea6\uff0c\u53ef\u4ee5\u770b\u5230\u8fd9\u91cc\u8fd8\u7528\u7684\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u3002  </p> <p> </p> <ul> <li>\u6b65\u8fdb\uff0c\u679c\u7136 \u8df3\u5230\u4e86 AutoCorrelation-forward</li> </ul> <p> </p> <p>\u5176\u5b9e\uff0c\u8df3\u8fdb\u6765\u6ca1\u7528\uff0c\u56e0\u4e3a\u6682\u65f6\u4e0d\u770b\u81ea\u76f8\u5173\u673a\u5236\u7684\u8ba1\u7b97\uff0c\u8fd9\u662f\u672c\u6587\u7684\u521b\u65b0\u3002\u9010\u6b65\u8df3\u51fa\uff0c\u770b DecoderLayer \u7684\u5904\u7406\u3002</p> <p>\u4e24\u4e2a\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u4e09\u4e2a\u8d8b\u52bf\u5206\u89e3\uff0c\u4e00\u4e2a\u8fd8\u539f\u7ef4\u5ea6\u7684\u7ebf\u6027\u5c42\u3002</p> <p>DecoderLayer\u4ee3\u7801\u6267\u884c\u7684\u6d41\u7a0b\u56fe </p> Markdown<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \u8f93\u5165\u5e8f\u5217 x [B,L,d_model] \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     \u81ea\u6ce8\u610f\u529b + \u6b8b\u5dee\u8fde\u63a5    \u2502    x = x + dropout(self_attention(x,x,x))\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       \u5e8f\u5217\u5206\u89e3 1         \u2502    x, trend1 = decomp1(x)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                  \u2198\n       \u2502                   trend1 [B,L,d_model] \u2192 \u4fdd\u5b58\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \u4ea4\u53c9\u6ce8\u610f\u529b(\u7f16\u7801\u5668\u8f93\u51fa)     \u2502    x = x + dropout(cross_attention(x,cross,cross))\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       \u5e8f\u5217\u5206\u89e3 2         \u2502    x, trend2 = decomp2(x)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                  \u2198\n       \u2502                   trend2 [B,L,d_model] \u2192 \u4fdd\u5b58\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502        \u524d\u9988\u7f51\u7edc          \u2502\n\u2502  y=x (\u590d\u5236\u64cd\u4f5c)          \u2502\n\u2502  \u5377\u79ef1 + \u6fc0\u6d3b + Dropout  \u2502    y = dropout(activation(conv1(y.transpose)))\n\u2502  \u5377\u79ef2 + Dropout        \u2502    y = dropout(conv2(y).transpose)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \u6b8b\u5dee\u8fde\u63a5 (x + y)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       \u5e8f\u5217\u5206\u89e3 3         \u2502    x, trend3 = decomp3(x + y)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                  \u2198\n       \u2502                   trend3 [B,L,d_model] \u2192 \u4fdd\u5b58\n       \u2193\n       \u2502\n       \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502    \u2502   \u5408\u5e76\u8d8b\u52bf: trend1 + trend2 + trend3 \u2502\n       \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                    \u2193\n       \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502    \u2502   \u8d8b\u52bf\u6295\u5f71 (\u7ef4\u5ea6\u8c03\u6574)               \u2502    residual_trend = projection(residual_trend)\n       \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                    \u2193\n       \u2502                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \u5b63\u8282\u6027\u8f93\u51fa x   \u2502  \u2502 \u8d8b\u52bf\u8f93\u51fa         \u2502\n\u2502 [B,L,d_model] \u2502  \u2502 [B,L,c_out]      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li> \u4e3a\u4ec0\u4e48\u53ea\u5bf9\u8d8b\u52bf\u6210\u5206\u8fdb\u884c\u6295\u5f71\uff1f\uff08\u7b54\uff1a\u90fd\u6295\u5f71\u4e86\uff0c\u53ea\u662f\u4f4d\u7f6e\u4e0d\u540c\uff09</li> </ul> <p>\u901a\u8fc7\u6295\u5f71\u5c42\u5c06\u8d8b\u52bf\u7ef4\u5ea6\u4eced_model\u8c03\u6574\u4e3ac_out(\u8f93\u51fa\u7279\u5f81\u7ef4\u5ea6)</p> <p>\u9996\u5148\uff0c\u9700\u8981\u660e\u786e\uff0c\u8d8b\u52bf\u6210\u5206\u548c\u5b63\u8282\u6210\u5206\u6700\u540e\u90fd\u9700\u8981 \u4ece <code>d_model</code> \u8fd8\u539f\u4e3a <code>feature dim</code> \u4e5f\u5c31\u662f\u539f\u59cb\u7684\u6570\u636e\u7ef4\u5ea6\uff0c\u4f46\u662f\u8fd9\u91cc\u8d8b\u52bf\u6210\u5206\u548c\u5b63\u8282\u6210\u5206\u8fd8\u539f\u7684\u4f4d\u7f6e\u4e0d\u540c\uff0c\u65b9\u5f0f\u4e0d\u540c\u3002</p> <p>\u7b2c\u4e00\u4e2a\u8fd8\u539f\u4f4d\u7f6e</p> <p>\u2460 \u9996\u5148\u660e\u786e Decoder \u8c03\u7528 DecoderLayer \u8fdb\u884c\u5355\u4e2a\u89e3\u7801\u5668\u7684\u5904\u7406</p> Python<pre><code># \u8fd4\u56de\u5b63\u8282\u6027\u6210\u5206(\u4e0d\u8fdb\u884c\u6295\u5f71)\u548c\u6295\u5f71\u540e\u7684\u8d8b\u52bf\u6210\u5206\nreturn x, residual_trend\n# x: [B, L, d_model], residual_trend: [B, L, c_out]\n</code></pre> <p>\u5355\u4e2a DecoderLayer \u8fd4\u56de\u7684\u5b63\u8282\u6210\u5206\u548c\u8d8b\u52bf\u6210\u5206\u7684\u7ef4\u5ea6\u5c31\u662f\u4e0d\u4e00\u6837\u7684</p> <p>\u2461 \u5b63\u8282\u6210\u5206\u5728 Decoder \u4e2d\u8fd8\u539f\u7ef4\u5ea6\uff0c\u901a\u8fc7 if \u5224\u65ad</p> Python<pre><code>        # \u5982\u679c\u5b58\u5728\u6295\u5f71\u5c42\uff0c\u5219\u5bf9\u8f93\u51fa\u8fdb\u884c\u6295\u5f71\u5904\u7406\n        # x[B, L, d_model] -&gt; Linear -&gt; x[B, L, c_out]\n        if self.projection is not None:\n            x = self.projection(x)\n</code></pre> <ul> <li> \u90a3\u5177\u4f53\u4ec0\u4e48\u65f6\u5019\u89e6\u53d1\u5462\uff1f\u6bcf\u6b21 DecoderLayer \u6267\u884c\u5b8c\uff1f\u8fd8\u662f\u6240\u6709 DecoderLayer \u6700\u7ec8\u6267\u884c\u5b8c\uff1f \u56de\u7b54\uff1a\u540e\u8005\uff0c\u7406\u7531\uff1a</li> </ul> Python<pre><code>def forward(self, x, cross, x_mask=None, cross_mask=None, trend=None):\n    # \u904d\u5386\u6bcf\u4e2a\u89e3\u7801\u5668\u5c42\uff0c\u5904\u7406\u8f93\u5165\u5e8f\u5217x\u548c\u4ea4\u53c9\u5e8f\u5217cross\n    # x[B, L, d_model] -&gt; DecoderLayer.forward -&gt; x[B, L, d_model], residual_trend[B, L, c_out]\n    for layer in self.layers:\n        # \u8c03\u7528\u89e3\u7801\u5668\u5c42\u7684\u524d\u5411\u4f20\u64ad\u65b9\u6cd5\uff0c\u66f4\u65b0x\u548c\u6b8b\u5dee\u8d8b\u52bf\n        # x[B, L, d_model], cross[B, L, d_model] -&gt; DecoderLayer.forward -&gt; x[B, L, d_model], residual_trend[B, L, c_out]\n        x, residual_trend = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n        # \u66f4\u65b0\u8d8b\u52bf\u4fe1\u606f\uff0c\u5c06\u6b8b\u5dee\u8d8b\u52bf\u6dfb\u52a0\u5230\u5f53\u524d\u8d8b\u52bf\n        # trend[B, L, c_out] + residual_trend[B, L, c_out] -&gt; trend[B, L, c_out]\n        trend = trend + residual_trend\n\n    # \u5982\u679c\u5b58\u5728\u5f52\u4e00\u5316\u5c42\uff0c\u5219\u5bf9\u8f93\u51fa\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\n    # x[B, L, d_model] -&gt; LayerNorm -&gt; x[B, L, d_model]\n    if self.norm is not None:\n        x = self.norm(x)\n\n    # \u5982\u679c\u5b58\u5728\u6295\u5f71\u5c42\uff0c\u5219\u5bf9\u8f93\u51fa\u8fdb\u884c\u6295\u5f71\u5904\u7406\n    # x[B, L, d_model] -&gt; Linear -&gt; x[B, L, c_out]\n    if self.projection is not None:\n        x = self.projection(x)\n</code></pre> <p>for \u5faa\u73af\u662f\u4e3a\u5faa\u73af DecoderLayer\uff0cDecoderLayer \u6267\u884c\u5b8c\u4e86\uff0c\u5c31\u662f\u6700\u540e\u7684\u5904\u7406\u4e86\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#_14","title":"\u6570\u636e\u6d41\u52a8\u56fe","text":"<p>\u2462 \u8d8b\u52bf\u6210\u5206 \u5728\u6bcf\u6b21 DecoderLayer  forward \u7684\u6700\u540e\u5c31\u4f1a\u8fdb\u884c\u8fd8\u539f\u7ef4\u5ea6</p> <p></p> <p>\u753b\u56fe\u76f4\u89c2\u7406\u89e3 Decoder \u548c DecoderLayer \u4e2d\u5173\u4e8e\u5b63\u8282\u6210\u5206\u548c\u8d8b\u52bf\u6210\u5206\u7684\u7406\u89e3</p> Python<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Decoder.forward                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \u8f93\u5165: x[B,L,d_model], cross[B,L,d_model], trend[B,L,c_out], masks            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2193\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 DecoderLayer 1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502  \u2502 \u8f93\u5165\u5e8f\u5217 x [B,L,d_model] \u2502                                                              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502                 \u2193                                                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502  \u2502   \u81ea\u6ce8\u610f\u529b + \u6b8b\u5dee\u8fde\u63a5     \u2502    x = x + dropout(self_attention(x,x,x))                    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502                 \u2193                                                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502  \u2502       \u5e8f\u5217\u5206\u89e3 1         \u2502    x, trend1 = decomp1(x)                                    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502         \u2502                  \u2198                                                              \u2502\n\u2502         \u2502                   trend1 [B,L,d_model] \u2192 \u4fdd\u5b58                                    \u2502\n\u2502         \u2193                                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502  \u2502 \u4ea4\u53c9\u6ce8\u610f\u529b(\u7f16\u7801\u5668\u8f93\u51fa)     \u2502    x = x + dropout(cross_attention(x,cross,cross))          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502                 \u2193                                                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502  \u2502       \u5e8f\u5217\u5206\u89e3 2         \u2502    x, trend2 = decomp2(x)                                    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502         \u2502                  \u2198                                                              \u2502\n\u2502         \u2502                   trend2 [B,L,d_model] \u2192 \u4fdd\u5b58                                    \u2502\n\u2502         \u2193                                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502  \u2502        \u524d\u9988\u7f51\u7edc          \u2502                                                              \u2502\n\u2502  \u2502  y=x (\u590d\u5236\u64cd\u4f5c)          \u2502                                                              \u2502\n\u2502  \u2502  \u5377\u79ef1 + \u6fc0\u6d3b + Dropout  \u2502    y = dropout(activation(conv1(y.transpose)))              \u2502\n\u2502  \u2502  \u5377\u79ef2 + Dropout        \u2502    y = dropout(conv2(y).transpose)                          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502                 \u2193                                                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502  \u2502 \u6b8b\u5dee\u8fde\u63a5 (x + y)         \u2502                                                              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502                 \u2193                                                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502  \u2502       \u5e8f\u5217\u5206\u89e3 3         \u2502    x, trend3 = decomp3(x + y)                                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502         \u2502                  \u2198                                                              \u2502\n\u2502         \u2502                   trend3 [B,L,d_model] \u2192 \u4fdd\u5b58                                    \u2502\n\u2502         \u2502                                                                                 \u2502\n\u2502         \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                      \u2502\n\u2502         \u2502    \u2502 \u7d2f\u52a0\u8d8b\u52bf: trend1 + trend2 + trend3   \u2502     [B,L,d_model]                    \u2502\n\u2502         \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                      \u2502\n\u2502         \u2502                    \u2193                                                            \u2502\n\u2502         \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                      \u2502\n\u2502         \u2502    \u2502 \u8d8b\u52bf\u6295\u5f71: \u5377\u79ef(kernel=3,padding=1)    \u2502     [B,L,d_model] \u2192 [B,L,c_out]      \u2502\n\u2502         \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                      \u2502\n\u2502         \u2502                    \u2193                                                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                \u2502\n\u2502  \u2502 \u5b63\u8282\u6027\u8f93\u51fa x   \u2502    \u2502 \u8d8b\u52bf\u8f93\u51fa residual_trend \u2502                                         \u2502\n\u2502  \u2502 [B,L,d_model] \u2502    \u2502 [B,L,c_out]       \u2502                                                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502                     \u2193\n           \u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n           \u2502             \u2502 Decoder\u4e2d\u7d2f\u79ef\u8d8b\u52bf   \u2502     trend += residual_trend\n           \u2502             \u2502 [B,L,c_out]        \u2502     [B,L,c_out] += [B,L,c_out]\n           \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2193                       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  x\u4f20\u5165\u4e0b\u4e00\u5c42        \u2502    \u2502  trend\u4f20\u5165\u4e0b\u4e00\u5c42    \u2502\n\u2502  [B,L,d_model]     \u2502    \u2502  [B,L,c_out]       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2193                           \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         DecoderLayer 2                             \u2502\n\u2502                          (\u91cd\u590d\u6d41\u7a0b)                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2193                                   \u2193\n         .                                   .\n         .                                   .\n         \u2193                                   \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         DecoderLayer N                             \u2502\n\u2502                          (\u91cd\u590d\u6d41\u7a0b)                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2193                                   \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \u6700\u7ec8\u5b63\u8282\u6027 x       \u2502             \u2502  \u7d2f\u79ef\u8d8b\u52bf trend     \u2502\n\u2502  [B,L,d_model]     \u2502             \u2502  [B,L,c_out]       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2193                                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u2502\n\u2502 \u5f52\u4e00\u5316(\u5982\u679c\u5b58\u5728)    \u2502                        \u2502\n\u2502 [B,L,d_model]      \u2502                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n         \u2193                                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u2502\n\u2502 \u6295\u5f71(\u5982\u679c\u5b58\u5728)      \u2502     [B,L,d_model] \u2192 [B,L,c_out]\n\u2502 [B,L,c_out]        \u2502                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n         \u2193                                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Decoder\u5b63\u8282\u6027\u8f93\u51fa  \u2502             \u2502  Decoder\u8d8b\u52bf\u8f93\u51fa   \u2502\n\u2502  [B,L,c_out]       \u2502             \u2502  [B,L,c_out]       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>\u7b2c\u4e8c\u4e2a \u8fd8\u539f\u64cd\u4f5c</p> Python<pre><code># \u89e3\u7801\u5668\u5c42\u5185\u7684\u8d8b\u52bf\u6295\u5f71\uff08\u4f7f\u7528\u5377\u79ef\uff09\nself.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=3, \n                           stride=1, padding=1, padding_mode='circular', bias=False)\n\n# Decoder\u7c7b\u4e2d\u7684\u5b63\u8282\u6027\u6295\u5f71\uff08\u901a\u5e38\u662f\u7ebf\u6027\u5c42\uff09\nself.projection = nn.Linear(d_model, c_out) if projection else None\n</code></pre> <p>\u8d8b\u52bf\u4f7f\u7528\u5377\u79ef\u6295\u5f71\u6709\u4ee5\u4e0b\u4f18\u52bf\uff1a\uff08\u8d8b\u52bf\u7684\u521d\u59cb\u5316\u672c\u6765\u4f7f\u7528\u7684\u662f\u5e73\u5747\u6c60\u5316\uff0c\u8fd9\u91cc\u7684 1D \u5377\u79ef\u5c31\u76f8\u5f53\u4e8e\u5168\u8fde\u63a5\uff0c\u53ea\u662f\u4e0d\u540c\u7684\u6570\u636e\u7ec4\u7ec7\u65b9\u5f0f\uff09</p> <ul> <li>\u53ef\u4ee5\u6355\u83b7\u5c40\u90e8\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff08kernel_size=3\uff09</li> <li>\u4f7f\u7528\u5faa\u73af\u586b\u5145\uff08circular padding\uff09\u9002\u5408\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u7684\u5468\u671f\u6027</li> <li>\u53ef\u4ee5\u5e73\u6ed1\u5904\u7406\u8d8b\u52bf\u53d8\u5316\uff0c\u51cf\u5c11\u566a\u58f0</li> </ul> <ul> <li> \u5355\u4e2a DecoderLayer \u8fd4\u56de\u7684\u662f \u7eaf\u5b63\u8282\u6027\u6210\u5206 x[B,L,d_model] \u548c \u8f6c\u6362\u540e\u7684\u8d8b\u52bf\u6210\u5206 residual_trend[B,L,c_out]</li> </ul> <p>\ud83d\udfe2 \u5f62\u72b6\u53d8\u5316\u7406\u89e3\uff1a</p> <p>\ud83d\udd35 \u5b63\u8282\u6027\u6210\u5206:</p> <p>\u25b6\ufe0f DecoderLayer\u5185\u90e8:</p> <ul> <li>\u59cb\u7ec8\u4fdd\u6301\u5f62\u72b6 [B,L,d_model]</li> <li>\u7ecf\u8fc7\u591a\u4e2a\u5b50\u6a21\u5757\u5904\u7406(\u81ea\u6ce8\u610f\u529b\u3001\u4ea4\u53c9\u6ce8\u610f\u529b\u3001\u524d\u9988\u7f51\u7edc)\uff0c\u4f46\u7ef4\u5ea6\u4e0d\u53d8</li> <li>\u8f93\u51fa\u5230Decoder\u65f6\u4ecd\u4e3a [B,L,d_model]</li> </ul> <p>\u25b6\ufe0f Decoder\u6700\u7ec8\u5904\u7406: </p> <ul> <li>\u901a\u8fc7\u6240\u6709DecoderLayer\u540e\u4ecd\u4e3a [B,L,d_model]</li> <li>\u7ecf\u8fc7\u53ef\u9009\u7684\u5f52\u4e00\u5316\u5c42\uff0c\u7ef4\u5ea6\u4e0d\u53d8</li> <li>\u7ecf\u8fc7\u53ef\u9009\u7684\u6295\u5f71\u5c42\u540e\uff0c\u53d8\u4e3a [B,L,c_out]</li> </ul> <p>\ud83d\udd35 \u8d8b\u52bf\u6210\u5206:</p> <p>\u25b6\ufe0f DecoderLayer\u5185\u90e8\u8d8b\u52bf\u63d0\u53d6:</p> <p>\u4e09\u4e2a\u8d8b\u52bf\u5206\u91cf(trend1/2/3)\u90fd\u662f [B,L,d_model]</p> <p>\u4e09\u4e2a\u8d8b\u52bf\u7d2f\u52a0\u540e\u4ecd\u4e3a [B,L,d_model]</p> <p>\u7ecf\u8fc7\u6295\u5f71\u5c42\u540e\uff0c\u53d8\u4e3a [B,L,c_out]</p> <p>\u25b6\ufe0f Decoder\u4e2d\u7684\u8d8b\u52bf\u7d2f\u79ef:</p> <p>Decoder\u8f93\u5165\u7684\u521d\u59cb\u8d8b\u52bftrend\u4e3a [B,L,c_out]</p> <p>\u6bcf\u4e2aDecoderLayer\u8f93\u51fa\u7684residual_trend\u4e3a [B,L,c_out]</p> <p>\u7d2f\u79ef\u540e\u7684\u8d8b\u52bf\u7ef4\u5ea6\u4fdd\u6301 [B,L,c_out]</p> <p>\ud83c\udf08\u5404\u5c42\u95f4\u7684\u6570\u636e\u4f20\u9012 </p> <p>\ud83e\udee7 \u5b63\u8282\u6027\u6210\u5206\u4f20\u9012:</p> <p>\u5b63\u8282\u6027\u6210\u5206x\u5728\u5404DecoderLayer\u4e4b\u95f4\u4f20\u9012</p> <p>\u6bcf\u4e2aDecoderLayer\u5904\u7406\u540e\u7684\u5b63\u8282\u6027\u6210\u5206\u4f5c\u4e3a\u4e0b\u4e00\u5c42\u7684\u8f93\u5165</p> <p>\u6700\u540e\u4e00\u5c42\u7684\u5b63\u8282\u6027\u6210\u5206\u8f93\u51fa\u540e\u7ecf\u8fc7\u5f52\u4e00\u5316\u548c\u6295\u5f71</p> <p>\ud83e\udee7 \u8d8b\u52bf\u6210\u5206\u4f20\u9012: </p> <p>DecoderLayer\u5185\u90e8\u63d0\u53d6\u7684\u4e09\u4e2a\u8d8b\u52bf\u6210\u5206\u5728\u5c42\u5185\u7d2f\u52a0\u548c\u6295\u5f71</p> <p>\u6bcf\u4e2aDecoderLayer\u63d0\u4f9b\u4e00\u4e2a\u8d8b\u52bf\u8d21\u732eresidual_trend</p> <p>Decoder\u7ef4\u62a4\u4e00\u4e2a\u7d2f\u79ef\u8d8b\u52bftrend\uff0c\u5782\u76f4\u7d2f\u79ef\u5404\u5c42\u7684\u8d21\u732e</p> <p>\u6700\u7ec8\u7d2f\u79ef\u540e\u7684\u8d8b\u52bf\u4e0d\u9700\u8981\u989d\u5916\u5904\u7406\uff0c\u76f4\u63a5\u4f5c\u4e3a\u8f93\u51fa</p> <p>\ud83d\udc0b DecoderLayer\u7684\u8f93\u5165\u8f93\u51fa:</p> <p>\u8f93\u5165: \u5b63\u8282\u6027\u6210\u5206<code>x[B,L,d_model]</code>\u548c\u7f16\u7801\u5668\u8f93\u51fa<code>cross[B,L,d_model]</code></p> <p>\u8f93\u51fa: \u5904\u7406\u540e\u7684\u5b63\u8282\u6027\u6210\u5206<code>x[B,L,d_model]</code>\u548c\u8d8b\u52bf\u8d21\u732e<code>residual_trend[B,L,c_out]</code></p> <ul> <li> \u7f16\u7801\u5668\u7684\u8f93\u51fa\u4f5c\u4e3a K \u548c V\uff0c\u89e3\u7801\u5668\u7684\u8f93\u5165\u4f5c\u4e3a Q</li> </ul> <p>\u76ee\u6807\u5e8f\u5217\u751f\u6210\u67e5\u8be2\uff0c\u5bf9\u7167\u6e90\u5e8f\u5217</p> <ul> <li> \u5bf9\u6bd4\u7f16\u7801\u5668\u7684\u8bbe\u8ba1</li> </ul> <p>\u4e0e\u7f16\u7801\u5668\u7684\u5173\u952e\u533a\u522b</p> <ul> <li>\u8d8b\u52bf\u5904\u7406\u65b9\u5f0f: </li> </ul> <p>\u7f16\u7801\u5668: \u4e22\u5f03\u8d8b\u52bf\u6210\u5206\uff0c\u53ea\u4fdd\u7559\u5b63\u8282\u6027</p> <p>\u89e3\u7801\u5668: \u4fdd\u5b58\u5e76\u7d2f\u79ef\u8d8b\u52bf\u6210\u5206\uff0c\u6700\u7ec8\u4e0e\u5b63\u8282\u6027\u5206\u5f00\u8f93\u51fa</p> <ul> <li>\u5206\u89e3\u6b21\u6570:</li> </ul> <p>\u7f16\u7801\u5668: \u4e24\u6b21\u5206\u89e3(\u6ce8\u610f\u529b\u540e\u548c\u524d\u9988\u7f51\u7edc\u540e)</p> <p>\u89e3\u7801\u5668: \u4e09\u6b21\u5206\u89e3(\u81ea\u6ce8\u610f\u529b\u540e\u3001\u4ea4\u53c9\u6ce8\u610f\u529b\u540e\u548c\u524d\u9988\u7f51\u7edc\u540e)</p> <ul> <li>\u8d8b\u52bf\u7d2f\u79ef:</li> </ul> <p>\u7f16\u7801\u5668: \u65e0\u8d8b\u52bf\u7d2f\u79ef</p> <p>\u89e3\u7801\u5668: \u4e09\u4e2a\u9636\u6bb5\u7684\u8d8b\u52bf\u76f8\u52a0\uff0c\u5f62\u6210\u5b8c\u6574\u8d8b\u52bf\u8868\u793a</p> <ul> <li>\u8f93\u51fa\u7ef4\u5ea6:</li> </ul> <p>\u7f16\u7801\u5668: \u8f93\u51fa\u4fdd\u6301d_model\u7ef4\u5ea6</p> <p>\u89e3\u7801\u5668: \u5bf9\u8d8b\u52bf\u6210\u5206\u8fdb\u884c\u6295\u5f71\uff0c\u8c03\u6574\u4e3ac_out\u7ef4\u5ea6 \u8fd9\u79cd\u8bbe\u8ba1\u4f53\u73b0\u4e86Autoformer\u5bf9\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u7684\u7cbe\u5fc3\u5904\u7406\uff0c\u901a\u8fc7\u5728\u89e3\u7801\u5668\u4e2d\u7d2f\u79ef\u8d8b\u52bf\u4fe1\u606f\uff0c\u7ed3\u5408\u7f16\u7801\u5668\u63d0\u53d6\u7684\u5b63\u8282\u6027\u7279\u5f81\uff0c\u6700\u7ec8\u80fd\u591f\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002</p> <ul> <li> \u95ee\uff1a\u4e3a\u4ec0\u4e48\u8981\u8fd9\u6837\u8bbe\u8ba1\uff1f</li> </ul> <p>\u95ee\u9898\u63cf\u8ff0\uff1a</p> <p>\u8d8b\u52bf\u6210\u5206\uff1a\u5728\u6bcf\u4e2a\u89e3\u7801\u5668\u5c42\u5185\u90e8\u5c31\u8fdb\u884c\u6295\u5f71\uff0c\u5e76\u4e14\u5404\u5c42\u7684\u6295\u5f71\u7ed3\u679c\u88ab\u7d2f\u79ef</p> <p>\u5b63\u8282\u6027\u6210\u5206\uff1a\u4fdd\u6301\u539f\u59cb\u7ef4\u5ea6\u901a\u8fc7\u6240\u6709\u89e3\u7801\u5668\u5c42\uff0c\u53ea\u5728\u6700\u540e\u8fdb\u884c\u4e00\u6b21\u7edf\u4e00\u6295\u5f71</p> <p>\u6211\u7684\u7406\u89e3\uff1a\u5b63\u8282\u662f\u4e00\u4e2a\u9ad8\u9891\u6210\u5206\uff0c\u4fdd\u6301\u9ad8\u7ef4\u8868\u793a\u80fd\u591f\u66f4\u597d\u7684\u8868\u793a\u7279\u5f81\u3002\u8d8b\u52bf\u6210\u5206\u662f\u4e00\u4e2a\u4f4e\u9891\u6210\u5206\uff0c\u4e0d\u7ba1\u662f\u5377\u79ef\u6216\u8005\u662f DecoderLayer \u6700\u540e\u7684 conv \u90fd\u53ef\u4ee5\u8fbe\u5230\u5e73\u6ed1\u566a\u58f0\u7684\u4f5c\u7528\uff0c\u4f7f\u5f97\u7f51\u7edc\u80fd\u591f\u66f4\u52a0\u5173\u6ce8\u957f\u671f\u7a33\u5b9a\u7684\u8d8b\u52bf</p> <p>\u5bf9\u54e6~\u5f97\u5230 gpt \u7684\u80af\u5b9a\u3002okay\uff0cgo\u3002\u5b83\u7684\u8865\u5145\uff1a </p> <p>Autoformer\u7684\u8bbe\u8ba1\u7406\u5ff5\u786e\u5b9e\u56f4\u7ed5\u7740\u5bf9\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u4e0d\u540c\u9891\u7387\u6210\u5206\u7684\u5dee\u5f02\u5316\u5904\u7406</p> <p>\ud83d\udd35 \u5b63\u8282\u6027\u6210\u5206\uff08\u9ad8\u9891\uff09\u7684\u5904\u7406\u7b56\u7565</p> <p>\u4fdd\u6301\u9ad8\u7ef4\u8868\u793a</p> <ul> <li>\u5b63\u8282\u6027\u6210\u5206\u5728DecoderLayer\u4e2d\u59cb\u7ec8\u4fdd\u6301d_model\u7ef4\u5ea6\uff08\u901a\u5e38\u8f83\u9ad8\uff09</li> <li>\u53ea\u5728Decoder\u7684\u6700\u540e\u9636\u6bb5\u624d\u6295\u5f71\u5230c_out\u7ef4\u5ea6</li> <li>\u8fd9\u79cd\u8bbe\u8ba1\u5141\u8bb8\u6a21\u578b\u4f7f\u7528\u4e30\u5bcc\u7684\u7279\u5f81\u7a7a\u95f4\u6765\u8868\u8fbe\u590d\u6742\u7684\u5468\u671f\u6027\u6a21\u5f0f</li> </ul> <p>\u6ce8\u610f\u529b\u673a\u5236\u7684\u4f18\u52bf</p> <ul> <li>\u81ea\u6ce8\u610f\u529b\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u7279\u522b\u9002\u5408\u6355\u83b7\u4e0d\u540c\u65f6\u95f4\u70b9\u4e4b\u95f4\u7684\u5468\u671f\u6027\u5173\u7cfb</li> <li>\u5b63\u8282\u6027\u6210\u5206\u7ecf\u8fc7\u591a\u6b21\u6ce8\u610f\u529b\u5904\u7406\uff0c\u53ef\u4ee5\u8bc6\u522b\u590d\u6742\u7684\u91cd\u590d\u6a21\u5f0f</li> </ul> <p>\u591a\u5c42\u6e10\u8fdb\u5f0f\u5904\u7406 </p> <ul> <li>\u6bcf\u5c42DecoderLayer\u90fd\u5bf9\u5b63\u8282\u6027\u8fdb\u884c\u8fdb\u4e00\u6b65\u7cbe\u70bc</li> <li>\u901a\u8fc7\u5c42\u5c42\u4f20\u9012\uff0c\u5141\u8bb8\u6a21\u578b\u5b66\u4e60\u5230\u5c42\u6b21\u5316\u7684\u5b63\u8282\u6a21\u5f0f\uff08\u5982\u65e5\u5185\u6a21\u5f0f\u3001\u5468\u5185\u6a21\u5f0f\u3001\u6708\u5185\u6a21\u5f0f\uff09</li> </ul> <p>\ud83d\udd35 \u8d8b\u52bf\u6210\u5206\uff08\u4f4e\u9891\uff09\u7684\u5904\u7406\u7b56\u7565</p> <p>\u65e9\u671f\u964d\u7ef4\u548c\u5e73\u6ed1\u5904\u7406</p> <ul> <li>\u8d8b\u52bf\u6210\u5206\u5728\u6bcf\u4e2aDecoderLayer\u5185\u5c31\u901a\u8fc7\u5377\u79ef\uff08kernel_size=3\uff09\u8fdb\u884c\u6295\u5f71   \u5377\u79ef\u7684\u672c\u8d28\u662f\u4e00\u79cd\u5e73\u6ed1\u64cd\u4f5c\uff0c\u80fd\u591f\u8fc7\u6ee4\u6389\u9ad8\u9891\u566a\u58f0</li> <li>\u5faa\u73af\u586b\u5145\uff08padding_mode='circular'\uff09\u9002\u5408\u5904\u7406\u5468\u671f\u6027\u65f6\u95f4\u5e8f\u5217   \u7d2f\u79ef\u673a\u5236\u7684\u610f\u4e49</li> </ul> <p>\u4e0d\u540c\u5c42\u6355\u83b7\u7684\u8d8b\u52bf\u901a\u8fc7\u7b80\u5355\u7d2f\u52a0\u7684\u65b9\u5f0f\u7ec4\u5408</p> <ul> <li>\u8d8b\u52bf\u4f7f\u7528\u8f83\u4f4e\u7684\u7ef4\u5ea6\uff08c_out\uff09\u5c31\u8db3\u4ee5\u8868\u8fbe</li> <li>\u8d8b\u52bf\u672c\u8d28\u4e0a\u662f\u4f4e\u9891\u3001\u5e73\u6ed1\u7684\u6210\u5206\uff0c\u7279\u5f81\u590d\u6742\u5ea6\u4f4e\u4e8e\u5b63\u8282\u6027</li> </ul> <ul> <li> \u4e3a\u4ec0\u4e48\u5b63\u8282\u6210\u5206\u548c\u8d8b\u52bf\u6210\u5206\uff0c\u4e00\u4e2a\u7528nn.Linear\u4e00\u4e2a\u7528 nn.conv1D\uff1f</li> </ul> <p>\u8865\u5145\uff1a\u8d8b\u52bf\u6210\u5206\u5377\u79ef\u65f6\u7528\u5230\u7684\u5faa\u73af\u586b\u5145</p> <p>\u81ea\u5df1\u7684\u8bdd\uff1akernel size=3\uff0c\u5e73\u6ed1\u8d8b\u52bf\uff0c\u8003\u8651\u5c40\u90e8\u4e0a\u4e0b\u6587\uff0c\u8fc7\u6ee4\u566a\u58f0\uff1b\uff08\u4f1a\u6709\u4e00\u6b65\u5f62\u72b6\u53d8\u5316\uff0c\u4f46\u56e0\u4e3a\u5377\u79ef\u6838\u53c2\u6570\u5171\u4eab\uff0c\u53ef\u4ee5\u8bc6\u522b\u76f8\u540c\u7684\u5468\u671f\u53d8\u5316\uff09</p> <p>\u5b63\u8282\u6210\u5206\u4f7f\u7528 nn.Linear\uff0c\u4fdd\u7559\u9ad8\u9891\u6210\u5206\u548c\u5feb\u901f\u53d8\u5316\u7684\u90e8\u5206\u3002</p> <ul> <li>\u5b63\u8282\u6027\u6210\u5206\uff08\u9ad8\u9891\u3001\u590d\u6742\u53d8\u5316\uff09\uff1a\u4f7f\u7528\u7ebf\u6027\u6295\u5f71\u4fdd\u7559\u7cbe\u7ec6\u7ed3\u6784</li> <li>\u8d8b\u52bf\u6210\u5206\uff08\u4f4e\u9891\u3001\u5e73\u6ed1\u53d8\u5316\uff09\uff1a\u4f7f\u7528\u5377\u79ef\u6295\u5f71\u5f15\u5165\u5e73\u6ed1\u6548\u679c\u548c\u5c40\u90e8\u4e0a\u4e0b\u6587</li> </ul> <p>\u6700\u540e\u7684\u4e00\u70b9\u5173\u4e8e\u67e5\u6f0f\u8865\u7f3a</p> <p>Decoder \u5bf9\u5e94\u8bba\u6587\u4e2d\u7684\u8fd9\u91cc\uff1a</p> <p></p> <p>\u516c\u5f0f\u4e2d\uff0c</p> <p> </p> <ul> <li> \u8fd9\u91cc\u7684 \\(\\mathcal{W}_{l,}\\) \u662f\u4ec0\u4e48\u610f\u601d\uff1f</li> </ul> <p>\u9996\u5148\u9700\u8981\u660e\u786e\uff0c\u5404\u4e2a\u7684\u5f62\u72b6</p> <p>\\(\\mathcal{T}_{de}^{l}\u3001\\mathcal{T}_{de}^{l-1} \\in \\mathbb{R}^{B \\times L \\times c_{out}}\\)</p> <p>\\(\\mathcal{T}_{de}^{l,1} \u3001\\mathcal{T}_{de}^{l,2}\u3001\\mathcal{T}_{de}^{l,3}\\in \\mathbb{R}^{B \\times L \\times d_{model}}\\)</p> <p>\u2192 \\(\\mathcal{W}_{l,1}\u3001\\mathcal{W}_{l,2}\u3001\\mathcal{W}_{l,3}\\) \u5206\u522b\u662f\u8c03\u6574\u7ef4\u5ea6\u6240\u7528\u5230\u7684\u53d8\u6362\u77e9\u9635</p>"},{"location":"Reproduction/6_AutoFormer/#autoformer-forward_1","title":"\u6c47\u603b Autoformer forward","text":"<p>1</p> <pre><code>classDiagram\n    class Model {\n        +int seq_len\n        +int label_len\n        +int pred_len\n        +bool output_attention\n        +series_decomp decomp\n        +DataEmbedding_wo_pos enc_embedding\n        +DataEmbedding_wo_pos dec_embedding\n        +Encoder encoder\n        +Decoder decoder\n        +forward(x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\n    }\n\n    class series_decomp {\n        +moving_avg moving_avg\n        +forward(x) res, moving_mean\n    }\n\n    class moving_avg {\n        +int kernel_size\n        +AvgPool1d avg\n        +forward(x)\n    }\n\n    class DataEmbedding_wo_pos {\n        +TokenEmbedding value_embedding\n        +PositionalEmbedding position_embedding\n        +TemporalEmbedding or TimeFeatureEmbedding temporal_embedding  \n        +Dropout dropout\n        +forward(x, x_mark)\n    }\n\n    class TokenEmbedding {\n        +Conv1d tokenConv\n        +forward(x)\n    }\n\n    class TemporalEmbedding {\n        +Embedding minute_embed\n        +Embedding hour_embed\n        +Embedding weekday_embed\n        +Embedding day_embed\n        +Embedding month_embed\n        +forward(x)\n    }\n\n    class TimeFeatureEmbedding {\n        +Linear embed\n        +forward(x)\n    }\n\n    class Encoder {\n        +List~EncoderLayer~ layers\n        +my_Layernorm norm_layer\n        +forward(x, attn_mask)\n    }\n\n    class EncoderLayer {\n        +AutoCorrelationLayer attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, attn_mask)\n    }\n\n    class AutoCorrelationLayer {\n        +AutoCorrelation attention\n        +Linear query_projection\n        +Linear key_projection\n        +Linear value_projection\n        +Linear out_projection\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class AutoCorrelation {\n        +bool mask_flag\n        +int factor\n        +float scale\n        +Dropout dropout\n        +bool output_attention\n        +time_delay_agg_training(values, corr)\n        +time_delay_agg_inference(values, corr)\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class Decoder {\n        +List~DecoderLayer~ layers\n        +my_Layernorm norm_layer\n        +Linear projection\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    class DecoderLayer {\n        +AutoCorrelationLayer self_attention\n        +AutoCorrelationLayer cross_attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +series_decomp decomp3\n        +Dropout dropout\n        +activation\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    %% \u6838\u5fc3\u7ec4\u4ef6\u5173\u7cfb\n    Model --&gt; series_decomp\n    Model --&gt; DataEmbedding_wo_pos\n    Model --&gt; Encoder\n    Model --&gt; Decoder\n\n    %% \u5d4c\u5165\u5c42\u5173\u7cfb - \u4fee\u6b63\u4e3a\u6761\u4ef6\u5173\u7cfb\n    DataEmbedding_wo_pos --&gt; TokenEmbedding\n    DataEmbedding_wo_pos ..&gt; TemporalEmbedding : \u5f53embed_type!='timeF'\n    DataEmbedding_wo_pos ..&gt; TimeFeatureEmbedding : \u5f53embed_type='timeF'\n\n    %% \u7f16\u7801\u5668\u7ec4\u4ef6\u5173\u7cfb\n    Encoder --&gt; EncoderLayer\n    EncoderLayer --&gt; AutoCorrelationLayer\n    EncoderLayer --&gt; Conv1d\n    EncoderLayer --&gt; series_decomp\n    AutoCorrelationLayer --&gt; AutoCorrelation\n\n    %% \u89e3\u7801\u5668\u7ec4\u4ef6\u5173\u7cfb\n    Decoder --&gt; DecoderLayer\n    DecoderLayer --&gt; AutoCorrelationLayer\n    DecoderLayer --&gt; Conv1d\n    DecoderLayer --&gt; series_decomp\n\n    %% \u5e8f\u5217\u5206\u89e3\u5173\u7cfb\n    series_decomp --&gt; moving_avg\n    moving_avg --&gt; AvgPool1d\n</code></pre> <p>2 </p> <pre><code>classDiagram\n    class Model {\n        +int seq_len\n        +int label_len\n        +int pred_len\n        +bool output_attention\n        +series_decomp decomp\n        +DataEmbedding_wo_pos enc_embedding\n        +DataEmbedding_wo_pos dec_embedding\n        +Encoder encoder\n        +Decoder decoder\n        +forward(x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\n    }\n\n    class series_decomp {\n        +moving_avg moving_avg\n        +forward(x) res, moving_mean\n    }\n\n    class moving_avg {\n        +int kernel_size\n        +AvgPool1d avg\n        +forward(x)\n    }\n\n    class DataEmbedding_wo_pos {\n        +TokenEmbedding value_embedding\n        +TemporalEmbedding|TimeFeatureEmbedding temporal_embedding\n        +Dropout dropout\n        +forward(x, x_mark)\n        +__init__(c_in, d_model, embed_type, freq, dropout)\n    }\n\n    class TokenEmbedding {\n        +Conv1d tokenConv\n        +forward(x)\n    }\n\n    class TemporalEmbedding {\n        +Embedding minute_embed\n        +Embedding hour_embed\n        +Embedding weekday_embed\n        +Embedding day_embed\n        +Embedding month_embed\n        +forward(x)\n    }\n\n    class TimeFeatureEmbedding {\n        +Linear embed\n        +forward(x)\n    }\n\n    class Encoder {\n        +List~EncoderLayer~ layers\n        +my_Layernorm norm_layer\n        +forward(x, attn_mask)\n    }\n\n    class EncoderLayer {\n        +AutoCorrelationLayer attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, attn_mask)\n    }\n\n    class AutoCorrelationLayer {\n        +AutoCorrelation attention\n        +Linear query_projection\n        +Linear key_projection\n        +Linear value_projection\n        +Linear out_projection\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class AutoCorrelation {\n        +bool mask_flag\n        +int factor\n        +float scale\n        +Dropout dropout\n        +bool output_attention\n        +time_delay_agg_training(values, corr)\n        +time_delay_agg_inference(values, corr)\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class Decoder {\n        +List~DecoderLayer~ layers\n        +my_Layernorm norm_layer\n        +Linear projection\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    class DecoderLayer {\n        +AutoCorrelationLayer self_attention\n        +AutoCorrelationLayer cross_attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +series_decomp decomp3\n        +Dropout dropout\n        +activation\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    %% Model\u4e2d\u7684\u7ec4\u4ef6\u5b9e\u4f8b\u5316\u5173\u7cfb\n    Model *-- \"1\" series_decomp : \u521b\u5efadecomp\n    Model *-- \"1\" DataEmbedding_wo_pos : \u521b\u5efaenc_embedding\n    Model *-- \"1\" DataEmbedding_wo_pos : \u521b\u5efadec_embedding\n    Model *-- \"1\" Encoder : \u521b\u5efaencoder\n    Model *-- \"1\" Decoder : \u521b\u5efadecoder\n\n    %% DataEmbedding_wo_pos\u5185\u90e8\u7ec4\u4ef6\n    DataEmbedding_wo_pos *-- \"1\" TokenEmbedding : \u521b\u5efavalue_embedding\n    DataEmbedding_wo_pos *-- \"1\" TemporalEmbedding : \u521b\u5efatemporal_embedding(\u5f53embed_type!='timeF')\n    DataEmbedding_wo_pos *-- \"1\" TimeFeatureEmbedding : \u521b\u5efatemporal_embedding(\u5f53embed_type='timeF')\n\n    %% \u5176\u4ed6\u7ec4\u4ef6\u5173\u7cfb\n    series_decomp *-- \"1\" moving_avg\n    Encoder *-- \"e_layers\" EncoderLayer\n    EncoderLayer *-- \"1\" AutoCorrelationLayer\n    EncoderLayer *-- \"2\" series_decomp : decomp1,decomp2\n    AutoCorrelationLayer *-- \"1\" AutoCorrelation\n    Decoder *-- \"d_layers\" DecoderLayer\n    DecoderLayer *-- \"2\" AutoCorrelationLayer : self\u548ccross\u6ce8\u610f\u529b\n    DecoderLayer *-- \"3\" series_decomp : decomp1,2,3\n</code></pre>"},{"location":"Reproduction/6_AutoFormer/#_15","title":"\u9644\u5f55","text":"<p>\u539f\u59cb Transformer \u67b6\u6784</p> <p>\u8fd4\u56de \u6b63\u6587\u4f4d\u7f6e\uff1a\u539f\u59cb Transformer \u67b6\u6784 </p> <p></p> <ul> <li><code>d_model</code> \u662f\u5d4c\u5165\u7ef4\u5ea6\uff0c\u4e5f\u5c31\u662f Embedding dim\uff0cD \u662f\u5355\u4e2a\u65f6\u95f4\u6b65\u89c2\u5bdf\u7684\u7279\u5f81\u6570\u3002</li> <li>\u5f97\u5230 Embeddingdim \u7684\u64cd\u4f5c\uff0cNLP \u4e2d\u4e00\u822c\u53eb word embedding\uff0c\u8fd9\u91cc\u53eb tokenEmbedding\u4e5f\u8fd8\u633a\u5408\u7406\u7684\uff0c\u5355\u4e2a\u65f6\u95f4\u6b65\u5c31\u662f\u5355\u4e2a token\u3002</li> </ul>"},{"location":"Reproduction/6_AutoFormer/#conv2","title":"\u7591\u95ee\u4e00 \u4e3a\u4ec0\u4e48Conv2\u4e4b\u540e\u6ca1\u6709\u8fdb\u884c\u6fc0\u6d3b\u51fd\u6570\u7684\u5e94\u7528","text":"<p>\uff081\uff09\u9075\u5faa\u539f\u59cbTransformer\u7684\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5728\u539f\u59cbTransformer\u8bbe\u8ba1\u4e2d\uff0cFFN\u7684\u7ed3\u6784\u4e3a\uff1a<code>FFN(x) = max(0, xW\u2081 + b\u2081)W\u2082 + b\u2082</code>\uff0c\u8fd9\u76f8\u5f53\u4e8e\u4e24\u4e2a\u7ebf\u6027\u53d8\u6362\uff0c\u4e2d\u95f4\u6709\u4e00\u4e2aReLU\u6fc0\u6d3b\u51fd\u6570\u3002\u7b2c\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\u540e\u5e94\u7528\u6fc0\u6d3b\u51fd\u6570\uff0c\u800c\u7b2c\u4e8c\u4e2a\u7ebf\u6027\u53d8\u6362\u540e\u4e0d\u5e94\u7528\u6fc0\u6d3b\u51fd\u6570\u3002Autoformer\u4f7f\u75281D\u5377\u79ef\u66ff\u4ee3\u7ebf\u6027\u53d8\u6362\uff0c\u4f46\u4fdd\u6301\u4e86\u76f8\u540c\u7684\u6fc0\u6d3b\u51fd\u6570\u6a21\u5f0f\u3002</p> <p>\uff082\uff09\u4fdd\u6301\u8f93\u51fa\u7684\u7ebf\u6027\u7279\u6027\uff0c\u6700\u540e\u4e00\u5c42\u4e0d\u4f7f\u7528\u6fc0\u6d3b\u51fd\u6570\u53ef\u4ee5\u4fdd\u6301\u8f93\u51fa\u7684\u7ebf\u6027\u7279\u6027\uff0c\u8fd9\u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5c24\u5176\u91cd\u8981\u3002\u5982\u679c\u5728\u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\u540e\u5e94\u7528\u6fc0\u6d3b\u51fd\u6570\uff1a</p> <ul> <li>\u5bf9\u4e8eReLU\uff1a\u4f1a\u5bfc\u81f4\u8d1f\u503c\u88ab\u622a\u65ad\u4e3a\u96f6\uff0c\u9650\u5236\u6a21\u578b\u8868\u8fbe\u8d1f\u5411\u8d8b\u52bf\u7684\u80fd\u529b</li> <li>\u5bf9\u4e8e\u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570\uff1a\u4f1a\u5f15\u5165\u975e\u7ebf\u6027\u53d8\u6362\uff0c\u53ef\u80fd\u9650\u5236\u6a21\u578b\u5bf9\u7ebf\u6027\u8d8b\u52bf\u7684\u5efa\u6a21\u80fd\u529b</li> <li>\u5728\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4e2d\uff0c\u4fdd\u6301\u4e00\u5b9a\u7684\u7ebf\u6027\u7279\u6027\u5f88\u91cd\u8981\uff0c\u56e0\u4e3a\u8bb8\u591a\u65f6\u95f4\u5e8f\u5217\u5305\u542b\u5f3a\u7ebf\u6027\u8d8b\u52bf\u3002\u6700\u540e\u4e00\u5c42\u4e0d\u4f7f\u7528\u6fc0\u6d3b\u51fd\u6570\uff0c\u53ef\u4ee5\u4f7f\u6a21\u578b\u66f4\u597d\u5730\u6355\u6349\u8fd9\u4e9b\u7ebf\u6027\u8d8b\u52bf\u3002</li> </ul> <p>\uff083\uff09\u603b\u4e4b\uff0c\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u548c\u6fc0\u6d3b\u51fd\u6570**\u8d1f\u8d23\u6355\u6349\u975e\u7ebf\u6027\u7279\u5f81\uff0c**\u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\u6ca1\u6709\u6fc0\u6d3b\u51fd\u6570\uff0c\u4fdd\u6301\u4e86\u4e00\u5b9a\u7684\u7ebf\u6027\u6620\u5c04\u80fd\u529b\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u5728\u975e\u7ebf\u6027\u8868\u8fbe\u80fd\u529b\u548c\u4fdd\u6301\u7ebf\u6027\u7279\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861</p>"},{"location":"Reproduction/6_AutoFormer/#2-conv1d-nnlinear","title":"\u7591\u95ee 2 \u4e3a\u4ec0\u4e48\u662f conv1d\uff0c\u800c\u4e0d\u662f nn.Linear","text":"<ul> <li>\u9996\u5148\uff0c\u5fc5\u987b\u660e\u786e\u7684\u662f\uff0c\u4f7f\u7528nn.Linear \u4e0d\u662f \u4e3a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u521b\u5efa\u5355\u72ec\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u800c\u662f\u5bf9\u6240\u6709\u65f6\u95f4\u6b65\u5e94\u7528\u76f8\u540c\u7684\u6743\u91cd\uff08\u6743\u91cd\u5171\u4eab\uff09\u3002</li> </ul> <p>\u4f8b\u5b50\uff1a </p> <p>\u65b9\u5f0f1\uff1a\u5e94\u7528\u4e8e\u6574\u4e2a\u5e8f\u5217\uff08\u6279\u91cf\u5904\u7406\u6240\u6709\u65f6\u95f4\u6b65\uff09 </p> <p>\u5047\u8bbe\u8f93\u5165x\u5f62\u72b6\u4e3a[B, L, D]</p> Text Only<pre><code>linear_layer = nn.Linear(D, D_out)\noutput = linear_layer(x)  # \u8f93\u51fa\u5f62\u72b6\u4e3a[B, L, D_out]\n</code></pre> <p>\u540c\u4e00\u4e2a\u7ebf\u6027\u5c42\u4f1a\u5e94\u7528\u5230\u6240\u6709\u65f6\u95f4\u6b65\uff0c\u6743\u91cd\u662f\u5171\u4eab\u7684\u3002\u8fd9\u4e0ekernel_size=1\u7684Conv1D\u975e\u5e38\u76f8\u4f3c </p> <ul> <li>kernel_size=1\u7684Conv1D\u5728\u529f\u80fd\u4e0a\u7c7b\u4f3c\u4e8e\u72ec\u7acb\u5e94\u7528\u4e8e\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u4f46\u5b83\u6709\u4e00\u4e2a\u5173\u952e\u533a\u522b\uff1a\u6743\u91cd\u5171\u4eab\u3002\u4f7f\u7528\u5377\u79ef\u610f\u5473\u7740\u540c\u4e00\u7ec4\u6743\u91cd\u5e94\u7528\u4e8e\u6240\u6709\u65f6\u95f4\u6b65</li> </ul> <p>\u65b9\u5f0f2\uff1a\u5faa\u73af\u5e94\u7528\u4e8e\u6bcf\u4e2a\u65f6\u95f4\u6b65 </p> Text Only<pre><code># \u5047\u8bbe\u8f93\u5165x\u5f62\u72b6\u4e3a[B, L, D]\nlinear_layer = nn.Linear(D, D_out)\noutputs = []\nfor i in range(L):\n    output_step = linear_layer(x[:, i, :])  # \u8f93\u51fa\u5f62\u72b6\u4e3a[B, D_out]\n    outputs.append(output_step)\noutput = torch.stack(outputs, dim=1)  # \u8f93\u51fa\u5f62\u72b6\u4e3a[B, L, D_out]\n</code></pre> <p>\u8fd9\u79cd\u65b9\u5f0f\u4e5f\u662f\u4f7f\u7528\u540c\u4e00\u4e2a\u7ebf\u6027\u5c42\uff0c\u6743\u91cd\u4ecd\u7136\u662f\u5171\u4eab\u7684\u3002</p> <p>\u5176\u5b9e\u8fd9\u4e2a\u7591\u95ee\u770b\u56de\u7b54\u5176\u5b9e\u4e5f\u662f\u5927\u53ef\u4e0d\u5fc5\u7684\u3002\u770b\u770b\u5c31\u884c\u4e86\uff0c\u60f3\u7740\u770b\u660e\u767d\u4e0d\u5927\u53ef\u80fd\u3002</p> <p>\u5728Autoformer\u4e2d\u4f7f\u7528kernel_size=1\u7684Conv1D\u65f6\uff0c\u5b83\u5728\u529f\u80fd\u4e0a\u4e0e\u65b9\u5f0f1\u4e2d\u7684nn.Linear\u975e\u5e38\u76f8\u4f3c\uff0c\u4e3b\u8981\u533a\u522b\u5728\u4e8e\uff1a </p> <ol> <li>\u7ef4\u5ea6\u987a\u5e8f\uff1a    - Conv1D\u671f\u671b\u8f93\u5165\u5f62\u72b6\u4e3a<code>[B, C, L]</code>\uff08\u6279\u6b21\u5927\u5c0f\u3001\u901a\u9053\u6570\u3001\u5e8f\u5217\u957f\u5ea6\uff09    - Linear\u671f\u671b\u8f93\u5165\u5f62\u72b6\u4e3a<code>[B, L, D]</code>\uff08\u6279\u6b21\u5927\u5c0f\u3001\u5e8f\u5217\u957f\u5ea6\u3001\u7279\u5f81\u7ef4\u5ea6\uff09</li> <li>\u5b9e\u73b0\u6548\u7387\uff1a    - Conv1D\u5728GPU\u4e0a\u5bf9\u4e8e\u5e8f\u5217\u6570\u636e\u6709\u66f4\u4f18\u5316\u7684\u5b9e\u73b0    - \u4f7f\u7528Conv1D\u53ef\u4ee5\u907f\u514dreshape\u64cd\u4f5c\u6216\u5faa\u73af\u5904\u7406\u65f6\u95f4\u6b65</li> <li>\u6846\u67b6\u8bbe\u8ba1\uff1a    - \u4f7f\u7528Conv1D\u4e0eAutoformer\u7684\u6574\u4f53\u67b6\u6784\u8bbe\u8ba1\u66f4\u4e00\u81f4    - Conv1D\u63d0\u4f9b\u4e86\u6269\u5c55\u5230\u66f4\u5927kernel_size\u7684\u53ef\u80fd\u6027</li> </ol> <p> </p> <p></p> <p> </p>"},{"location":"Reproduction/6_AutoFormer/#_16","title":"\u5e8f\u5217\u5206\u89e3\u7684\u73b0\u5b9e\u610f\u4e49","text":"<p>Autoformer\u4e2d\u5e8f\u5217\u5206\u89e3\u7684\u7279\u6b8a\u6027\u4e0e\u610f\u4e49 </p> <p>Autoformer\u4e2d\u7684\u5e8f\u5217\u5206\u89e3\uff08series_decomp\uff09\u662f\u8be5\u6a21\u578b\u6700\u5177\u521b\u65b0\u6027\u7684\u7279\u70b9\u4e4b\u4e00\uff0c\u5b83\u6df1\u523b\u4f53\u73b0\u4e86\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5904\u7406\u7684\u7279\u6b8a\u9700\u6c42\u3002\u8ba9\u6211\u8be6\u7ec6\u89e3\u6790\u8fd9\u4e00\u8bbe\u8ba1\u7684\u610f\u4e49\uff1a</p> <p>\ud83d\udfe2 \u65f6\u95f4\u5e8f\u5217\u7684\u57fa\u672c\u7ec4\u6210\u90e8\u5206 </p> <p>\u9996\u5148\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u901a\u5e38\u53ef\u4ee5\u5206\u89e3\u4e3a\u4e09\u4e2a\u57fa\u672c\u7ec4\u6210\u90e8\u5206\uff1a - \u8d8b\u52bf\uff08Trend\uff09\uff1a\u957f\u671f\u7684\u53d8\u5316\u65b9\u5411\uff0c\u5982\u7ecf\u6d4e\u589e\u957f\u7684\u603b\u4f53\u8d8b\u52bf - \u5b63\u8282\u6027\uff08Seasonality\uff09\uff1a\u5468\u671f\u6027\u7684\u53d8\u5316\u6a21\u5f0f\uff0c\u5982\u6bcf\u5e74\u7684\u5b63\u8282\u6027\u9500\u552e\u53d8\u5316 - \u6b8b\u5dee\uff08Residual\uff09\uff1a\u968f\u673a\u6ce2\u52a8\u6216\u566a\u58f0</p> <p>\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u65b9\u6cd5\uff08\u5982ARIMA\u3001\u6307\u6570\u5e73\u6ed1\u6cd5\uff09\u901a\u5e38\u4f1a\u5148\u5206\u89e3\u65f6\u95f4\u5e8f\u5217\uff0c\u518d\u5206\u522b\u5efa\u6a21\u3002</p> <p>\ud83d\udfe2 Autoformer\u7684\u5e8f\u5217\u5206\u89e3\u673a\u5236</p> <p>Autoformer\u901a\u8fc7<code>series_decomp</code>\u5c06\u8f93\u5165\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u4e24\u4e2a\u90e8\u5206\uff1a</p> Python<pre><code>res, moving_mean = self.decomp1(x)\n</code></pre> <p>\u8fd9\u91cc\uff1a - <code>res</code> \u662f\u5b63\u8282\u6027\u90e8\u5206\uff08\u77ed\u671f\u5468\u671f\u6027\u53d8\u5316\uff09 - <code>moving_mean</code> \u662f\u8d8b\u52bf\u90e8\u5206\uff08\u957f\u671f\u65b9\u5411\u6027\u53d8\u5316\uff09</p> <p>\u5173\u952e\u70b9\u662f\uff0cAutoformer\u5728\u591a\u4e2a\u4f4d\u7f6e\u4f7f\u7528\u5e8f\u5217\u5206\u89e3\uff0c\u5e76\u6709\u9009\u62e9\u5730\u4e22\u5f03\u8d8b\u52bf\u90e8\u5206\u3002\u4f8b\u5982\uff1a</p> Python<pre><code># \u5c06\u6b8b\u5dee\u8fde\u63a5\u7ed3\u679c\u5206\u89e3\uff0c\u4ec5\u4fdd\u7559\u5b63\u8282\u6027\u90e8\u5206\nres, _ = self.decomp2(x + y)\n</code></pre> <p>\ud83d\udfe2  \u8fd9\u79cd\u8bbe\u8ba1\u7684\u6df1\u5c42\u610f\u4e49 </p> <p>\uff081\uff09\u5206\u79bb\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u7684\u6a21\u5f0f</p> <p>\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u4ee3\u8868\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u7684\u53d8\u5316\u6a21\u5f0f\uff1a - \u8d8b\u52bf\u53cd\u6620\u957f\u671f\u53d8\u5316\uff08\u4f4e\u9891\u4fe1\u53f7\uff09 - \u5b63\u8282\u6027\u53cd\u6620\u77ed\u671f\u5468\u671f\u53d8\u5316\uff08\u9ad8\u9891\u4fe1\u53f7\uff09</p> <p>\u901a\u8fc7\u5206\u79bb\u8fd9\u4e24\u79cd\u6a21\u5f0f\uff0cAutoformer\u53ef\u4ee5\uff1a - \u8ba9\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e13\u6ce8\u4e8e\u6355\u83b7\u5b63\u8282\u6027\u6a21\u5f0f\uff0c\u8fd9\u66f4\u9002\u5408\u5176\u64c5\u957f\u6355\u83b7\u7684\u5c40\u90e8\u4f9d\u8d56\u5173\u7cfb - \u5355\u72ec\u5904\u7406\u8d8b\u52bf\u90e8\u5206\uff0c\u907f\u514d\u6df7\u5408\u4e0d\u540c\u9891\u7387\u7684\u4fe1\u53f7\u5bfc\u81f4\u7684\u5efa\u6a21\u56f0\u96be</p> <p>\uff082\uff09\u6e10\u8fdb\u5f0f\u5206\u89e3\u67b6\u6784 </p> <p>Autoformer\u91c7\u7528\"\u6e10\u8fdb\u5f0f\u5206\u89e3\"\uff08Progressive Decomposition\uff09\u67b6\u6784\uff1a - \u6bcf\u4e00\u5c42\u90fd\u8fdb\u884c\u5e8f\u5217\u5206\u89e3\uff0c\u9010\u6b65\u63d0\u53d6\u5b63\u8282\u6027\u7279\u5f81 - \u901a\u8fc7\u4e22\u5f03\u4e2d\u95f4\u5c42\u7684\u8d8b\u52bf\u4fe1\u606f\uff0c\u5f3a\u5236\u6a21\u578b\u5173\u6ce8\u5b63\u8282\u6027\u6a21\u5f0f - \u5728\u89e3\u7801\u5668\u4e2d\uff0c\u5206\u522b\u7d2f\u79ef\u5404\u5c42\u7684\u8d8b\u52bf\u4fe1\u606f\uff0c\u5f62\u6210\u6700\u7ec8\u8d8b\u52bf\u9884\u6d4b</p> <p>\u8fd9\u79cd\u67b6\u6784\u89e3\u51b3\u4e86\u4f20\u7edfTransformer\u5728\u957f\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u74f6\u9888\uff1a - \u4f20\u7edfTransformer\u5728\u957f\u671f\u9884\u6d4b\u4e2d\u5f80\u5f80\u5b58\u5728\"\u957f\u671f\u9884\u6d4b\u504f\u5dee\u79ef\u7d2f\"\u95ee\u9898 - \u5206\u79bb\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u53ef\u4ee5\u51cf\u8f7b\u8fd9\u79cd\u504f\u5dee\u79ef\u7d2f</p> <p>\uff083\uff09\u589e\u5f3a\u5b63\u8282\u6027\u548c\u5468\u671f\u6027\u6a21\u5f0f\u7684\u5b66\u4e60 </p> <p>\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5b63\u8282\u6027\u6a21\u5f0f\uff08\u5982\u6bcf\u65e5\u3001\u6bcf\u5468\u3001\u6bcf\u6708\u6216\u6bcf\u5e74\u7684\u5468\u671f\u6027\uff09\u662f\u9884\u6d4b\u7684\u91cd\u8981\u4f9d\u636e\u3002\u901a\u8fc7\u4fdd\u7559\u5b63\u8282\u6027\u90e8\u5206\uff1a - \u6a21\u578b\u53ef\u4ee5\u66f4\u597d\u5730\u6355\u6349\u8fd9\u4e9b\u91cd\u590d\u51fa\u73b0\u7684\u6a21\u5f0f - \u589e\u5f3a\u4e86\u5bf9\u5468\u671f\u6027\u884c\u4e3a\u7684\u8bc6\u522b\u80fd\u529b - \u964d\u4f4e\u4e86\u8d8b\u52bf\u53d8\u5316\u5bf9\u5b63\u8282\u6027\u6a21\u5f0f\u8bc6\u522b\u7684\u5e72\u6270</p> <p>\ud83d\udfe2 \u5de5\u7a0b\u5b9e\u73b0\u7684\u5de7\u5999\u4e4b\u5904 </p> <p>\u4ece\u4ee3\u7801\u5b9e\u73b0\u770b\uff0cAutoformer\u7684\u5e8f\u5217\u5206\u89e3\u91c7\u7528\u7b80\u5355\u800c\u6709\u6548\u7684\u79fb\u52a8\u5e73\u5747\u65b9\u6cd5\uff1a </p>Python<pre><code># \u8ba1\u7b97\u79fb\u52a8\u5e73\u5747\uff0c\u63d0\u53d6\u5e8f\u5217\u8d8b\u52bf\u5206\u91cf\nmoving_mean = self.moving_avg(x)\n# \u901a\u8fc7\u539f\u59cb\u5e8f\u5217\u51cf\u53bb\u8d8b\u52bf\u5206\u91cf\uff0c\u5f97\u5230\u6b8b\u5dee(\u5b63\u8282\u6027\u5206\u91cf)\nres = x - moving_mean\n</code></pre><p></p> <p>\u8fd9\u4e00\u7b80\u5355\u64cd\u4f5c\u5728\u8ba1\u7b97\u6548\u7387\u4e0e\u6548\u679c\u4e4b\u95f4\u53d6\u5f97\u4e86\u5f88\u597d\u7684\u5e73\u8861\uff1a - \u8ba1\u7b97\u5f00\u9500\u4f4e\uff0c\u9002\u5408\u5904\u7406\u957f\u5e8f\u5217 - \u6548\u679c\u663e\u8457\uff0c\u80fd\u6709\u6548\u5206\u79bb\u4e0d\u540c\u9891\u7387\u7684\u4fe1\u53f7</p> <p>\ud83d\udfe2 \u4e0e\u4f20\u7edfTransformer\u7684\u5173\u952e\u533a\u522b </p> <p>\u5728\u4f20\u7edfTransformer\u4e2d\uff0c\u6b8b\u5dee\u8fde\u63a5\u76f4\u63a5\u5c06\u539f\u59cb\u8f93\u5165\u548c\u5904\u7406\u540e\u7684\u8f93\u51fa\u76f8\u52a0\uff1a </p>Python<pre><code>x = x + self.dropout(new_x)  # \u4f20\u7edfTransformer\n</code></pre><p></p> <p>\u800cAutoformer\u5728\u76f8\u52a0\u540e\u8fd8\u8fdb\u884c\u4e86\u5e8f\u5217\u5206\u89e3\uff1a </p>Python<pre><code>x = x + self.dropout(new_x)\nx, _ = self.decomp1(x)  # Autoformer\u7684\u7279\u6b8a\u5904\u7406\n</code></pre><p></p> <p>\u4ee5\u53ca\u5728\u524d\u9988\u7f51\u7edc\u540e\uff1a </p>Python<pre><code>res, _ = self.decomp2(x + y)  # \u4f20\u7edfTransformer\u53ea\u6709 x = x + y\n</code></pre><p></p> <p>\u8fd9\u4e00\u521b\u65b0\u8bbe\u8ba1\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u4fe1\u606f\u5728\u7f51\u7edc\u4e2d\u7684\u6d41\u52a8\u65b9\u5f0f\uff0c\u4f7f\u6a21\u578b\u66f4\u9002\u5408\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u3002</p> <p>\ud83d\udfe2 \u5b9e\u9645\u5e94\u7528\u610f\u4e49 </p> <p>\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u8fd9\u79cd\u5e8f\u5217\u5206\u89e3\u673a\u5236\u5e26\u6765\u7684\u597d\u5904\u5305\u62ec\uff1a</p> <ol> <li>\u63d0\u9ad8\u957f\u671f\u9884\u6d4b\u51c6\u786e\u6027\uff1a\u901a\u8fc7\u5206\u79bb\u8d8b\u52bf\u548c\u5b63\u8282\u6027\uff0c\u51cf\u5c11\u957f\u671f\u9884\u6d4b\u4e2d\u7684\u8bef\u5dee\u79ef\u7d2f</li> <li>\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\uff1a\u5206\u89e3\u540e\u7684\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u7ec4\u4ef6\u66f4\u5bb9\u6613\u7406\u89e3\u548c\u89e3\u91ca</li> <li>\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff1a\u5b66\u4e60\u5230\u7684\u5b63\u8282\u6027\u6a21\u5f0f\u53ef\u4ee5\u66f4\u597d\u5730\u6cdb\u5316\u5230\u65b0\u7684\u65f6\u95f4\u6bb5</li> <li>\u51cf\u8f7b\u6570\u636e\u9884\u5904\u7406\u8d1f\u62c5\uff1a\u6a21\u578b\u5185\u7f6e\u7684\u5206\u89e3\u673a\u5236\u51cf\u5c11\u4e86\u6570\u636e\u9884\u5904\u7406\u7684\u9700\u6c42</li> </ol> <p>\ud83d\udfe2 \u7ed3\u8bba </p> <p>Autoformer\u4e2d\u7684\u5e8f\u5217\u5206\u89e3\u4e0d\u4ec5\u662f\u4e00\u4e2a\u6280\u672f\u7ec6\u8282\uff0c\u800c\u662f\u4e00\u4e2a\u4f53\u73b0\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u672c\u8d28\u7279\u6027\u7684\u5173\u952e\u8bbe\u8ba1\u3002\u5b83\u4f7fAutoformer\u80fd\u591f\u6709\u6548\u533a\u5206\u548c\u5904\u7406\u4e0d\u540c\u9891\u7387\u7684\u4fe1\u53f7\uff0c\u63d0\u9ad8\u957f\u671f\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002\u8fd9\u4e00\u8bbe\u8ba1\u5145\u5206\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u9886\u57df\u77e5\u8bc6\uff08\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff09\u4e0e\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff08Transformer\uff09\u6709\u673a\u7ed3\u5408\uff0c\u521b\u9020\u51fa\u66f4\u9002\u5408\u7279\u5b9a\u4efb\u52a1\u7684\u6a21\u578b\u67b6\u6784\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#_17","title":"\u7406\u89e3\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236","text":""},{"location":"Reproduction/6_AutoFormer/#k-v-q","title":"\u7f16\u7801\u5668\u7684\u8f93\u51fa\u4f5c\u4e3a K \u548c V\uff0c\u89e3\u7801\u5668\u7684\u8f93\u5165\u4f5c\u4e3a Q","text":"<p>\ud83d\udfe2 \u6ce8\u610f\u529b\u673a\u5236\u672c\u8d28\u4e0a\u662f\u4e00\u79cd\u8f6f\u68c0\u7d22\u7cfb\u7edf\uff1a</p> <ul> <li>Query\uff08\u67e5\u8be2\uff09\uff1a\u8868\u8fbe\u5f53\u524d\u89e3\u7801\u4f4d\u7f6e\u9700\u8981\u7684\u4fe1\u606f\u7c7b\u578b</li> <li>Key\uff08\u952e\uff09\uff1a\u8868\u793a\u6e90\u5e8f\u5217\u4e2d\u5404\u4f4d\u7f6e\u4fe1\u606f\u7684\"\u7d22\u5f15\"</li> <li>Value\uff08\u503c\uff09\uff1a\u8868\u793a\u6e90\u5e8f\u5217\u4e2d\u5404\u4f4d\u7f6e\u7684\u5b9e\u9645\u5185\u5bb9</li> </ul> <p>\u89e3\u7801\u5668\u901a\u8fc7\u5176\u9690\u85cf\u72b6\u6001\u5f62\u6210\u67e5\u8be2\uff08Q\uff09\uff0c\u7136\u540e\u6839\u636e\u4e0e\u7f16\u7801\u5668\u9690\u85cf\u72b6\u6001\uff08K\uff09\u7684\u76f8\u5173\u6027\uff0c\u63d0\u53d6\u76f8\u5e94\u7684\u7f16\u7801\u5668\u4fe1\u606f\uff08V\uff09\u3002</p> <p>\ud83d\udfe2 \u5728\u5e8f\u5217\u5230\u5e8f\u5217\u5b66\u4e60\u4e2d\uff0c\u4ea4\u53c9\u6ce8\u610f\u529b\u5b9e\u73b0\u4e86\u6761\u4ef6\u751f\u6210\uff1a</p> <p>\u7f16\u7801\u5668\uff1a\u8d1f\u8d23\u7406\u89e3\u8f93\u5165\u5e8f\u5217\uff08\u5982\u6e90\u8bed\u8a00\u6587\u672c\u6216\u5386\u53f2\u65f6\u95f4\u5e8f\u5217\uff09</p> <p>\u89e3\u7801\u5668\uff1a\u8d1f\u8d23\u57fa\u4e8e\u8f93\u5165\u5e8f\u5217\u751f\u6210\u8f93\u51fa\u5e8f\u5217\uff08\u5982\u76ee\u6807\u8bed\u8a00\u6587\u672c\u6216\u672a\u6765\u65f6\u95f4\u5e8f\u5217\uff09</p> <p>\u89e3\u7801\u5668\u9700\u8981\"\u6709\u6761\u4ef6\u5730\"\u751f\u6210\u8f93\u51fa\uff0c\u8fd9\u4e2a\u6761\u4ef6\u5c31\u662f\u7f16\u7801\u5668\u5904\u7406\u7684\u8f93\u5165\u5e8f\u5217\uff0c\u4ea4\u53c9\u6ce8\u610f\u529b\u63d0\u4f9b\u4e86\u8fd9\u79cd\u6761\u4ef6\u673a\u5236\u3002</p> <p>\ud83d\udfe2 \u5728Autoformer\u8fd9\u6837\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u4e2d\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u6709\u5176\u7279\u6b8a\u610f\u4e49\uff1a</p> <p>\u7f16\u7801\u5668\uff1a\u5904\u7406\u5386\u53f2\u65f6\u95f4\u5e8f\u5217\uff0c\u63d0\u53d6\u5173\u952e\u6a21\u5f0f\u548c\u7279\u5f81</p> <p>\u89e3\u7801\u5668\uff1a\u57fa\u4e8e\u8fd9\u4e9b\u6a21\u5f0f\u751f\u6210\u672a\u6765\u65f6\u95f4\u5e8f\u5217</p> <p>\u4ea4\u53c9\u6ce8\u610f\u529b\u8ba9\u89e3\u7801\u5668\u80fd\u591f\u5728\u751f\u6210\u6bcf\u4e2a\u672a\u6765\u65f6\u95f4\u6b65\u65f6\uff0c\u9009\u62e9\u6027\u5730\u5173\u6ce8\u5386\u53f2\u5e8f\u5217\u4e2d\u7684\u76f8\u5173\u6a21\u5f0f\uff0c\u5c24\u5176\u662f\u90a3\u4e9b\u4e0e\u5f53\u524d\u9884\u6d4b\u4f4d\u7f6e\u76f8\u5173\u7684\u5b63\u8282\u6027\u6216\u5468\u671f\u6027\u6a21\u5f0f\u3002</p>"},{"location":"Reproduction/6_AutoFormer/#_18","title":"\u5faa\u73af\u586b\u5145","text":"<p>\u9002\u7528\uff1a\u7279\u522b\u9002\u5408\u5904\u7406\u5177\u6709\u5468\u671f\u6027\u7279\u5f81\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e</p> <p>\u672c\u6587\u4f7f\u7528\u5faa\u73af\u586b\u5145\u7684\u4f4d\u7f6e\uff0c\u5bf9\u8d8b\u52bf\u6210\u5206\u8fd8\u539f\u539f\u59cb\u7ef4\u5ea6\u7684\u65f6\u5019\uff1a</p> Python<pre><code>self.projection = nn.Conv1d(in_channels=d_model, \n                            out_channels=c_out, \n                            kernel_size=3, \n                            stride=1, \n                            padding=1, \n                            padding_mode='circular', \n                            bias=False)\n</code></pre> <p>\u533a\u5206\u51e0\u79cd\u586b\u5145\u65b9\u5f0f</p> <p>\u3010\u4e3b\u8981\u89c2\u5bdf\uff0ca,b,c,d\u7684\u5de6\u53f3 \u3011</p> <p>\uff081\uff090 \u586b\u5145\uff1a\u96f6\u586b\u5145\uff08\u9ed8\u8ba4\uff0c'zeros'\uff09\uff1a\u75280\u503c\u586b\u5145\u5e8f\u5217\u8fb9\u754c</p> Text Only<pre><code>\u539f\u5e8f\u5217: [a, b, c, d]\n\u586b\u5145\u540e: [0, 0, a, b, c, d, 0, 0]\n</code></pre> <p>\uff082\uff09\u91cd\u590d\u586b\u5145\uff1a\u91cd\u590d\u586b\u5145\uff08'replicate'\uff09\uff1a\u590d\u5236\u8fb9\u754c\u503c</p> Text Only<pre><code>\u539f\u5e8f\u5217: [a, b, c, d]\n\u586b\u5145\u540e: [a, a, a, b, c, d, d, d]\n</code></pre> <p>(3)\u5faa\u73af\u586b\u5145\uff08'circular'\uff09\uff1a\u5c06\u5e8f\u5217\u89c6\u4e3a\u5faa\u73af\u7ed3\u6784</p> Text Only<pre><code>\u539f\u5e8f\u5217: [a, b, c, d]\n\u586b\u5145\u540e: [c, d, a, b, c, d, a, b]\n</code></pre> <p>\u4e3a\u4ec0\u4e48\u5e8f\u5217\u586b\u5145\uff0c\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217</p> <p>\u5c06\u65f6\u95f4\u5e8f\u5217\u89c6\u4e3a\u4e00\u4e2a\u5faa\u73af\uff0c\u5e8f\u5217\u672b\u5c3e\u8fde\u63a5\u5230\u5e8f\u5217\u5f00\u5934\uff0c\u4fdd\u6301\u65f6\u95f4\u6570\u636e\u7684\u5468\u671f\u6027\u7279\u6027\uff0c\u4e0d\u5f15\u5165\u4eba\u4e3a\u7684\u503c\uff0c\u53ea\u4f7f\u7528\u5df2\u6709\u6570\u636e</p> <p>\u65f6\u95f4\u5e8f\u5217\u5468\u671f\u6027\u7684\u63cf\u8ff0\uff1a</p> <ul> <li>\u5e74\u5ea6\u5468\u671f\uff1a\u6bcf\u5e74\u540c\u4e00\u65f6\u95f4\u70b9\u7684\u6570\u636e\u53ef\u80fd\u6709\u76f8\u4f3c\u6a21\u5f0f</li> <li>\u6708\u5ea6\u5468\u671f\uff1a\u6bcf\u6708\u53ef\u80fd\u6709\u76f8\u4f3c\u7684\u6a21\u5f0f\uff08\u5982\u6708\u521d\u3001\u6708\u4e2d\u3001\u6708\u672b\uff09</li> <li>\u5468\u5ea6\u5468\u671f\uff1a\u6bcf\u5468\u7684\u5de5\u4f5c\u65e5\u548c\u5468\u672b\u6a21\u5f0f\u5f80\u5f80\u7c7b\u4f3c</li> <li>\u65e5\u5185\u5468\u671f\uff1a\u6bcf\u5929\u5185\u7684\u6d3b\u52a8\u6a21\u5f0f\uff08\u5982\u65e9\u9ad8\u5cf0\u3001\u5348\u4f11\u65f6\u95f4\uff09</li> </ul> <p>\u4f8b\u5b50\uff1a</p> Text Only<pre><code>[\u5468\u4e00, \u5468\u4e8c, \u5468\u4e09, \u5468\u56db, \u5468\u4e94, \u5468\u516d, \u5468\u65e5]\n</code></pre> <p>\u5faa\u73af\u586b\u5145\u4ee5\u540e\uff1a </p> Text Only<pre><code>\u8fb9\u754c\u5904\u7406\u540e\uff1a[\u5468\u516d, \u5468\u65e5, \u5468\u4e00, \u5468\u4e8c, ..., \u5468\u65e5, \u5468\u4e00, \u5468\u4e8c]\n</code></pre> <p>PyTorch\u4e2d\u7684\u5faa\u73af\u586b\u5145\u5b9e\u73b0\u4f1a\u5c06\u5e8f\u5217\u89c6\u4e3a\u73af\u5f62\u7ed3\u6784\uff1a</p> <ul> <li>\u5bf9\u4e8e\u9700\u8981\u5728\u5de6\u4fa7\u586b\u5145\u7684\u90e8\u5206\uff0c\u4ece\u5e8f\u5217\u53f3\u7aef\u53d6\u503c</li> <li>\u5bf9\u4e8e\u9700\u8981\u5728\u53f3\u4fa7\u586b\u5145\u7684\u90e8\u5206\uff0c\u4ece\u5e8f\u5217\u5de6\u7aef\u53d6\u503c</li> </ul>"},{"location":"Reproduction/6_AutoFormer/#_19","title":"\u4e3a\u4ec0\u4e48\u5b63\u8282\u6210\u5206\u548c\u8d8b\u52bf\u6210\u5206\u4e0d\u540c\u7684\u8fd8\u539f\u7ef4\u5ea6\u65b9\u6cd5","text":"<p>\u9996\u5148\uff0c\u660e\u786e\uff0c\u5b63\u8282\u6210\u5206 \u4f7f\u7528\u7ebf\u6027\u5c42\u6295\u5f71 </p> Python<pre><code># Decoder\u7c7b\u4e2d\u7684\u6295\u5f71\nself.projection = projection  # \u901a\u5e38\u662fnn.Linear(d_model, c_out)\n\n# \u4f7f\u7528\u65f6\nif self.projection is not None:\n    x = self.projection(x)  # x: [B, L, d_model] -&gt; [B, L, c_out]\n</code></pre> <p>\u8d8b\u52bf\u6210\u5206\uff1a\u4f7f\u7528\u5377\u79ef\u5c42\uff08Conv1d\uff09\u8fdb\u884c\u6295\u5f71</p> Python<pre><code># DecoderLayer\u7c7b\u4e2d\u7684\u6295\u5f71\nself.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, \n                           kernel_size=3, stride=1, padding=1,\n                           padding_mode='circular', bias=False)\n\n# \u4f7f\u7528\u65f6\nresidual_trend = self.projection(residual_trend.permute(0, 2, 1)).transpose(1, 2)\n</code></pre> <p>\ud83d\udd35 \u89e3\u91ca\u8fd9\u4e48\u8bbe\u8ba1\u7684\u7406\u7531\uff1a</p> <p>\u5b63\u8282\u6210\u5206\u4f5c\u4e3a\u9ad8\u9891\u6210\u5206\uff0c\u4e0d\u4f1a\u5e73\u6ed1\u65f6\u95f4\u5e8f\u5217\uff0c\u4fdd\u7559\u4e86\u5b63\u8282\u6027\u7684\u5c16\u9510\u53d8\u5316</p> <p>\u8d8b\u52bf\u6210\u5206\u4f5c\u4e3a\u4f4e\u9891\u6210\u5206\uff0c\u8d8b\u52bf\u672c\u8d28\u4e0a\u662f==\u5e73\u6ed1==\u7684</p> <ul> <li>\u8bbe\u7f6e kernel size = 3\uff0c\u8003\u8651\u4e86\u5c40\u90e8\u4e0a\u4e0b\u6587\u6709\u52a9\u4e8e\u7ef4\u6301\u8fd9\u79cd\u5e73\u6ed1\u6027</li> <li>\u5377\u79ef\u64cd\u4f5c\uff08\u7279\u522b\u662fkernel_size=3\uff09\u80fd\u591f\u5e73\u6ed1\u8d8b\u52bf\uff0c\u8fc7\u6ee4\u6389\u4e0d\u5fc5\u8981\u7684\u9ad8\u9891\u6270\u52a8</li> <li>\uff08\u53c2\u6570\u5171\u4eab\uff09\u8de8\u4e0d\u540c\u65f6\u95f4\u70b9\u7684\u76f8\u540c\u6a21\u5f0f\u53ef\u4ee5\u88ab\u76f8\u540c\u7684\u5377\u79ef\u6838\u8bc6\u522b</li> </ul>"},{"location":"Reproduction/6_AutoFormer_v1/","title":"(\u7eed) Autoformer","text":""},{"location":"Reproduction/6_AutoFormer_v1/#autoformer","title":"(\u7eed) Autoformer","text":"2025-03-23 20:53:222025-09-28 12:54:03 <p> \u7ea6 1095 \u4e2a\u5b57  29 \u884c\u4ee3\u7801  5 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 6 \u5206\u949f</p> <p>\u8bba\u6587\u3001\u516c\u5f0f\u3001\u56fe\u3001\u4ee3\u7801</p> <p>\uff080\uff09\u56de\u987e</p> <p>\u9996\u5148\uff0c\u8fdb\u5165\u539f\u6587\u81ea\u76f8\u5173\u673a\u5236\u7684\u90e8\u5206\uff0c\u4ed4\u7ec6\u89c2\u5bdf\u539f\u6587\uff0c\u539f\u65873.1\u7684\u6807\u9898\u662f\u5206\u89e3\u67b6\u6784\uff0c\u5e76\u7531\u6b64\u5c55\u5f00\u5e8f\u5217\u5206\u89e3\u6a21\u5757\u3001\u6a21\u578b\u8f93\u5165\u3001\u7f16\u7801\u5668\u3001\u89e3\u7801\u5668\u90e8\u5206\u3002\u8fd9\u662f\u5341\u5206\u5408\u7406\u7684\uff0c\u56e0\u4e3a\u672c\u6587\u7684\u4e00\u4e2a\u7a81\u51fa\u4eae\u70b9\u5c31\u662f\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u6210\u9ad8\u9891\u7684\u5b63\u8282\u6210\u5206\u548c\u4f4e\u9891\u7684\u8d8b\u52bf\u6210\u5206\uff0c\u5728\u7f16\u7801\u5668\u4e2d\u7684\u6bcf\u5c42\u4e2d\u7684\u6ce8\u610f\u529b\u548c\u524d\u9988\u7f51\u4e4b\u540e\u90fd\u8fdb\u884c\u4e86\u5e8f\u5217\u5206\u89e3\uff0c\u4f7f\u5f97\u9ad8\u9891\u6210\u5206\u9010\u5c42\u63d0\u53d6\u3002\u5728\u89e3\u7801\u5668\u4e2d\uff0c\u6bcf\u5c42\u4e2d\u7684\u81ea\u6ce8\u610f\u529b\u3001\u4ea4\u53c9\u6ce8\u610f\u529b\u3001\u524d\u9988\u7f51\u4ee5\u540e\uff0c\u540c\u6837\u8fdb\u884c\u4e86\u5e8f\u5217\u5206\u89e3\uff0c\u5c42\u5185\u4f20\u9012\u5b63\u8282\u6210\u5206\uff0c\u8d8b\u52bf\u6210\u5206\u8fdb\u884c\u7d2f\u52a0\uff0c\u6240\u4ee5\u7b2c\u4e00\u90e8\u5206\u7684\u6807\u9898\u53eb\u505a\u5e8f\u5217\u5206\u89e3\u3002\u4e5f\u662f\u4e00\u4e2a\u7a81\u51fa\u521b\u65b0\u3002</p> <p>(0-0) Autoformer\u90e8\u5206\u7684\u539f\u6587\u7ec4\u7ec7\u5f62\u5f0f</p> <p> </p> <p>\u63a5\u4e0b\u6765\u8fdb\u884c\u7b2c\u4e8c\u4e2a\u7a81\u51fa\u521b\u65b0\uff0c\u6539\u8fdb\u539f\u59cbTransformer \u7684\u6ce8\u610f\u529b\u673a\u5236\u7684\u8ba1\u7b97\u3002</p> <p>\uff081\uff09\u81ea\u76f8\u5173\u673a\u5236</p> <p></p> <p>\u672c\u6587\u63d0\u51fa\u4e86 \u9010\u5e8f\u5217\u8fde\u63a5\u7684\u81ea\u76f8\u5173\u673a\u5236 \u6765\u8fdb\u884c\u4fe1\u606f\u805a\u5408\u3002</p> <p>\u81ea\u76f8\u5173 \u901a\u8fc7\u8ba1\u7b97\u5e8f\u5217\u7684\u76f8\u5173\u5173\u7cfb \u53d1\u73b0 \u5468\u671f\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u4e14\u901a\u8fc7\u65f6\u95f4\u5ef6\u8fdf\u805a\u5408 \u805a\u5408 \u76f8\u4f3c\u7684\u5b50\u5e8f\u5217</p> <p>\u5173\u952e\u70b9\uff1a\u2460\u81ea\u76f8\u5173\u673a\u5236\u53d1\u73b0\u5468\u671f\u6027\u7684\u4f9d\u8d56\u5173\u7cfb \u2461 time delay aggregation \u8fd9\u91cc\u7684 aggregate \u805a\u5408\u7684\u662f \u6a21\u5f0f\u76f8\u540c\u7684\u5b50\u5e8f\u5217\u3002</p> <p>\uff082\uff09\u57fa\u4e8e\u5468\u671f\u7684\u4f9d\u8d56\u5173\u7cfb</p> <p> </p> <p>\u5468\u671f\u4e2d\uff0c\u76f8\u540c\u76f8\u4f4d\u4f4d\u7f6e\u63d0\u4f9b\u4e86\u76f8\u4f3c\u7684\u5b50\u8fc7\u7a0b</p> <p>\u53d7\u968f\u673a\u8fc7\u7a0b\u7406\u8bba\u7684\u542f\u53d1\uff0c\u5bf9\u4e8e\u771f\u5b9e\u7684\u79bb\u6563\u65f6\u95f4\u5e8f\u5217 \\(\\{\\mathcal{X}_t\\}\\) \uff0c\u901a\u8fc7\u4ee5\u4e0b\u516c\u5f0f\u83b7\u5f97\u81ea\u76f8\u5173\u5173\u7cfb \\(\\mathcal{R}_{\\mathcal{XX}}(\\mathcal{T})\\) \uff1a</p> <p>\\(\\mathcal{R}_{\\mathcal{XX}}(\\mathcal{T}) = \\lim _{L \\rightarrow \\infty } \\frac{1}{L} \\sum_{t=1}^{L} \\mathcal{X}_t \\mathcal{X}_{t-\\mathcal{T}}\\)</p> <ul> <li>\\(\\mathcal{R}_{\\mathcal{XX}}(\\mathcal{T})\\) \u53cd\u6620\u7684\u662f \\(\\{\\mathcal{X}_t \\}\\)  \u4e0e \u5176 \\(\\mathcal{T}\\) \u6ede\u540e\u5e8f\u5217 \\(\\{\\mathcal{X}_{t-\\mathcal{T}}\\}\\) \u4e4b\u95f4\u7684\u65f6\u95f4\u5ef6\u8fdf\u76f8\u4f3c\u6027\u3002 </li> <li>\u6211\uff1a\\(\\mathcal{T}\\)  \u8868\u793a\u5ef6\u8fdf\u65f6\u95f4\u6b65\uff1b\\(\\mathcal{R}_{\\mathcal{XX}}(\\mathcal{T})\\) \u5c31\u662f\u81ea\u76f8\u5173\u7cfb\u6570</li> </ul> <p>\u5982\u56fe 2 \u6240\u793a\uff0c\u4f7f\u7528\u81ea\u76f8\u5173\u7cfb\u6570 \\(\\mathcal{R}_{\\mathcal{XX}}(\\mathcal{T})\\) \u4f5c\u4e3a\u4f30\u8ba1\u5468\u671f\u957f\u5ea6 \\(\\mathcal{T}\\)\u7684\u7f6e\u4fe1\u5ea6\u3002\uff08\u8fd9\u91cc\u8bf4\u51c6\u786e\u7684\u8bf4\u6cd5\u662f \u672a\u5f52\u4e00\u5316\u7684\u7f6e\u4fe1\u5ea6\uff09</p> <p>\u7136\u540e\uff0c\u9009\u62e9\\(k\\) \u4e2a\u6700\u6709\u53ef\u80fd\u7684\u5468\u671f\u957f\u5ea6 \\(\\mathcal{T}_1,.....,\\mathcal{T}_k\\)</p> <p>\u57fa\u4e8e\u5468\u671f\u7684\u4f9d\u8d56\u5173\u7cfb\u5c31\u662f\u4ece\u8fd9 \\(k\\) \u4e2a\u6700\u6709\u53ef\u80fd\u7684\u5468\u671f\u957f\u5ea6\u4e2d\u5bfc\u51fa\uff0c\u5e76\u4e14\u901a\u8fc7\u76f8\u5e94\u7684\u81ea\u76f8\u5173\u8fdb\u884c\u52a0\u6743\u3002</p> <p>\uff083\uff09\u539f\u6587\u56fe 2 </p> <p></p> <p>\uff083-1\uff09\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u7684\u7ef4\u5ea6\u8f6c\u6362</p> Python<pre><code>BLD-&gt;BLHd-&gt;BHLd   \\\n\n                    BHLS\n\nBSD-&gt;BSHd-&gt;BHSd   /\n</code></pre> <p>\u9996\u5148\uff0c\u8bf4\u660e\u539f\u59cb\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\uff0cQKV \u7684\u6784\u9020\uff0c\u6807\u51c6\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u7684\u8f93\u5165\u662f BLD\u2192BLHd\u2192BHLd\uff08view \u4ee5\u540e permute\uff09\uff08ps\uff0c\u8fd9\u91cc\u7ebf\u6027\u5c42\u7684\u76ee\u7684\u662f\u5c06\u539f\u59cb\u7ef4\u5ea6\u5d4c\u5165\u5230 H*d?\u4e0d\u7ba1\uff0c\u4e0d\u5f71\u54cd\u7406\u89e3\uff0c\u540e\u9762\u518d\u8bf4\uff09</p> Python<pre><code>q = self.q_proj(q).view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n\nk = self.k_proj(k).view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n\nv = self.v_proj(v).view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n</code></pre> <p>\u770b\u5230\u6211\u4eec\u9879\u76ee\u7684\u4ee3\u7801</p> <p>\ud83d\udd87\ufe0f \u5f53\u524d\u4f4d\u7f6e\uff1aAutoCorrelation  forward</p> <p>\u9996\u5148\u662f\u83b7\u53d6\u4e00\u4e9b\u7ef4\u5ea6\u4fe1\u606f</p> <p>\ud83d\udd87\ufe0f \u6e90\u7801\uff1a\u4fdd\u7559\u67e5\u8be2\u5411\u91cf\u7684 B\u3001L\u3001H\u3001E</p> <ul> <li> \u95ee\u9898\uff1a\u4e3a\u4ec0\u4e48\u6807\u51c6\u591a\u5934\u6ce8\u610f\u529b\u7684\u8f93\u5165\u662f BHLd \u7684\uff0c\u8fd9\u91cc\u786e\u5b9e BLHd \u7684\uff0c\u8fd9\u91cc\u5c11\u4e86\u4e00\u6b65\u5440</li> </ul> <p>\u662f\u7684\u3002\u786e\u5b9e\u5c11\u4e86\u4e00\u6b65\uff0c\u53ea\u8fdb\u884c\u4e86 view\uff0c\u6ca1\u6709 transpose</p> <p>\u7b54\u6848\u5728 AutoCorrelationLayer \u7684 forward \u4e2d\uff0cqkv \u7684\u5904\u7406\u3002</p> Python<pre><code>queries = self.query_projection(queries).view(B, L, H, -1)\nkeys = self.key_projection(keys).view(B, S, H, -1)\nvalues = self.value_projection(values).view(B, S, H, -1)\n</code></pre> <p>\u8865\u5145\uff0c\u8fd9\u91cc\u7684qkv \u7684\u5efa\u6a21<code>nn.Linear</code>\u662f\u5c06 \u539f\u59cb <code>d_model</code>\uff0c\u5d4c\u5165\u5230 <code>d_keys * n_heads</code> </p> <p>\ud83d\udd87\ufe0f \u6e90\u7801\uff1a\u4fdd\u7559\u503c\u5411\u91cf\u7684\u5e8f\u5217\u957f\u5ea6S\u548c\u5d4c\u5165\u7ef4\u5ea6D</p> <p>\u84bd\uff0c\u4e00\u822c Transformer \u4e5f\u662f\u5206\u5f00\u67e5\u8be2\u5411\u91cf\u548c\u503c\u5411\u91cf\u7684\u5e8f\u5217\u957f\u5ea6\u3002Q \u548c K \u7684\u5411\u91cf\u957f\u5ea6\u53ef\u4ee5\u4e0d\u4e00\u81f4\uff0c\u4f46\u662f\u5d4c\u5165\u7ef4\u5ea6\u5fc5\u987b\u662f\u4e00\u81f4\u7684\u3002\u5e76\u4e14\u751f\u6210\u7684 attn \u7684\u5f62\u72b6\u662f <code>BHLS</code> \u7684\uff08<code>\u67e5\u8be2\u5411\u91cf\u957f\u5ea6 \u00d7 \u503c\u5411\u91cf\u957f\u5ea6</code>\uff09</p> <ul> <li>\ud83d\udfe2 \u6e90\u7801\uff1a\u63a5\u4e0b\u6765\uff0c\u4e00\u4e2a\u5e8f\u5217\u5bf9\u9f50\u64cd\u4f5c\uff0c\u6807\u51c6\u5bf9\u51c6\u67e5\u8be2\u5e8f\u5217</li> </ul> <p>\u23e9\ufe0f \u5982\u679c\u67e5\u8be2\u65f6\u95f4\u6b65\u6b65\u957f &gt; \u952e\u548c\u503c\u7684\u65f6\u95f4\u6b65\u6b65\u957f\uff1b\u5904\u7406\u952e\u5e8f\u5217\u548c\u503c\u5e8f\u5217\u957f\u5ea6\u548c\u67e5\u8be2\u5e8f\u5217\u957f\u5ea6\u5bf9\u9f50\uff0c\u952e\u5e8f\u5217\u548c\u503c\u5e8f\u5217\u4e0d\u591f\u957f\u7684\u90e8\u5206\uff0c\u586b\u5145 0</p> <p>\u23e9\ufe0f \u5982\u679c\u67e5\u8be2\u5e8f\u5217\u65ad\u4e86\uff0c\u622a\u65ad\u952e\u5e8f\u5217\u548c\u503c\u5e8f\u5217\u591a\u7684\u90e8\u5206</p> Python<pre><code>if L &gt; S: \n    zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n    values = torch.cat([values, zeros], dim=1)\n    keys = torch.cat([keys, zeros], dim=1)\nelse:\n    values = values[:, :L, :, :]\n    keys = keys[:, :L, :, :]\n</code></pre> <p>\u5f3a\u8c03\uff0c\u4e3a\u4ec0\u4e48\u8fd9\u91cc\u5904\u7406\u7684\u662f dim1\uff0c\u7406\u7531\u56e0\u4e3a\u4e4b\u524d\u8bf4\u8fc7\u4e86\uff0c\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u4f20\u8fdb\u6765\u7684 QKV\uff0c\u6ca1\u6709\u8fdb\u884c transpose\uff0c\u6240\u4ee5\u6570\u636e\u683c\u5f0f\u662f<code>[BLHd]</code>\u7684</p> <p>\u6e90\u7801\u8bb2\u89e3\uff1a </p> Python<pre><code># period-based dependencies\n\nq_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n\nk_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n\nres = q_fft * torch.conj(k_fft)\n\ncorr = torch.fft.irfft(res, n=L, dim=-1)\n</code></pre> <p>\u8be5\u90e8\u5206\u662f\u539f\u8bba\u6587\uff0c\u5b98\u65b9\u6ce8\u91ca\u7ed9\u7684 </p> <p></p> <p>\u73b0\u5728\u770b\u4ee3\u7801\u662f\u600e\u4e48\u548c\u8bba\u6587\u5bf9\u5e94\u7684</p>"},{"location":"Reproduction/6_AutoFormer_v2_eg/","title":"AutoFormer \u53ef\u89c6\u5316\u7ed3\u679c","text":""},{"location":"Reproduction/6_AutoFormer_v2_eg/#autoformer","title":"AutoFormer \u53ef\u89c6\u5316\u7ed3\u679c","text":"2025-03-26 22:14:452025-09-28 12:54:03 <p> \u7ea6 293 \u4e2a\u5b57  26 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>\u7528\u4e00\u6bb5\u4ee3\u7801\u6f14\u793a Autoformer \u7684\u8fc7\u7a0b\uff0c\u5e8f\u5217\u5206\u89e3\u505a\u7684\u4e8b\uff1a</p> <p></p> <p>\u8fd8\u6709\u5bf9\u5e94\u7684\u5e45\u5ea6\u8c31\u3001\u76f8\u4f4d\u8c31\u5206\u89e3\u7ed3\u679c\uff1a</p> Python<pre><code>\u4e3b\u8981\u8c10\u6ce2:\n- \u5468\u671f: 24.0\u5c0f\u65f6, \u5e45\u5ea6: 15.27, \u76f8\u4f4d: 175.7\u00b0\n- \u5468\u671f: 28.0\u5c0f\u65f6, \u5e45\u5ea6: 1.74, \u76f8\u4f4d: -5.5\u00b0\n- \u5468\u671f: 56.0\u5c0f\u65f6, \u5e45\u5ea6: 1.29, \u76f8\u4f4d: 19.1\u00b0\n- \u5468\u671f: 12.9\u5c0f\u65f6, \u5e45\u5ea6: 1.12, \u76f8\u4f4d: 32.7\u00b0\n- \u5468\u671f: 9.9\u5c0f\u65f6, \u5e45\u5ea6: 1.10, \u76f8\u4f4d: 25.4\u00b0\n</code></pre>"},{"location":"Reproduction/6_AutoFormer_v2_eg/#_1","title":"\u6a21\u62df\u6570\u636e","text":"<p>\u9996\u5148\uff0c\u521b\u5efa\u4e00\u4e2a\u6a21\u62df\u7684\u4e00\u5468\u7535\u529b\u9700\u6c42\u6570\u636e\uff0c\u5305\u62ec\u957f\u671f\u8d8b\u52bf\u3001\u65e5\u5185\u53d8\u5316\u3001\u5de5\u4f5c\u65e5\u4e0e\u5468\u672b\u53d8\u5316\u4ee5\u53ca\u566a\u58f0\u3002</p> <p>24\u00d77=168\u5c0f\u65f6</p> \\[  \\text{power\\_demand}(t) = \\text{trend}(t) + \\text{daily}(t) + \\text{weekly}(t) + \\text{noise}(t)  \\] <p>\u5176\u4e2d\uff1a</p> <p>\u5c06\u957f\u671f\u8d8b\u52bf\u3001\u65e5\u5185\u53d8\u5316\u3001\u5de5\u4f5c\u65e5\u4e0e\u5468\u672b\u53d8\u5316\u4ee5\u53ca\u566a\u58f0\u53e0\u52a0\u5728\u4e00\u8d77\uff0c\u751f\u6210\u4e00\u4e2a\u6a21\u62df\u7684\u4e00\u5468\u7535\u529b\u9700\u6c42\u6570\u636e $$ \\text{trend}(t) = 100 + 0.05 \\cdot t $$</p> <p>\u957f\u671f\u8d8b\u52bf\u662f\u4e00\u4e2a\u7ebf\u6027\u589e\u957f\u7684\u8d8b\u52bf\uff0c\u521d\u59cb\u503c\u4e3a 100\uff0c\u6bcf\u5c0f\u65f6\u589e\u52a0 0.05\u3002</p> \\[ \\text{daily}(t) = 15 \\cdot \\sin\\left(\\frac{2\\pi t}{24} - \\frac{\\pi}{2}\\right) \\] <p>\u65e5\u5185\u53d8\u5316\uff1a 24 \u5c0f\u65f6\u5468\u671f\u7684\u6b63\u5f26\u6ce2\uff0c\u5e45\u5ea6\u4e3a 15\uff0c\u76f8\u4f4d\u504f\u79fb\u4e3a -\u03c0/2\u3002</p> \\[ \\text{weekly}(t) = \\begin{cases} 10 &amp; \\text{if } t \\mod 168 &lt; 120 \\ -10 &amp; \\text{if } t \\mod 168 \\geq 120 \\end{cases} \\] <p>\u5de5\u4f5c\u65e5\u4e0e\u5468\u672b\u53d8\u5316\uff1a\uff08\u516c\u53f8\u7528\u7535\u91cf\uff09\u4e00\u4e2a\u6bcf\u5468\u5468\u671f\u7684\u53d8\u5316\uff0c\u5de5\u4f5c\u65e5\u589e\u52a0 10\uff0c\u5468\u672b\u51cf\u5c11 10</p> <p>\u5173\u4e8e\u8fd9\u91cc\u4e3a\u4ec0\u4e48\u5bf9 120 \u53d6\u4f59\u6570\uff1a</p> <ul> <li>t % 168 \u8ba1\u7b97\u65f6\u95f4 t \u5728\u4e00\u5468\u5185\u7684\u5c0f\u65f6\u6570\uff08\u53d6\u4f59\u6570\uff09\u3002</li> <li>t % 168 &lt; 120\u8868\u793a\u524d 5 \u5929\u7684\u5c0f\u65f6\u6570\uff085 \u5929 * 24 \u5c0f\u65f6 = 120 \u5c0f\u65f6\uff09\uff0c\u5bf9\u5e94\u5de5\u4f5c\u65e5\u3002</li> <li>t % 168 &gt;= 120\u8868\u793a\u540e 2 \u5929\u7684\u5c0f\u65f6\u6570\uff08168 \u5c0f\u65f6 - 120 \u5c0f\u65f6 = 48 \u5c0f\u65f6\uff09\uff0c\u5bf9\u5e94\u5468\u672b\u3002</li> </ul> \\[  \\text{noise}(t) = \\text{\u968f\u673a\u566a\u58f0\uff0c\u5747\u503c\u4e3a0\uff0c\u6807\u51c6\u5dee\u4e3a3}  \\] Python<pre><code>hours = np.arange(168)\n# \u521b\u5efa\u957f\u671f\u8d8b\u52bf\ntrend = 100 + 0.05 * hours\n# \u521b\u5efa\u65e5\u5185\u53d8\u5316 (24\u5c0f\u65f6\u5468\u671f)\ndaily = 15 * np.sin(2*np.pi*hours/24 - np.pi/2)\n# \u521b\u5efa\u5de5\u4f5c\u65e5vs\u5468\u672b\u53d8\u5316 (\u4e00\u5468\u5468\u671f)\nweekly = np.zeros_like(hours)\nfor i in range(7):\n    if i &lt; 5:  # \u5de5\u4f5c\u65e5\n        weekly[i*24:(i+1)*24] = 10\n    else:      # \u5468\u672b\n        weekly[i*24:(i+1)*24] = -10\n# \u6dfb\u52a0\u4e00\u4e9b\u566a\u58f0\nnoise = 3 * np.random.randn(168)\n</code></pre>"},{"location":"Reproduction/6_AutoFormer_v2_eg/#_2","title":"\u7ed3\u679c\u5206\u6790","text":"Python<pre><code>\u4e3b\u8981\u8c10\u6ce2:\n- \u5468\u671f: 24.0\u5c0f\u65f6, \u5e45\u5ea6: 15.27, \u76f8\u4f4d: 175.7\u00b0\n- \u5468\u671f: 28.0\u5c0f\u65f6, \u5e45\u5ea6: 1.74, \u76f8\u4f4d: -5.5\u00b0\n- \u5468\u671f: 56.0\u5c0f\u65f6, \u5e45\u5ea6: 1.29, \u76f8\u4f4d: 19.1\u00b0\n- \u5468\u671f: 12.9\u5c0f\u65f6, \u5e45\u5ea6: 1.12, \u76f8\u4f4d: 32.7\u00b0\n- \u5468\u671f: 9.9\u5c0f\u65f6, \u5e45\u5ea6: 1.10, \u76f8\u4f4d: 25.4\u00b0\n</code></pre>"},{"location":"Reproduction/7_summary/","title":"\u6c47\u603b\u590d\u73b0\u8c03\u7528\u56fe","text":""},{"location":"Reproduction/7_summary/#_1","title":"\u6c47\u603b\u590d\u73b0\u8c03\u7528\u56fe","text":"2025-03-23 20:53:222025-09-28 12:54:03 <p> \u7ea6 15 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"Reproduction/7_summary/#autoformer","title":"Autoformer","text":"<p>1</p> <pre><code>classDiagram\n    class Model {\n        +int seq_len\n        +int label_len\n        +int pred_len\n        +bool output_attention\n        +series_decomp decomp\n        +DataEmbedding_wo_pos enc_embedding\n        +DataEmbedding_wo_pos dec_embedding\n        +Encoder encoder\n        +Decoder decoder\n        +forward(x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\n    }\n\n    class series_decomp {\n        +moving_avg moving_avg\n        +forward(x) res, moving_mean\n    }\n\n    class moving_avg {\n        +int kernel_size\n        +AvgPool1d avg\n        +forward(x)\n    }\n\n    class DataEmbedding_wo_pos {\n        +TokenEmbedding value_embedding\n        +TemporalEmbedding|TimeFeatureEmbedding temporal_embedding\n        +Dropout dropout\n        +forward(x, x_mark)\n        +__init__(c_in, d_model, embed_type, freq, dropout)\n    }\n\n    class TokenEmbedding {\n        +Conv1d tokenConv\n        +forward(x)\n    }\n\n    class TemporalEmbedding {\n        +Embedding minute_embed\n        +Embedding hour_embed\n        +Embedding weekday_embed\n        +Embedding day_embed\n        +Embedding month_embed\n        +forward(x)\n    }\n\n    class TimeFeatureEmbedding {\n        +Linear embed\n        +forward(x)\n    }\n\n    class Encoder {\n        +List~EncoderLayer~ layers\n        +my_Layernorm norm_layer\n        +forward(x, attn_mask)\n    }\n\n    class EncoderLayer {\n        +AutoCorrelationLayer attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, attn_mask)\n    }\n\n    class AutoCorrelationLayer {\n        +AutoCorrelation attention\n        +Linear query_projection\n        +Linear key_projection\n        +Linear value_projection\n        +Linear out_projection\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class AutoCorrelation {\n        +bool mask_flag\n        +int factor\n        +float scale\n        +Dropout dropout\n        +bool output_attention\n        +time_delay_agg_training(values, corr)\n        +time_delay_agg_inference(values, corr)\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class Decoder {\n        +List~DecoderLayer~ layers\n        +my_Layernorm norm_layer\n        +Linear projection\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    class DecoderLayer {\n        +AutoCorrelationLayer self_attention\n        +AutoCorrelationLayer cross_attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +series_decomp decomp3\n        +Dropout dropout\n        +activation\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    %% Model\u4e2d\u7684\u7ec4\u4ef6\u5b9e\u4f8b\u5316\u5173\u7cfb\n    Model *-- \"1\" series_decomp : \u521b\u5efadecomp\n    Model *-- \"1\" DataEmbedding_wo_pos : \u521b\u5efaenc_embedding\n    Model *-- \"1\" DataEmbedding_wo_pos : \u521b\u5efadec_embedding\n    Model *-- \"1\" Encoder : \u521b\u5efaencoder\n    Model *-- \"1\" Decoder : \u521b\u5efadecoder\n\n    %% DataEmbedding_wo_pos\u5185\u90e8\u7ec4\u4ef6\n    DataEmbedding_wo_pos *-- \"1\" TokenEmbedding : \u521b\u5efavalue_embedding\n    DataEmbedding_wo_pos *-- \"1\" TemporalEmbedding : \u521b\u5efatemporal_embedding(\u5f53embed_type!='timeF')\n    DataEmbedding_wo_pos *-- \"1\" TimeFeatureEmbedding : \u521b\u5efatemporal_embedding(\u5f53embed_type='timeF')\n\n    %% \u5176\u4ed6\u7ec4\u4ef6\u5173\u7cfb\n    series_decomp *-- \"1\" moving_avg\n    Encoder *-- \"e_layers\" EncoderLayer\n    EncoderLayer *-- \"1\" AutoCorrelationLayer\n    EncoderLayer *-- \"2\" series_decomp : decomp1,decomp2\n    AutoCorrelationLayer *-- \"1\" AutoCorrelation\n    Decoder *-- \"d_layers\" DecoderLayer\n    DecoderLayer *-- \"2\" AutoCorrelationLayer : self\u548ccross\u6ce8\u610f\u529b\n    DecoderLayer *-- \"3\" series_decomp : decomp1,2,3\n</code></pre> <p>2</p> <pre><code>classDiagram\n    class Model {\n        +int seq_len\n        +int label_len\n        +int pred_len\n        +bool output_attention\n        +series_decomp decomp\n        +DataEmbedding_wo_pos enc_embedding\n        +DataEmbedding_wo_pos dec_embedding\n        +Encoder encoder\n        +Decoder decoder\n        +forward(x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\n    }\n\n    class series_decomp {\n        +moving_avg moving_avg\n        +forward(x) res, moving_mean\n    }\n\n    class moving_avg {\n        +int kernel_size\n        +AvgPool1d avg\n        +forward(x)\n    }\n\n    class DataEmbedding_wo_pos {\n        +TokenEmbedding value_embedding\n        +PositionalEmbedding position_embedding\n        +TemporalEmbedding or TimeFeatureEmbedding temporal_embedding  \n        +Dropout dropout\n        +forward(x, x_mark)\n    }\n\n    class TokenEmbedding {\n        +Conv1d tokenConv\n        +forward(x)\n    }\n\n    class TemporalEmbedding {\n        +Embedding minute_embed\n        +Embedding hour_embed\n        +Embedding weekday_embed\n        +Embedding day_embed\n        +Embedding month_embed\n        +forward(x)\n    }\n\n    class TimeFeatureEmbedding {\n        +Linear embed\n        +forward(x)\n    }\n\n    class Encoder {\n        +List~EncoderLayer~ layers\n        +my_Layernorm norm_layer\n        +forward(x, attn_mask)\n    }\n\n    class EncoderLayer {\n        +AutoCorrelationLayer attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, attn_mask)\n    }\n\n    class AutoCorrelationLayer {\n        +AutoCorrelation attention\n        +Linear query_projection\n        +Linear key_projection\n        +Linear value_projection\n        +Linear out_projection\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class AutoCorrelation {\n        +bool mask_flag\n        +int factor\n        +float scale\n        +Dropout dropout\n        +bool output_attention\n        +time_delay_agg_training(values, corr)\n        +time_delay_agg_inference(values, corr)\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class Decoder {\n        +List~DecoderLayer~ layers\n        +my_Layernorm norm_layer\n        +Linear projection\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    class DecoderLayer {\n        +AutoCorrelationLayer self_attention\n        +AutoCorrelationLayer cross_attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +series_decomp decomp3\n        +Dropout dropout\n        +activation\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    %% \u6838\u5fc3\u7ec4\u4ef6\u5173\u7cfb\n    Model --&gt; series_decomp\n    Model --&gt; DataEmbedding_wo_pos\n    Model --&gt; Encoder\n    Model --&gt; Decoder\n\n    %% \u5d4c\u5165\u5c42\u5173\u7cfb - \u4fee\u6b63\u4e3a\u6761\u4ef6\u5173\u7cfb\n    DataEmbedding_wo_pos --&gt; TokenEmbedding\n    DataEmbedding_wo_pos ..&gt; TemporalEmbedding : \u5f53embed_type!='timeF'\n    DataEmbedding_wo_pos ..&gt; TimeFeatureEmbedding : \u5f53embed_type='timeF'\n\n    %% \u7f16\u7801\u5668\u7ec4\u4ef6\u5173\u7cfb\n    Encoder --&gt; EncoderLayer\n    EncoderLayer --&gt; AutoCorrelationLayer\n    EncoderLayer --&gt; Conv1d\n    EncoderLayer --&gt; series_decomp\n    AutoCorrelationLayer --&gt; AutoCorrelation\n\n    %% \u89e3\u7801\u5668\u7ec4\u4ef6\u5173\u7cfb\n    Decoder --&gt; DecoderLayer\n    DecoderLayer --&gt; AutoCorrelationLayer\n    DecoderLayer --&gt; Conv1d\n    DecoderLayer --&gt; series_decomp\n\n    %% \u5e8f\u5217\u5206\u89e3\u5173\u7cfb\n    series_decomp --&gt; moving_avg\n    moving_avg --&gt; AvgPool1d\n</code></pre>"},{"location":"Reproduction/7_summary/#encoderdecoder","title":"Encoder&amp;Decoder","text":"<pre><code>classDiagram\n    class Model {\n        +DataEmbedding_wo_pos enc_embedding\n        +DataEmbedding_wo_pos dec_embedding\n        +Encoder encoder\n        +Decoder decoder\n        +series_decomp decomp\n        +forward(x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\n    }\n\n    class Encoder {\n        +List~EncoderLayer~ layers\n        +my_Layernorm norm_layer\n        +forward(x, attn_mask)\n    }\n\n    class EncoderLayer {\n        +AutoCorrelationLayer attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, attn_mask)\n    }\n\n    class AutoCorrelationLayer {\n        +AutoCorrelation attention\n        +Linear query_projection\n        +Linear key_projection\n        +Linear value_projection\n        +Linear out_projection\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class AutoCorrelation {\n        +bool mask_flag\n        +int factor\n        +float scale\n        +Dropout dropout\n        +bool output_attention\n        +time_delay_agg_training(values, corr)\n        +time_delay_agg_inference(values, corr)\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class Decoder {\n        +List~DecoderLayer~ layers\n        +my_Layernorm norm_layer\n        +Linear projection\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    class DecoderLayer {\n        +AutoCorrelationLayer self_attention\n        +AutoCorrelationLayer cross_attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    Model --&gt; Encoder\n    Model --&gt; Decoder\n    Encoder --&gt; EncoderLayer\n    EncoderLayer --&gt; AutoCorrelationLayer\n    EncoderLayer --&gt; Conv1d\n    EncoderLayer --&gt; series_decomp\n    AutoCorrelationLayer --&gt; AutoCorrelation\n    Decoder --&gt; DecoderLayer\n    DecoderLayer --&gt; AutoCorrelationLayer\n    DecoderLayer --&gt; Conv1d\n    DecoderLayer --&gt; series_decomp\n</code></pre>"},{"location":"Reproduction/7_summary/#decoder","title":"\u653e\u5927 Decoder","text":"<pre><code>classDiagram\n    class Model {\n        +Encoder encoder\n        +Decoder decoder\n        +forward(x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\n    }\n\n    class Decoder {\n        +List~DecoderLayer~ layers\n        +my_Layernorm norm_layer\n        +Linear projection\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    class DecoderLayer {\n        +AutoCorrelationLayer self_attention\n        +AutoCorrelationLayer cross_attention\n        +Conv1d conv1\n        +Conv1d conv2\n        +series_decomp decomp1\n        +series_decomp decomp2\n        +Dropout dropout\n        +activation\n        +forward(x, enc_out, x_mask, cross_mask, trend)\n    }\n\n    class AutoCorrelationLayer {\n        +AutoCorrelation attention\n        +Linear query_projection\n        +Linear key_projection\n        +Linear value_projection\n        +Linear out_projection\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    class AutoCorrelation {\n        +bool mask_flag\n        +int factor\n        +float scale\n        +Dropout dropout\n        +bool output_attention\n        +time_delay_agg_training(values, corr)\n        +time_delay_agg_inference(values, corr)\n        +forward(queries, keys, values, attn_mask)\n    }\n\n    Model --&gt; Encoder\n    Model --&gt; Decoder\n    Decoder --&gt; DecoderLayer\n    DecoderLayer --&gt; AutoCorrelationLayer\n    DecoderLayer --&gt; Conv1d\n    DecoderLayer --&gt; series_decomp\n    AutoCorrelationLayer --&gt; AutoCorrelation\n</code></pre>"},{"location":"Reproduction/8_ThuML/","title":"thuml\u590d\u73b0","text":""},{"location":"Reproduction/8_ThuML/#thuml","title":"thuml\u590d\u73b0","text":"2025-04-02 15:40:002025-09-28 12:54:03 <p> \u7ea6 12 \u4e2a\u5b57  3 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>https://github.com/thuml/Time-Series-Library</p>"},{"location":"Reproduction/8_ThuML/#_1","title":"\u5f00\u59cb","text":"<p>\u65b0\u5efa\u865a\u62df\u73af\u5883\uff1a</p> Python<pre><code>conda create -n ThuML python=3.8\nconda activate ThuML\npip install -r requirements.txt\n</code></pre>"},{"location":"Reproduction/9_WITRAN/","title":"WITRAN\u4ee3\u7801\u590d\u73b0","text":""},{"location":"Reproduction/9_WITRAN/#witran","title":"WITRAN\u4ee3\u7801\u590d\u73b0","text":"2025-04-14 22:46:482025-09-28 12:54:03 <p> \u7ea6 2729 \u4e2a\u5b57  99 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 15 \u5206\u949f</p> <p>\u7b80\u5355\u590d\u73b0\uff0c\u53ea\u590d\u73b0\u6a21\u578b\u90e8\u5206\uff0c\u770b\u660e\u767d\u6570\u636e\u6d41\u52a8\uff0c\u6536\u56de\u6211\u7684\u8bdd\uff0c\u8fd9\u4e2a\u4ee3\u7801\u592a\u96be\u4e86\uff0c\u6709\u5404\u79cd\u95e8\uff0c\u6211\u4e0d\u719f</p>"},{"location":"Reproduction/9_WITRAN/#witran_2dpsgmu_encoder","title":"WITRAN_2DPSGMU_Encoder","text":"<ul> <li>\u7ef4\u62a4\u5404\u79cd\u95e8</li> </ul> Python<pre><code>def forward(self, input, batch_size, input_size, flag): \n</code></pre> <p>\u9996\u5148\u8fd9\u4e2a\u7c7b\u7684 forward \u63a5\u6536\uff1a\u8f93\u5165\u5f20\u91cf input\u3001batchsize\uff0cinputsize \u6bcf\u5c0f\u65f6\u8bb0\u5f55\u7684\u7279\u5f81\u6570\uff0cflag \u7528\u4e8e\u63a7\u5236\u8c03\u6574\u7ef4\u5ea6</p> Python<pre><code>        if flag == 1: \n            input = input.permute(2, 0, 1, 3)\n        else: \n            input = input.permute(1, 0, 2, 3)\n</code></pre> <p>\u8fdb\u5165\u51fd\u6570\uff0c\u9996\u5148\u662f\u6839\u636e flag \u8c03\u6574\u7ef4\u5ea6\uff0c\u8fd9\u91cc flag=0\uff0c\u5c06\u8f93\u5165 input \u7684\u7ef4\u5ea6\u4ece[4,32,24,11] permute\u6210[4,32,24,11]\uff0c\u5177\u4f53\u7684\u5b9e\u9645\u542b\u4e49\u4f5c\u8005\u8bf4\u662f\u6309\u7167\u81ea\u7136\u5468\u671f\u5bf9\u65f6\u5e8f\u6570\u636e\u8fdb\u884c\u5217\u91cd\u6392\uff0c\u8fd9\u91cc\u662f\u5c0f\u65f6\u7ea7\u522b\u7684\u6570\u636e\uff0c\u56e0\u6b64 96 \u4e2a\u5c0f\u65f6\u8bb0\u5f55\u7684 4 \u5929 24 \u5c0f\u65f6\u7684\u6570\u636e\uff0c\u56e0\u6b64\u91cd\u6392\u6210 [4,32,24,11]</p> Python<pre><code>Water2sea_slice_num, _, Original_slice_len, _ = input.shape\n\n'''\n    \u83b7\u53d6\u8c03\u6574\u7ef4\u5ea6\u540e\u7684\u5f62\u72b6 \u5207\u7247\u6570\uff084\u30014 \u5929\uff09\u3001\u539f\u59cb\u5207\u7247\u957f\u5ea6\uff0824 \u5c0f\u65f6\uff09\n    Water2sea_slice_num = 4 \uff0cOriginal_slice_len = 24\n'''\nWater2sea_slice_len = Water2sea_slice_num + Original_slice_len - 1\n'''\n    \u8ba1\u7b97\u6269\u5c55\u540e\u7684\u5e8f\u5217\u957f\u5ea6 Water2sea_slice_num = 4,Original_slice_len = 24\n    Water2sea_slice_len = 24 + 4 - 1 = 27\n    \u5207\u7247\u957f\u5ea6 = \u5207\u7247\u6570 + \u539f\u59cb\u5207\u7247\u957f\u5ea6 - 1\n'''\n</code></pre> <p>\u63a5\u4e0b\u6765\u5bf9 input \u7684\u5f62\u72b6\u8fdb\u884c\u89e3\u5305\u64cd\u4f5c\uff0c\u5f97\u5230\u8f6c\u4e8c\u7ef4\u65f6\u5e8f\u6570\u636e\u7684\u884c\u6570\u548c\u5217\u6570\uff0c\u6211\u4eec\u539f\u59cb\u5f97\u5230\u7684\u884c\u6570\u662f 4\uff0c\u5217\u6570\u662f 24\uff0c\u4f46\u4f5c\u8005\u4e3a\u4e86\u8ba9\u65f6\u95f4\u70b9\u8fde\u7eed\uff0c\u5b9e\u9645\u4f7f\u7528\u7684\u5217\u662f 27\uff0c\u4e5f\u5c31\u662f\u8bf4 4+24-1=27</p> \u8bf4\u660e\uff1a\u5173\u4e8e\u8fd9\u4e2a 27 \u53ef\u4ee5\u8be6\u7ec6\u8bf4\u660e\u4f5c\u8005\u4e3a\u4ec0\u4e48\u8fd9\u4e48\u5904\u7406\uff0c\u56e0\u4e3a\u540e\u9762\u6d89\u53ca\u5230\u586b\u5145\u64cd\u4f5c <p> \u4f5c\u8005\u4e3a\u4e86\u8ba9\u65f6\u95f4\u70b9\u8fde\u7eed\uff0c\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u7684\u65b9\u5f0f\u6269\u5c55\u5217\u6570\uff1a \u7b2c 1 \u5929\u7684\u6570\u636e\u4ece\u7b2c 0 \u5217\u5f00\u59cb\u3002 \u7b2c 2 \u5929\u7684\u6570\u636e\u4ece\u7b2c 1 \u5217\u5f00\u59cb\u3002 \u7b2c 3 \u5929\u7684\u6570\u636e\u4ece\u7b2c 2 \u5217\u5f00\u59cb\u3002 \u7b2c 4 \u5929\u7684\u6570\u636e\u4ece\u7b2c 3 \u5217\u5f00\u59cb\u3002 \u539f\u59cb\u8f93\u5165 [32, 4, 24, 11] \u88ab\u8c03\u6574\u4e3a [4, 32, 24, 11]\uff0c\u6309\u7167\u5929\u6570\u548c\u5c0f\u65f6\u7ec4\u7ec7\u3002\u540e\u9762 \u6269\u5c55\u540e\u7684\u5217\u6570 27 \u5305\u542b\u4e86\u539f\u59cb\u7684 24 \u5c0f\u65f6\u6570\u636e\uff0c\u5e76\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u5f15\u5165\u4e86 3 \u5c0f\u65f6\u7684\u91cd\u53e0\u3002 \u66f4\u5f62\u8c61\u7684\u8868\u793a\uff1a     \u5047\u8bbe\u6709 4 \u5929\u7684\u6570\u636e\uff0c\u6bcf\u5929 24 \u5c0f\u65f6\uff0c\u6bcf\u5c0f\u65f6\u6709 11 \u4e2a\u7279\u5f81\uff1a     \u7b2c 1 \u5929\uff1a[\u7279\u5f811, \u7279\u5f812, ..., \u7279\u5f8111]\uff0c\u5171 24 \u5c0f\u65f6\u3002     \u7b2c 2 \u5929\uff1a[\u7279\u5f811, \u7279\u5f812, ..., \u7279\u5f8111]\uff0c\u5171 24 \u5c0f\u65f6\u3002     \u7b2c 3 \u5929\uff1a[\u7279\u5f811, \u7279\u5f812, ..., \u7279\u5f8111]\uff0c\u5171 24 \u5c0f\u65f6\u3002     \u7b2c 4 \u5929\uff1a[\u7279\u5f811, \u7279\u5f812, ..., \u7279\u5f8111]\uff0c\u5171 24 \u5c0f\u65f6\u3002 \u6269\u5c55\u540e\u7684\u6570\u636e     \u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u7684\u65b9\u5f0f\uff0c\u6bcf\u4e00\u5929\u7684\u6570\u636e\u4e0e\u524d\u4e00\u5929\u7684\u6570\u636e\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u4ea7\u751f\u4e86\u91cd\u53e0\uff1a     \u7b2c 1 \u5929\uff1a[0:24]\uff0c\u8868\u793a\u7b2c 1 \u5929\u7684 24 \u5c0f\u65f6\u6570\u636e\u3002     \u7b2c 2 \u5929\uff1a[1:25]\uff0c\u8868\u793a\u7b2c 2 \u5929\u7684 24 \u5c0f\u65f6\u6570\u636e\uff0c\u4e0e\u7b2c 1 \u5929\u7684\u6570\u636e\u91cd\u53e0 1 \u5c0f\u65f6\u3002     \u7b2c 3 \u5929\uff1a[2:26]\uff0c\u8868\u793a\u7b2c 3 \u5929\u7684 24 \u5c0f\u65f6\u6570\u636e\uff0c\u4e0e\u7b2c 2 \u5929\u7684\u6570\u636e\u91cd\u53e0 2 \u5c0f\u65f6\u3002     \u7b2c 4 \u5929\uff1a[3:27]\uff0c\u8868\u793a\u7b2c 4 \u5929\u7684 24 \u5c0f\u65f6\u6570\u636e\uff0c\u4e0e\u7b2c 3 \u5929\u7684\u6570\u636e\u91cd\u53e0 3 \u5c0f\u65f6\u3002 </p> Python<pre><code>hidden_slice_row = torch.zeros(Water2sea_slice_num * batch_size, self.hidden_size).to(input.device)\n'''\n    \u521d\u59cb\u5316\u884c\u548c\u5217\u7684\u9690\u85cf\u72b6\u6001\n\n    \u8f93\u5165\uff1a Water2sea_slice_num = 4\uff0cbatch_size = 32\uff0chidden_size = 32\n    \u5904\u7406\uff1atorch.zeros \n    \u8f93\u51fa\uff1a hidden_slice_row :  [4 * 32, 28] = [128, 32]\n'''\n\nhidden_slice_col = torch.zeros(Water2sea_slice_num * batch_size, self.hidden_size).to(input.device)\n\n'''\n    \u5b58\u50a8\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u5217\u9690\u85cf\u72b6\u6001\n    \u8f93\u5165\uff1a\n        Water2sea_slice_num = 4\uff0cbatch_size = 32\uff0cself.hidden_size = 32\n    \u5904\u7406\uff1atorch.zeros\n    \u8f93\u51fa\uff1a\n        hidden_slice_col = [128, 32]        \n'''\n</code></pre> <p>\u63a5\u4e0b\u6765\u521d\u59cb\u5316\u884c\u9690\u85cf\u72b6\u6001\u548c\u5217\u9690\u85cf\u72b6\u6001</p> <p>\u5148\u8bf4\u7ed3\u8bba\uff0c\u884c\u9690\u85cf\u72b6\u6001\u7684\u5f62\u72b6\u662f [128,32]\uff0c128 \u8868\u793a 4\u00d732,4 \u8868\u793a 4 \u5929\uff0c\u8981\u4e3a \u6bcf\u4e00\u5929\u7ef4\u62a4\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\uff0c\u53c8\u56e0\u4e3a batchsize=32\uff0c\u6bcf\u4e00\u5929\u7684\u6570\u636e\u9700\u8981\u4e3a\u6bcf\u4e2a\u6837\u672c\u7ef4\u62a4\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\uff0c\u7528\u4e8e\u6355\u83b7\u65f6\u95f4\u5e8f\u5217\u7684\u7279\u5f81\u4fe1\u606f\uff0c\u6240\u4ee5\u4e00\u5171\u7ef4\u62a4 128 \u4e2a\u9690\u85cf\u72b6\u6001\uff0c\u6bcf\u4e2a\u9690\u85cf\u72b6\u6001\u7684\u7ef4\u5ea6\u662f 32\u3002</p> <p>\u8fd9\u91cc 4 \u5929\uff0c\u4ee3\u7801\u4e2d\u7684\u53d8\u91cf\u5b9a\u4e49\u4e3a <code>Water2sea_slice_num</code> \u5207\u7247\u6570\uff0c<code>batchsize</code> \u4e0d\u8bf4\u4e86\uff0c<code>self.hidden_size=32</code></p> <p>\u73b0\u5728\u770b\u5217\u9690\u85cf\u72b6\u6001\uff0c\u5f62\u72b6[128,32]\uff0c\u4e0e\u884c\u9690\u85cf\u72b6\u6001\u540c\u7406</p> <p>\u5176\u5b9e\u6211\u4ee5\u4e3a\u5217\u9690\u85cf\u72b6\u6001\u7ef4\u62a4\u7684\u662f\u5c0f\u65f6\u7684\uff0c24\u00d732</p> Python<pre><code>input_transfer = torch.zeros(Water2sea_slice_num, batch_size, Water2sea_slice_len, input_size).to(input.device)\n</code></pre> <p>\u4e0b\u4e00\u53e5\uff0c0 \u521d\u59cb\u5316\u8f93\u5165\u5f20\u91cf\uff0c\u8fd9\u4e2a\u5f20\u91cf\u7684\u5f62\u72b6\u662f[4,32,27,11]\uff0c4 \u662f 4 \u5929\uff0c32 \u4e2a\u6837\u672c\u6570\uff0c27 \u662f\u4e3a\u4e86\u8ba9\u65f6\u95f4\u70b9\u8fde\u7eed\uff0c\u4f5c\u8005\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u7684\u65b9\u5f0f\u6269\u5c55\u5e8f\u5217\u957f\u5ea6\uff0c\u8ba1\u7b97\u65b9\u5f0f\u662f\u524d\u9762\u90a3\u53e5 <code>Water2sea_slice_len = Water2sea_slice_num + Original_slice_len - 1</code>\u3002\u4f8b\u5982\uff0c<code>Water2sea_slice_len = 4 + 24 - 1 = 27</code></p> <p>\u6269\u5c55\u5e8f\u5217\u957f\u5ea6\u7684\u76ee\u7684\u662f \u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u4ea7\u751f\u91cd\u53e0\uff0c\u6355\u83b7\u65f6\u95f4\u5e8f\u5217\u7684\u8fde\u7eed\u6027\u3002</p> Python<pre><code>for r in range(Water2sea_slice_num):\n</code></pre> <p>\u63a5\u4e0b\u6765\u904d\u5386 4 \u5929</p> Python<pre><code>input_transfer[r, :, r:r+Original_slice_len, :] = input[r, :, :, :]\n</code></pre> <p>\u76ee\u7684\u662f\u4e3a\u4e86\u5c06\u539f\u59cb\u8f93\u5165\u586b\u5145\u5230\u6269\u5c55\u540e\u7684\u5f20\u91cf\u4e2d</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u539f\u59cb\u8f93\u5165 input \u7684\u5f62\u72b6\u4e3a <code>[4, 32, 24, 11]</code> \uff0c\u6269\u5c55\u5e8f\u5217\u8bb0\u4e3a  <code>input_transfer</code>  \uff0c\u5f62\u72b6\u4e3a <code>[4, 32, 27, 11]</code> \u7528 24 \u4e2a\u5c0f\u65f6\u7684\u6570\u636e\u586b\u5145\u8fd9\u4e2a 27\uff0c\u6bcf\u6b21\u632a\u52a8 r \u6b65\uff0c\u7528\u56fe\u8868\u793a\uff1a</p> Python<pre><code>input_transfer[0, :, :, :]\uff1a\n| H1 H2 H3 ... H24  0   0   0  |\ninput_transfer[1, :, :, :]\uff1a\n|  0  H1 H2 ... H24  0   0  |\ninput_transfer[2, :, :, :]\uff1a\n|  0   0  H1 ... H24   0  |\ninput_transfer[3, :, :, :]\uff1a\n|  0   0   0  H1 ... H24  |\n</code></pre> <p>\u539f\u59cb\u8f93\u5165\u7684\u5e8f\u5217\u957f\u5ea6\u4e3a 24\uff0c\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u586b\u5145\uff0c\u6269\u5c55\u4e3a 27\u3002</p> <p></p> <p>\u904d\u5386 r \u4e5f\u5c31\u662f\u5929\uff0c\u586b\u5145\u7684\u4f4d\u7f6e\u4ece r \u5f00\u59cb\uff0c\u5230 \u586b\u7d27\u968f\u5176\u540e\u7684 <code>Original_slice_len</code> \u539f\u59cb\u5207\u7247\u957f\u5ea6\u3002</p> \u518d\u8bf4\u4e00\u904d <p>&gt; \u4e5f\u5c31\u662f\u539f\u672c\u7684\u7b2c 1 \u5929\u4ece\u7b2c1 \u4e2a\u4f4d\u7f6e\u5f00\u59cb\uff0c\u7b2c 2\u5929\u4ece\u7b2c1 \u4e2a\u4f4d\u7f6e\u5f00\u59cb\uff0c\u7b2c 3\u5929\u4ece\u7b2c1 \u4e2a\u4f4d\u7f6e\u5f00\u59cb\uff0c\u7b2c 4\u5929\u4ece\u7b2c1 \u4e2a\u4f4d\u7f6e\u5f00\u59cb\uff0c\u6bcf\u5929\u6709 24 \u4e2a\u4f4d\u7f6e\uff0c\u73b0\u5728\u4e3a\u4e86\u65f6\u95f4\u8fde\u7eed\uff0c\u5bf9\u6bcf\u5929\u8fdb\u884c\u586b\u5145\uff0c\u586b\u5145\u540e\u7684\u7b2c\u4e00\u5929\u4ece\u7b2c1 \u4e2a\u4f4d\u7f6e\u5f00\u59cb\uff0c\u586b\u539f\u59cb\u7684 24 \u5c0f\u65f6\u6570\u636e\uff0c\u586b\u5145\u540e\u7684\u7b2c\u4e8c\u5929\u4ece\u7b2c 2 \u4e2a\u4f4d\u7f6e\u5f00\u59cb\uff0c\u586b\u539f\u6765\u7b2c\u4e8c\u5929\u7684 24 \u5c0f\u65f6\uff0c\u586b\u5145\u540e\u7684\u7b2c 3 \u5929\u4ece\u7b2c 3 \u4e2a\u4f4d\u7f6e\u5f00\u59cb\uff0c\u586b\u539f\u6765\u7b2c 3 \u5929\u7684 24 \u5c0f\u65f6\u6570\u636e\uff0c\u586b\u5145\u540e\u7684\u7b2c 4 \u5929\u4ece\u7b2c 4 \u4e2a\u4f4d\u5f00\u59cb\uff0c\u586b\u539f\u6765\u7684 24 \u5c0f\u65f6\u6570\u636e\uff0c\u5982\u679c\u662f\u5bf9\u5e94\u5230 python \u7684\u7d22\u5f15\uff0c\u5c31\u628a\u524d\u9762\u6240\u6709\u7b2c\u51cf\u53bb 1 \u5c31\u884c\u3002 </p> Python<pre><code>hidden_row_all_list = []   \nhidden_col_all_list = []   \n</code></pre> <p>\u63a5\u4e0b\u6765\u662f\u521d\u59cb\u5316\u884c\u9690\u85cf\u72b6\u6001\u5217\u8868\u548c\u5217\u9690\u85cf\u72b6\u6001\u5217\u8868</p> Python<pre><code>for layer in range(self.num_layers): \n</code></pre> <p>\u63a5\u4e0b\u6765\u5f00\u59cb \u904d\u5386  <code>self.num_layers = 3</code></p> <p>\u8bbe\u7f6e\u5c42\u6570=3\uff0c</p> Python<pre><code>if layer == 0:\n</code></pre> <p>\u904d\u5386\u5230\u7b2c\u4e00\u5c42\u65f6\uff0c</p> Python<pre><code>a = input_transfer.reshape(Water2sea_slice_num * batch_size, Water2sea_slice_len, input_size) \n</code></pre> <p>\u4f7f\u7528\u6269\u5c55\u540e\u7684\u8f93\u5165\u5f20\u91cf input_transfer \u4f5c\u4e3a\u8f93\u5165\uff0c \u8f93\u5165\u662f a\uff0c\u5f62\u72b6\u4e3a <code>[128, 27, 11]</code> \u5c06 4 \u5929\uff0c\u6bcf\u5929\u7684 32 \u4e2a\u6837\u672c\u5408\u5e76\uff0c\u6240\u4ee5\u662f 128 \u4e2a\u72b6\u6001\u9700\u8981\u66f4\u65b0\uff0c\u5d4c\u5165\u5230 hiddensize= 32 \u7ef4\u3002</p> <p>\u8f93\u5165 a \u7684\u5f62\u72b6 [128, 27, 11]\uff1a\u8868\u793a 128 \u4e2a\u6837\u672c\uff084 \u5929 \u00d7 \u6bcf\u5929 32 \u4e2a\u6837\u672c\uff09\u300127 \u4e2a\u65f6\u95f4\u6b65\u3001\u6bcf\u4e2a\u65f6\u95f4\u6b65 11 \u4e2a\u7279\u5f81\uff0c\u901a\u8fc7\u7ebf\u6027\u53d8\u6362\u5c06\u8f93\u5165\u7279\u5f81\uff0811 \u7ef4\uff09\u6620\u5c04\u5230\u9690\u85cf\u72b6\u6001\u7684\u7279\u5f81\u7a7a\u95f4\uff0832 \u7ef4\uff09\u3002\u5173\u4e8e\u8fd9\u4e2a a\u7684\u8be6\u7ec6\u5904\u7406\u540e\u9762\u4f1a\u8bf4\u3002</p> Python<pre><code>W = self.W_first_layer\n</code></pre> <p>\u7b2c\u4e00\u5c42\u7684\u6743\u91cd <code>W</code>\uff0c\u4f7f\u7528\u521d\u59cb\u5316\u7684\u6743\u91cd <code>self.W_first_layer</code>  \uff0c\u5b9a\u4e49\u5728 init</p> Python<pre><code>self.W_first_layer =  torch.nn.Parameter(torch.empty(6 * hidden_size, input_size + 2 * hidden_size))\n</code></pre> <p>\u8fd9\u4e2a\u6743\u91cd\u662f\u521d\u59cb\u5316\u4e86\u6240\u4ee5\u9700\u8981\u7684\u6743\u91cd\uff0c\u521d\u59cb\u5316\u6743\u91cd\u7684\u5f62\u72b6\u662f </p> <p><code>[6 * hidden_size, input_size + 2 * hidden_size]</code></p> <p>\u4e3a\u4ec0\u4e48\u662f\u8fd9\u4e2a\u5f62\u72b6\uff1f </p> <ul> <li><code>6 * hidden_size</code> \u8868\u793a\u6a21\u578b\u4e2d\u9700\u8981\u751f\u6210 6 \u4e2a\u95e8\u63a7\u4fe1\u53f7\u3001\u6bcf\u4e2a\u95e8\u7684\u5927\u5c0f\u4e3a hidden_size</li> <li><code>input_size + 2 * hidden_size</code> \u8868\u793a\u8f93\u5165\u7279\u5f81\u7684\u6570\u91cf\uff0c\u8f93\u5165\u7279\u5f81\u7531 3 \u4e2a\u90e8\u5206\u7ec4\u6210\uff1a\u2460input_size\uff1a\u5f53\u524d\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u7279\u5f81\u2461hidden_size\uff1a\u884c\u9690\u85cf\u72b6\u6001\uff08hidden_slice_row\uff09\u2462hidden_size\uff1a\u5217\u9690\u85cf\u72b6\u6001\uff08hidden_slice_col\uff09</li> </ul> <p>\u4e3a\u4ec0\u4e48\u662f 6 \u4e2a\u95e8\u5462\uff1f</p> <ul> <li>\u9996\u5148\uff0c\u6bcf\u4e2a\u95e8\u90fd\u8981\u7ef4\u62a4\u884c\u9690\u85cf\u72b6\u6001\u548c\u5217\u9690\u85cf\u72b6\u6001</li> <li>\u90a3\u4e00\u5171\u8981\u7ef4\u62a4 3 \u4e2a\u95e8\uff0c\u5206\u522b\u662f\u8f93\u5165\u95e8\u3001\u8f93\u51fa\u95e8\u3001\u66f4\u65b0\u95e8</li> <li>\u6240\u4ee5\u662f 6 \u4e2a\u95e8</li> </ul> <p>\u5177\u4f53\u6765\u8bf4 </p> <p>\u5177\u4f53\u6765\u8bf4</p> <p>\u66f4\u65b0\u95e8\uff08Update Gate\uff09</p> <ul> <li>\u7528\u4e8e\u63a7\u5236\u9690\u85cf\u72b6\u6001\u4e2d\u4fdd\u7559\u591a\u5c11\u6765\u81ea\u4e0a\u4e00\u65f6\u95f4\u6b65\uff0c\u591a\u5c11\u6765\u81ea\u5f53\u524d\u65f6\u95f4\u6b65\u7684\u8f93\u5165\uff1b</li> <li>\u5305\u62ec\uff1aupdate_gate_row\uff08\u884c\u65b9\u5411\u66f4\u65b0\u95e8\uff09\u3001update_gate_col\uff08\u5217\u65b9\u5411\u66f4\u65b0\u95e8\uff09</li> </ul> <p>\u8f93\u51fa\u95e8\uff08Output Gate\uff09\uff1a</p> <ul> <li>\u7528\u4e8e\u63a7\u5236\u9690\u85cf\u72b6\u6001\u7684\u8f93\u51fa\u5f3a\u5ea6\u3002</li> <li>\u5305\u62ec\uff1aoutput_gate_row\uff08\u884c\u65b9\u5411\u8f93\u51fa\u95e8\uff09\u3001output_gate_col\uff08\u5217\u65b9\u5411\u8f93\u51fa\u95e8\uff09</li> </ul> <p>\u8f93\u5165\u95e8\uff08Input Gate\uff09\uff1a</p> <ul> <li>\u7528\u4e8e\u751f\u6210\u9690\u85cf\u72b6\u6001\u7684\u5019\u9009\u503c\u3002</li> <li>\u5305\u62ec\uff1ainput_gate_row\uff08\u884c\u65b9\u5411\u8f93\u5165\u95e8\uff09\uff1binput_gate_col\uff08\u5217\u65b9\u5411\u8f93\u5165\u95e8\uff09\u3002</li> </ul> <p>\u603b\u5171\u9700\u8981\u751f\u6210 6 \u4e2a\u95e8\u7684\u4fe1\u53f7\uff0c\u56e0\u6b64\u8f93\u51fa\u7279\u5f81\u7684\u6570\u91cf\u4e3a <code>6 * hidden_size</code></p> <p>\u90a3\u8f93\u5165\u7279\u5f81\u7684\u5f62\u72b6 <code>input_size + 2 * hidden_size</code></p> <p>\u8868\u793a\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\uff0c\u6a21\u578b\u9700\u8981\u7ed3\u5408\u5f53\u524d\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u7279\u5f81\u548c\u9690\u85cf\u72b6\u6001\u6765\u751f\u6210\u95e8\u63a7\u4fe1\u53f7\u3002\u8f93\u5165\u7279\u5f81\u7684\u7ec4\u6210\u6709\uff1a</p> <ul> <li>**input_size\uff1a**\u5f53\u524d\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u7279\u5f81\uff1b</li> <li>hidden_size\uff08\u884c\u9690\u85cf\u72b6\u6001\uff09\uff1a\u8868\u793a\u4e0a\u4e00\u65f6\u95f4\u6b65\u7684\u884c\u9690\u85cf\u72b6\u6001\uff08hidden_slice_row\uff09\uff1b</li> <li>hidden_size\uff08\u5217\u9690\u85cf\u72b6\u6001\uff09\uff1a\u8868\u793a\u4e0a\u4e00\u65f6\u95f4\u6b65\u7684\u5217\u9690\u85cf\u72b6\u6001\uff08hidden_slice_col\uff09\uff1b </li> </ul> <p>\u56e0\u6b64\uff0c\u603b\u7684\u8f93\u5165\u7279\u5f81\u6570\u91cf\u4e3a input_size + 2 * hidden_size\u3002</p> <p>\u597d\uff0c\u4ee5\u4e0a\u5b8c\u6210\u4e86 \u7b2c\u4e00\u5c42\u65f6\uff0c\u600e\u4e48\u83b7\u5f97\u521d\u59cb\u5316\u7684\u72b6\u6001\u4e0e\u6743\u91cd</p> <p>\u4e5f\u5c31\u662f\u8fd9\u91cc\uff1a</p> Python<pre><code>if layer == 0:\n    '''\n    layer = 0 \u7b2c\u4e00\u5c42\u4f7f\u7528\u6269\u5c55\u540e\u7684\u8f93\u5165\u5f20\u91cf\u4f5c\u4e3a\u8f93\u5165\n    '''\n    a = input_transfer.reshape(Water2sea_slice_num * batch_size, Water2sea_slice_len, input_size) \n    '''\n        \u8f93\u5165\uff1aWater2sea_slice_num=4\uff0cbatch_size=32\uff0cWater2sea_slice_len27\uff0cinput_size=11\n        \u5904\u7406\uff1a.reshape\n        \u8f93\u51fa\uff1aa [128,27,11]\n    '''             \n    W = self.W_first_layer\n    '''\n        \u8f93\u5165\uff1aself.W_first_layer = torch.nn.Parameter(torch.empty(6 * hidden_size, input_size + 2 * hidden_size))\n\n            \u8f93\u5165 hidden_size=32\uff0cinput_size=11\n            \u5904\u7406\uff1atorch.nn.Parameter(torch.empty(\n            \u8f93\u51fa\uff1aself.W_first_layer [192,75]\n\n        \u8f93\u51fa\uff1aW = self.W_first_layer = [192,75]\n    '''\n</code></pre> <p>\u90a3\u5982\u679c\u4e0d\u662f\u7b2c\u4e00\u5c42\u5462\uff1f\u63a5\u4e0b\u6765\u770b else\uff1a</p> Python<pre><code>else:\n    a = F.dropout(output_all_slice, self.dropout, self.training)\n</code></pre> <p>\u8fd8\u662f\u5148\u5f97\u5230\u6bcf\u5c42\u7684\u8f93\u5165 a\uff0c\u6bd4\u5982\u7b2c\u4e8c\u5c42\u7684\u8f93\u5165\u4f1a\u63a5\u6536\u4e0a\u4e00\u5c42\u7684\u8f93\u51fa output_all_slice\uff0c\u5e76\u8fdb\u884c dropout \u9632\u6b62\u8fc7\u62df\u5408\u3002</p> <p>\u8fd9\u91cc\u6240\u6d89\u53ca\u7684\u6bcf\u4e2a\u8f93\u5165\u89e3\u91ca\uff1a</p> <p>\uff081\uff09\u5173\u4e8e\u8fd9\u4e2a <code>output_all_slice</code> \u5f62\u72b6\u662f <code>[128, 27, 64]</code></p> <p>\u8fd9\u91cc\u6d89\u53ca\u7684\u6bcf\u4e2a\u6570\u5b57\u7684\u89e3\u91ca</p> <ul> <li>128\uff1a\u603b\u6837\u672c\u6570\uff084 \u5929 \u00d7 \u6bcf\u5929 32 \u4e2a\u6837\u672c\uff09</li> <li>27\uff1a\u6269\u5c55\u540e\u7684\u65f6\u95f4\u6b65\u6570\u3002</li> <li>64\uff1a\u62fc\u63a5\u540e\u7684\u9690\u85cf\u72b6\u6001\u7279\u5f81\u7ef4\u5ea6\uff08<code>2 * hidden_size</code>\uff0c\u5373\u884c\u9690\u85cf\u72b6\u6001\u548c\u5217\u9690\u85cf\u72b6\u6001\u5404 32 \u7ef4\uff09</li> </ul> <p>\uff082\uff09\u7b2c\u4e8c\u4e2a\u8f93\u5165\uff1a<code>self.dropout</code></p> <ul> <li>Dropout \u7684\u6982\u7387\uff0c\u4f8b\u5982 0.05\uff0c\u8868\u793a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e2a\u795e\u7ecf\u5143\u6709 5% \u7684\u6982\u7387\u88ab\u968f\u673a\u7f6e\u4e3a 0\u3002</li> </ul> <p>\uff083\uff09\u7b2c\u4e09\u4e2a\u8f93\u5165\uff1aself.training\uff1a</p> <ul> <li>\u8868\u793a\u5f53\u524d\u662f\u5426\u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f\u3002</li> <li>\u5982\u679c\u4e3a True\uff0c\u5219\u6267\u884c Dropout \u64cd\u4f5c\uff1b\u5982\u679c\u4e3a False\uff08\u63a8\u7406\u6a21\u5f0f\uff09\uff0c\u5219\u4e0d\u6267\u884c Dropout\u3002</li> </ul> <p>\u8fd9\u53e5\u5c31\u662f \u5bf9\u4e0a\u4e00\u5c42\u7684\u8f93\u51fa <code>output_all_slice</code> \u8fdb\u884c Dropout \u64cd\u4f5c</p> <p>\u8f93\u5165 \u4e0a\u4e00\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\u4e3a <code>[128, 27, 64]</code>\uff0c<code>F.dropout</code>\u4e0d\u4f1a\u6539\u53d8\u5f62\u72b6\uff0c\u6240\u4ee5 \u8f93\u51fa\u5f62\u72b6 <code>a</code> \u7684\u5f62\u72b6\u4e5f\u662f <code>[128, 27, 64]</code></p> <p>\u8fd9\u91cc\u8f93\u5165\u7684\u542b\u4e49\uff0c\u8f93\u51fa\u7684\u542b\u4e49\uff0c\u6bcf\u4e2a\u6570\u5b57\u7684\u542b\u4e49\uff0c\u5904\u7406\u7684\u542b\u4e49\u90fd\u8bf4\u4e86\uff0c\u6e05\u6e05\u723d\u723d</p> <p>\u8fd9\u91cc\u7684 if-else \u662f\u5173\u4e8e\u6bcf\u5c42\u8f93\u5165 a\u548c\u6743\u91cd \u7684\u5904\u7406\uff0c</p> <p>\u9996\u5148\u5173\u4e8e\u8f93\u5165 a\uff1a\u5982\u679c\u662f\u7b2c\u4e00\u5c42\u7684 a \u5bf9\u539f\u59cb\u6269\u5c55\u8f93\u5165\u5f20\u91cf <code>input_transfer</code> reshape\u4e00\u4e0b\uff0c\u5982\u679c\u662f\u5176\u5b83\u5c42\u6bd4\u5982\u7b2c\u4e8c\u5c42\u7684\u8f93\u5165 a\uff0c\u5c31\u662f\u5bf9\u4e0a\u4e00\u5c42\u7684\u8f93\u51fa <code>output_all_slice</code> \u8fdb\u884c dropout\uff0c\u968f\u673a\u5931\u6d3b\u4e00\u90e8\u5206\u8f93\u5165\u8282\u70b9\uff0c\u540c\u65f6\u9700\u8981\u6ce8\u610f\u5982\u679c\u662f\u63a8\u7406\u6a21\u5f0f\u7684\u8bdd\uff0c\u4e0d\u8fdb\u884c dropout\uff0c\u8f93\u5165 a \u7684\u5f62\u72b6\uff0c\u5982\u679c\u662f\u7b2c\u4e00\u5c42 <code>[128,27,11]</code>\uff0c\u5982\u679c\u662f\u5176\u5b83\u5c42\u8f93\u5165a \u7684\u5f62\u72b6  <code>[128, 27, 64]</code></p> <p>\u6ce8\u610f\u533a\u5206\u8fd9\u91cc\u6bcf\u4e2a\u6570\u5b57\u7684\u542b\u4e49\uff1a</p> <ul> <li>128\uff1a\u603b\u6837\u672c\u6570\uff084 \u5929 \u00d7 \u6bcf\u5929 32 \u4e2a\u6837\u672c\uff09\uff0c\u5c06\u5929\u6570\u548c\u6279\u6b21\u5927\u5c0f\u5408\u5e76\u4e3a\u4e00\u4e2a\u7ef4\u5ea6\u3002</li> <li>27\uff1a\u6269\u5c55\u540e\u7684\u65f6\u95f4\u6b65\u6570\u3002</li> <li>11\uff1a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\u7ef4\u5ea6</li> <li>64\uff1a\u62fc\u63a5\u540e\u7684\u9690\u85cf\u72b6\u6001\u7279\u5f81\u7ef4\u5ea6\uff082 \u00d7 hidden_size\uff0c\u5373\u884c\u9690\u85cf\u72b6\u6001\u548c\u5217\u9690\u85cf\u72b6\u6001\u5404 32 \u7ef4\uff09\u3002</li> </ul> <p>\u8bf4\u53e5\u9898\u5916\u8bdd\uff0cRNN \u7684\u6807\u51c6\u8f93\u5165\u5c31\u662f <code>NTC</code>\uff0cN \u4e5f\u53ef\u4ee5\u8bb0\u4f5c B \u8868\u793a\u51e0\u4e2a\u6837\u672c\uff0cT \u8868\u793a\u4e00\u4e2a\u6837\u672c\u51e0\u4e2a\u65f6\u95f4\u6b65\uff0cC \u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\u6570\uff0c\u6807\u51c6\u8f93\u51fa\u662f\uff0c<code>[\u5c42\u6570\u00d7\u65b9\u5411,\u6837\u672c\u6570,\u9690\u85cf\u5c42\u7ef4\u5ea6]</code></p> <p>\u7ee7\u7eed\u770b else\uff0c\u8fd8\u6709\u6743\u91cd\u6ca1\u8bf4</p> Python<pre><code>if layer == 1:\n    layer0_output = a   # \u4fdd\u5b58\u7b2c\u4e00\u5c42\u7684\u8f93\u51fa\uff0c\u7528\u4e8e\u6b8b\u5dee\u8fde\u63a5\n    '''\n        \u8f93\u5165\uff1a\n            a [128, 27, 64]\uff08\u7b2c\u4e00\u5c42\u7684\u8f93\u51fa\uff09\n        \u5904\u7406\uff1a\n            \u5c06\u7b2c\u4e00\u5c42\u7684\u8f93\u51fa\u4fdd\u5b58\u5230 layer0_output \u4e2d\uff0c\u7528\u4e8e\u540e\u7eed\u5c42\u7684\u6b8b\u5dee\u8fde\u63a5\u3002\n        \u8f93\u51fa\uff1a\n            layer0_output [128, 27, 64]\n\n    '''\n</code></pre> <p>\u5982\u679c\u662f\u7b2c\u4e00\u5c42\u7684\u8bdd\uff0c\u8fd8\u8981\u4fdd\u5b58\u7b2c 0 \u5c42\u7684\u8f93\u51fa\uff0c\u7528\u4e8e\u540e\u7eed\u6b8b\u5dee\u8fde\u63a5\u7684\u5904\u7406</p> <p>\u8fd9\u91cc\u60f3\u8bf4\u7684\u662f</p> <ul> <li>\u7b2c index= 0 \u5c42\u7684\u8f93\u5165  <code>[128,27,11]</code> \uff0c\u7b2c 0 \u5c42\u7684\u8f93\u51fa\u53cd\u800c\u662f <code>[128, 27, 64]</code></li> <li>\u4eff\u7167 RNN \u7684\u7406\u89e3\uff0c\u539f\u59cb\u7684 [N,T,C]\uff0c\u7ecf\u8fc7 RNN \u8f93\u51fa\uff0c[N,T,HiddenDim]\uff0c\u5982\u679c\u5355\u72ec\u53d6\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u9690\u85cf\u72b6\u6001\u5c31\u662f [\u5c42\u6570\u00d7\u65b9\u5411,N,HiddenDim]</li> <li>\u8fd9\u91cc\u7684 64 \u662f\u884c\u9690\u85cf\u72b6\u6001(32)+\u5217\u9690\u85cf\u72b6\u6001(32)</li> </ul> <p>\u597d\uff0c\u4e0b\u4e00\u884c\uff1a</p> Python<pre><code> W = self.W_other_layer[layer-1, :, :]   # \u5176\u4ed6\u5c42\u7684\u6743\u91cd\u77e9\u9635\n        '''\n            \u8f93\u5165\uff1a\n                self.W_other_layer [2, 192, 128]\uff08\u5176\u4ed6\u5c42\u7684\u6743\u91cd\u77e9\u9635\uff0c\u5f62\u72b6\u4e3a [num_layers-1, 6 * hidden_size, 4 * hidden_size]\uff09\n                layer-1\uff08\u5f53\u524d\u5c42\u7684\u7d22\u5f15\u51cf 1\uff0c\u7528\u4e8e\u9009\u62e9\u5bf9\u5e94\u5c42\u7684\u6743\u91cd\u77e9\u9635\uff09\n            \u5904\u7406\uff1a\n                \u63d0\u53d6\u5f53\u524d\u5c42\u7684\u6743\u91cd\u77e9\u9635 W\u3002\n            \u8f93\u51fa\uff1a\n                W [192, 128]\uff08\u5f53\u524d\u5c42\u7684\u6743\u91cd\u77e9\u9635\uff09\n\n        '''\n</code></pre> <p>\u521d\u59cb\u5316\u6743\u91cd</p> <p>\u5148\u770b\u5176\u5b83\u5c42\u6743\u91cd\u77e9\u9635\u7684\u5b9a\u4e49\uff1a</p> Python<pre><code>self.W_other_layer = torch.nn.Parameter(torch.empty(num_layers - 1, 6 * hidden_size, 4 * hidden_size))\n</code></pre>"},{"location":"Reproduction/DAVE/","title":"DAVE\u590d\u73b0","text":""},{"location":"Reproduction/DAVE/#dave","title":"DAVE\u590d\u73b0","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 28 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"Reproduction/DAVE/#mainpy","title":"main.py","text":"<p>RuntimeError: stack expects each tensor to be equal size, but got [1, 400, 248] at entry 0 and [1, 512, 512] at entry 1</p>"},{"location":"Reproduction/CodeRepo/1_0_Autoformer/","title":"Autoformer","text":"In\u00a0[5]: Copied! <pre>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nimport warnings\n\n# \u5ffd\u7565\u8b66\u544a\nwarnings.filterwarnings('ignore')\n</pre> import torch import numpy as np import matplotlib.pyplot as plt import matplotlib.font_manager as fm import warnings  # \u5ffd\u7565\u8b66\u544a warnings.filterwarnings('ignore') In\u00a0[6]: Copied! <pre># \u8bbe\u7f6e\u5168\u5c40\u5b57\u4f53\u4e3a\u7cfb\u7edf\u4e2d\u7684\u4e2d\u6587\u5b57\u4f53\nfont_path = '/System/Library/Fonts/Supplemental/Songti.ttc'  # macOS \u4e2d\u7684\u5b57\u4f53\u8def\u5f84\nfont_prop = fm.FontProperties(fname=font_path)\nplt.rcParams['font.family'] = font_prop.get_name()\nplt.rcParams['axes.unicode_minus'] = False  # \u89e3\u51b3\u8d1f\u53f7\u663e\u793a\u95ee\u9898\n</pre> # \u8bbe\u7f6e\u5168\u5c40\u5b57\u4f53\u4e3a\u7cfb\u7edf\u4e2d\u7684\u4e2d\u6587\u5b57\u4f53 font_path = '/System/Library/Fonts/Supplemental/Songti.ttc'  # macOS \u4e2d\u7684\u5b57\u4f53\u8def\u5f84 font_prop = fm.FontProperties(fname=font_path) plt.rcParams['font.family'] = font_prop.get_name() plt.rcParams['axes.unicode_minus'] = False  # \u89e3\u51b3\u8d1f\u53f7\u663e\u793a\u95ee\u9898 In\u00a0[7]: Copied! <pre># \u8bbe\u7f6e\u53c2\u6570\nsample_rate = 100  # \u91c7\u6837\u7387100Hz\nduration = 1.0     # 1\u79d2\u4fe1\u53f7\nN = int(sample_rate * duration)  # \u6837\u672c\u70b9\u6570\nt = torch.linspace(0, duration, N)  # \u65f6\u95f4\u70b9\n\n# \u521b\u5efa\u4fe1\u53f7\uff1a10Hz\u548c20Hz\u7684\u6b63\u5f26\u6ce2\nfreq1, freq2 = 10, 20\namplitude1, amplitude2 = 1.0, 0.5\nsignal = amplitude1 * torch.sin(2 * np.pi * freq1 * t) + amplitude2 * torch.sin(2 * np.pi * freq2 * t)\n</pre> # \u8bbe\u7f6e\u53c2\u6570 sample_rate = 100  # \u91c7\u6837\u7387100Hz duration = 1.0     # 1\u79d2\u4fe1\u53f7 N = int(sample_rate * duration)  # \u6837\u672c\u70b9\u6570 t = torch.linspace(0, duration, N)  # \u65f6\u95f4\u70b9  # \u521b\u5efa\u4fe1\u53f7\uff1a10Hz\u548c20Hz\u7684\u6b63\u5f26\u6ce2 freq1, freq2 = 10, 20 amplitude1, amplitude2 = 1.0, 0.5 signal = amplitude1 * torch.sin(2 * np.pi * freq1 * t) + amplitude2 * torch.sin(2 * np.pi * freq2 * t) In\u00a0[8]: Copied! <pre># \u8ba1\u7b97FFT\nsignal_rfft = torch.fft.rfft(signal)\n</pre> # \u8ba1\u7b97FFT signal_rfft = torch.fft.rfft(signal) In\u00a0[11]: Copied! <pre># \u83b7\u53d6\u5e45\u5ea6\u8c31 - \u8fd9\u91cc\u4e58\u4ee52\u662f\u56e0\u4e3a\u80fd\u91cf\u5728\u6b63\u8d1f\u9891\u7387\u4e0a\u5206\u5e03\n# \u5bf9\u4e8erfft\uff0c\u6211\u4eec\u53ea\u770b\u5230\u6b63\u9891\u7387\u90e8\u5206\nmagnitude_spectrum = torch.abs(signal_rfft) * 2 / N  # \u5f52\u4e00\u5316\n# \u5bf9\u4e8e\u7b2c0\u4e2a\u548c\u7b2cN/2\u4e2a\u9891\u7387\u5206\u91cf\u4e0d\u9700\u8981\u4e58\u4ee52\nif N % 2 == 0:  # \u5982\u679cN\u662f\u5076\u6570\n    magnitude_spectrum[0] /= 2\n    magnitude_spectrum[-1] /= 2\nmagnitude_spectrum\n</pre> # \u83b7\u53d6\u5e45\u5ea6\u8c31 - \u8fd9\u91cc\u4e58\u4ee52\u662f\u56e0\u4e3a\u80fd\u91cf\u5728\u6b63\u8d1f\u9891\u7387\u4e0a\u5206\u5e03 # \u5bf9\u4e8erfft\uff0c\u6211\u4eec\u53ea\u770b\u5230\u6b63\u9891\u7387\u90e8\u5206 magnitude_spectrum = torch.abs(signal_rfft) * 2 / N  # \u5f52\u4e00\u5316 # \u5bf9\u4e8e\u7b2c0\u4e2a\u548c\u7b2cN/2\u4e2a\u9891\u7387\u5206\u91cf\u4e0d\u9700\u8981\u4e58\u4ee52 if N % 2 == 0:  # \u5982\u679cN\u662f\u5076\u6570     magnitude_spectrum[0] /= 2     magnitude_spectrum[-1] /= 2 magnitude_spectrum Out[11]: <pre>tensor([4.2915e-08, 2.3602e-03, 4.8474e-03, 7.6151e-03, 1.0882e-02, 1.5008e-02,\n        2.0674e-02, 2.9410e-02, 4.5613e-02, 8.9570e-02, 9.8378e-01, 1.0874e-01,\n        4.9075e-02, 2.9227e-02, 1.8140e-02, 9.8490e-03, 1.9463e-03, 7.6402e-03,\n        2.2964e-02, 6.0132e-02, 4.4995e-01, 1.3441e-01, 6.7800e-02, 4.8336e-02,\n        3.8852e-02, 3.3153e-02, 2.9309e-02, 2.6521e-02, 2.4397e-02, 2.2719e-02,\n        2.1359e-02, 2.0234e-02, 1.9289e-02, 1.8486e-02, 1.7797e-02, 1.7201e-02,\n        1.6684e-02, 1.6234e-02, 1.5841e-02, 1.5497e-02, 1.5198e-02, 1.4938e-02,\n        1.4714e-02, 1.4522e-02, 1.4360e-02, 1.4226e-02, 1.4118e-02, 1.4036e-02,\n        1.3978e-02, 1.3943e-02, 6.9658e-03])</pre> In\u00a0[10]: Copied! <pre># \u83b7\u53d6\u9891\u7387\u8f74\nfrequencies = torch.fft.rfftfreq(N, 1.0/sample_rate)\nfrequencies\n</pre> # \u83b7\u53d6\u9891\u7387\u8f74 frequencies = torch.fft.rfftfreq(N, 1.0/sample_rate) frequencies Out[10]: <pre>tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n        42., 43., 44., 45., 46., 47., 48., 49., 50.])</pre> In\u00a0[12]: Copied! <pre># \u8be6\u7ec6\u6253\u5370\u7ed3\u679c\nprint(f\"\u91c7\u6837\u7387: {sample_rate}Hz\")\nprint(f\"\u4fe1\u53f7\u957f\u5ea6: {N}\u70b9\")\nprint(f\"\u9891\u7387\u5206\u8fa8\u7387: {sample_rate/N}Hz\")\nprint(\"\\n\u524d25\u4e2a\u9891\u7387\u70b9\u53ca\u5176\u5e45\u5ea6:\")\nfor i in range(min(25, len(frequencies))):\n    print(f\"\u9891\u7387 {frequencies[i]:.1f}Hz: \u5e45\u5ea6 {magnitude_spectrum[i]:.4f}\")\n</pre> # \u8be6\u7ec6\u6253\u5370\u7ed3\u679c print(f\"\u91c7\u6837\u7387: {sample_rate}Hz\") print(f\"\u4fe1\u53f7\u957f\u5ea6: {N}\u70b9\") print(f\"\u9891\u7387\u5206\u8fa8\u7387: {sample_rate/N}Hz\") print(\"\\n\u524d25\u4e2a\u9891\u7387\u70b9\u53ca\u5176\u5e45\u5ea6:\") for i in range(min(25, len(frequencies))):     print(f\"\u9891\u7387 {frequencies[i]:.1f}Hz: \u5e45\u5ea6 {magnitude_spectrum[i]:.4f}\") <pre>\u91c7\u6837\u7387: 100Hz\n\u4fe1\u53f7\u957f\u5ea6: 100\u70b9\n\u9891\u7387\u5206\u8fa8\u7387: 1.0Hz\n\n\u524d25\u4e2a\u9891\u7387\u70b9\u53ca\u5176\u5e45\u5ea6:\n\u9891\u7387 0.0Hz: \u5e45\u5ea6 0.0000\n\u9891\u7387 1.0Hz: \u5e45\u5ea6 0.0024\n\u9891\u7387 2.0Hz: \u5e45\u5ea6 0.0048\n\u9891\u7387 3.0Hz: \u5e45\u5ea6 0.0076\n\u9891\u7387 4.0Hz: \u5e45\u5ea6 0.0109\n\u9891\u7387 5.0Hz: \u5e45\u5ea6 0.0150\n\u9891\u7387 6.0Hz: \u5e45\u5ea6 0.0207\n\u9891\u7387 7.0Hz: \u5e45\u5ea6 0.0294\n\u9891\u7387 8.0Hz: \u5e45\u5ea6 0.0456\n\u9891\u7387 9.0Hz: \u5e45\u5ea6 0.0896\n\u9891\u7387 10.0Hz: \u5e45\u5ea6 0.9838\n\u9891\u7387 11.0Hz: \u5e45\u5ea6 0.1087\n\u9891\u7387 12.0Hz: \u5e45\u5ea6 0.0491\n\u9891\u7387 13.0Hz: \u5e45\u5ea6 0.0292\n\u9891\u7387 14.0Hz: \u5e45\u5ea6 0.0181\n\u9891\u7387 15.0Hz: \u5e45\u5ea6 0.0098\n\u9891\u7387 16.0Hz: \u5e45\u5ea6 0.0019\n\u9891\u7387 17.0Hz: \u5e45\u5ea6 0.0076\n\u9891\u7387 18.0Hz: \u5e45\u5ea6 0.0230\n\u9891\u7387 19.0Hz: \u5e45\u5ea6 0.0601\n\u9891\u7387 20.0Hz: \u5e45\u5ea6 0.4500\n\u9891\u7387 21.0Hz: \u5e45\u5ea6 0.1344\n\u9891\u7387 22.0Hz: \u5e45\u5ea6 0.0678\n\u9891\u7387 23.0Hz: \u5e45\u5ea6 0.0483\n\u9891\u7387 24.0Hz: \u5e45\u5ea6 0.0389\n</pre> In\u00a0[13]: Copied! <pre># \u53ef\u89c6\u5316\u7ed3\u679c    \nplt.figure(figsize=(15, 10))\n\n# \u539f\u59cb\u4fe1\u53f7\nplt.subplot(3, 1, 1)\nplt.plot(t.numpy(), signal.numpy())\nplt.title('\u539f\u59cb\u4fe1\u53f7 - 10Hz (\u5e45\u5ea61.0) + 20Hz (\u5e45\u5ea60.5)\u7684\u6b63\u5f26\u6ce2 1*sin(2\u03c0*10*t) + 0.5*sin(2\u03c0*20*t)')\nplt.xlabel('\u65f6\u95f4 (\u79d2)')\nplt.ylabel('\u5e45\u5ea6')\nplt.grid(True)\n\n# \u9891\u8c31\u5e45\u5ea6 - \u7ebf\u6027\u523b\u5ea6\nplt.subplot(3, 1, 2)\nplt.plot(frequencies.numpy(), magnitude_spectrum.numpy())\nplt.title('\u9891\u8c31\u5e45\u5ea6 (\u7ebf\u6027\u523b\u5ea6)')\nplt.xlabel('\u9891\u7387 (Hz)')\nplt.ylabel('\u5e45\u5ea6')\nplt.grid(True)\n# \u6807\u6ce810Hz\u548c20Hz\u7684\u5cf0\u503c\nplt.axvline(x=10, color='r', linestyle='--', alpha=0.7)\nplt.axvline(x=20, color='g', linestyle='--', alpha=0.7)\nplt.text(10, 0.9, '10Hz', color='r')\nplt.text(20, 0.45, '20Hz', color='g')\n\n# \u9891\u8c31\u5e45\u5ea6 - \u5bf9\u6570\u523b\u5ea6\uff0c\u4fbf\u4e8e\u89c2\u5bdf\u5c0f\u5e45\u503c\nplt.subplot(3, 1, 3)\nplt.semilogy(frequencies.numpy(), magnitude_spectrum.numpy())\nplt.title('\u9891\u8c31\u5e45\u5ea6 (\u5bf9\u6570\u523b\u5ea6)')\nplt.xlabel('\u9891\u7387 (Hz)')\nplt.ylabel('\u5e45\u5ea6 (log)')\nplt.grid(True)\nplt.axvline(x=10, color='r', linestyle='--', alpha=0.7)\nplt.axvline(x=20, color='g', linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n# \u7406\u8bba\u9a8c\u8bc1 - \u91cd\u5efa\u4fe1\u53f7\n# \u521b\u5efa\u7406\u60f3\u9891\u8c31\nideal_spectrum = torch.zeros_like(signal_rfft)\nideal_spectrum[10] = amplitude1 * N / 2 * np.exp(-0.5j * np.pi)  # 10Hz, \u76f8\u4f4d\u4e3a-\u03c0/2\nideal_spectrum[20] = amplitude2 * N / 2 * np.exp(-0.5j * np.pi)  # 20Hz, \u76f8\u4f4d\u4e3a-\u03c0/2\n\n# \u9006\u53d8\u6362\u91cd\u5efa\nreconstructed = torch.fft.irfft(ideal_spectrum, n=N)\n\n# \u6bd4\u8f83\u539f\u59cb\u4fe1\u53f7\u548c\u91cd\u5efa\u4fe1\u53f7\nplt.figure(figsize=(12, 6))\nplt.plot(t.numpy(), signal.numpy(), 'b-', label='\u539f\u59cb\u4fe1\u53f7')\nplt.plot(t.numpy(), reconstructed.numpy(), 'r--', label='\u4ece\u9891\u8c31\u91cd\u5efa\u7684\u4fe1\u53f7')\nplt.title('\u539f\u59cb\u4fe1\u53f7\u4e0e\u91cd\u5efa\u4fe1\u53f7\u6bd4\u8f83')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# \u8ba1\u7b97\u91cd\u5efa\u8bef\u5dee\nerror = torch.max(torch.abs(signal - reconstructed))\nprint(f\"\\n\u91cd\u5efa\u8bef\u5dee(\u6700\u5927\u7edd\u5bf9\u5dee): {error:.10f}\")\n</pre> # \u53ef\u89c6\u5316\u7ed3\u679c     plt.figure(figsize=(15, 10))  # \u539f\u59cb\u4fe1\u53f7 plt.subplot(3, 1, 1) plt.plot(t.numpy(), signal.numpy()) plt.title('\u539f\u59cb\u4fe1\u53f7 - 10Hz (\u5e45\u5ea61.0) + 20Hz (\u5e45\u5ea60.5)\u7684\u6b63\u5f26\u6ce2 1*sin(2\u03c0*10*t) + 0.5*sin(2\u03c0*20*t)') plt.xlabel('\u65f6\u95f4 (\u79d2)') plt.ylabel('\u5e45\u5ea6') plt.grid(True)  # \u9891\u8c31\u5e45\u5ea6 - \u7ebf\u6027\u523b\u5ea6 plt.subplot(3, 1, 2) plt.plot(frequencies.numpy(), magnitude_spectrum.numpy()) plt.title('\u9891\u8c31\u5e45\u5ea6 (\u7ebf\u6027\u523b\u5ea6)') plt.xlabel('\u9891\u7387 (Hz)') plt.ylabel('\u5e45\u5ea6') plt.grid(True) # \u6807\u6ce810Hz\u548c20Hz\u7684\u5cf0\u503c plt.axvline(x=10, color='r', linestyle='--', alpha=0.7) plt.axvline(x=20, color='g', linestyle='--', alpha=0.7) plt.text(10, 0.9, '10Hz', color='r') plt.text(20, 0.45, '20Hz', color='g')  # \u9891\u8c31\u5e45\u5ea6 - \u5bf9\u6570\u523b\u5ea6\uff0c\u4fbf\u4e8e\u89c2\u5bdf\u5c0f\u5e45\u503c plt.subplot(3, 1, 3) plt.semilogy(frequencies.numpy(), magnitude_spectrum.numpy()) plt.title('\u9891\u8c31\u5e45\u5ea6 (\u5bf9\u6570\u523b\u5ea6)') plt.xlabel('\u9891\u7387 (Hz)') plt.ylabel('\u5e45\u5ea6 (log)') plt.grid(True) plt.axvline(x=10, color='r', linestyle='--', alpha=0.7) plt.axvline(x=20, color='g', linestyle='--', alpha=0.7)  plt.tight_layout() plt.show()  # \u7406\u8bba\u9a8c\u8bc1 - \u91cd\u5efa\u4fe1\u53f7 # \u521b\u5efa\u7406\u60f3\u9891\u8c31 ideal_spectrum = torch.zeros_like(signal_rfft) ideal_spectrum[10] = amplitude1 * N / 2 * np.exp(-0.5j * np.pi)  # 10Hz, \u76f8\u4f4d\u4e3a-\u03c0/2 ideal_spectrum[20] = amplitude2 * N / 2 * np.exp(-0.5j * np.pi)  # 20Hz, \u76f8\u4f4d\u4e3a-\u03c0/2  # \u9006\u53d8\u6362\u91cd\u5efa reconstructed = torch.fft.irfft(ideal_spectrum, n=N)  # \u6bd4\u8f83\u539f\u59cb\u4fe1\u53f7\u548c\u91cd\u5efa\u4fe1\u53f7 plt.figure(figsize=(12, 6)) plt.plot(t.numpy(), signal.numpy(), 'b-', label='\u539f\u59cb\u4fe1\u53f7') plt.plot(t.numpy(), reconstructed.numpy(), 'r--', label='\u4ece\u9891\u8c31\u91cd\u5efa\u7684\u4fe1\u53f7') plt.title('\u539f\u59cb\u4fe1\u53f7\u4e0e\u91cd\u5efa\u4fe1\u53f7\u6bd4\u8f83') plt.legend() plt.grid(True) plt.show()  # \u8ba1\u7b97\u91cd\u5efa\u8bef\u5dee error = torch.max(torch.abs(signal - reconstructed)) print(f\"\\n\u91cd\u5efa\u8bef\u5dee(\u6700\u5927\u7edd\u5bf9\u5dee): {error:.10f}\") <pre>Font 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n</pre> <pre>\u91cd\u5efa\u8bef\u5dee(\u6700\u5927\u7edd\u5bf9\u5dee): 1.0633112192\n</pre> In\u00a0[2]: Copied! <pre>from scipy.fft import fft\nfft([4,3,2,1])\n</pre> from scipy.fft import fft fft([4,3,2,1]) Out[2]: <pre>array([10.-0.j,  2.-2.j,  2.-0.j,  2.+2.j])</pre> <p>\u4e0a\u9762\u5b9e\u73b0\u4e86 \u8f93\u5165\u6570\u7ec4\u4e3a [4, 3, 2, 1]\uff0c\u957f\u5ea6\u4e3a 4\u3002\u5085\u91cc\u53f6\u53d8\u6362\u7684\u7ed3\u679c\u4e5f\u662f\u4e00\u4e2a\u957f\u5ea6\u4e3a 4 \u7684\u590d\u6570\u6570\u7ec4\u3002</p> <p>\u8ba1\u7b97\u516c\u5f0f\u4e3a\uff1a</p> <p>$ X_k = \\sum_{n=0}^{N-1} x_n \\cdot e^{-i \\cdot 2\\pi \\cdot k \\cdot n / N} $</p> <p>\u5176\u4e2d\uff1a</p> <p>$ X_k $ \u662f\u7b2c ( k ) \u4e2a\u9891\u7387\u5206\u91cf\u7684\u5085\u91cc\u53f6\u7cfb\u6570 $ x_n $ \u662f\u8f93\u5165\u4fe1\u53f7\u7684\u7b2c ( n ) \u4e2a\u6837\u672c $ N $ \u662f\u8f93\u5165\u4fe1\u53f7\u7684\u957f\u5ea6\uff08\u5728\u672c\u4f8b\u4e2d\u4e3a 4\uff09</p> <p>\u8ba1\u7b97\u6bcf\u4e2a  $X_k$ \uff1a</p> <p>$ X_0 $ :</p> <p>$ X_0 = 4 \\cdot e^{-i \\cdot 2\\pi \\cdot 0 \\cdot 0 / 4} + 3 \\cdot e^{-i \\cdot 2\\pi \\cdot 0 \\cdot 1 / 4} + 2 \\cdot e^{-i \\cdot 2\\pi \\cdot 0 \\cdot 2 / 4} + 1 \\cdot e^{-i \\cdot 2\\pi \\cdot 0 \\cdot 3 / 4} $</p> <p>$ X_0 = 4 + 3 + 2 + 1 = 10 $</p> <p>$ X_1 $:</p> <p>$  X_1 = 4 \\cdot e^{-i \\cdot 2\\pi \\cdot 1 \\cdot 0 / 4} + 3 \\cdot e^{-i \\cdot 2\\pi \\cdot 1 \\cdot 1 / 4} + 2 \\cdot e^{-i \\cdot 2\\pi \\cdot 1 \\cdot 2 / 4} + 1 \\cdot e^{-i \\cdot 2\\pi \\cdot 1 \\cdot 3 / 4} $</p> <p>$ X_1 = 4 + 3 \\cdot e^{-i \\cdot \\pi / 2} + 2 \\cdot e^{-i \\cdot \\pi} + 1 \\cdot e^{-i \\cdot 3\\pi / 2} $</p> <p>$ X_1 = 4 + 3 \\cdot (-i) + 2 \\cdot (-1) + 1 \\cdot i $</p> <p>$ X_1 = 4 - 2 - 2i $</p> <p>$ X_1 = 2 - 2i $ </p> In\u00a0[14]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nimport torch\nimport torch.nn.functional as F\n</pre> import numpy as np import matplotlib.pyplot as plt from scipy import signal import torch import torch.nn.functional as F In\u00a0[15]: Copied! <pre># \u521b\u5efa\u4e00\u4e2a\u6a21\u62df\u7684\u4e00\u5468\u7535\u529b\u9700\u6c42\u6570\u636e (\u6bcf\u5c0f\u65f6\u4e00\u4e2a\u70b9\uff0c\u51717*24=168\u4e2a\u70b9)\nhours = np.arange(168)\n# \u521b\u5efa\u957f\u671f\u8d8b\u52bf\ntrend = 100 + 0.05 * hours\n# \u521b\u5efa\u65e5\u5185\u53d8\u5316 (24\u5c0f\u65f6\u5468\u671f)\ndaily = 15 * np.sin(2*np.pi*hours/24 - np.pi/2)\n# \u521b\u5efa\u5de5\u4f5c\u65e5vs\u5468\u672b\u53d8\u5316 (\u4e00\u5468\u5468\u671f)\nweekly = np.zeros_like(hours)\nfor i in range(7):\n    if i &lt; 5:  # \u5de5\u4f5c\u65e5\n        weekly[i*24:(i+1)*24] = 10\n    else:      # \u5468\u672b\n        weekly[i*24:(i+1)*24] = -10\n# \u6dfb\u52a0\u4e00\u4e9b\u566a\u58f0\nnoise = 3 * np.random.randn(168)\n# \u5408\u6210\u6700\u7ec8\u65f6\u95f4\u5e8f\u5217\npower_demand = trend + daily + weekly + noise\n</pre> # \u521b\u5efa\u4e00\u4e2a\u6a21\u62df\u7684\u4e00\u5468\u7535\u529b\u9700\u6c42\u6570\u636e (\u6bcf\u5c0f\u65f6\u4e00\u4e2a\u70b9\uff0c\u51717*24=168\u4e2a\u70b9) hours = np.arange(168) # \u521b\u5efa\u957f\u671f\u8d8b\u52bf trend = 100 + 0.05 * hours # \u521b\u5efa\u65e5\u5185\u53d8\u5316 (24\u5c0f\u65f6\u5468\u671f) daily = 15 * np.sin(2*np.pi*hours/24 - np.pi/2) # \u521b\u5efa\u5de5\u4f5c\u65e5vs\u5468\u672b\u53d8\u5316 (\u4e00\u5468\u5468\u671f) weekly = np.zeros_like(hours) for i in range(7):     if i &lt; 5:  # \u5de5\u4f5c\u65e5         weekly[i*24:(i+1)*24] = 10     else:      # \u5468\u672b         weekly[i*24:(i+1)*24] = -10 # \u6dfb\u52a0\u4e00\u4e9b\u566a\u58f0 noise = 3 * np.random.randn(168) # \u5408\u6210\u6700\u7ec8\u65f6\u95f4\u5e8f\u5217 power_demand = trend + daily + weekly + noise <p>$trend = 100+0.05\\times t$  \u7ebf\u6027\u589e\u957f\u7684\u8d8b\u52bf\uff0c\u521d\u59cb\u503c\u4e3a 100\uff0c\u6bcf\u5c0f\u65f6\u589e\u52a0 0.05</p> <p>$daily = 15 \\sin(\\frac{2\\pi t}{24}-\\frac{\\pi}{2})$ 24 \u5c0f\u65f6\u5468\u671f\u7684\u6b63\u5f26\u6ce2\uff0c\u5e45\u5ea6\u4e3a 15\uff0c\u76f8\u4f4d\u504f\u79fb\u4e3a -\u03c0/2\u3002</p> <p>weekly \u8fd9\u662f\u4e00\u4e2a\u6bcf\u5468\u5468\u671f\u7684\u53d8\u5316\uff0c\u5de5\u4f5c\u65e5\u589e\u52a0 10\uff0c\u5468\u672b\u51cf\u5c11 10\u3002</p> <p>noise = 3 * np.random.randn(168) \u8fd9\u662f\u4e00\u4e2a\u5747\u503c\u4e3a 0\uff0c\u6807\u51c6\u5dee\u4e3a 3 \u7684\u9ad8\u65af\u566a\u58f0\u3002</p> In\u00a0[\u00a0]: Copied! <pre># \u6a21\u62dfAutoformer\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u51fd\u6570\ndef series_decomp(data, kernel_size=25):\n    # \u4f7f\u7528\u5377\u79ef\u5b9e\u73b0\u79fb\u52a8\u5e73\u5747\n    weights = torch.ones(kernel_size) / kernel_size\n    weights = weights.view(1, 1, -1).to(torch.float32)\n    data_pad = F.pad(torch.from_numpy(data).float().view(1, 1, -1), \n                    (kernel_size//2, kernel_size//2), mode='replicate')\n    trend = F.conv1d(data_pad, weights).view(-1).numpy()\n    seasonal = data - trend\n    return seasonal, trend\n\n# \u4f7f\u7528FFT\u5206\u6790\u5b63\u8282\u6027\u6210\u5206\u4e2d\u7684\u8c10\u6ce2\ndef analyze_harmonics(seasonal, sampling_rate=1):\n    # \u6267\u884cFFT\n    fft_result = np.fft.rfft(seasonal)\n    # \u8ba1\u7b97\u9891\u7387\n    freqs = np.fft.rfftfreq(len(seasonal), d=1/sampling_rate)\n    # \u8ba1\u7b97\u5e45\u5ea6\n    magnitudes = np.abs(fft_result) * 2 / len(seasonal)\n    # \u8ba1\u7b97\u76f8\u4f4d (\u8f6c\u6362\u4e3a\u5ea6)\n    phases = np.angle(fft_result) * 180 / np.pi\n    return freqs, magnitudes, phases\n\n# \u5206\u89e3\u65f6\u95f4\u5e8f\u5217\nseasonal, trend = series_decomp(power_demand)\n\n# \u5206\u6790\u8c10\u6ce2\nfreqs, magnitudes, phases = analyze_harmonics(seasonal)\n\n# \u627e\u51fa\u4e3b\u8981\u8c10\u6ce2 (\u5e45\u5ea6\u6700\u5927\u7684\u51e0\u4e2a)\nn_harmonics = 5\ntop_indices = np.argsort(magnitudes)[-n_harmonics:][::-1]\nmain_freqs = freqs[top_indices]\nmain_periods = 1/main_freqs[main_freqs &gt; 0]  # \u907f\u514d\u9664\u4ee5\u96f6\nmain_magnitudes = magnitudes[top_indices]\nmain_phases = phases[top_indices]\n\n# \u91cd\u6784\u4fe1\u53f7\uff0c\u4ec5\u4f7f\u7528\u4e3b\u8981\u8c10\u6ce2\nreconstructed_seasonal = np.zeros_like(seasonal)\nt = np.arange(len(seasonal))\nfor i, idx in enumerate(top_indices):\n    if freqs[idx] &gt; 0:  # \u8df3\u8fc7\u76f4\u6d41\u5206\u91cf\n        reconstructed_seasonal += main_magnitudes[i] * np.cos(2*np.pi*freqs[idx]*t + np.radians(main_phases[i]))\n\n# \u53ef\u89c6\u5316\nplt.figure(figsize=(18, 12))\n\n# \u539f\u59cb\u65f6\u95f4\u5e8f\u5217\nplt.subplot(3, 2, 1)\nplt.plot(hours, power_demand)\nplt.title('\u539f\u59cb\u7535\u529b\u9700\u6c42\u65f6\u95f4\u5e8f\u5217')\nplt.xlabel('\u5c0f\u65f6')\nplt.ylabel('\u529f\u7387 (MW)')\nplt.grid(True)\n\n# \u8d8b\u52bf\u548c\u5b63\u8282\u6027\u5206\u89e3\nplt.subplot(3, 2, 2)\nplt.plot(hours, trend, label='\u8d8b\u52bf')\nplt.plot(hours, seasonal, label='\u5b63\u8282\u6027')\nplt.title('\u65f6\u95f4\u5e8f\u5217\u5206\u89e3')\nplt.xlabel('\u5c0f\u65f6')\nplt.ylabel('\u529f\u7387 (MW)')\nplt.legend()\nplt.grid(True)\n\n# \u9891\u8c31\u5206\u6790\nplt.subplot(3, 2, 3)\nplt.stem(freqs[:50], magnitudes[:50])  # \u53ea\u663e\u793a\u524d50\u4e2a\u9891\u7387\nplt.title('\u5b63\u8282\u6027\u6210\u5206\u7684\u9891\u8c31')\nplt.xlabel('\u9891\u7387 (\u5468\u671f/\u5c0f\u65f6)')\nplt.ylabel('\u5e45\u5ea6')\nplt.grid(True)\n\n# \u76f8\u4f4d\u5206\u6790\nplt.subplot(3, 2, 4)\nplt.stem(freqs[:50], phases[:50])\nplt.title('\u5b63\u8282\u6027\u6210\u5206\u7684\u76f8\u4f4d\u8c31')\nplt.xlabel('\u9891\u7387 (\u5468\u671f/\u5c0f\u65f6)')\nplt.ylabel('\u76f8\u4f4d (\u5ea6)')\nplt.grid(True)\n\n# \u4e3b\u8981\u8c10\u6ce2\nplt.subplot(3, 2, 5)\nfor i, idx in enumerate(top_indices):\n    if freqs[idx] &gt; 0:  # \u8df3\u8fc7\u76f4\u6d41\u5206\u91cf\n        period = 1/freqs[idx]\n        plt.plot(hours, main_magnitudes[i] * np.cos(2*np.pi*freqs[idx]*t + np.radians(main_phases[i])),\n                 label=f'{period:.1f}\u5c0f\u65f6\u5468\u671f')\nplt.title('\u4e3b\u8981\u8c10\u6ce2')\nplt.xlabel('\u5c0f\u65f6')\nplt.ylabel('\u5e45\u5ea6')\nplt.legend()\nplt.grid(True)\n\n# \u539f\u59cb\u5b63\u8282\u6027\u4e0e\u91cd\u6784\u6bd4\u8f83\nplt.subplot(3, 2, 6)\nplt.plot(hours, seasonal, label='\u539f\u59cb\u5b63\u8282\u6027')\nplt.plot(hours, reconstructed_seasonal, label='\u8c10\u6ce2\u91cd\u6784', linestyle='--')\nplt.title('\u5b63\u8282\u6027\u6210\u5206\u4e0e\u8c10\u6ce2\u91cd\u6784\u6bd4\u8f83')\nplt.xlabel('\u5c0f\u65f6')\nplt.ylabel('\u5e45\u5ea6')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n# \u6253\u5370\u4e3b\u8981\u8c10\u6ce2\u4fe1\u606f\nprint(\"\u4e3b\u8981\u8c10\u6ce2:\")\nfor i, idx in enumerate(top_indices):\n    if freqs[idx] &gt; 0:\n        print(f\"- \u5468\u671f: {1/freqs[idx]:.1f}\u5c0f\u65f6, \u5e45\u5ea6: {main_magnitudes[i]:.2f}, \u76f8\u4f4d: {main_phases[i]:.1f}\u00b0\")\n</pre> # \u6a21\u62dfAutoformer\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u51fd\u6570 def series_decomp(data, kernel_size=25):     # \u4f7f\u7528\u5377\u79ef\u5b9e\u73b0\u79fb\u52a8\u5e73\u5747     weights = torch.ones(kernel_size) / kernel_size     weights = weights.view(1, 1, -1).to(torch.float32)     data_pad = F.pad(torch.from_numpy(data).float().view(1, 1, -1),                      (kernel_size//2, kernel_size//2), mode='replicate')     trend = F.conv1d(data_pad, weights).view(-1).numpy()     seasonal = data - trend     return seasonal, trend  # \u4f7f\u7528FFT\u5206\u6790\u5b63\u8282\u6027\u6210\u5206\u4e2d\u7684\u8c10\u6ce2 def analyze_harmonics(seasonal, sampling_rate=1):     # \u6267\u884cFFT     fft_result = np.fft.rfft(seasonal)     # \u8ba1\u7b97\u9891\u7387     freqs = np.fft.rfftfreq(len(seasonal), d=1/sampling_rate)     # \u8ba1\u7b97\u5e45\u5ea6     magnitudes = np.abs(fft_result) * 2 / len(seasonal)     # \u8ba1\u7b97\u76f8\u4f4d (\u8f6c\u6362\u4e3a\u5ea6)     phases = np.angle(fft_result) * 180 / np.pi     return freqs, magnitudes, phases  # \u5206\u89e3\u65f6\u95f4\u5e8f\u5217 seasonal, trend = series_decomp(power_demand)  # \u5206\u6790\u8c10\u6ce2 freqs, magnitudes, phases = analyze_harmonics(seasonal)  # \u627e\u51fa\u4e3b\u8981\u8c10\u6ce2 (\u5e45\u5ea6\u6700\u5927\u7684\u51e0\u4e2a) n_harmonics = 5 top_indices = np.argsort(magnitudes)[-n_harmonics:][::-1] main_freqs = freqs[top_indices] main_periods = 1/main_freqs[main_freqs &gt; 0]  # \u907f\u514d\u9664\u4ee5\u96f6 main_magnitudes = magnitudes[top_indices] main_phases = phases[top_indices]  # \u91cd\u6784\u4fe1\u53f7\uff0c\u4ec5\u4f7f\u7528\u4e3b\u8981\u8c10\u6ce2 reconstructed_seasonal = np.zeros_like(seasonal) t = np.arange(len(seasonal)) for i, idx in enumerate(top_indices):     if freqs[idx] &gt; 0:  # \u8df3\u8fc7\u76f4\u6d41\u5206\u91cf         reconstructed_seasonal += main_magnitudes[i] * np.cos(2*np.pi*freqs[idx]*t + np.radians(main_phases[i]))  # \u53ef\u89c6\u5316 plt.figure(figsize=(18, 12))  # \u539f\u59cb\u65f6\u95f4\u5e8f\u5217 plt.subplot(3, 2, 1) plt.plot(hours, power_demand) plt.title('\u539f\u59cb\u7535\u529b\u9700\u6c42\u65f6\u95f4\u5e8f\u5217') plt.xlabel('\u5c0f\u65f6') plt.ylabel('\u529f\u7387 (MW)') plt.grid(True)  # \u8d8b\u52bf\u548c\u5b63\u8282\u6027\u5206\u89e3 plt.subplot(3, 2, 2) plt.plot(hours, trend, label='\u8d8b\u52bf') plt.plot(hours, seasonal, label='\u5b63\u8282\u6027') plt.title('\u65f6\u95f4\u5e8f\u5217\u5206\u89e3') plt.xlabel('\u5c0f\u65f6') plt.ylabel('\u529f\u7387 (MW)') plt.legend() plt.grid(True)  # \u9891\u8c31\u5206\u6790 plt.subplot(3, 2, 3) plt.stem(freqs[:50], magnitudes[:50])  # \u53ea\u663e\u793a\u524d50\u4e2a\u9891\u7387 plt.title('\u5b63\u8282\u6027\u6210\u5206\u7684\u9891\u8c31') plt.xlabel('\u9891\u7387 (\u5468\u671f/\u5c0f\u65f6)') plt.ylabel('\u5e45\u5ea6') plt.grid(True)  # \u76f8\u4f4d\u5206\u6790 plt.subplot(3, 2, 4) plt.stem(freqs[:50], phases[:50]) plt.title('\u5b63\u8282\u6027\u6210\u5206\u7684\u76f8\u4f4d\u8c31') plt.xlabel('\u9891\u7387 (\u5468\u671f/\u5c0f\u65f6)') plt.ylabel('\u76f8\u4f4d (\u5ea6)') plt.grid(True)  # \u4e3b\u8981\u8c10\u6ce2 plt.subplot(3, 2, 5) for i, idx in enumerate(top_indices):     if freqs[idx] &gt; 0:  # \u8df3\u8fc7\u76f4\u6d41\u5206\u91cf         period = 1/freqs[idx]         plt.plot(hours, main_magnitudes[i] * np.cos(2*np.pi*freqs[idx]*t + np.radians(main_phases[i])),                  label=f'{period:.1f}\u5c0f\u65f6\u5468\u671f') plt.title('\u4e3b\u8981\u8c10\u6ce2') plt.xlabel('\u5c0f\u65f6') plt.ylabel('\u5e45\u5ea6') plt.legend() plt.grid(True)  # \u539f\u59cb\u5b63\u8282\u6027\u4e0e\u91cd\u6784\u6bd4\u8f83 plt.subplot(3, 2, 6) plt.plot(hours, seasonal, label='\u539f\u59cb\u5b63\u8282\u6027') plt.plot(hours, reconstructed_seasonal, label='\u8c10\u6ce2\u91cd\u6784', linestyle='--') plt.title('\u5b63\u8282\u6027\u6210\u5206\u4e0e\u8c10\u6ce2\u91cd\u6784\u6bd4\u8f83') plt.xlabel('\u5c0f\u65f6') plt.ylabel('\u5e45\u5ea6') plt.legend() plt.grid(True)  plt.tight_layout() plt.show()  # \u6253\u5370\u4e3b\u8981\u8c10\u6ce2\u4fe1\u606f print(\"\u4e3b\u8981\u8c10\u6ce2:\") for i, idx in enumerate(top_indices):     if freqs[idx] &gt; 0:         print(f\"- \u5468\u671f: {1/freqs[idx]:.1f}\u5c0f\u65f6, \u5e45\u5ea6: {main_magnitudes[i]:.2f}, \u76f8\u4f4d: {main_phases[i]:.1f}\u00b0\") <pre>\u4e3b\u8981\u8c10\u6ce2:\n- \u5468\u671f: 24.0\u5c0f\u65f6, \u5e45\u5ea6: 15.27, \u76f8\u4f4d: 175.7\u00b0\n- \u5468\u671f: 28.0\u5c0f\u65f6, \u5e45\u5ea6: 1.74, \u76f8\u4f4d: -5.5\u00b0\n- \u5468\u671f: 56.0\u5c0f\u65f6, \u5e45\u5ea6: 1.29, \u76f8\u4f4d: 19.1\u00b0\n- \u5468\u671f: 12.9\u5c0f\u65f6, \u5e45\u5ea6: 1.12, \u76f8\u4f4d: 32.7\u00b0\n- \u5468\u671f: 9.9\u5c0f\u65f6, \u5e45\u5ea6: 1.10, \u76f8\u4f4d: 25.4\u00b0\n</pre> In\u00a0[17]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.colors as colors\n\n# \u8bbe\u7f6e\u4e2d\u6587\u663e\u793a\nfont_path = '/System/Library/Fonts/Supplemental/Songti.ttc'  # macOS \u4e2d\u7684\u5b8b\u4f53\u5b57\u4f53\nchinese_font = FontProperties(fname=font_path)\nplt.rcParams['axes.unicode_minus'] = False  # \u89e3\u51b3\u8d1f\u53f7\u663e\u793a\u95ee\u9898\n\n# \u53c2\u6570\u8bbe\u7f6e\nT = 6  # \u5468\u671f\nomega = (2 * np.pi) / T  # \u89d2\u9891\u7387\nn = 2  # \u5468\u671f\u4e2a\u6570\nt = np.arange(0, n * T + 0.1, 0.1)  # \u65f6\u95f4\u5e8f\u5217\uff0c\u4ece0\u5230n*T\uff0c\u6b65\u957f\u4e3a0.1\n\n# \u8ba1\u7b97\u590d\u6307\u6570\u4fe1\u53f7\nf = np.exp(1j * omega * t)\nreal_part = np.real(f)  # \u5b9e\u90e8\nimag_part = np.imag(f)  # \u865a\u90e8\n\n# \u521b\u5efa\u4e09\u7ef4\u56fe\u50cf\nfig = plt.figure(figsize=(20, 16))\nax = fig.add_subplot(111, projection='3d')\n\n# \u7ed8\u5236\u4e09\u7ef4\u66f2\u7ebf\nspiral, = ax.plot(t, imag_part, real_part, linewidth=3, color='blue', label='\u590d\u6307\u6570\u4fe1\u53f7')\n\n# \u521b\u5efa\u6295\u5f71\u5e73\u9762\n# xy\u5e73\u9762 (z=0)\nmax_t = n * T\nxy_x, xy_y = np.meshgrid(np.linspace(0, max_t, 20), np.linspace(-1.5, 1.5, 20))\nxy_z = np.zeros_like(xy_x)\nxy_plane = ax.plot_surface(xy_x, xy_y, xy_z, alpha=0.2, color='lightblue', label='xy\u5e73\u9762')\n\n# xz\u5e73\u9762 (y=0)\nxz_x, xz_z = np.meshgrid(np.linspace(0, max_t, 20), np.linspace(-1.5, 1.5, 20))\nxz_y = np.zeros_like(xz_x)\nxz_plane = ax.plot_surface(xz_x, xz_y, xz_z, alpha=0.2, color='lightgreen', label='xz\u5e73\u9762')\n\n# yz\u5e73\u9762 (x=0)\nyz_y, yz_z = np.meshgrid(np.linspace(-1.5, 1.5, 20), np.linspace(-1.5, 1.5, 20))\nyz_x = np.zeros_like(yz_y)\nyz_plane = ax.plot_surface(yz_x, yz_y, yz_z, alpha=0.2, color='lightyellow', label='yz\u5e73\u9762')\n\n# \u7ed8\u5236\u6295\u5f71\u66f2\u7ebf\nxy_proj, = ax.plot(t, imag_part, np.zeros_like(t), 'g--', linewidth=2, label='xy\u5e73\u9762\u6295\u5f71')\nxz_proj, = ax.plot(t, np.zeros_like(t), real_part, 'r--', linewidth=2, label='xz\u5e73\u9762\u6295\u5f71')\nyz_proj, = ax.plot(np.zeros_like(t), imag_part, real_part, 'm--', linewidth=2, label='yz\u5e73\u9762\u6295\u5f71')\n\n# \u7ed8\u5236\u5355\u4f4d\u5706\ntheta = np.linspace(0, 2*np.pi, 100)\ny_circle = np.sin(theta)\nz_circle = np.cos(theta)\nt_circle = np.zeros_like(theta)\nunit_circle, = ax.plot(t_circle, y_circle, z_circle, 'k-', linewidth=2, label='\u5355\u4f4d\u5706')\n\n# \u6dfb\u52a0\u9634\u5f71\u6548\u679c\n# \u9009\u62e9\u51e0\u4e2a\u5173\u952e\u70b9\u6765\u753b\u9634\u5f71\nshadow_indices = np.arange(0, len(t), 10)  # \u6bcf10\u4e2a\u70b9\u53d6\u4e00\u4e2a\nfor i in shadow_indices:\n    # \u4ece\u590d\u5e73\u9762\u5230\u65f6\u95f4\u8f74\u7684\u7ad6\u7ebf\n    ax.plot([0, t[i]], [0, 0], [0, 0], 'k:', alpha=0.3)\n    \n    # \u4ece\u65f6\u95f4\u8f74\u5230xy\u6295\u5f71\u7684\u7ebf\n    ax.plot([t[i], t[i]], [0, imag_part[i]], [0, 0], 'g:', alpha=0.6)\n    \n    # \u4ece\u65f6\u95f4\u8f74\u5230xz\u6295\u5f71\u7684\u7ebf\n    ax.plot([t[i], t[i]], [0, 0], [0, real_part[i]], 'r:', alpha=0.6)\n    \n    # \u4ece\u6295\u5f71\u70b9\u5230\u7a7a\u95f4\u66f2\u7ebf\u7684\u8fde\u7ebf\n    ax.plot([t[i], t[i]], [imag_part[i], imag_part[i]], [0, real_part[i]], 'b-', alpha=0.4)\n    ax.plot([t[i], t[i]], [0, imag_part[i]], [real_part[i], real_part[i]], 'b-', alpha=0.4)\n    \n    # \u57280\u70b9\u5904\u753b\u4e00\u4e2a\u5230\u5f53\u524d\u70b9\u7684\u6247\u5f62\u9634\u5f71\n    if i &gt; 0:\n        # \u4ece\u539f\u70b9\u5230\u590d\u5e73\u9762\u4e0a\u7684\u70b9\u7684\u6247\u5f62\n        angle = np.linspace(0, omega * t[i], 20)\n        x_fan = np.zeros_like(angle)\n        y_fan = np.sin(angle)\n        z_fan = np.cos(angle)\n        ax.plot(x_fan, y_fan, z_fan, 'r-', alpha=0.3)\n        \n        # \u586b\u5145\u6247\u5f62\u533a\u57df\n        ax.plot_surface(\n            np.outer(x_fan, np.ones(2)),\n            np.outer(y_fan, np.linspace(0, 1, 2)),\n            np.outer(z_fan, np.linspace(0, 1, 2)),\n            color='yellow', alpha=0.1\n        )\n\n# \u6807\u8bb0\u7279\u6b8a\u70b9\nspecial_times = [0, T/4, T/2, 3*T/4, T]\nfor st in special_times:\n    idx = np.argmin(np.abs(t - st))\n    ax.scatter([t[idx]], [imag_part[idx]], [real_part[idx]], color='red', s=100, label=f't={st}' if st == 0 else \"\")\n    ax.text(t[idx]+0.2, imag_part[idx], real_part[idx], f't={st}', fontsize=12)\n\n# \u8bbe\u7f6e\u5750\u6807\u8f74\u6807\u7b7e\nax.set_xlabel('x\u8f74\uff1a\u65f6\u95f4 t', fontproperties=chinese_font, fontsize=14)\nax.set_ylabel('y \u8f74\uff1a\u865a\u90e8 Im(f) sin(1*omega*t)', fontproperties=chinese_font, fontsize=14)\nax.set_zlabel('z \u8f74\uff1a\u5b9e\u90e8 Re(f) cos(1*omega*t)', fontproperties=chinese_font, fontsize=14)\n\n# \u8bbe\u7f6e\u5750\u6807\u8f74\u8303\u56f4\nax.set_xlim(0, max_t)\nax.set_ylim(-1.5, 1.5)\nax.set_zlim(-1.5, 1.5)\n\n# \u6dfb\u52a0\u7f51\u683c\nax.grid(True)\n\n# \u8bbe\u7f6e\u6807\u9898\nax.set_title(f'\u590d\u6307\u6570\u4fe1\u53f7 $f=e^{{i\\\\omega t}}$ \u7684\u4e09\u7ef4\u53ef\u89c6\u5316\uff0c\u5468\u671fT={T}\uff0cn={n}\u4e2a\u5468\u671f',\n            fontproperties=chinese_font, fontsize=16)\n\n# \u6dfb\u52a00\u70b9\u6807\u8bb0\nax.scatter([0], [0], [0], color='black', s=100, marker='o')\nax.text(0.2, 0, 0, '\u539f\u70b9', fontsize=12, fontproperties=chinese_font)\n\n# \u6dfb\u52a0\u56fe\u4f8b\n# ax.legend(loc='upper right', prop=chinese_font)  # \u56fe\u4f8b\u592a\u591a\u53ef\u80fd\u4f1a\u6321\u4f4f\u56fe\u50cf\n\n# \u6dfb\u52a0\u6570\u5b66\u516c\u5f0f\u8bf4\u660e\nformula_text = (\n    f\"\u590d\u6307\u6570\u4fe1\u53f7: $f = e^{{i\\\\omega t}}$\uff0c\u5176\u4e2d $\\\\omega = \\\\frac{{2\\\\pi}}{{T}} = \\\\frac{{2\\\\pi}}{{{T}}}$\\n\"\n    f\"\u5b9e\u90e8: $\\\\cos(\\\\omega t)$\uff0c\u865a\u90e8: $\\\\sin(\\\\omega t)$\\n\"\n    f\"\u5468\u671f: T = {T}\uff0c\u603b\u65f6\u95f4: {n*T}\"\n)\nfig.text(0.5, 0.02, formula_text, ha='center', fontproperties=chinese_font, fontsize=14)\n\n# \u8bbe\u7f6e\u66f4\u597d\u7684\u89c6\u89d2\nax.view_init(elev=25, azim=40)\n\n# \u8c03\u6574\u56fe\u5f62\u5e03\u5c40\nplt.tight_layout(rect=[0, 0.05, 1, 0.95])\nplt.show()\n\n# \u7ed8\u5236\u5e73\u9762\u6295\u5f71\u7684\u8be6\u7ec6\u89c6\u56fe\nplt.figure(figsize=(18, 12))\n\n# 1. \u65f6\u95f4\u57df\u4fe1\u53f7\nplt.subplot(2, 2, 1)\nplt.plot(t, real_part, 'b-', label=r'$\\cos(\\omega t)$ (\u5b9e\u90e8)')\nplt.plot(t, imag_part, 'r-', label=r'$\\sin(\\omega t)$ (\u865a\u90e8)')\nplt.grid(True)\nplt.legend(prop=chinese_font)\nplt.title('\u590d\u6307\u6570\u4fe1\u53f7\u7684\u5b9e\u90e8\u548c\u865a\u90e8', fontproperties=chinese_font)\nplt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font)\nplt.ylabel('\u5e45\u5ea6', fontproperties=chinese_font)\n\n# 2. \u590d\u5e73\u9762\u4e0a\u7684\u8f68\u8ff9\nplt.subplot(2, 2, 2)\nplt.plot(real_part, imag_part, 'g-')\nplt.grid(True)\nplt.title('\u590d\u5e73\u9762\u8f68\u8ff9 (\u5355\u4f4d\u5706)', fontproperties=chinese_font)\nplt.xlabel('\u5b9e\u90e8', fontproperties=chinese_font)\nplt.ylabel('\u865a\u90e8', fontproperties=chinese_font)\nplt.axis('equal')  # \u4fdd\u6301\u5750\u6807\u8f74\u6bd4\u4f8b\u4e00\u81f4\n\n# \u6dfb\u52a0\u9634\u5f71\u6247\u533a\nfor st in special_times:\n    idx = np.argmin(np.abs(t - st))\n    angle = np.linspace(0, omega * t[idx], 100)\n    x_fan = np.cos(angle)\n    y_fan = np.sin(angle)\n    plt.fill(x_fan, y_fan, 'yellow', alpha=0.1)\n    plt.plot(x_fan, y_fan, 'k--', alpha=0.3)\n    \n# \u6807\u8bb0\u7279\u6b8a\u70b9\nfor st in special_times:\n    idx = np.argmin(np.abs(t - st))\n    plt.plot(real_part[idx], imag_part[idx], 'ro')\n    plt.annotate(f't = {st}', \n                xy=(real_part[idx], imag_part[idx]),\n                xytext=(real_part[idx]*1.2, imag_part[idx]*1.2),\n                fontproperties=chinese_font,\n                fontsize=10)\n\n# 3. \u4e09\u7ef4\u87ba\u65cb\u7684\u4fef\u89c6\u56fe\nplt.subplot(2, 2, 3)\nplt.plot(t, imag_part, 'g-')\nplt.grid(True)\nplt.title('\u4e09\u7ef4\u87ba\u65cb\u7684\u4fef\u89c6\u56fe (t-\u865a\u90e8 \u5e73\u9762)', fontproperties=chinese_font)\nplt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font)\nplt.ylabel('\u865a\u90e8', fontproperties=chinese_font)\n\n# \u6dfb\u52a0\u4ece\u65f6\u95f4\u8f74\u5230\u66f2\u7ebf\u7684\u5782\u7ebf\u9634\u5f71\nshadow_indices = np.arange(0, len(t), 20)\nfor i in shadow_indices:\n    plt.plot([t[i], t[i]], [0, imag_part[i]], 'k:', alpha=0.5)\n    \n# \u6807\u8bb0\u7279\u6b8a\u70b9\nfor st in special_times:\n    idx = np.argmin(np.abs(t - st))\n    plt.plot(t[idx], imag_part[idx], 'ro')\n    plt.annotate(f't = {st}', \n                xy=(t[idx], imag_part[idx]),\n                xytext=(t[idx]+0.2, imag_part[idx]+0.1),\n                fontproperties=chinese_font,\n                fontsize=10)\n\n# 4. \u4e09\u7ef4\u87ba\u65cb\u7684\u4fa7\u89c6\u56fe\nplt.subplot(2, 2, 4)\nplt.plot(t, real_part, 'r-')\nplt.grid(True)\nplt.title('\u4e09\u7ef4\u87ba\u65cb\u7684\u4fa7\u89c6\u56fe (t-\u5b9e\u90e8 \u5e73\u9762)', fontproperties=chinese_font)\nplt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font)\nplt.ylabel('\u5b9e\u90e8', fontproperties=chinese_font)\n\n# \u6dfb\u52a0\u4ece\u65f6\u95f4\u8f74\u5230\u66f2\u7ebf\u7684\u5782\u7ebf\u9634\u5f71\nfor i in shadow_indices:\n    plt.plot([t[i], t[i]], [0, real_part[i]], 'k:', alpha=0.5)\n    \n# \u6807\u8bb0\u7279\u6b8a\u70b9\nfor st in special_times:\n    idx = np.argmin(np.abs(t - st))\n    plt.plot(t[idx], real_part[idx], 'ro')\n    plt.annotate(f't = {st}', \n                xy=(t[idx], real_part[idx]),\n                xytext=(t[idx]+0.2, real_part[idx]+0.1),\n                fontproperties=chinese_font,\n                fontsize=10)\n\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from matplotlib.font_manager import FontProperties from mpl_toolkits.mplot3d import Axes3D import matplotlib.colors as colors  # \u8bbe\u7f6e\u4e2d\u6587\u663e\u793a font_path = '/System/Library/Fonts/Supplemental/Songti.ttc'  # macOS \u4e2d\u7684\u5b8b\u4f53\u5b57\u4f53 chinese_font = FontProperties(fname=font_path) plt.rcParams['axes.unicode_minus'] = False  # \u89e3\u51b3\u8d1f\u53f7\u663e\u793a\u95ee\u9898  # \u53c2\u6570\u8bbe\u7f6e T = 6  # \u5468\u671f omega = (2 * np.pi) / T  # \u89d2\u9891\u7387 n = 2  # \u5468\u671f\u4e2a\u6570 t = np.arange(0, n * T + 0.1, 0.1)  # \u65f6\u95f4\u5e8f\u5217\uff0c\u4ece0\u5230n*T\uff0c\u6b65\u957f\u4e3a0.1  # \u8ba1\u7b97\u590d\u6307\u6570\u4fe1\u53f7 f = np.exp(1j * omega * t) real_part = np.real(f)  # \u5b9e\u90e8 imag_part = np.imag(f)  # \u865a\u90e8  # \u521b\u5efa\u4e09\u7ef4\u56fe\u50cf fig = plt.figure(figsize=(20, 16)) ax = fig.add_subplot(111, projection='3d')  # \u7ed8\u5236\u4e09\u7ef4\u66f2\u7ebf spiral, = ax.plot(t, imag_part, real_part, linewidth=3, color='blue', label='\u590d\u6307\u6570\u4fe1\u53f7')  # \u521b\u5efa\u6295\u5f71\u5e73\u9762 # xy\u5e73\u9762 (z=0) max_t = n * T xy_x, xy_y = np.meshgrid(np.linspace(0, max_t, 20), np.linspace(-1.5, 1.5, 20)) xy_z = np.zeros_like(xy_x) xy_plane = ax.plot_surface(xy_x, xy_y, xy_z, alpha=0.2, color='lightblue', label='xy\u5e73\u9762')  # xz\u5e73\u9762 (y=0) xz_x, xz_z = np.meshgrid(np.linspace(0, max_t, 20), np.linspace(-1.5, 1.5, 20)) xz_y = np.zeros_like(xz_x) xz_plane = ax.plot_surface(xz_x, xz_y, xz_z, alpha=0.2, color='lightgreen', label='xz\u5e73\u9762')  # yz\u5e73\u9762 (x=0) yz_y, yz_z = np.meshgrid(np.linspace(-1.5, 1.5, 20), np.linspace(-1.5, 1.5, 20)) yz_x = np.zeros_like(yz_y) yz_plane = ax.plot_surface(yz_x, yz_y, yz_z, alpha=0.2, color='lightyellow', label='yz\u5e73\u9762')  # \u7ed8\u5236\u6295\u5f71\u66f2\u7ebf xy_proj, = ax.plot(t, imag_part, np.zeros_like(t), 'g--', linewidth=2, label='xy\u5e73\u9762\u6295\u5f71') xz_proj, = ax.plot(t, np.zeros_like(t), real_part, 'r--', linewidth=2, label='xz\u5e73\u9762\u6295\u5f71') yz_proj, = ax.plot(np.zeros_like(t), imag_part, real_part, 'm--', linewidth=2, label='yz\u5e73\u9762\u6295\u5f71')  # \u7ed8\u5236\u5355\u4f4d\u5706 theta = np.linspace(0, 2*np.pi, 100) y_circle = np.sin(theta) z_circle = np.cos(theta) t_circle = np.zeros_like(theta) unit_circle, = ax.plot(t_circle, y_circle, z_circle, 'k-', linewidth=2, label='\u5355\u4f4d\u5706')  # \u6dfb\u52a0\u9634\u5f71\u6548\u679c # \u9009\u62e9\u51e0\u4e2a\u5173\u952e\u70b9\u6765\u753b\u9634\u5f71 shadow_indices = np.arange(0, len(t), 10)  # \u6bcf10\u4e2a\u70b9\u53d6\u4e00\u4e2a for i in shadow_indices:     # \u4ece\u590d\u5e73\u9762\u5230\u65f6\u95f4\u8f74\u7684\u7ad6\u7ebf     ax.plot([0, t[i]], [0, 0], [0, 0], 'k:', alpha=0.3)          # \u4ece\u65f6\u95f4\u8f74\u5230xy\u6295\u5f71\u7684\u7ebf     ax.plot([t[i], t[i]], [0, imag_part[i]], [0, 0], 'g:', alpha=0.6)          # \u4ece\u65f6\u95f4\u8f74\u5230xz\u6295\u5f71\u7684\u7ebf     ax.plot([t[i], t[i]], [0, 0], [0, real_part[i]], 'r:', alpha=0.6)          # \u4ece\u6295\u5f71\u70b9\u5230\u7a7a\u95f4\u66f2\u7ebf\u7684\u8fde\u7ebf     ax.plot([t[i], t[i]], [imag_part[i], imag_part[i]], [0, real_part[i]], 'b-', alpha=0.4)     ax.plot([t[i], t[i]], [0, imag_part[i]], [real_part[i], real_part[i]], 'b-', alpha=0.4)          # \u57280\u70b9\u5904\u753b\u4e00\u4e2a\u5230\u5f53\u524d\u70b9\u7684\u6247\u5f62\u9634\u5f71     if i &gt; 0:         # \u4ece\u539f\u70b9\u5230\u590d\u5e73\u9762\u4e0a\u7684\u70b9\u7684\u6247\u5f62         angle = np.linspace(0, omega * t[i], 20)         x_fan = np.zeros_like(angle)         y_fan = np.sin(angle)         z_fan = np.cos(angle)         ax.plot(x_fan, y_fan, z_fan, 'r-', alpha=0.3)                  # \u586b\u5145\u6247\u5f62\u533a\u57df         ax.plot_surface(             np.outer(x_fan, np.ones(2)),             np.outer(y_fan, np.linspace(0, 1, 2)),             np.outer(z_fan, np.linspace(0, 1, 2)),             color='yellow', alpha=0.1         )  # \u6807\u8bb0\u7279\u6b8a\u70b9 special_times = [0, T/4, T/2, 3*T/4, T] for st in special_times:     idx = np.argmin(np.abs(t - st))     ax.scatter([t[idx]], [imag_part[idx]], [real_part[idx]], color='red', s=100, label=f't={st}' if st == 0 else \"\")     ax.text(t[idx]+0.2, imag_part[idx], real_part[idx], f't={st}', fontsize=12)  # \u8bbe\u7f6e\u5750\u6807\u8f74\u6807\u7b7e ax.set_xlabel('x\u8f74\uff1a\u65f6\u95f4 t', fontproperties=chinese_font, fontsize=14) ax.set_ylabel('y \u8f74\uff1a\u865a\u90e8 Im(f) sin(1*omega*t)', fontproperties=chinese_font, fontsize=14) ax.set_zlabel('z \u8f74\uff1a\u5b9e\u90e8 Re(f) cos(1*omega*t)', fontproperties=chinese_font, fontsize=14)  # \u8bbe\u7f6e\u5750\u6807\u8f74\u8303\u56f4 ax.set_xlim(0, max_t) ax.set_ylim(-1.5, 1.5) ax.set_zlim(-1.5, 1.5)  # \u6dfb\u52a0\u7f51\u683c ax.grid(True)  # \u8bbe\u7f6e\u6807\u9898 ax.set_title(f'\u590d\u6307\u6570\u4fe1\u53f7 $f=e^{{i\\\\omega t}}$ \u7684\u4e09\u7ef4\u53ef\u89c6\u5316\uff0c\u5468\u671fT={T}\uff0cn={n}\u4e2a\u5468\u671f',             fontproperties=chinese_font, fontsize=16)  # \u6dfb\u52a00\u70b9\u6807\u8bb0 ax.scatter([0], [0], [0], color='black', s=100, marker='o') ax.text(0.2, 0, 0, '\u539f\u70b9', fontsize=12, fontproperties=chinese_font)  # \u6dfb\u52a0\u56fe\u4f8b # ax.legend(loc='upper right', prop=chinese_font)  # \u56fe\u4f8b\u592a\u591a\u53ef\u80fd\u4f1a\u6321\u4f4f\u56fe\u50cf  # \u6dfb\u52a0\u6570\u5b66\u516c\u5f0f\u8bf4\u660e formula_text = (     f\"\u590d\u6307\u6570\u4fe1\u53f7: $f = e^{{i\\\\omega t}}$\uff0c\u5176\u4e2d $\\\\omega = \\\\frac{{2\\\\pi}}{{T}} = \\\\frac{{2\\\\pi}}{{{T}}}$\\n\"     f\"\u5b9e\u90e8: $\\\\cos(\\\\omega t)$\uff0c\u865a\u90e8: $\\\\sin(\\\\omega t)$\\n\"     f\"\u5468\u671f: T = {T}\uff0c\u603b\u65f6\u95f4: {n*T}\" ) fig.text(0.5, 0.02, formula_text, ha='center', fontproperties=chinese_font, fontsize=14)  # \u8bbe\u7f6e\u66f4\u597d\u7684\u89c6\u89d2 ax.view_init(elev=25, azim=40)  # \u8c03\u6574\u56fe\u5f62\u5e03\u5c40 plt.tight_layout(rect=[0, 0.05, 1, 0.95]) plt.show()  # \u7ed8\u5236\u5e73\u9762\u6295\u5f71\u7684\u8be6\u7ec6\u89c6\u56fe plt.figure(figsize=(18, 12))  # 1. \u65f6\u95f4\u57df\u4fe1\u53f7 plt.subplot(2, 2, 1) plt.plot(t, real_part, 'b-', label=r'$\\cos(\\omega t)$ (\u5b9e\u90e8)') plt.plot(t, imag_part, 'r-', label=r'$\\sin(\\omega t)$ (\u865a\u90e8)') plt.grid(True) plt.legend(prop=chinese_font) plt.title('\u590d\u6307\u6570\u4fe1\u53f7\u7684\u5b9e\u90e8\u548c\u865a\u90e8', fontproperties=chinese_font) plt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font) plt.ylabel('\u5e45\u5ea6', fontproperties=chinese_font)  # 2. \u590d\u5e73\u9762\u4e0a\u7684\u8f68\u8ff9 plt.subplot(2, 2, 2) plt.plot(real_part, imag_part, 'g-') plt.grid(True) plt.title('\u590d\u5e73\u9762\u8f68\u8ff9 (\u5355\u4f4d\u5706)', fontproperties=chinese_font) plt.xlabel('\u5b9e\u90e8', fontproperties=chinese_font) plt.ylabel('\u865a\u90e8', fontproperties=chinese_font) plt.axis('equal')  # \u4fdd\u6301\u5750\u6807\u8f74\u6bd4\u4f8b\u4e00\u81f4  # \u6dfb\u52a0\u9634\u5f71\u6247\u533a for st in special_times:     idx = np.argmin(np.abs(t - st))     angle = np.linspace(0, omega * t[idx], 100)     x_fan = np.cos(angle)     y_fan = np.sin(angle)     plt.fill(x_fan, y_fan, 'yellow', alpha=0.1)     plt.plot(x_fan, y_fan, 'k--', alpha=0.3)      # \u6807\u8bb0\u7279\u6b8a\u70b9 for st in special_times:     idx = np.argmin(np.abs(t - st))     plt.plot(real_part[idx], imag_part[idx], 'ro')     plt.annotate(f't = {st}',                  xy=(real_part[idx], imag_part[idx]),                 xytext=(real_part[idx]*1.2, imag_part[idx]*1.2),                 fontproperties=chinese_font,                 fontsize=10)  # 3. \u4e09\u7ef4\u87ba\u65cb\u7684\u4fef\u89c6\u56fe plt.subplot(2, 2, 3) plt.plot(t, imag_part, 'g-') plt.grid(True) plt.title('\u4e09\u7ef4\u87ba\u65cb\u7684\u4fef\u89c6\u56fe (t-\u865a\u90e8 \u5e73\u9762)', fontproperties=chinese_font) plt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font) plt.ylabel('\u865a\u90e8', fontproperties=chinese_font)  # \u6dfb\u52a0\u4ece\u65f6\u95f4\u8f74\u5230\u66f2\u7ebf\u7684\u5782\u7ebf\u9634\u5f71 shadow_indices = np.arange(0, len(t), 20) for i in shadow_indices:     plt.plot([t[i], t[i]], [0, imag_part[i]], 'k:', alpha=0.5)      # \u6807\u8bb0\u7279\u6b8a\u70b9 for st in special_times:     idx = np.argmin(np.abs(t - st))     plt.plot(t[idx], imag_part[idx], 'ro')     plt.annotate(f't = {st}',                  xy=(t[idx], imag_part[idx]),                 xytext=(t[idx]+0.2, imag_part[idx]+0.1),                 fontproperties=chinese_font,                 fontsize=10)  # 4. \u4e09\u7ef4\u87ba\u65cb\u7684\u4fa7\u89c6\u56fe plt.subplot(2, 2, 4) plt.plot(t, real_part, 'r-') plt.grid(True) plt.title('\u4e09\u7ef4\u87ba\u65cb\u7684\u4fa7\u89c6\u56fe (t-\u5b9e\u90e8 \u5e73\u9762)', fontproperties=chinese_font) plt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font) plt.ylabel('\u5b9e\u90e8', fontproperties=chinese_font)  # \u6dfb\u52a0\u4ece\u65f6\u95f4\u8f74\u5230\u66f2\u7ebf\u7684\u5782\u7ebf\u9634\u5f71 for i in shadow_indices:     plt.plot([t[i], t[i]], [0, real_part[i]], 'k:', alpha=0.5)      # \u6807\u8bb0\u7279\u6b8a\u70b9 for st in special_times:     idx = np.argmin(np.abs(t - st))     plt.plot(t[idx], real_part[idx], 'ro')     plt.annotate(f't = {st}',                  xy=(t[idx], real_part[idx]),                 xytext=(t[idx]+0.2, real_part[idx]+0.1),                 fontproperties=chinese_font,                 fontsize=10)  plt.tight_layout() plt.show() In\u00a0[16]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.colors as colors\nfrom matplotlib import cm\n\n# \u8bbe\u7f6e\u4e2d\u6587\u663e\u793a\nfont_path = '/System/Library/Fonts/Supplemental/Songti.ttc'  # macOS \u4e2d\u7684\u5b8b\u4f53\u5b57\u4f53\nchinese_font = FontProperties(fname=font_path)\nplt.rcParams['axes.unicode_minus'] = False  # \u89e3\u51b3\u8d1f\u53f7\u663e\u793a\u95ee\u9898\n\n# \u53c2\u6570\u8bbe\u7f6e\nT = 6  # \u5468\u671f\nomega = (2 * np.pi) / T  # \u89d2\u9891\u7387\nn = 2  # \u5468\u671f\u4e2a\u6570\nt = np.arange(0, n * T + 0.1, 0.1)  # \u65f6\u95f4\u5e8f\u5217\uff0c\u4ece0\u5230n*T\uff0c\u6b65\u957f\u4e3a0.1\n\n# \u8ba1\u7b97\u590d\u6307\u6570\u4fe1\u53f7\nf = np.exp(2j * omega * t)  # \u6ce8\u610f\u8fd9\u91cc\u4f7f\u75282j\nreal_part = np.real(f)  # \u5b9e\u90e8\nimag_part = np.imag(f)  # \u865a\u90e8\n\n# \u521b\u5efa\u4e09\u7ef4\u56fe\u50cf\nfig = plt.figure(figsize=(20, 16))\nax = fig.add_subplot(111, projection='3d')\n\n# \u7ed8\u5236\u4e09\u7ef4\u66f2\u7ebf\nspiral, = ax.plot(t, imag_part, real_part, linewidth=3, color='blue', label='\u590d\u6307\u6570\u4fe1\u53f7')\n\n# \u53c2\u6570\u8bbe\u7f6e\nmax_t = n * T\nt_grid = np.linspace(0, max_t, 100)\nxy_range = np.linspace(-1.5, 1.5, 100)\nzero_grid = np.zeros_like(t_grid)\n\n# \u521b\u5efa\u6295\u5f71\u5e73\u9762\u7f51\u683c\nt_mesh, im_mesh = np.meshgrid(t_grid, xy_range)\nre_mesh = np.zeros_like(t_mesh)\n\n# XY\u5e73\u9762\uff08\u5730\u9762\u6295\u5f71\uff09- \u751f\u6210\u5b9e\u9645\u6295\u5f71\u66f2\u9762\nZ_xy = np.zeros_like(t_mesh)  # z=0\u5e73\u9762\n# \u521b\u5efa\u6295\u5f71\u6570\u636e\nt_proj = t.reshape(-1, 1)\nimag_proj = imag_part.reshape(-1, 1)\npoints_xy = np.hstack((t_proj, imag_proj))\n\n# \u7ed8\u5236XY\u5e73\u9762\u57fa\u7840\nxy_plane = ax.plot_surface(t_mesh, im_mesh, re_mesh, \n                          color='lightblue', alpha=0.2)\n\n# \u5728XY\u5e73\u9762\u4e0a\u7ed8\u5236\u6295\u5f71\u66f2\u7ebf\nxy_proj, = ax.plot(t, imag_part, np.zeros_like(t), 'g-', linewidth=3)\n\n# \u7ed8\u5236\u4ece\u66f2\u7ebf\u5230XY\u5e73\u9762\u7684\u5782\u76f4\u7ebf\uff08\"\u9634\u5f71\u7ebf\"\uff09\nfor i in range(0, len(t), 10):\n    ax.plot([t[i], t[i]], [imag_part[i], imag_part[i]], [real_part[i], 0], 'k--', alpha=0.3)\n\n# XZ\u5e73\u9762\uff08\u540e\u5899\u6295\u5f71\uff09\nt_mesh, re_mesh = np.meshgrid(t_grid, xy_range)\nim_mesh = np.zeros_like(t_mesh)  # y=0\u5e73\u9762\n\n# \u7ed8\u5236XZ\u5e73\u9762\nxz_plane = ax.plot_surface(t_mesh, im_mesh, re_mesh,\n                          color='lightgreen', alpha=0.2)\n\n# \u5728XZ\u5e73\u9762\u4e0a\u7ed8\u5236\u6295\u5f71\u66f2\u7ebf \nxz_proj, = ax.plot(t, np.zeros_like(t), real_part, 'r-', linewidth=3)\n\n# \u7ed8\u5236\u4ece\u66f2\u7ebf\u5230XZ\u5e73\u9762\u7684\u5782\u76f4\u7ebf\nfor i in range(0, len(t), 10):\n    ax.plot([t[i], t[i]], [0, imag_part[i]], [real_part[i], real_part[i]], 'k--', alpha=0.3)\n\n# YZ\u5e73\u9762\uff08\u4fa7\u5899\u6295\u5f71\uff09- \u590d\u5e73\u9762\nim_mesh, re_mesh = np.meshgrid(xy_range, xy_range)\nt_mesh = np.zeros_like(im_mesh)  # x=0\u5e73\u9762\n\n# \u7ed8\u5236YZ\u5e73\u9762\nyz_plane = ax.plot_surface(t_mesh, im_mesh, re_mesh,\n                          color='lightyellow', alpha=0.2)\n\n# \u5728YZ\u5e73\u9762\u4e0a\u7ed8\u5236\u5355\u4f4d\u5706 \ntheta = np.linspace(0, 2*np.pi, 100)\ny_circle = np.sin(2*theta)  # \u8fd9\u91cc\u4f7f\u75282*theta\u5339\u914df=exp(2j*omega*t)\nz_circle = np.cos(2*theta)\nt_circle = np.zeros_like(theta)\nunit_circle, = ax.plot(t_circle, y_circle, z_circle, 'k-', linewidth=2)\n\n# \u5728\u590d\u5e73\u9762(YZ\u5e73\u9762)\u4e0a\u521b\u5efa\u65f6\u95f4\u523b\u5ea6\u7684\u6295\u5f71\u70b9\n# \u8fd9\u4e9b\u70b9\u8868\u793a\u590d\u6307\u6570\u5728\u7279\u5b9a\u65f6\u95f4\u70b9\u7684\u503c\u5728\u590d\u5e73\u9762\u4e0a\u7684\u6295\u5f71\nspecial_times = np.linspace(0, T, 13)  # \u66f4\u591a\u7684\u70b9\u4ee5\u663e\u793a\u8f68\u8ff9\nfor st in special_times:\n    idx = np.argmin(np.abs(t - st))\n    ax.scatter([0], [imag_part[idx]], [real_part[idx]], color='purple', s=30)\n    # \u8fde\u63a5\u539f\u70b9\u5230\u590d\u5e73\u9762\u4e0a\u7684\u70b9\n    ax.plot([0, 0], [0, imag_part[idx]], [0, real_part[idx]], 'purple', alpha=0.3)\n\n# \u586b\u5145\u6247\u533a\u9634\u5f71 - \u5728\u590d\u5e73\u9762(YZ\u5e73\u9762)\u4e0a\n# \u9009\u62e9\u51e0\u4e2a\u4ee3\u8868\u6027\u65f6\u95f4\u70b9\nfor st in [T/4, T/2, 3*T/4, T]:\n    idx = np.argmin(np.abs(t - st))\n    # \u8ba1\u7b97\u6247\u533a\u8303\u56f4\u5185\u7684\u89d2\u5ea6\n    angle = np.linspace(0, 2*omega*t[idx], 50)  # \u6ce8\u610f\u8fd9\u91cc\u4f7f\u75282*omega\u5339\u914df=exp(2j*omega*t)\n    # \u521b\u5efa\u6247\u533a\u70b9\n    x_fan = np.zeros_like(angle)\n    y_fan = np.sin(angle)\n    z_fan = np.cos(angle)\n    # \u586b\u5145\u6247\u533a\n    fan_x = np.vstack((x_fan, x_fan))\n    fan_y = np.vstack((np.zeros_like(angle), y_fan))\n    fan_z = np.vstack((np.zeros_like(angle), z_fan))\n    ax.plot_surface(fan_x, fan_y, fan_z, color='yellow', alpha=0.1)\n    # \u7ed8\u5236\u6247\u533a\u8fb9\u754c\n    ax.plot(x_fan, y_fan, z_fan, 'k:', alpha=0.5)\n\n# \u6807\u8bb0\u7279\u6b8a\u70b9\nhighlight_times = [0, T/4, T/2, 3*T/4, T]\nfor st in highlight_times:\n    idx = np.argmin(np.abs(t - st))\n    # \u5728\u87ba\u65cb\u4e0a\u6807\u8bb0\u70b9\n    ax.scatter([t[idx]], [imag_part[idx]], [real_part[idx]], color='red', s=100)\n    ax.text(t[idx]+0.2, imag_part[idx], real_part[idx], f't={st}', fontsize=12)\n    \n    # \u5728xy\u5e73\u9762\u6295\u5f71\u4e0a\u6807\u8bb0\u70b9\n    ax.scatter([t[idx]], [imag_part[idx]], [0], color='green', s=80)\n    \n    # \u5728xz\u5e73\u9762\u6295\u5f71\u4e0a\u6807\u8bb0\u70b9\n    ax.scatter([t[idx]], [0], [real_part[idx]], color='red', s=80)\n    \n    # \u5728yz\u5e73\u9762\u590d\u5e73\u9762\u4e0a\u6807\u8bb0\u70b9\n    ax.scatter([0], [imag_part[idx]], [real_part[idx]], color='purple', s=80)\n\n# \u6dfb\u52a0\u65f6\u95f4\u8f74\u4e0a\u7684\u539f\u70b9\u6807\u8bb0\nax.scatter([0], [0], [0], color='black', s=100)\nax.text(0.2, 0, 0, '\u539f\u70b9', fontsize=12, fontproperties=chinese_font)\n\n# \u8bbe\u7f6e\u5750\u6807\u8f74\u6807\u7b7e\nax.set_xlabel('x\u8f74\uff1a\u65f6\u95f4 t', fontproperties=chinese_font, fontsize=14)\nax.set_ylabel('y \u8f74\uff1a\u865a\u90e8 Im(f) sin(2*omega*t)', fontproperties=chinese_font, fontsize=14)\nax.set_zlabel('z \u8f74\uff1a\u5b9e\u90e8 Re(f) cos(2*omega*t)', fontproperties=chinese_font, fontsize=14)\n\n# \u8bbe\u7f6e\u5750\u6807\u8f74\u8303\u56f4\nax.set_xlim(0, max_t)\nax.set_ylim(-1.5, 1.5)\nax.set_zlim(-1.5, 1.5)\n\n# \u6dfb\u52a0\u7f51\u683c\nax.grid(True)\n\n# \u8bbe\u7f6e\u6807\u9898 - \u6ce8\u610f\u8fd9\u91cc\u662f2j\u800c\u4e0d\u662fj\nax.set_title(f'\u590d\u6307\u6570\u4fe1\u53f7 $f=e^{{2i\\\\omega t}}$ \u7684\u4e09\u7ef4\u53ef\u89c6\u5316\uff0c\u5468\u671fT={T/2}\uff0cn={n}\u4e2a\u5468\u671f',\n            fontproperties=chinese_font, fontsize=16)\n\n# \u6dfb\u52a0\u6570\u5b66\u516c\u5f0f\u8bf4\u660e\nformula_text = (\n    f\"\u590d\u6307\u6570\u4fe1\u53f7: $f = e^{{2i\\\\omega t}}$\uff0c\u5176\u4e2d $\\\\omega = \\\\frac{{2\\\\pi}}{{T}} = \\\\frac{{2\\\\pi}}{{{T}}}$\\n\"\n    f\"\u5b9e\u90e8: $\\\\cos(2\\\\omega t)$\uff0c\u865a\u90e8: $\\\\sin(2\\\\omega t)$\\n\"\n    f\"\u5b9e\u9645\u5468\u671f: T/{2} = {T/2}\uff0c\u603b\u65f6\u95f4: {n*T}\"\n)\nfig.text(0.5, 0.02, formula_text, ha='center', fontproperties=chinese_font, fontsize=14)\n\n# \u8bbe\u7f6e\u66f4\u597d\u7684\u89c6\u89d2\nax.view_init(elev=25, azim=40)\n\n# \u8c03\u6574\u56fe\u5f62\u5e03\u5c40\nplt.tight_layout(rect=[0, 0.05, 1, 0.95])\nplt.show()\n\n# \u7ed8\u5236\u5e73\u9762\u6295\u5f71\u7684\u8be6\u7ec6\u89c6\u56fe\nplt.figure(figsize=(18, 12))\n\n# 1. \u65f6\u95f4\u57df\u4fe1\u53f7\nplt.subplot(2, 2, 1)\nplt.plot(t, real_part, 'b-', label=r'$\\cos(2\\omega t)$ (\u5b9e\u90e8)')\nplt.plot(t, imag_part, 'r-', label=r'$\\sin(2\\omega t)$ (\u865a\u90e8)')\nplt.grid(True)\nplt.legend(prop=chinese_font)\nplt.title('\u590d\u6307\u6570\u4fe1\u53f7\u7684\u5b9e\u90e8\u548c\u865a\u90e8', fontproperties=chinese_font)\nplt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font)\nplt.ylabel('\u5e45\u5ea6', fontproperties=chinese_font)\n\n# 2. \u590d\u5e73\u9762\u4e0a\u7684\u8f68\u8ff9\nplt.subplot(2, 2, 2)\nplt.plot(real_part, imag_part, 'g-')\nplt.grid(True)\nplt.title('\u590d\u5e73\u9762\u8f68\u8ff9 (\u5355\u4f4d\u5706)', fontproperties=chinese_font)\nplt.xlabel('\u5b9e\u90e8', fontproperties=chinese_font)\nplt.ylabel('\u865a\u90e8', fontproperties=chinese_font)\nplt.axis('equal')  # \u4fdd\u6301\u5750\u6807\u8f74\u6bd4\u4f8b\u4e00\u81f4\n\n# \u6dfb\u52a0\u9634\u5f71\u6247\u533a\nfor st in highlight_times:\n    idx = np.argmin(np.abs(t - st))\n    angle = np.linspace(0, 2*omega * t[idx], 100)  # \u6ce8\u610f\u8fd9\u91cc\u75282*omega\n    x_fan = np.cos(angle)\n    y_fan = np.sin(angle)\n    plt.fill(x_fan, y_fan, 'yellow', alpha=0.1)\n    plt.plot(x_fan, y_fan, 'k--', alpha=0.3)\n    \n# \u6807\u8bb0\u7279\u6b8a\u70b9\nfor st in highlight_times:\n    idx = np.argmin(np.abs(t - st))\n    plt.plot(real_part[idx], imag_part[idx], 'ro')\n    plt.annotate(f't = {st}', \n                xy=(real_part[idx], imag_part[idx]),\n                xytext=(real_part[idx]*1.2, imag_part[idx]*1.2),\n                fontproperties=chinese_font,\n                fontsize=10)\n\n# 3. \u65f6\u95f4-\u865a\u90e8\u5e73\u9762\nplt.subplot(2, 2, 3)\nplt.plot(t, imag_part, 'g-')\nplt.grid(True)\nplt.title('\u4e09\u7ef4\u87ba\u65cb\u7684\u4fef\u89c6\u56fe (t-\u865a\u90e8 \u5e73\u9762)', fontproperties=chinese_font)\nplt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font)\nplt.ylabel('\u865a\u90e8', fontproperties=chinese_font)\n\n# \u6dfb\u52a0\u4ece\u65f6\u95f4\u8f74\u5230\u66f2\u7ebf\u7684\u5782\u7ebf\u9634\u5f71\nshadow_indices = np.arange(0, len(t), 20)\nfor i in shadow_indices:\n    plt.plot([t[i], t[i]], [0, imag_part[i]], 'k:', alpha=0.5)\n    \n# \u6807\u8bb0\u7279\u6b8a\u70b9\nfor st in highlight_times:\n    idx = np.argmin(np.abs(t - st))\n    plt.plot(t[idx], imag_part[idx], 'ro')\n    plt.annotate(f't = {st}', \n                xy=(t[idx], imag_part[idx]),\n                xytext=(t[idx]+0.2, imag_part[idx]+0.1),\n                fontproperties=chinese_font,\n                fontsize=10)\n\n# 4. \u65f6\u95f4-\u5b9e\u90e8\u5e73\u9762\nplt.subplot(2, 2, 4)\nplt.plot(t, real_part, 'r-')\nplt.grid(True)\nplt.title('\u4e09\u7ef4\u87ba\u65cb\u7684\u4fa7\u89c6\u56fe (t-\u5b9e\u90e8 \u5e73\u9762)', fontproperties=chinese_font)\nplt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font)\nplt.ylabel('\u5b9e\u90e8', fontproperties=chinese_font)\n\n# \u6dfb\u52a0\u4ece\u65f6\u95f4\u8f74\u5230\u66f2\u7ebf\u7684\u5782\u7ebf\u9634\u5f71\nfor i in shadow_indices:\n    plt.plot([t[i], t[i]], [0, real_part[i]], 'k:', alpha=0.5)\n    \n# \u6807\u8bb0\u7279\u6b8a\u70b9\nfor st in highlight_times:\n    idx = np.argmin(np.abs(t - st))\n    plt.plot(t[idx], real_part[idx], 'ro')\n    plt.annotate(f't = {st}', \n                xy=(t[idx], real_part[idx]),\n                xytext=(t[idx]+0.2, real_part[idx]+0.1),\n                fontproperties=chinese_font,\n                fontsize=10)\n\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from matplotlib.font_manager import FontProperties from mpl_toolkits.mplot3d import Axes3D import matplotlib.colors as colors from matplotlib import cm  # \u8bbe\u7f6e\u4e2d\u6587\u663e\u793a font_path = '/System/Library/Fonts/Supplemental/Songti.ttc'  # macOS \u4e2d\u7684\u5b8b\u4f53\u5b57\u4f53 chinese_font = FontProperties(fname=font_path) plt.rcParams['axes.unicode_minus'] = False  # \u89e3\u51b3\u8d1f\u53f7\u663e\u793a\u95ee\u9898  # \u53c2\u6570\u8bbe\u7f6e T = 6  # \u5468\u671f omega = (2 * np.pi) / T  # \u89d2\u9891\u7387 n = 2  # \u5468\u671f\u4e2a\u6570 t = np.arange(0, n * T + 0.1, 0.1)  # \u65f6\u95f4\u5e8f\u5217\uff0c\u4ece0\u5230n*T\uff0c\u6b65\u957f\u4e3a0.1  # \u8ba1\u7b97\u590d\u6307\u6570\u4fe1\u53f7 f = np.exp(2j * omega * t)  # \u6ce8\u610f\u8fd9\u91cc\u4f7f\u75282j real_part = np.real(f)  # \u5b9e\u90e8 imag_part = np.imag(f)  # \u865a\u90e8  # \u521b\u5efa\u4e09\u7ef4\u56fe\u50cf fig = plt.figure(figsize=(20, 16)) ax = fig.add_subplot(111, projection='3d')  # \u7ed8\u5236\u4e09\u7ef4\u66f2\u7ebf spiral, = ax.plot(t, imag_part, real_part, linewidth=3, color='blue', label='\u590d\u6307\u6570\u4fe1\u53f7')  # \u53c2\u6570\u8bbe\u7f6e max_t = n * T t_grid = np.linspace(0, max_t, 100) xy_range = np.linspace(-1.5, 1.5, 100) zero_grid = np.zeros_like(t_grid)  # \u521b\u5efa\u6295\u5f71\u5e73\u9762\u7f51\u683c t_mesh, im_mesh = np.meshgrid(t_grid, xy_range) re_mesh = np.zeros_like(t_mesh)  # XY\u5e73\u9762\uff08\u5730\u9762\u6295\u5f71\uff09- \u751f\u6210\u5b9e\u9645\u6295\u5f71\u66f2\u9762 Z_xy = np.zeros_like(t_mesh)  # z=0\u5e73\u9762 # \u521b\u5efa\u6295\u5f71\u6570\u636e t_proj = t.reshape(-1, 1) imag_proj = imag_part.reshape(-1, 1) points_xy = np.hstack((t_proj, imag_proj))  # \u7ed8\u5236XY\u5e73\u9762\u57fa\u7840 xy_plane = ax.plot_surface(t_mesh, im_mesh, re_mesh,                            color='lightblue', alpha=0.2)  # \u5728XY\u5e73\u9762\u4e0a\u7ed8\u5236\u6295\u5f71\u66f2\u7ebf xy_proj, = ax.plot(t, imag_part, np.zeros_like(t), 'g-', linewidth=3)  # \u7ed8\u5236\u4ece\u66f2\u7ebf\u5230XY\u5e73\u9762\u7684\u5782\u76f4\u7ebf\uff08\"\u9634\u5f71\u7ebf\"\uff09 for i in range(0, len(t), 10):     ax.plot([t[i], t[i]], [imag_part[i], imag_part[i]], [real_part[i], 0], 'k--', alpha=0.3)  # XZ\u5e73\u9762\uff08\u540e\u5899\u6295\u5f71\uff09 t_mesh, re_mesh = np.meshgrid(t_grid, xy_range) im_mesh = np.zeros_like(t_mesh)  # y=0\u5e73\u9762  # \u7ed8\u5236XZ\u5e73\u9762 xz_plane = ax.plot_surface(t_mesh, im_mesh, re_mesh,                           color='lightgreen', alpha=0.2)  # \u5728XZ\u5e73\u9762\u4e0a\u7ed8\u5236\u6295\u5f71\u66f2\u7ebf  xz_proj, = ax.plot(t, np.zeros_like(t), real_part, 'r-', linewidth=3)  # \u7ed8\u5236\u4ece\u66f2\u7ebf\u5230XZ\u5e73\u9762\u7684\u5782\u76f4\u7ebf for i in range(0, len(t), 10):     ax.plot([t[i], t[i]], [0, imag_part[i]], [real_part[i], real_part[i]], 'k--', alpha=0.3)  # YZ\u5e73\u9762\uff08\u4fa7\u5899\u6295\u5f71\uff09- \u590d\u5e73\u9762 im_mesh, re_mesh = np.meshgrid(xy_range, xy_range) t_mesh = np.zeros_like(im_mesh)  # x=0\u5e73\u9762  # \u7ed8\u5236YZ\u5e73\u9762 yz_plane = ax.plot_surface(t_mesh, im_mesh, re_mesh,                           color='lightyellow', alpha=0.2)  # \u5728YZ\u5e73\u9762\u4e0a\u7ed8\u5236\u5355\u4f4d\u5706  theta = np.linspace(0, 2*np.pi, 100) y_circle = np.sin(2*theta)  # \u8fd9\u91cc\u4f7f\u75282*theta\u5339\u914df=exp(2j*omega*t) z_circle = np.cos(2*theta) t_circle = np.zeros_like(theta) unit_circle, = ax.plot(t_circle, y_circle, z_circle, 'k-', linewidth=2)  # \u5728\u590d\u5e73\u9762(YZ\u5e73\u9762)\u4e0a\u521b\u5efa\u65f6\u95f4\u523b\u5ea6\u7684\u6295\u5f71\u70b9 # \u8fd9\u4e9b\u70b9\u8868\u793a\u590d\u6307\u6570\u5728\u7279\u5b9a\u65f6\u95f4\u70b9\u7684\u503c\u5728\u590d\u5e73\u9762\u4e0a\u7684\u6295\u5f71 special_times = np.linspace(0, T, 13)  # \u66f4\u591a\u7684\u70b9\u4ee5\u663e\u793a\u8f68\u8ff9 for st in special_times:     idx = np.argmin(np.abs(t - st))     ax.scatter([0], [imag_part[idx]], [real_part[idx]], color='purple', s=30)     # \u8fde\u63a5\u539f\u70b9\u5230\u590d\u5e73\u9762\u4e0a\u7684\u70b9     ax.plot([0, 0], [0, imag_part[idx]], [0, real_part[idx]], 'purple', alpha=0.3)  # \u586b\u5145\u6247\u533a\u9634\u5f71 - \u5728\u590d\u5e73\u9762(YZ\u5e73\u9762)\u4e0a # \u9009\u62e9\u51e0\u4e2a\u4ee3\u8868\u6027\u65f6\u95f4\u70b9 for st in [T/4, T/2, 3*T/4, T]:     idx = np.argmin(np.abs(t - st))     # \u8ba1\u7b97\u6247\u533a\u8303\u56f4\u5185\u7684\u89d2\u5ea6     angle = np.linspace(0, 2*omega*t[idx], 50)  # \u6ce8\u610f\u8fd9\u91cc\u4f7f\u75282*omega\u5339\u914df=exp(2j*omega*t)     # \u521b\u5efa\u6247\u533a\u70b9     x_fan = np.zeros_like(angle)     y_fan = np.sin(angle)     z_fan = np.cos(angle)     # \u586b\u5145\u6247\u533a     fan_x = np.vstack((x_fan, x_fan))     fan_y = np.vstack((np.zeros_like(angle), y_fan))     fan_z = np.vstack((np.zeros_like(angle), z_fan))     ax.plot_surface(fan_x, fan_y, fan_z, color='yellow', alpha=0.1)     # \u7ed8\u5236\u6247\u533a\u8fb9\u754c     ax.plot(x_fan, y_fan, z_fan, 'k:', alpha=0.5)  # \u6807\u8bb0\u7279\u6b8a\u70b9 highlight_times = [0, T/4, T/2, 3*T/4, T] for st in highlight_times:     idx = np.argmin(np.abs(t - st))     # \u5728\u87ba\u65cb\u4e0a\u6807\u8bb0\u70b9     ax.scatter([t[idx]], [imag_part[idx]], [real_part[idx]], color='red', s=100)     ax.text(t[idx]+0.2, imag_part[idx], real_part[idx], f't={st}', fontsize=12)          # \u5728xy\u5e73\u9762\u6295\u5f71\u4e0a\u6807\u8bb0\u70b9     ax.scatter([t[idx]], [imag_part[idx]], [0], color='green', s=80)          # \u5728xz\u5e73\u9762\u6295\u5f71\u4e0a\u6807\u8bb0\u70b9     ax.scatter([t[idx]], [0], [real_part[idx]], color='red', s=80)          # \u5728yz\u5e73\u9762\u590d\u5e73\u9762\u4e0a\u6807\u8bb0\u70b9     ax.scatter([0], [imag_part[idx]], [real_part[idx]], color='purple', s=80)  # \u6dfb\u52a0\u65f6\u95f4\u8f74\u4e0a\u7684\u539f\u70b9\u6807\u8bb0 ax.scatter([0], [0], [0], color='black', s=100) ax.text(0.2, 0, 0, '\u539f\u70b9', fontsize=12, fontproperties=chinese_font)  # \u8bbe\u7f6e\u5750\u6807\u8f74\u6807\u7b7e ax.set_xlabel('x\u8f74\uff1a\u65f6\u95f4 t', fontproperties=chinese_font, fontsize=14) ax.set_ylabel('y \u8f74\uff1a\u865a\u90e8 Im(f) sin(2*omega*t)', fontproperties=chinese_font, fontsize=14) ax.set_zlabel('z \u8f74\uff1a\u5b9e\u90e8 Re(f) cos(2*omega*t)', fontproperties=chinese_font, fontsize=14)  # \u8bbe\u7f6e\u5750\u6807\u8f74\u8303\u56f4 ax.set_xlim(0, max_t) ax.set_ylim(-1.5, 1.5) ax.set_zlim(-1.5, 1.5)  # \u6dfb\u52a0\u7f51\u683c ax.grid(True)  # \u8bbe\u7f6e\u6807\u9898 - \u6ce8\u610f\u8fd9\u91cc\u662f2j\u800c\u4e0d\u662fj ax.set_title(f'\u590d\u6307\u6570\u4fe1\u53f7 $f=e^{{2i\\\\omega t}}$ \u7684\u4e09\u7ef4\u53ef\u89c6\u5316\uff0c\u5468\u671fT={T/2}\uff0cn={n}\u4e2a\u5468\u671f',             fontproperties=chinese_font, fontsize=16)  # \u6dfb\u52a0\u6570\u5b66\u516c\u5f0f\u8bf4\u660e formula_text = (     f\"\u590d\u6307\u6570\u4fe1\u53f7: $f = e^{{2i\\\\omega t}}$\uff0c\u5176\u4e2d $\\\\omega = \\\\frac{{2\\\\pi}}{{T}} = \\\\frac{{2\\\\pi}}{{{T}}}$\\n\"     f\"\u5b9e\u90e8: $\\\\cos(2\\\\omega t)$\uff0c\u865a\u90e8: $\\\\sin(2\\\\omega t)$\\n\"     f\"\u5b9e\u9645\u5468\u671f: T/{2} = {T/2}\uff0c\u603b\u65f6\u95f4: {n*T}\" ) fig.text(0.5, 0.02, formula_text, ha='center', fontproperties=chinese_font, fontsize=14)  # \u8bbe\u7f6e\u66f4\u597d\u7684\u89c6\u89d2 ax.view_init(elev=25, azim=40)  # \u8c03\u6574\u56fe\u5f62\u5e03\u5c40 plt.tight_layout(rect=[0, 0.05, 1, 0.95]) plt.show()  # \u7ed8\u5236\u5e73\u9762\u6295\u5f71\u7684\u8be6\u7ec6\u89c6\u56fe plt.figure(figsize=(18, 12))  # 1. \u65f6\u95f4\u57df\u4fe1\u53f7 plt.subplot(2, 2, 1) plt.plot(t, real_part, 'b-', label=r'$\\cos(2\\omega t)$ (\u5b9e\u90e8)') plt.plot(t, imag_part, 'r-', label=r'$\\sin(2\\omega t)$ (\u865a\u90e8)') plt.grid(True) plt.legend(prop=chinese_font) plt.title('\u590d\u6307\u6570\u4fe1\u53f7\u7684\u5b9e\u90e8\u548c\u865a\u90e8', fontproperties=chinese_font) plt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font) plt.ylabel('\u5e45\u5ea6', fontproperties=chinese_font)  # 2. \u590d\u5e73\u9762\u4e0a\u7684\u8f68\u8ff9 plt.subplot(2, 2, 2) plt.plot(real_part, imag_part, 'g-') plt.grid(True) plt.title('\u590d\u5e73\u9762\u8f68\u8ff9 (\u5355\u4f4d\u5706)', fontproperties=chinese_font) plt.xlabel('\u5b9e\u90e8', fontproperties=chinese_font) plt.ylabel('\u865a\u90e8', fontproperties=chinese_font) plt.axis('equal')  # \u4fdd\u6301\u5750\u6807\u8f74\u6bd4\u4f8b\u4e00\u81f4  # \u6dfb\u52a0\u9634\u5f71\u6247\u533a for st in highlight_times:     idx = np.argmin(np.abs(t - st))     angle = np.linspace(0, 2*omega * t[idx], 100)  # \u6ce8\u610f\u8fd9\u91cc\u75282*omega     x_fan = np.cos(angle)     y_fan = np.sin(angle)     plt.fill(x_fan, y_fan, 'yellow', alpha=0.1)     plt.plot(x_fan, y_fan, 'k--', alpha=0.3)      # \u6807\u8bb0\u7279\u6b8a\u70b9 for st in highlight_times:     idx = np.argmin(np.abs(t - st))     plt.plot(real_part[idx], imag_part[idx], 'ro')     plt.annotate(f't = {st}',                  xy=(real_part[idx], imag_part[idx]),                 xytext=(real_part[idx]*1.2, imag_part[idx]*1.2),                 fontproperties=chinese_font,                 fontsize=10)  # 3. \u65f6\u95f4-\u865a\u90e8\u5e73\u9762 plt.subplot(2, 2, 3) plt.plot(t, imag_part, 'g-') plt.grid(True) plt.title('\u4e09\u7ef4\u87ba\u65cb\u7684\u4fef\u89c6\u56fe (t-\u865a\u90e8 \u5e73\u9762)', fontproperties=chinese_font) plt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font) plt.ylabel('\u865a\u90e8', fontproperties=chinese_font)  # \u6dfb\u52a0\u4ece\u65f6\u95f4\u8f74\u5230\u66f2\u7ebf\u7684\u5782\u7ebf\u9634\u5f71 shadow_indices = np.arange(0, len(t), 20) for i in shadow_indices:     plt.plot([t[i], t[i]], [0, imag_part[i]], 'k:', alpha=0.5)      # \u6807\u8bb0\u7279\u6b8a\u70b9 for st in highlight_times:     idx = np.argmin(np.abs(t - st))     plt.plot(t[idx], imag_part[idx], 'ro')     plt.annotate(f't = {st}',                  xy=(t[idx], imag_part[idx]),                 xytext=(t[idx]+0.2, imag_part[idx]+0.1),                 fontproperties=chinese_font,                 fontsize=10)  # 4. \u65f6\u95f4-\u5b9e\u90e8\u5e73\u9762 plt.subplot(2, 2, 4) plt.plot(t, real_part, 'r-') plt.grid(True) plt.title('\u4e09\u7ef4\u87ba\u65cb\u7684\u4fa7\u89c6\u56fe (t-\u5b9e\u90e8 \u5e73\u9762)', fontproperties=chinese_font) plt.xlabel('\u65f6\u95f4 t', fontproperties=chinese_font) plt.ylabel('\u5b9e\u90e8', fontproperties=chinese_font)  # \u6dfb\u52a0\u4ece\u65f6\u95f4\u8f74\u5230\u66f2\u7ebf\u7684\u5782\u7ebf\u9634\u5f71 for i in shadow_indices:     plt.plot([t[i], t[i]], [0, real_part[i]], 'k:', alpha=0.5)      # \u6807\u8bb0\u7279\u6b8a\u70b9 for st in highlight_times:     idx = np.argmin(np.abs(t - st))     plt.plot(t[idx], real_part[idx], 'ro')     plt.annotate(f't = {st}',                  xy=(t[idx], real_part[idx]),                 xytext=(t[idx]+0.2, real_part[idx]+0.1),                 fontproperties=chinese_font,                 fontsize=10)  plt.tight_layout() plt.show() In\u00a0[18]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\nimport matplotlib as mpl\n\n# \u8bbe\u7f6e\u4e2d\u6587\u663e\u793a\nfont_path = '/System/Library/Fonts/Supplemental/Songti.ttc'  # macOS \u4e2d\u7684\u5b8b\u4f53\u5b57\u4f53\nchinese_font = FontProperties(fname=font_path)\nplt.rcParams['axes.unicode_minus'] = False  # \u89e3\u51b3\u8d1f\u53f7\u663e\u793a\u95ee\u9898\n\n# \u521b\u5efa\u6570\u636e\ntheta = np.linspace(0, 2*np.pi, 1000)\nx = np.cos(theta)\ny = np.sin(theta)\n\n# \u590d\u5e73\u9762\u4e0a\u7684\u7279\u6b8a\u70b9\nspecial_points = {\n    0: [1, 0, r'$e^{i \\cdot 0} = 1$', 'red'],\n    np.pi/2: [0, 1, r'$e^{i \\cdot \\pi/2} = i$', 'blue'],\n    np.pi: [-1, 0, r'$e^{i \\cdot \\pi} = -1$', 'green'],\n    3*np.pi/2: [0, -1, r'$e^{i \\cdot 3\\pi/2} = -i$', 'purple'],\n    2*np.pi: [1, 0, r'$e^{i \\cdot 2\\pi} = 1$', 'orange']\n}\n\n# \u521b\u5efa\u56fe\u5f62\nplt.figure(figsize=(10, 10))\nax = plt.subplot(111)\n\n# \u7ed8\u5236\u5355\u4f4d\u5706\nplt.plot(x, y, 'k-', lw=1.5, alpha=0.7)\n\n# \u7ed8\u5236\u5750\u6807\u8f74\nplt.axhline(y=0, color='gray', linestyle='-', alpha=0.7)\nplt.axvline(x=0, color='gray', linestyle='-', alpha=0.7)\n\n# \u7ed8\u5236\u5355\u4f4d\u5706\u4e0a\u7684\u7279\u6b8a\u70b9\nfor angle, (px, py, text, color) in special_points.items():\n    plt.plot(px, py, 'o', markersize=10, color=color)\n    plt.annotate(text, xy=(px, py), xytext=(px*1.5, py*1.5),\n                fontsize=12, color=color,\n                arrowprops=dict(facecolor=color, shrink=0.05, width=2, alpha=0.7))\n\n# \u4e3a\u67d0\u4e2a\u4efb\u610f\u70b9\u7ed8\u5236\u590d\u6307\u6570\u53ef\u89c6\u5316\nt_example = np.pi/4  # \u53ef\u4ee5\u66f4\u6539\u8fd9\u4e2a\u503c\u770b\u4e0d\u540c\u89d2\u5ea6\nx_example = np.cos(t_example)\ny_example = np.sin(t_example)\n\n# \u7ed8\u5236\u5230\u4efb\u610f\u70b9\u7684\u534a\u5f84\nplt.plot([0, x_example], [0, y_example], 'r--', lw=2)\n\n# \u6807\u8bb0\u89d2\u5ea6\narc = np.linspace(0, t_example, 100)\narc_x = 0.2 * np.cos(arc)\narc_y = 0.2 * np.sin(arc)\nplt.plot(arc_x, arc_y, 'b-', lw=1.5)\nplt.text(0.25 * np.cos(t_example/2), 0.25 * np.sin(t_example/2), \n         r'$\\theta$', fontsize=14, ha='center', va='center')\n\n# \u6dfb\u52a0\u5750\u6807\u6807\u7b7e\nplt.text(1.05, 0, r'$Re$', fontsize=14)\nplt.text(0, 1.05, r'$Im$', fontsize=14)\n\n# \u8bbe\u7f6e\u7ed8\u56fe\u8303\u56f4\u548c\u6807\u9898\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.axis('equal')\nplt.xlim(-2, 2)\nplt.ylim(-2, 2)\nplt.title('\u6b27\u62c9\u516c\u5f0f $e^{i\\\\theta} = \\\\cos\\\\theta + i\\\\sin\\\\theta$', fontproperties=chinese_font, fontsize=16)\n\n# \u6dfb\u52a0\u516c\u5f0f\u6ce8\u91ca\nformula_text = (\n    r\"\u6b27\u62c9\u516c\u5f0f: $e^{i\\theta} = \\cos\\theta + i\\sin\\theta$\"\n    \"\\n\"\n    r\"\u5f53 $\\theta = \\pi$ \u65f6: $e^{i\\pi} + 1 = 0$\"\n)\nplt.figtext(0.5, 0.01, formula_text, ha='center', fontproperties=chinese_font, fontsize=14)\n\nplt.tight_layout(rect=[0, 0.05, 1, 0.95])\nplt.show()\n\n# \u53e6\u5916\u7ed8\u5236\u6b27\u62c9\u516c\u5f0f\u5206\u91cf\u56fe\nt = np.linspace(0, 2*np.pi, 1000)\ncos_t = np.cos(t)\nsin_t = np.sin(t)\n\nplt.figure(figsize=(12, 8))\n\n# \u5b9e\u90e8\u548c\u865a\u90e8\u4f5c\u4e3a\u51fd\u6570\u56fe\u50cf\nplt.subplot(211)\nplt.plot(t, cos_t, 'b-', label=r'$\\cos(\\theta)$ (\u5b9e\u90e8)')\nplt.plot(t, sin_t, 'r-', label=r'$\\sin(\\theta)$ (\u865a\u90e8)')\nplt.grid(True)\nplt.legend(prop=chinese_font)\nplt.title('\u6b27\u62c9\u516c\u5f0f\u7684\u5b9e\u90e8\u548c\u865a\u90e8', fontproperties=chinese_font)\nplt.xlabel(r'$\\theta$')\nplt.ylabel(r'$\\cos(\\theta), \\sin(\\theta)$')\n\n# \u53c2\u6570\u65b9\u7a0b\u8868\u793a\nplt.subplot(212)\nplt.plot(cos_t, sin_t, 'g-')\nplt.grid(True)\nplt.title('\u6b27\u62c9\u516c\u5f0f\u5728\u590d\u5e73\u9762\u4e0a\u7684\u8f68\u8ff9(\u5355\u4f4d\u5706)', fontproperties=chinese_font)\nplt.xlabel(r'$\\cos(\\theta)$ (\u5b9e\u90e8)')\nplt.ylabel(r'$\\sin(\\theta)$ (\u865a\u90e8)')\nplt.axis('equal')\n\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from matplotlib.font_manager import FontProperties import matplotlib as mpl  # \u8bbe\u7f6e\u4e2d\u6587\u663e\u793a font_path = '/System/Library/Fonts/Supplemental/Songti.ttc'  # macOS \u4e2d\u7684\u5b8b\u4f53\u5b57\u4f53 chinese_font = FontProperties(fname=font_path) plt.rcParams['axes.unicode_minus'] = False  # \u89e3\u51b3\u8d1f\u53f7\u663e\u793a\u95ee\u9898  # \u521b\u5efa\u6570\u636e theta = np.linspace(0, 2*np.pi, 1000) x = np.cos(theta) y = np.sin(theta)  # \u590d\u5e73\u9762\u4e0a\u7684\u7279\u6b8a\u70b9 special_points = {     0: [1, 0, r'$e^{i \\cdot 0} = 1$', 'red'],     np.pi/2: [0, 1, r'$e^{i \\cdot \\pi/2} = i$', 'blue'],     np.pi: [-1, 0, r'$e^{i \\cdot \\pi} = -1$', 'green'],     3*np.pi/2: [0, -1, r'$e^{i \\cdot 3\\pi/2} = -i$', 'purple'],     2*np.pi: [1, 0, r'$e^{i \\cdot 2\\pi} = 1$', 'orange'] }  # \u521b\u5efa\u56fe\u5f62 plt.figure(figsize=(10, 10)) ax = plt.subplot(111)  # \u7ed8\u5236\u5355\u4f4d\u5706 plt.plot(x, y, 'k-', lw=1.5, alpha=0.7)  # \u7ed8\u5236\u5750\u6807\u8f74 plt.axhline(y=0, color='gray', linestyle='-', alpha=0.7) plt.axvline(x=0, color='gray', linestyle='-', alpha=0.7)  # \u7ed8\u5236\u5355\u4f4d\u5706\u4e0a\u7684\u7279\u6b8a\u70b9 for angle, (px, py, text, color) in special_points.items():     plt.plot(px, py, 'o', markersize=10, color=color)     plt.annotate(text, xy=(px, py), xytext=(px*1.5, py*1.5),                 fontsize=12, color=color,                 arrowprops=dict(facecolor=color, shrink=0.05, width=2, alpha=0.7))  # \u4e3a\u67d0\u4e2a\u4efb\u610f\u70b9\u7ed8\u5236\u590d\u6307\u6570\u53ef\u89c6\u5316 t_example = np.pi/4  # \u53ef\u4ee5\u66f4\u6539\u8fd9\u4e2a\u503c\u770b\u4e0d\u540c\u89d2\u5ea6 x_example = np.cos(t_example) y_example = np.sin(t_example)  # \u7ed8\u5236\u5230\u4efb\u610f\u70b9\u7684\u534a\u5f84 plt.plot([0, x_example], [0, y_example], 'r--', lw=2)  # \u6807\u8bb0\u89d2\u5ea6 arc = np.linspace(0, t_example, 100) arc_x = 0.2 * np.cos(arc) arc_y = 0.2 * np.sin(arc) plt.plot(arc_x, arc_y, 'b-', lw=1.5) plt.text(0.25 * np.cos(t_example/2), 0.25 * np.sin(t_example/2),           r'$\\theta$', fontsize=14, ha='center', va='center')  # \u6dfb\u52a0\u5750\u6807\u6807\u7b7e plt.text(1.05, 0, r'$Re$', fontsize=14) plt.text(0, 1.05, r'$Im$', fontsize=14)  # \u8bbe\u7f6e\u7ed8\u56fe\u8303\u56f4\u548c\u6807\u9898 plt.grid(True, linestyle='--', alpha=0.7) plt.axis('equal') plt.xlim(-2, 2) plt.ylim(-2, 2) plt.title('\u6b27\u62c9\u516c\u5f0f $e^{i\\\\theta} = \\\\cos\\\\theta + i\\\\sin\\\\theta$', fontproperties=chinese_font, fontsize=16)  # \u6dfb\u52a0\u516c\u5f0f\u6ce8\u91ca formula_text = (     r\"\u6b27\u62c9\u516c\u5f0f: $e^{i\\theta} = \\cos\\theta + i\\sin\\theta$\"     \"\\n\"     r\"\u5f53 $\\theta = \\pi$ \u65f6: $e^{i\\pi} + 1 = 0$\" ) plt.figtext(0.5, 0.01, formula_text, ha='center', fontproperties=chinese_font, fontsize=14)  plt.tight_layout(rect=[0, 0.05, 1, 0.95]) plt.show()  # \u53e6\u5916\u7ed8\u5236\u6b27\u62c9\u516c\u5f0f\u5206\u91cf\u56fe t = np.linspace(0, 2*np.pi, 1000) cos_t = np.cos(t) sin_t = np.sin(t)  plt.figure(figsize=(12, 8))  # \u5b9e\u90e8\u548c\u865a\u90e8\u4f5c\u4e3a\u51fd\u6570\u56fe\u50cf plt.subplot(211) plt.plot(t, cos_t, 'b-', label=r'$\\cos(\\theta)$ (\u5b9e\u90e8)') plt.plot(t, sin_t, 'r-', label=r'$\\sin(\\theta)$ (\u865a\u90e8)') plt.grid(True) plt.legend(prop=chinese_font) plt.title('\u6b27\u62c9\u516c\u5f0f\u7684\u5b9e\u90e8\u548c\u865a\u90e8', fontproperties=chinese_font) plt.xlabel(r'$\\theta$') plt.ylabel(r'$\\cos(\\theta), \\sin(\\theta)$')  # \u53c2\u6570\u65b9\u7a0b\u8868\u793a plt.subplot(212) plt.plot(cos_t, sin_t, 'g-') plt.grid(True) plt.title('\u6b27\u62c9\u516c\u5f0f\u5728\u590d\u5e73\u9762\u4e0a\u7684\u8f68\u8ff9(\u5355\u4f4d\u5706)', fontproperties=chinese_font) plt.xlabel(r'$\\cos(\\theta)$ (\u5b9e\u90e8)') plt.ylabel(r'$\\sin(\\theta)$ (\u865a\u90e8)') plt.axis('equal')  plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Reproduction/CodeRepo/1_0_Autoformer/#autoformer","title":"Autoformer\u00b6","text":""},{"location":"Reproduction/CodeRepo/1_0_Autoformer/#scipyfft","title":"scipy.fft\u00b6","text":""},{"location":"Reproduction/CodeRepo/1_0_Autoformer/","title":"\u9891\u8c31\u3001\u76f8\u4f4d\u3001\u8c10\u6ce2\u53ef\u89c6\u5316\u00b6","text":""},{"location":"Reproduction/CodeRepo/1_0_Autoformer/","title":"\u6b27\u62c9\u516c\u5f0f\u7684\u56fe\u50cf\u5316\u8868\u793a\u00b6","text":""},{"location":"Reproduction/CodeRepo/1_0_Autoformer/#f-ei-omega-t","title":"\u590d\u6307\u6570\u4fe1\u53f7: $f = e^{{i \\omega t}}$\u00b6","text":""},{"location":"Reproduction/CodeRepo/1_0_Autoformer/#f-e2i-omega-t","title":"\u590d\u6307\u6570\u4fe1\u53f7: $f = e^{{2i \\omega t}}$\u00b6","text":""},{"location":"Reproduction/CodeRepo/1_0_Autoformer/","title":"\u590d\u5e73\u9762\u4e0e\u6b27\u62c9\u516c\u5f0f\u00b6","text":""},{"location":"Reproduction/CodeRepo/1_MultiHeadAttention/","title":"\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u5f62\u72b6\u53d8\u5316","text":""},{"location":"Reproduction/CodeRepo/1_MultiHeadAttention/#_1","title":"\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u5f62\u72b6\u53d8\u5316","text":"2025-03-19 20:59:292025-09-28 12:54:03 <p> \u7ea6 700 \u4e2a\u5b57  83 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 5 \u5206\u949f</p>"},{"location":"Reproduction/CodeRepo/1_MultiHeadAttention/#qkv","title":"QKV","text":"<p>\u5173\u4e8e Transformer \u7684 QKV \u540c\u6e90\u95ee\u9898</p> <p>\\(QK^TV = B_QL_QD_Q \\cdot B_KD_KL_K \\cdot B_VL_VD_V\\)</p> <p>\uff081\uff09\u56de\u7b54\u540c\u6e90\u95ee\u9898\uff1a</p> <ul> <li>\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff08selfA\uff09\uff0c\\(QKV\\) \u6765\u81ea\u540c\u4e00\u4e2a\u5e8f\u5217</li> <li>\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u4e2d\uff08crossA\uff09\uff0c\\(Q\\) \u6765\u81ea\u4e00\u4e2a\u5e8f\u5217\uff0c\\(KV\\) \u6765\u81ea\u53e6\u4e00\u4e2a\u5e8f\u5217\uff0c\u6355\u6349\u4e24\u4e2a\u4e0d\u540c\u5e8f\u5217\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb</li> </ul> <p>\uff082\uff09\u8ba8\u8bba\u5f62\u72b6\u95ee\u9898\uff1a</p> <ul> <li>\u5fc5\u987b\u6ee1\u8db3\u7684\u662f\uff1a \\(D_Q = D_K\\) \u3001 \\(L_K = L_V\\)</li> <li>\u7b80\u5316\u7248\u672c\uff1a \\(attn = L_Q \\times L_K\\)</li> </ul> <p>\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\uff1a</p> <p>\u7684\u5f62\u72b6\u53d8\u5316\uff1aBLD  \\(\\stackrel{D=H\\cdot d}{\\rightarrow}\\)  BLHd </p>"},{"location":"Reproduction/CodeRepo/1_MultiHeadAttention/#_2","title":"\u5f62\u72b6\u53d8\u5316","text":"Python<pre><code>def forward(self, q, k, v, mask=None):\n    batch_size, sequence_length, model_dim = q.shape\n\n    # [B, L, d_model] \u2192 \u7ebf\u6027\u6295\u5f71 \u2192 [B, L, H*d_k] \u2192 view \u2192 [B, L, H,d_k] \u2192 transpose  \u2192 [B, H, L, d_k]\n    q = self.q_proj(q).view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n    # [B, L, d_model] \u2192 \u7ebf\u6027\u6295\u5f71 \u2192 [B, L, H*d_k] \u2192 view \u2192 [B, L, H,d_k] \u2192 transpose  \u2192 [B, H, L, d_k]\n    k = self.k_proj(k).view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n    # [B, L, d_model] \u2192 \u7ebf\u6027\u6295\u5f71 \u2192 [B, L, H*d_v] \u2192 view \u2192 [B, L, H,d_v] \u2192 transpose  \u2192 [B, H, L, d_v]\n    v = self.v_proj(v).view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n\n    # [B, H, L, d_k] \u00d7 [B, H, d_k, S] \u2192 \u77e9\u9635\u4e58\u6cd5(torch.matmul) \u2192 [B, H, L, S]\n    scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.head_dim)\n\n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, -1e09)\n\n    # [B, H, L, S] \u2192 softmax \u2192 [B, H, L, S]\n    prob = F.softmax(scores, dim=-1)\n\n    prob = self.dropout(prob)\n\n    # [B, H, L, S] \u00d7 [B, H, S, d_v] \u2192 \u77e9\u9635\u4e58\u6cd5(torch.matmul) \u2192 [B, H, L, d_v] \u2192 \u8f6c\u7f6e(.transpose) \u2192 [B, L, H, d_v] \u2192 \u91cd\u5851(.view) \u2192 [B, L, d_model]\n    attn_weights = torch.matmul(prob, v).transpose(1, 2).contiguous().view(batch_size, sequence_length, model_dim)\n\n    # \u6062\u590d\u539f\u59cb\u7ef4\u5ea6\uff1a[B, L, d_model] \u2192 \u7ebf\u6027\u6295\u5f71 \u2192 [B, L, d_model]\n    output = self.o_proj(attn_weights)\n    return output\n</code></pre> <p>\u5f62\u72b6\u5206\u6790  </p> <p>\uff081\uff09\u67e5\u8be2\uff08queries\uff09\uff1a</p> <ul> <li><code>[B, L, d_model] \u2192 \u7ebf\u6027\u6295\u5f71(nn.Linear) \u2192 [B, L, H*d_k] \u2192 \u91cd\u5851(.view) \u2192 [B, L, H, d_k] \u2192 \u8f6c\u7f6e(.transpose) \u2192 [B, H, L, d_k]</code></li> <li>\u901a\u8fc7\u7ebf\u6027\u6295\u5f71\u5c06\u67e5\u8be2\u5411\u91cf\u6295\u5f71\u5230\u591a\u5934\u6ce8\u610f\u529b\u7a7a\u95f4\uff0c\u5e76\u91cd\u5851\u4e3a\u591a\u5934\u7684\u5f62\u72b6\u3002</li> </ul> Python<pre><code>q = self.q_proj(q).view(batch_size,sequence_length,self.num_heads,self.head_dim).transpose(1,2)\n</code></pre> <p>\uff082\uff09\u952e\uff08keys\uff09\uff1a  \\(D_Q = D_K \\triangleq d_k\\) </p> <ul> <li><code>[B, S, d_model] \u2192 \u7ebf\u6027\u6295\u5f71(nn.Linear) \u2192 [B, L, H*d_k] \u2192 \u91cd\u5851(.view) \u2192 [B, L, H, d_k] \u2192 \u8f6c\u7f6e(.transpose) \u2192 [B, H, L, d_k]</code></li> <li>\u901a\u8fc7\u7ebf\u6027\u6295\u5f71\u5c06\u952e\u5411\u91cf\u6295\u5f71\u5230\u591a\u5934\u6ce8\u610f\u529b\u7a7a\u95f4\uff0c\u5e76\u91cd\u5851\u4e3a\u591a\u5934\u7684\u5f62\u72b6\u3002</li> <li>\u66f4\u51c6\u786e\u7684\u8bb0\u53f7\uff0c\u8868\u793a QK\u7684\u7ef4\u5ea6\u5fc5\u987b\u76f8\u540c \\(\\triangleq d_k\\) \uff0cKV \u7684\u957f\u5ea6\u5fc5\u987b\u76f8\u540c \\(\\triangleq S\\)</li> </ul> <p>\u7b80\u5316\u7248</p> <ul> <li>\\(Q \\triangleq BLD_k\u3001  K \\triangleq BSD_k \u3001V \\triangleq BSD_v\\) </li> <li>linear \u3001view\u3001transpose \\(Q\uff1aBLD_k -&gt; BLHd_k -&gt; BHLd_k\\) </li> <li>\\(K\uff1aBSD_k -&gt; BSHd_k -&gt; BHSd_k\\) </li> <li>\\(V\uff1aBSD_v -&gt; BSHd_v -&gt; BHSd_v\\)</li> <li>torch.matmal \\(QK^T: BHLd_k \\cdot BHd_kS -&gt; BHLS\\)</li> <li>softmax \u3001dropout\u3001torch.matmul \\(sonftmax(QK^T)V -&gt;BHLS \\cdot BHSd_v -&gt; BHLd_v -&gt; transpose -&gt; view -&gt; BLD\\) </li> </ul> <p>\uff083\uff09\u503c\uff08values\uff09\uff1a</p> <ul> <li><code>[B, L, d_model] \u2192 \u7ebf\u6027\u6295\u5f71(nn.Linear) \u2192 [B, L, H*d_v] \u2192 \u91cd\u5851(.view) \u2192 [B, L, H, d_v] \u2192 \u8f6c\u7f6e(.transpose) \u2192 [B, H, L, d_v]</code></li> <li>\u901a\u8fc7\u7ebf\u6027\u6295\u5f71\u5c06\u503c\u5411\u91cf\u6295\u5f71\u5230\u591a\u5934\u6ce8\u610f\u529b\u7a7a\u95f4\uff0c\u5e76\u91cd\u5851\u4e3a\u591a\u5934\u7684\u5f62\u72b6\u3002</li> </ul> <p>\uff084\uff09\u8ba1\u7b97\u6ce8\u610f\u529b\u5f97\u5206\uff1a</p> Python<pre><code>scores = torch.matmul(q,k.transpose(-1,-2))//math.sqrt(self.head_dim)\n</code></pre> <ul> <li><code>[B, H, L, d_k] \u00d7 ([B, H, L, d_k] \u2192 transpose \u2192 [B, H, d_k, L]) \u2192 \u77e9\u9635\u4e58\u6cd5(torch.matmul) \u2192 [B, H, L, L]</code> </li> <li>\u901a\u8fc7\u77e9\u9635\u4e58\u6cd5\u8ba1\u7b97\u67e5\u8be2\u548c\u952e\u4e4b\u95f4\u7684\u70b9\u79ef\u6ce8\u610f\u529b\u5f97\u5206\uff0c\u5e76\u8fdb\u884c\u7f29\u653e\u3002</li> </ul> <p>\uff085\uff09\u8ba1\u7b97\u6ce8\u610f\u529b\u52a0\u6743\u503c\uff1a</p> <ul> <li><code>[B, H, L, L] \u2192 softmax \u2192 [B, H, L, L]</code></li> <li>\u901a\u8fc7softmax\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\u3002</li> </ul> <p>\uff086\uff09\u5e94\u7528\u6ce8\u610f\u529b\u6743\u91cd\uff1a</p> <ul> <li><code>[B, H, L, L] \u00d7 [B, H, L, d_v] \u2192 \u77e9\u9635\u4e58\u6cd5 \u2192 [B, H, L, d_v] \u2192 \u8f6c\u7f6e \u2192 [B, L, H, d_v] \u2192 \u91cd\u5851 \u2192 [B, L, d_model]</code></li> <li>\u901a\u8fc7\u77e9\u9635\u4e58\u6cd5\u5c06\u6ce8\u610f\u529b\u6743\u91cd\u5e94\u7528\u4e8e\u503c\u5411\u91cf\uff0c\u5e76\u91cd\u5851\u4e3a\u539f\u59cb\u5f62\u72b6\u3002</li> </ul> <p>\uff087\uff09\u8f93\u51fa\uff1a \u8fd8\u539f\u7ef4\u5ea6</p> <ul> <li><code>[B, L, d_model] \u2192 \u7ebf\u6027\u6295\u5f71 \u2192 [B, L, d_model]</code></li> <li>\u901a\u8fc7\u7ebf\u6027\u6295\u5f71\u5c06\u5408\u5e76\u7684\u8f93\u51fa\u6062\u590d\u5230\u539f\u59cb\u7ef4\u5ea6\u3002</li> </ul> <p>\ud83d\udce2 \u7b80\u5316\u7248</p> <ul> <li>\\(Q \\triangleq BLD_k\u3001  K \\triangleq BSD_k \u3001V \\triangleq BSD_v\\) </li> <li>linear \u3001view\u3001transpose \\(Q\uff1aBLD_k -&gt; BLHd_k -&gt; BHLd_k\\) </li> <li>\\(K\uff1aBSD_k -&gt; BSHd_k -&gt; BHSd_k\\) </li> <li>\\(V\uff1aBSD_v -&gt; BSHd_v -&gt; BHSd_v\\)</li> <li>torch.matmal \\(QK^T: BHLd_k \\cdot BHd_kS -&gt; BHLS\\)</li> <li>softmax \u3001dropout\u3001torch.matmul \\(sonftmax(QK^T)V -&gt;BHLS \\cdot BHSd_v -&gt; BHLd_v -&gt; transpose -&gt; view -&gt; BLD\\) </li> </ul> <p>\u5b8c\u6574\u7684\u4ee3\u7801\uff0c\u5f97\u4f1a\u5440</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self,model_dim,num_heads,dropout=0.1):\n        super().__init__()\n        self.model_dim = model_dim\n        self.num_heads = num_heads\n        self.head_dim = model_dim // num_heads\n\n        self.q_proj = nn.Linear(model_dim,model_dim)\n        self.k_proj = nn.Linear(model_dim,model_dim)\n        self.v_proj = nn.Linear(model_dim,model_dim)\n\n        self.dropout = nn.Dropout(dropout)\n\n        self.o_proj = nn.Linear(model_dim,model_dim)\n\n    def forward(self,q,k,v,mask=None):\n\n        batch_size,sequence_length,model_dim = q.shape\n\n        q = self.q_proj(q).view(batch_size,sequence_length,self.num_heads,self.head_dim).transpose(1,2)\n        k = self.k_proj(k).view(batch_size,sequence_length,self.num_heads,self.head_dim).transpose(1,2)\n        v = self.v_proj(v).view(batch_size,sequence_length,self.num_heads,self.head_dim).transpose(1,2)\n\n        scores = torch.matmul(q,k.transpose(-1,-2))//math.sqrt(self.head_dim)\n\n        if mask is not None:\n            scores = scores.masked_fill(mask==0,-1e09)\n\n        prob = F.softmax(scores,dim=-1)\n\n        prob = self.dropout(prob)\n\n        attn_weights = torch.matmul(prob,v).transpose(1,2).contiguous().view(batch_size,sequence_length,model_dim)\n\n        output = self.o_proj(attn_weights)\n        return output\n\nmodel_dim = 512 \nnum_heads = 8\nmha = MultiHeadAttention(model_dim=model_dim, num_heads=num_heads, dropout=0.1)\nbatch_size = 10\nsequence_length = 60\nq = torch.randn(batch_size, sequence_length, model_dim)\nk = torch.randn(batch_size, sequence_length, model_dim)\nv = torch.randn(batch_size, sequence_length, model_dim)\n\nmask = None\noutput = mha(q, k, v, mask)\nprint(output.shape)  # \u8f93\u51fa\u7684\u5f62\u72b6\u5e94\u8be5\u662f(batch_size, sequence_length, model_dim)\n</code></pre>"},{"location":"Reproduction/CodeRepo/2_transformer/","title":"\u4ece\u73b0\u5b9e\u751f\u6d3b\u7684\u89d2\u5ea6\u770b Transformer","text":""},{"location":"Reproduction/CodeRepo/2_transformer/#transformer","title":"\u4ece\u73b0\u5b9e\u751f\u6d3b\u7684\u89d2\u5ea6\u770b Transformer","text":"2025-03-20 15:53:262025-09-28 12:54:03 <p> \u7ea6 1301 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 7 \u5206\u949f</p> <p>\u539f\u59cb Transformer \u7684\u7ed3\u6784</p> <p></p> <p>\u7f16\u7801\u5668\uff0c\u89e3\u7801\u5668\uff0c\u7f16\u7801\u5668\u63a5\u6536\u7684 input \u662f word embedding + positional embedding\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u3002\u89e3\u7801\u5668\u63a5\u6536\u7684 \u8f93\u5165\u662f output\uff0c\u9884\u6d4b\u90e8\u5206\uff0c\u540c\u6837\u662f word embedding+positional embedding\uff0c\u7136\u540e\u5206\u522b\u7ecf\u8fc7\u89e3\u7801\u5668\u8f93\u5165\u7684 \u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ee5\u53ca\u548c\u7f16\u7801\u5668\u8f93\u51fa \u7684 \u4ea4\u53c9\u6ce8\u610f\u529b\uff0c\u6700\u540e\u7ecf\u8fc7 \u5168\u8fde\u63a5\u5c42\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u3002</p> <p>\u9996\u5148\u5f3a\u8c03\u4e00\u4e0b\u5173\u4e8eTransformer \u4e3a\u4ec0\u4e48\u662f\u6ce8\u610f\u529b\u673a\u5236\u548c\u5168\u8fde\u63a5\u5c42\u7684\u8bbe\u8ba1\uff1f</p> <p>\u9996\u5148\uff0cTransformer \u5728 NLP\u4e2d\u63a5\u6536\u7684\u6570\u636e\u683c\u5f0f \u662f [B,L,D]\uff0cbatch size\uff0c\u4e00\u4e2a batch \u4e2d\u6709\u591a\u5c11\u4e2a\u53e5\u5b50\uff0c\u4e00\u4e2a\u53e5\u5b50\u4e2d\u6709\u51e0\u4e2a\u8bcd L\uff0c\u6bcf\u4e2a\u8bcd\u7684\u5d4c\u5165D\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e2a\u8bcd\u7528\u957f\u5ea6\u4e3a\u591a\u5c11\u7684\u5411\u91cf\u8868\u793a</p> <p>\u6700\u76f4\u89c2\u7684\u8bb2\u89e3\uff0c\u5c31\u662f \u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c L \u5c42\u9762\u7684\u4ea4\u4e92\uff0c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c D \u5c42\u9762\u7684\u4ea4\u4e92\u3002</p> <p>L \u5c42\u9762\u4e5f\u5c31\u662f\u6ce8\u610f\u5230\u4e86 \u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u4ea4\u4e92\uff0cD \u5c42\u9762\u5c31\u662f\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7279\u5f81\u7684\u4ea4\u4e92 </p> <p>\u5728L\u5c42\u9762\uff08\u5355\u8bcd\u5c42\u9762\uff09\u8fdb\u884c\u4ea4\u4e92\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u5355\u8bcd\u5bf9\u5176\u4ed6\u5355\u8bcd\u7684\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u6355\u6349\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b</p> <p>\u5728D\u5c42\u9762\uff08\u5373\u5355\u8bcd\u5d4c\u5165\u7684\u7279\u5f81\u5c42\u9762\uff09\u8fdb\u884c\u4ea4\u4e92\uff0c\u5bf9\u6bcf\u4e2a\u5355\u8bcd\u7684\u5d4c\u5165\u5411\u91cf\u8fdb\u884c\u975e\u7ebf\u6027\u53d8\u6362\uff0c\u6355\u6349\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u7279\u5f81\u4ea4\u4e92 </p> <p>\u5bf9\u5e94\u5230\u65f6\u95f4\u5e8f\u5217\u4e2d</p> <p>1\ufe0f\u20e3 \u6807\u51c6 \u8f93\u5165 \u683c\u5f0f\u4e5f\u662f BLD\uff0c\u5177\u4f53\u7684\u89e3\u91ca\uff1a </p> <p>B = 32 (\u6279\u91cf\u5927\u5c0f\uff0c32\u4e2a\u65f6\u95f4\u5e8f\u5217\u6837\u672c) L = 36 (\u6bcf\u4e2a\u6837\u672c\u670936\u4e2a\u65f6\u95f4\u6b65\uff0c\u5982\u8fc7\u53bb36\u5929\u7684\u6570\u636e) D = 7 (\u6bcf\u4e2a\u65f6\u95f4\u6b65\u67097\u4e2a\u7279\u5f81\uff0c\u5982\u5bf9\u4e8e\u80a1\u7968\u53ef\u80fd\u5305\u62ec\u5f00\u76d8\u4ef7\u3001\u6536\u76d8\u4ef7\u3001\u6700\u9ad8\u4ef7\u3001\u6700\u4f4e\u4ef7\u3001\u4ea4\u6613\u91cf\u7b49)</p> <p>2\ufe0f\u20e3 \u5904\u7406   \u6ce8\u610f\u529b\u673a\u5236</p> <p>\u7f16\u7801\u5668\u4e2d\uff0c\u6ce8\u610f\u529b\u5728\u6240\u670936\u4e2a\u65f6\u95f4\u6b65\u4e4b\u95f4\u5efa\u7acb\u8fde\u63a5 \u89e3\u7801\u5668\u4e2d\uff0c\u6ce8\u610f\u529b\u65e2\u5728\u9884\u6d4b\u5e8f\u5217\u5185\u90e8\u5efa\u7acb\u8fde\u63a5\uff0c\u4e5f\u4e0e\u7f16\u7801\u5668\u8f93\u51fa\u5efa\u7acb\u8fde\u63a5</p> <p>\u65f6\u95f4\u6b65\u4e4b\u95f4\u7684\u5efa\u6a21 \u53ef\u4ee5 \u53d1\u73b0\u80a1\u7968\u4ef7\u683c\u6bcf\u5468\u4e94\u53ef\u80fd\u4e0b\u8dcc\uff0c\u6216\u8005\u6bcf\u6708\u521d\u53ef\u80fd\u4e0a\u6da8\u7684\u6a21\u5f0f</p> <p>3\ufe0f\u20e3 \u5904\u7406  \u524d\u9988\u5168\u8fde\u63a5\u5c42</p> <p>\u5904\u7406\u6bcf\u4e2a\u65f6\u95f4\u6b65\u51857\u4e2a\u7279\u5f81\u4e4b\u95f4\u7684\u5173\u7cfb</p> <p>\u4f8b\u5982\uff0c\u4ea4\u6613\u91cf\u4e0e\u4ef7\u683c\u53d8\u52a8\u7684\u5173\u7cfb\uff0c\u6216\u5f00\u76d8\u4ef7\u4e0e\u6536\u76d8\u4ef7\u7684\u5173\u7cfb</p> <p>\u8bf6\uff0c\u8bf4\u8d77\u8fd9\u4e2a\uff0c\u5173\u4e8e\u7528\u73b0\u5b9e\u4f8b\u5b50\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\uff0c</p> <p>\u9996\u5148\uff0c\u5377\u79ef\u662f\u4ec0\u4e48\u610f\u601d\uff1f </p> <p>\u5047\u5982\u6211\u4eec\u8981\u8ba4\u8bc6\u4e00\u4e2a\u4ebaA\uff0cB \u662f A \u7684\u76f4\u63a5\u670b\u53cb\uff0c\u5f62\u6210\u4e86B \u5bf9 A \u7684\u7b2c\u4e00\u6b21\u8ba4\u8bc6\uff0cB \u5c31\u76f8\u5f53\u4e8e\u5377\u79ef\u6838\u4e86\uff0c\u90a3\u76f4\u63a5\u8ba4\u8bc6 A\u7684\u80af\u5b9a\u4e0d\u6b62\u4e00\u4e2a\u4eba\uff0c\u8fd8\u6709B1\uff0cB2\uff0cB3...\u7b49\uff0c\u6bcf\u4e2a\u4eba\u5bf9\u5f62\u6210\u4e86\u5bf9 A \u7684\u7b2c\u4e00\u6b21\u8ba4\u8bc6\uff0c\u7236\u6bcd\u8ba4\u8bc6 A\u66f4\u5173\u6ce8\u751f\u6d3b\u5c42\u9762\uff0c\u5b66\u6821\u4e2d\u76f4\u63a5\u8ba4\u8bc6\u7684 A \u66f4\u5173\u4e8e\u4e3a\u4eba\u5904\u4e8b\u90e8\u5206\uff0c\u5de5\u4f5c\u4e2d\u76f4\u63a5\u8ba4\u8bc6\u7684 A \u66f4\u5173\u4e8e A \u7684\u751f\u4ea7\u6027\u3002\u8fd9\u91cc\u76f4\u63a5\u8ba4\u8bc6 A \u7684B1\uff0cB2\uff0cB3...\u5c31\u662f\u6bcf\u4e00\u5c42\u4e2d \u5377\u79ef\u6838\u7684\u4e2a\u6570\u3002\u9664\u4e86\u76f4\u63a5\u8ba4\u8bc6 A \u7684\uff0c\u8fd8\u6709\u901a\u8fc7\u76f4\u63a5\u8ba4\u8bc6 A \u7684\u4ebaB \u8ba4\u8bc6 A\uff0c\u8fd9\u6ce2\u4eba\u53eb C\uff0c\u90a3\u8fd8\u6709\u901a\u8fc7 C \u8ba4\u8bc6 A \u7684\uff0c\u90a3 C \u53c8\u8ba4\u8bc6 D\uff0cD \u53c8\u901a\u8fc7 C \u8ba4\u8bc6 A\u3002\u9664\u4e86\u522b\u4eba\u8ba4\u8bc6 A\uff0cA \u81ea\u5df1\u4e5f\u6709\u5bf9\u81ea\u5df1\u7684\u8ba4\u8bc6\u3002</p> <p>Transformer\u662f\u4ec0\u4e48\u610f\u601d\uff1f</p> <p>\u9664\u4e86\u521a\u521a\u8bf4\u7684 \u6ce8\u610f\u529b\u673a\u5236\u548c\u524d\u9988\u5168\u8fde\u63a5\u5c42\u7684\u7406\u89e3\uff0c\u8fd8\u6709 Encoder \u3001Decoder \u3001\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u7684\u7406\u89e3\u3002</p> <ul> <li> Encoder&amp;Decoder \u7684\u4ea4\u4e92\u600e\u4e48\u7406\u89e3\uff1f</li> </ul> <p>\u9996\u5148\uff0c\u6574\u4f53\u4e0a\u7684\u8fd9\u4e2a\u56fe\uff1a</p> <p></p> <p>\u7f16\u7801\u5668\u76f8\u5f53\u4e8e\u7532\u65b9\uff0c\u89e3\u7801\u5668\u76f8\u5f53\u4e8e\u4e59\u65b9\uff0c\u7532\u65b9\u6709\u9700\u6c42\uff0c\u81ea\u5df1\u516c\u53f8\u5185\u90e8\u4e00\u7ea7\u4e00\u7ea7\u6c9f\u901a\uff0c\u4ece\u6700\u5f00\u59cb\u7684\u60f3\u6cd5\u6700\u7ec8\u5f62\u6210\u65b9\u6cd5\u4ea4\u7ed9\u6700\u540e\u4e00\u4e2a\u4eba\uff0c\u8fd9\u4e2a\u4eba\u53bb\u548c\u4e59\u516c\u53f8\u6c9f\u901a\uff0c\u4e59\u516c\u53f8\u53c8\u6709\u5f88\u591a\u4e2a\u90e8\u5206\uff0c\u6bcf\u4e2a\u90e8\u5206\u5206\u522b\u5b8c\u6210\u7532\u516c\u53f8\u63d0\u51fa\u7684\u65b9\u6848\u7684\u4e00\u90e8\u5206\uff0c\u8fd9\u4e00\u4e2a\u8fc7\u7a0b\u4e2d\u9700\u8981\u4e0d\u65ad\u7684\u4e0e\u7532\u516c\u53f8\u624b\u62ff\u6700\u7ec8\u65b9\u6848\u7684\u4eba\u4e0d\u65ad\u6c9f\u901a\uff0c\u6700\u7ec8\u4e59\u516c\u53f8\u5b8c\u6210\u65b9\u6848\u3002</p> <ul> <li> \u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u600e\u4e48\u7406\u89e3</li> </ul> <p>\u5bf9\u4e8e BLD \u7684\u5e8f\u5217\uff0c\u9996\u5148\u660e\u767d\u7684\u662f\uff0c\u90a3\u4e2a\u7ef4\u5ea6\u5206\u591a\u5934\u4e86\uff0c\u662f D \u7ef4\u5ea6\u5206\u6210 num head\u7ef4\u5ea6\u548c head dim\uff0c\u5176\u4e2d num head \u00d7 head dim = embedding dim\uff08D\uff09\uff0c\u76f8\u5f53\u4e8e\u4ec0\u4e48\u610f\u601d\uff0c\u4e00\u4e2a\u4eba\u5b66\u77e5\u8bc6\uff08B =1\uff09\uff0cL \u662f\u8981\u5b66\u7684\u51e0\u672c\u4e66\uff0cD \u662f\u6bcf\u672c\u4e66\u6709\u51e0\u4e2a\u7ae0\u8282\uff0c\u4e00\u822c\u662f\u4e00\u4e2a\u8001\u5e08\u6559\u6211\u4eec\u5b66\u4e00\u6574\u672c\u4e66\uff0c\u4f46\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u7684\u610f\u601d\u662f\uff0c\u4e00\u672c\u4e66\u7684\u51e0\u4e2a\u7ae0\u8282\uff0c\u5206\u5f00\uff0c\u6bd4\u5982\u7b2c\u4e00\u4e2a\u8001\u5e08\u6559\u7b2c\u4e00\u7ae0\u548c\u7b2c\u4e8c\u7ae0\uff0c\u7b2c\u4e8c\u4e2a\u8001\u5e08\u6559\u7b2c\u4e09\u7ae0\u548c\u7b2c\u56db\u7ae0\uff0c\u6700\u540e\u4e24\u5f20\u7b2c\u4e09\u4e2a\u8001\u5e08\u6559\uff0c\u8fd9\u6837\u5b66\u4e60\u7684\u65f6\u5019\uff0c\u540c\u6837\u662f\u4e00\u4e2a\u5b66\u671f\uff0c\u4e00\u4e2a\u8001\u5e08\u53ea\u9700\u8981\u5173\u6ce8\u4e24\u7ae0\u7684\u5185\u5bb9\uff0c\u5bf9\u4e8e\u8bfe\u7a0b\u8282\u594f\u7684\u628a\u63e1\u77e5\u8bc6\u7406\u89e3\u7684\u66f4\u900f\u5f7b\uff0c\u6548\u679c\u4f1a\u6bd4\u4e00\u4e2a\u8001\u5e08\u6559\u4e00\u6574\u672c\u4e66\u7684\u5185\u5bb9\u8981\u597d\u4e00\u4e9b\u3002</p> <p>B=3\uff0c\u5c31\u662f\u73ed\u91cc\u7684 3 \u4e2a\u4eba\uff0c\u6bcf\u4e2a\u4eba\u8fd9\u5b66\u671f\u90fd\u8981\u4e0a\u8fd9\u51e0\u672c\u8bfe\uff0c\u540c\u6837\u7684 LD\u3002</p> <p>\u6700\u540e\u4e00\u4e2a linear \u5c42\uff0c\u5e94\u8be5\u662f\u4e3a\u4e86\u8fd8\u539f\u539f\u59cb\u7ef4\u5ea6\u7684\u3002</p>"},{"location":"Reproduction/CodeRepo/3_fourier/","title":"DFT\u4f8b\u9898","text":""},{"location":"Reproduction/CodeRepo/3_fourier/#dft","title":"DFT\u4f8b\u9898","text":"2025-03-27 09:20:382025-09-28 12:54:03 <p> \u7ea6 513 \u4e2a\u5b57  3 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>\u8ba8\u8bba </p> <p>\u590d\u6570\u3001\u590d\u6307\u6570\u3001\u4e09\u89d2\u51fd\u6570\u7684\u76f8\u4e92\u5bf9\u5e94 </p> <p>\\(a+bi\\)</p> <p>= \\(\\sqrt{a^2 + b^2} e^{i {arctan\\frac{b}{a}}}\\) </p> <p>= \\(\\sqrt{a^2 + b^2}(\\cos {(\\arctan\\frac{b}{a})}+ i \\sin {(\\arctan\\frac{b}{a})} )\\) </p> <p>\\(\\cos {(\\arctan\\frac{b}{a})} = \\frac{a}{\\sqrt{a^2 + b^2}}\\) </p> <p>\\(\\sin {(\\arctan\\frac{b}{a})} = \\frac{b}{\\sqrt{a^2 + b^2}}\\)</p> <p>\u56fe\u5f62\uff1a</p> <p> </p> <p>\u95ee\u9898\u63cf\u8ff0\uff1a</p> <p>\u5bf9[4,3,2,1]\u8fdb\u884c DFT</p> Python<pre><code>from scipy.fft import fft\nfft([4,3,2,1])\n</code></pre> <p>out\uff1a</p> Python<pre><code>array([10.-0.j,  2.-2.j,  2.-0.j,  2.+2.j])\n</code></pre> <p>\u6570\u5b66\u4e0a\u7684\u8ba1\u7b97\uff1a</p> <ul> <li>\\(N=4\\)\uff0c\u57fa\u6ce2\u9891\u7387 \\(\\Omega = \\frac{2\\pi}{N} = \\frac{\\pi}{2}\\)\uff0c\u57fa\u6ce2\u5206\u91cf\u4e3a\uff1a\\(1\\Omega n\\)</li> <li>\u8c10\u6ce2\u9891\u7387\u5206\u522b\u4e3a\uff1a$2\\Omega $   \u3001$3\\Omega $</li> <li>\u8c10\u6ce2\u5206\u91cf\uff08\\(k\\Omega n\\)\uff09\u5206\u522b\u4e3a\uff1a$2\\Omega n $ \u3001 $ 3\\Omega n $</li> </ul> <p>\u5229\u7528\u516c\u5f0f\uff1a\\(X[k]=w^{kn}x_n\\) </p> <p>\\(w=e^{-i\\Omega} = e^{-i\\frac{\\pi}{2}}=-i\\)   \u51e0\u4f55\u610f\u4e49\uff0c\u590d\u5e73\u9762\u53cd\u65b9\u5411\u65cb\u8f6c 90\u00b0</p> \\[ w^{kn} = \\begin{bmatrix} w^{0\u00d70} &amp; w^{0\u00d71} &amp; w^{0\u00d72} &amp; w^{0\u00d73}\\\\w^{1\u00d70} &amp;w^{1\u00d71} &amp; w^{1\u00d72} &amp; w^{1\u00d73}\\\\w^{2\u00d70} &amp; w^{2\u00d71} &amp; w^{2\u00d72} &amp; w^{2\u00d73}\\\\w^{3\u00d70} &amp;w^{3\u00d71} &amp; w^{3\u00d72} &amp; w^{3\u00d73} \\end{bmatrix} \\\\\\\\\\quad = \\begin{bmatrix} w^{0} &amp; w^{0} &amp; w^{0} &amp; w^{0}\\\\w^{0} &amp; w^{1} &amp; w^{2} &amp; w^{3}\\\\w^{0} &amp; w^{2} &amp; w^{4} &amp; w^{6}\\\\w^{0} &amp; w^{3} &amp; w^{6} &amp; w^{9} \\end{bmatrix} \\quad = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1\\\\ 1 &amp; w^{1} &amp; w^{2} &amp; w^{3}\\\\1 &amp; w^{2} &amp; w^{4} &amp; w^{6}\\\\1 &amp; w^{3} &amp; w^{6} &amp; w^{9} \\end{bmatrix} \\\\\\\\= \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1\\\\1 &amp; -i &amp; i^{2} &amp; -i^{3}\\\\1 &amp; i^{2} &amp; i^{4} &amp; i^{6}\\\\1 &amp; -i^{3} &amp; i^{6} &amp; -i^{9} \\end{bmatrix} \\] <p>\u5173\u4e8e\u590d\u6570 \\(i\\) \u7684\u5468\u671f\u6027\uff1a</p> <ul> <li>\\(i^{0}=i^{4n}=1\\)</li> <li>\\(i^{1}=i^{1+4n}=i\\)</li> <li>\\(i^{2}=i^{2+4n}=-1\\)</li> <li>\\(i^{3}=i^{3+4n}=-i\\)</li> </ul> <p>\u6240\u4ee5\uff1a</p> \\[\\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1\\\\ 1 &amp; -i &amp; i^{2} &amp; -i^{3}\\\\1 &amp; i^{2} &amp; i^{4} &amp; i^{6}\\\\1 &amp; -i^{3} &amp; i^{6} &amp; -i^{9} \\end{bmatrix} =  \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1\\\\1 &amp; -i &amp; i^{2} &amp; -i^{3}\\\\1 &amp; i^{2} &amp; i^{4} &amp; i^{2}\\\\1 &amp; -i^{3} &amp; i^{2} &amp; -i \\end{bmatrix} =  \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1\\\\1 &amp; -i &amp; -1 &amp; -i\\\\1 &amp; -1 &amp; 1 &amp; -1\\\\1 &amp; -i &amp; -1 &amp; -i \\end{bmatrix}\\] <p>\u6240\u4ee5 DFT\uff1a</p> \\[\\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1\\\\1 &amp; -i &amp; -1 &amp; i\\\\1 &amp; -1 &amp; 1 &amp; -1\\\\1 &amp; i &amp; -1 &amp; -i \\end{bmatrix}\\begin{bmatrix} 4\\\\3\\\\2\\\\1  \\end{bmatrix}=\\begin{bmatrix} 10\\\\4-3i-2+i\\\\4-3+2-1\\\\4+3i-2-i  \\end{bmatrix}=\\begin{bmatrix} 10\\\\2-2i\\\\2\\\\2+2i  \\end{bmatrix}\\] <p>\u5b83\u7684\u590d\u6307\u6570\u5f62\u5f0f\u3001\u4e09\u89d2\u51fd\u6570\u5f62\u5f0f\u3001\u8f85\u52a9\u89d2\u5f62\u5f0f\u4ee5\u53ca\u5bf9\u5e94\u7684\uff1a\u5e45\u5ea6\u8c31\u3001\u76f8\u4f4d\u8c31</p> <p></p> <p>\u76ee\u524d\uff0c\u5206\u6790\u5230\u8fd9\u91cc\uff0c\u8fd8\u6709\u4e00\u4e9b\u6bd4\u8f83\u5947\u602a\u7684\u5730\u65b9</p>"},{"location":"Reproduction/CodeRepo/4_self_/","title":"\u81ea\u603b\uff1a\u6252\u6a21\u5757","text":""},{"location":"Reproduction/CodeRepo/4_self_/#_1","title":"\u81ea\u603b\uff1a\u6252\u6a21\u5757","text":"2025-04-10 20:13:162025-09-28 12:54:03 <p> \u7ea6 354 \u4e2a\u5b57  467 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 8 \u5206\u949f</p>"},{"location":"Reproduction/CodeRepo/4_self_/#autoformer","title":"Autoformer \u5e8f\u5217\u5206\u89e3\u6a21\u5757","text":"<p>\u6a21\u5757\u56fe\u6570\u636e\u6d41\u52a8\uff1a</p> <p> </p> <p>\u4ee3\u7801\u6458\u51fa\uff1a</p> <p>\u4f7f\u7528\u8bf4\u660e\uff1a </p> Bash<pre><code>\u8f93\u5165\u5e8f\u5217\u5f62\u72b6[B,S,D]: torch.Size([32, 96, 7])\n\u5b63\u8282\u6027\u5206\u91cf\u5f62\u72b6[B,S,D]: torch.Size([32, 96, 7])\n\u8d8b\u52bf\u6027\u5206\u91cf\u5f62\u72b6[B,S,D]: torch.Size([32, 96, 7])\n</code></pre> <ul> <li>\u8f93\u5165\u8f93\u51fa\u5f62\u72b6\u76f8\u540c</li> <li>\u5728\u63d0\u53d6\u8d8b\u52bf\u6027\u5206\u91cf\u65f6\uff0c\u7528\u7684\u79fb\u52a8\u5e73\u5747\uff0c\u540c\u65f6\u63d0\u53d6\u7684\u7b2c\u4e00\u4e2a\u65f6\u95f4\u548c\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u8fdb\u884c\u4e86 \u590d\u5236\u586b\u5145\uff0c\u4fdd\u8bc1 \u79fb\u52a8\u5e73\u5747\u4ee5\u540e\u8f93\u5165\u548c\u8f93\u51fa\u5e8f\u5217\u957f\u5ea6\u4fdd\u6301\u4e0d\u53d8</li> <li>\u5b63\u8282\u6027\u5206\u91cf\u76f4\u63a5\u662f <code>\u539f\u59cb\u5e8f\u5217 - \u8d8b\u52bf\u6027\u5206\u91cf</code> </li> <li>\u6309\u7167\u5b9e\u9645\u60c5\u51b5\uff0c\u4fee\u6539 <code>B, L, D  = 32, 96, 7</code> \u548c <code>kernel_size = 25</code> \u5373\u53ef</li> <li>1D avgPool \u4f5c\u7528\u5728 <code>dim = -1</code></li> </ul> Python<pre><code>import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\n\nclass moving_avg(nn.Module):\n    \"\"\"\n    Moving average block to highlight the trend of time series\n    \"\"\"\n    def __init__(self, kernel_size, stride):\n        super(moving_avg, self).__init__()\n        self.kernel_size = kernel_size\n        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0) # AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n\n    def forward(self, x):\n        # padding on the both ends of time series\n\n        # \u63d0\u53d6\u7b2c\u4e00\u4e2a\u65f6\u95f4\u6b65\u5e76\u91cd\u590d\uff0c\u7528\u4e8e\u524d\u7aef\u586b\u5145 x.shape =  [32, 36, 7]\n        #  [B, L, D] -&gt; [B, 1, D] -&gt; [B, (kernel_size-1)//2, D]\n        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1) \n\n        # \u63d0\u53d6\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u5e76\u91cd\u590d\uff0c\u7528\u4e8e\u540e\u7aef\u586b\u5145\n        # [B, L, D] -&gt; [B, 1, D] -&gt; [B, (kernel_size-1)//2, D]\n        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n\n        # \u8fde\u63a5\u586b\u5145\u90e8\u5206\u4e0e\u539f\u5e8f\u5217\n        # [B, (k-1)//2, D] + [B, L, D] + [B, (k-1)//2, D] -&gt; [B, L+(k-1), D]\n        x = torch.cat([front, x, end], dim=1)\n\n        # \u8f6c\u7f6e\u5e76\u5e94\u7528\u4e00\u7ef4\u5e73\u5747\u6c60\u5316\n        # [B, L+(k-1), D] -&gt; [B, D, L+(k-1)] -&gt; [B, D, L]\n        # \u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3akernel_size\uff0c\u6b65\u957f\u4e3a1\uff0c\u8f93\u51fa\u957f\u5ea6\u4e3a(L+(k-1)-k+1)=L \uff08length + 2P - K + 1\uff09\n        x = self.avg(x.permute(0, 2, 1))\n\n        # \u8f6c\u7f6e\u56de\u539f\u59cb\u7ef4\u5ea6\u987a\u5e8f [B, D, L] -&gt; [B, L, D]\n        x = x.permute(0, 2, 1)\n        return x\n\n\nclass series_decomp(nn.Module):\n    \"\"\"\n    Series decomposition block\n    \"\"\"\n    def __init__(self, kernel_size):\n        super(series_decomp, self).__init__()\n        self.moving_avg = moving_avg(kernel_size, stride=1)\n\n    def forward(self, x):\n\n        # \u8ba1\u7b97\u79fb\u52a8\u5e73\u5747\uff0c\u63d0\u53d6\u5e8f\u5217\u8d8b\u52bf\u5206\u91cf\n        # x \u5f62\u72b6[B, L, D] -&gt; moving_mean\u5f62\u72b6[B, L, D]\n        #  moving_avg\u5185\u90e8\u4f1a\u8fdb\u884c\u586b\u5145\uff0c\u4fdd\u8bc1\u8f93\u51fa\u5f62\u72b6\u4e0e\u8f93\u5165\u76f8\u540c\n        moving_mean = self.moving_avg(x)\n\n        # \u901a\u8fc7\u539f\u59cb\u5e8f\u5217\u51cf\u53bb\u8d8b\u52bf\u5206\u91cf\uff0c\u5f97\u5230\u6b8b\u5dee(\u5b63\u8282\u6027\u5206\u91cf)\uff0c\u9010\u5143\u7d20\u51cf\u6cd5\u64cd\u4f5c\n        # x\u5f62\u72b6[B, L, D] - moving_mean\u5f62\u72b6[B, L, D] -&gt; res\u5f62\u72b6[B, L, D]\n        res = x - moving_mean\n\n        # \u8fd4\u56de\u5b63\u8282\u6027\u5206\u91cf\u548c\u8d8b\u52bf\u5206\u91cf\uff0c\u5747\u4fdd\u6301\u539f\u59cb\u5f62\u72b6[B, L, D]\n        # \u7b2c\u4e00\u4e2a\u8fd4\u56de\u503cres\u662f\u5b63\u8282\u6027\u5206\u91cf\uff0c\u7b2c\u4e8c\u4e2a\u8fd4\u56de\u503cmoving_mean\u662f\u8d8b\u52bf\u5206\u91cf\n        return res, moving_mean\n\n\n# init\n# Decomp\nkernel_size = 25\ndecomp = series_decomp(kernel_size)\n\nB, L, D  = 32, 96, 7\n\n# forward\nx_enc = torch.randn(B, L, D )\n# \u5bf9\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\uff0c\u5c06x_enc[B, L, D]\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6210\u5206\uff0c\u5f62\u72b6\u4fdd\u6301\u4e0d\u53d8\nseasonal_init, trend_init = decomp(x_enc) # \u5747\u4e3a[B, L, D]\n\nprint(\"\u8f93\u5165\u5e8f\u5217\u5f62\u72b6:\",x_enc.shape)\nprint(\"\u5b63\u8282\u6027\u5206\u91cf\u5f62\u72b6:\",seasonal_init.shape)\nprint(\"\u8d8b\u52bf\u6027\u5206\u91cf\u5f62\u72b6:\",trend_init.shape)\n</code></pre>"},{"location":"Reproduction/CodeRepo/4_self_/#segrnn","title":"SegRNN \u5e8f\u5217\u5206\u6bb5","text":"<p>\u6570\u636e\u6d41\u52a8\u56fe</p> <p> </p> <p>\u8f93\u5165&amp;\u8f93\u51fa</p> Bash<pre><code>\u8f93\u5165\u5e8f\u5217\u5f62\u72b6[B,S,D]:  torch.Size([32, 96, 7]) \noutputs.shape[B,P,D]: torch.Size([32, 720, 7])\n</code></pre> <p>\u8bf4\u660e\uff1a</p> <ul> <li>\u6765\u6e90\uff1aSegRNN github</li> <li>\u9700\u8981\u7684\u53c2\u6570\uff1a <code>batch_size\u3001 seq_len \u3001enc_in</code></li> <li>\u7279\u522b\u7684\u53c2\u6570\uff1a<code>seg_len</code>  \u8868\u793a\u5206\u6bb5\u957f\u5ea6\uff0c\u5177\u4f53\u5206\u51e0\u6bb5\u5728\u4ee3\u7801\u4e2d\u7684 init \u4e2d\u8ba1\u7b97\u3002</li> <li>\u8be5\u4ee3\u7801\u914d\u7f6e\u65f6 \u4f7f\u7528\u547d\u4ee4\u884c\u53c2\u6570\u8fdb\u884c\u914d\u7f6e</li> <li>\u540e\u9762\u5907\u4efd\u4e86\u591a\u6837\u5316\u914d\u7f6e\uff1a\u4f7f\u7528\u591a\u5361\u8fdb\u884c\u8bad\u7ec3</li> <li>\u8f93\u5165\u548c\u8f93\u51fa\u5206\u522b\u662f\u4ec0\u4e48\u610f\u601d\uff1a\u8f93\u5165\u4e0d\u591a\u8bf4\u4e86\uff0c\u8f93\u51fa\u7684\u662f[B,P,D]\uff0c\u5c31\u662f\u6839\u636e\u7ed9\u5b9a\u7684\u8f93\u5165\u5e8f\u5217\u9884\u6d4b\u7684\u672a\u6765\u65f6\u95f4\u6b65</li> <li>\u8fd9\u91cc\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c\u4e5f\u53ef\u4ee5</li> </ul> Python<pre><code>'''\nConcise version implementation that only includes necessary code\n'''\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, configs):\n        super(Model, self).__init__()\n\n        # get parameters\n        self.seq_len = configs.seq_len\n        self.pred_len = configs.pred_len\n        self.enc_in = configs.enc_in\n        self.d_model = configs.d_model\n        self.dropout = configs.dropout\n\n        self.seg_len = configs.seg_len\n        self.seg_num_x = self.seq_len//self.seg_len\n        self.seg_num_y = self.pred_len // self.seg_len\n\n\n        self.valueEmbedding = nn.Sequential(\n            nn.Linear(self.seg_len, self.d_model),\n            nn.ReLU()\n        )\n        self.rnn = nn.GRU(input_size=self.d_model, hidden_size=self.d_model, num_layers=1, bias=True,\n                              batch_first=True, bidirectional=False)\n        self.pos_emb = nn.Parameter(torch.randn(self.seg_num_y, self.d_model // 2))\n        self.channel_emb = nn.Parameter(torch.randn(self.enc_in, self.d_model // 2))\n        self.predict = nn.Sequential(\n            nn.Dropout(self.dropout),\n            nn.Linear(self.d_model, self.seg_len)\n        )\n\n    def forward(self, x):\n        # b:batch_size c:channel_size s:seq_len s:seq_len\n        # d:d_model w:seg_len n:seg_num_x m:seg_num_y\n        batch_size = x.size(0)\n\n        # normalization and permute     b,s,c -&gt; b,c,s\n        seq_last = x[:, -1:, :].detach()\n        x = (x - seq_last).permute(0, 2, 1) # b,c,s\n\n        # segment and embedding    b,c,s -&gt; bc,n,w -&gt; bc,n,d\n        x = self.valueEmbedding(x.reshape(-1, self.seg_num_x, self.seg_len))\n\n        # encoding\n        _, hn = self.rnn(x) # bc,n,d  1,bc,d\n\n        # m,d//2 -&gt; 1,m,d//2 -&gt; c,m,d//2\n        # c,d//2 -&gt; c,1,d//2 -&gt; c,m,d//2\n        # c,m,d -&gt; cm,1,d -&gt; bcm, 1, d\n        pos_emb = torch.cat([\n            self.pos_emb.unsqueeze(0).repeat(self.enc_in, 1, 1),\n            self.channel_emb.unsqueeze(1).repeat(1, self.seg_num_y, 1)\n        ], dim=-1).view(-1, 1, self.d_model).repeat(batch_size,1,1)\n\n        _, hy = self.rnn(pos_emb, hn.repeat(1, 1, self.seg_num_y).view(1, -1, self.d_model)) # bcm,1,d  1,bcm,d\n\n        # 1,bcm,d -&gt; 1,bcm,w -&gt; b,c,s\n        y = self.predict(hy).view(-1, self.enc_in, self.pred_len)\n\n        # permute and denorm\n        y = y.permute(0, 2, 1) + seq_last\n\n        return y\n\n# init\nimport argparse\nparser = argparse.ArgumentParser(description='Model family for Time Series Forecasting')\n\n# forecasting task\nparser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\nparser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\nparser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\nparser.add_argument('--enc_in', type=int, default=7, help='encoder input size') # DLinear with --individual, use this \nparser.add_argument('--d_model', type=int, default=512, help='dimension of model')\nparser.add_argument('--dropout', type=float, default=0.5, help='dropout')\nparser.add_argument('--seg_len', type=int, default=48, help='segment length')\n\nargs = parser.parse_args()\n\nmodel = Model(args).float()\n\nbatch_x = torch.randn(args.batch_size,args.seq_len,args.enc_in)\n# forward\noutputs = model(batch_x)\nprint(\"\u8f93\u5165\u5e8f\u5217\u5f62\u72b6[B,S,D]: \",batch_x.shape)\nprint(\"outputs.shape[B,P,D]:\",outputs.shape)\n</code></pre> <p>\u591a\u5361\u8bad\u7ec3</p> Python<pre><code>'''\nConcise version implementation that only includes necessary code\n'''\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self, configs):\n        super(Model, self).__init__()\n\n        # get parameters\n        self.seq_len = configs.seq_len\n        self.pred_len = configs.pred_len\n        self.enc_in = configs.enc_in\n        self.d_model = configs.d_model\n        self.dropout = configs.dropout\n\n        self.seg_len = configs.seg_len\n        self.seg_num_x = self.seq_len//self.seg_len\n        self.seg_num_y = self.pred_len // self.seg_len\n\n\n        self.valueEmbedding = nn.Sequential(\n            nn.Linear(self.seg_len, self.d_model),\n            nn.ReLU()\n        )\n        self.rnn = nn.GRU(input_size=self.d_model, hidden_size=self.d_model, num_layers=1, bias=True,\n                              batch_first=True, bidirectional=False)\n        self.pos_emb = nn.Parameter(torch.randn(self.seg_num_y, self.d_model // 2))\n        self.channel_emb = nn.Parameter(torch.randn(self.enc_in, self.d_model // 2))\n        self.predict = nn.Sequential(\n            nn.Dropout(self.dropout),\n            nn.Linear(self.d_model, self.seg_len)\n        )\n\n    def forward(self, x):\n        # b:batch_size c:channel_size s:seq_len s:seq_len\n        # d:d_model w:seg_len n:seg_num_x m:seg_num_y\n        batch_size = x.size(0)\n\n        # normalization and permute     b,s,c -&gt; b,c,s\n        seq_last = x[:, -1:, :].detach()\n        x = (x - seq_last).permute(0, 2, 1) # b,c,s\n\n        # segment and embedding    b,c,s -&gt; bc,n,w -&gt; bc,n,d\n        x = self.valueEmbedding(x.reshape(-1, self.seg_num_x, self.seg_len))\n\n        # encoding\n        _, hn = self.rnn(x) # bc,n,d  1,bc,d\n\n        # m,d//2 -&gt; 1,m,d//2 -&gt; c,m,d//2\n        # c,d//2 -&gt; c,1,d//2 -&gt; c,m,d//2\n        # c,m,d -&gt; cm,1,d -&gt; bcm, 1, d\n        pos_emb = torch.cat([\n            self.pos_emb.unsqueeze(0).repeat(self.enc_in, 1, 1),\n            self.channel_emb.unsqueeze(1).repeat(1, self.seg_num_y, 1)\n        ], dim=-1).view(-1, 1, self.d_model).repeat(batch_size,1,1)\n\n        _, hy = self.rnn(pos_emb, hn.repeat(1, 1, self.seg_num_y).view(1, -1, self.d_model)) # bcm,1,d  1,bcm,d\n\n        # 1,bcm,d -&gt; 1,bcm,w -&gt; b,c,s\n        y = self.predict(hy).view(-1, self.enc_in, self.pred_len)\n\n        # permute and denorm\n        y = y.permute(0, 2, 1) + seq_last\n\n        return y\n\n# init\nimport argparse\nparser = argparse.ArgumentParser(description='Model family for Time Series Forecasting')\n\n# forecasting task\nparser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\nparser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n# parser.add_argument('--label_len', type=int, default=0, help='start token length')  #fixed\nparser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\nparser.add_argument('--enc_in', type=int, default=7, help='encoder input size') # DLinear with --individual, use this \nparser.add_argument('--d_model', type=int, default=512, help='dimension of model')\nparser.add_argument('--dropout', type=float, default=0.5, help='dropout')\nparser.add_argument('--seg_len', type=int, default=48, help='segment length')\n\n# SegRNN\nparser.add_argument('--rnn_type', default='gru', help='rnn_type')\nparser.add_argument('--dec_way', default='pmf', help='decode way')\nparser.add_argument('--win_len', type=int, default=48, help='windows length')\nparser.add_argument('--channel_id', type=int, default=1, help='Whether to enable channel position encoding')\n\n# GPU\nparser.add_argument('--use_gpu', type=bool, default=False, help='use gpu')\nparser.add_argument('--gpu', type=int, default=0, help='gpu')\nparser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\nparser.add_argument('--devices', type=str, default='0,1', help='device ids of multile gpus')\n\nargs = parser.parse_args()\n\nargs.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n\nif args.use_gpu and args.use_multi_gpu:\n    args.devices = args.devices.replace(' ', '')\n    device_ids = args.devices.split(',')\n    args.device_ids = [int(id_) for id_ in device_ids]\n    args.gpu = args.device_ids[0]\n\n\nmodel = Model(args).float()\n\n\nif args.use_multi_gpu and args.use_gpu:\n    model = nn.DataParallel(model, device_ids=args.device_ids)\n\n\nbatch_x = torch.randn(args.batch_size,args.seq_len,args.enc_in)\n# forward\noutputs = model(batch_x)\nprint(\"\u8f93\u5165\u5e8f\u5217\u5f62\u72b6: \",batch_x.shape)\nprint(\"outputs.shape:\",outputs.shape)\n</code></pre>"},{"location":"Reproduction/CodeRepo/4_self_/#autoformer-enc_embedding","title":"Autoformer enc_embedding","text":"<p>\u8f93\u5165\u8f93\u51fa\uff1a</p> Bash<pre><code>\u8f93\u5165\u5e8f\u5217\u5f62\u72b6[B,S,D]:  torch.Size([32, 96, 7])\n\u8f93\u5165\u5e8f\u5217\u65f6\u95f4\u6233\u9884\u5904\u7406\u5f62\u72b6[B,S,freq]:  torch.Size([32, 96, 4])\noutputs.shape[B,S,d_model]: torch.Size([32, 96, 512])\n</code></pre> <ul> <li>\u4ee3\u7801\u8bf4\u660e\uff0c\u5b9e\u73b0\u4e86\uff1a </li> </ul> Python<pre><code>x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n</code></pre> <p>\u503c\u5d4c\u5165\u3001\u65f6\u95f4\u5d4c\u5165\u3001\u4f4d\u7f6e\u7f16\u7801</p> <ul> <li>\u6ca1\u4ec0\u4e48\u597d\u8bf4\u7684\uff0c\u8f93\u5165\u90fd\u901a\u8fc7\u547d\u4ee4\u884c\u53c2\u6570\u914d\u7f6e\u597d\u4e86</li> </ul> Python<pre><code>import torch\nfrom torch import nn\nimport math\n\n# \u4e3a\u4e86\u4fdd\u8bc1\u4e0d\u62a5\u7248\u672c\u9519\u8bef\ndef compared_version(ver1, ver2):\n    \"\"\"\n    :param ver1\n    :param ver2\n    :return: ver1&lt; = &gt;ver2 False/True\n    \"\"\"\n    list1 = str(ver1).split(\".\")\n    list2 = str(ver2).split(\".\")\n\n    for i in range(len(list1)) if len(list1) &lt; len(list2) else range(len(list2)):\n        if int(list1[i]) == int(list2[i]):\n            pass\n        elif int(list1[i]) &lt; int(list2[i]):\n            return -1\n        else:\n            return 1\n\n    if len(list1) == len(list2):\n        return True\n    elif len(list1) &lt; len(list2):\n        return False\n    else:\n        return True\n\n\nclass TokenEmbedding(nn.Module):\n    def __init__(self, c_in, d_model):\n        super(TokenEmbedding, self).__init__()\n        padding = 1 if compared_version(torch.__version__, '1.5.0') else 2\n        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n        # Conv1d(7, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n        for m in self.modules():\n            if isinstance(m, nn.Conv1d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n\n    def forward(self, x):\n        # x [B, L, D] \u2192 permute \u2192 [B, D, L] \u2192 \u5377\u79ef \u2192 [B, d_model, L] \u2192 transpose \u2192 [B, L, d_model]\n        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n        return x\n\nclass PositionalEmbedding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEmbedding, self).__init__()\n        # Compute the positional encodings once in log space.\n        pe = torch.zeros(max_len, d_model).float()\n        pe.require_grad = False\n\n        position = torch.arange(0, max_len).float().unsqueeze(1)\n        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return self.pe[:, :x.size(1)]\n\n\n\nclass TemporalEmbedding(nn.Module):\n    def __init__(self, d_model, embed_type='fixed', freq='h'):\n        super(TemporalEmbedding, self).__init__()\n\n         # \u5b9a\u4e49\u5404\u65f6\u95f4\u5355\u4f4d\u7684\u53ef\u80fd\u53d6\u503c\u6570\u91cf\n        minute_size = 4  # \u5206\u949f\u5d4c\u5165\u8868\u5927\u5c0f(\u6bcf15\u5206\u949f\u4e00\u4e2a\u7d22\u5f15)\n        hour_size = 24   # \u5c0f\u65f6\u5d4c\u5165\u8868\u5927\u5c0f(0-23\u5c0f\u65f6)\n        weekday_size = 7  # \u661f\u671f\u5d4c\u5165\u8868\u5927\u5c0f(\u661f\u671f\u4e00\u5230\u661f\u671f\u65e5)\n        day_size = 32     # \u65e5\u671f\u5d4c\u5165\u8868\u5927\u5c0f(1-31\u65e5)\n        month_size = 13   # \u6708\u4efd\u5d4c\u5165\u8868\u5927\u5c0f(1-12\u6708\uff0c0\u53ef\u80fd\u4f5c\u4e3a\u586b\u5145)\n\n        # \u6839\u636eembed_type\u9009\u62e9\u5d4c\u5165\u7c7b\u578b\n        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n\n        # \u6839\u636e\u9891\u7387\u521b\u5efa\u5bf9\u5e94\u7684\u5d4c\u5165\u5c42\uff0c\u6bcf\u4e2a\u5d4c\u5165\u5c42\u8f93\u51fa\u7ef4\u5ea6\u90fd\u662fd_model\n        if freq == 't':\n            self.minute_embed = Embed(minute_size, d_model)\n\n        # \u521b\u5efa\u65f6\u95f4\u5355\u4f4d\u7684\u5d4c\u5165\u5c42\n        self.hour_embed = Embed(hour_size, d_model)\n        self.weekday_embed = Embed(weekday_size, d_model)\n        self.day_embed = Embed(day_size, d_model)\n        self.month_embed = Embed(month_size, d_model)\n\n    def forward(self, x):\n\n        # \u8f93\u5165x\u5f62\u72b6\u4e3a[B, L, time_features]\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u957f\u6574\u578b\u7528\u4e8e\u5d4c\u5165\u67e5\u8868\n        x = x.long()\n\n        # \u63d0\u53d6\u6bcf\u4e2a\u65f6\u95f4\u7279\u5f81\u5e76\u67e5\u627e\u5bf9\u5e94\u7684\u5d4c\u5165\u5411\u91cf\n\n        # x[:,:,i]\u5f62\u72b6\u4e3a[B,L]\uff0c\u901a\u8fc7\u5d4c\u5165\u540e\u53d8\u4e3a[B,L,d_model]\uff0c [B,L,d_model]\u6216\u6807\u91cf0\n        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(self, 'minute_embed') else 0.\n        hour_x = self.hour_embed(x[:, :, 3])   # [B,L,d_model]\n        weekday_x = self.weekday_embed(x[:, :, 2])   # [B,L,d_model]\n        day_x = self.day_embed(x[:, :, 1])   # [B,L,d_model]\n        month_x = self.month_embed(x[:, :, 0])   # [B,L,d_model]\n\n        # \u5c06\u6240\u6709\u65f6\u95f4\u7279\u5f81\u7684\u5d4c\u5165\u5411\u91cf\u76f8\u52a0\uff0c\u5f62\u6210\u6700\u7ec8\u7684\u65f6\u95f4\u5d4c\u5165\n        # \u6bcf\u4e2a\u65f6\u95f4\u7279\u5f81\u8f93\u51fa\u5f62\u72b6\u4e3a[B,L,d_model]\uff0c\u76f8\u52a0\u540e\u5f62\u72b6\u4e0d\u53d8\n        return hour_x + weekday_x + day_x + month_x + minute_x\n\n\nclass TimeFeatureEmbedding(nn.Module):\n    def __init__(self, d_model, embed_type='timeF', freq='h'):\n        super(TimeFeatureEmbedding, self).__init__()\n        # freq_map\u5b9a\u4e49\u4e0d\u540c\u6570\u636e\u9891\u7387\u4e0b\u4f7f\u7528\u7684\u65f6\u95f4\u7279\u5f81\u7ef4\u5ea6\n        freq_map = {'h': 4, 't': 5, 's': 6, 'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3} \n        d_inp = freq_map[freq]  # \u6839\u636e\u9891\u7387\u786e\u5b9a\u8f93\u5165\u7ef4\u5ea6\n        self.embed = nn.Linear(d_inp, d_model, bias=False) # \u521b\u5efa\u65e0\u504f\u7f6e\u7684\u7ebf\u6027\u5c42\u5c06d_inp\u7ef4\u5ea6\u6620\u5c04\u5230d_model\u7ef4\u5ea6\n\n    def forward(self, x):\n        # \u8f93\u5165x\u5f62\u72b6: [B, L, d_inp] - B\u662f\u6279\u6b21\u5927\u5c0f, L\u662f\u5e8f\u5217\u957f\u5ea6, d_inp\u662f\u65f6\u95f4\u7279\u5f81\u6570\u91cf\n        # \u7ebf\u6027\u53d8\u6362\u540e\u8f93\u51fa\u5f62\u72b6: [B, L, d_model]\n        return self.embed(x)\n\nclass DataEmbedding_wo_pos(nn.Module):\n    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n        super(DataEmbedding_wo_pos, self).__init__()\n\n        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n        self.position_embedding = PositionalEmbedding(d_model=d_model)\n        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n            d_model=d_model, embed_type=embed_type, freq=freq)\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, x, x_mark):\n        # x [B, L, D] \u2192 permute \u2192 [B, D, L] \u2192 \u5377\u79ef \u2192 [B, d_model, L] \u2192 transpose \u2192 [B, L, d_model]\n        # x_mark [B, L, d_inp] \u2192 \u7ebf\u6027\u5c42\u53d8\u6362(\u65f6\u95f4\u7279\u5f81\u6574\u4f53\u6620\u5c04) \u2192 [B, L, d_model]\n        # x_mark [B, L, time_features] \u2192 \u63d0\u53d6\u65f6\u95f4\u7279\u5f81\u5e76\u67e5\u8868 \u2192 \u5206\u522b\u5d4c\u5165 (\u6708/\u65e5/\u661f\u671f/\u5c0f\u65f6/\u5206\u949f) \u2192 \u6bcf\u4e2a\u65f6\u95f4\u7279\u5f81 [B, L, d_model] \u2192 \u76f8\u52a0 \u2192 [B, L, d_model]\n        # [B, L, d_model] + [B, L, d_model] \u2192 [B, L, d_model]\n        x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n        return self.dropout(x)\n\n\nimport argparse\nparser = argparse.ArgumentParser(description='Model family for Time Series Forecasting')\n#\u9ed8\u8ba4\u4f7f\u7528 TimeFeatureEmbedding \u5d4c\u5165\nparser.add_argument('--embed', type=str, default='timeF',help='time features encoding, options:[timeF, fixed, learned]') \nparser.add_argument('--freq', type=str, default='h',\n                        help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\nparser.add_argument('--dropout', type=float, default=0.5, help='dropout')\n\n# \u65f6\u5e8f\u6807\u914d BSD BPD d_model  D\u8fd9\u91cc\u8bb0\u4f5c enc_in \u6709\u7684\u662f pred_len + label_len\nparser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\nparser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\nparser.add_argument('--label_len', type=int, default=0, help='start token length')  #fixed\nparser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\nparser.add_argument('--enc_in', type=int, default=7, help='encoder input size') # DLinear with --individual, use this \nparser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n\nargs = parser.parse_args()\nenc_embedding = DataEmbedding_wo_pos(args.enc_in, args.d_model, args.embed,  args.freq,args.dropout)\n# enc\n# \u7f16\u7801\u5668\u8f93\u5165\u5d4c\u5165\uff0c\u5c06\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u7279\u5f81\u8f6c\u6362\u4e3a\u6a21\u578b\u5185\u90e8\u8868\u793a\n# \u5f62\u72b6\u53d8\u5316\uff1ax_enc[B, L, D] -&gt; enc_out[B, L, d_model]\nx_enc = torch.randn(args.batch_size,args.seq_len,args.enc_in)\nx_mark_enc = torch.randn(args.batch_size,args.seq_len,4) \n#\u56e0\u4e3a\u662f\u5c0f\u65f6\uff0c\u6570\u636e\u5c01\u88c5\u7684\u65f6\u5019\u4f1a\u8ba1\u7b97  offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear]\nenc_out = enc_embedding(x_enc, x_mark_enc)\n\nprint(\"\u8f93\u5165\u5e8f\u5217\u5f62\u72b6[B,S,D]: \",x_enc.shape)\nprint(\"\u8f93\u5165\u5e8f\u5217\u65f6\u95f4\u6233\u9884\u5904\u7406\u5f62\u72b6[B,S,freq]: \",x_mark_enc.shape)\n\nprint(\"outputs.shape[B,S,d_model]:\",enc_out.shape)\n</code></pre>"},{"location":"Reproduction/CodeRepo/4_self_/#unettsf","title":"UNetTSF","text":"<p>\u8f93\u5165&amp;\u8f93\u51fa</p> Bash <p>\u8bf4\u660e\uff1a</p>"},{"location":"Reproduction/CodeRepo/4_self_/#autoformer_1","title":"Autoformer \u81ea\u76f8\u5173\u673a\u5236","text":""},{"location":"Reproduction/CodeRepo/4_self_/#patchtst","title":"PatchTST","text":""},{"location":"Reproduction/CodeRepo/4_self_/#itransformer","title":"itransformer","text":""},{"location":"Reproduction/CodeRepo/4_self_/#longtrans","title":"LongTrans","text":""},{"location":"Reproduction/CodeRepo/4_self_/#pyraformer","title":"Pyraformer","text":""},{"location":"Reproduction/CodeRepo/4_self_/#dlinear","title":"DLinear","text":""},{"location":"Statistics/","title":"\ud83d\udc0b \u7edf\u8ba1\u5b66","text":""},{"location":"Statistics/#_1","title":"\ud83d\udc0b \u7edf\u8ba1\u5b66","text":"2025-03-23 22:06:212025-09-28 12:54:04 <p> \u7ea6 63 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>Abstract</p> <p>\u7edf\u8ba1\u5b66\u76f8\u5173\u7684\u5185\u5bb9\u4f1a\u5199\u5728\u8fd9\u91cc</p> <ul> <li>\u5085\u91cc\u53f6\u7ea7\u6570:<ul> <li>Fourier \u7ea7\u6570</li> <li>Fourier\u57fa\u7840\u77e5\u8bc6</li> <li>\u590d\u5e73\u9762\u65cb\u8f6c&amp;DFT</li> <li>\u76f4\u89c2\u7406\u89e3\u5085\u91cc\u53f6\u53d8\u6362</li> <li>\u4fe1\u53f7\u7684\u5408\u6210\u4e0e\u5206\u89e3</li> <li>FS\u3001FT\u3001DTFS\u3001DTFT</li> <li>\u590d\u6307\u6570\u7684\u6027\u8d28</li> </ul> </li> </ul>"},{"location":"Statistics/1_0_fourier/","title":"\u590d\u5e73\u9762\u65cb\u8f6c&amp;DFT","text":""},{"location":"Statistics/1_0_fourier/#dft","title":"\u590d\u5e73\u9762\u65cb\u8f6c&amp;DFT","text":"2025-03-25 19:58:082025-09-28 12:54:03 <p> \u7ea6 5234 \u4e2a\u5b57  93 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 26 \u5206\u949f</p>"},{"location":"Statistics/1_0_fourier/#_1","title":"\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362","text":"<p>\u52a8\u753b\u8bb2\u89e3\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362</p> <p>\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u516c\u5f0f\uff1a(\u5e45\u89d2-\u6a21\u578b\u5f62\u5f0f)</p> <p></p> <ul> <li>\\(x_n\\) \u539f\u59cb\u79bb\u6563\u65f6\u95f4\u5e8f\u5217</li> <li>\\(\\frac{2\\pi}{N} \\cdot k\\)  \uff1a\u6bcf\u6b21\u65cb\u8f6c\u7684\u89d2\u5ea6 = \\(k\\) \u4e2a \\(\\frac{2\\pi}{N}\\)</li> <li>\\(n\\)\uff1a\u6bcf\u4e2a\u65f6\u95f4\u70b9\uff08\u4ece\u524d\u5f80\u540e\uff09\u90fd\u8981\u65cb\u8f6c</li> </ul> <p>\u590d\u5e73\u9762\uff1a </p> <p></p> <p>\u6f14\u793a\uff0c\u5c06 \u539f\u59cb\u5e8f\u5217[4,3,2,1]\u8fdb\u884c\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff1a $$ X_k= \\sum_{n=0}^{N-1} x_n \\cdot e^{-i\\cdot(\\frac{2\\pi k}{N})n} $$</p> <ul> <li>N=4 \u539f\u59cb\u5e8f\u5217 4 \u4e2a\u65f6\u95f4\u70b9\uff0cn \u4ece 0 \u5f00\u59cb\u6309\u65f6\u95f4\u70b9\u5148\u540e\u4f9d\u6b21\u65cb\u8f6c</li> <li>\u6bcf\u4e2a\u65f6\u95f4\u70b9\u65cb\u8f6c \\(\\frac{2\\pi k}{N}\\) \u4e2a\u89d2\u5ea6\uff0ck=0,1,2,3</li> <li>k=0\u65f6\uff0c\u6bcf\u4e2a\u65f6\u95f4\u70b9\uff0c\u5bf9\u5e94\u65f6\u95f4\u5e8f\u5217\u5bf9\u5e94\u7684\u7ebf\u6bb5\uff0c\u4e0d\u65cb\u8f6c</li> <li>k=1\u65f6\uff0c\u65cb\u8f6c 90\u00b0</li> <li>k=2\u65f6\uff0c\u65cb\u8f6c 180\u00b0</li> <li>k=3\u65f6\uff0c\u65cb\u8f6c 270\u00b0</li> </ul> <ul> <li>1 \u4e2a\u5468\u671f = \u65f6\u95f4\u5e8f\u5217\u957f\u5ea6</li> <li>2 \u4e2a\u5468\u671f = \u65f6\u95f4\u5e8f\u5217\u957f\u5ea6</li> <li>3 \u4e2a\u5468\u671f = \u65f6\u95f4\u5e8f\u5217\u957f\u5ea6</li> <li>4 \u4e2a\u5468\u671f = \u65f6\u95f4\u5e8f\u5217\u957f\u5ea6 \u300a===\u300b\u4e00\u4e2a\u5468\u671f\u4e00\u4e2a\u70b9</li> </ul> <ul> <li>\u65cb\u8f6c\uff1a\u987a\u65f6\u9488\u65cb\u8f6c</li> </ul> <p></p> <p>\u987a\u65f6\u9488\u65cb\u8f6c 90 \u5ea6\uff1a</p> <p></p> <p>\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\uff0c\u987a\u65f6\u9488\u65cb\u8f6c 180 \u5ea6</p> <p> </p> <p>\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\uff0c\u987a\u65f6\u9488\u65cb\u8f6c 270 \u5ea6</p> <p></p> <p>\u5f97\u5230\u5085\u91cc\u53f6\u53d8\u6362\uff1a</p> <p> </p> <p></p> <p>\u4ee5\u4e0a\u662f 4 \u4e2a\u70b9\u7684\u4f8b\u5b50\uff0c\u73b0\u5728\u4e3e\u4e00\u4e2a 6 \u4e2a\u70b9\u7684\u4f8b\u5b50</p> <p>\u516c\u5f0f\uff0c\u4f9d\u7136\u662f DFT $$ X_k= \\sum_{n=0}^{N-1} x_n \\cdot e^{-i\\cdot(\\frac{2\\pi k}{N})n} $$</p> <ul> <li>\u65f6\u95f4\u5e8f\u5217\u4e2d\u6709 6 \u4e2a\u65f6\u95f4\u70b9</li> <li>\u6bcf\u6b21\u65cb\u8f6c  \\(\\frac{2\\pi k}{N}\\) \u4e2a\u89d2\u5ea6\uff0c\u5176\u4e2d\uff0c\\(\\frac{2\\pi }{N} = \\frac{ 360\u00b0 }{60\u00b0}= 60\u00b0\\)</li> <li>k=0\uff0c\u8868\u793a\uff0c\u7b2c\u4e00\u6b21\u904d\u5386 \u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6240\u6709\u65f6\u95f4\u70b9\u65f6\uff0c\u52a0\u548c\u5373\u53ef\u3002\u4e0d\u8f6c\u3002</li> <li>k=1\uff0c\u7b2c\u4e8c\u6b21\u904d\u5386\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u65f6\u95f4\u70b9\u65f6\uff0c\u6bcf\u4e2a\u70b9\u4f9d\u6b21\uff0c\u4ece\u524d\u5f80\u540e\uff0c\u987a\u65f6\u9488\u65cb\u8f6c \\(60\u00b0\\) \\(\u300a====\u300b\\) \u5468\u671f\u957f\u5ea6=\u5e8f\u5217\u957f\u5ea6  \\(\u300a====\u300b\\)  \u56e0\u4e3a 6 \u4e2a\u70b9\uff0c\u6bcf\u4e2a\u70b9\u8f6c 60 \u5ea6\uff0c\u904d\u5386\u5b8c\u6240\u6709\u65f6\u95f4\u70b9\uff0c\u521a\u597d\u8f6c\u5b8c\u4e00\u5708\u3002</li> <li>k=2\uff0c\u7b2c\u4e09\u6b21\u904d\u5386\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6240\u6709\u65f6\u95f4\u70b9\u65f6\uff0c\u6bcf\u4e2a\u70b9\u4f9d\u6b21\u518d\u6b21\u65cb\u8f6c \\(60 \u00b0\\)\uff0c\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\uff0c\u65cb\u8f6c\u4e86 \\(120\u00b0\\) \\(\u300a===\u300b\\)\ud83d\udd34\u5e8f\u5217\u957f\u5ea6 = 3 \u4e2a\u5468\u671f\u957f\u5ea6  \\(\u300a====\u300b\\) 6 \u4e2a\u70b9\uff0c\u6bcf\u4e2a\u70b9\u8f6c 120 \u5ea6\uff0c\u904d\u5386\u5b8c\u6240\u6709\u65f6\u95f4\u70b9\uff0c\ud83d\udd34\u8f6c\u5b8c 3\u5708\u3002</li> <li>k=3\uff0c\u7b2c\u56db\u6b21\u904d\u5386\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6240\u6709\u65f6\u95f4\u70b9\u65f6\uff0c\u6bcf\u4e2a\u70b9\u4f9d\u6b21\u518d\u6b21\u65cb\u8f6c \\(60 \u00b0\\)\uff0c\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\uff0c\u65cb\u8f6c\u4e86 \\(180\u00b0\\) \\(\u300a===\u300b\\)\ud83d\udd34\u5e8f\u5217\u957f\u5ea6 = 2\u4e2a\u5468\u671f\u957f\u5ea6  \\(\u300a====\u300b\\) 6 \u4e2a\u70b9\uff0c\u6bcf\u4e2a\u70b9\u8f6c 180 \u5ea6\uff0c\u904d\u5386\u5b8c\u6240\u6709\u65f6\u95f4\u70b9\uff0c\ud83d\udd34\u8f6c\u5b8c 2 \u5708\u3002</li> <li>k=4\uff0c\u7b2c\u4e94\u6b21\u904d\u5386\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6240\u6709\u65f6\u95f4\u70b9\u65f6\uff0c\u6bcf\u4e2a\u70b9\u4f9d\u6b21\u518d\u6b21\u65cb\u8f6c \\(60 \u00b0\\)\uff0c\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\uff0c\u65cb\u8f6c\u4e86 \\(240\u00b0\\) \\(\u300a===\u300b\\) \ud83d\udd34\u5e8f\u5217\u957f\u5ea6 = 3\u4e2a\u5468\u671f\u957f\u5ea6  \\(\u300a====\u300b\\) 6 \u4e2a\u70b9\uff0c\u6bcf\u4e2a\u70b9\u8f6c 180 \u5ea6\uff0c\u904d\u5386\u5b8c\u6240\u6709\u65f6\u95f4\u70b9\uff0c\ud83d\udd34\u8f6c\u5b8c 2 \u5708\u3002</li> <li>k=5\uff0c\u7b2c\u516d\u6b21\u904d\u5386\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6240\u6709\u65f6\u95f4\u70b9\u65f6\uff0c\u6bcf\u4e2a\u70b9\u4f9d\u6b21\u518d\u6b21\u65cb\u8f6c \\(60 \u00b0\\)\uff0c\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\uff0c\u65cb\u8f6c\u4e86 \\(300\u00b0\\) \\(\u300a===\u300b\\) \ud83d\udd34\u5e8f\u5217\u957f\u5ea6 = 3\u4e2a\u5468\u671f\u957f\u5ea6  \\(\u300a====\u300b\\) 6 \u4e2a\u70b9\uff0c\u6bcf\u4e2a\u70b9\u8f6c 180 \u5ea6\uff0c\u904d\u5386\u5b8c\u6240\u6709\u65f6\u95f4\u70b9\uff0c\ud83d\udd34\u8f6c\u5b8c 2 \u5708\u3002</li> <li>\u4e5f\u5c31\u662f\u8bf4\uff0c\\(k\\) \u904d\u5386\u5728 \\(2 \\pi\\) \u4e0a\uff0c\\(n\\) \u904d\u5386\u539f\u59cb\u5e8f\u5217\u3002\\(k\\) \u53ea\u662f\u6bcf\u4e2a\u65f6\u95f4\u70b9\u65cb\u8f6c\u7684\u89d2\u5ea6\u3002\u8868\u793a\u6240\u6709\u65f6\u95f4\u70b9\u5728\u8be5\u9891\u7387\u4e0a==\u7684\u76f8\u5173\u6027\uff1f\uff08\u54cd\u5e94\u503c\uff1f\uff09==</li> </ul> <p>k=0\uff0cDFT \u7684\u7b2c 1 \u4e2a\u503c\uff0c\u76f4\u63a5\u5bf9\u6240\u6709\u5143\u7d20\u52a0\u548c</p> <p>k=1\uff0c\u6bcf\u4e2a\u70b9\u8f6c 60 \u5ea6\uff1a</p> <p> </p> <p>k=2\uff0c\u6bcf\u4e2a\u70b9\u987a\u65f6\u9488\u65cb\u8f6c 120 \u5ea6</p> <p> </p> <p>\u6bcf\u4e2a\u70b9\u987a\u65f6\u9488\u65cb\u8f6c 180 \u5ea6</p> <p> </p> <p>\u6bcf\u4e2a\u70b9\u65cb\u8f6c\u987a\u65f6\u9488\u65cb\u8f6c 240 \u5ea6</p> <p></p> <p>\u6bcf\u4e2a\u70b9\u65cb\u8f6c300 \u5ea6</p> <p></p> <p>\u987a\u65f6\u9488\u65cb\u8f6c 300 \u5ea6\uff0c\u548c\u65cb\u8f6c 60 \u5ea6\uff0c\u5341\u5206\u76f8\u4f3c\uff0c\u53ea\u662f\u98a0\u5012\u4e86\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u5b9e\u90e8\u662f\u5b8c\u5168\u4e00\u6837\u7684\uff0c\u865a\u90e8\u662f\u53d6\u53cd\u7684\u3002\u56e0\u4e3a \\(e^x = cosx+isinx\\)  \uff1b\u7b2c 0 \u4e2a\u503c\u662f\u539f\u59cb\u65f6\u95f4\u70b9\u52a0\u548c\u7684\u3002</p> <p></p> <p> </p> <p>\u501f\u52a9\u5de5\u5177\u8ba1\u7b97 DFT</p> <p></p> <ul> <li>k=0\uff0c\u539f\u59cb\u5e8f\u5217\u5143\u7d20\u52a0\u548c</li> <li>k=1\uff0c\u8f6c 60 \u5ea6\uff0c\u8f6c\u4e00\u5708</li> <li>k=2\uff0c\u8f6c 120 \u5ea6\uff0c6 \u4e2a\u70b9\uff0c\u8f6c 3 \u5708</li> <li>k=3\uff0c\u8f6c 180 \u5ea6\uff0c\u5728\u5b9e\u6570\u8f74\u4e0a\u79fb\u52a8\uff0c6 \u4e2a\u70b9\u8f6c2 \u5708</li> <li>k=4\uff0c\u8f6c 240 \u5ea6\uff0c\u76f8\u5bf9\u4e8e 120 \u5ea6\u65cb\u8f6c\u6765\u8bf4\uff0c\u5b9e\u6570\u8f74\u4e0d\u53d8\uff0c\u865a\u6570\u8f74\u4e92\u4e3a\u76f8\u53cd\u6570</li> <li>k=5\uff0c\u8f6c 300 \u5ea6\uff0c\u76f8\u5bf9\u4e8e 60 \u5ea6\u65cb\u8f6c\u6765\u8bf4\uff0c\u5b9e\u6570\u8f74\u4e0d\u53d8\uff0c\u865a\u90e8\u4e92\u4e3a\u76f8\u53cd\u6570</li> </ul> <p>\u7531\uff0c\u65f6\u57df\u5f97\u5230\u4e86\u9891\u57df \\(===\u300b[4,3,2,1]\u2192[10,2-2i,2,2+2i]\\)</p> <ul> <li>k=0\uff0c\u5143\u7d20\u52a0\u548c</li> <li>k=1\uff0c\u8f6c 90 \u5ea6</li> <li>k=2\uff0c\u5b9e\u6570\u8f74\u4e0a\uff0c180 \u5ea6</li> <li>k=3\uff0c\u8f6c 270 \u5ea6\uff0c\u76f8\u5bf9\u4e8e k=1\uff0c\u5b9e\u6570\u90e8\u5206\u4e0d\u53d8\uff0c\u865a\u6570\u90e8\u5206\u4e92\u4e3a\u76f8\u53cd\u6570</li> </ul> <p>\u90a3\u4e48\uff0c\u5982\u679c\u6709\u9891\u57df\uff0c$[10,2-2i,2,2+2i] $ \u600e\u4e48\u5f97\u5230 \u65f6\u57df\uff1f \\([4,3,2,1]\\)</p> <ul> <li>DFT \u987a\u65f6\u9488\u65cb\u8f6c\uff0c\u9006\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u90a3\u5c31\u9006\u65f6\u9488\u65cb\u8f6c</li> </ul> <p></p> <p>\u5728\u590d\u5e73\u9762\u8868\u793a\uff1a</p> <p> </p> <ul> <li>\u9996\u5148\uff0c\u7b2c 0 \u4e2a\u503c\uff0c\u9891\u57df\u5143\u7d20\u52a0\u548c</li> </ul> <p> </p> <ul> <li>\u987a\u65f6\u9488\u65cb\u8f6c 90 \u5ea6\uff0c\u4f9d\u7136\u662f\u6309\u7167\u9891\u57df\u5143\u7d20\u987a\u5e8f\uff0c\u4f9d\u6b21\u65cb\u8f6c</li> </ul> <p></p> <ul> <li>\u518d\u6b21\uff0c\u6bcf\u4e2a\u70b9\u4f9d\u6b21\u65cb\u8f6c 180 \u5ea6</li> </ul> <p> </p> <p>\u987a\u65f6\u9488\uff0c\u6bcf\u4e2a\u70b9\uff0c\u76f8\u5bf9\u4e8e\u521d\u59cb\u4f4d\u7f6e\uff0c\u65cb\u8f6c 270 \u5ea6\uff0c\u90fd\u662f\u4ece\u521d\u59cb\u4f4d\u7f6e\u5f00\u59cb\u65cb\u8f6c\uff0c\u4e00\u6b21\u65cb\u8f6c\u5b8c\u89d2\u5ea6</p> <p> </p> <p>\u95ee\u9898\uff0c\u4e3a\u4ec0\u4e48\uff0c\u662f [16,12,8,4] \u4e0d\u662f [4,3,2,1] \uff1f</p> <p> </p> <p>\u7b54\u6848\uff1a\u9664\u4ee5 \u5e8f\u5217\u957f\u5ea6 \uff0c\u8fd9\u91cc\u662f 4.</p> <p></p> <p>\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u987a\u65f6\u9488\u65cb\u8f6c\uff0c \\(\\frac{2\\pi}{N}\\)</p> <p>\u9006\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u9006\u65f6\u9488\u65cb\u8f6c\uff0c\u4e5f\u662f\\(\\frac{2\\pi}{N}\\)\uff0c\u6700\u540e\u8fd8\u8981\u9664\u4ee5\u5e8f\u5217\u957f\u5ea6 \\(N\\)</p> <p></p> <p>\u590d\u5e73\u9762\u4e0e \\(e^x\\) \uff0c\u8fd9\u4e00\u6b65\u7684\u8f6c\u6362\uff0c\u5176\u5b9e\u662f\u4ece \\((cos\\theta,sin\\theta)\\) \u76f4\u63a5\u7528\u4e86 \\(e^{i\\theta}\\) \u8868\u793a</p> <p></p> <p>\u7c7b\u4f3c\u7684\uff0c\u590d\u5e73\u9762\u5750\u6807\u70b9\uff0c\u5168\u90e8\u7528\u6307\u6570\u8868\u793a</p> <p>  $$ e^{i\\theta} = cos\\theta + isin\\theta $$ \u5177\u4f53\u6765\u8bf4\uff1a</p> <ul> <li>\\(1 = e^{i2\\pi} = cos2\\pi + isin2\\pi = 1\\)</li> <li>\\(i = e^{i\\frac{\\pi}{2}} = cos\\frac{\\pi}{2} + isin\\frac{\\pi}{2} = i\\)</li> <li>\\(-1 = e^{i\\pi} = cos\\pi + isin \\pi = -1\\)</li> <li>\\(-i = e^{i\\frac{3\\pi}{2}} = cos\\frac{3\\pi}{2} + isin\\frac{3\\pi}{2} = -i\\)</li> </ul> <p>\u63a5\u4e0b\u6765\uff0c\u5bf9 1 \u8fdb\u884c\u5206\u89e3\uff0c\u5177\u4f53\u6765\u8bf4\uff1a</p> <ul> <li>\\(x^2=1\\)</li> <li>\\(x^3=1\\)</li> <li>\\(x^4=1\\)</li> <li>\\(x^5=1\\)</li> </ul> <p>\u56e0\u4e3a\u8ba8\u8bba\u7684\u662f\u4e09\u89d2\u51fd\u6570\uff0c\u6240\u4ee5\u7528 \\(\\omega\\) </p> <p>\u8fd9\u91cc\u5176\u5b9e\uff0c\u6211\u89c9\u5f97\u5e94\u8be5\u8fd9\u4e48\u89e3\u91ca</p> <ul> <li>\\(\\omega^2 = 1 ===&gt;\\)   \u8f6c1\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\)</li> <li>\\(\\omega^3 = 1 ===&gt;\\) \u8f6c3\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1 ===&gt;\\)  \u5f97\u5230\u5bf9\u5e94\u7684\u89d2\uff0c\u8fdb\u884c\u76f8\u5e94\u7684\u590d\u6570\u8868\u793a\uff0c\u6bd4\u5982\u8fd9\u91cc \\(\\omega=120\u00b0\\) \uff0c\\(x\\) \u8f74\u6b63\u65b9\u5411\u5f00\u59cb\u627e\u70b9\uff0c120\u00b0\u6807\u4e00\u4e2a\uff0c\u518d\u4e00\u4e2a120\u00b0\uff0c\u518d\u6807\u4e00\u4e2a\u3002\uff08\u6a21\u957f=1\uff0c\u89d2\u5ea6\uff1d120\u00b0\uff09</li> <li>\\(\\omega^4 = 1 ===&gt;\\) \u8f6c4\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\)</li> <li>\\(\\omega^5 = 1 ===&gt;\\) \u8f6c5\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\)</li> <li>\\(\\omega^6 = 1 ===&gt;\\) \u8f6c6\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\)</li> <li>......</li> <li>\\(\\omega^n = 1 ===&gt;\\) \u8f6cn\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\) </li> </ul> <p>\u5355\u4f4d\u6839 </p> <p></p> <ul> <li>\\(\\omega = 120\u00b0\\) \u662f\u89d2\uff0c\u4e5f\u662f\u590d\u6570\u8868\u793a\uff0c\u4e5f\u662f \u6307\u6570</li> <li>\u590d\u6570\uff1a \\(\\omega = -\\frac{1}{2} + i \\sqrt{\\frac{3}{2}}\\)</li> <li>\u203b \u6307\u6570\uff1a\\(\\omega = e^{i\\frac{2\\pi k}{N}}\\) \u8fd9\u91cc\u5212\u5206\u6210 3 \u4e2a\uff0c\u4e5f\u5c31\u662f 3 \u4e2a\u6837\u672c\u70b9\uff0c\u6240\u4ee5 \\(N=3\\)\uff0c\u8fd9\u662f\u7b2c\u4e00\u6b21\u65cb\u8f6c\uff0c\u6240\u4ee5\uff0c\\(k=1\\) \u6240\u4ee5\u6307\u6570\u8868\u793a \\(\\omega = e^{i \\frac{2 \\pi}{3}}\\)</li> </ul> <p>\u57fa\u4e8e\u4ee5\u4e0a\u8ba4\u8bc6\uff0c\u91cd\u65b0\u770b DFT</p> <p></p> <p>\u7b26\u53f7\u8bf4\u660e</p> <ul> <li>DFT \u7684\u7ed3\u679c \\(X_k\\)</li> <li>\\(x_n\\) \uff1a \u6211\u4eec\u6b63\u5728\u65cb\u8f6c\u7684\u6746\u7684\u957f\u5ea6</li> <li>\\(e^{-i(2\\pi\\frac{k}{N}n)}\\) \uff1a \u8fd9\u4e2a\u6307\u6570\uff0c\u5c31\u8868\u793a\u4e86\u65cb\u8f6c\u89d2\u5ea6\uff0c\u8868\u793a\u7684\u662f\u5355\u4f4d\u6839\u7684\u65cb\u8f6c\u89d2\u5ea6\uff0c\u56e0\u4e3a\u4e58\u4ee5\u4e86 \\(x_n\\) \u6240\u4ee5\u6709\u957f\u5ea6</li> <li>\\(\\sum_{n=0}^{N-1}\\) : \u6c42\u548c\u8868\u793a \u6240\u6709\u6746\u7684\u4e32\u8054</li> </ul> <p> </p> <p>\\(e^{-i(2\\pi\\frac{k}{N}n)}\\) \u7684\u66f4\u5177\u4f53\u4e00\u70b9</p> <ul> <li>\\((2\\pi\\frac{k}{N}n)\\) \uff1a \u8868\u793a\uff0c\u65cb\u8f6c\u7684\u89d2\u5ea6\u3002\u5e76\u4e14\u4e3b\u8981\u662f \\(2\\pi\\frac{k}{N}\\) \uff0c\\(n\\) \u7684\u610f\u601d\u662f\uff0c\u8868\u793a\u5bf9\u6240\u6709\u6746\u65cb\u8f6c</li> <li>\u8d1f\u53f7 \u8868\u793a \u987a\u65f6\u9488\u65cb\u8f6c</li> </ul> <p>\u539f\u59cb\u5e8f\u5217\u4e2d\u7684\u70b9\uff0c\u65cb\u8f6c \\(e^{-i(2\\pi\\frac{k}{N}n)}\\) \uff0c\u5f97\u5230  \\(X_k\\) \u7684\u56fe\u5f62\u5316\u8fc7\u7a0b\uff1a</p> <p>\u5bf9\u4e8e\u904d\u5386\u4e00\u6b21\u5e8f\u5217\uff0c\u6240\u6709\u65f6\u95f4\u70b9\uff0c\u65cb\u8f6c\u7684\u89d2\u5ea6\u662f\u4e0d\u53d8\u7684\u3002</p> <p></p> <p> </p> <p>\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u5316\u548c\u79bb\u6563\u5085\u91cc\u53f6\u9006\u53d8\u6362\uff1a</p> <p> </p> <p>\\(e^{-i}\\) \u8868\u793a \u987a\u65f6\u9488\u65cb\u8f6c\uff0c\\(e^i\\) \u8868\u793a\u9006\u65f6\u9488\u65cb\u8f6c </p> <p>\u65cb\u8f6c\u89d2\u5ea6 \\(\\frac{2 \\pi k}{N}\\) </p> <p></p> <p>\u6700\u540e\uff0c\u7279\u522b\u6ce8\u610f\u4e00\u4e0b\uff0c\u9006\u5085\u91cc\u53f6\u53d8\u6362\u9700\u8981\u9664\u4ee5 \u5e8f\u5217\u957f\u5ea6 \\(N\\)</p> <p></p> <p>\u5f53\u7136\u4e86\uff0c\u4e5f\u6709\u8868\u793a \\(\\frac{1}{\\sqrt{N}}\\)</p> <p> </p> <p>\u5085\u91cc\u53f6\u53d8\u6362\u7684\u77e9\u9635\u8868\u793a\uff1a</p> <p>\u8fd8\u662f\u4ece [4,3,2,1]\u5f00\u59cb\uff1a</p> <p> </p> <p>\u7528\u5355\u4f4d\u6839\u77e9\u9635\u8868\u793a\uff0cDFT</p> <p> </p> <p>\u5173\u4e8e\u77e9\u9635\u8be6\u7ec6\u5c55\u5f00\uff1a</p> <p></p> <ul> <li>\u7b80\u5316\u8bb0\u5fc6\uff1a\\(\\omega_{kn} x_n = X_k\\) </li> </ul> <p>$ \\omega = e^{i\\frac{ 2\\pi}{N}} $</p> <ul> <li>\u884c\u8868\u793a \\(\\frac{2\\pi k}{N}\\) \u9891\u7387\uff0c\u5206\u522b\u4e0e \u539f\u59cb\u5e8f\u5217 \\(x_0\uff0cx_1\uff0cx_2\uff0c......,x_{N-1}\\) \u7684\u76f8\u5173\u6027</li> </ul> <p>\u9006\u5085\u91cc\u53f6\u53d8\u6362\u7684\u77e9\u9635\u5f62\u5f0f\uff1a</p> <p></p>"},{"location":"Statistics/1_0_fourier/#_2","title":"\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u4e2d\u7684\u5e8f\u5217\u5468\u671f\u89c4\u5f8b","text":"<p>\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u4e2d\u7684\u5e8f\u5217\u5468\u671f\u89c4\u5f8b</p> <p>\u9996\u5148\uff0c\u56de\u5fc6\\([4,3,2,1]\\)\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u7684\u8fc7\u7a0b</p> <p></p> <p>\u5728\u590d\u5e73\u9762\u4e2d\u8ba8\u8bba\uff0c\u4f9d\u6b21\u753b\u51fa 4,3,2,1 \u7684\u7ebf\u6bb5\uff0c\u6807\u51fa\u7b2c\u4e00\u4e2a\u70b9\uff0c\u4e5f\u5c31\u662f <code>10</code></p> <p>\u7136\u540e\uff0c\u987a\u65f6\u9488\uff0c\u4f9d\u6b21\u65cb\u8f6c 90 \u5ea6\uff0c\u5148\u8f6c\u7b2c\u4e00\u6761\u7ebf\u6bb5 <code>4</code> \uff0c\u8f6c\u52a8 4 \u7684\u65f6\u5019\uff0c\u4f1a\u5e26\u7740\u8f6c 3,2,1\uff0c\u4f46\u662f\u8f6c\u7684\u662f 4 \u7684\u53f3\u7aef\u70b9</p> <p> </p> <p>\u63a5\u7740\u8f6c\uff0c\u7b2c\u4e8c\u6761\u8fb9\u7684\u53f3\u7aef\u70b9</p> <p> </p> <p>\u7136\u540e\u8f6c\u7b2c\u4e09\u6761\u8fb9\u7684\u53f3\u7aef\u70b9\uff0c\u8f6c\u52a8 90 \u5ea6\uff0c\u6700\u7ec8\u8f6c\u7b2c\u56db\u6761\u8fb9</p> <p> </p> <p>\u8bb0\u5f55\u5f97\u5230\u6700\u7ec8\u7684\u4f4d\u7f6e\u3002</p> <p>\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u548c\u9006\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362</p> <p> </p> <p>\u63a5\u4e0b\u6765\uff0c\u8ba8\u8bba\u5468\u671f\u5e8f\u5217\uff1a</p> <p></p> <p>\u5bf9\u8fd9\u4e2a\u5e8f\u5217\u8fdb\u884c\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff1a </p> <p> </p> <p>\u4ec5\u89c2\u5bdf 0 \u503c\u548c\u975e 0 \u503c </p> <p></p> <p> </p> <p>\u63a5\u4e0b\u6765\u7684\u95ee\u9898\uff1a</p> <p>\u5468\u671f=4 \u7684\u65f6\u95f4\u5e8f\u5217 \u91cd\u590d 3 \u6b21 </p> <p> </p> <p>\u9996\u5148\u89c2\u5bdf\u7b2c\u4e00\u4e2a\u5468\u671f\u4e3a 4 \u5e8f\u5217\u7684\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff1a</p> <p> </p> <ul> <li>270\u00b0+90\u00b0=360\u00b0\uff0c\u6240\u4ee5\u8f6c\u52a8270\u00b0\u65f6\uff0c\u4e0e90\u00b0\u7684\u5b9e\u90e8\u76f8\u540c\uff0c\u865a\u90e8\u4e92\u4e3a\u76f8\u53cd\u6570</li> </ul> <p>\u90a3\u4e48\u6b64\u65f63 \u4e2a \u5468\u671f\u4e3a 4 \u7684\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u5462\uff1f </p> <p> </p> <p>\u76f4\u89c2\u4e0a\u8bf4\uff0c\u662f \u4e0a\u9762\u5f97\u5230\u7684\uff0c\u4e00\u4e2a\u5468\u671f\u4e3a 4 \u7684\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u4f46\u5176\u5b9e\u4e0d\u662f\u7684\uff0c\u800c\u662f<code>\u00d73</code>\uff0c3 \u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u91cd\u590d\u6a21\u5f0f\u3002\u800c\u5176\u4ed6\u90e8\u5206\u586b\u5145 0\uff0c\u5f97\u5230\u91cd\u590d 3 \u6b21\u7684\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362</p> <p> </p> <p>\u518d\u6b21\u770b\u4e00\u4e0b\uff0c\u8fd9\u91cc\u6709\u533a\u522b</p> <p> </p> <p>\u8fd9\u91cc\u662f\u91cd\u590d 3 \u6b21\uff0c\u5468\u671f \u4e3a 4 \u7684\u539f\u59cb\u65f6\u95f4\u5e8f\u5217</p> <p>\u5f97\u5230\u7684\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u662f\uff0c\u5206\u6210 4 \u5757\uff0c\uff08\u6bcf\u5757\u5185\u7b2c\u4e00\u4e2a\u5143\u7d20\u4e0d\u4e3a 0\uff0c\u5176\u4f59\u4e24\u4e2a\u5143\u7d20=0\uff09</p> <ul> <li>\u6bcf\u6b21\u65cb\u8f6c\u7684\u89d2\u5ea6\u53d8\u4e86\uff1a\\(\\frac{2 \\pi k}{N}\\)</li> </ul> <p>\u5206\u6790\u4e3a\u4ec0\u4e48\u662f\u8fd9\u6837\u7684\uff1f</p> <p>\u76f4\u89c2\u4e0a\u8bf4\uff0c\u662f \u4e0a\u9762\u5f97\u5230\u7684\uff0c\u4e00\u4e2a\u5468\u671f\u4e3a 4 \u7684\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u4f46\u5176\u5b9e\u4e0d\u662f\u7684\uff0c\u800c\u662f<code>\u00d73</code>\uff0c3 \u4e2a\u65f6\u95f4\u5e8f\u5217\u7684\u91cd\u590d\u6a21\u5f0f\u3002\u800c\u5176\u4ed6\u90e8\u5206\u586b\u5145 0\uff0c\u5f97\u5230\u91cd\u590d 3 \u6b21\u7684\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362</p> <ul> <li>\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\uff0c\u5728\u5bf9\u5e94\u9891\u7387\u4e0a\u7684\u5206\u91cf\uff0c\u5305\u542b\u89d2\u5ea6\uff08 \\(e^{-i\\frac{2 \\pi k n}{N} }\\) \uff09\u548c\u6a21\u957f \\(x_n\\)  \u3002</li> <li> <p>\\(e^{-i}\\) \u8868\u793a \u987a\u65f6\u9488\u65cb\u8f6c</p> </li> <li> <p>\u5176\u5b9e\u4e0d\u662f\u5f88\u61c2\u8fd9\u4e2a n\u7684\u542b\u4e49\uff0c\u7b2c 0\u4e2a\uff0c\u7b2c 1 \u4e2a\uff0c...\uff0c\u6bcf\u4e2a\u7ebf\u6bb5\u8f6c\u89d2\u5c31\u662f\u8f6c\u89d2\uff0c\u4e58 n \u5e72\u5565\u3002</p> </li> </ul> <p>\u6211\u61c2\u8fd9\u4e2a n \u4e86\uff0c\u9996\u5148\uff0c\u5206\u6790\uff0c\u8fd9\u51e0\u6761\u7ebf\u6bb5\u662f\u4f9d\u6b21\u65cb\u8f6c\u7684\u3002</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u5047\u5982\u57fa\u672c\u65cb\u8f6c\u5355\u5143\u662f 60\u00b0\uff0c\u4e00\u5171 6 \u6761\u7ebf\u6bb5\uff08\u4e00\u5b9a\u8981\u6ee1\u8db3 \\(\\frac{2 \\pi }{N}\\) \uff09\uff0c</p> <p>\u73b0\u5728\u590d\u8ff0\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u5728\u65cb\u8f6c 60 \u5ea6\u65f6\uff0c\u6bcf\u6761\u7ebf\u6bb5\u7684\u65cb\u8f6c\u60c5\u51b5\u3002</p> <p>\u7b2c\u4e00\u6761\u7ebf\u6bb5\u8f6c 60 \u5ea6\uff0c\u7b2c\u4e00\u6761\u7ebf\u6bb5\u8f6c\u7684\u65f6\u5019\uff0c\u5e26\u7740\u7b2c\u4e8c\u6761\u3001\u7b2c\u4e09\u6761\u3001\u7b2c\u56db\u6761...\u7ebf\u6bb5\u4e5f\u8f6c\u4e86 60 \u5ea6</p> <p>\u63a5\u4e0b\u6765\u8f6c\u7b2c\u4e8c\u6761\u7ebf\u6bb5\uff0c\u7b2c\u4e8c\u6761\u7ebf\u6bb5\u5728\u7b2c\u4e00\u6761\u7ebf\u6bb5\u7684\u57fa\u7840\u4e0a\u8f6c\uff0c\u5f00\u59cb\u8f6c\uff0c\u7b2c\u4e8c\u6761\u7ebf\u6bb5\u8f6c 60 \u5ea6\uff0c\u76f8\u5bf9\u4e8e\u8d77\u59cb\u4f4d\u7f6e\u8f6c\u4e86 120 \u5ea6\uff0c\u540c\u65f6\u5e26\u52a8\u4e86\u7b2c\u4e09\u6761\u548c\u7b2c\u56db\u6761\u7b49\u5176\u4f59\u51e0\u6761\u7ebf\u6bb5\u8f6c 60 \u5ea6\uff0c\u63a5\u4e0b\u6765\uff0c\u7b2c\u4e09\u6761\u7ebf\u6bb5\u5728\u7b2c\u4e8c\u6761\u7ebf\u6bb5\u7684\u57fa\u7840\u4e0a\u518d\u8f6c 60 \u5ea6\uff0c\u76f8\u5bf9\u4e8e\u5176\u5b9e\u8f6c\u4e86 180 \u5ea6....</p> <p>\u6240\u4ee5\uff0c\u5bf9\u4e8e\u7279\u5b9a\u9891\u7387 \\(k\\) \u6765\u8bf4\uff0c\u6bcf\u6761\u7ebf\u6bb5\u90fd\u4f1a\u8f6c \\(\\frac{2 \\pi k}{N} n\\)</p> <p>\u5177\u4f53\u5730\uff0c\\(x_0\\) \u8f6c \\(e^{-\\frac{2 \\pi k}{N} \\cdot 0}\\)</p> <p>\\(x_1\\) \u8f6c  \\(e^{-\\frac{2 \\pi k}{N} \\cdot 1}\\)  \uff0c\u4e00\u4e2a  \\(\\frac{2 \\pi k}{N}\\) </p> <p>\\(x_2\\) \u8f6c  \\(e^{-\\frac{2 \\pi k}{N} \\cdot 2}\\) \uff0c2 \u4e2a \\(\\frac{2 \\pi k}{N}\\)</p> <p>\\(x_3\\) \u8f6c \\(e^{-\\frac{2 \\pi k}{N} \\cdot 3}\\) \uff0c3 \u4e2a \\(\\frac{2 \\pi k}{N}\\)</p> <p>\u63a5\u4e0b\u6765\uff0c\u4e00\u4e2a\u4e2a\u8ba1\u7b97\uff0c\u8fd9\u4e2a\u5177\u6709\u5468\u671f\u6027\u8d28\u7684\u65f6\u95f4\u5e8f\u5217\u7684\u5085\u91cc\u53f6\u53d8\u6362\uff1a</p> <p></p> <p>\u7b2c\u4e00\u4e2a\u5143\u7d20\uff1a</p> <p>\u540c\u6837\u5728\u5b9e\u6570\u8f74\u4e0a\u753b\u51fa\u7ebf\u6bb5\uff0c\u7136\u540e\u5143\u7d20\u52a0\u548c\u653e\u5230 DFT \u7684\u7b2c\u4e00\u4e2a\u4f4d\u7f6e</p> <p></p> <p>\u63a5\u4e0b\u6765\uff0c\u8ba8\u8bbaDFT \u4e2d\u7684\u7b2c\u4e8c\u4e2a\u5143\u7d20\uff0c\u4e5f\u5c31\u662f\u6bcf\u5929\u7ebf\u6bb5\u65cb\u8f6c \\(\\frac{2 \\pi}{N}\\) \uff0c\\(N=12\\) \uff0c\u4e5f\u5c31\u662f\u6bcf\u6761\u7ebf\u6bb5\u4f9d\u6b21\u65cb\u8f6c 60 \u5ea6\u3002</p> <p> </p> <p> </p> <p> </p> <p>\u7b2c\u4e09\u4e2a\u5468\u671f\u540c\u7406\uff0c\u6bcf\u6761\u7ebf\u6bb5\uff0c\u65f6\u95f4\u70b9\u5bf9\u5e94\u7684\u957f\u5ea6\u4f9d\u6b21\u8f6c 60\u00b0\uff0c\u540c\u65f6\u5728\u7b2c\u4e8c\u6b21\u65cb\u8f6c\u7684\u57fa\u7840\u4e0a\uff0c\u65cb\u8f6c\uff0c\u4e5f\u5c31\u662f\u76f8\u5bf9\u4e8e\u7b2c\u4e00\u6b21\u65cb\u8f6c</p> <ul> <li>\u7b2c\u4e00\u4e2a\u5468\u671f\u65cb\u8f6c 30 \u5ea6\uff0c4 \u4e2a\u65f6\u95f4\u70b9\uff0c4 \u6761\u7ebf\u6bb5\uff0c\u6240\u4ee5 4 \u6761\u7ebf\u6bb5\u4e2d\u7684\u6700\u540e\u4e00\u6761\u7ebf\u6bb5\u8f6c\u4e86 \\(30\u00d74=120\u00b0\\)</li> <li>\u7b2c\u4e8c\u4e2a\u5468\u671f\u5728\u7b2c\u4e00\u4e2a\u5468\u671f\u7684\u57fa\u7840\u4e0a\u65cb\u8f6c\uff0c\u4e5f\u5c31\u662f\u628a\u7b2c\u4e00\u4e2a\u5468\u671f\u7684\u6240\u6709\u8f6c\u8fc7\u7684\uff0c\u5df2\u7ecf\u5b8c\u6210\u7684\u5f62\u72b6\uff0c\u518d\u8f6c 120\u00b0\uff0c\u7136\u540e\u62fc\u5230\u7b2c\u4e00\u4e2a\u5468\u671f\u65cb\u8f6c\u7684\u540e\u9762\u3002</li> <li>\u540c\u7406\uff0c\u7b2c\u4e09\u4e2a\u5468\u671f\u4e5f\u662f\uff0c\u5bf9\u4e8e\u7b2c\u4e8c\u4e2a\u5468\u671f\u65cb\u8f6c\u597d\u7684\u56fe\u5f62\u8f6c 120 \u5ea6\uff0c\u76f8\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u5468\u671f\u8f6c\u597d\u7684\u5f62\u72b6\uff0c\u65cb\u8f6c 240 \u5ea6\u3002</li> </ul> <p>\u5f97\u5230\uff1a</p> <p></p> <p>\u6240\u4ee5 DFT \u7684\u7b2c\u4e8c\u4e2a\u6570=0</p> <p>\u7b2c\u4e09\u4e2a\u6570\uff0c\u540c\u7406\u3002\u7b2c\u4e00\u6761\u7ebf\u6bb5\u8f6c \\(\\frac{2 \\pi}{N}k\\)\uff0c\u8fd9\u91cc \\(k=2\\)\uff0c\u5bf9\u5e94\u7684\u6bcf\u6761\u7ebf\u6bb5\uff0c\u8f6c \u4ece\u7f16\u53f7 0 \u5f00\u59cb\uff0c\u8f6c \\(\\frac{2 \\pi}{N}k n\\) \u8bb0\u7684\u662f\u6bcf\u6761\u7ebf\u6bb5\u7684\u7d2f\u79ef\u65cb\u8f6c\u89d2\u5ea6</p> <p> </p> <p>\u73b0\u5728\u8ba8\u8bba\u4e0b\u4e00\u4e2a\u70b9\u4e3a\u4ec0\u4e48\u4e0d\u662f 0</p> <p> </p> <p>\u8fd9\u91cc \\(k=3\\)\uff0c \u4e5f\u5c31\u662f\u8bf4 \u7b2c\u4e00\u6761\u7ebf\u6bb5 \u65cb\u8f6c \\(\\frac{2 \\pi k }{N} = 30\u00b0\u00d73=90\u00b0\\) \uff0c\u6240\u4ee5\u4e0b\u4e00\u4e2a\u5143\u7d20 \\(\\neq 0\\) </p> <p> </p> <p>\u8fd9\u91cc \\(\\frac{2 \\pi}{N}=30\u00b0\\)</p> <ul> <li>\\(k=0\\) \u4e0d\u8f6c\uff0c\u6240\u6709\u5143\u7d20\u76f8\u52a0</li> <li>\\(k=1\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = \\frac{2\\pi }{N}n\\) </li> </ul> <ul> <li>\u7b2c\u4e00\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N}\\cdot 0\\) </li> <li>\u7b2c\u4e8c\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N}\\cdot 1 = 30\u00b0\\) </li> <li>\u7b2c\u4e09\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N}\\cdot 2 = 60\u00b0\\)</li> <li>\u7b2c\u56db\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N}\\cdot 3 = 90\u00b0\\)</li> <li>\u7b2c\u4e94\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N}\\cdot 4 = 120\u00b0\\)</li> <li>\u7b2c\u516d\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N}\\cdot 5 = 150\u00b0\\)</li> </ul> <ul> <li>\\(k=2\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 60\u00b0 n\\) </li> </ul> <ul> <li>\u7b2c\u4e00\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N} \\cdot (k=2)\\cdot 0\\) </li> <li>\u7b2c\u4e8c\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N} \\cdot (k=2)\\cdot 1 = 60\u00b0\\) </li> <li>\u7b2c\u4e09\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N} \\cdot (k=2)\\cdot 2 = 120\u00b0\\) </li> <li>\u7b2c\u56db\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N} \\cdot (k=2)\\cdot 3 = 180\u00b0\\)</li> <li>\u7b2c\u4e94\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N} \\cdot (k=2)\\cdot 4 = 240\u00b0\\)</li> <li>\u7b2c\u516d\u6761\uff0c\u8f6c \\(\\frac{2\\pi }{N} \\cdot (k=2)\\cdot 5 = 300\u00b0\\)</li> </ul> <ul> <li> <p>\\(k=3\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 90\u00b0 n\\) </p> </li> <li> <p>\\(k=4\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 120\u00b0 n\\) </p> </li> <li> <p>\\(k=5\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 150\u00b0 n\\) </p> </li> <li> <p>\\(k=6\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 180\u00b0 n\\) </p> </li> <li> <p>\\(k=7\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 210\u00b0 n\\) </p> </li> <li> <p>\\(k=8\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 240\u00b0 n\\) </p> </li> <li> <p>\\(k=9\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 270\u00b0 n\\) </p> </li> <li> <p>\\(k=10\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 300\u00b0 n\\) </p> </li> <li> <p>\\(k=11\\)\uff0c\u8f6c \\(\\frac{2\\pi k}{N}n = 330\u00b0 n\\) </p> </li> </ul> <p> </p> <p>\u5bf9\u6bd4\u7ed3\u679c\uff1a</p> <p></p> <p>\u76f4\u65b9\u56fe\u8868\u793a\uff1a </p> <p></p> <p>\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362&amp;\u9006\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff1a</p> <p>k = 0\uff0c\u4f9d\u7136\u662f\u539f\u59cb\u5e8f\u5217\u52a0\u548c</p> <p>k=1\uff0c\u6bcf\u4e2a\u65f6\u95f4\u70b9\u4e0a\u9762\u6807\u4e86\uff0c\u6bcf\u4e2a\u65f6\u95f4\u65cb\u8f6c\u7684\u5ea6\u6570\uff0c\u65cb\u8f6c\u5f97\u5230\u9006\u5085\u91cc\u53f6\u53d8\u6362\u7684\u7b2c\u4e8c\u4e2a\u503c</p> <p>\u9006\u5085\u91cc\u53f6\u53d8\u6362\u9700\u8981\u6ce8\u610f\u7684\u70b9\uff1a</p> <ul> <li>\u9664\u4ee5\u5e8f\u5217\u957f\u5ea6 \\(N\\)</li> <li>\u65cb\u8f6c\u65b9\u5411\uff1a\u9006\u65f6\u9488</li> </ul> <p> </p> <p>k=2 \u65f6\uff0c\u6bcf\u4e2a\u65cb\u8f6c 2 \u4e2a 30 \u5ea6</p> <p></p> <p> </p>"},{"location":"Statistics/1_0_fourier/#_3","title":"\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362","text":"<ul> <li> \u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362</li> </ul>"},{"location":"Statistics/1_0_fourier/#dft_1","title":"\u624b\u6413 DFT \u4f8b\u9898","text":"<p>\u6570\u5b57\u4fe1\u53f7\u5904\u740613-1_\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08DFT\uff09 </p> <p>\u8fd9\u91cc\u5177\u4f53\u7528\u7684\u65f6\u5019\u662f\u5171\u8f6d\u590d\u6570\uff0c\u8868\u793a\u987a\u65f6\u9488\u65cb\u8f6c\uff0c\u4e0a\u9762\u5199\u7684\u6ca1\u5199\u6210 \\(e^{-j0\\Omega n}\\) \u6ca1\u52a0\u8d1f\u53f7\uff0c\u8868\u793a\u7684\u95ee\u9898\uff0c\u52a0\u4e86\u662f\u66f4\u4e25\u8c28\u3002</p> <p> </p> <p>\u203b \u91cd\u70b9\uff1a</p> <p></p> <p>\u590d\u5e73\u9762\u4e0e\u6307\u6570\uff0c\u4e0e \u4e8c\u7ef4\u5750\u6807 \uff1a</p> <p> </p> <ul> <li>\u6ce8\u610f\u770b\uff0c\u4e0a\u9762\u5de6\u56fe\uff0c\u9006\u65f6\u9488\u65cb\u8f6c\u662f \\(e^{j \\phi}\\) \uff0c\u6307\u6570\u90e8\u5206\u662f\u6b63\u7684\u3002</li> </ul> <p>\u8fd9\u91cc\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u592a\u9ad8\u4e86\uff0c4 \u4e2a\u70b9\uff0c\u8fdb\u884c\u4e86 16 \u6b21\u7684\u8ba1\u7b97\uff0c\\(n^2\\)\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u6240\u4ee5\u540e\u9762\u6709 FFT</p> <p>\u7ee7\u7eed\u770b\u9898\u76ee\uff0c\u8fd9\u91cc\u8fdb\u884c\u4e86\u5f52\u4e00\u5316\uff1a</p> <p> </p> <ul> <li>\u4e0a\u9762\u7684\u5468\u671f\u6027\uff0c\u9700\u8981\u597d\u597d\u7684\u7406\u89e3\u3002</li> </ul> <p>\u8fd9\u91cc\uff0c\u6709 \u590d\u6307\u6570\u4e0e\u5e45\u5ea6\u8c31\u3001\u76f8\u4f4d\u8c31\u7684\u5173\u7cfb\u3002\u56e0\u4e3a\u5206\u89e3\u5230\u9891\u57df\uff0c\u8fd8\u662f\u8981\u8fdb\u884c\u9891\u8c31\u5206\u6790\uff0c\u8981\u6709\u5b9e\u9645\u610f\u4e49\u6765\u7684\u3002</p> <p></p> <p>\u518d\u6765\u770b\uff1a</p> <p></p> <p>\u6700\u7ec8\u5206\u89e3\u51fa\u6765\u7684\u9891\u57df\u8868\u793a\uff1a\\(sin(\\frac{\\pi}{2}n)\\)</p> <p>\u9a8c\u8bc1\uff1a\u539f\u59cb\u65f6\u95f4\u5e8f\u5217 4 \u4e2a\u70b9\u3002</p> <p>\\(n=0\\) \u65f6\uff0c\\(sin(\\frac{\\pi}{2}n) = 0\\)</p> <p>\\(n=1\\) \u65f6\uff0c\\(sin(\\frac{\\pi}{2}1) = 1\\)</p> <p>\\(n=2\\) \u65f6\uff0c\\(sin(\\frac{\\pi}{2}2) = 0\\)</p> <p>\\(n=3\\) \u65f6\uff0c\\(sin(\\frac{\\pi}{2}3) = -1\\)</p> <p>\u521a\u597d\u7531\u9891\u57df\u8fd8\u539f\u4e3a\u65f6\u57df\u3002\\([0,1,0,-1]\\)</p> <ul> <li> \u4e0d\u61c2\uff0c\u600e\u4e48\u7531\u53cc\u8fb9\u8c31\u8f6c\u6362\u4e3a\u5355\u8fb9\u8c31</li> <li> \u4e0d\u61c2\uff0c\u592a\u795e\u5947\u4e86\uff0c\u4e3a\u4ec0\u4e48\u5c31\u7531\u8fd9\u4e2aDFT \u51fa\u6765\u7684\u4e1c\u897f\uff0c\u5c31\u8fd8\u539f\u4e3a\u4e86\u539f\u59cb\u65f6\u95f4\u5e8f\u5217</li> <li> \u795e\u5947\uff0c\u5c5e\u5b9e\u795e\u5947\u3002\\([0,1,0,-1]\\) \u5c31\u5bf9\u5e94\u7684\u4e09\u89d2\u51fd\u6570\u662f \\(sin(\\frac{\\pi}{2}n)\\quad n=0,1,2,3\\) </li> </ul> <p>\u592a\u795e\u5947\u4e86\u3002\u56e0\u4e3a\u628a\uff0c\u660e\u660e\u662f\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u4e0e  \\(e^{-j0\\Omega n}\u3001e^{-j1\\Omega n}\u3001e^{-j2\\Omega n}\u3001e^{-j3\\Omega n}\\) \u8fdb\u884c\u6295\u5f71\u8fd0\u7b97\u3002</p> <p></p> <ul> <li>\u6700\u5f00\u59cb\u5c31\u662f\u628a\u957f\u5ea6\u4e3a \\(N_0\\) \u7684\u4fe1\u53f7\u770b\u6210\u662f\u5468\u671f\u4e3a \\(N_0\\) \u7684\u4fe1\u53f7</li> <li>\u7269\u7406\u542b\u4e49\uff1a\u628a\u5e8f\u5217\u5206\u89e3\u6210\u4e00\u7cfb\u5217\u7684\u5355\u4f4d\u5706\u4e0a\u7684\u590d\u6307\u6570\u5e8f\u5217\u7684\u7ebf\u6027\u7ec4\u5408</li> </ul> <p>\u91cd\u65b0\u770b\u8fd9\u4e2a\u9898 </p> <p></p> <p> </p> <p></p> <p>\u77e9\u9635\u5f62\u5f0f\u8fdb\u884cDFT\uff1a\\(w_{kn}x_n=X_k,\u5176\u4e2dk,n=(0,1,2,...N-1)\\)</p> <p>$ \\Omega = \\frac{2\\pi}{N}=\\frac{2\\pi}{4} = \\frac{\\pi}{2}$ (\u8fd9\u4e1c\u897f\u53eb\u5565\uff1f\u57fa\u9891\u3001\u57fa\u6ce2\uff0c\u8fd8\u662f\u89d2\u9891\u7387\uff0c\u603b\u4e4b\u662f\\(T=N\\))</p> <p>\u4e5f\u5c31\u662f \\(\\omega_0 = e^{-\\frac{\\pi}{2}i}\\)    \u66f4\u8fdb\u4e00\u6b65\uff0c\\(\\omega_0 = e^{-\\frac{\\pi}{2}i} = -i\\)  \u7269\u7406\u542b\u4e49\uff1a\u6cbf\u7740\u5355\u4f4d\u5706\u53cd\u65b9\u5411\u65cb\u8f6c \\(\\frac{\\pi}{2}\\)</p> <p> </p>"},{"location":"Statistics/1_0_fourier/#_4","title":"\u590d\u5e73\u9762||\u590d\u6307\u6570\u7684\u5468\u671f\u6027","text":"<p>\u590d\u6307\u6570\u7684\u5468\u671f\u6027\uff1a</p> <p>\\(e^{ix}\\) \u5468\u671f \\(T=2\\pi\\)</p> <p>\u590d\u6307\u6570\u7684\u4e00\u822c\u5f62\u5f0f \\(e^{i\\Omega t}\\) \u5468\u671f \\(T=\\frac{2\\pi}{\\Omega}\\)</p> <p></p> <ul> <li> <p>\u8fd9\u91cc\u7684 \\(n= \\pm 1\u3001\\pm 2\u3001\\pm 3,......\\)</p> </li> <li> <p>\\(e^{i}\\) \u6307\u6570\u90e8\u5206 \\(\uff1e0\\) \uff1a\u8868\u793a\u9006\u65f6\u9488\u65cb\u8f6c\uff0c\u662f\u6b63\u65b9\u5411\u3002</p> </li> <li>\\(e^{ix} \\&amp; e^{-ix}\\) \uff1a\u5b9e\u90e8\u4e0d\u53d8\uff0c\u865a\u90e8\u4e92\u4e3a\u76f8\u53cd\u6570</li> </ul> <p>\u89e3\u91ca\uff1a </p> <ul> <li>\\(e^{ix} = \\cos x + i \\sin x\\)</li> <li>\\(e^{-ix} = \\cos x - i \\sin x\\)</li> </ul> <ul> <li> \uff08solved\uff09\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898 \u4e0d\u6e05\u695a \\(T=N\u3001T=\\frac{N}{2}\u3001T=\\frac{N}{3}\u3001T=\\frac{N}{4}\\) \uff1f\u8ddf  \\(\\omega \u3001T\\) \uff1f</li> </ul> <ul> <li>\\(\\omega = 2\\pi f = \\frac{2 \\pi}{T}\\) </li> </ul> <p>\u628a\u8bb0\u53f7\u533a\u5206\u4e00\u4e0b\u5c31\u597d\u3002 </p> <p>\\(\\Omega = \\frac{2\\pi}{N}\\)  \u6240\u4ee5 \u8fd9\u4e2a\u53eb\u57fa\u6ce2\u7684\u89d2\u9891\u7387\uff0c\\(T=N\\) \u540e\u9762\u4f9d\u6b21\uff0c\\(N/2\u3001N/3\u3001......\\)</p> <p>\u8fd9\u91cc\u53d8\u5316\u7684\u662f \\(k\\)\uff0c\u60f3\u8981\u8ba8\u8bba\u7684\u662f\u57fa\u6ce2\u3001\u8c10\u6ce2</p> <p>\\(\\Omega = \\frac{2\\pi}{N}\\)   \u2192 \\(T=N\\)</p> <p>\\(2\\Omega = \\frac{2\\pi}{N/2}\\)   \u2192 \\(T=N/2\\)</p> <p>\\(3\\Omega = \\frac{2\\pi}{N/3}\\)   \u2192 \\(T=N/3\\)</p> <p>\\(4\\Omega = \\frac{2\\pi}{N/4}\\)   \u2192 \\(T=N/4\\)</p> <p>(1)\\(X_k = \\sum_{n=0}^{N-1} x_n e^{-i\\frac{2 \\pi k n}{N}}\\)</p> <p>(2) \\(\\quad = \\sum_{n=0}^{N-1} x_n e^{-i \\Omega kn}\\)</p> <p>(3)\\(X_k = w^{kn}x_n\\) \uff0c\\(kn=0 \\sim N-1\\) </p> <p></p> <p>\uff08\u56de\u7b54\uff09\u501f\u52a9\u4e0a\u9762\u7684\u9898\u76ee\uff0c\u91cd\u65b0\u89c4\u8303\u4e00\u4e0b\u7b26\u53f7\u8868\u8fbe\u4e0e\u4e00\u4e9b\u53eb\u6cd5\uff0c\u611f\u89c9\u7406\u6e05\u695a\u4e86\uff1a</p> <p>\\(\\omega = 2\\pi f = \\frac{2 \\pi}{T}\\) </p> <p>\u7ed9\u5b9a\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217 \u957f\u5ea6\u4e3aN\uff0c\u8fdb\u884c DFT</p> <p>\u5728\u8fdb\u884c DFT \u7684\u65f6\u5019\uff0c\u4e09\u89d2\u51fd\u6570\u7684\u5206\u89e3\u662f\u9075\u5faa\u4e00\u5b9a\u89c4\u5219\u7684\uff0c\u5468\u671f\u662f\u5f88\u89c4\u8303\u7684\u9009\u53d6\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f \\(T=N\u3001T=\\frac{N}{2}\u3001T=\\frac{N}{3}\u3001T=\\frac{N}{4},...\\)</p> <ul> <li> \u6700\u540e\u4e00\u4e2a\u662f \\(\\frac{N}{N-1}\\)? \u8fd8\u6709 \\(\\frac{N}{N}\\)? \u8fd8\u6709\u5e8f\u5217\u5143\u7d20\u52a0\u548c\u662f\u4ec0\u4e48\u5468\u671f\u7684</li> </ul> <p>\u8bb0 \\(\\Omega = \\frac{2\\pi}{N}\\) </p> <p>\u8865\u5145\uff1a\u8fd9\u91cc\u53d8\u5316\u7684\u662f \\(k\\)\uff0c\u60f3\u8981\u8ba8\u8bba\u7684\u662f\u57fa\u6ce2\u3001\u8c10\u6ce2</p> <p>\\(\\Omega = \\frac{2\\pi}{N}\\)   \u2192 \\(T=N\\)</p> <p>\\(2\\Omega = \\frac{2\\pi}{N/2}\\)   \u2192 \\(T=N/2\\)</p> <p>\\(3\\Omega = \\frac{2\\pi}{N/3}\\)   \u2192 \\(T=N/3\\)</p> <p>\\(4\\Omega = \\frac{2\\pi}{N/4}\\)   \u2192 \\(T=N/4\\)</p> <p>DFT : \\(X_k = \\sum_{n=0}^{N-1} x_n e^{-i\\frac{2 \\pi k n}{N}}\\)</p> <p>\\(\\quad = \\sum_{n=0}^{N-1} x_n e^{-i \\Omega kn}\\)</p> <p>\u6b63\u4ea4\u57fa\uff1a\\(1\uff0ce^{-i \\Omega }\u3001e^{-i 2\\Omega }\u3001e^{-i 3\\Omega }\u3001e^{-i 4\\Omega }......\\) </p> <p>\u8bb0\u4e3a \\(\\omega = e^{i \\Omega } = e^{i\\frac{2 \\pi k }{N}}\\)  \u4e5f\u6709\u8bb0\u6210 \\(\\omega_0\\) \u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u7684\u957f\u5ea6\uff0c\u662f\u5468\u671f\u6700\u957f\u7684\uff0c\u4ee5\u6b64\u4e3a\u57fa\u7840\u8fdb\u884c \u6b63\u5f26\u51fd\u6570\u3001\u4f59\u5f26\u51fd\u6570\u7684\u5c55\u5f00\u3002</p> <p>\u77e9\u9635\u5f62\u5f0f\u7684 DFT \u7b80\u5355\u8bb0\u6cd5\uff1a\\(X_k = w^{kn}x_n\\)  \uff0c\\(kn=0 \\sim N-1\\)</p> <p> </p>"},{"location":"Statistics/1_0_fourier/#dft_2","title":"\u6570\u5b66 &amp; DFT","text":"<p>\u6570\u5b57\u4fe1\u53f7\u5904\u7406_\u5f15\u8a00 </p> <p>\u7b26\u53f7\u8868\u793a\uff1a </p> <p></p> <p>\u91c7\u6837\u5b9a\u7406\uff1a</p> <p></p> <ul> <li>\u8fd9\u91cc\u7684\u91c7\u6837\u5468\u671f=0.01s\uff0c\u4e5f\u5c31\u662f\u8bf4\u91c7\u6837\u9891\u7387=100Hz</li> <li>\u5bf9\u5e94\u7684\u91c7\u6837\u4ee5\u540e\uff0c200Hz \u7684\u91c7\u4e0d\u5230\u4e86\uff0c\u4e5f\u5c31\u662f\u8bf4\u8fc7\u6ee4\u6389\u4e86 200Hz \u7684\u566a\u58f0\u4fe1\u53f7</li> <li>\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\uff0c\u5047\u8bbe\u8981\u91c7\u5230 500Hz \u7684\u4fe1\u53f7\uff0c\u90a3\u4e48\u91c7\u6837\u9891\u7387\u8bbe\u7f6e\u6210\u591a\u5c11\uff1f\u7b54\uff1a2 \u500d\u7684 500Hz\uff0c\u4e5f\u5c31\u662f\u8bf4\u9700\u8981\u8bbe\u7f6e\u4e3a 1000Hz \u7684\u91c7\u6837\u9891\u7387\uff0c\u4e5f\u5c31\u662f0.001s \u91c7\u6837\u4e00\u4e2a\u70b9\u3002</li> </ul> <p></p> <ul> <li>\u592a\u795e\u5947\u4e86</li> <li>\u5229\u7528matlab \u81ea\u5e26\u7684 fft \u53d8\u6362\uff0c\u53d1\u73b0 10Hz\uff0c40Hz \u9644\u8fd1\u786e\u5b9e\u54cd\u5e94\u503c\u6bd4\u8f83\u9ad8</li> <li>\u5fae\u5f31\u4fe1\u53f7\u662f\u91c7\u6837\u8fc7\u7a0b\u5bfc\u81f4\u7684\u9891\u8c31\u6cc4\u9732\u95ee\u9898</li> <li>\u90a3\u6211\u4eec\u60f3\u8981\u7684\u662f 10Hz\uff0c\u540e\u9762\u8bbe\u8ba1\uff08\u4f4e\u901a\uff09\u6ee4\u6ce2\u5668\uff0c\u53bb\u6389 40Hz \u7684\u5373\u53ef</li> </ul> <p> </p> <ul> <li>\u5c31\u662f MATLAB \u6f14\u793a\u4f4e\u901a\u6ee4\u6ce2\u5668</li> </ul>"},{"location":"Statistics/1_0_fourier/#_5","title":"(\u7eed)\u4f8b\u9898","text":"<p>DFT \u6ca1\u6709\u9057\u6f0f\u4e86\u5f52\u4e00\u5316\u8fc7\u7a0b</p> <p>\\(j \\Omega k t\\)</p> <p>\u91cd\u70b9\u9700\u8981\u7406\u89e3\uff0cFFT \u5206\u89e3\u51fa\u6765\u7684\u590d\u6570\u7684\u7ed3\u679c\u662f\u4ec0\u4e48\u610f\u601d</p> <p> </p> <p>\u66f4\u5b9e\u9645\u7684\u4f8b\u5b50\uff1a</p> <p>\u5229\u7528\u8ba1\u7b97\u673a\u8ba1\u7b97 DFT\uff0c\u5f97\u5230\u76f8\u4f4d\u89d2\u548c\u5e45\u503c</p> <p> </p> <ul> <li>\uff08\u5df2\u89e3\u51b3\uff1a\u91c7\u6837\u5b9a\u7406\uff09\u4e3a\u4ec0\u4e48\u9891\u7387\u662f 25Hz</li> <li>\\(\\Omega kn\\)   \u8fd9\u91cc \\(k=5\uff0ck=10\\) \u6709\u54cd\u5e94 \uff0c\\(\\Omega = \\frac{2\\pi}{N}\\) \uff0c\u81f3\u4e8e \u56fe\u7247\u4e2d\u7684 \\(2 \\pi\\) \u5e94\u8be5\u662f\u8fdb\u884c\u4e86\u5f52\u4e00\u5316\u3002\u5426\u5219\u7684\u8bdd\uff0c\u5e94\u8be5\u662f  \\(1\\Omega n\u30012 \\Omega n\u30013 \\Omega n\u30014 \\Omega n,......\\) </li> <li>50Hz\u7684\u91c7\u6837\u7387\u8868\u793a\u4ec0\u4e48\uff1f1s \u91c7\u6837 50 \u4e2a\u6837\u672c\u70b9\uff0c\u6839\u636e\u91c7\u6837\u5b9a\u7406\uff0c\u786e\u5b9e\u53ea\u80fd\u6700\u5927\u89c2\u5bdf\u5230\u7684\u9891\u7387\u662f 25Hz\uff0c\u522b\u7684\u90fd\u88ab\u8fc7\u6ee4\u6389\u4e86\u3002</li> </ul> <p>\u91c7\u6837\u5b9a\u7406\uff1a</p> <p></p> <ul> <li>\u8fd9\u91cc\u7684\u91c7\u6837\u5468\u671f=0.01s\uff0c\u4e5f\u5c31\u662f\u8bf4\u91c7\u6837\u9891\u7387=100Hz</li> <li>\u5bf9\u5e94\u7684\u91c7\u6837\u4ee5\u540e\uff0c200Hz \u7684\u91c7\u4e0d\u5230\u4e86\uff0c\u4e5f\u5c31\u662f\u8bf4\u8fc7\u6ee4\u6389\u4e86 200Hz \u7684\u566a\u58f0\u4fe1\u53f7</li> <li>\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\uff0c\u5047\u8bbe\u8981\u91c7\u5230 500Hz \u7684\u4fe1\u53f7\uff0c\u90a3\u4e48\u91c7\u6837\u9891\u7387\u8bbe\u7f6e\u6210\u591a\u5c11\uff1f\u7b54\uff1a2 \u500d\u7684 500Hz\uff0c\u4e5f\u5c31\u662f\u8bf4\u9700\u8981\u8bbe\u7f6e\u4e3a 1000Hz \u7684\u91c7\u6837\u9891\u7387\uff0c\u4e5f\u5c31\u662f0.001s \u91c7\u6837\u4e00\u4e2a\u70b9\u3002</li> </ul> <p> </p> <p>DFT \u7684\u601d\u60f3\u662f\uff0c\u5982\u679c\u91c7\u96c6\u5230\u7684\u6570\u636e\u957f\u5ea6\u662f \\(N_0\\) \u90a3\u4e48\u5c31\u8ba4\u4e3a\u6570\u636e\u7684\u5468\u671f\\(=N_0\\) \uff0c\u7136\u540e\u8fdb\u884c DFT\uff0c\u770b\u91cc\u9762\u6709\u591a\u5c11\u4e2a\u5206\u91cf\u3002</p>"},{"location":"Statistics/1_1_fourier/","title":"\u76f4\u89c2\u7406\u89e3\u5085\u91cc\u53f6\u53d8\u6362","text":""},{"location":"Statistics/1_1_fourier/#_1","title":"\u76f4\u89c2\u7406\u89e3\u5085\u91cc\u53f6\u53d8\u6362","text":"2025-03-25 23:35:092025-09-28 12:54:03 <p> \u7ea6 739 \u4e2a\u5b57  9 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p> <p>\u76f4\u89c2\u7406\u89e3\u5085\u91cc\u53f6\u53d8\u6362</p> <p></p> <p>\u65f6\u57df\u3001\u9891\u57df\u8f6c\u6362\u53ea\u6d89\u53ca\u4e09\u4e2a\u56fe\uff1a\u65f6\u57df\u56fe\u3001\u632f\u5e45\u8c31\u3001\u76f8\u4f4d\u8c31</p> <p> </p> <p>\u5085\u91cc\u53f6\u7ea7\u6570\u9886\u57df\uff0c\u8ba4\u4e3a\uff0c\u6ce2 \u6700\u57fa\u672c\u7684\u7269\u8d28\u5355\u4f4d \u662f \u4e09\u89d2\u51fd\u6570\uff1b</p> <p>\u5404\u79cd\u590d\u6742\u7684\u57fa\u672c\u4fe1\u53f7\u90fd\u662f\u4e09\u89d2\u51fd\u6570\u7684\u53e0\u52a0\u3002\u66f4\u57fa\u672c\u7684\uff0c\u662f\u6b63\u5f26\u4e09\u89d2\u51fd\u6570\u7684\u53e0\u52a0\u3002</p> <p></p> <p>\u6b63\u5f26\u6ce2\u3001\u4f59\u5f26\u6ce2\u90fd\u662f\u6b63\u5f26\u4fe1\u53f7\uff0c\u53ea\u662f\u8ba4\u4e3a\u76f8\u5dee \\(\\frac{\\pi}{2}\\) \u7684\u76f8\u4f4d\u5bf9\u5e94\u7684 \u5085\u91cc\u53f6\u7ea7\u6570\u4e5f\u662f\u65e2\u53ef\u4ee5\u5c55\u5f00\u4e3a\u53ea\u542b\u6709\u6b63\u5f26\u6ce2\u7684\uff0c\u4e5f\u53ef\u4ee5\u5c55\u5f00\u4e3a\u53ea\u542b\u6709\u4f59\u5f26\u6ce2\u7684\u3002</p> <p></p> <p>\u5148\u5c06\u65f6\u57df\u4fe1\u53f7\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u8f6c\u6362\u4e3a\u9891\u57df\u4fe1\u53f7</p> <p></p> <p>\u4ece\u524d\u5411\u540e\u89c2\u5bdf\uff0c\u5f97\u5230**\u65f6\u57df\u56fe**</p> <p></p> <p>\u632f\u5e45\u8c31\uff1a</p> <p>\u4ece\u524d\u5f80\u540e\u89c2\u5bdf\uff0c\u5f97\u5230\u632f\u5e45\u8c31\uff0c\u4e0a\u4e0b\u632f\u5e45\u4fdd\u7559\u5355\u4fa7</p> <p></p> <p>\u76f8\u4f4d\u8c31\uff1a</p> <p>\u4ece\u4e0a\u5f80\u4e0b\u89c2\u5bdf\uff0c\u53bb\u6389\u76f8\u540c\u7684\u90e8\u5206\uff0c\u5f97\u5230\u76f8\u4f4d\u8c31\uff0c\u7ffb\u8f6c\u76f8\u4f4d\u8c31\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u4fbf\u4e8e\u89c2\u5bdf</p> <p>\u76f8\u4f4d\uff1a $ A sin(2 \\pi f \\cdot x + \\phi)$ \uff0c\u5176\u4e2d \\(\\phi\\) \u5c31\u662f\u76f8\u4f4d\u8c31</p> <p> </p> <p>\u603b\u7ed3\uff1a</p> <p></p> <ul> <li>\u4ece\u524d\u5f80\u540e\u89c2\u5bdf\u662f \u9891\u57df\u56fe\u50cf\uff0c\u4e5f\u5c31\u662f\u632f\u5e45\u8c31  $ A sin(2 \\pi f \\cdot x + \\phi)$ \u4e5f\u5c31\u662f \\(A\\) </li> <li>\u4ece\u5de6\u5f80\u53f3\u89c2\u5bdf\u662f\u65f6\u57df\u56fe\u50cf\uff0c\u4ece\u5de6\u5f80\u53f3\u89c2\u5bdf\u5e76\u76f8\u52a0</li> <li>\u4ece\u4e0a\u5f80\u4e0b\u770b\u662f\u76f8\u4f4d\u8c31 \\(\\phi_0\\)  \u521d\u76f8\u4f4d</li> <li>\u8fd8\u6709\u4e00\u70b9\u9700\u8981\u5f3a\u8c03\uff0c\u4f4e\u9891\u6ce2\u63cf\u8ff0\u8f6e\u5ed3\uff0c\u4ee3\u8868\u957f\u671f\u8d8b\u52bf\uff1b\u9ad8\u9891\u6ce2\u63cf\u8ff0\u7ec6\u8282\u3002</li> </ul> <p>\u5bf9\u5e94\u5230\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362</p> \\[ X_k = \\sum_{n=0}^{N-1} x_t e^{-i\\frac{2\\pi k n}{N}} \\quad n=0,1,2,3...,N-1\\] <p>\u5176\u4e2d\uff0c\\(k= 0,1,2,3...,N-1\\) \u4e5f\u662f\u8fd9\u4e2a\u8303\u56f4\uff0c\u540c\u65f6\u9700\u8981\u6ce8\u610f\u7684\u662f \u4e00\u822c\u662f\u56fa\u5b9a\u4e00\u4e2a \\(k\\)\uff0c\u7136\u540e\u6240\u6709\u65f6\u95f4\u70b9 \\(x_0,x_1,x_2,x_3,.....,x_{N-1}\\) \u671d\u7740 \u56fa\u5b9a\u7684 \\(k\\) \u9891\u7387\u8fdb\u884c\u76f8\u5173\u6027\u8ba1\u7b97\uff0c\u6216\u8005\u53eb\u6295\u5f71\u3002</p> <ul> <li> \u5176\u5b9e\u5173\u4e8e\u8fd9\u4e2a k \u4e0e\u9891\u7387 f \u7684\u5173\u7cfb\uff0c\u6211\u4e5f\u4e0d\u6e05\u695a</li> </ul> <p>\\(e^{-i\\frac{2\\pi k n}{N}} = cos\\frac{2\\pi k n}{N} - isin\\frac{2\\pi k n}{N}\\)</p> <p>\\(\\omega_0 = \\frac{2\\pi}{N} = 2 \\pi f\\)</p> <p>\u6240\u4ee5\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u4e5f\u8bb8\uff0c\\(\\omega_k = \\frac{2\\pi k}{N} = 2 \\pi f\\)</p> <p>\u4e5f\u5c31\u662f\u8bf4 \\(f=\\frac{k}{N}\\)</p> <p>\\(\\omega_k = \\frac{2\\pi k}{N}\\) \u8868\u793a \u539f\u59cb \u65f6\u95f4\u5e8f\u5217 \u4e0e\u8be5 \u9891\u7387\u7684\u76f8\u5173\u6027\uff1f</p> <p>\u8fd8\u6709\u8fd9\u79cd\u8f6c\u51e0\u5708\u7684\u95ee\u9898\u6211\u4e5f\u4e0d\u660e\u767d\u3002 </p> <p>k=1\uff0c\u8868\u793a\u539f\u59cb\u65f6\u95f4\u5e8f\u5217 \\(T=N\\)  \uff1b\\(N\\)\u4e2a\u65f6\u95f4\u70b9\u6784\u6210\u4e00\u4e2a\u5468\u671f</p> <p>k=2\uff0c\u8868\u793a \\(T = \\frac{N}{2}\\) \uff1f\u56e0\u4e3a \u53ef\u4ee5\u770b\u6210  \\(\\frac{2 \\pi}{\\frac{N}{2}}\\)</p> <p>k=3\uff0c\u8868\u793a\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u6784\u6210 3 \u4e2a\u5468\u671f</p> <p>\u8fd8\u6709\uff0cDFT \u4e0e\u632f\u5e45\u8c31\u3001\u76f8\u4f4d\u8c31\u7684\u5173\u7cfb \u6211\u4e5f\u4e0d\u660e\u767d</p> <p>$ X_k = \\sum_{n=0}^{N-1} x_t e^{-i\\frac{2\\pi k n}{N}} \\quad n=0,1,2,3...,N-1$</p> <p>\\(e^{-i\\frac{2\\pi k n}{N}} = cos\\frac{2\\pi k n}{N} - isin\\frac{2\\pi k n}{N}\\)</p> <p>\u6240\u4ee5 $ X_k = \\sum_{n=0}^{N-1} x_t (cos\\frac{2\\pi k n}{N} - isin\\frac{2\\pi k n}{N}) $</p> <p>$ \\quad = \\sum_{n=0}^{N-1} x_t cos\\frac{2\\pi k n}{N} - i x_t sin\\frac{2\\pi k n}{N}) $</p> <p>\u632f\u5e45\uff1a \\(x_t\\)</p> <p>\u89d2\u5ea6\uff1a\\(\\frac{2\\pi k n}{N}\\) </p>"},{"location":"Statistics/1_2_signal/","title":"\u4fe1\u53f7\u7684\u5408\u6210\u4e0e\u5206\u89e3","text":"2025-03-27 00:00:002025-09-28 12:54:03 <p>\u5085\u91cc\u53f6\u7ea7\u6570\u7684\u4e09\u89d2\u5f62\u5f0f\u3001\u6307\u6570\u5f62\u5f0f\u3001\u76f8\u4f4d\u3001\u9891\u8c31</p> <p>\u5085\u91cc\u53f6\u7684\u4e09\u89d2\u51fd\u6570\uff1a</p> <p>\u6b63\u4ea4\u57fa\uff1a\\(\\cos1\\omega x,\\sin1\\omega x,\\cos2\\omega x,\\sin2\\omega x,\\cos3\\omega x,\\sin3\\omega x,...,\\)</p> <p>\u5085\u91cc\u53f6\u7684\u6307\u6570\u51fd\u6570\u5f62\u5f0f\uff1a</p> <p>\u6b63\u4ea4\u57fa\uff1a\\(\\{e^{-jn\\omega t},...,e^{-j2\\omega t},e^{-j\\omega t},e^{j0\\omega t},e^{j\\omega t},e^{j2\\omega t},...e^{jn\\omega t}\\}\\)</p> <p>\u6570\u5b57\u4fe1\u53f7\u5904\u7406_\u4fe1\u53f7\u7684\u5408\u6210\u4e0e\u5206\u89e3</p> <p>\u590d\u6570\u5f62\u5f0f\uff1a\\(a+bi\\)</p> <p>\u590d\u6307\u6570\u5f62\u5f0f\uff1a\\(\\sqrt{a^2+b^2}(cos\\theta+i sin\\theta)\\) </p> <p>\u5176\u4e2d\uff0c</p> <p>\\(cos\\theta = \\frac{a}{\\sqrt{a^2+b^2}}\\) </p> <p>$sin\\theta = \\frac{ b }{ \\sqrt{a^2 + b^2} } $  </p> <p></p> <ul> <li>\u5c24\u5176\u6ce8\u610f\u8fd9\u91cc\u5185\u79ef\u7684 \u8d1f\u53f7 </li> </ul> <p> </p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_1","title":"\u5411\u91cf\u7684\u5408\u6210\u4e0e\u5206\u89e3","text":"<p>\u7ea2\u8272\u662f\u60f3\u8981\u8868\u793a\u7684\u5411\u91cf\u3002 </p> <p></p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_2","title":"\u4fe1\u53f7\u7684\u5408\u6210\u4e0e\u5206\u89e3","text":"<p>\u5085\u91cc\u53f6\u53d8\u6362\u7684\u601d\u60f3\uff0c\u5c06\u590d\u6742\u7684\u5468\u671f\u4fe1\u53f7\u53d8\u6210\u4e00\u7cfb\u5217\u7b80\u5355\u4e09\u89d2\u51fd\u6570\u7684\u7ebf\u6027\u8868\u793a\u3002</p> <p>\u8fd9\u4e2a\u601d\u60f3\u600e\u4e48\u8fd9\u4e48\u50cf \u6cf0\u52d2\u5c55\u5f00\uff0c\u5c06\u4efb\u610f\u4e00\u4e2a\u51fd\u6570\u5c55\u5f00\u6210\u4e00\u7cfb\u5217\u5e42\u51fd\u6570\u6c42\u548c\u3002\u6cf0\u52d2\u5c55\u5f00\u4ece\u5bfc\u6570\u89d2\u5ea6\u9010\u70b9\u6a21\u4eff\u3002\u90a3\uff0c\u5085\u91cc\u53f6\u53d8\u6362\u5462\uff1f\u600e\u4e48\u7528\u66f4\u901a\u4fd7\u7684\u8bed\u8a00\u63cf\u8ff0\uff1f</p> <p>\u51fd\u6570\u5185\u79ef\uff1a\u52a0\u6cd5\u53d8\u79ef\u5206\u8fd0\u7b97</p> <p></p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_3","title":"\u4e09\u89d2\u51fd\u6570\u6b63\u4ea4\u57fa","text":"<p>\u4e09\u89d2\u51fd\u6570\u96c6\u7684\u6b63\u4ea4\u6027</p> <p></p> <p>\u7ed3\u8bba\uff1a</p> <ul> <li>\u4efb\u610f\u4e24\u4e2a\u4e0d\u540c\u51fd\u6570\u5185\u79ef=0</li> <li>\u76f8\u540c\u51fd\u6570\u5185\u79ef \\(\\neq 0\\) </li> </ul> <p></p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_4","title":"\u5468\u671f\u4fe1\u53f7 \u5085\u91cc\u53f6\u7ea7\u6570","text":"<ul> <li>\u6b63\u4ea4\u57fa\u662f\uff1a</li> </ul> <p>\\(\\{1,\\cos x,\\sin x,\\cos 2x,\\sin 2x,...,\\cos nx,\\sin nx\\}\\) </p> <p>\u6700\u5927\u5468\u671f\u662f \\(2\\pi\\)\uff0c  \u6700\u5927\u5468\u671f\u5185 \u3001\u6b63\u4ea4\u57fa\u4e2d\u7684\u5176\u4f59\u51fd\u6570\u3001\u91cd\u590d\u6574\u6570\u6b21\uff0c\u5982\\(1,2,3,4,....n\\)\u3002\u5c31\u662f\u6b63\u4ea4\u57fa\u51fd\u6570\u524d\u9762\u7684\u7cfb\u6570\u3002</p> <p>\u7406\u89e3\uff08\u4e3a\u4e86\u6015\u81ea\u5df1\u4ee5\u540e\u60f3\u4e0d\u8d77\u6765\uff0c\u91cd\u590d\u65e0\u6570\u6b21\uff0c\u4e0d\u538c\u5176\u70e6\ud83e\udd72\uff09\uff1a</p> <ul> <li>\\(\\cos x,\\sin x\\)  \u6700\u5927\u5468\u671f \\(2\\pi\\)</li> <li>\\(\\cos 2x,\\sin 2x\\) \u5468\u671f\\(=\\pi\\) \uff0c\u6700\u5927\u5468\u671f \\(2\\pi\\) \u5185\u91cd\u590d 2 \u6b21</li> <li>\\(\\cos 3x,\\sin 3x\\) \u5468\u671f\\(=\\frac{2\\pi}{3}\\) \uff0c\u6700\u5927\u5468\u671f \\(2\\pi\\) \u5185\u91cd\u590d 3 \u6b21</li> <li>...</li> <li>\\(\\cos nx,\\sin nx\\) \u5468\u671f\\(=\\frac{2\\pi}{n}\\) \uff0c\u6700\u5927\u5468\u671f \\(2\\pi\\) \u5185\u91cd\u590d \\(n\\) \u6b21 </li> </ul> <ul> <li>\u5085\u91cc\u53f6\u7ea7\u6570\u7528\u7684\u662f\uff1a</li> </ul> <p>\\(\\cos1\\omega x,\\sin1\\omega x,\\cos2\\omega x,\\sin2\\omega x,\\cos3\\omega x,\\sin3\\omega x,...,\\)</p> <p>\u6700\u5927\u5468\u671f\uff0c\u5c31\u662f\u8981\u5c55\u5f00\u7684\u5468\u671f\u4fe1\u53f7\u7684\u5468\u671f \\(T\\) \uff0c\u524d\u9762\u5df2\u7ecf\u8bb0 \\(\\omega = \\frac{2\\pi}{T}\\)</p> <ul> <li> <p>\\(\\cos1\\omega x,\\sin1\\omega x\\) \u6700\u5927\u5468\u671f \\(T\\)</p> </li> <li> <p>\\(\\cos2\\omega x,\\sin2\\omega x\\) \u5468\u671f\\(=\\frac{T}{2}\\) \uff0c\u6700\u5927\u5468\u671f \\(T\\) \u5185\u91cd\u590d \\(2\\) \u6b21</p> </li> <li> <p>\\(\\cos3\\omega x,\\sin3\\omega x\\) \u5468\u671f\\(=\\frac{T}{3}\\) \uff0c\u6700\u5927\u5468\u671f \\(T\\) \u5185\u91cd\u590d \\(3\\) \u6b21</p> </li> </ul> <p>\u76ee\u524d\uff0c\u5c31\u662f\u611f\u89c9\uff0c\u5085\u91cc\u53f6\u7ea7\u6570\u5c31\u662f\u8bf4\u628a\u7ed9\u5b9a\u4e00\u7ec4\u65f6\u95f4\u5e8f\u5217\u6570\u636e</p> <p>\u8fd9\u7ec4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u662f1\u4e2a\u5468\u671f\u7684\u53ef\u80fd\u6027\uff1f\u662f\u8fd9\u4e48\u63cf\u8ff0\u5417\uff1f</p> <p>\u8fd9\u7ec4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u662f2\u4e2a\u5468\u671f\u7684\u53ef\u80fd\u6027\uff0c\u8fd9\u7ec4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u662f3\u4e2a\u5468\u671f\u7684\u53ef\u80fd\u6027\uff0c\u8fd9\u7ec4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u662f4\u4e2a\u5468\u671f\u7684\u53ef\u80fd\u6027\uff0c.......</p> <p>\u6216\u8005\u8bf4\uff1a</p> <p>\u8fd9\u7ec4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u662f2\u4e2a\u5468\u671f\u7684\u8bdd\uff0c\u76f8\u5173\u6027\uff0c\u6bcf\u4e2a\u65f6\u95f4\u70b9\u4e0e\u5bf9\u5e94\u5468\u671f\u7684\u4e09\u89d2\u51fd\u6570\u7684\u54cd\u5e94\u503c\u7684\u76f8\u5173\u6027\uff1f</p> <p>\u8fd9\u4e48\u63cf\u8ff0\uff1a\\(f(t)\\)\u662f\u60f3\u8981\u5206\u89e3\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u8981\u5206\u89e3\u5230\u8fd9\u7ec4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u6784\u6210 1 \u4e2a\u5468\u671f\uff0c2 \u4e2a\u5468\u671f\uff0c3\u4e2a\u5468\u671f\u7684\u6807\u51c6\u6b63\u4f59\u5f26\u51fd\u6570\u4e0a\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e09\u89d2\u51fd\u6570\u6b63\u4ea4\u57fa\u8bf4\u7684\u662f \u8fd9\u7ec4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5206\u89e3\u5230\u54ea\u4e2a\u9891\u7387\u7684 3 \u4e2a\u51fd\u6570\u4e0a\uff0c\u904d\u5386\u6240\u6709\u7684\u53ef\u80fd\u6027\uff08\\(1 \\sim \\infty\\) DFT\u662f \\(n=1 \\sim N-1\\)\uff09\u3002\u786e\u5b9a\u4e00\u4e2a\u4e09\u89d2\u51fd\u6570\u4e0d\u4ec5\u9700\u8981\u9891\u7387\uff0c\u8fd8\u6709\u632f\u5e45\u548c\u521d\u59cb\u76f8\u4f4d\uff0c\u4e09\u89d2\u51fd\u6570\u7684\u6807\u51c6\u5f62\u5f0f \\(A\\sin(\\omega x+\\phi)\\)</p> <p>\u6709\u4e86 \\(\\omega\\)\u4ee5\u540e\uff0c\u8fd8\u8981\u627e\u632f\u5e45 \\(A\\) \u548c\u521d\u59cb\u76f8\u4f4d \\(\\phi\\) \u5177\u4f53\u7684\u5c31\u662f\u6b63\u4ea4\u57fa\u6c42 \\(a_n\\) \u548c \\(b_n\\)\u4e86</p> <p>\u4e32\u8d77\u6765\u4e86\uff0c\u90fd\u4e32\u8d77\u6765\u4e86\uff0c\u7cfb\u6570\u7684\u542b\u4e49\u3002</p> <p>\u540e\u9762\u8fd8\u5e94\u8be5\u6ce8\u610f\uff0c\u4e3a\u4ec0\u4e48\u590d\u6307\u6570\u5f62\u5f0f\u66f4\u597d\uff0c\u56e0\u4e3a\u9891\u7387\u3001\u76f8\u4f4d\u3001\u632f\u5e45\u90fd\u76f4\u89c2\u5730\u663e\u793a\u4e86\u3002</p> <ul> <li>\u5c06\u539f\u59cb\u5468\u671f\u4fe1\u53f7\u8868\u793a\u6210\uff1a\u76f4\u6d41\u5206\u91cf\u3001\u6b63\u5f26\u4fe1\u53f7\u3001\u4f59\u5f26\u4fe1\u53f7\u7ebf\u6027\u7ec4\u5408\u7684\u65b9\u5f0f</li> </ul> <p> </p> <ul> <li>\u6b63\u4f59\u5f26\u4fe1\u53f7\u5206\u522b\u8bb0\u4e3a\uff0c1 \u6b21\u8c10\u6ce2\u30012 \u6b21\u8c10\u6ce2\u30013 \u6b21 \u8c10\u6ce2\uff0c\u610f\u601d\u5c31\u662f\u9891\u7387\u5206\u522b\u662f\uff0c\\(1\\omega\\)\u3001\\(2\\omega\\)\u3001\\(3\\omega\\) \uff0c\u8fd9\u91cc\u7684\u9891\u7387\u8bf4\u7684\u662f\u89d2\u9891\u7387  \\(\\rightarrow\\) \u8fd9\u4e2a\u590d\u6742\u7684\u5468\u671f\u4fe1\u53f7\u4e0e\u7b80\u5355\u76841\u6b21\u8c10\u6ce2\u30012\u6b21\u8c10\u6ce2\u7684\u76f8\u5173\u6027\ud83d\udd34</li> <li>\u8fd9\u91cc\u7684\u89d2\u9891\u7387\u53ef\u4ee5\u4e00\u76f4\u53d6\u5230\u65e0\u7a77\u5927</li> </ul> <p>\u5085\u91cc\u53f6\u8ba1\u6570\u7684\u51e0\u4f55\u610f\u4e49</p> <p></p> <ul> <li>\\(\u7cfb\u6570\\)\u8868\u793a\u4fe1\u53f7\u5728\u5bf9\u5e94\u9891\u7387\u4e0a\u7684\\(\u5750\u6807\\)</li> </ul> <p>\u5b9e\u4f8b\uff1a\u65b9\u6ce2\u4fe1\u53f7\u7684\u5206\u89e3</p> <p> </p> <p>\u5404\u79cd\u5947\u5947\u602a\u602a\u7684\u5468\u671f\u4fe1\u53f7\u5206\u89e3\u6210\u6b63\u5f26\u4fe1\u53f7\u548c\u4f59\u5f26\u4fe1\u53f7\u7684\u7ebf\u6027\u7ec4\u5408</p> <p>\u4f8b\u5b50\u4e2d \\(T_0 = 4\\) \u7684\u5468\u671f\u4fe1\u53f7\uff0c\u5176\u4e2d \\(T_1 = 1\\) </p> <p>\u53ef\u4ee5\u5206\u89e3\u4e3a\u76f4\u6d41\u5206\u91cf\uff0c1 \u6b21\u8c10\u6ce2\u7684\u4f59\u5f26\u5206\u91cf\uff0c3 \u6b21\u8c10\u6ce2\u7684\u4f59\u5f26\u5206\u91cf\u8fd8\u6709 5 \u6b21\u8c10\u6ce2\uff0c7 \u6b21\u8c10\u6ce2</p> <p></p> <ul> <li>\u89c2\u5bdf\u8fd9\u4e2a\u65b9\u6ce2\u4fe1\u53f7\u7684\u5206\u89e3\uff1a\u6ca1\u6709\u6b63\u5f26\u5206\u91cf \u8868\u793a \u8fd9\u4e2a\u65b9\u6ce2\u4fe1\u53f7\u5728\u6b63\u5f26\u5947\u51fd\u6570\u4e0a\u7684\u6295\u5f71=0\uff0c</li> <li>\u540c\u65f6\uff0c\u8fd9\u4e2a\u51fd\u6570\uff0c\u5e76\u4e0d\u662f\u6240\u6709\u7684\u4f59\u5f26\u8c10\u6ce2\u5206\u91cf\u90fd\u6709\uff0c\u53ea\u6709\u5947\u6570\u9879</li> </ul> <p>\u53ef\u89c6\u5316\u5206\u89e3\u51fa\u7684\u76f4\u6d41\u5206\u91cf\u548c\u8c10\u6ce2\u5206\u91cf</p> <p> </p> <p>\u540c\u65f6\uff0c\u968f\u7740\u8c10\u6ce2\u5206\u91cf\u7684\u589e\u52a0\uff0c\u5408\u6210\u4fe1\u53f7\u8d8a\u6765\u8d8a\u903c\u8fd1\u539f\u4fe1\u53f7\u3002</p> <ul> <li>\u4e0b\u56fe\u4e2d\uff0c\u9636\u8dc3\u5904\u6709\u5c16\u70b9\u8868\u793a\u5409\u5e03\u65af\u73b0\u8c61\uff0c\u4e0e\u72c4\u5229\u514b\u96f7\u6761\u4ef6\u6709\u5173\uff0c\u6682\u65f6\u4e0d\u7ba1</li> </ul> <p></p> <ul> <li>\u540c\u65f6\u5e94\u5f53\u6ce8\u610f\u7684\u662f\uff0c\u5468\u671f\u4fe1\u53f7\u4f7f\u7528\u5085\u91cc\u53f6\u7ea7\u6570\u8fdb\u884c\u4fe1\u53f7\u7684\u5408\u6210\u4e0e\u5206\u89e3</li> <li>\u5bf9\u4e8e\u975e\u5468\u671f\u4fe1\u53f7\u4f7f\u7528\u5085\u91cc\u53f6\u53d8\u6362\u8fdb\u884c \u4fe1\u53f7\u7684\u5408\u6210\u4e0e\u5206\u89e3</li> <li>\u8fd9\u91cc\u6211\u6709\u4e00\u4e2a\u95ee\u9898</li> </ul> <p>\u8c10\u6ce2\u5206\u91cf\uff1f </p> <p>\u6700\u5927\u5468\u671f\uff0c\u5c31\u662f\u8981\u5c55\u5f00\u7684\u5468\u671f\u4fe1\u53f7\u7684\u5468\u671f \\(T\\) \uff0c\u524d\u9762\u5df2\u7ecf\u8bb0 \\(\\omega = \\frac{2\\pi}{T}\\)</p> <ul> <li> <p>\\(\\cos1\\omega x,\\sin1\\omega x\\) \u6700\u5927\u5468\u671f \\(T\\)</p> </li> <li> <p>\\(\\cos2\\omega x,\\sin2\\omega x\\) \u5468\u671f\\(=\\frac{T}{2}\\) \uff0c\u6700\u5927\u5468\u671f \\(T\\) \u5185\u91cd\u590d \\(2\\) \u6b21</p> </li> <li> <p>\\(\\cos3\\omega x,\\sin3\\omega x\\) \u5468\u671f\\(=\\frac{T}{3}\\) \uff0c\u6700\u5927\u5468\u671f \\(T\\) \u5185\u91cd\u590d \\(3\\) \u6b21</p> </li> </ul> <p>\u611f\u89c9 \u8fd9\u91cc\u7684\u7406\u89e3\uff0c\u8fd8\u662f\u5f97\u518d\u52a0\u6df1\u4e00\u4e0b\u3002</p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_5","title":"\u5e45\u5ea6\u8c31\u548c\u76f8\u4f4d\u8c31","text":"<ul> <li>\u9996\u5148\uff0c\u7ed9\u51fa\u65f6\u57df\u4e0a\u7684\u6ce2\u5f62\uff0c\u770b\u4e0d\u5230\u5177\u4f53\u7684\u5185\u5bb9\uff0c\u53ea\u80fd\u5927\u81f4\u4e0a\u770b\u51fa\u662f\u4e00\u4e2a\u5468\u671f\u4fe1\u53f7\uff0c\u5468\u671f\u5927\u81f4\u770b\u51fa=4\uff0c\u901a\u8fc7\u5468\u671f\u4fe1\u53f7\u7684\u81ea\u76f8\u5173\uff0c\u53ef\u4ee5\u51c6\u786e\u7684\u5224\u8bfb\u51fa\u5468\u671f\u4fe1\u53f7\u7684\u5468\u671f</li> <li>\u5468\u671f\u4fe1\u53f7\u5468\u671f=4\uff0c\u6b64\u65f6\u6839\u636e\u8ba1\u7b97 \\(\\omega_0 = \\frac{2\\pi}{T}=\\frac{\\pi}{2}\\) \u8868\u793a==\u57fa\u6ce2==\u9891\u7387 = \\(\\frac{\\pi}{2}\\)</li> <li>\u901a\u8fc7\u5085\u91cc\u53f6\u7ea7\u6570\u5f97\u5230\u5177\u4f53\u7684\u4f59\u5f26\u8c31\u548c\u6b63\u5f26\u8c31\uff0c\u4f46\u5b9e\u9645\u4e0a\u5e76\u6ca1\u6709\u4f59\u5f26\u8c31\u548c\u6b63\u5f26\u8c31\u7684\u8bf4\u6cd5</li> <li>\u901a\u8fc7\u4e0a\u56fe\u53f3\u56fe\uff0c\u53ef\u4ee5\u770b\u51fa\u4fe1\u53f7\u542b\u6709\u7684\u6b63\u5f26\u4fe1\u606f\u548c\u4f59\u5f26\u4fe1\u606f\uff1a</li> <li>\u8fd8\u6709\u76f4\u6d41\u5206\u91cf \\(0.5\\)\u30011 \u6b21\u8c10\u6ce2\u7684\u4f59\u5f26\u5206\u91cf\uff0c1 \u6b21\u8c10\u6ce2\u7684\u6b63\u5f26\u5206\u91cf\uff0c\u8fd8\u6709\u4e00\u4e2a 5 \u6b21\u8c10\u6ce2\u7684\u4f59\u5f26\u5206\u91cf\uff0c\u540c\u65f6\u5b83\u7684\u632f\u5e45\u662f0.127\uff0c\u540c\u65f6\u5728\u8fd9\u91cc\u7684\u6b63\u5f26\u8c31\u548c\u4f59\u5f26\u8c31\u7684\u8868\u793a\u4e0a\u4e5f\u5341\u5206\u6e05\u6670\u7684</li> <li>\u4f46\u662f\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5e76\u6ca1\u6709\u4f59\u5f26\u8c31\u548c\u6b63\u5f26\u8c31\u7684\u6982\u5ff5\uff0c\u95ee\u9898\u5c31\u5728\u4e3a\u4ec0\u4e48\u5085\u91cc\u53f6\u7ea7\u6570\u7ed9\u51fa\u7684\u4e5f\u662f\u6b63\u4f59\u5f26\u51fd\u6570\u7684\u5206\u89e3\uff0c\u76f8\u4f4d\u8c31\u600e\u4e48\u6765\uff1f\u53cc\u8fb9\u8c31\uff0c\u5e45\u5ea6\u8c31\uff1f</li> </ul> <p>\u56de\u7b54\uff0c\u9996\u5148\uff0c\u56fe\u4e2d\u663e\u793a\u7684\u76f4\u6d41\u5206\u91cf 0.5\u653e\u5728\u4e86\u4f59\u5f26\u8c31\u4e0a\uff0c\u90a3\u4e3a\u4ec0\u4e48\u4e0d\u653e\u5728\u6b63\u5f26\u8c31\u4e0a\u4e0a\uff1f\u6216\u8005\u5c06\u76f4\u6d41\u5206\u91cf\u5e73\u5747\u5206\u914d\u5728\u6b63\u5f26\u51fd\u6570 \u548c \u4f59\u5f26\u51fd\u6570\u4e0a\uff1f\u4e5f\u5c31\u662f\u8bf4\u8fd9\u91cc\u76f4\u6d41\u5206\u91cf\u5c31\u51fa\u73b0\u4e86\u6b67\u4e49\uff0c\u4e0d\u7b26\u5408\u4e25\u8c28\u7684\u7279\u6027\u3002\u6240\u4ee5\uff0c\u9891\u8c31\u5206\u6790\u4e3a\u4e86\u4e25\u8c28\uff0c\u4e0d\u7528\u4f59\u5f26\u8c31\u548c\u6b63\u5f26\u8c31\uff0c\u7528\u7684\u662f\u5e45\u5ea6\u8c31\u548c\u76f8\u4f4d\u8c31\uff0c\u6709\u4e86 sinx \u548c cosx \u7528\u8f85\u52a9\u89d2\u516c\u5f0f\u5373\u53ef\u5f97\u5230\u5e45\u5ea6\u548c\u76f8\u4f4d</p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_6","title":"\u5e45\u5ea6\u8c31\u548c\u76f8\u4f4d\u8c31","text":"<ul> <li>\u901a\u8fc7\u8f85\u52a9\u89d2\u53d8\u6362\uff0c\u5468\u671f\u4fe1\u53f7\u7684\u5206\u89e3\u53ef\u4ee5\u7edf\u4e00\u53d8\u6210\u4f59\u5f26\u51fd\u6570\u7684\u8868\u73b0\u5f62\u5f0f</li> </ul> <ul> <li>\u770b\u8fd9\u4e2a\u5b9e\u4f8b\uff0c\u5c06\u76f8\u540c\u9891\u7387\u7684\u8c10\u6ce2\u5229\u7528\u8f85\u52a9\u89d2\u516c\u5f0f\u7edf\u4e00\u7528\u4f59\u5f26\u51fd\u6570\u8868\u793a\uff0c\u5f97\u5230\u5e45\u5ea6\u8c31\u548c\u76f8\u4f4d\u8c31</li> <li>\u770b\u56fe\uff0c\u6216\u8005\u770b\u5085\u91cc\u53f6\u7ea7\u6570\u7684\u8f85\u52a9\u89d2\u5f62\u5f0f\uff1a\u76f4\u6d41\u5206\u91cf=0.5\uff0c1 \u6b21\u8c10\u6ce2\u7684\u5206\u91cf\\(=\\sqrt{2}\\) \uff0c5 \u6b21\u8c10\u6ce2\u5206\u91cf\u5bf9\u5e94\u7684 \u5e45\u503c =0.127\uff0c\u540c\u65f6\u5728 1 \u6b21\u8c10\u6ce2\u5206\u91cf\u4e0a\u6709\u4e00\u4e2a \\(-\\frac{\\pi}{4}\\)\u7684\u6ede\u540e\u76f8\u4f4d</li> </ul> <p>\u4ee5\u4e0a\u8be6\u7ec6\u8bf4\u660e\u4e86\u5e45\u5ea6\u8c31\u548c\u76f8\u4f4d\u8c31\u3002</p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_7","title":"\u53cc\u8fb9\u8c31","text":"<ul> <li>\u53cc\u8fb9\u8c31\u5c31\u662f\u501f\u52a9\u6b27\u62c9\u516c\u5f0f\uff0c\u5c06\u5085\u91cc\u53f6\u7ea7\u6570\u4f59\u5f26\u51fd\u6570\u8868\u793a\u7684\u8f85\u52a9\u89d2\u5f62\u5f0f\u8f6c\u6362\u4e3a \\(e\\) \u7684\u590d\u6307\u6570\u5f62\u5f0f</li> </ul> <ul> <li>\u5c06\u4f59\u5f26\u4fe1\u53f7\u8868\u793a\u5355\u8fb9\u8c31\u53d8\u6210\u590d\u6307\u6570\u5f62\u5f0f\u8868\u793a\u53cc\u8fb9\u8c31</li> <li>\u533a\u522b&amp;\u8054\u7cfb</li> <li>\u53cc\u8fb9\u8c31\u7684 \u5e45\u503c\uff0c\u7531 \u5355\u8fb9\u8c31\u7684\u5e45\u503c \u51cf\u534a\uff0c\u5bf9\u79f0\u5230\u8d1f\u9891\u7387\u4e0a</li> <li>\u76f8\u4f4d\u5927\u5c0f\u4e0d\u53d8\uff0c\u9891\u7387\u8fdb\u884c\u5947\u5bf9\u79f0</li> </ul> <p>\u4e3e\u4f8b\u5b50\uff1a</p> <p> </p> <ul> <li>\u5355\u8fb9\u8c31\u548c\u53cc\u8fb9\u8c31 \u672c\u8d28\u662f\u4e00\u6837\u7684\uff0c\u4f46\u662f\u8868\u8fbe\u5f62\u5f0f\u662f\u4e0d\u540c\u7684</li> </ul> <p>\u5355\u8fb9\u8c31\uff1a</p> <p></p> <ul> <li>\u8fd9\u91cc\u7684\u5355\u8fb9\u8c31\u662f\u4f59\u5f26\u51fd\u6570\u7684\u5206\u89e3\u5f62\u5f0f\uff0c\u5728\u4e00\u6b21\u8c10\u6ce2\u4e0a\u6709\u5e45\u503c\uff0c5 \u6b21\u8c10\u6ce2\u4e0a\u6709\u5e45\u503c</li> <li>\u76f8\u4f4d\u8c31\uff1a\u5728 1 \u6b21\u8c10\u6ce2\u4e0a\u6709\u6ede\u540e</li> </ul> <p>\u5bf9\u5e94\u7684\u8868\u8fbe\u5f0f\uff1a</p> <p> </p> <ul> <li>\u63a5\u4e0b\u6765\u5c06\u4e24\u4e2a\u4f59\u5f26\u53d8\u6210\u590d\u6307\u6570\u76f8\u52a0 \u9664\u4ee5 2 \u7684\u5f62\u5f0f\uff0c\u5f97\u5230\u5e45\u5ea6\u8c31\uff0c\u540c\u65f6\u5e45\u5ea6\u8c31\u4ea7\u751f\u4e86\u6b63\u8d1f\u4e24\u79cd\u9891\u7387\uff0c\u5bf9\u5e94\u7684\u5e45\u5ea6\u51cf\u534a\uff0c\u5e76\u4e14\u662f\u5076\u5bf9\u79f0\u7684</li> </ul> <p> </p> <p>\u8868\u8fbe\u5f0f\uff1a</p> <p> </p> <p>\u76f8\u4f4d\u5728\u6b63\u9891\u7387\u4e0a\u6709\u4e00\u4e2a\u6ede\u540e\u7684 45\u00b0\uff0c\u8d1f\u9891\u7387\u4e0a\u4e5f\u6709\u4e00\u4e2a==\u6ede\u540e\u7684== 45\u00b0\uff0c\u5e76\u4e14\u662f\u5947\u5bf9\u79f0\u7684\uff0c\u6240\u4ee5\u6709\u4e00\u4e2a==\u8d85\u524d== 45 \u5ea6\u7684\u76f8\u4f4d\u3002</p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_8","title":"\ud83d\udd35 \u5982\u4f55\u7406\u89e3 \u53cc\u8fb9\u8c31\u7684\u8d1f\u9891\u7387","text":"<p>\u7b80\u5355\u8bf4\u5c31\u662f\u65cb\u8f6c\u65b9\u5411\u4e0d\u540c\uff0c\u6b63\u65b9\u5411\u662f\u9006\u65f6\u9488\u65cb\u8f6c\uff0c\u5bf9\u5e94\u7684\uff0c\u53cd\u65b9\u5411\u662f\u987a\u65f6\u9488\u65cb\u8f6c\u3002</p> <p>\u4ece\u4e0b\u9762\u7684\u56fe\u4e5f\u53ef\u4ee5\u770b\u51fa\u6765</p> <p></p> <ul> <li> \u8fd9\u4e2a \u8c10\u6ce2 \\(k \\omega t\\) \uff0c\u5c31\u6709\u70b9\u610f\u601d</li> </ul> <p> </p> <p>\u590d\u6307\u6570\u8868\u793a\u5f62\u5f0f\uff1a</p> <p></p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_9","title":"\u590d\u6307\u6570\u51fd\u6570\u6b63\u4ea4\u57fa","text":"<p>\u7edf\u4e00\u4e86\u76f4\u6d41\u5206\u91cf \\(k=0\\) </p> <p></p> <ul> <li> \u8fd9\u91cc\uff0c\u8fd9\u4e2a\u8d1f\u53f7\uff1f</li> </ul>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_10","title":"\u5085\u91cc\u53f6\u7ea7\u6570\u7684\u590d\u6307\u6570\u5f62\u5f0f","text":"<p>\u7ea7\u6570\u8ba8\u8bba\u7684\u662f\u5468\u671f\u51fd\u6570\uff0c\u53d8\u6362\u662f\u975e\u5468\u671f\u51fd\u6570</p> <p></p> <ul> <li>\u5728\u6bcf\u4e2a\u6b63\u4ea4\u57fa\u4e0a\u7684\u6295\u5f71\u5c31\u662f\u7cfb\u6570\uff0c\u540c\u6837\u7528\u5185\u79ef\u4e4b\u6bd4\u8fdb\u884c\u8ba1\u7b97</li> </ul>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_11","title":"\u4e3a\u4ec0\u4e48\u5728\u8ba1\u7b97\u5185\u79ef\u7684\u65f6\u5019\u7528\u8d1f\u53f7\uff1f","text":"<p>\u4e0e\u590d\u6570\u76f8\u5173\uff1a</p> <p> </p> <ul> <li> <p>\u590d\u6570\u6a21\u957f\u7684\u8ba1\u7b97= \u590d\u6570 \u00d7 \u5b83\u7684\u5171\u8f6d\u590d\u6570\uff0c\u4e5f\u5c31\u662f\u662f\u8bf4\uff0c\u590d\u6570\u5185\u79ef\u7684\u8ba1\u7b97\u662f\u590d\u6570\u4e0e\u5176\u5171\u8f6d\u590d\u6570\u76f8\u4e58\u3002</p> </li> <li> <p>\u5b9e\u90e8\u4e0d\u53d8\uff0c\u865a\u90e8\u90e8\u5206\u76f8\u53cd\u3002</p> </li> </ul> <p>\u66f4\u8be6\u7ec6\u7684\u8bf4\u660e\uff0c\u4e3a\u4ec0\u4e48\u662f\u8d1f\u53f7\uff1a </p> <p></p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#i2-1","title":"\u4ece\u51e0\u4f55\u7684\u89d2\u5ea6\u7406\u89e3 \\(i^2 = -1\\)","text":"","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#sinomega-t","title":"\\(\\sin(\\omega t)\\)\u7684\u53cc\u8fb9\u8c31","text":"<p>\u4e00\u5b9a\u8981\u7262\u8bb0\uff0c\u53ef\u4ee5\u4ece\u51e0\u4f55\u65cb\u8f6c\u7684\u89d2\u5ea6\u7406\u89e3\u865a\u6570\u5355\u4f4d j</p> <p>\u5177\u4f53\u7684 \\(j\\) \u5199\u6210\u5e45\u89d2-\u6a21\u957f\u5f62\u5f0f\uff1a\\(j = 1 \\cdot e^{j \\frac{\\pi}{2}}\\) </p> <ul> <li>\\(1\\) \u8868\u793a\u6a21\u957f</li> <li>\\(j\\) \u8868\u793a\u9006\u65f6\u9488\u3001\u6b63\u65b9\u5411\u65cb\u8f6c</li> <li>\\(\\frac{\\pi}{2}\\) \u8868\u793a\u65cb\u8f6c\u89d2\u5ea6</li> <li>\u51e0\u4f55\u89e3\u91ca\uff1a\u65cb\u8f6c 90\u00b0\u7684\u5355\u4f4d\u77e2\u91cf</li> </ul> <p>\u540c\u7406</p> <p>\\(-j\\) \u5199\u6210\u5e45\u89d2-\u6a21\u957f\u5f62\u5f0f\uff1a\\(j = 1 \\cdot e^{-j \\frac{\\pi}{2}}\\) </p> <ul> <li>\\(1\\) \u8868\u793a\u6a21\u957f</li> <li>\\(-j\\) \u8868\u793a\u987a\u65f6\u9488\u3001\u53cd\u65b9\u5411\u65cb\u8f6c\uff0cDFT \u7528\u7684\u65b9\u5411</li> <li>\\(\\frac{\\pi}{2}\\) \u8868\u793a\u65cb\u8f6c\u89d2\u5ea6</li> <li>\u51e0\u4f55\u89e3\u91ca\uff1a\u65cb\u8f6c -90\u00b0\u7684\u5355\u4f4d\u77e2\u91cf</li> </ul> <p>\ud83d\udd35 \u4ee3\u5165\u865a\u6570\u5355\u4f4d\u7684\u590d\u6307\u6570\u5f62\u5f0f\uff1a</p> <p></p> <p>\u7ed3\u679c\u89e3\u8bfb\uff1a</p> <ul> <li>\u5e45\u5ea6\u503c\u90fd\u7b49\u4e8e \\(\\frac{1}{2}\\) \u2192 \u5728\u4e00\u6b21\u8c10\u6ce2\u4e0a\u7684\u5206\u91cf\u90fd\u662f \\(\\frac{1}{2}\\)</li> <li>\u540c\u65f6\u5728 $k\\Omega t = 1\\Omega t $ \u7684\u9891\u7387\u4e0a \u6709 \\(-\\frac{\\pi}{2}\\) \u7684\u76f8\u4f4d\u6ede\u540e</li> <li>\u5728 $-k\\Omega t = -1\\Omega t $ \u7684\u9891\u7387\u4e0a \u6709 \\(\\frac{\\pi}{2}\\) \u7684\u76f8\u4f4d\u8d85\u524d</li> </ul> <p>\u7531\u6b64\u7ed8\u5236\u51fa\u5e45\u5ea6\u8c31\u548c\u76f8\u4f4d\u8c31\uff1a</p> <p> </p> <ul> <li>\uff08\u5e45\u5ea6\u8c31\uff09\u5728 \\(1 \\Omega t\\) \u548c \\(- 1 \\Omega t\\) \u5206\u522b\u6709 \\(\\frac{1}{2}\\)  \u7684\u5e45\u5ea6\u503c</li> <li>\uff08\u76f8\u4f4d\u8c31\uff09\u5728  \\(- 1 \\Omega t\\) \u4e0a\u6709\u4e00\u4e2a \\(\\frac{\\pi}{2}\\) \u7684\u8d85\u524d</li> <li>\uff08\u76f8\u4f4d\u8c31\uff09\u5728  \\(1 \\Omega t\\) \u4e0a\u6709\u4e00\u4e2a \\(- \\frac{\\pi}{2}\\) \u7684\u6ede\u540e</li> </ul>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_12","title":"\u65b9\u6ce2\u4fe1\u53f7\u7684\u5408\u6210\u4e0e\u5206\u89e3\u5b9e\u4f8b","text":"<p>\u9996\u5148\u6570\u5b66\u4e0a\u7684\u63a8\u5bfc\uff1a</p> <p> </p> <ul> <li>\u91c7\u7528\u590d\u6307\u6570\u5206\u89e3</li> <li>\u5c06\u5468\u671f\u4fe1\u53f7 \\(x_t\\) \u5206\u89e3\u5230\u6b63\u4ea4\u57fa\u51fd\u6570\u4e0a\uff0c\u8868\u793a\u4e3a\u6b63\u4ea4\u57fa\u51fd\u6570\u7684\u7ebf\u6027\u7ec4\u5408</li> <li>\u539f\u59cb\u5468\u671f\u4fe1\u53f7\u5728\u6b63\u4ea4\u57fa\u51fd\u6570\u4e0a\u7684\u6295\u5f71\u7528\uff0c\u5185\u79ef\u8ba1\u7b97</li> <li>\u6807\u7ea2\u8272\u7684\uff1a\u8868\u793a\u590d\u6570\u7684\u5185\u79ef\uff0c\u6d89\u53ca\u5230\u5171\u8f6d\u590d\u6570\u3002</li> <li>\u5176\u4e2d\uff0c\u76f8\u540c\u6b63\u4ea4\u57fa\u7684\u5185\u79ef=T\uff0c\\(\\int_{-\\frac{T}{2}}^{\\frac{T}{2}} dt = T\\) \u662f\u5fc5\u7136\u7684\u3002\u5bf9\u5e38\u6570\u79ef\u5206\uff0c\u7ed3\u679c=\u533a\u95f4\u957f\u5ea6</li> </ul> <p>\u63a5\u4e0b\u6765\uff0c\u6c42\u76f4\u6d41\u5206\u91cf\uff1a</p> <p> </p> <p>\u63a5\u4e0b\u6765\uff0c\\(k \\neq 0\\)</p> <p></p> <p>\u79ef\u5206\u51fa\u6765\u7684\u7ed3\u679c\uff0c\u4ee3\u5165\u6b27\u62c9\u516c\u5f0f\uff0c\u53d8\u6210\u53ea\u6709\u6b63\u5f26\u51fd\u6570\u7684\u3002\u4f46\u662f\u753b\u56fe\u7684\u65f6\u5019\u7528\u7684\u662f\u4f59\u5f26\u51fd\u6570\u753b\u56fe\uff0c\u6240\u4ee5\u8fd8\u662f\u8981\u8f6c\u5316\u6210\u4f59\u5f26\u51fd\u6570\uff0c\u53d8\u6210\u5355\u8fb9\u8c31\u3002\u5177\u4f53\u7684\u5c31\u662f \\(\u7cfb\u6570\u00d72\\) \u53d8\u6210\u5355\u8fb9\u8c31</p> <p></p> <p>\u8fd9\u53e5</p> <p> </p> <p>\u5f97\u6ce8\u610f\u4e00\u4e0b\u3002\u539f\u59cb\u4fe1\u53f7\u7684\u5468\u671f\u6709\u4e86\uff0c\u90a3\u4e48\u57fa\u6ce2\u9891\u7387 \\(\\Omega\\) \u5c31\u6709\u4e86 \u2192 \\(k\\Omega n\\)  \u6295\u5f71\u7684\u8c10\u6ce2\u9891\u7387\u4e5f\u6709\u4e86</p> <p>\u8fd9\u91cc\u662f\u5085\u91cc\u53f6\u7ea7\u6570\u7684\u5177\u4f53\u6b65\u9aa4\uff1a\uff08\u5176\u4e2d\u62df\u5408\u7684\u8c10\u6ce2\u5206\u91cf\u4e2a\u6570\u53ef\u4ee5\u81ea\u5df1\u8bbe\u5b9a\uff09 </p> <p></p> <p>\u56e0\u4e3a\u516c\u5f0f\u4e2d\u62df\u5408\u7684\u8c10\u6ce2\u7406\u8bba\u4e0a\u6765\u8bf4\u662f\u65e0\u7a77\u591a\u4e2a\u3002\u8fd9\u91cc\u9700\u8981\u4e0e\u540e\u9762\u7684DFT \u7684\u53d8\u6362\u62df\u5408\u8c10\u6ce2\u6570\u91cf\u9700\u8981\u4f5c\u533a\u5206\u3002</p> <p>\u76ee\u524d\u7684\u7406\u89e3\uff1a</p> <ul> <li>\u5468\u671f\u4fe1\u53f7\uff0c\u7528\u7684\u662f\u7ea7\u6570\uff0c\u53ef\u4ee5\u5206\u89e3\u51fa\u65e0\u7a77\u591a\u4e2a\u8c10\u6ce2</li> <li>\u975e\u5468\u671f\u4fe1\u53f7\uff0c\u7528\u7684\u662f\u53d8\u6362\uff0c\u5206\u89e3\u51fa\u7684\u8c10\u6ce2\u662f  \\(\\frac{\u91c7\u6837\u9891\u7387}{2}\\)</li> </ul> <p></p> <p>\u5f97\u5230\u7cfb\u6570\u4ee5\u540e\uff0c\u53ef\u4ee5\u7ed8\u5236\u5355\u8fb9\u8c31\u4e86</p> <p></p> <p>\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\uff0c\u53cc\u8fb9\u8c31\u8f6c\u6362\u4e3a\u5355\u8fb9\u8c31</p> <p>\u53cc\u8fb9\u8c31\u7684 \u8c10\u6ce2\u6a21\u957f\u9700\u8981 \u00d7 2\uff0c\u76f4\u6d41\u5206\u91cf\u4e0d\u9700\u8981 \u00d72</p> <p>\\(ak\\_cos\\) \uff1a \u4e5f\u53ea\u662f \u5355\u8fb9\u8c31 \\(\\cos\\) \u5bf9\u5e94\u7684 \u5e45\u503c</p> <p> </p> <p>\u56fe\u4e2d\u5f97\u5230\u4e86\u5355\u8fb9\u8c31\u7684\u5e45\u5ea6\u503c\uff0c\u89e3\u8bfb\u5e45\u5ea6\u8c31\uff1a</p> <ul> <li>\u76f4\u6d41\u5206\u91cf = 0.5</li> </ul> <p> </p> <ul> <li>\\(ak\\_cos\\) \u7684\u503c\u4e0e\u5355\u8fb9\u8c31\u4e00\u4e00\u5bf9\u5e94</li> <li>\\(k\\Omega n\\)  \u7b2c 0 \u4e2a\u539f\u59cb\u662f\u76f4\u6d41\u5206\u91cf</li> <li>\\(1\\Omega n\\)  1 \u6b21\u8c10\u6ce2\u5206\u91cf\u662f 0.6366</li> <li>\\(2\\Omega n\\)   \u5076\u6b21\u8c10\u6ce2\u662f\u6ca1\u6709\u7684</li> <li>\\(3\\Omega n\\) </li> <li>\\(4\\Omega n\\)</li> <li>\\(5\\Omega n\\)</li> <li>\\(6\\Omega n\\)</li> <li>\\(7\\Omega n\\)  7 \u6b21\u8c10\u6ce2\u5206\u91cf\u662f \\(-0.0909\\)</li> </ul> <p>\u6f14\u793a\u5206\u89e3\u51fa\u6765\u7684\u4fe1\u53f7 </p> <p>\u9996\u5148 \u76f4\u6d41\u5206\u91cf\u7684\u7ed8\u5236\uff0c\\(c_0\\) \u00d7 \u5e8f\u5217\u957f\u5ea6\uff1a</p> <p></p> <p>\u7136\u540e\u5c31\u662f\u7ed8\u5236\u8c10\u6ce2\u5206\u91cf\uff1a</p> <p> </p> <ul> <li>1 \u6b21\u8c10\u6ce2\u5206\u91cf</li> <li>2 \u6b21\u8c10\u6ce2\u5206\u91cf</li> <li>...</li> <li> <p>\u8fd9\u662f\u5206\u89e3\u8c10\u6ce2\u4e2a\u6570=7\uff0c\u6240\u4ee5\u4e00\u5171 7 \u6b21\u8c10\u6ce2\u5206\u91cf</p> </li> <li> <p> \uff08why\uff1f\uff09\u8fd9\u91cc\u6211\u7684\u95ee\u9898\u662f\uff0c\u4e3a\u4ec0\u4e48\u554a\uff1f\u4e3a\u4ec0\u4e48\u60f3\u5206\u89e3\u51e0\u6761\u8c10\u6ce2\u5206\u91cf\u5c31\u80fd\u5206\u89e3\u51e0\u6761\u8c10\u6ce2\u5206\u91cf</p> </li> </ul> <p>\u5206\u89e3\u4e3a 13 \u6761\u8c10\u6ce2\u5206\u91cf</p> <p> </p> <p>\u5206\u89e3\u5b8c\u8c10\u6ce2\u5206\u91cf\u4ee5\u540e\uff0c\u518d\u5408\u6210\uff1a</p> <p> </p> <p>100 \u6b21\u8c10\u6ce2\u5206\u91cf\u53ca\u5408\u6210\uff1a</p> <p> </p> <p>\u4e2d\u95f4\u53d1\u767d\u7684\u662f\u56e0\u4e3a\u6ca1\u6709\u5076\u6570\u6b21\u8c10\u6ce2\u5206\u91cf \\(\\cos k \\Omega n\\) \uff0c\\(k\\)\u7b49\u4e8e\u5076\u6570\u65f6\uff0c\u5168\u90e8\u7b49\u4e8e\\(0\\)\uff0c\u8fd9\u4e2a\u4ece\u5355\u8fb9\u5e45\u5ea6\u8c31\u4e2d\u4e5f\u53ef\u4ee5\u770b\u51fa\u6765\u3002</p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_13","title":"\u6b27\u62c9\u516c\u5f0f\u7684\u56fe\u50cf\u5316\u89e3\u91ca","text":"<p>\u5176\u5b9e\u6211\u4e0d\u61c2\uff0c\u4e3a\u4ec0\u4e48\u8fd9\u91cc\u7684 \\(T=6\\) </p> <p>\u590d\u6307\u6570\u4fe1\u53f7\u7684\u5468\u671f\uff0c\u5728\u51e0\u4f55\u56fe\u5f62\u4e2d\u5bf9\u5e94\u8fd9\u4ec0\u4e48\uff1f</p> <p>n=2\uff0c\u8868\u793a\u7ed8\u5236 2 \u4e2a\u5468\u671f</p> <p>\u4f46\u786e\u5b9e\uff0c\u6709\u4e86\u65f6\u95f4\u5e8f\u5217\u5468\u671f\uff0c\u5c31\u6709\u4e86\u57fa\u6ce2\u9891\u7387\uff0c\u57fa\u6ce2\u9891\u7387\u5bf9\u5e94\u5230\u51e0\u4f55\u56fe\u5f62\u4e0a\u53c8\u662f\u4ec0\u4e48\uff1f</p> <p>\\(t = 0:0.1:(n*T)\\)  \u786e\u5b9e\u5c31\u662f\u603b\u7684\u65f6\u95f4\u5e8f\u5217\u957f\u5ea6</p> <p>\u8fd9\u91cc\u7684\u4e09\u7ef4\u5750\u6807\uff0c\u5206\u522b\u8868\u793a\uff1a\\(f = e^{i\\Omega k t} = e^{i\\Omega  t}\\)  \u4e5f\u5c31\u662f\u8bf4\u753b\u7684\u662f\u57fa\u6ce2\u9891\u7387\u7684\u6b27\u62c9\u516c\u5f0f\uff08k=1\uff09</p> <p>\u731c\u60f3\uff0c\u5982\u679c\u7ed8\u5236\u7684\u662f k=2\uff0c2 \u6b21\u8c10\u6ce2\u7684\u6b27\u62c9\u516c\u5f0f\uff0c\u5176\u4f59\u90fd\u4e0d\u53d8\uff0c\u4f1a\u53d1\u751f\u4ec0\u4e48\uff1f</p> <p>\u90a3\u5176\u5b9e\uff0c\u57fa\u9891\uff0c\u4e5f\u53ef\u4ee5\u53eb 1 \u6b21\u8c10\u6ce2</p> <ul> <li>x \u8f74 \u7ed8\u5236\u7684\u662f \u65f6\u95f4 \\(t\\)</li> <li>y \u8f74\u7ed8\u5236\u7684\u662f \\(img(f)\\) \u865a\u90e8\u90e8\u5206</li> <li> <p>z \u8f74\u7ed8\u5236\u7684\u662f \\(real(f)\\) \u5b9e\u90e8\u90e8\u5206</p> </li> <li> <p> \u5e94\u8be5\u81ea\u5df1\u7528 python \u5b9e\u73b0\u4e00\u4e0b\u3002</p> </li> </ul> <p>\u753b\u7684\u4e00\u4e2a\u4e70\u5bb6\u79c0\uff1a</p> <p> </p> <p></p> <p></p> <p></p> <ul> <li>\u662f\u628a\uff0c\u770b\u51fa\u6765\u4e86\u5427\uff0c</li> </ul> Python<pre><code># \u53c2\u6570\u8bbe\u7f6e\n&lt;div markdown=\"1\" style=\"margin-top: -30px; font-size: 0.75em; opacity: 0.7;\"&gt;\n:material-circle-edit-outline: \u7ea6 4846 \u4e2a\u5b57 :fontawesome-solid-code: 12 \u884c\u4ee3\u7801 :material-image-multiple-outline: 69 \u5f20\u56fe\u7247 :material-clock-time-two-outline: \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 24 \u5206\u949f\n&lt;/div&gt;\nT = 6  # \u5468\u671f\nomega = (2 * np.pi) / T  # \u89d2\u9891\u7387\nn = 2  # \u5468\u671f\u4e2a\u6570\nt = np.arange(0, n * T + 0.1, 0.1)  # \u65f6\u95f4\u5e8f\u5217\uff0c\u4ece0\u5230n*T\uff0c\u6b65\u957f\u4e3a0.1\n\n# \u8ba1\u7b97\u590d\u6307\u6570\u4fe1\u53f7\nf = np.exp(2j * omega * t)  # \u6ce8\u610f\u8fd9\u91cc\u4f7f\u75282j\nreal_part = np.real(f)  # \u5b9e\u90e8\nimag_part = np.imag(f)  # \u865a\u90e8\n</code></pre> <ul> <li>\u8fd9\u91cc\u7684\u57fa\u7840\u53c2\u6570\u4e0d\u53d8\uff0c\u53ea\u6539\u8fd9\u91cc\uff0c<code>f = np.exp(2j * omega * t)  # \u6ce8\u610f\u8fd9\u91cc\u4f7f\u75282j</code> \u4e00\u4e2a\u7528 <code>1j * omega * t</code>  \u4e00\u4e2a\u7528 <code>2j * omega * t</code></li> <li> <p>\u4e0a\u9762\u7684\u7279\u6b8a\u70b9 \\(\\frac{T}{4}\\)\u3001\\(\\frac{T}{2}\\)\u3001\\(\\frac{3T}{4}\\)\u3001\\(T\\) \u4e5f\u5f88\u597d\u770b\u3002\u90fd\u53cd\u6620\u4e86 \u539f\u59cb\u5468\u671f\u4e0e 1 \u6b21\u8c10\u6ce2\u30012 \u6b21\u8c10\u6ce2\u5b8c\u6210\u5468\u671f\u7684\u5173\u7cfb</p> </li> <li> <p>\u533a\u522b\u5c31\u5728\u4e8e\uff0c\u672c\u6765\u662f \u4e00\u4e2a\u5468\u671f T=6 \u5185\u5b8c\u6210\u4e00\u4e2a\u5468\u671f\uff0c\u6539\u6210 2 \u6b21\u8c10\u6ce2 <code>2j * omega * t</code> \uff0c\u5c31\u662f  \u539f\u59cb\u5468\u671f T=6 \u5185\u5b8c\u62102\u4e2a\u5468\u671f\uff0c\u90a3\u5982\u679c\u8fd9\u6837\u7684\u8bdd\uff0c\u4e5f\u662f\u53ef\u4ee5\u7406\u89e3\uff0c\u4e3a\u4ec0\u4e48\u5468\u671f\u7684\u5085\u91cc\u53f6 \u7ea7\u6570\uff0c\u53ef\u4ee5\u5206\u89e3 \\(\\infty\\) \u6b21\u7684\u8c10\u6ce2\u3002\u4e0b\u9762\u8fd9\u91cc\u753b 50 \u6b21\u8c10\u6ce2\u5206\u91cf\uff0c\u610f\u601d\u5c31\u662f <code>50j * omega * t</code> \uff0c\u4e5f\u5c31\u662f\u539f\u59cb T=6 \u5185\uff0c\u5b8c\u6210 50 \u4e2a\u5468\u671f\u3002</p> </li> </ul> Python<pre><code># \u8ba1\u7b97\u590d\u6307\u6570\u4fe1\u53f7\nf = np.exp(50j * omega * t)  # \u6ce8\u610f\u8fd9\u91cc\u4f7f\u7528\u7684\u8c10\u6ce2\u9891\u7387\n</code></pre> <p>\u8fd8\u6709\u4e00\u70b9 j \u524d\u9762\u52a0 1</p> <ul> <li>\u65e2\u53ef\u4ee5\u8868\u793a\u4e3a 1 \u6b21\u8c10\u6ce2\u4e5f\u53ef\u4ee5\u53eb\u57fa\u6ce2\u9891\u7387\uff08\u7406\u89e3\u9519\u4e86\u518d\u6539\uff0c\u5148\u8fd9\u4e48\u7406\u89e3\uff09</li> <li>\u5fc5\u987b\u8981\u52a0 1\uff0c1 \u4e0d\u53ef\u4ee5\u7701\u7565\uff0c\u8981\u4e0d\u7136 python \u4e0d\u8ba4\u8bc6 j \u662f\u865a\u6570\u5355\u4f4d\u3002</li> </ul> <p> </p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_14","title":"\u5355\u4f4d\u5706\u4e0a\u7684\u590d\u6307\u6570\u4fe1\u53f7","text":"<p>\u8bfe\u4ef6\uff1a\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff1a\u5178\u578b\u4fe1\u53f7</p> <p>\u91cd\u70b9\u5f3a\u8c03\u51e0\u5904\uff1a</p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_15","title":"\u5355\u4f4d\u5706\u4e0a\u7684\u590d\u6307\u6570\u4fe1\u53f7","text":"<p>\u8fde\u7eed\u65f6\u95f4\u5f62\u5f0f</p> <p>\u4e00\u822c\u5f62\u5f0f\uff1a</p> \\[e^{j(\\omega t+\\phi)}\\] <p>\u590d\u6307\u6570\u5f62\u5f0f \u5176\u5b9e\u5e94\u8be5\u662f\u6a21\u957f-\u5e45\u89d2\u5f62\u5f0f\uff0c\u8fd9\u91cc\u8ba8\u8bba\u7684\u662f\u5355\u4f4d\u5706\u4e0a\u7684\u590d\u6307\u6570\uff0c\u2234 \u6a21\u957f\u4e3a 1</p> <p></p> <p>\u8fd9\u91cc\u6bd4\u8f83\u5bb9\u6613\u6df7\u6dc6\u7684\u662f\uff1a$\\omega $ \u7684\u7406\u89e3\uff0c\u5355\u4f4d\u662f rad/s\uff0c\u63cf\u8ff0\u6bcf\u79d2\u8f6c\u51e0\u5ea6\u3002\uff08\u8ddf\u540e\u9762\u79bb\u6563\u7684\u8fdb\u884c\u5bf9\u6bd4\uff09</p> <ul> <li>\u8fde\u7eed\u65f6\u95f4\u5355\u4f4d\u5706\u4e0a\u7684\u590d\u6307\u6570\u4fe1\u53f7\u4e00\u5b9a\u662f\u5468\u671f\u7684\u6a21\u957f\u4e00\u5b9a\u662f 1</li> </ul> <p>\u6027\u8d28 1\uff1a\u5468\u671f\u6027</p> <ul> <li>\u63cf\u8ff0\u4e00\u4e2a\u4e09\u89d2\u51fd\u6570\uff1a\u5e45\u503c\u3001\u521d\u76f8\u4f4d\u3001\u9891\u7387\uff08or \u5468\u671f\uff09</li> </ul> <p></p> <p>\u6027\u8d28 2\uff1a\\(\\omega\\) \u3001T \u4e0e\u632f\u8361\u7684\u5173\u7cfb </p> <p> </p> <p>\u79bb\u6563\u65f6\u95f4\u4e0e\u5355\u4f4d\u5706\u4e0a\u7684\u590d\u6307\u6570 </p> <p> </p> <ul> <li> <p>\u8fd9\u91cc\u7684 \\(\\Omega\\)  \u6570\u5b57\u89d2\u9891\u7387\u53ef\u4ee5\u7406\u89e3\u4e3a \u91c7\u6837 \\(nT_s\\) \u4e2a\u65f6\u95f4\u70b9\uff0c\u5e73\u5747\u5206\u5355\u4f4d\u5706\uff0c\u6bcf\u4efd\u7684\u5f27\u5ea6\uff08\u6211\u5148\u8fd9\u4e48\u7406\u89e3\uff0c\u9519\u4e86\u518d\u6539\uff09</p> </li> <li> <p>$\\omega $ \u6a21\u62df\u89d2\u9891\u7387\uff0crad/s\uff0c\u6bcf s \u8d70\u8fc7\u7684\u5f27\u5ea6</p> </li> <li>$\\omega_s $ \u91c7\u6837\u89d2\u9891\u7387\uff0c\u6bcf\u79d2\u91c7\u6837\u591a\u5c11\u5f27\u5ea6\uff1f</li> </ul> <p>\u6027\u8d28 1\uff1a\u5468\u671f\u6027 </p> <p> </p> <ul> <li>\u8282\u62cd\u662f\u4ec0\u4e48\u610f\u601d\uff1f</li> </ul> <p>\u6027\u8d28 2\uff1a\\(\\Omega , T\\) \u4e0e\u632f\u8361 </p> <p> </p> <ul> <li>\u91c7\u6837\u5b9a\u7406\uff1a\u4e3a\u4e86\u6355\u6349\u7cfb\u7edf\u4e2d\u6700\u9ad8\u9891\u5206\u91cf\uff0c\u91c7\u6837\u9891\u7387=\u6700\u9ad8\u9891\u7387\u00d72\uff0c\u624d\u80fd\u4fdd\u8bc1\u6700\u9ad8\u9891\u7387\u5206\u91cf\u4e0d\u4f1a\u88ab\u8fc7\u6ee4\u6389</li> <li>\u7cfb\u7edf\u53ef\u4ee5\u5206\u89e3\u51fa\u7684\u6700\u9ad8\u5206\u91cf = \\(\\frac{1}{2}\\) \u91c7\u6837\u9891\u7387</li> <li>\\(\\Omega = \\pi\\) \u65f6\uff0c\u5bf9\u5e94\u7cfb\u7edf\u53ef\u5206\u89e3\u51fa\u6700\u9ad8\u9891\u5206\u91cf</li> <li>\u4e0a\u9762\u4e09\u5f20\u56fe\uff1a\u753b\u7684\u662f \\(e^{i\\Omega n}\\) \u7684\u5b9e\u90e8\u90e8\u5206 \\(\\cos \\Omega\\)   \uff08\\(e^{i\\Omega n} = \\cos \\Omega + i \\sin \\Omega\\)\uff09 </li> <li>\u5f52\u4e00\u5316\u540e\u7684\u8282\u62cd \\(n=0,1,2,......N_0-1\\) \u8282\u62cd\u4e5f\u8bb8\u5c31\u53ef\u4ee5\u7406\u89e3\u4e3a\u65f6\u95f4\u70b9\uff0c\u6bcf\u4e2a\u8282\u62cd\u91c7\u6837\u4e00\u4e2a\u70b9</li> <li>\\(n=0\\)\uff0c\u5bf9\u5e94 \\(\\Omega = 0\\) \uff08\u8fd9\u79cd\u7406\u89e3\u662f\u9519\u8bef\u7684\uff0c\u662f\u5728 $fixed \\quad \\Omega $ \u8ba8\u8bba\u6bcf\u4e2a\u65f6\u95f4\u70b9 \u6216\u8005 \u8282\u62cd\u7684\u5230 \\(k \\Omega\\) \u4e0a\u7684\u6295\u5f71 \uff09 </li> <li>\\(\\Omega = \\pi\\) \u5b9e\u90e8\u6ce2\u5f62\u53cd\u590d\u6a2a\u8df3</li> </ul> <p>\u7591\u95ee\uff08\u542b\u4e49\u662f\u4ec0\u4e48\uff1f\\(\\Omega ?= \\frac{2\\pi}{N}\\)\uff09\uff0c\u4e5f\u8bb8\u8fd9\u91cc\u53ea\u662f\u6570\u5b66\u610f\u4e49\u4e0a\u7684\u8ba8\u8bba\u3002</p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_2_signal/#_16","title":"\u4e00\u822c\u7684\u590d\u6307\u6570\u4fe1\u53f7","text":"<p>\u8fde\u7eed\u7684\u60c5\u51b5</p> <p></p> <p>\u6240\u4ee5\uff0c\u5355\u4f4d\u5706\u4e0a\u7684\u590d\u6307\u6570\u4fe1\u53f7\uff0c\u7279\u6b8a\u5728\u54ea\u91cc\uff1f</p> <p>\u6700\u4e00\u822c\u7684\u590d\u6307\u6570\u4fe1\u53f7?  \\(x(t)=(c(t)+{d(t)}i) e^{ib(t)+a(t)}\\)</p> <ul> <li>\u6309\u7167 ppt \u6765\u8bf4\uff0c\u662f\u5e38\u6570\u3002  \\(x(t)=(c+{d}i) e^{a(t)+b(t)i}\\)</li> </ul> <p>\u7531\u590d\u6570\u3001\u590d\u6307\u6570\u3001\u4e09\u89d2\u51fd\u6570\u5bf9\u5e94\u5173\u7cfb </p> <p>\\(a+bi\\)</p> <p>= \\(\\sqrt{a^2 + b^2} e^{i {arctan\\frac{b}{a}}} = |\u6a21\u957f|e^{i \u5e45\u89d2}\\) </p> <p>= \\(\\sqrt{a^2 + b^2}(\\cos {(\\arctan\\frac{b}{a})}+ i \\sin {(\\arctan\\frac{b}{a})} )\\)</p> <p>\\(=|\u6a21\u957f|(\\cos\u5e45\u89d2+ \\sin\u5e45\u89d2)\\) </p> <p>$\\cos {(\\arctan\\frac{b}{a})} = \\frac{a}{\\sqrt{a^2 + b^2}} $   </p> <p>\\(\u4f59\u5f26\u503c =  \\frac{\u5b9e\u90e8}{|\u6a21\u957f|}\\)</p> <p>\\(\\sin {(\\arctan\\frac{b}{a})} = \\frac{b}{\\sqrt{a^2 + b^2}}\\) </p> <p>\\(\u6b63\u5f26\u503c = \\frac{\u865a\u90e8}{|\u6a21\u957f|}\\)</p> <p>\\(\u5e45\u89d2 = \\arctan \\frac{\u865a\u90e8}{\u5b9e\u90e8}\\) </p> <ul> <li>\u5e76\u4e14\uff0c</li> </ul> \\[x(t)=(c+{d}i) e^{a(t)+b(t)i} \\] \\[\\stackrel{\u6ce8\u610f\u770b\u6307\u6570\u53d8\u5316}{\\rightarrow} x(t)=(c+{d}i) e^{(a+bi)t}\\] \\[\\stackrel{\u590d\u6570\u2192\u590d\u6307\u6570}{\\rightarrow}x(t)=|\u6a21\u957f|e^{i\u5e45\u89d2} e^{(a+bi)t} \\] <p>\u518d\u770b\u8fd9\u4e00\u5806\u4e1c\u897f\uff0c\u5de5\u6574\u591a\u4e86\uff1a</p> <p></p> <p>\u5206\u89e3\uff1a\\(|\u6a21\u957f|e^{i\u5e45\u89d2}\\)  \u662f \u5305\u7edc\u7ebf\u90e8\u5206\uff1b\\(e^{(a+bi)t}\\)   \u662f\u632f\u8361\u90e8\u5206\u3002</p> <p></p> <p>\u8fd9\u91cc\u662f\u4e00\u822c\u7684\u79bb\u6563\u65f6\u95f4\u7684\u590d\u6307\u6570\u4fe1\u53f7\uff1a</p> <p> </p> <p>\u8fd9\u91cc\u4e3b\u8981\u662f\u5355\u4f4d\u5706\u4e0a\u7684\u590d\u6307\u6570\u4fe1\u53f7\uff0c\u533a\u5206 \\(\\omega\\)  &amp;  \\(\\Omega\\)</p> <p>\u8fd9\u91cc\u6ce8\u610f\u4fe1\u53f7\u53d8\u6362\u90fd\u662f\u9488\u5bf9t \u7684\uff0c\u800c\u4e0d\u662f\u62ec\u53f7\u4e2d\u7684\u6240\u6709\u4e1c\u897f\uff1a</p> <p> </p>","tags":["\u7edf\u8ba1\u5b66"]},{"location":"Statistics/1_3_complexExp/","title":"\u590d\u6307\u6570\u7684\u6027\u8d28","text":""},{"location":"Statistics/1_3_complexExp/#_1","title":"\u590d\u6307\u6570\u7684\u6027\u8d28","text":"2025-03-26 13:11:102025-09-28 12:54:03 <p> \u7ea6 2658 \u4e2a\u5b57  24 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 13 \u5206\u949f</p>"},{"location":"Statistics/1_3_complexExp/#_2","title":"\u590d\u5e73\u9762\uff1a","text":"<p>\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u987a\u65f6\u9488\u65cb\u8f6c\uff0c \\(\\frac{2\\pi}{N}\\)</p> <p>\u9006\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u9006\u65f6\u9488\u65cb\u8f6c\uff0c\u4e5f\u662f\\(\\frac{2\\pi}{N}\\)\uff0c\u6700\u540e\u8fd8\u8981\u9664\u4ee5\u5e8f\u5217\u957f\u5ea6 \\(N\\)</p> <p> </p> <p>\u590d\u5e73\u9762\u4e0e \\(e^x\\) \uff0c\u8fd9\u4e00\u6b65\u7684\u8f6c\u6362\uff0c\u5176\u5b9e\u662f\u4ece \\((cos\\theta,sin\\theta)\\) \u76f4\u63a5\u7528\u4e86 \\(e^{i\\theta}\\) \u8868\u793a</p>"},{"location":"Statistics/1_3_complexExp/#_3","title":"\u590d\u6307\u6570\u8868\u793a\u590d\u5e73\u9762","text":"<p>\u7c7b\u4f3c\u7684\uff0c\u590d\u5e73\u9762\u5750\u6807\u70b9\uff0c\u5168\u90e8\u7528\u6307\u6570\u8868\u793a</p> <p> $$ e^{i\\theta} = cos\\theta + isin\\theta $$ \u5177\u4f53\u6765\u8bf4\uff1a</p> <p>\u89c4\u5b9a \u9006\u65f6\u9488\u65cb\u8f6c\u4e3a\u6b63\u65b9\u5411\u3002</p> <p>\u4e5f\u6b63\u662f\u56e0\u4e3a\u5982\u6b64\uff0c\u5085\u91cc\u53f6\u7684\u590d\u6307\u6570\u7684\u590d\u6570\uff0c\u56e0\u4e3a\u5085\u91cc\u53f6\u65cb\u8f6c\u7528\u7684\u662f \u987a\u65f6\u9488\u3002 </p> <ul> <li>\\(1 = e^{i2\\pi} = cos2\\pi + isin2\\pi = 1\\)</li> <li>\\(i = e^{i\\frac{\\pi}{2}} = cos\\frac{\\pi}{2} + isin\\frac{\\pi}{2} = i\\)</li> <li>\\(-1 = e^{i\\pi} = cos\\pi + isin \\pi = -1\\)</li> <li>\\(-i = e^{i\\frac{3\\pi}{2}} = cos\\frac{3\\pi}{2} + isin\\frac{3\\pi}{2} = -i\\)</li> </ul> <p>\u8fd9\u91cc\uff0c\u4f60\u522b\u8bb0\u8fd9\u4e2a\u6570\u4e86\uff0c\u4ece\u51e0\u4f55\u7684\u89d2\u5ea6\u7406\u89e3</p> <ul> <li>\\(e^{i2\\pi} = e^{i0\\pi}=e^{i2\\pi n} = 1\\)</li> </ul> <p>\u8868\u793a\u5728\u590d\u5e73\u9762\u5355\u4f4d\u5706\u7684\u8d77\u70b9\u4f4d\u7f6e</p> <ul> <li>\\(i = e^{i\\frac{\\pi}{2}} = e^{i(\\frac{\\pi}{2}+2n\\pi)}\\)</li> </ul> <p>\u8868\u793a\u5355\u4f4d\u5706\u534a\u5f84\u4ece\u8d77\u70b9\u9006\u65f6\u9488\u65cb\u8f6c 90\u00b0\uff0c\u5230\u8fbe \\(i\\)</p> <ul> <li>\\(-1 = e^{i\\pi}=e^{i(\\pi+2n\\pi)}\\)</li> </ul> <p>\\(e^{i\\pi}\\)\u8868\u793a\u5355\u4f4d\u5706\u534a\u5f84\u4ece\u8d77\u70b9\u9006\u65f6\u9488\u65cb\u8f6c 180\u00b0\uff0c\u5230\u8fbe \\(-1\\)</p> <p>\\(e^{-i\\pi}\\)  \u8868\u793a\u5355\u4f4d\u5706\u534a\u5f84\u4ece\u8d77\u70b9\u53cd\u65b9\u5411\u65cb\u8f6c 180\u00b0\uff0c\u5230\u8fbe \\(-1\\)</p> <ul> <li>\\(-i = e^{i\\frac{3\\pi}{2}} = e^{-i\\frac{\\pi}{2}} = -i = e^{i\\frac{3\\pi}{2}} = e^{i(-\\frac{\\pi}{2}+2n\\pi)}\\)</li> </ul> <p>\\(e^{i\\frac{3\\pi}{2}}\\)\u8868\u793a\u5355\u4f4d\u5706\u534a\u5f84\u4ece\u8d77\u70b9\u9006\u65f6\u9488\u65cb\u8f6c 270\u00b0\uff0c\u5230\u8fbe \\(-1\\)</p> <p>\\(e^{-i\\frac{\\pi}{2}}\\)  \u8868\u793a\u5355\u4f4d\u5706\u534a\u5f84\u4ece\u8d77\u70b9\u53cd\u65b9\u5411\u65cb\u8f6c 90\u00b0\uff0c\u5230\u8fbe \\(-1\\)</p> <ul> <li>\u6015\u6211\u4ee5\u540e\u641e\u53cd\uff0c\u8fd9\u91cc\u7279\u5730\u7528\u4e86\u53cd\u65b9\u5411\u65cb\u8f6c\uff0c\u5176\u5b9e\u5c31\u662f\u987a\u65f6\u9488\u65cb\u8f6c</li> <li>\u6ce8\u610f\u4e00\u4e0b\uff0c\u8fd9\u91cc \\(n=0,\\pm 1,\\pm 2,\\pm 3,...\\)</li> </ul> <p>\u5355\u4f4d\u6839 </p> <p></p> <ul> <li>\\(\\omega = 120\u00b0\\) \u662f\u89d2\uff0c\u4e5f\u662f\u590d\u6570\u8868\u793a\uff0c\u4e5f\u662f \u6307\u6570</li> <li>\u590d\u6570\uff1a \\(\\omega = -\\frac{1}{2} + i \\sqrt{\\frac{3}{2}}\\)</li> <li>\u203b \u6307\u6570\uff1a\\(\\omega = e^{i\\frac{2\\pi k}{N}}\\) \u8fd9\u91cc\u5212\u5206\u6210 3 \u4e2a\uff0c\u4e5f\u5c31\u662f 3 \u4e2a\u6837\u672c\u70b9\uff0c\u6240\u4ee5 \\(N=3\\)\uff0c\u8fd9\u662f\u7b2c\u4e00\u6b21\u65cb\u8f6c\uff0c\u6240\u4ee5\uff0c\\(k=1\\) \u6240\u4ee5\u6307\u6570\u8868\u793a \\(\\omega = e^{i \\frac{2 \\pi}{3}}\\)</li> </ul>"},{"location":"Statistics/1_3_complexExp/#_4","title":"\u590d\u6307\u6570\u7684\u5468\u671f\u6027","text":"<p>\\(e^{ix}\\) \u5468\u671f \\(T=2\\pi\\)</p> <p>\u590d\u6307\u6570\u7684\u4e00\u822c\u5f62\u5f0f \\(e^{i\\Omega t}\\) \u5468\u671f \\(T=\\frac{2\\pi}{\\Omega}\\)</p> <p></p> <ul> <li> <p>\u8fd9\u91cc\u7684 \\(n= \\pm 1\u3001\\pm 2\u3001\\pm 3,......\\)</p> </li> <li> <p>\\(e^{i}\\) \u6307\u6570\u90e8\u5206 \\(\uff1e0\\) \uff1a\u8868\u793a\u9006\u65f6\u9488\u65cb\u8f6c\uff0c\u662f\u6b63\u65b9\u5411\u3002</p> </li> <li>\\(e^{ix} \\&amp; e^{-ix}\\) \uff1a\u5b9e\u90e8\u4e0d\u53d8\uff0c\u865a\u90e8\u4e92\u4e3a\u76f8\u53cd\u6570</li> </ul> <p>\u89e3\u91ca\uff1a </p> <ul> <li>\\(e^{ix} = \\cos x + i \\sin x\\)</li> <li>\\(e^{-ix} = \\cos x - i \\sin x\\)</li> </ul> <ul> <li> \\(T=N\u3001T=\\frac{N}{2}\u3001T=\\frac{N}{3}\u3001T=\\frac{N}{4}\\) \uff1f\u8ddf  \\(\\omega \u3001T\\) \uff1f</li> </ul> <ul> <li>\u8fd9\u91cc\u7684 \\(N\\) \u8868\u793a\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u7684\u957f\u5ea6 </li> <li>\\(\\omega = 2\\pi f = \\frac{2 \\pi}{T}\\) </li> </ul> <p>\u628a\u8bb0\u53f7\u533a\u5206\u4e00\u4e0b\u5c31\u597d\u3002 </p> <p>\\(\\Omega = \\frac{2\\pi}{N}\\)  \u6240\u4ee5 \u8fd9\u4e2a\u53eb\u57fa\u6ce2\u7684\u89d2\u9891\u7387\uff0c\\(T=N\\) \u540e\u9762\u4f9d\u6b21\uff0c\\(N/2\u3001N/3\u3001......\\)</p> <p>\u8fd9\u91cc\u53d8\u5316\u7684\u662f \\(k\\)\uff0c\u60f3\u8981\u8ba8\u8bba\u7684\u662f\u57fa\u6ce2\u3001\u8c10\u6ce2</p> <p>\\(\\Omega = \\frac{2\\pi}{N}\\)   \u2192 \\(T=N\\)</p> <p>\\(2\\Omega = \\frac{2\\pi}{N/2}\\)   \u2192 \\(T=N/2\\)</p> <p>\\(3\\Omega = \\frac{2\\pi}{N/3}\\)   \u2192 \\(T=N/3\\)</p> <p>\\(4\\Omega = \\frac{2\\pi}{N/4}\\)   \u2192 \\(T=N/4\\)</p> <p>(1)\\(X_k = \\sum_{n=0}^{N-1} x_n e^{-i\\frac{2 \\pi k n}{N}}\\)</p> <p>(2) \\(\\quad = \\sum_{n=0}^{N-1} x_n e^{-i \\Omega kn}\\)</p> <p>(3)\\(X_k = w^{kn}x_n\\) \uff0c\\(kn=0 \\sim N-1\\) </p> <p> </p> <ul> <li>\u5173\u4e8e\u8fd9\u91cc\u7684\u5468\u671f\u6027\u7279\u522b\u7684\u5f3a\u8c03\u4e00\u4e0b\uff0c\u5c24\u5176\u662f\u548c\u4e09\u89d2\u51fd\u6570\u7684\u5f62\u5f0f\u4f5c\u5bf9\u6bd4\uff1a</li> </ul> <p>\u6700\u5927\u5468\u671f \u4e0e \u6b63\u4ea4\u57fa </p> <ul> <li>\u5bf9\u4e8e\u4efb\u610f\u5468\u671f \\(T\\) \u7684\u542b\u4e49\u8fdb\u884c\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u7528\u5230\u7684\u6b63\u4ea4\u57fa\uff0c\u5728\u4e00\u4e2a\u5468\u671f\u5185\u3001\u4e5f\u5c31\u662f\u6700\u5927\u5468\u671f\u5185\u7684\u79ef\u5206\\(=0\\) \uff0c\u8fd9\u53e5\u8bdd\u9002\u7528\u4e8e\u4e09\u89d2\u51fd\u6570\u6b63\u4ea4\u57fa\uff0c\u4e5f\u9002\u7528\u4e8e\u590d\u6307\u6570\u6b63\u4ea4\u57fa\u2192\u590d\u6307\u6570\u6b63\u4ea4\u57fa\u7684\u8bc1\u660e</li> </ul> <p> </p>"},{"location":"Statistics/1_3_complexExp/#2pi","title":"\u5468\u671f\u4e3a\u4ec0\u4e48\u662f \\(2\\pi\\)","text":"<p>\ud83c\udf3a \u5b83\u662f\u57fa\u672c\u6b63\u5f26\u51fd\u6570 \\(\\sin(x)\\) \u7684\u4e00\u4e2a\u5b8c\u6574\u5468\u671f </p> <p>\ud83c\udf3a \u5b83\u662f\u6240\u6709 \\(\\sin(nx)\\) \u51fd\u6570\u7684\u5468\u671f\u516c\u500d\u6570 </p> <p>\ud83c\udf3a \u5b83\u6784\u6210\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u6b63\u4ea4\u7cfb\u7edf </p> <p>\u89e3\u91ca\u5468\u671f\u516c\u500d\u6570\uff1a </p> <p>\u5bf9\u4e8e\u4efb\u610f\u6b63\u6574\u6570 \\(n\\)\uff0c\\(\\sin(nx)\\) \u7684\u5468\u671f\u662f \\(\\frac{2\\pi}{n}\\)\u3002\u5f53\u6211\u4eec\u53d6 \\([0,2\\pi]\\) \u4f5c\u4e3a\u79ef\u5206\u533a\u95f4\u65f6\uff1a</p> <ul> <li>\\(\\sin(1x)\\) \u5728\u6b64\u533a\u95f4\u5b8c\u6210 1 \u4e2a\u5b8c\u6574\u5468\u671f</li> <li>\\(\\sin(2x)\\) \u5728\u6b64\u533a\u95f4\u5b8c\u6210 2 \u4e2a\u5b8c\u6574\u5468\u671f</li> <li>\\(\\sin(3x)\\) \u5728\u6b64\u533a\u95f4\u5b8c\u6210 3 \u4e2a\u5b8c\u6574\u5468\u671f</li> </ul> <p>\u8fd9\u610f\u5473\u7740\uff0c\u5bf9\u4e8e\u4efb\u4f55\u6574\u6570 \\(n\\)\uff0c\\(\\sin(nx)\\) \u5728 \\([0,2\\pi]\\) \u533a\u95f4\u5185\u5305\u542b\u6574\u6570\u4e2a\u5b8c\u6574\u5468\u671f\u3002</p> <p>\u5bf9\u4e8e \\(sin(nx)\\) \u6765\u8bf4\uff0c \\(2\\pi\\)  \u662f\u57fa\u672c\u7684\u6700\u5927\u5468\u671f\u3002</p> <ul> <li> \u6b63\u4ea4\u6027\u7684\u6570\u5b66\u539f\u7406 </li> </ul> <p>\u5f53\u6211\u4eec\u8ba1\u7b97\u79ef\u5206 \\(\\int_0^{2\\pi} \\sin(nx)\\sin(mx) dx\\) \u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e09\u89d2\u6052\u7b49\u5f0f\uff1a</p> \\[\\sin(nx)\\sin(mx) = \\frac{1}{2}[\\cos((n-m)x) - \\cos((n+m)x)]\\] <p>\u6240\u4ee5\u79ef\u5206\u53d8\u4e3a\uff1a</p> \\[\\int_0^{2\\pi} \\sin(nx)\\sin(mx) dx = \\frac{1}{2}\\int_0^{2\\pi} [\\cos((n-m)x) - \\cos((n+m)x)] dx\\] <p>\u5bf9\u4e8e\u4efb\u4f55\u975e\u96f6\u6574\u6570 \\(k\\)\uff0c\\(\\int_0^{2\\pi} \\cos(kx) dx = 0\\)\uff08\u56e0\u4e3a\u4f59\u5f26\u51fd\u6570\u5728\u5b8c\u6574\u5468\u671f\u4e0a\u7684\u79ef\u5206\u4e3a\u96f6\uff09\u3002</p> <p>\u5f53 \\(n \\neq m\\) \u65f6\uff0c\\((n-m)\\) \u548c \\((n+m)\\) \u90fd\u662f\u975e\u96f6\u6574\u6570\uff0c\u6240\u4ee5\u4e24\u9879\u79ef\u5206\u90fd\u7b49\u4e8e\u96f6\uff0c\u6700\u7ec8\u7ed3\u679c\u662f\u96f6\u3002</p> <ul> <li> \u51fd\u6570\u7a7a\u95f4\u7684\u5b8c\u5907\u6027 </li> </ul> <p>\\([0,2\\pi]\\) \u533a\u95f4\u4e0a\u7684\u4e09\u89d2\u51fd\u6570\u7cfb\u7edf \\(\\{1, \\sin(x), \\sin(2x), ..., \\cos(x), \\cos(2x), ...\\}\\) \u6784\u6210\u4e86\u5e73\u65b9\u53ef\u79ef\u51fd\u6570\u7a7a\u95f4\u7684\u4e00\u4e2a\u5b8c\u5907\u6b63\u4ea4\u57fa\u3002\u8fd9\u610f\u5473\u7740\u4efb\u4f55\u5728\u6b64\u533a\u95f4\u4e0a\u7684\u5e73\u65b9\u53ef\u79ef\u51fd\u6570\u90fd\u53ef\u4ee5\u8868\u793a\u4e3a\u8fd9\u4e9b\u57fa\u51fd\u6570\u7684\u7ebf\u6027\u7ec4\u5408\u3002</p> <ul> <li> \u5b9e\u9645\u4f8b\u5b50\u8bf4\u660e </li> </ul> <p>\u8ba9\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5177\u4f53\u4f8b\u5b50\u6765\u7406\u89e3\uff1a\u8003\u8651 \\(\\sin(2x)\\) \u548c \\(\\sin(3x)\\)\u3002</p> <ul> <li>\\(\\sin(2x)\\) \u7684\u5468\u671f\u662f \\(\\pi\\)</li> <li>\\(\\sin(3x)\\) \u7684\u5468\u671f\u662f \\(\\frac{2\\pi}{3}\\)</li> </ul> <p>\u5982\u679c\u6211\u4eec\u53ea\u5728\u4e00\u4e2a\u51fd\u6570\u7684\u5468\u671f\u4e0a\u79ef\u5206\uff0c\u6bd4\u5982 \\([0,\\pi]\\)\uff0c\u53e6\u4e00\u4e2a\u51fd\u6570\u5728\u6b64\u533a\u95f4\u4e0d\u4f1a\u5b8c\u6210\u6574\u6570\u4e2a\u5468\u671f\uff0c\u6b63\u4ea4\u6027\u53ef\u80fd\u4e0d\u6210\u7acb\u3002\u4f46\u5728 \\([0,2\\pi]\\) \u4e0a\uff1a</p> <ul> <li>\\(\\sin(2x)\\) \u5b8c\u6210\u4e86 2 \u4e2a\u5b8c\u6574\u5468\u671f</li> <li>\\(\\sin(3x)\\) \u5b8c\u6210\u4e86 3 \u4e2a\u5b8c\u6574\u5468\u671f</li> </ul> <p>\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4e24\u4e2a\u51fd\u6570\u7684\u4e58\u79ef\u5728\u6b63\u8d1f\u533a\u57df\"\u6070\u597d\u5e73\u8861\"\uff0c\u4f7f\u79ef\u5206\u4e3a\u96f6\u3002</p> <ul> <li> \u603b\u7ed3 </li> </ul> <p>\\([0,2\\pi]\\) \u79ef\u5206\u533a\u95f4\u7684\u9009\u62e9\u4e0d\u662f\u57fa\u4e8e\u5355\u4e2a\u51fd\u6570\u7684\u5468\u671f\uff0c\u800c\u662f\u57fa\u4e8e\u5efa\u7acb\u4e00\u4e2a\u5b8c\u6574\u6b63\u4ea4\u7cfb\u7edf\u7684\u9700\u8981\u3002\u8fd9\u4e2a\u7279\u6b8a\u533a\u95f4\u786e\u4fdd\u4e86:</p> <ul> <li>\u6240\u6709 \\(\\sin(nx)\\) \u51fd\u6570\u5728\u6b64\u533a\u95f4\u4e0a\u5305\u542b\u6574\u6570\u4e2a\u5468\u671f</li> <li>\u4e0d\u540c\u9891\u7387\u7684\u6b63\u5f26\u51fd\u6570\u5728\u6b64\u533a\u95f4\u4e0a\u6b63\u4ea4</li> <li>\u4e09\u89d2\u51fd\u6570\u7cfb\u7edf\u5728\u6b64\u533a\u95f4\u4e0a\u6784\u6210\u5b8c\u5907\u6b63\u4ea4\u57fa</li> </ul>"},{"location":"Statistics/1_3_complexExp/#omega-omega-t","title":"\\(\\Omega \u3001\\omega\\) \u4e0e\u5468\u671f \\(T\\)","text":"<p>\u8fd9\u53e5\u8bdd\uff0c</p> <p>\u4f60\u4ed4\u7ec6\u89c2\u5bdf\u8fd9\u91cc\uff1a</p> <p></p> <p>\u6b63\u4ea4\u57fa\u5206\u522b\u662f \uff08k \u53d6 1,2,3,...\uff09</p> <p>\u2b50\ufe0e \\(\\{0,\\cos\\omega t,\\sin\\omega t,\\cos2\\omega t,\\sin2\\omega t,\\cos3\\omega t,\\sin3\\omega t,..\\}\\) </p> <p>\u5206\u522b\u5b8c\u6210\uff0c\u76f4\u6d41\u5206\u91cf\uff0c1\u4e2a\u5468\u671f\uff0c2 \u4e2a\u5468\u671f\uff0c3 \u4e2a\u5468\u671f</p> <p>(k \u53d6 0,1,2,3,...) \u5bf9\u4e8e\u590d\u6307\u6570\u6765\u8bf4 \u76f4\u6d41\u5206\u91cf\u548c\u590d\u6307\u6570\u5408\u5e76\u4e86\uff0c\u6240\u4ee5 k \u4ece 0 \u5f00\u59cb\u53d6</p> <p>\u2b50\ufe0e \\(\\{e^{0jk\\omega t},e^{\\pm j\\omega t},e^{\\pm 2 j\\omega t},e^{\\pm 3 j\\omega t},... \\}\\) </p> <p>\u5206\u522b\u5b8c\u6210\uff0c\u76f4\u6d41\u5206\u91cf\uff0c1 \u4e2a\u5468\u671f\uff0c2 \u4e2a\u5468\u671f\uff0c3 \u4e2a\u5468\u671f\uff0c4 \u4e2a\u5468\u671f\uff0c......</p> <p>\uff08\u4ee5 \u539f\u59cb\u4fe1\u53f7\u957f\u5ea6\u4e3a\u57fa\u51c6\uff0c\u5b8c\u62101 \u4e2a\u5468\u671f\uff0c2 \u4e2a\u5468\u671f\uff0c... ...\uff09</p> <p>\u63d0\u793a\u4e00\u70b9\uff0c\u5982\u679c\u628a\u590d\u6307\u6570\u8bb0\u6210\uff0c\\(\\{e^{0j\\Omega t},e^{\\pm j\\Omega t},e^{\\pm 2 j\\Omega t},e^{\\pm 3 j\\Omega t},... \\}\\)</p> <p>\uff08\u8fd9\u91cc\u662f\u6211\u770b\u5f97\u5f88\u987a\u7545\u7684\u7684\u8868\u793a\uff09 </p> <p>\u90a3\u4e48\uff0c\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u5c31\u53ef\u4ee5\u8bb0\u6210 \\(X[k] = \\sum_{n=0}^{\\infty} x[n]w_{kn}\\)</p> <p>\u5176\u4e2d \\(w=e^{-i\\frac{2\\pi}{N}}\\)  \u57fa\u6ce2\u5bf9\u5e94\u7684\u9891\u7387\u3001\u57fa\u9891\u6ce2\u3002\u4e0e\u4e4b\u5bf9\u5e94\u7684\u662f\u8c10\u6ce2\u3002</p> <p>\u518d\u628a \\(\\Omega  \\stackrel{\u8bb0\u4f5c}{=} \\frac{2\\pi}{N}\\)</p> <p>\u6b63\u4ea4\u57fa\u53ef\u4ee5\u5199\u6210 \\(\\{e^{0j\\Omega t},e^{\\pm j\\Omega t},e^{\\pm 2 j\\Omega t},e^{\\pm 3 j\\Omega t},... \\}\\)</p> <p>\u90fd\u7528 \\(\\omega\\) \u8868\u793a\uff1a\\(\\{\\omega^{0t},\\omega^{1t},\\omega^{2t},\\omega^{3t},\\omega^{4t}..\\}\\)</p> <p>\u4e8e\u662f\uff0c\u5c31\u6709\u4e86 DFT \u7684\u77e9\u9635\u5f62\u5f0f\uff1a</p> <p></p> <p></p>"},{"location":"Statistics/1_3_complexExp/#_5","title":"\u590d\u6307\u6570\u6b63\u4ea4\u57fa","text":"<p>\u7279\u522b\u60f3\u5f3a\u8c03\u7684\u662f\uff0c\u4e3a\u4ec0\u4e48\u4e24\u4e2a\u4e0d\u540c\u51fd\u6570\u5185\u79ef=0</p> <p>\u501f\u52a9\u6700\u5927\u5468\u671f\u6765\u7406\u89e3\uff0c\u8fd9\u91cc\u7684 T \u662f\u6700\u5927\u5468\u671f\uff0c\u4e00\u4e2a\u5468\u671f\u5185\u7684\u79ef\u5206\\(=0\\)\uff0c\u6240\u4ee5\\(=0\\)</p> <p>\u600e\u4e48\u7406\u89e3\u8fd9\u91cc\u7684\u6700\u5927\u5468\u671f\uff1f</p> <p>\\(e^{j(n-k)\\omega t}\\) \u7684\u5468\u671f \uff1a</p> <p>$ e^{j(n-k)\\omega t} \u7684 \u5468\u671f =\\frac{2 \\pi}{(n-k)\\omega}$</p> <p>\u5176\u4e2d\uff0c\u8fd9\u91cc\u7684\u5085\u91cc\u53f6\u53d8\u6362\u4e2d\uff1a \\(\\omega = \\frac{2 \\pi}{N}\\) \\(N\\)\u8868\u793a\u539f\u59cb\u5e8f\u5217\u957f\u5ea6\uff0c\u8fd9\u91cc\u5c06\u539f\u59cb\u5e8f\u5217\u957f\u5ea6\u8bb0\u4e3a \\(T\\) \uff0c\u6240\u4ee5 \\(\\omega = \\frac{2 \\pi}{T}\\) </p> <p>\u6240\u4ee5 \\(e^{j(n-k)\\omega t} \u7684 \u5468\u671f = \\frac{N}{n-k} =\\frac{T}{n-k}\\) </p> <p>\u4e5f\u5c31\u662f\u8bf4</p> <p> </p> <p>\u8fd9\u91cc\u79ef\u5206\u5185 \u590d\u6307\u6570\u7684 \\(\u5468\u671f =\\frac{T}{n-k}\\) </p> <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u5728 \\(t \\in (-\\frac{T}{2},\\frac{T}{2})\\) \u4e2d\uff0c\\(e^{j(n-k)\\omega t}\\) \u5b8c\u6210\u4e86 \\(n-k\\) \u6b21\u5468\u671f</p> <p>\u4e5f\u5c31\u662f\u8bf4 \\(T\\) \u662f\u6240\u6709  \\(e^{j(n-k)\\omega t}\\) \u7684\u6700\u5927\u5468\u671f\uff0c\u6240\u4ee5\u5468\u671f\u5185\u79ef\u5206 \\(= 0\\)</p> <p>\u5bf9\u7167\u7740 \u4e09\u89d2\u51fd\u6570\u6b63\u4ea4\u57fa\uff1a </p> <p> </p>"},{"location":"Statistics/1_3_complexExp/#_6","title":"\u2b50\ufe0e \u590d\u6570\u3001\u590d\u6307\u6570\u3001\u4e09\u89d2\u51fd\u6570\u7684\u76f8\u4e92\u5bf9\u5e94","text":"<p>\\(a+bi\\)</p> <p>= \\(\\sqrt{a^2 + b^2} e^{i {arctan\\frac{b}{a}}} = |\u6a21\u957f|e^{i \u5e45\u89d2}\\) </p> <p>= \\(\\sqrt{a^2 + b^2}(\\cos {(\\arctan\\frac{b}{a})}+ i \\sin {(\\arctan\\frac{b}{a})} )\\)</p> <p>\\(=|\u6a21\u957f|(\\cos\u5e45\u89d2+ \\sin\u5e45\u89d2)\\) </p> <p>$\\cos {(\\arctan\\frac{b}{a})} = \\frac{a}{\\sqrt{a^2 + b^2}} $   </p> <p>\\(\u4f59\u5f26\u503c =  \\frac{\u5b9e\u90e8}{|\u6a21\u957f|}\\)</p> <p>\\(\\sin {(\\arctan\\frac{b}{a})} = \\frac{b}{\\sqrt{a^2 + b^2}}\\) </p> <p>\\(\u6b63\u5f26\u503c = \\frac{\u865a\u90e8}{|\u6a21\u957f|}\\)</p> <p>\\(\u5e45\u89d2 = \\arctan \\frac{\u865a\u90e8}{\u5b9e\u90e8}\\) </p> <p>\u56fe\u5f62\uff1a </p> <p> </p> <p>\u8fd9\u91cc\u6709\u4e00\u4e2a\u9057\u7559\u95ee\u9898\uff1a\u600e\u4e48\u7528\u5355\u4e2a\u4f59\u5f26\u51fd\u6570\u8868\u793a\u6216\u8005\u5355\u4e2a\u6b63\u5f26\u51fd\u6570\u8868\u793a </p> <p>\u501f\u52a9\u7684\u77e5\u8bc6\uff1a\u7531\u8fd9\u91cc\uff0c\u53cc\u8fb9\u8c31\u548c\u5355\u8fb9\u8c31\u7684\u5173\u7cfb</p> <ul> <li>\u53cc\u8fb9\u8c31\u5c31\u662f\u501f\u52a9\u6b27\u62c9\u516c\u5f0f\uff0c\u5c06\u5085\u91cc\u53f6\u7ea7\u6570\u4f59\u5f26\u51fd\u6570\u8868\u793a\u7684\u8f85\u52a9\u89d2\u5f62\u5f0f\u8f6c\u6362\u4e3a \\(e\\) \u7684\u590d\u6307\u6570\u5f62\u5f0f</li> </ul> <p></p> <p></p> <ul> <li>\u5c06\u4f59\u5f26\u4fe1\u53f7\u8868\u793a\u5355\u8fb9\u8c31\u53d8\u6210\u590d\u6307\u6570\u5f62\u5f0f\u8868\u793a\u53cc\u8fb9\u8c31</li> <li>\u533a\u522b&amp;\u8054\u7cfb\uff08\u53cc\u8fb9\u8c31&amp;\u5355\u8fb9\u8c31\uff0c\u6a21\u957f\u548c\u76f8\u89d2\u7684\u65b9\u5411\u548c\u5927\u5c0f\u90fd\u8981\u8ba8\u8bba\u5230\uff09</li> <li>\u53cc\u8fb9\u8c31\u7684 \u5e45\u503c\uff0c\u7531 \u5355\u8fb9\u8c31\u7684\u5e45\u503c \u51cf\u534a\uff0c\u5bf9\u79f0\u5230\u8d1f\u9891\u7387\u4e0a</li> <li>\u76f8\u4f4d\u5927\u5c0f\u4e0d\u53d8\uff0c\u9891\u7387\u8fdb\u884c\u5947\u5bf9\u79f0</li> </ul> <p>\u4e3e\u4f8b\u5b50\uff1a </p> <p></p> <p>\u7531\u4e09\u89d2\u51fd\u6570\u51fa\u53d1\uff0c\u53ef\u4ee5\u5f88\u5bb9\u6613\u7684\u5199\u51fa \u590d\u6307\u6570\u5f62\u5f0f\u3002</p> <p>\u5e76\u7531\u4e09\u89d2\u51fd\u6570\u7684\u5355\u8fb9\u8c31\u753b\u51fa\u53cc\u8fb9\u8c31\u3002</p> <p>\u4f46\u5b9e\u9645\u4e0a\uff0c\u7528 DFT\uff08\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff09\uff0cDFS\uff08\u79bb\u6563\u5085\u91cc\u53f6\u7ea7\u6570\uff09\u7528\u590d\u6307\u6570\u5206\u89e3\u66f4\u5bb9\u6613\u8ba1\u7b97\uff0c\u56e0\u4e3a\u6709\u77e9\u9635\u5f62\u5f0f\u3002\\(X[k]=w^{kn}x[n]\\)  \uff1b\u90a3 \u600e\u4e48\u7531\u590d\u6307\u6570\u5f62\u5f0f\uff08\u53cc\u8fb9\u8c31\uff09\u76f4\u63a5\u5199\u51fa\u4e09\u89d2\u51fd\u6570\u7684\u5f62\u5f0f\uff08\u5355\u8fb9\u8c31\uff09\uff0c\u6ce8\u610f\uff0c\u4e0d\u662f\u4e2d\u95f4\u7684\u8f85\u52a9\u89d2\u5f62\u5f0f\uff1f</p> <p>\u7531\u8fd9\u91cc\u4f8b\u9898\uff1a</p> <p> </p> <p></p> <p>\u7531\u8fd9\u4e2a\u4f8b\u9898\u7684\u5904\u7406\uff0c\u53ef\u4ee5\u770b\u51fa\u662f \u53d6\u5f97\u4e24\u4e2a\u7684\u5468\u671f\uff0c\u8fdb\u884c\u5171\u8f6d\u3002</p> <p>\u4e5f\u5c31\u662f \u7528\u7684 \u5171\u8f6d\u6027\u8d28\u3001\u6b27\u62c9\u516c\u5f0f\u3001\u5468\u671f\u6027 \uff0c \u5176\u5b9e\uff0c\u8fd8\u6709\u4e00\u4e2a\u5947\u5076\u6027\uff0c\u7528\u4e86\u5947\u5076\u6027\u53ef\u4ee5\u770b\u51fa\u53cc\u8fb9\u8c31\u548c\u5355\u8fb9\u8c31</p> <p> </p> <p>\u6211\u73b0\u5728\u7684\u95ee\u9898\uff1a\u80fd\u4e0d\u80fd\u7531</p> <p></p> <p>\u590d\u6307\u6570\u5f62\u5f0f\u76f4\u63a5\u5199\u51fa\u4e09\u89d2\u51fd\u6570\u5f62\u5f0f\uff1b\u80fd\u4e0d\u80fd\u7531\u53cc\u8fb9\u8c31\u76f4\u63a5\u5199\u51fa\u5355\u8fb9\u8c31\uff1f</p> <p>\u8fd9\u4e2a\u9898\u7684\u7279\u6b8a\u4e4b\u5904\uff1a</p> <p> </p> <ul> <li> <p>\u4e00\u822c\u6709\u4e86 $e^{ix} $ \u76f4\u63a5\u5bf9\u6307\u6570\u90e8\u5206 \u53d6\u8d1f\u6570\uff0c\u5f97\u5230 \\(e^{-ix}\\) \uff0c\u518d\u76f8\u52a0\u5373\u53ef\u5f97\u5230\u5355\u8fb9\u8c31</p> </li> <li> <p> \u4f46\u662f\u95ee\u9898\u662f \u5982\u679c \\(x[n] = e^{ix}\\) \u90a3\u968f\u4fbf\u53d6  \\(e^{-ix}\\) \u5c31\u4e0d\u4e00\u5b9a\u6709\u610f\u4e49\u4e86\uff0c\u4e0d\u4e00\u5b9a\u662f  \\(x[n]\\) \u4e86\u3002\u8fd9\u4e2a\u9898\u662f\u53ef\u4ee5\u3002\uff08\u540e\u9762\u518d\u770b</p> </li> </ul>"},{"location":"Statistics/1_4_signal/","title":"FS\u3001FT\u3001DTFS\u3001DTFT","text":""},{"location":"Statistics/1_4_signal/#fsftdtfsdtft","title":"FS\u3001FT\u3001DTFS\u3001DTFT","text":"2025-03-27 19:04:352025-09-28 12:54:03 <p> \u7ea6 321 \u4e2a\u5b57  5 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>\u53c2\u770b\u8bfe\u4ef6</p> \u8fde\u7eed\u65f6\u95f4\u5468\u671f\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u7ea7\u6570 \u67e5\u770b \u8fde\u7eed\u65f6\u95f4\u975e\u5468\u671f\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u53d8\u6362 \u67e5\u770b \u79bb\u6563\u65f6\u95f4\u5468\u671f\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u53d8\u6362 \u67e5\u770b \u79bb\u6563\u65f6\u95f4\u975e\u5468\u671f\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u53d8\u6362 \u67e5\u770b <p>\u76ee\u5f55\uff1a </p> <p></p> <p>\u76ee\u6807\u90fd\u662f\uff1a\u539f\u59cb\u4fe1\u53f7\u8868\u793a\u4e3a\u4e00\u7cfb\u5217\u5355\u4f4d\u5706\u4e0a\u7684\u6b63\u4ea4\u57fa\u8868\u793a \\(x(t)=... ...\\)</p> <ul> <li>\u5728\u6b63\u4ea4\u57fa\u4e0a\u7684\u5f3a\u5ea6\uff0c\u7528\u5185\u79ef\u8ba1\u7b97</li> </ul> <p>FS   \u8fde\u7eed\u65f6\u95f4\u5468\u671f\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u7ea7\u6570</p> <p>\u3010\u65f6\u57df\u2192\u9891\u57df\u3011</p> \\[x(t) = \\sum_{k=-\\infty}^{\\infty}F(k\\omega_0)e^{jk\\omega_0 t}\\] <p>\u5176\u4e2d\uff1a\u3010\u9891\u57df\u2192\u65f6\u57df\u3011</p> <p>\\(F(k\\omega_0) = \\frac{1}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}} x(t)e^{-jk\\omega_0t}dt\\)</p> <p>FT  \u8fde\u7eed\u65f6\u95f4\u975e\u5468\u671f\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u7ea7\u6570</p> \\[x(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}F(\\omega)e^{j\\omega t}d\\omega \\] <p>\u5176\u4e2d\uff0c</p> <p>$ F(\\omega) = \\int_{-\\infty}^{\\infty} x(t) e^{-j\\omega t}dt  $</p> <p>DTFS  \u79bb\u6563\u65f6\u95f4\u5468\u671f\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u7ea7\u6570</p> \\[x[n] = \\sum_{k=0}^{N_0 - 1} F(k\\Omega_0)e^{jk\\Omega_0 n}\\] <p>$ F(k\\Omega_0)= \\frac{1}{N_0}\\sum_{n=0}^{N_0 - 1}x[n]e^{-jk\\Omega_0 n}$</p> <p>DTFT \u79bb\u6563\u65f6\u95f4\u5468\u671f\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u53d8\u6362 \\(\\rightarrow FFT\\)</p> <p>\\(x[n] = \\frac{1}{2\\pi}\\int_0^{2\\pi}F(\\Omega)e^{j\\Omega n} d\\Omega\\) </p> <p>\\(F(\\Omega) = \\sum_{n=-\\infty}^{\\infty}x[n]e^{-j\\Omega n}\\)</p>"},{"location":"Statistics/1_FFT/","title":"Fourier\u7ea7\u6570","text":""},{"location":"Statistics/1_FFT/#fourier","title":"Fourier\u7ea7\u6570","text":"2025-03-23 22:06:212025-09-28 12:54:03 <p> \u7ea6 1814 \u4e2a\u5b57  32 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 9 \u5206\u949f</p> <ul> <li> \u5085\u91cc\u53f6\u7ea7\u6570</li> <li> <p> \u5085\u91cc\u53f6\u53d8\u6362</p> </li> <li> <p> \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362</p> </li> <li> \u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362</li> </ul>"},{"location":"Statistics/1_FFT/#_1","title":"\u4e09\u89d2\u51fd\u6570\u5f62\u5f0f","text":"<p>\ud83d\udfe2  case1\uff1a\u5468\u671f= \\(2 \\pi\\)</p> <p>\u5468\u671f\u4e3a \\(2\\pi\\)\u7684\u51fd\u6570\u5c55\u5f00\u5f0f</p> \\[f(t) = \\frac{a_0}{2} + \\sum_{n=1}^{+ \\infty} a_n cosnt + b_nsinnt\\] \\[\\left\\{ \\begin{aligned} a_0 &amp; =\\frac{1}{\\pi}\\int_{-\\pi}^{\\pi}f(t)\\mathrm{d}t, \\\\ a_n &amp; =\\frac{1}{\\pi}\\int_{-\\pi}^{\\pi}f(t)\\cos\\mathrm{n}t\\mathrm{d}t, \\\\ b_n &amp; =\\frac{1}{\\pi}\\int_{-\\pi}^{\\pi}f(t)\\sin\\mathrm{n}t\\mathrm{d}t \\end{aligned}\\right.\\] <p>\ud83d\udfe2 case2\uff1a\u5468\u671f=2T</p> <p>\\(t=?x = 2\\pi \\frac{x}{2T} = \\pi \\frac{x}{T}\\)</p> \\[f(x)=\\frac{a_0}{2} + \\sum_{n=1}^{+ \\infty} a_n cosn\\pi\\frac{x}{T} + b_nsinn\\pi\\frac{x}{T}\\] <p>\\(dt = \\frac{\\pi}{T}dx\\)</p> <p>\\(t \\in (-\\pi,\\pi)  \u2192 x \\in (-T,T)\\)</p> \\[\\left\\{ \\begin{aligned} a_0 &amp; =\\frac{1}{T}\\int_{-T}^{T}f(x)\\mathrm{d}x, \\\\ a_n &amp; =\\frac{1}{T}\\int_{-T}^{T}f(x)\\cos\\mathrm{n}\\pi \\frac{x}{T}\\mathrm{d}x, \\\\ b_n &amp; =\\frac{1}{T}\\int_{-T}^{T}f(x)\\sin\\mathrm{n}\\pi \\frac{x}{T}\\mathrm{d}x \\end{aligned}\\right.\\] <p>\ud83d\udfe2 case3\uff1a\u5468\u671f=T</p> <p>\\(t=?x = 2\\pi \\frac{x}{T} =\\omega x\\)    (\u4ee4 $\\omega = \\frac{2\\pi}{T} $)</p> <p>\\(dt = \\frac{2\\pi}{T}dx\\)</p> <p>\\(t \\in (-\\pi,\\pi)  \u2192 x \\in (-\\frac{T}{2},\\frac{T}{2})\\)</p> <p>\\(f(x)=\\frac{a_0}{2} + \\sum_{n=1}^{+ \\infty} a_n cos n2\\pi\\frac{x}{T} + b_nsin n2\\pi\\frac{x}{T}\\) </p> <p>\u66f4\u5e38\u7528\u7684\u5f62\u5f0f\uff1a</p> \\[f(x)=\\frac{a_0}{2} + \\sum_{n=1}^{+ \\infty} a_n cos n \\omega x + b_nsin n \\omega x\\] \\[\\left\\{ \\begin{aligned} a_0 &amp; =\\frac{2}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)\\mathrm{d}x, \\\\ a_n &amp; =\\frac{2}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)\\cos\\mathrm{n}\\omega x\\mathrm{d}x, \\\\ b_n &amp; =\\frac{2}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)\\sin\\mathrm{n}\\omega x\\mathrm{d}x \\end{aligned}\\right.\\] <p>\u7279\u522b\u7684\uff0c\\(\\omega_0=\\frac{2\\pi}{T}\\) \u8bb0\u4f5c\u57fa\u9891\uff0c\u5468\u671f\u6700\u957f\uff0c\u6700\u4f4e\u9891</p>"},{"location":"Statistics/1_FFT/#_2","title":"\u6307\u6570\u5f62\u5f0f","text":"\\[ \\left\\{ \\begin{aligned} e^{ix}=cosx+isinx, \\\\ e^{-ix}=cosx-isinx, \\\\ \\end{aligned}\\right. \\] \\[ \\left\\{ \\begin{aligned} cosn\\omega x = \\frac{e^{in\\omega x}+e^{-in\\omega x}}{2}, \\\\ i sin n\\omega x = \\frac{e^{in\\omega x}-e^{-in\\omega x}}{2}, \\\\ \\end{aligned}\\right. \\] <p>\\(f(x)=\\frac{a_0}{2} + \\sum_{n=1}^{+ \\infty} a_n cos n \\omega x + b_nsin n \\omega x\\)</p> <p>\\(\\quad =\\frac{a_0}{2} + \\sum_{n=1}^{+ \\infty} a_n \\frac{e^{in\\omega x}+e^{-in\\omega x}}{2} - i b_n\\frac{e^{in\\omega x}-e^{-in\\omega x}}{2}\\)</p> <p>\\(\\quad =\\frac{a_0}{2} + \\sum_{n=1}^{+ \\infty} \\frac{a_n - i b_n}{2} e^{in\\omega x}+ \\frac{a_n + i b_n}{2} e^{-in\\omega x}\\)</p> <p>\u8bb0\u7cfb\u6570\u5206\u522b\u4e3a\uff1a</p> <p>\\(c_0 = \\frac{a_0}{2} = \\frac{1}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)\\mathrm{d}x \\quad (n=0)\\) </p> <p>\\(c_n = \\frac{a_n - i b_n}{2} = \\frac{\\frac{2}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)\\cos\\mathrm{n}\\omega x\\mathrm{d}x-i\\frac{2}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)\\sin\\mathrm{n}\\omega x\\mathrm{d}x}{2}\\)</p> <p>$ \\quad = \\frac{\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)\\cos\\mathrm{n}\\omega x\\mathrm{d}x-if(x)\\sin\\mathrm{n}\\omega x\\mathrm{d}x}{T}$</p> <p>$ \\quad = \\frac{\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)(\\cos\\mathrm{n}\\omega x-i\\sin\\mathrm{n}\\omega x)\\mathrm{d}x}{T}$</p> <p>$ \\quad = \\frac{\\int_{-\\frac{T}{2}}^{\\frac{T}{2}} f(x) e^ {- \\mathrm{n}\\omega x} \\mathrm{d}x}{T}$</p> <p>$ \\quad = \\frac{1}{T} \\int_{-\\frac{T}{2}}^{\\frac{T}{2}} f(x) e^{- \\mathrm{n}\\omega x }\\mathrm{d} x \\quad (n=1,2,3,4... ...)$</p> <p>\\(c_{-n} = \\frac{a_n + i b_n}{2} = \\frac{\\frac{2}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)\\cos\\mathrm{n}\\omega x\\mathrm{d}x + i\\frac{2}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}}f(x)\\sin\\mathrm{n}\\omega x\\mathrm{d}x}{2}\\)</p> <p>$ \\quad = \\frac{1}{T} \\int_{-\\frac{T}{2}}^{\\frac{T}{2}} f(x) e^{\\mathrm{n}\\omega x }\\mathrm{d} x \\quad (n=1,2,3,4... ...)$</p> <p>\u6c47\u603b \\(c_0,c_n,c_{-n}\\) </p> <p>\u53ef\u5f97\uff1a</p> <p>\\(c_n = \\frac{1}{T} \\int_{-\\frac{T}{2}}^{\\frac{T}{2}} f(x) e^{- \\mathrm{n}\\omega x }\\mathrm{d} x \\quad (n=0,\\pm 1,\\pm 2,\\pm 3,\\pm 4... ...)\\)</p> <p>\u6700\u7ec8\u5f97\u5230\uff0c\u5085\u91cc\u53f6\u7ea7\u6570\u7684\u6307\u6570\u5f62\u5f0f\uff1a</p> \\[f(x)=\\sum_{n= - \\infty}^{\\infty} c_n e^{i n \\omega x }\\] \\[c_n = \\frac{1}{T} \\int_{-\\frac{T}{2}}^{\\frac{T}{2}} f(x) e^{- \\mathrm{n}\\omega x }\\mathrm{d} x \\quad (n=0,\\pm 1,\\pm 2,\\pm 3,\\pm 4... ...)\\] <p>\u5085\u91cc\u53f6\u7ea7\u6570\u7684\u6307\u6570\u5f62\u5f0f\uff0c\u53ef\u4ee5\u6e05\u695a\u5730\u5c55\u793a\u51fa\u5e45\u89d2\u548c\u6a21\u957f\uff0c\u8fd9\u662f\u4e09\u89d2\u51fd\u6570\u5f62\u5f0f\u5c55\u793a\u4e0d\u76f4\u89c2\u7684\u3002</p> <p>\u4e2d\u95f4\u7684\u8865\u5145\uff1a </p> <p>\u5173\u4e8e\u300c\u5085\u91cc\u53f6\u7ea7\u6570\u7684\u6307\u6570\u5f62\u5f0f\uff0c\u53ef\u4ee5\u6e05\u695a\u5730\u5c55\u793a\u51fa\u5e45\u89d2\u548c\u6a21\u957f \u300d\u7684\u89e3\u91ca\uff1a</p> <p>\u8fd9\u91cc\u7528\u7684\u662f\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u4e86\u3002</p> <p>\ud83d\udce2 \u6ce8\u610f\u533a\u522b\uff1a</p> <ul> <li>\u5085\u91cc\u53f6\u7ea7\u6570\u662f\u5c55\u5f00\u5468\u671f\u51fd\u6570</li> <li>\u5085\u91cc\u53f6\u53d8\u6362\u662f\u5bf9\u4e8e\u975e\u5468\u671f\u51fd\u6570</li> </ul> <p>\u590d\u5e73\u9762\u4e0e \\(e^x\\) \uff0c\u8fd9\u4e00\u6b65\u7684\u8f6c\u6362\uff0c\u5176\u5b9e\u662f\u4ece \\((cos\\theta,sin\\theta)\\) \u76f4\u63a5\u7528\u4e86 \\(e^{i\\theta}\\) \u8868\u793a</p> <p></p> <p>\u7c7b\u4f3c\u7684\uff0c\u590d\u5e73\u9762\u5750\u6807\u70b9\uff0c\u5168\u90e8\u7528\u6307\u6570\u8868\u793a</p> <p>  $$ e^{i\\theta} = cos\\theta + isin\\theta $$ \u5177\u4f53\u6765\u8bf4\uff1a</p> <ul> <li>\\(1 = e^{i2\\pi} = cos2\\pi + isin2\\pi = 1\\)</li> <li>\\(i = e^{i\\frac{\\pi}{2}} = cos\\frac{\\pi}{2} + isin\\frac{\\pi}{2} = i\\)</li> <li>\\(-1 = e^{i\\pi} = cos\\pi + isin \\pi = -1\\)</li> <li>\\(-i = e^{i\\frac{3\\pi}{2}} = cos\\frac{3\\pi}{2} + isin\\frac{3\\pi}{2} = -i\\)</li> </ul> <p>\u63a5\u4e0b\u6765\uff0c\u5bf9 1 \u8fdb\u884c\u5206\u89e3\uff0c\u5177\u4f53\u6765\u8bf4\uff1a</p> <ul> <li>\\(x^2=1\\)</li> <li>\\(x^3=1\\)</li> <li>\\(x^4=1\\)</li> <li>\\(x^5=1\\)</li> </ul> <p>\u56e0\u4e3a\u8ba8\u8bba\u7684\u662f\u4e09\u89d2\u51fd\u6570\uff0c\u6240\u4ee5\u7528 \\(\\omega\\) </p> <p>\u8fd9\u91cc\u5176\u5b9e\uff0c\u6211\u89c9\u5f97\u5e94\u8be5\u8fd9\u4e48\u89e3\u91ca</p> <ul> <li>\\(\\omega^2 = 1 ===&gt;\\)   \u8f6c1\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\)</li> <li>\\(\\omega^3 = 1 ===&gt;\\) \u8f6c3\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1 ===&gt;\\)  \u5f97\u5230\u5bf9\u5e94\u7684\u89d2\uff0c\u8fdb\u884c\u76f8\u5e94\u7684\u590d\u6570\u8868\u793a\uff0c\u6bd4\u5982\u8fd9\u91cc \\(\\omega=120\u00b0\\) \uff0c\\(x\\) \u8f74\u6b63\u65b9\u5411\u5f00\u59cb\u627e\u70b9\uff0c120\u00b0\u6807\u4e00\u4e2a\uff0c\u518d\u4e00\u4e2a120\u00b0\uff0c\u518d\u6807\u4e00\u4e2a\u3002\uff08\u6a21\u957f=1\uff0c\u89d2\u5ea6\uff1d120\u00b0\uff09</li> <li>\\(\\omega^4 = 1 ===&gt;\\) \u8f6c4\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\)</li> <li>\\(\\omega^5 = 1 ===&gt;\\) \u8f6c5\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\)</li> <li>\\(\\omega^6 = 1 ===&gt;\\) \u8f6c6\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\)</li> <li>......</li> <li>\\(\\omega^n = 1 ===&gt;\\) \u8f6cn\u4e2a \\(\\omega\\) \u8f6c\u4e00\u5708 \\(=1\\) </li> </ul> <p>\u5355\u4f4d\u6839 </p> <p></p> <ul> <li>\\(\\omega = 120\u00b0\\) \u662f\u89d2\uff0c\u4e5f\u662f\u590d\u6570\u8868\u793a\uff0c\u4e5f\u662f \u6307\u6570</li> <li>\u590d\u6570\uff1a \\(\\omega = -\\frac{1}{2} + i \\sqrt{\\frac{3}{2}}\\)</li> <li>\u203b \u6307\u6570\uff1a\\(\\omega = e^{i\\frac{2\\pi k}{N}}\\) \u8fd9\u91cc\u5212\u5206\u6210 3 \u4e2a\uff0c\u4e5f\u5c31\u662f 3 \u4e2a\u6837\u672c\u70b9\uff0c\u6240\u4ee5 \\(N=3\\)\uff0c\u8fd9\u662f\u7b2c\u4e00\u6b21\u65cb\u8f6c\uff0c\u6240\u4ee5\uff0c\\(k=1\\) \u6240\u4ee5\u6307\u6570\u8868\u793a \\(\\omega = e^{i \\frac{2 \\pi}{3}}\\)</li> </ul> <p>\u57fa\u4e8e\u4ee5\u4e0a\u8ba4\u8bc6\uff0c\u91cd\u65b0\u770b DFT</p> <p></p> <p>\u7b26\u53f7\u8bf4\u660e</p> <ul> <li> <p>DFT \u7684\u7ed3\u679c \\(X_k\\)</p> </li> <li> <p>\\(x_n\\) \uff1a \u6211\u4eec\u6b63\u5728\u65cb\u8f6c\u7684\u6746\u7684\u957f\u5ea6</p> </li> <li> <p>\\(e^{-i(2\\pi\\frac{k}{N}n)}\\) \uff1a \u8fd9\u4e2a\u6307\u6570\uff0c\u5c31\u8868\u793a\u4e86\u65cb\u8f6c\u89d2\u5ea6\uff0c\u8868\u793a\u7684\u662f\u5355\u4f4d\u6839\u7684\u65cb\u8f6c\u89d2\u5ea6\uff0c\u56e0\u4e3a\u4e58\u4ee5\u4e86 \\(x_n\\) \u6240\u4ee5\u6709\u957f\u5ea6</p> </li> </ul> <p>\u5176\u4e2d\uff0c\\(e^{-i}\\) \u8868\u793a\u987a\u65f6\u9488\u65cb\u8f6c</p> <p>\\(2\\pi \\frac{k}{N}n\\) \u8868\u793a\u65f6\u95f4\u5e8f\u5217\u7684 \\(n\\) \u70b9\u4e0e\u9891\u7387 \\(\\frac{k}{N}\\) \u7684\u76f8\u5173\u6027</p> <p>\u590d\u6307\u6570\u9879\uff0c\u88ab\u79f0\u4e3a \u65cb\u8f6c\u56e0\u5b50\u6216\u5355\u4f4d\u65cb\u8f6c\u77e2\u91cf</p> <ul> <li> \u5ffd\u7136\u5f88\u597d\u5947\uff0c\u89d2\u9891\u7387 \\(\\omega\\) \u5230\u5e95\u662f\u4ec0\u4e48\u3002</li> </ul> <ul> <li>\\(\\sum_{n=0}^{N-1}\\) : \u6c42\u548c\u8868\u793a \u6240\u6709\u6746\u7684\u4e32\u8054</li> </ul> <p></p>"},{"location":"Statistics/1_FFT/#_3","title":"\u7269\u7406\u610f\u4e49","text":"<p>\u57fa\u4e8e\u4ee5\u4e0a\u7406\u89e3\uff0c\u6269\u5145\u4e00\u4e9b\u66f4\u7ec6\u81f4\u7684\u7406\u89e3</p> <p></p> <p>cos \u5f62\u5f0f \u53ef\u4ee5\u53ea\u7528 \u6b63\u5f26\u51fd\u6570 \u6216\u8005\u4f59\u5f26\u51fd\u6570</p> <p> </p> <p> </p> <p>\u6307\u6570\u5f62\u5f0f</p> <p>\u6307\u6570\u5f62\u5f0f  \u6307\u6570\u5f62\u5f0f\u4e5f\u8bc1\u660e\u8fc7\u4e86</p> <p></p> <p>\u7cfb\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\uff1a </p> <p></p> <p></p> <p>\u4ee3\u5165\u6765\u4ee3\u5165\u53bb\u53ef\u5f97\uff0c\uff08\u4ee5 $a_n $ \u548c \\(b_n\\) \u4e3a\u57fa\u51c6\uff09\uff1a</p> <p></p>"},{"location":"Statistics/1_FFT/#_4","title":"\u4ece\u5085\u91cc\u53f6\u7ea7\u6570 \u2192\u5085\u91cc\u53f6\u53d8\u6362","text":"<ul> <li>\u5085\u91cc\u53f6\u7ea7\u6570\u662f\u5bf9\u5468\u671f\u4e3aT\u7684\u786e\u5b9a\u6027\u4fe1\u53f7\u505a\u5c55\u5f00\uff0c\u800c\u5085\u91cc\u53f6\u53d8\u6362\u5c06\u5468\u671f\u63a8\u5e7f\u5230\u65e0\u7a77\uff0c\u80fd\u5bf9\u5177\u6709\u4efb\u610f\u957f\u5ea6\u7684\u4fe1\u53f7\u505a\u5c55\u5f00</li> <li>\u8fde\u7eed\u5468\u671f\u4fe1\u53f7 ---&gt; \u5085\u91cc\u53f6\u7ea7\u6570\uff1b\u8fde\u7eed\u975e\u5468\u671f\u4fe1\u53f7 ---&gt; \u5085\u91cc\u53f6\u53d8\u6362\u3002</li> </ul> <p>\u6700\u6700\u6838\u5fc3\u7684\uff1a </p> <p></p>"},{"location":"Statistics/1_FFT/#add","title":"Add","text":"<p>\u6700\u5e38\u7528\u7684\u5085\u91cc\u53f6\u7ea7\u6570\u5f62\u5f0f\uff1a</p> <p></p> <p> </p> <p> </p> <p> </p> <p></p>"},{"location":"Statistics/1_FFT/#_5","title":"\u5085\u91cc\u53f6\u7ea7\u6570\u63a8\u5bfc","text":"<p>\u4ece\u65e0\u5230\u6709</p> <p> </p> <p></p> <p>\u57fa\u9891&amp;\u8c10\u6ce2 </p> <p></p> <p> </p> <p> </p> <p> </p> <p>\u7531\u4e09\u89d2\u51fd\u6570\u63a8\u5bfc\u6307\u6570\u5f62\u5f0f\uff1a</p> <p>\u518d\u770b\u4e00\u904d\u4e09\u89d2\u51fd\u6570\uff1a</p> <p> </p> <p>\u6b27\u62c9\u516c\u5f0f</p> <p> </p> <p> </p> <p></p> <p></p> <p>\u5168\u90e8\u6563\u5f00\u7684 \u6307\u6570\u578b \u5085\u91cc\u53f6\u7ea7\u6570 </p> <p> </p> <p>reference</p> <p>\u5085\u91cc\u53f6\u7ea7\u6570\u516c\u5f0f\u63a8\u5bfc</p> <p>\u6570\u503c\u5206\u6790-\u6700\u4f73\u4e09\u89d2\u903c\u8fd1&amp;Fourier\u53d8\u6362&amp;\u4e09\u89d2\u63d2\u503c</p> <p>(\u5f88\u591a\u6f02\u4eae\u7684\u56fe)\u5982\u4f55\u7406\u89e3\u5085\u7acb\u53f6\u7ea7\u6570\u516c\u5f0f\uff1f</p> <p>\u5085\u91cc\u53f6\u7cfb\u5217\uff08\u4e00\uff09\u5085\u91cc\u53f6\u7ea7\u6570\u7684\u63a8\u5bfc</p> <p>https://www.tup.com.cn/upload/books/yz/079859-01.pdf</p> <p>\u7eaf\u5e72\u8d27\u6570\u5b66\u63a8\u5bfc \u5085\u91cc\u53f6\u7ea7\u6570\u4e0e\u5085\u91cc\u53f6\u53d8\u6362 Part5_\u4ece\u5085\u91cc\u53f6\u7ea7\u6570\u63a8\u5bfc\u5085\u91cc\u53f6\u53d8\u6362</p>"},{"location":"Statistics/2_FFT/","title":"Fourier\u57fa\u7840\u77e5\u8bc6","text":""},{"location":"Statistics/2_FFT/#fourier","title":"Fourier\u57fa\u7840\u77e5\u8bc6","text":"2025-03-23 22:58:122025-09-28 12:54:03 <p> \u7ea6 2439 \u4e2a\u5b57  6 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 12 \u5206\u949f</p> <ul> <li>Fourier\u57fa\u7840\u77e5\u8bc6<ul> <li>K1\uff1a\u57fa\u9891\u548c\u8c10\u6ce2</li> <li>K2\uff1a\u6b63\u4ea4\u57fa</li> <li>Q \u5468\u671f\u4e3a\u4ec0\u4e48\u662f \\(2\\pi\\)</li> <li>Q \u9ad8\u9891\u548c\u4f4e\u9891\u3001\u6ce2\u5f62\u53d8\u6362\u3001\u632f\u8361</li> <li>Q \u4e09\u89d2\u51fd\u6570\u57fa\u7840</li> <li>K3 \u5085\u91cc\u53f6\u7ea7\u6570 &amp; \u5085\u91cc\u53f6\u53d8\u6362</li> <li>Q Re &amp; Im</li> <li>K4 \u590d\u6570</li> <li>K5 \u76f4\u89d2\u5750\u6807\u7cfb\u3001\u590d\u5e73\u9762\u3001\u6781\u5750\u6807</li> <li>K6\u6b27\u62c9\u516c\u5f0f</li> <li>K7 \u4e09\u89d2\u51fd\u6570\u4e0e\u590d\u6307\u6570</li> </ul> </li> </ul>"},{"location":"Statistics/2_FFT/#k1","title":"K1\uff1a\u57fa\u9891\u548c\u8c10\u6ce2","text":"<ul> <li> <p>\u57fa\u9891\u662f\u9891\u7387\u6700\u4f4e\u7684\u5206\u91cf\uff0c\u57fa\u9891\u5bf9\u5e94\u7684\u5468\u671f\u662f\u6700\u957f\u7684</p> </li> <li> <p>\u8c10\u6ce2\u9891\u7387\u66f4\u9ad8\uff0c\u5468\u671f\u66f4\u77ed</p> </li> </ul> <p>1   \u57fa\u9891\u572812\u4e2a\u70b9\u4e2d\u5b8c\u62101\u4e2a\u5b8c\u6574\u5468\u671f   2   \u7b2c\u4e8c\u8c10\u6ce2\u572812\u4e2a\u70b9\u4e2d\u5b8c\u62102\u4e2a\u5b8c\u6574\u5468\u671f\uff0c\u6bcf\u4e2a\u5468\u671f6\u4e2a\u70b9   3   \u7b2c\u4e09\u8c10\u6ce2\u572812\u4e2a\u70b9\u4e2d\u5b8c\u62103\u4e2a\u5b8c\u6574\u5468\u671f\uff0c\u6bcf\u4e2a\u5468\u671f4\u4e2a\u70b9</p> <p>Fundamental Frequency (1/12): [0.0, 0.5, 0.87, 1.0, 0.87, 0.5, 0.0, -0.5, -0.87, -1.0, -0.87, -0.5] Second Harmonic (2/12): [0.0, 0.87, 0.87, 0.0, -0.87, -0.87, -0.0, 0.87, 0.87, 0.0, -0.87, -0.87] Third Harmonic (3/12): [0.0, 1.0, 0.0, -1.0, -0.0, 1.0, 0.0, -1.0, -0.0, 1.0, 0.0, -1.0]</p> <p></p>"},{"location":"Statistics/2_FFT/#k2","title":"K2\uff1a\u6b63\u4ea4\u57fa","text":"<p>\u6b63\u4ea4\u57fa\u7684\u7b2c\u4e00\u53e5\uff1a\u4efb\u4f55\u5411\u91cf\u90fd\u53ef\u4ee5\u552f\u4e00\u5730\u8868\u793a\u4e3a\u8fd9\u7ec4\u57fa\u5411\u91cf\u7684\u7ebf\u6027\u7ec4\u5408</p> <p>\u6b63\u4ea4\u57fa\u7684\u7b2c\u4e8c\u53e5\uff1a\u6b63\u4f59\u5f26\u51fd\u6570\u5728\u5176\u5468\u671f\u4e0a\u7684\u79ef\u5206</p> <p></p> <ul> <li> \u975e\u540c\u9891\u6b63\u4f59\u5f26\u4e09\u89d2\u51fd\u6570\u5728\u5468\u671f\u4e0a\u7684\u79ef\u5206\uff1a </li> </ul> \\[\\int_0^{2\\pi} \\sin(nx)\\sin(mx) dx = 0 \\quad \\text{\u5f53} n \\neq m\\] <p>\\(\\(\\int_0^{2\\pi} \\cos(nx)\\cos(mx) dx = 0 \\quad \\text{\u5f53} n \\neq m\\)\\) </p> \\[\\int_0^{2\\pi} \\sin(nx)\\cos(mx) dx = 0 \\quad \\text{\u5bf9\u6240\u6709} n, m\\] <ul> <li> \u540c\u9891\u6b63\u4f59\u5f26\u51fd\u6570\u5728\u5468\u671f\u4e0a\u7684\u79ef\u5206 </li> </ul> <p>\\(\\(\\int_0^{2\\pi} \\sin^2(nx) dx = \\pi, \\quad \\text{\u5f53 } n &gt; 0\\)\\) </p> \\[\\int_0^{2\\pi} \\cos^2(nx) dx = \\pi, \\quad \\text{\u5f53 } n &gt; 0\\] <p>\\(\\(\\int_0^{2\\pi} \\cos^2(0x) dx = \\int_0^{2\\pi} 1 dx = 2\\pi \\quad \\text{(\u5e38\u6570\u9879\u7279\u4f8b)}\\)\\)</p> <p>\u7ed3\u8bba\u4ee5\u53ca\u6587\u5b57\u6e38\u620f\uff1a</p> <p></p> <p> </p> <p>\u6b63\u4ea4\u57fa\u7684\u7b2c\u4e09\u53e5\uff1a\u5c06\u4efb\u4f55\u5468\u671f\u51fd\u6570\u5206\u89e3\u4e3a\u6b63\u5f26\u548c\u4f59\u5f26\u51fd\u6570\u7684\u548c \u27a1\ufe0f \u5085\u91cc\u53f6\u7ea7\u6570</p> \\[f(x) = a_0 + \\sum_{n=1}^{\\infty} [a_n \\cos(nx) + b_n \\sin(nx)]\\] \\[a_0 = \\frac{1}{2\\pi}\\int_0^{2\\pi} f(x) dx\\] \\[a_n = \\frac{1}{\\pi}\\int_0^{2\\pi} f(x)\\cos(nx) dx\\] \\[b_n = \\frac{1}{\\pi}\\int_0^{2\\pi} f(x)\\sin(nx) dx\\] <p>\u6b63\u4ea4\u57fa\u7b2c\u56db\u53e5\u7684\u524d\u63d0\uff1a\u5085\u91cc\u53f6\u7ea7\u6570\u9002\u7528\u4e8e\u5468\u671f\u51fd\u6570\u3002\u5bf9\u4e8e\u975e\u5468\u671f\u51fd\u6570\uff0c\u9700\u8981\u5085\u91cc\u53f6\u53d8\u6362</p> <ul> <li> <p> \u6b63\u4ea4\u57fa\u7b2c\u56db\u53e5\uff1a\u5085\u91cc\u53f6\u53d8\u6362</p> </li> <li> <p> \u5f53\u5468\u671f\u8d8b\u4e8e\u65e0\u7a77\u5927\u65f6\uff0c\u5085\u91cc\u53f6\u7ea7\u6570\u4e2d\u7684\u79bb\u6563\u9891\u7387\u53d8\u6210\u8fde\u7eed\u9891\u7387\uff0c\u6c42\u548c\u53d8\u6210\u79ef\u5206\uff0c\u5f97\u5230\u5085\u91cc\u53f6\u53d8\u6362</p> </li> </ul> \\[F(\\omega) = \\int_{-\\infty}^{\\infty} f(t)e^{-i\\omega t}dt\\] <p>\\(e^{-i\\omega t} = \\cos(\\omega t) - i\\sin(\\omega t)\\)</p> <ul> <li> \u6b63\u4ea4\u57fa\u7b2c\u4e94\u53e5\uff1aDFT &amp; FFT ||  \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u5316 &amp; \u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362</li> </ul> \\[X[k] = \\sum_{n=0}^{N-1} x[n]e^{-i2\\pi kn/N}\\] <ul> <li> \u6b63\u4ea4\u57fa \u7b2c\u4e8c\u53e5 &amp; \u7b2c\u4e09\u53e5 \u4e00\u8d77\u7406\u89e3 </li> </ul> \\[f(x) = a_0 + \\sum_{n=1}^{\\infty} [a_n \\cos(nx) + b_n \\sin(nx)]\\] <p>\\(a_0 = \\frac{1}{2\\pi}\\int_0^{2\\pi} f(x) dx\\)</p> <p>\\(a_n = \\frac{1}{\\pi}\\int_0^{2\\pi} f(x)\\cos(nx) dx\\)</p> <p>\\(b_n = \\frac{1}{\\pi}\\int_0^{2\\pi} f(x)\\sin(nx) dx\\)</p> <p>\\(\\int_0^{2\\pi} \\sin(nx)\\sin(mx) dx = \\pi\\delta_{nm}\\)</p> <p>\\(\\int_0^{2\\pi} \\cos(nx)\\cos(mx) dx = \\pi\\delta_{nm}\\)</p> <p>\\(\\int_0^{2\\pi} \\sin(nx)\\cos(mx) dx = 0\\)</p> <p>\u5176\u4e2d\\(\\delta_{nm}\\)\u662f\u514b\u7f57\u5185\u514b\u51fd\u6570\u3002</p>"},{"location":"Statistics/2_FFT/#q-2pi","title":"Q \u5468\u671f\u4e3a\u4ec0\u4e48\u662f \\(2\\pi\\)","text":"<p>\ud83c\udf3a \u5b83\u662f\u57fa\u672c\u6b63\u5f26\u51fd\u6570 \\(\\sin(x)\\) \u7684\u4e00\u4e2a\u5b8c\u6574\u5468\u671f </p> <p>\ud83c\udf3a \u5b83\u662f\u6240\u6709 \\(\\sin(nx)\\) \u51fd\u6570\u7684\u5468\u671f\u516c\u500d\u6570 </p> <p>\ud83c\udf3a \u5b83\u6784\u6210\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u6b63\u4ea4\u7cfb\u7edf </p> <p>\u89e3\u91ca\u5468\u671f\u516c\u500d\u6570\uff1a </p> <p>\u5bf9\u4e8e\u4efb\u610f\u6b63\u6574\u6570 \\(n\\)\uff0c\\(\\sin(nx)\\) \u7684\u5468\u671f\u662f \\(\\frac{2\\pi}{n}\\)\u3002\u5f53\u6211\u4eec\u53d6 \\([0,2\\pi]\\) \u4f5c\u4e3a\u79ef\u5206\u533a\u95f4\u65f6\uff1a</p> <ul> <li>\\(\\sin(1x)\\) \u5728\u6b64\u533a\u95f4\u5b8c\u6210 1 \u4e2a\u5b8c\u6574\u5468\u671f</li> <li>\\(\\sin(2x)\\) \u5728\u6b64\u533a\u95f4\u5b8c\u6210 2 \u4e2a\u5b8c\u6574\u5468\u671f</li> <li>\\(\\sin(3x)\\) \u5728\u6b64\u533a\u95f4\u5b8c\u6210 3 \u4e2a\u5b8c\u6574\u5468\u671f</li> </ul> <p>\u8fd9\u610f\u5473\u7740\uff0c\u5bf9\u4e8e\u4efb\u4f55\u6574\u6570 \\(n\\)\uff0c\\(\\sin(nx)\\) \u5728 \\([0,2\\pi]\\) \u533a\u95f4\u5185\u5305\u542b\u6574\u6570\u4e2a\u5b8c\u6574\u5468\u671f\u3002</p> <p>\u5bf9\u4e8e \\(sin(nx)\\) \u6765\u8bf4\uff0c \\(2\\pi\\)  \u662f\u57fa\u672c\u7684\u6700\u5927\u5468\u671f\u3002</p> <ul> <li> \u6b63\u4ea4\u6027\u7684\u6570\u5b66\u539f\u7406 </li> </ul> <p>\u5f53\u6211\u4eec\u8ba1\u7b97\u79ef\u5206 \\(\\int_0^{2\\pi} \\sin(nx)\\sin(mx) dx\\) \u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e09\u89d2\u6052\u7b49\u5f0f\uff1a</p> \\[\\sin(nx)\\sin(mx) = \\frac{1}{2}[\\cos((n-m)x) - \\cos((n+m)x)]\\] <p>\u6240\u4ee5\u79ef\u5206\u53d8\u4e3a\uff1a</p> \\[\\int_0^{2\\pi} \\sin(nx)\\sin(mx) dx = \\frac{1}{2}\\int_0^{2\\pi} [\\cos((n-m)x) - \\cos((n+m)x)] dx\\] <p>\u5bf9\u4e8e\u4efb\u4f55\u975e\u96f6\u6574\u6570 \\(k\\)\uff0c\\(\\int_0^{2\\pi} \\cos(kx) dx = 0\\)\uff08\u56e0\u4e3a\u4f59\u5f26\u51fd\u6570\u5728\u5b8c\u6574\u5468\u671f\u4e0a\u7684\u79ef\u5206\u4e3a\u96f6\uff09\u3002</p> <p>\u5f53 \\(n \\neq m\\) \u65f6\uff0c\\((n-m)\\) \u548c \\((n+m)\\) \u90fd\u662f\u975e\u96f6\u6574\u6570\uff0c\u6240\u4ee5\u4e24\u9879\u79ef\u5206\u90fd\u7b49\u4e8e\u96f6\uff0c\u6700\u7ec8\u7ed3\u679c\u662f\u96f6\u3002</p> <ul> <li> \u51fd\u6570\u7a7a\u95f4\u7684\u5b8c\u5907\u6027 </li> </ul> <p>\\([0,2\\pi]\\) \u533a\u95f4\u4e0a\u7684\u4e09\u89d2\u51fd\u6570\u7cfb\u7edf \\(\\{1, \\sin(x), \\sin(2x), ..., \\cos(x), \\cos(2x), ...\\}\\) \u6784\u6210\u4e86\u5e73\u65b9\u53ef\u79ef\u51fd\u6570\u7a7a\u95f4\u7684\u4e00\u4e2a\u5b8c\u5907\u6b63\u4ea4\u57fa\u3002\u8fd9\u610f\u5473\u7740\u4efb\u4f55\u5728\u6b64\u533a\u95f4\u4e0a\u7684\u5e73\u65b9\u53ef\u79ef\u51fd\u6570\u90fd\u53ef\u4ee5\u8868\u793a\u4e3a\u8fd9\u4e9b\u57fa\u51fd\u6570\u7684\u7ebf\u6027\u7ec4\u5408\u3002</p> <ul> <li> \u5b9e\u9645\u4f8b\u5b50\u8bf4\u660e </li> </ul> <p>\u8ba9\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5177\u4f53\u4f8b\u5b50\u6765\u7406\u89e3\uff1a\u8003\u8651 \\(\\sin(2x)\\) \u548c \\(\\sin(3x)\\)\u3002</p> <ul> <li>\\(\\sin(2x)\\) \u7684\u5468\u671f\u662f \\(\\pi\\)</li> <li>\\(\\sin(3x)\\) \u7684\u5468\u671f\u662f \\(\\frac{2\\pi}{3}\\)</li> </ul> <p>\u5982\u679c\u6211\u4eec\u53ea\u5728\u4e00\u4e2a\u51fd\u6570\u7684\u5468\u671f\u4e0a\u79ef\u5206\uff0c\u6bd4\u5982 \\([0,\\pi]\\)\uff0c\u53e6\u4e00\u4e2a\u51fd\u6570\u5728\u6b64\u533a\u95f4\u4e0d\u4f1a\u5b8c\u6210\u6574\u6570\u4e2a\u5468\u671f\uff0c\u6b63\u4ea4\u6027\u53ef\u80fd\u4e0d\u6210\u7acb\u3002\u4f46\u5728 \\([0,2\\pi]\\) \u4e0a\uff1a</p> <ul> <li>\\(\\sin(2x)\\) \u5b8c\u6210\u4e86 2 \u4e2a\u5b8c\u6574\u5468\u671f</li> <li>\\(\\sin(3x)\\) \u5b8c\u6210\u4e86 3 \u4e2a\u5b8c\u6574\u5468\u671f</li> </ul> <p>\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4e24\u4e2a\u51fd\u6570\u7684\u4e58\u79ef\u5728\u6b63\u8d1f\u533a\u57df\"\u6070\u597d\u5e73\u8861\"\uff0c\u4f7f\u79ef\u5206\u4e3a\u96f6\u3002</p> <ul> <li> \u603b\u7ed3 </li> </ul> <p>\\([0,2\\pi]\\) \u79ef\u5206\u533a\u95f4\u7684\u9009\u62e9\u4e0d\u662f\u57fa\u4e8e\u5355\u4e2a\u51fd\u6570\u7684\u5468\u671f\uff0c\u800c\u662f\u57fa\u4e8e\u5efa\u7acb\u4e00\u4e2a\u5b8c\u6574\u6b63\u4ea4\u7cfb\u7edf\u7684\u9700\u8981\u3002\u8fd9\u4e2a\u7279\u6b8a\u533a\u95f4\u786e\u4fdd\u4e86:</p> <ul> <li>\u6240\u6709 \\(\\sin(nx)\\) \u51fd\u6570\u5728\u6b64\u533a\u95f4\u4e0a\u5305\u542b\u6574\u6570\u4e2a\u5468\u671f</li> <li>\u4e0d\u540c\u9891\u7387\u7684\u6b63\u5f26\u51fd\u6570\u5728\u6b64\u533a\u95f4\u4e0a\u6b63\u4ea4</li> <li>\u4e09\u89d2\u51fd\u6570\u7cfb\u7edf\u5728\u6b64\u533a\u95f4\u4e0a\u6784\u6210\u5b8c\u5907\u6b63\u4ea4\u57fa</li> </ul>"},{"location":"Statistics/2_FFT/#q","title":"Q \u9ad8\u9891\u548c\u4f4e\u9891\u3001\u6ce2\u5f62\u53d8\u6362\u3001\u632f\u8361","text":"<p>\u5468\u671f\u957f\u7684\uff0c\u9891\u7387\u4f4e\uff1b\u5468\u671f\u77ed\u7684\uff0c\u9891\u7387\u9ad8\u3002</p> <p>\u2234 \u4f4e\u9891\u6ce2\uff0c\u5468\u671f\u957f\uff08\u4f4e\u9891\uff0c\u5c31\u662f f \u503c\u5c0f\uff0c\u5468\u671f\u957f\uff0c\u5c31\u662f T \u503c\u5927\uff09</p> <p>\u4f4e\u9891\u6ce2\uff0c\u5468\u671f\u957f\uff0c\u6ce2\u5f62\u53d8\u6362\u7f13\u6162\uff0c\u4e00\u6b21\u5b8c\u6574\u7684\u632f\u8361\u9700\u8981\u8f83\u957f\u7684\u65f6\u95f4\u3002</p>"},{"location":"Statistics/2_FFT/#q_1","title":"Q \u4e09\u89d2\u51fd\u6570\u57fa\u7840","text":"<p>\\(A \\sin(\\omega t+\\phi)\\)</p> <ul> <li>\\(A\\) \u632f\u5e45</li> <li>\\(\\omega\\)  \u89d2\u9891\u7387</li> <li>\\(\\phi\\) \u521d\u59cb\u76f8\u4f4d\uff0c\\(t=0\\) \u65f6\uff0c\u4e09\u89d2\u51fd\u6570\u6ce2\u7684\u4f4d\u7f6e</li> <li>\\(T = \\frac{1}{f}\\)\u3001\\(T=\\frac{2\\pi}{\\omega}\\) </li> <li>\u4ece\u4e09\u89d2\u51fd\u6570\u7684\u8868\u8fbe\u5f0f\u4e0a\uff0c \\(\\omega\\) \u4e0e\u9891\u7387\u6210\u6b63\u6bd4\uff0c\u53ef\u4ee5\u76f4\u63a5\u4e0b\u7ed3\u8bba\uff0c\\(\\omega\\) \u8d8a\u5927\uff0c\u8d8a\u9ad8\u9891\uff0c\u53ef\u4ee5\u975e\u5e38\u76f4\u89c2\u7684\u770b\u51fa\u6765</li> </ul> Text Only<pre><code>x = 1.0 * np.sin(2 * np.pi * 5 * t / N)   # 5Hz\u6210\u5206 - \u4e2d\u9891\nx += 0.5 * np.sin(2 * np.pi * 10 * t / N)  # 10Hz\u6210\u5206 - \u8f83\u9ad8\u9891\nx += 0.25 * np.sin(2 * np.pi * 20 * t / N) # 20Hz\u6210\u5206 - \u6700\u9ad8\u9891\n</code></pre>"},{"location":"Statistics/2_FFT/#k3","title":"K3 \u5085\u91cc\u53f6\u7ea7\u6570 &amp; \u5085\u91cc\u53f6\u53d8\u6362","text":"<ul> <li> \u95ee\u9898\uff1a\\(\\(F(\\omega) = \\int_{-\\infty}^{\\infty} f(t)e^{-i\\omega t}dt\\)\\)</li> </ul> <p>\u6982\u5ff5\u4e0a\u7684\u8f6c\u53d8\uff1a\u4ece\u79bb\u6563\u5085\u91cc\u53f6\u7ea7\u6570\u5230\u8fde\u7eed\u5085\u91cc\u53f6\u53d8\u6362</p> <p>\u8981\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5c31\u5f97\u77e5\u9053 \ud83d\udfe9  \u8865\u5145\uff1a\u5085\u91cc\u53f6\u7ea7\u6570</p> <p>\ud83c\udf3a \u4e09\u89d2\u5f62\u5f0f\u7684\u5085\u91cc\u53f6\u7ea7\u6570\uff1a \\(\\(f(x) = a_0 + \\sum_{n=1}^{\\infty} [a_n \\cos(nx) + b_n \\sin(nx)]\\)\\)</p> <p>\ud83c\udf3a \u590d\u6307\u6570\u5f62\u5f0f\u7684\u5085\u91cc\u53f6\u7ea7\u6570\uff1a  \\(\\(f(t) = \\sum_{n=-\\infty}^{\\infty} c_n e^{i\\omega_0 nt}\\)\\)</p> <ul> <li> \u7b49\u4ef7\u6027\u7684\u8bc1\u660e\u3002</li> </ul> <p>\ud83d\udfe6 \u4e09\u89d2\u5f62\u5f0f\u7684\u5085\u91cc\u53f6\u7ea7\u6570\uff1a </p> \\[f(x) = a_0 + \\sum_{n=1}^{\\infty} [a_n \\cos(nx) + b_n \\sin(nx)]\\] <p>\ud83d\udfe6 \u590d\u6307\u6570\u5f62\u5f0f\u7684\u5085\u91cc\u53f6\u7ea7\u6570\uff1a</p> <p>\u5bf9\u4e8e\u5468\u671f\u4e3a \\(T\\) \u7684\u51fd\u6570 \\(f(t)\\)\uff0c\u5176\u5085\u91cc\u53f6\u7ea7\u6570\u8868\u793a\u4e3a\uff1a</p> \\[f(t) = \\sum_{n=-\\infty}^{\\infty} c_n e^{i\\omega_0 nt}\\] <p>\u5176\u4e2d \\(\\omega_0 = \\frac{2\\pi}{T}\\) \u662f\u57fa\u9891\uff0c\u7cfb\u6570 \\(c_n\\) \u7531\u4ee5\u4e0b\u516c\u5f0f\u7ed9\u51fa\uff1a</p> \\[c_n = \\frac{1}{T} \\int_{-T/2}^{T/2} f(t) e^{-i\\omega_0 nt} dt\\] <p>\u8fd9\u91cc\u6bcf\u4e2a\u9891\u7387\u5206\u91cf\u662f \\(\\omega_n = n\\omega_0\\)\uff0c\u662f\u57fa\u9891 \\(\\omega_0\\) \u7684\u6574\u6570\u500d\uff0c\u6240\u4ee5\u662f\u79bb\u6563\u7684\u9891\u7387\u503c\u3002</p> <p>\ud83d\udfea \u8981\u8bc1\u660e\u7b49\u4ef7\uff0c\u6b27\u62c9\u516c\u5f0f\u7262\u8bb0\u4e8e\u5fc3\uff1a\\(e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta)\\)</p>"},{"location":"Statistics/2_FFT/#q-re-im","title":"Q  Re &amp; Im","text":"<ul> <li>Re - \u6765\u81ea\u62c9\u4e01\u8bed \"**Re**alis Pars\"\uff0c\u610f\u4e3a\"\u5b9e\u9645\u90e8\u5206\"</li> <li>Im - \u6765\u81ea\u62c9\u4e01\u8bed \"**Im**aginaria Pars\"\uff0c\u610f\u4e3a\"\u865a\u6784\u90e8\u5206\"</li> </ul> <p>**eg\uff1a**\u4ee5\u590d\u6570 \\(z = a + bi\\) \u4e3a\u4f8b\uff1a</p> <ul> <li>\u5b9e\u90e8\uff1a\\(\\text{Re}[z] = a\\)</li> <li>\u865a\u90e8\uff1a\\(\\text{Im}[z] = b\\)</li> </ul> <p>eg\uff1a\u5728\u5085\u91cc\u53f6\u5206\u6790\u4e2d\u7684\u5e94\u7528</p> <p>\u5728\u5085\u91cc\u53f6\u5206\u6790\u4e2d\uff0c\u590d\u7cfb\u6570 \\(c_n\\) \u5305\u542b\u4e86\u4fe1\u53f7\u7684\u4e24\u7c7b\u4fe1\u606f\uff1a</p> <ul> <li>\\(\\text{Re}[c_n]\\) (\u5b9e\u90e8) - \u4e0e\u4f59\u5f26\u5206\u91cf\u76f8\u5173\uff0c\u8868\u793a\u4fe1\u53f7\u7684\"\u5076\u5bf9\u79f0\"\u90e8\u5206</li> <li>\\(\\text{Im}[c_n]\\) (\u865a\u90e8) - \u4e0e\u6b63\u5f26\u5206\u91cf\u76f8\u5173\uff0c\u8868\u793a\u4fe1\u53f7\u7684\"\u5947\u5bf9\u79f0\"\u90e8\u5206</li> </ul> <p>\u5f53\u6211\u4eec\u5c06\u590d\u6307\u6570\u5f62\u5f0f\u8f6c\u6362\u4e3a\u4e09\u89d2\u5f62\u5f0f\u65f6\uff0c\u8fd9\u79cd\u5206\u89e3\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\uff1a</p> <ul> <li>\u4f59\u5f26\u7cfb\u6570 \\(a_n = 2\\text{Re}[c_n]\\)</li> <li>\u6b63\u5f26\u7cfb\u6570 \\(b_n = -2\\text{Im}[c_n]\\)</li> </ul> <p>eg\uff1a\u4ece\u51e0\u4f55\u89d2\u5ea6\u7406\u89e3\u5b9e\u90e8\u548c\u865a\u90e8\uff1a</p> <ul> <li>\u5b9e\u90e8 (Re): \u590d\u6570\u5728\u5b9e\u8f74\u4e0a\u7684\u6295\u5f71</li> </ul> <p>\uff081\uff09\u8868\u793a\"\u6c34\u5e73\"\u5206\u91cf</p> <p>\uff082\uff09\u4e0e\u4f59\u5f26\u51fd\u6570\u76f8\u5173\u8054\uff08\u4f59\u5f26\u57280\u5904\u53d6\u6700\u5927\u503c\uff09</p> <ul> <li>\u865a\u90e8 (Im): \u590d\u6570\u5728\u865a\u8f74\u4e0a\u7684\u6295\u5f71</li> </ul> <p>\uff081\uff09\u8868\u793a\"\u5782\u76f4\"\u5206\u91cf</p> <p>\uff082\uff09\u4e0e\u6b63\u5f26\u51fd\u6570\u76f8\u5173\u8054\uff08\u6b63\u5f26\u57280\u5904\u53d6\u503c\u4e3a0\uff09</p>"},{"location":"Statistics/2_FFT/#k4","title":"K4 \u590d\u6570","text":"<p>\u590d\u6570\u7684\u6a21\u548c\u76f8\u89d2 \u3001\u590d\u5e73\u9762\u3001\u6781\u5750\u6807\u7cfb</p> <ul> <li> <p> \u5bf9\u4e8e\u4efb\u610f\u590d\u6570 \\(c = a + bi\\)\uff1a</p> </li> <li> <p>\u6a21 \\(|c| = \\sqrt{a^2 + b^2}\\)\uff1a\u8868\u793a\u590d\u6570\u5728\u590d\u5e73\u9762\u4e0a\u8ddd\u79bb\u539f\u70b9\u7684\u8ddd\u79bb</p> </li> <li> <p>\u76f8\u89d2 \\(\\theta = \\tan^{-1}(b/a)\\)\uff1a\u8868\u793a\u590d\u6570\u5728\u590d\u5e73\u9762\u4e0a\u4e0e\u6b63\u5b9e\u8f74\u7684\u5939\u89d2</p> </li> <li> <p> \uff08\u5b8c\u6574\u8868\u8fbe\u4fe1\u606f\uff09\u590d\u6570\u80fd\u540c\u65f6\u7f16\u7801\u4e24\u7c7b\u4fe1\u606f\uff1a</p> </li> <li> <p>\u5e45\u5ea6\u4fe1\u606f\uff1a\u901a\u8fc7 \\(|c_n|\\)\uff08\u590d\u6570\u7684\u6a21\uff09</p> </li> <li>\u76f8\u4f4d\u4fe1\u606f\uff1a\u901a\u8fc7 \\(\\arg(c_n)\\)\uff08\u590d\u6570\u7684\u8f90\u89d2\uff09</li> </ul> <p>\u8fd9\u4f7f\u5f97\u4e00\u4e2a\u590d\u6570 \\(c_n\\) \u53ef\u4ee5\u5b8c\u6574\u63cf\u8ff0\u4fe1\u53f7\u4e2d\u9891\u7387\u4e3a \\(n\\omega_0\\) \u7684\u5206\u91cf\u7684\u5e45\u5ea6\u548c\u76f8\u4f4d\u3002</p> <ul> <li> <p> \u590d\u6570\u53ef\u4ee5\u7528\u6781\u5750\u6807\u5f62\u5f0f\u8868\u793a\uff1a\\(c = |c|e^{i\\theta}\\) \uff08\u8f6c\u4e86\u591a\u5c11\u5ea6\uff0c\u591a\u957f\u3002\uff09</p> </li> <li> <p> \u590d\u5e73\u53f0\u8868\u793a\uff1a</p> </li> </ul> <p>\u4efb\u4f55\u590d\u6570 \\(c = a + bi\\) \u90fd\u53ef\u4ee5\u5728\u590d\u5e73\u9762\u4e0a\u8868\u793a\u4e3a\u4e00\u4e2a\u70b9 \\((a, b)\\)\uff1a</p> <ul> <li>\\(a\\) \u662f\u5b9e\u90e8\uff0c\u5bf9\u5e94\u6a2a\u5750\u6807\uff08\u5b9e\u8f74\uff09</li> <li>\\(b\\) \u662f\u865a\u90e8\uff0c\u5bf9\u5e94\u7eb5\u5750\u6807\uff08\u865a\u8f74\uff09</li> </ul> <p>\u5982\u56fe\u6240\u793a\uff1a\u590d\u5e73\u9762\u4e0a\u7684\u76f8\u89d2\u8868\u793a</p> <p></p> <p>\u521d\u59cb\u76f8\u4f4d\u3001\u632f\u5e45\u3001\u9891\u7387</p> <p></p>"},{"location":"Statistics/2_FFT/#k5","title":"K5 \u76f4\u89d2\u5750\u6807\u7cfb\u3001\u590d\u5e73\u9762\u3001\u6781\u5750\u6807","text":"<p>\u76f4\u89d2\u5750\u6807\u4e0e\u6781\u5750\u6807\u7684\u5173\u7cfb</p> <p>\u590d\u5e73\u9762\u4e0a\u7684\u70b9\u53ef\u4ee5\u7528\u4e24\u79cd\u65b9\u5f0f\u8868\u793a\uff1a</p> <ol> <li>\u76f4\u89d2\u5750\u6807 \\((a, b)\\)\uff1a\u901a\u8fc7\u5b9e\u90e8\u548c\u865a\u90e8\u5b9a\u4e49\u70b9\u7684\u4f4d\u7f6e</li> <li>\u6781\u5750\u6807 \\((r, \\theta)\\)\uff1a\u901a\u8fc7\u5230\u539f\u70b9\u7684\u8ddd\u79bb(\u6a21)\u548c\u4e0e\u6b63\u5b9e\u8f74\u7684\u5939\u89d2(\u76f8\u89d2)\u5b9a\u4e49\u70b9\u7684\u4f4d\u7f6e</li> </ol> <p>\u8fd9\u4e24\u79cd\u8868\u793a\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\uff1a</p> <ul> <li>\\(a = r\\cos\\theta\\)</li> <li>\\(b = r\\sin\\theta\\)</li> </ul> <p>\u53cd\u8fc7\u6765\uff1a</p> <ul> <li>\\(r = \\sqrt{a^2 + b^2}\\)</li> <li>\\(\\theta = \\tan^{-1}(b/a)\\)\uff08\u5f53 \\(a &gt; 0\\) \u65f6\uff09</li> </ul>"},{"location":"Statistics/2_FFT/#k6","title":"K6\u6b27\u62c9\u516c\u5f0f","text":"<p>\\(e^{ix} = cosx+isinx\\)</p>"},{"location":"Statistics/2_FFT/#k7","title":"K7 \u4e09\u89d2\u51fd\u6570\u4e0e\u590d\u6307\u6570","text":"\\[cosx = \\frac{e^{ix}+e^{-ix}}{2}\\] \\[ isinx = \\frac{e^{ix}- e^{-ix}}{2}\\]"},{"location":"bagu/","title":"\u9762\u8bd5","text":""},{"location":"bagu/#_1","title":"\u9762\u8bd5","text":"2024-11-15 19:19:112025-09-28 12:54:04 <p> \u7ea6 35 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>Abstract</p> <p>\u627e\u5de5\u4f5c\u627e\u5de5\u4f5c\uff0c\u8111\u5b50\u771f\u662f\u4e2a\u597d\u4e1c\u897f</p> \u673a\u5668\u5b66\u4e60\u9762\u8bd5 \u67e5\u770b PyTorch\u9762\u8bd5 \u67e5\u770b Transformer\u9762\u8bd5 \u67e5\u770b"},{"location":"bagu/deeplearning/","title":"Index","text":"2024-11-15 19:19:112025-09-28 12:54:04 <p> \u7ea6 2 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <ul> <li> Batchnorm &amp; layernorm</li> </ul>"},{"location":"bagu/deeplearning/1/","title":"visionTransformer\u4ee3\u7801","text":""},{"location":"bagu/deeplearning/1/#visiontransformer","title":"visionTransformer\u4ee3\u7801","text":"2024-11-25 22:33:462025-09-28 12:54:04 <p> \u7ea6 30 \u4e2a\u5b57  197 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p>"},{"location":"bagu/deeplearning/1/#1-patch","title":"1 patch\u7684\u6784\u5efa","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# step1 convert image to embedding vector sequence\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    patch_embedding = patch @ weight\n    return patch_embedding\ndef image2emb_conv(image,kernel,stride):\n    conv_output = F.conv2d(image,kernel,stride=stride) # bs*oc*oh*ow\n    bs,oc,oh,ow = conv_output.shape\n    patch_embedding = conv_output.reshape((bs,oc,oh*ow)).transpose(-1,-2)\n\n    return patch_embedding\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim) # model_dim\u662f\u8f93\u51fa\u901a\u9053\u6570\u76ee\uff0cpatch depth\u662f\u5377\u79ef\u6838\u7684\u9762\u79ef\u4e58\u4ee5\u8f93\u5165\u901a\u9053\u6570\n\n# \u5206\u5757\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)\nkernel = weight.transpose(0,1).reshape((-1,ic,patch_size,patch_size))\n\n# \u4e8c\u7ef4\u5377\u79ef\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_conv = image2emb_conv(image,kernel,patch_size)\n\n\nprint(patch_embedding_naive)\nprint(patch_embedding_conv)\n</code></pre> <p>\u6ce8\u91ca\uff1a</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# step1 convert image to embedding vector sequence\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width = 1,3,8,8\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    # patchshape = torch.Size([1, 48, 4])   patch_size = 4\n    # 1\uff1abatchsize\n    # 48 = 3*4*4\uff08\u5377\u79ef\u8986\u76d6\u7684input region\uff09\n    # 4\uff1a1,3,8,8\u7684\u8f93\u5165\u56fe\u7247\u7528 1344\u7684\u5377\u79ef\u6838\u5377\u79ef\uff0c\u5f97\u52304\u4e2ainput region\n    # transpose(-1,-2) \u2192 1,4,48  \n    patch_embedding = patch @ weight\n    # 1,4,48 @ 48,8 = 1\u00d7 4 \u00d7 8\n    return patch_embedding\n\ndef image2emb_conv(image,kernel,stride):\n    # image = bs,ic,image_h,image_w = 1,3,8,8 \n    # kernel = 8 \u00d7 3 \u00d7 4 \u00d7 4\n    # stride = patch_size = 4 \n    conv_output = F.conv2d(image,kernel,stride=stride) # bs*oc*oh*ow\n    # (h-k+2p+s)/s = (8-4+4)/4  = 2\n    # conv_output = 8 \u00d7 1 \u00d7 2 \u00d7 2\n    bs,oc,oh,ow = conv_output.shape\n    patch_embedding = conv_output.reshape((bs,oc,oh*ow)).transpose(-1,-2)\n    # conv_output = 1 \u00d7 8 \u00d7 2 \u00d7 2\n    # reshape \uff1a 1 \u00d7 8 \u00d7 4\n    # transpose(-1,-2)  1 \u00d7 4 \u00d7 8\n    #\uff08\u8f93\u5165\u56fe\u7247 \u5212\u5206\u6210 4\u4e2apatch\uff0c\u6bcf\u4e2apatch\u7531\u539f\u6765\u7684 48\u4e2a\u50cf\u7d20\u8868\u793a\uff0c\u964d\u7ef4\u62108\u7ef4\u8868\u793a\uff09\n    return patch_embedding\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim) # model_dim\u662f\u8f93\u51fa\u901a\u9053\u6570\u76ee\uff0cpatch depth\u662f\u5377\u79ef\u6838\u7684\u9762\u79ef\u4e58\u4ee5\u8f93\u5165\u901a\u9053\u6570\n\n# \u5206\u5757\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)\n\n# conv\u7248\u672c\uff1a\nkernel = weight.transpose(0,1).reshape((-1,ic,patch_size,patch_size))\n# weight = 48 \u00d7 8\n# transpose(0,1) : 8 \u00d7 48\n# reshape :8 \u00d7 3 \u00d7 4 \u00d7 4\n\n# \u4e8c\u7ef4\u5377\u79ef\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_conv = image2emb_conv(image,kernel,patch_size)\n# image = bs,ic,image_h,image_w = 1,3,8,8 \n# kernel = 8 \u00d7 3 \u00d7 4 \u00d7 4\n# patch_size = 4\n\nprint(patch_embedding_naive)\nprint(patch_embedding_conv)\n</code></pre>"},{"location":"bagu/deeplearning/1/#2-cls-token-embedding","title":"2 CLS token embedding","text":"Python<pre><code># step2 prepend CLS token embedding\n# patch_embedding_conv = 1 \u00d7 4 \u00d7 8\n# cls_token_embedding = 1 \u00d7 1 \u00d7 8\n\ncls_token_embedding = torch.randn(bs,1,model_dim,requires_grad=True)\n# token_embedding\n# \u7b2c\u4e00\u4e2a\u4f4d\u7f6e \u662f cls token\uff0ccls token\u7684\u5d4c\u5165\u7ef4\u5ea6\u662f 8\n# \u6240\u4ee5 dim = 1\ntoken_embedding = torch.cat([cls_token_embedding,patch_embedding_conv],dim=1)\n</code></pre>"},{"location":"bagu/deeplearning/1/#3-position-embedding","title":"3 Position embedding","text":"Python<pre><code># step3 add position embedding\npositon_embedding_table = torch.randn(max_num_token,model_dim,requires_grad=True)\nseq_len = token_embedding.shape[1]\npositon_embedding = torch.tile(positon_embedding_table[:seq_len],[token_embedding.shape[0],1,1])\ntoken_embedding += positon_embedding\n</code></pre> <p>\u6ce8\u91ca\uff1a</p> Python<pre><code># step3 add position embedding\n# max_num_token = 16\n# model_dim = 8\n# positon_embedding_table = 16,8\npositon_embedding_table = torch.randn(max_num_token,model_dim,requires_grad=True)\n\n# token_embedding = 1,5,8 (bs,5\u4e2a\u4f4d\u7f6e(1\u4e2acls token\u30014\u4e2a\u5355\u8bcd),model_dim = 8)\n# seq_len = 5\nseq_len = token_embedding.shape[1]\n\npositon_embedding = torch.tile(positon_embedding_table[:seq_len],[token_embedding.shape[0],1,1])\n# positon_embedding_table[:seq_len] = positon_embedding_table[:5] \u53d6\u524d5\u4e2a8\u7ef4\n# [:5] \u8868\u793a \u5bf9 \u7b2c\u4e00\u7ef4 \u7d22\u5f15\n# positon_embedding_table[:seq_len] = 5,8\n# [token_embedding.shape[0],1,1] = [1,1,1]\n# positon_embedding = 1,5,8\ntoken_embedding += positon_embedding\n# token_embedding = 1,5,8\n</code></pre>"},{"location":"bagu/deeplearning/1/#4-transformer-encoder","title":"4 Transformer Encoder","text":"Python<pre><code># step4 Pass embedding to Transformer Encoder\n# d_model = model_dim = 8\nencoder_layer = nn.TransformerEncoderLayer(d_model=model_dim,nhead=8)\ntransformer_encoder = nn.TransformerEncoder(encoder_layer,num_layers=6)\n# token_embedding = 1,5,8(\u53ef\u4ee5\u7406\u89e3\u4e3a 5\u4e2a\u8bcd\uff0c\u6bcf\u4e2a\u8bcd \u5d4c\u5165 8\u4e2a\u7ef4\u5ea6)\nencoder_output = transformer_encoder(token_embedding)\n</code></pre>"},{"location":"bagu/deeplearning/1/#5-classification-head","title":"5 classification head","text":"Python<pre><code># step5 do classification\ncls_token_output = encoder_output[:,0,:]\nlinear_layer = nn.Linear(model_dim,num_classes)\nlogits = linear_layer(cls_token_output)\nloss_fn = nn.CrossEntropyLoss()\nloss = loss_fn(logits,label)\nprint(loss)\n</code></pre>"},{"location":"bagu/deeplearning/1/#6","title":"6 \u5168\u90e8\u4ee3\u7801","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    patch_embedding = patch @ weight\n    return patch_embedding\ndef image2emb_conv(image,kernel,stride):\n    conv_output = F.conv2d(image,kernel,stride=stride) # bs*oc*oh*ow\n    bs,oc,oh,ow = conv_output.shape\n    patch_embedding = conv_output.reshape((bs,oc,oh*ow)).transpose(-1,-2)\n\n    return patch_embedding\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\nmax_num_token = 16\nnum_classes = 10\nlabel = torch.randint(10,(bs,))\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim) # model_dim\u662f\u8f93\u51fa\u901a\u9053\u6570\u76ee\uff0cpatch depth\u662f\u5377\u79ef\u6838\u7684\u9762\u79ef\u4e58\u4ee5\u8f93\u5165\u901a\u9053\u6570\n\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)  # \u5206\u5757\u65b9\u6cd5\u5f97\u5230embedding\nkernel = weight.transpose(0,1).reshape((-1,ic,patch_size,patch_size))   # oc*ic*kh*kw\n\npatch_embedding_conv = image2emb_conv(image,kernel,patch_size) # \u4e8c\u7ef4\u5377\u79ef\u65b9\u6cd5\u5f97\u5230embedding\n\n# print(patch_embedding_naive)\n# print(patch_embedding_conv)\n\n# step2 prepend CLS token embedding\ncls_token_embedding = torch.randn(bs,1,model_dim,requires_grad=True)\ntoken_embedding = torch.cat([cls_token_embedding,patch_embedding_conv],dim=1)\n\n# step3 add position embedding\npositon_embedding_table = torch.randn(max_num_token,model_dim,requires_grad=True)\nseq_len = token_embedding.shape[1]\npositon_embedding = torch.tile(positon_embedding_table[:seq_len],[token_embedding.shape[0],1,1])\ntoken_embedding += positon_embedding\n\n# step4 Pass embedding to Transformer Encoder\nencoder_layer = nn.TransformerEncoderLayer(d_model=model_dim,nhead=8)\ntransformer_encoder = nn.TransformerEncoder(encoder_layer,num_layers=6)\nencoder_output = transformer_encoder(token_embedding)\n\n# step5 do classification\ncls_token_output = encoder_output[:,0,:]\nlinear_layer = nn.Linear(model_dim,num_classes)\nlogits = linear_layer(cls_token_output)\nloss_fn = nn.CrossEntropyLoss()\nloss = loss_fn(logits,label)\nprint(loss)\n</code></pre>"},{"location":"bagu/deeplearning/pytorch_shape_function/","title":"pytorch\u7684\u7ef4\u5ea6\u53d8\u6362\u51fd\u6570","text":""},{"location":"bagu/deeplearning/pytorch_shape_function/#pytorch","title":"pytorch\u7684\u7ef4\u5ea6\u53d8\u6362\u51fd\u6570","text":"2024-11-15 19:19:112025-09-28 12:54:04 <p> \u7ea6 419 \u4e2a\u5b57  6 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p>"},{"location":"bagu/deeplearning/pytorch_shape_function/#_1","title":"\u7ef4\u5ea6\u8f6c\u6362\u51fd\u6570","text":"<ol> <li><code>torch.unsqueeze(input, dim)</code>\uff1a\u5728\u6307\u5b9a\u7ef4\u5ea6 <code>dim</code> \u4e0a\u589e\u52a0\u4e00\u4e2a\u65b0\u7684\u7ef4\u5ea6\u3002\u5982\u679c <code>dim</code> \u5df2\u7ecf\u5b58\u5728\uff0c\u5219\u5728\u5176\u524d\u9762\u6dfb\u52a0\u65b0\u7684\u7ef4\u5ea6\u3002</li> <li><code>torch.squeeze(input, dim=None)</code>\uff1a\u79fb\u9664\u6240\u6709\u957f\u5ea6\u4e3a1\u7684\u7ef4\u5ea6\u3002\u5982\u679c\u6307\u5b9a\u4e86 <code>dim</code>\uff0c\u5219\u53ea\u79fb\u9664\u8be5\u7ef4\u5ea6\u3002</li> <li><code>torch.flatten(input, start_dim=0, end_dim=-1)</code>\uff1a\u5c06\u8f93\u5165\u5f20\u91cf\u4ece <code>start_dim</code> \u5230 <code>end_dim</code> \u7684\u6240\u6709\u7ef4\u5ea6\u5c55\u5e73\u3002</li> <li><code>torch.view(input, size)</code> \u6216 <code>input.view(size)</code>\uff1a\u91cd\u65b0\u8c03\u6574\u5f20\u91cf\u7684\u5f62\u72b6\uff0c\u4e0d\u6539\u53d8\u6570\u636e\u3002</li> <li><code>torch.reshape(input, shape)</code>\uff1a\u4e0e <code>view</code> \u7c7b\u4f3c\uff0c\u7528\u4e8e\u6539\u53d8\u5f20\u91cf\u7684\u5f62\u72b6\uff0c\u4f46 <code>reshape</code> \u53ef\u4ee5\u5904\u7406\u66f4\u590d\u6742\u7684\u7ef4\u5ea6\u53d8\u6362\uff0c\u5982\u589e\u52a0\u6216\u51cf\u5c11\u7ef4\u5ea6\u3002</li> <li><code>torch.permute(input, dims)</code>\uff1a\u91cd\u65b0\u6392\u5217\u8f93\u5165\u5f20\u91cf\u7684\u7ef4\u5ea6\uff0c<code>dims</code> \u662f\u4e00\u4e2a\u7ef4\u5ea6\u7d22\u5f15\u7684\u5143\u7ec4\u3002</li> <li><code>torch.transpose(input, dim0, dim1)</code>\uff1a\u4ea4\u6362\u8f93\u5165\u5f20\u91cf\u7684\u4e24\u4e2a\u7ef4\u5ea6\u3002</li> <li><code>torch.expand(input, size)</code>\uff1a\u5c06\u8f93\u5165\u5f20\u91cf\u6cbf\u6307\u5b9a\u7684\u7ef4\u5ea6\u590d\u5236\u6269\u5c55\u3002</li> <li><code>torch.cat(tensors, dim)</code>\uff1a\u6cbf\u6307\u5b9a\u7ef4\u5ea6 <code>dim</code> \u8fde\u63a5\u591a\u4e2a\u5f20\u91cf\u3002</li> <li><code>torch.stack(tensors, dim)</code>\uff1a\u6cbf\u65b0\u7684\u7ef4\u5ea6 <code>dim</code> \u5806\u53e0\u591a\u4e2a\u5f20\u91cf\uff0c\u4e0e <code>cat</code> \u4e0d\u540c\u7684\u662f\uff0c<code>stack</code> \u4f1a\u589e\u52a0\u4e00\u4e2a\u65b0\u7684\u7ef4\u5ea6\u3002</li> <li> <p><code>torch.reapeat</code></p> </li> <li> <p><code>torch.tile</code></p> </li> </ol> Python<pre><code>positon_embedding = torch.tile(positon_embedding_table[:seq_len],[token_embedding.shape[0],1,1])\n# positon_embedding_table[:seq_len] = positon_embedding_table[:5] \u53d6\u524d5\u4e2a8\u7ef4\n# [:5] \u8868\u793a \u5bf9 \u7b2c\u4e00\u7ef4 \u7d22\u5f15\n# positon_embedding_table[:seq_len] = 5,8\n# [token_embedding.shape[0],1,1] = [1,1,1]\n# positon_embedding = 1,5,8\n</code></pre>"},{"location":"bagu/deeplearning/pytorch_shape_function/#_2","title":"\u7406\u89e3\u5f20\u91cf","text":"<p>\u5047\u5982\u4f60\u6709\u4e00\u4e2a\u7bee\u5b50\uff0c\u91cc\u9762\u88c5\u6ee1\u4e86\u5404\u79cd\u989c\u8272\u7684\u5c0f\u7403\u3002\u6bcf\u4e2a\u5c0f\u7403\u4ee3\u8868\u4e00\u4e2a\u6570\u5b57\u3002\u73b0\u5728\uff0c\u5982\u679c\u6211\u4eec\u60f3\u628a\u8fd9\u4e9b\u5c0f\u7403\u6309\u7167\u4e00\u5b9a\u7684\u987a\u5e8f\u6392\u5217\uff0c\u6bd4\u5982\u4e00\u884c\u6216\u8005\u4e00\u5217\uff0c\u8fd9\u5c31\u662f\u4e00\u4e2a\u4e00\u7ef4\u6570\u7ec4\u3002\u5982\u679c\u4f60\u628a\u51e0\u884c\u8fd9\u6837\u7684\u5c0f\u7403\u6392\u5217\u8d77\u6765\uff0c\u5c31\u5f62\u6210\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u6570\u7ec4\uff0c\u5c31\u50cf\u4e00\u4e2a\u8868\u683c\u4e00\u6837\u3002\u5982\u679c\u4f60\u518d\u628a\u8fd9\u4e9b\u8868\u683c\u5806\u53e0\u8d77\u6765\uff0c\u5c31\u5f62\u6210\u4e86\u4e00\u4e2a\u4e09\u7ef4\u6570\u7ec4\u3002\u5728PyTorch\u4e2d\uff0c\u5f20\u91cf\u5c31\u662f\u4e00\u79cd\u7528\u6765\u8868\u793a\u8fd9\u4e9b\u4e0d\u540c\u7ef4\u5ea6\u6570\u7ec4\u7684\u6570\u636e\u7ed3\u6784\u3002</p> <p></p>"},{"location":"bagu/deeplearning/transformer/","title":"\u624b\u6495Transformer\u4ee3\u7801","text":""},{"location":"bagu/deeplearning/transformer/#transformer","title":"\u624b\u6495Transformer\u4ee3\u7801","text":"2025-02-22 22:04:482025-09-28 12:54:04 <p> \u7ea6 298 \u4e2a\u5b57  206 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p>"},{"location":"bagu/deeplearning/transformer/#_1","title":"\u81ea\u6ce8\u610f\u529b\u673a\u5236","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass SelfAttention(nn.Module):\n    def __init__(self,model_dim,dropout=0.1):\n\n        super().__init__()\n        self.model_dim = model_dim\n\n        self.q_proj = nn.Linear(model_dim,model_dim)\n        self.k_proj = nn.Linear(model_dim,model_dim)\n        self.v_proj = nn.Linear(model_dim,model_dim)\n\n        self.o_proj = nn.Linear(model_dim,model_dim)\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self,x,mask=None):\n        q = self.q_proj(x)\n        k = self.k_proj(x)\n        v = self.v_proj(x)\n\n        scores = torch.matmul(q,k.transpose(-1,-2))//math.sqrt(self.model_dim)\n\n        if mask is not None:\n            scores = scores.masked_fill(mask==0,-1e09)\n\n        prob = F.softmax(scores,dim=-1)\n\n        prob = self.dropout(prob)\n\n        attn_weights = torch.matmul(prob,v)\n\n        output = self.o_proj(attn_weights)\n\n        return output\n\nmodel_dim = 512\nseq_len = 8\nbatch_size = 2\n# mask shape = seq_len * model_dim\nx = torch.randn(batch_size,seq_len,model_dim)\n\nsa = SelfAttention(model_dim)\n\nattn_weights = sa(x)\nprint(attn_weights.shape)  # \u8f93\u51fa\u7684\u5f62\u72b6\u5e94\u8be5\u662f(batch_size, seq_len, model_dim)\n</code></pre>"},{"location":"bagu/deeplearning/transformer/#_2","title":"\u624b\u6495\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self,model_dim,num_heads,dropout=0.1):\n        super().__init__()\n        self.model_dim = model_dim\n        self.num_heads = num_heads\n        self.head_dim = model_dim // num_heads\n\n        self.q_proj = nn.Linear(model_dim,model_dim)\n        self.k_proj = nn.Linear(model_dim,model_dim)\n        self.v_proj = nn.Linear(model_dim,model_dim)\n\n        self.dropout = nn.Dropout(dropout)\n\n        self.o_proj = nn.Linear(model_dim,model_dim)\n\n    def forward(self,q,k,v,mask=None):\n\n        batch_size,sequence_length,model_dim = q.shape\n\n        q = self.q_proj(q).view(batch_size,sequence_length,self.num_heads,self.head_dim).transpose(1,2)\n        k = self.k_proj(k).view(batch_size,sequence_length,self.num_heads,self.head_dim).transpose(1,2)\n        v = self.v_proj(v).view(batch_size,sequence_length,self.num_heads,self.head_dim).transpose(1,2)\n\n        scores = torch.matmul(q,k.transpose(-1,-2))//math.sqrt(self.head_dim)\n\n        if mask is not None:\n            scores = scores.masked_fill(mask==0,-1e09)\n\n        prob = F.softmax(scores,dim=-1)\n\n        prob = self.dropout(prob)\n\n        attn_weights = torch.matmul(prob,v).transpose(1,2).contiguous().view(batch_size,sequence_length,model_dim)\n\n        output = self.o_proj(attn_weights)\n        return output\n\nmodel_dim = 512 \nnum_heads = 8\nmha = MultiHeadAttention(model_dim=model_dim, num_heads=num_heads, dropout=0.1)\nbatch_size = 10\nsequence_length = 60\nq = torch.randn(batch_size, sequence_length, model_dim)\nk = torch.randn(batch_size, sequence_length, model_dim)\nv = torch.randn(batch_size, sequence_length, model_dim)\n\nmask = None\noutput = mha(q, k, v, mask)\nprint(output.shape)  # \u8f93\u51fa\u7684\u5f62\u72b6\u5e94\u8be5\u662f(batch_size, sequence_length, model_dim)\n</code></pre> <p>note\uff1a</p> <ul> <li> <p>\u5047\u8bbe\u8f93\u5165\u6570\u636eq, k, v\u7684\u5f62\u72b6\u662f(batch_size, sequence_length, model_dim)</p> </li> <li> <p>\u4f8b\u5982\uff0c\u4e00\u4e2a\u6279\u6b21\u5927\u5c0f\u4e3a10\uff0c\u5e8f\u5217\u957f\u5ea6\u4e3a60\uff0c\u6a21\u578b\u7ef4\u5ea6\u4e3a512\u7684\u8f93\u5165 </p> </li> <li> <p>\u8fd9\u662f\u56e0\u4e3a\u6ce8\u610f\u529b\u673a\u5236\u7684\u76ee\u7684\u662f\u4e3a\u5e8f\u5217\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u8868\u793a\uff0c   \u800c\u4e0d\u662f\u751f\u6210\u4e00\u4e2a\u5e8f\u5217\u957f\u5ea6\u4e3a sequence_length \u7684\u5e8f\u5217\u3002</p> </li> </ul> <p>\u200b   \u6ce8\u610f\u529b\u673a\u5236\u4e3a\u5e8f\u5217\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u8868\u793a\uff0c\u8fd9\u4e2a\u8868\u793a\u7efc\u5408\u4e86\u5e8f\u5217\u4e2d\u6240\u6709\u5143\u7d20\u7684\u4fe1\u606f\uff0c</p> <p>\u200b   \u4f46\u8f93\u51fa\u7684\u5f62\u72b6\u4ecd\u7136\u662f (batch_size, sequence_length, model_dim)\uff0c</p> <p>\u200b   \u800c\u4e0d\u662f (batch_size, sequence_length, sequence_length)\u3002</p> <p>\u200b   \u8fd9\u662f\u56e0\u4e3a\u8f93\u51fa\u7684\u6bcf\u4e2a\u5143\u7d20\u662f\u5e8f\u5217\u4e2d\u5bf9\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20\u5728\u6240\u6709\u5934\u4e2d\u7684\u52a0\u6743\u8868\u793a\uff0c \u200b   \u800c\u4e0d\u662f\u5e8f\u5217\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5bf9\u5176\u4ed6\u5143\u7d20\u7684\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\u3002</p>"},{"location":"bagu/deeplearning/transformer/#_3","title":"\u624b\u6495\u4f4d\u7f6e\u7f16\u7801","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n</code></pre>"},{"location":"bagu/deeplearning/transformer/#_4","title":"\u4e00\u7ef4\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801","text":"<ul> <li>\u7c7b\u5199\u6cd5</li> <li>\u51fd\u6570\u5199\u6cd5</li> </ul> Python<pre><code>class SinCosPositionEmbedding(nn.Module):\n    def __init__(self, max_sequence_length,model_dim):\n        super().__init__()\n        self.max_sequence_length = max_sequence_length\n        self.model_dim = model_dim\n    def forward(self):\n        pe = torch.zeros(self.max_sequence_length,self.model_dim)\n        pos_mat = torch.arange(self.max_sequence_length).reshape(-1,1)\n        i_mat = torch.pow(10000,\n                          torch.arange(0,self.model_dim,2).reshape(1,-1)/self.model_dim\n                          )\n\n        pe[:,0::2] = torch.sin(pos_mat/i_mat)\n        pe[:,1::2] = torch.cos(pos_mat/i_mat)\n\n        return pe\nprint(SinCosPositionEmbedding(max_sequence_length=8,model_dim=4).forward())\n</code></pre> <p>\u51fd\u6570\u5199\u6cd5</p> Python<pre><code>def create_1d_absolute_sincos_embeddings(max_sequence_length,model_dim):\n    assert model_dim%2 == 0,\"wrong dimension\"\n    pe_table = torch.zeros(max_sequence_length,model_dim)\n    pos_mat = torch.arange(max_sequence_length).reshape(-1,1)\n    i_mat = torch.pow(\n        10000,\n        torch.arange(0,model_dim,2)/model_dim\n    )\n    pe_table[:,0::2]=torch.sin(pos_mat/i_mat)\n    pe_table[:,1::2]=torch.cos(pos_mat/i_mat)\n    return pe_table\n\n# Transformer\u8bba\u6587 \u4e00\u7ef4\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\nif __name__==\"__main__\":\n    max_sequence_length = 8\n    model_dim = 4\n    pe_table = create_1d_absolute_sincos_embeddings(max_sequence_length,model_dim)\n    print(pe_table)\n</code></pre>"},{"location":"bagu/deeplearning/transformer/#_5","title":"\u4e00\u7ef4\u53ef\u5b66\u4e60\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801","text":"<p>from vit</p> <p>\u7c7b\u5199\u6cd5\uff1a</p> Python<pre><code>import torch\nimport torch.nn as nn\nclass TrainablePositionEncoding(nn.Module):\n    def __init__(self, max_sequence_length, d_model):\n        super().__init__() \n        self.max_sequence_length = max_sequence_length\n        self.d_model = d_model\n\n    def forward(self):\n        pe = nn.Embedding(self.max_sequence_length, self.d_model)\n        nn.init.constant_(pe.weight, 0.)\n        return pe\nmax_sequence_length = 100\nd_model = 512\ntrainable_pe = TrainablePositionEncoding(max_sequence_length, d_model)\nposition_encodings = trainable_pe()\nprint(position_encodings.weight.shape)  # \u8f93\u51fa\uff1atorch.Size([100, 512])\n</code></pre> <p>\u51fd\u6570\u5199\u6cd5\uff1a</p> Python<pre><code>def create_1d_absolute_trainable_embeddings(max_sequence_length,model_dim):\n    pe = nn.Embedding(max_sequence_length,model_dim)\n    nn.init.constant_(pe.weight,0.)\n\n    return pe\n</code></pre>"},{"location":"bagu/deeplearning/transformer/#_6","title":"\u4e8c\u7ef4\u76f8\u5bf9\u53ef\u5b66\u4e60\u4f4d\u7f6e\u7f16\u7801","text":"<p>from SwinTransformer</p> Python<pre><code>def create_2d_relative_bias_trainable_embeddings(n_head,height,width,dim):\n    # width:5,[0,1,2,3,4],bias=[-width+1,width-1],2*width-1\n    # height:5,[0,1,2,3,4],bias=[-height+1,height-1],2*height-1\n\n    position_embedding = nn.Embedding((2*width-1)*(2*height-1),n_head)\n    nn.init.constant_(position_embedding.weight,0.)\n\n    def get_relative_position_index(height,width):\n        m1,m2 = torch.meshgrid(torch.arange(height),torch.arange(width))\n        coords = torch.stack(m1,m2) #[2,height,width]\n        coords_flatten = torch.flatten(coords,1) #[2,height*width]\n\n        # \u628a\u504f\u5dee\u53d8\u6210\u6b63\u6570\uff0c\u7136\u540e\u4eceposition_embedding\u4e2d\u6309\u7d22\u5f15\u53d6\u503c\n        relative_coords_bias = coords_flatten[:,:,None]-coords_flatten[:,None,:] # [2,height*width,height*width]\n\n        relative_coords_bias[0,:,:] += height-1\n        relative_coords_bias[1,:,:] += width-1\n\n        # A:2d,B:1d,B[[i*cols+j] = A[i,j]\n        relative_coords_bias[0,:,:] *= relative_coords_bias[1,:,:].max()+1\n\n        return relative_coords_bias.sum(0) # [height*width,height*width]\n    relative_position_bias = get_relative_position_index(height,width)\n    bias_embedding = position_embedding(torch.flatten(relative_position_bias)).reshape(height*width,height*width,n_head) #[height*width,height*width,n_head]\n\n    bias_embedding = position_embedding.permute(2,0,1).unsqueeze(0) # [1,n_head,height*width,height*width]\n\n    return bias_embedding\n</code></pre>"},{"location":"bagu/deeplearning/transformer/#_7","title":"\u4e8c\u7ef4\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801","text":"<p>from MAE</p> Python<pre><code># 4.2d absolute constant sincos embedding\n# Masked AutoEncoder \u8bba\u6587\ndef create_2d_absolute_sincos_embeddings(height,width,dim):\n    assert dim%4 ==0,\"wrong dimension!\"\n    position_embedding = torch.zeros(height*width,dim)\n    m1,m2 = torch.meshgrid(torch.arrange(height,dtype=torch.float),torch.arrange(width,dtype=torch.float))\n    coords = torch.stack(m1,m2)  # [2,height*width]\n\n    height_embedding = create_1d_absolute_sincos_embeddings(torch.flatten(coords[0]),dim//2)  # [height*width,dim//2]\n    width_embedding = create_1d_absolute_sincos_embeddings(torch.flatten(coords[1]),dim//2)  # [height*width,dim//2]\n\n    position_embedding[:,:dim//2] = height_embedding\n    position_embedding[:,:dim//2] = width_embedding\n\n    return position_embedding\n</code></pre>"},{"location":"bagu/leetcode/","title":"Index","text":"2024-11-15 19:19:112025-09-28 12:54:04 <p> \u7ea6 3 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <ul> <li> 1</li> <li> 2</li> </ul>"},{"location":"bagu/leetcode/1/","title":"1 \u4e24\u6570\u4e4b\u548c","text":""},{"location":"bagu/leetcode/1/#1","title":"1 \u4e24\u6570\u4e4b\u548c","text":"2024-11-15 19:19:112025-09-28 12:54:04 <p> \u7ea6 356 \u4e2a\u5b57  15 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <p>\u529b\u62631 \u4e24\u6570\u4e4b\u548c </p> Python<pre><code>class Solution:\n    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:\n</code></pre> <p>\u793a\u4f8b 1\uff1a</p> Python<pre><code>\u8f93\u5165\uff1anums = [2,7,11,15], target = 9\n\u8f93\u51fa\uff1a[0,1]\n\u89e3\u91ca\uff1a\u56e0\u4e3a nums[0] + nums[1] == 9 \uff0c\u8fd4\u56de [0, 1] \u3002\n</code></pre> Python<pre><code>class Solution:\n    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:\n        dict = {}\n\n        for i in range(len(nums)):\n            if target - nums[i] not in dict:\n                dict[nums[i]] = i\n            else:\n                return [dict[target-nums[i]],i]\n</code></pre> <p>\u9010\u5b57\u8be6\u89e3\uff1a\u9996\u5148\u8f93\u5165\u7684\u6570\u7ec4\u662fnums\uff0c\u5047\u8bbenums = [2,7,11,15]\uff0ci=0,1,2,3 \u5f53 i=0\u65f6\uff0c\u6b64\u65f6target=9\uff0ctarget-nums[0]=9-2=7,7\u4e0d\u5728\u5b57\u5178\u4e2d\uff0c\u56e0\u4e3a\u5b57\u5178\u662f\u7a7a\u7684\uff0c\u6240\u4ee5\u6267\u884cdict[num[i]] = i \u5373 dict[nums[0]]=0 \uff0cdict[2]=0\uff0ci=1,target-nums[i]=9-nums[1]=9-7=2,2\u5728\u5b57\u5178\u4e2d\uff0c\u6240\u4ee5\u6267\u884celse return[dict[2],1]=[0,1]\u8fd4\u56de\uff0c\u5f97\u5230\u7ed3\u679c</p> <p>\u518d\u6765\uff1a\u9996\u5148\u5b9a\u4e49\u7a7a\u5b57\u5178\uff0c\u7528\u6765\u5b58\u50a8\u5df2\u7ecf\u904d\u5386\u8fc7\u7684\u6570\u5b57\u53ca\u5176\u5bf9\u5e94\u7684\u7d22\u5f15\uff1b\u63a5\u4e0b\u6765 for loop\u904d\u5386\u6570\u7ec4nums,\u5176\u4e2di\u662f\u5f53\u524d\u904d\u5386\u5230\u7684\u6570\u5b57\u7684\u7d22\u5f15\uff1b\u5982\u679c\u4e0d\u5728\u5b57\u5178\u4e2d\uff0c\u8bf4\u660e\u4e4b\u524d\u6ca1\u6709\u9047\u5230\u8fc7\u4e0e\u5f53\u524d\u6570\u5b57\u76f8\u52a0\u7b49\u4e8etarget\u7684\u6570\u5b57\uff0c\u56e0\u6b64\u5c06\u5f53\u524d\u6570\u5b57\u53ca\u5176\u7d22\u5f15\u5b58\u5165\u5b57\u5178\u4e2d\u3002\u5982\u679c\u5728\u5b57\u5178\u4e2d\uff0c\u8bf4\u660e\u5df2\u7ecf\u627e\u5230\u4e86\u4e00\u5bf9\u6570\u5b57\uff0c\u548c\u7b49\u4e8etarget\uff0c\u4e8e\u662f\u8fd4\u56de\u8fd9\u4e24\u4e2a\u6570\u5b57\u7684\u7d22\u5f15\u3002\u8fd9\u4e24\u4e2a\u7d22\u5f15\u5206\u522b\u662fdict[target-nums[i]]\uff08\u5b58\u50a8\u5dee\u503c \u5bf9\u5e94\u7684\u7d22\u5f15\uff09\u548c i\uff08\u5f53\u524d\u6570\u5b57\u7684\u7d22\u5f15\uff09</p> <p>\u5206\u6790\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(n)\uff0c\u5176\u4e2dn\u4e3a\u6570\u7ec4\u7684\u957f\u5ea6\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u5143\u7d20\u53ea\u88ab\u8bbf\u95ee\u4e00\u6b21\uff0c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3aO(n)\uff0c\u6700\u574f\u7684\u60c5\u51b5\u662f\u53ef\u80fd\u9700\u8981\u5b58\u50a8\u6240\u6709\u5143\u7d20\u7684\u7d22\u5f15</p> <p>\u8fd9\u4e2a\u65b9\u6cd5\u4f7f\u7528\u4e86\u54c8\u5e0c\u8868\uff08\u901a\u8fc7\u5b57\u5178\uff09\u5feb\u901f\u67e5\u627e\u76ee\u6807\u6570\u5b57\uff0c\u662f\u4e00\u79cd\u5178\u578b\u7684\u54c8\u5e0c\u8868\u5e94\u7528\u573a\u666f\uff0c\u63d0\u9ad8\u67e5\u627e\u6548\u7387</p>"},{"location":"bagu/leetcode/2/","title":"2 \u4e24\u6570\u76f8\u52a0","text":""},{"location":"bagu/leetcode/2/#2","title":"2 \u4e24\u6570\u76f8\u52a0","text":"2024-11-15 19:19:112025-09-28 12:54:04 <p> \u7ea6 5 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"bagu/machinelearning/2/","title":"\u624b\u6495\u53cd\u5411\u4f20\u64ad","text":""},{"location":"bagu/machinelearning/2/#_1","title":"\u624b\u6495\u53cd\u5411\u4f20\u64ad","text":"2024-11-25 22:33:462025-09-28 12:54:04 <p> \u7ea6 8 \u4e2a\u5b57  261 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> Python<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\ndef init_parameters(layers_dim):\n    L = len(layers_dim)\n    parameters ={}\n    for i in range(1,L):\n        parameters[\"w\"+str(i)] = np.random.random([layers_dim[i],layers_dim[i-1]])\n        parameters[\"b\"+str(i)] = np.zeros((layers_dim[i],1))\n    return parameters\n\ndef sigmoid(z):\n    return 1.0/(1.0+np.exp(-z))\n\ndef sigmoid_prime(z):\n        return sigmoid(z) * (1-sigmoid(z))\n\ndef forward(x,parameters):\n    a = []\n    z = []\n    caches = {}\n    a.append(x)\n    z.append(x)\n    layers = len(parameters)//2\n    for i in range(1,layers):\n        z_temp =parameters[\"w\"+str(i)].dot(x) + parameters[\"b\"+str(i)]\n        z.append(z_temp)\n        a.append(sigmoid(z_temp))\n    z_temp = parameters[\"w\"+str(layers)].dot(a[layers-1]) + parameters[\"b\"+str(layers)]\n    z.append(z_temp)\n    a.append(z_temp)\n\n    caches[\"z\"] = z\n    caches[\"a\"] = a    \n    return  caches,a[layers]\n\ndef backward(parameters,caches,al,y):\n    layers = len(parameters)//2\n    grades = {}\n    m = y.shape[1]\n    grades[\"dz\"+str(layers)] = al - y\n    grades[\"dw\"+str(layers)] = grades[\"dz\"+str(layers)].dot(caches[\"a\"][layers-1].T) /m\n    grades[\"db\"+str(layers)] = np.sum(grades[\"dz\"+str(layers)],axis = 1,keepdims = True) /m\n    for i in reversed(range(1,layers)):\n        grades[\"dz\"+str(i)] = parameters[\"w\"+str(i+1)].T.dot(grades[\"dz\"+str(i+1)]) * sigmoid_prime(caches[\"z\"][i])\n        grades[\"dw\"+str(i)] = grades[\"dz\"+str(i)].dot(caches[\"a\"][i-1].T)/m\n        grades[\"db\"+str(i)] = np.sum(grades[\"dz\"+str(i)],axis = 1,keepdims = True) /m\n    return grades   \n\ndef update_grades(parameters,grades,learning_rate):\n    layers = len(parameters)//2\n    for i in range(1,layers+1):\n        parameters[\"w\"+str(i)] -= learning_rate * grades[\"dw\"+str(i)]\n        parameters[\"b\"+str(i)] -= learning_rate * grades[\"db\"+str(i)]\n    return parameters\n\ndef compute_loss(al,y):\n    return np.mean(np.square(al-y))\n\ndef load_data():\n    x = np.arange(0.0,1.0,0.01)\n    y =20* np.sin(2*np.pi*x)\n    plt.scatter(x,y)\n    return x,y\n\nx,y = load_data()\nx = x.reshape(1,100)\ny = y.reshape(1,100)\nplt.scatter(x,y)\nparameters = init_parameters([1,25,1])\nal = 0\nfor i in range(4000):\n    caches,al = forward(x, parameters)\n    grades = backward(parameters, caches, al, y)\n    parameters = update_grades(parameters, grades, learning_rate= 0.3)\n    if i %100 ==0:\n        print(compute_loss(al, y))\nplt.scatter(x,al)\nplt.show()\n</code></pre> <p>\u6ce8\u91ca</p> Python<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\ndef init_parameters(layers_dim):\n    # \u5b9a\u4e49\u4e00\u4e2a\u540d\u4e3a init_parameters \u7684\u51fd\u6570\uff0c\n    # \u5b83\u63a5\u6536\u4e00\u4e2a\u53c2\u6570 layers_dim\uff0c\u8fd9\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u5305\u542b\u4e86\u6bcf\u4e00\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf\u3002\n    # print(layers_dim)  # [1, 25, 1] \n    # \u8f93\u5165\u5c42\u6709 1 \u4e2a\u795e\u7ecf\u5143\uff0c\u9690\u85cf\u5c42\u6709 25 \u4e2a\u795e\u7ecf\u5143\uff0c\u8f93\u51fa\u5c42\u6709 1 \u4e2a\u795e\u7ecf\u5143\n    L = len(layers_dim) # \u83b7\u53d6\u5c42\u7684\u6570\u91cf\n    parameters ={} # \u521d\u59cb\u5316\u4e00\u4e2a\u7a7a\u5b57\u5178\uff0c\u7528\u4e8e\u5b58\u50a8\u6bcf\u4e00\u5c42\u7684\u53c2\u6570\n    for i in range(1,L): # \u4ece\u7b2c1\u5c42\u5f00\u59cb\u904d\u5386\u5230\u5012\u6570\u7b2c\u4e8c\u5c42\n        # \u521d\u59cb\u5316\u6743\u91cd w1 w2  \u7b2c\u4e00\u5c42\u8f93\u5165\u5c42 \u4e0d\u521d\u59cb\u5316\n        '''\n        - parameters[\"w\"+str(i)] \u521d\u59cb\u5316\u6743\u91cd\u77e9\u9635\uff0c\u5f62\u72b6\u4e3a [layers_dim[i], layers_dim[i-1]]\n          \u8fd9\u8868\u793a\u7b2c i \u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684\u5f62\u72b6\uff0c\u5176\u4e2d layers_dim[i] \u662f\u7b2c i \u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf\uff0clayers_dim[i-1] \u662f\u524d\u4e00\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf\u3002\n        - parameters[\"b\"+str(i)] \u521d\u59cb\u5316\u504f\u7f6e\u9879\uff0c\u5f62\u72b6\u4e3a [layers_dim[i], 1]\n          \u8fd9\u8868\u793a\u7b2c i \u5c42\u7684\u504f\u7f6e\u9879\u7684\u5f62\u72b6\uff0c\u5176\u4e2d layers_dim[i] \u662f\u7b2c i \u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf\u3002\n        '''\n        parameters[\"w\"+str(i)] = np.random.random([layers_dim[i],\n                                                   layers_dim[i-1]])\n        # \u521d\u59cb\u5316\u504f\u7f6e\u9879 b1 b2 \u7b2c0\u5c42\u8f93\u5165\u5c42 \u4e0d\u521d\u59cb\u5316\n        parameters[\"b\"+str(i)] = np.zeros((layers_dim[i],1))\n    # \u8fd4\u56de\u5305\u542b\u6240\u6709\u53c2\u6570\u7684\u5b57\u5178\n    # print(parameters['w1'].shape)  (25, 1)\n    '''\n        parameters['w1'].shape \u662f (25, 1)\uff1a\n        \u8868\u793a\u4ece\u8f93\u5165\u5c42\u5230\u7b2c 1 \u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684\u5f62\u72b6\u3002\n        \u8f93\u5165\u5c42\u6709 1 \u4e2a\u795e\u7ecf\u5143\uff0c\u7b2c 1 \u5c42\u6709 25 \u4e2a\u795e\u7ecf\u5143\uff0c\n        \u56e0\u6b64\u6743\u91cd\u77e9\u9635\u7684\u5f62\u72b6\u662f (25, 1)\u3002\n    '''\n    # print(parameters['w2'].shape)  (1, 25)\n    '''\n        parameters['w2'].shape \u662f (1, 25)\uff1a\n        \u8868\u793a\u4ece\u7b2c 1 \u5c42\u5230\u8f93\u51fa\u5c42\u7684\u6743\u91cd\u77e9\u9635\u7684\u5f62\u72b6\u3002\n        \u7b2c 1 \u5c42\u6709 25 \u4e2a\u795e\u7ecf\u5143\uff0c\u8f93\u51fa\u5c42\u6709 1 \u4e2a\u795e\u7ecf\u5143\uff0c\n        \u56e0\u6b64\u6743\u91cd\u77e9\u9635\u7684\u5f62\u72b6\u662f (1, 25)\u3002\n    '''\n    # print(parameters['b1'].shape)  (25, 1)\n    '''\n        parameters['b1'].shape \u662f (25, 1)\uff1a\n        \u8868\u793a\u7b2c 1 \u5c42\u7684\u504f\u7f6e\u9879\u7684\u5f62\u72b6\u3002\n        \u7b2c 1 \u5c42\u6709 25 \u4e2a\u795e\u7ecf\u5143\uff0c\n        \u56e0\u6b64\u504f\u7f6e\u9879\u7684\u5f62\u72b6\u662f (25, 1)\u3002\n    '''\n    # print(parameters['b2'].shape)  (1, 1)\n    '''\n        parameters['b2'].shape \u662f (1, 1)\uff1a\n        \u8868\u793a\u8f93\u51fa\u5c42\u7684\u504f\u7f6e\u9879\u7684\u5f62\u72b6\u3002\n        \u8f93\u51fa\u5c42\u6709 1 \u4e2a\u795e\u7ecf\u5143\uff0c\n        \u56e0\u6b64\u504f\u7f6e\u9879\u7684\u5f62\u72b6\u662f (1, 1)\u3002'''\n\n    '''\n        \u6743\u91cd\u77e9\u9635\u7684\u5f62\u72b6\u662f [\u5f53\u524d\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf, \u524d\u4e00\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf]\u3002\n        \u504f\u7f6e\u9879\u7684\u5f62\u72b6\u662f [\u5f53\u524d\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf, 1]\u3002'''\n\n    return parameters\n\n\ndef sigmoid(z):\n    return 1.0/(1.0+np.exp(-z))\n\ndef sigmoid_prime(z):\n        return sigmoid(z) * (1-sigmoid(z))\n\ndef forward(x,parameters):\n    # forward \u51fd\u6570\u63a5\u6536\u4e24\u4e2a\u53c2\u6570\uff1a\u8f93\u5165\u6570\u636e x \u548c\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570 parameters\n    # a \u548c z \u662f\u4e24\u4e2a\u5217\u8868\uff0c\u5206\u522b\u7528\u4e8e\u5b58\u50a8\u6bcf\u4e00\u5c42\u7684\u6fc0\u6d3b\u503c\u548c\u7ebf\u6027\u53d8\u6362\u503c\n    # caches \u662f\u4e00\u4e2a\u5b57\u5178\uff0c\u7528\u4e8e\u5b58\u50a8 a \u548c z \u5217\u8868\uff0c\u4ee5\u4fbf\u5728\u53cd\u5411\u4f20\u64ad\u65f6\u4f7f\u7528\n    # a.append(x) \u548c z.append(x) \u5c06\u8f93\u5165\u6570\u636e x \u6dfb\u52a0\u5230 a \u548c z \u5217\u8868\u4e2d\uff0c\u4f5c\u4e3a\u7b2c 0 \u5c42\u7684\u6fc0\u6d3b\u503c\u548c\u7ebf\u6027\u53d8\u6362\u503c\n    # layers \u8ba1\u7b97\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\u6570\uff0c\u5047\u8bbe parameters \u5b57\u5178\u4e2d\u5305\u542b\u6bcf\u4e00\u5c42\u7684\u6743\u91cd\u548c\u504f\u7f6e\u9879\uff0c\u56e0\u6b64\u5c42\u6570\u4e3a len(parameters) // 2\n    a = []\n    z = []\n    caches = {}\n    a.append(x)\n    z.append(x)\n    layers = len(parameters)//2  \n    # \u56e0\u4e3a\u5373\u6709w\u53c8\u6709b\uff0c\u6240\u4ee5\u9664\u4ee52  len(parameters) = 4\n    # print(layers)  # 2\n    for i in range(1,layers):\n        # \u8fd9\u6bb5\u4ee3\u7801\u904d\u5386\u4ece\u7b2c 1 \u5c42\u5230\u5012\u6570\u7b2c\u4e8c\u5c42\u7684\u6240\u6709\u5c42\n        # \u7b2c0\u5c42\u8f93\u5165\u5c42 \u4e0d\u8fdb\u884c\u8ba1\u7b97\n        # \u5982\u679c\u662f3\u5c42\u7684\u8bdd\uff0c\u7b2c0\u5c42 input  \u7b2c1\u5c42 w1\u3001b1  \u7b2c2\u5c42 w2\u3001b2\n        # \u6240\u4ee5\u8fd9\u4e2a for\u5faa\u73af \u904d\u5386\u4e0d\u5230 \u8f93\u51fa\u5c42\n        z_temp =parameters[\"w\"+str(i)].dot(x) + parameters[\"b\"+str(i)]\n        # print(\"w\"+str(i),\"b\"+str(i))  # w1 b1\n        z.append(z_temp)\n        a.append(sigmoid(z_temp))\n    z_temp = parameters[\"w\"+str(layers)].dot(a[layers-1]) + parameters[\"b\"+str(layers)]\n    # \u8fd9\u8fb9 \u53ea\u67093\u5c42\uff0c\u53ef\u4ee5\u76f4\u63a5\u5199\uff0c\u9690\u542b\u5c42\u548c\u8f93\u5165\u5c42\u70b9\u4e58\uff1b\u6700\u540e\u4e00\u5c42\u548c\u524d\u4e00\u5c42\u70b9\u4e58\n    # \u5982\u679c\u518d\u589e\u52a0\u4e00\u5c42\uff0c\u8fd9\u4e2a\u4ee3\u7801\u662f\u6709\u70b9\u95ee\u9898\u7684\uff1aparameters[\"w\"+str(i)].dot(x)\n    # \u5982\u679c\u5f88\u591a\u5c42 \u901a\u7528\u7684\u8bdd \u5e94\u8be5\u662f.dot(a[layers-1])\n    z.append(z_temp)\n    a.append(z_temp) \n    # \u6700\u540e\u4e00\u5c42\u7684\u6fc0\u6d3b\u503c\u76f4\u63a5\u4f7f\u7528\u7ebf\u6027\u53d8\u6362\u503c z_temp\uff0c\u4e0d\u4f7f\u7528 sigmoid \u6fc0\u6d3b\u51fd\u6570\u3002\n    # \u5c06 z_temp \u6dfb\u52a0\u5230 a \u5217\u8868\u4e2d\u3002\n\n    caches[\"z\"] = z\n    caches[\"a\"] = a \n    # \u5c06 z \u548c a \u5217\u8868\u5b58\u50a8\u5728 caches \u5b57\u5178\u4e2d\uff0c\u952e\u5206\u522b\u4e3a \"z\" \u548c \"a\"\u3002\n    # \u8fd4\u56de caches \u5b57\u5178\u548c\u6700\u540e\u4e00\u5c42\u7684\u6fc0\u6d3b\u503c a[layers]\u3002\n    return  caches,a[layers]\n\ndef backward(parameters,caches,al,y):\n    # backward \u51fd\u6570\u63a5\u6536\u56db\u4e2a\u53c2\u6570\uff1a\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570 parameters\u3001\n    # \u524d\u5411\u4f20\u64ad\u7684\u7f13\u5b58 caches\u3001\n    # \u524d\u5411\u4f20\u64ad\u7684\u8f93\u51fa al \u548c\u771f\u5b9e\u6807\u7b7e y\u3002\n    layers = len(parameters)//2\n    # layers \u8ba1\u7b97\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\u6570\uff0c\n    # \u5047\u8bbe parameters \u5b57\u5178\u4e2d\u5305\u542b\u6bcf\u4e00\u5c42\u7684\u6743\u91cd\u548c\u504f\u7f6e\u9879\uff0c\n    # \u56e0\u6b64\u5c42\u6570\u4e3a len(parameters) // 2\u3002\n    grades = {}\n    # grades \u662f\u4e00\u4e2a\u7a7a\u5b57\u5178\uff0c\u7528\u4e8e\u5b58\u50a8\u6bcf\u4e00\u5c42\u7684\u68af\u5ea6\u3002\n    m = y.shape[1]\n    # print(y.shape) (1, 100)\n    # m \u662f\u6837\u672c\u6570\u91cf\uff0c\u5373 y \u7684\u5217\u6570\u3002\n    grades[\"dz\"+str(layers)] = al - y\n    # print(\"dz\"+str(layers))  dz2\n    # al \u662f\u524d\u5411\u4f20\u64ad\u5f97\u5230\u7684\u8f93\u51fa\u5c42\u7684\u6fc0\u6d3b\u503c\uff08\u9884\u6d4b\u503c\uff09\u3002\n    # y \u662f\u771f\u5b9e\u6807\u7b7e\u3002\n    # dz \u8868\u793a\u8f93\u51fa\u5c42\u7684\u8bef\u5dee\uff0c\u8ba1\u7b97\u516c\u5f0f\u4e3a dz = al - y\u3002\n    # \u8fd9\u4e2a\u516c\u5f0f\u8868\u793a\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u5373\u8bef\u5dee\u3002\n    grades[\"dw\"+str(layers)] = grades[\"dz\"+str(layers)].dot(caches[\"a\"][layers-1].T) /m\n    # print(\"dw\"+str(layers)) dw2\n    # \u8ba1\u7b97\u8f93\u51fa\u5c42\u7684\u6743\u91cd\u68af\u5ea6 dw\uff1a\n    # grades[\"dz\" + str(layers)] \u662f\u8f93\u51fa\u5c42\u7684\u8bef\u5dee\u3002\n    # caches[\"a\"][layers - 1] \u662f\u524d\u4e00\u5c42\u7684\u6fc0\u6d3b\u503c\u3002\n    # m \u662f\u6837\u672c\u6570\u91cf\n    # dw \u8868\u793a\u8f93\u51fa\u5c42\u7684\u6743\u91cd\u68af\u5ea6\uff0c\u8ba1\u7b97\u516c\u5f0f\u4e3a dw = dz.dot(a_prev.T) / m\uff0c\n    # \u5176\u4e2d a_prev \u662f\u524d\u4e00\u5c42\u7684\u6fc0\u6d3b\u503c\u3002\n    # \u8fd9\u4e2a\u516c\u5f0f\u8868\u793a\u8bef\u5dee\u4e0e\u524d\u4e00\u5c42\u6fc0\u6d3b\u503c\u7684\u70b9\u79ef\uff0c\u7136\u540e\u9664\u4ee5\u6837\u672c\u6570\u91cf\uff0c\u5f97\u5230\u6743\u91cd\u7684\u5e73\u5747\u68af\u5ea6\u3002\n    grades[\"db\"+str(layers)] = np.sum(grades[\"dz\"+str(layers)],axis = 1,keepdims = True) /m\n    # print(\"db\"+str(layers))  db2\n    # \u8ba1\u7b97\u8f93\u51fa\u5c42\u7684\u504f\u7f6e\u68af\u5ea6 db\n    # \u53cd\u5411\u4f20\u64ad \u4ece\u8f93\u51fa\u5c42\u5f00\u59cb\n    # grades[\"dz\" + str(layers)] \u662f\u8f93\u51fa\u5c42\u7684\u8bef\u5dee\u3002\n    # np.sum(grades[\"dz\" + str(layers)], axis=1, keepdims=True) \n    # \u8ba1\u7b97\u8bef\u5dee\u5728\u6837\u672c\u7ef4\u5ea6\u4e0a\u7684\u603b\u548c\u3002\n    # m \u662f\u6837\u672c\u6570\u91cf\u3002\n    # db \u8868\u793a\u8f93\u51fa\u5c42\u7684\u504f\u7f6e\u68af\u5ea6\uff0c\n    # \u8ba1\u7b97\u516c\u5f0f\u4e3a db = np.sum(dz, axis=1, keepdims=True) / m\u3002\n    # \u8fd9\u4e2a\u516c\u5f0f\u8868\u793a\u8bef\u5dee\u5728\u6837\u672c\u7ef4\u5ea6\u4e0a\u7684\u5e73\u5747\u503c\uff0c\u5f97\u5230\u504f\u7f6e\u7684\u5e73\u5747\u68af\u5ea6\u3002\n    # dz \u8868\u793a\u8f93\u51fa\u5c42\u7684\u8bef\u5dee\uff0c\u8ba1\u7b97\u516c\u5f0f\u4e3a dz = al - y\u3002\n    # dw \u8868\u793a\u8f93\u51fa\u5c42\u7684\u6743\u91cd\u68af\u5ea6\uff0c\u8ba1\u7b97\u516c\u5f0f\u4e3a dw = dz.dot(a_prev.T) / m\u3002\n    # db \u8868\u793a\u8f93\u51fa\u5c42\u7684\u504f\u7f6e\u68af\u5ea6\uff0c\u8ba1\u7b97\u516c\u5f0f\u4e3a db = np.sum(dz, axis=1, keepdims=True) / m\u3002\n    # \u8fd9\u4e9b\u68af\u5ea6\u7528\u4e8e\u66f4\u65b0\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\n    for i in reversed(range(1,layers)):\n        grades[\"dz\"+str(i)] = parameters[\"w\"+str(i+1)].T.dot(grades[\"dz\"+str(i+1)]) * sigmoid_prime(caches[\"z\"][i])\n        grades[\"dw\"+str(i)] = grades[\"dz\"+str(i)].dot(caches[\"a\"][i-1].T)/m\n        grades[\"db\"+str(i)] = np.sum(grades[\"dz\"+str(i)],axis = 1,keepdims = True) /m\n    # \u8fd4\u56de\u5305\u542b\u6240\u6709\u68af\u5ea6\u7684\u5b57\u5178 grades\n    return grades  \n\n\ndef update_grades(parameters,grades,learning_rate):\n    layers = len(parameters)//2\n    for i in range(1,layers+1):\n        parameters[\"w\"+str(i)] -= learning_rate * grades[\"dw\"+str(i)]\n        parameters[\"b\"+str(i)] -= learning_rate * grades[\"db\"+str(i)]\n    return parameters\n\ndef compute_loss(al,y):\n    return np.mean(np.square(al-y))\n\ndef load_data():\n    x = np.arange(0.0,1.0,0.01)\n    y =20* np.sin(2*np.pi*x)\n    plt.scatter(x,y)\n    return x,y\n\nx,y = load_data()\nx = x.reshape(1,100)\ny = y.reshape(1,100)\nplt.scatter(x,y)\nparameters = init_parameters([1,25,1])\nal = 0\n# for i in range(4000):\nfor i in range(1):\n    caches,al = forward(x, parameters)\n    grades = backward(parameters, caches, al, y)\n    parameters = update_grades(parameters, grades, learning_rate= 0.3)\n    # if i %100 ==0:\n    #     print(compute_loss(al, y))\n# plt.scatter(x,al)\n# plt.show()\n</code></pre>"},{"location":"bagu/machinelearning/kmeans/","title":"\u624b\u6495kmeans","text":""},{"location":"bagu/machinelearning/kmeans/#kmeans","title":"\u624b\u6495kmeans","text":"2024-11-15 19:19:112025-09-28 12:54:04 <p> \u7ea6 5 \u4e2a\u5b57  71 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> Python<pre><code>import numpy as np\ndef kmeans(data, k, thresh=1, max_iterations=100):\n  centers = data[\n     np.random.choice(data.shape[0], k, replace=False)\n     ]\n  for _ in range(max_iterations):\n    distances = np.linalg.norm(\n       data[:, None] - centers, \n       axis=2\n       ) # n,k,d\n    labels = np.argmin(distances, axis=1)\n    new_centers = np.array(\n       [data[labels == i].mean(axis=0) for i in range(k)]\n       )\n    if np.all(centers == new_centers):break\n    center_change = np.linalg.norm(new_centers - centers)\n    if center_change &lt; thresh:break\n    centers = new_centers\n  return labels, centers\ndata = np.random.rand(100, 2)  # 100\u4e2a\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u6709\u4e24\u4e2a\u7279\u5f81\nk = 3  # \u805a\u7c7b\u6570\u4e3a3\nlabels, centers = kmeans(data, k)\nprint(\"\u7c07\u6807\u7b7e:\", labels)\nprint(\"\u805a\u7c7b\u4e2d\u5fc3\u70b9:\", centers)\n</code></pre> <p>\u6ce8\u91ca\uff1a</p> Python<pre><code>import numpy as np\ndef kmeans(data, k, thresh=1, max_iterations=100):\n  # data \uff1a n_samples * feature_dim\n  # \u4ece data \u4e2d\u968f\u673a\u9009\u62e9 n_clusters \u4e2a\u4e0d\u540c\u7684\u6837\u672c\u7d22\u5f15\n  # centers : n_clusters * feature_dim\n  # replace=False\uff1a\u8868\u793a\u5728\u9009\u62e9\u6837\u672c\u65f6\u4e0d\u5141\u8bb8\u91cd\u590d\uff0c\u5373\u6bcf\u4e2a\u6837\u672c\u53ea\u80fd\u88ab\u9009\u62e9\u4e00\u6b21\u3002\n  centers = data[np.random.choice(data.shape[0], k, replace=False)]\n  for _ in range(max_iterations):\n    # data \uff1a n_smaples * feature_dim\n    # data[:, None]\uff1an_samples * 1 * feature_dim  \\ n 1 d\n    # centers \uff1a n_clusters * feature_dim \\ k d\n    # data[:, None] - centers : n_samples * n_clusters * feature_dim \\ n k d\n    # np.linalg.norm : n_samples * n_clusters\n    distances = np.linalg.norm(data[:, None] - centers, axis=2)\n    # labels : n_samples * 1\n    # distances : n_samples * n_clusters\n    # np.argmin \u51fd\u6570\u8fd4\u56de\u6307\u5b9a\u8f74\u4e0a\u6700\u5c0f\u503c\u7684\u7d22\u5f15\u3002\n    # axis=1 \u8868\u793a\u6cbf\u7740\u7b2c 1 \u8f74\uff08\u5373\u5217\uff09\u5bfb\u627e\u6700\u5c0f\u503c\u7684\u7d22\u5f15\u3002\n    labels = np.argmin(distances, axis=1)\n    '''\n        \u8ddd\u79bb\u77e9\u9635:\n        [[0.5 1.2 0.9]\n        [1.  0.8 1.5]\n        [0.3 0.4 0.2]\n        [1.1 0.7 0.6]\n        [0.9 1.3 0.4]]\n        \u7c07\u6807\u7b7e:\n        [0 1 2 2 2]\n        \u7c07\u6807\u7b7e\u7684\u5f62\u72b6: (5,)\n    '''\n    new_centers = np.array([data[labels == i].mean(axis=0) for i in range(k)])\n\n    # np.all(centers == new_centers) \u8fd4\u56de True\uff0c\u8f93\u51fa\u7ed3\u679c\u4e3a \"\u4e2d\u5fc3\u70b9\u5df2\u6536\u655b\"\u3002\n    if np.all(centers == new_centers):\n      break\n    # \u8ba1\u7b97 new_centers \u548c centers \u4e4b\u95f4\u7684\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\uff08\u6216\u8303\u6570\uff09\u3002\n    center_change = np.linalg.norm(new_centers - centers)\n    if center_change &lt; thresh:\n        break\n    centers = new_centers\n  return labels, centers\n\ndata = np.random.rand(100, 2)  # 100\u4e2a\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u6709\u4e24\u4e2a\u7279\u5f81\nk = 3  # \u805a\u7c7b\u6570\u4e3a3\nlabels, centers = kmeans(data, k)\nprint(\"\u7c07\u6807\u7b7e:\", labels)\nprint(\"\u805a\u7c7b\u4e2d\u5fc3\u70b9:\", centers)\n</code></pre>"},{"location":"bagu/questions/1_questions/","title":"\u9762\u8bd5\u95ee\u9898","text":""},{"location":"bagu/questions/1_questions/#_1","title":"\u9762\u8bd5\u95ee\u9898","text":"2024-12-20 22:49:272025-09-28 12:54:04 <p> \u7ea6 30 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\uff081\uff09\u9762\u8bd5\u9898\uff1a\u8bf7\u539f\u7406\u4e0a\u89e3\u91ca\u4e3a\u4ec0\u4e48 Bert \u7684\u4e09\u4e2a Embedding \u53ef\u4ee5\u76f4\u63a5\u52a0\u5728\u4e00\u8d77</p> <p> </p>"},{"location":"learning/","title":"\u6df1\u5ea6\u5b66\u4e60","text":""},{"location":"learning/#_1","title":"\u6df1\u5ea6\u5b66\u4e60","text":"2024-11-15 20:00:582025-09-28 12:54:06 <p> \u7ea6 15 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>Note</p> <p>\ud83c\udf08 \u6df1\u5ea6\u5b66\u4e60\u76f8\u5173,\u4e03\u4e03\u516b\u516b</p>"},{"location":"learning/0_pdfNotes/","title":"\ud83d\udcd2","text":""},{"location":"learning/0_pdfNotes/#_1","title":"\ud83d\udcd2","text":"2025-03-19 10:51:172025-09-28 12:54:04 <p> \u7ea6 204 \u4e2a\u5b57  17 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u8fd9\u91cc\u90fd\u662f\u4e00\u4e9b\u4e4b\u524d\u7684\u7b14\u8bb0\u3002</p>"},{"location":"learning/0_pdfNotes/#_2","title":"\u5377\u79ef","text":"\u81a8\u80c0\u5377\u79ef \u67e5\u770b \u624b\u5199\u5e76\u9a8c\u8bc1\u6ed1\u52a8\u76f8\u4e58\u5b9e\u73b0PyTorch \u67e5\u770b \u624b\u5199\u5e76\u9a8c\u8bc1\u5411\u91cf\u5185\u79ef\u5b9e\u73b0pytorch\u4e8c\u7ef4\u5377\u79ef \u67e5\u770b PyTorch nn.Conv2d\u5377\u79ef\u7f51\u7edc\u4f7f\u7528\u6559\u7a0b \u67e5\u770b CNN \u5377\u79ef\u7f51\u7edc\u7ec4\u4f1a\u8bb2\u89e3 ppt \u67e5\u770b"},{"location":"learning/0_pdfNotes/#transformer","title":"transformer","text":"transformer\u5b66\u4e60\u7b14\u8bb0 \u67e5\u770b Encoder\u539f\u7406\u7cbe\u8bb2\u53ca\u5176PyTorch\u9010\u884c\u5b9e\u73b0 \u67e5\u770b Decoder\u539f\u7406\u7cbe\u8bb2\u53ca\u5176PyTorch\u9010\u884c\u5b9e\u73b0 \u67e5\u770b Transformer\u6a21\u578b\u603b\u7ed3 &amp; maksed loss\u7684\u5b9e\u73b0 \u67e5\u770b Transformer\u4ee3\u7801(\u6e90\u7801Pytorch\u7248\u672c) \u67e5\u770b ViT\u5b66\u4e60\u7b14\u8bb0 \u67e5\u770b vision Transformer\u7684\u539f\u7406\u4e0e\u96be\u70b9\u6e90\u7801\u5b9e\u73b0 \u67e5\u770b SwinTransformer \u5b66\u4e60\u7b14\u8bb0 \u67e5\u770b"},{"location":"learning/0_pdfNotes/#_3","title":"\u65f6\u5e8f\u6a21\u578b","text":"Pytorch RNN\u539f\u7406\u53ca\u624b\u5199\u590d\u73b0 \u67e5\u770b Pytorch LSTM\u539f\u7406\u53ca\u624b\u5199\u590d\u73b0 \u67e5\u770b"},{"location":"learning/0_pdfNotes/#unet","title":"UNet","text":"UNet\u7f51\u7edc\u67b6\u6784 \u67e5\u770b UNet\u7f51\u7edc\u67b6\u6784\u8bad\u7ec3 \u67e5\u770b"},{"location":"learning/1/","title":"5\u79cd\u5f52\u4e00\u5316\u65b9\u6cd5","text":""},{"location":"learning/1/#5","title":"5\u79cd\u5f52\u4e00\u5316\u65b9\u6cd5","text":"2024-11-25 22:33:462025-09-28 12:54:04 <p> \u7ea6 3785 \u4e2a\u5b57  464 \u884c\u4ee3\u7801  31 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 25 \u5206\u949f</p> <p>45\u3001\u4e94\u79cd\u5f52\u4e00\u5316\u7684\u539f\u7406\u4e0ePyTorch\u9010\u884c\u624b\u5199\u5b9e\u73b0\u8bb2\u89e3(BatchNorm/LayerNorm/InsNorm/GroupNorm/WeightNorm)</p> <p>\u56fe\u6e90</p> <p></p> <p></p>"},{"location":"learning/1/#batchnorm","title":"BatchNorm","text":""},{"location":"learning/1/#_1","title":"\u56fe\u793a","text":"<p>\u6279\u5f52\u4e00\u5316\u3001\u901a\u9053\u7ea7\u522b\u7684\u5f52\u4e00\u5316</p>"},{"location":"learning/1/#apibatchnorm1d-2d","title":"\u5b98\u7f51api\uff0cBatchNorm1D &amp; 2D","text":"<p>BatchNorm1D\u7684\u8f93\u5165\uff1aNCL\uff0c\u7528\u4e8eNLP</p> <p></p> <p>BatchNorm2D\u7684\u8f93\u5165\u662f\u56db\u7ef4\u7684\uff0c\u7528\u4e8e\u56fe\u50cf</p> <p></p> <p>\u4e00\u4e2a\u662f\u4e09\u7ef4tensor\u4f5c\u4e3a\u8f93\u5165</p> <p>\u4e00\u4e2a\u662f\u56db\u7ef4tensor\u4f5c\u4e3a\u8f93\u5165</p>"},{"location":"learning/1/#batchnorm1d","title":"BatchNorm1D","text":"<ul> <li>\u9996\u5148\uff0c\u4f4d\u4e8etorch.nn\u6a21\u5757\u4e0b\uff0c\u662f\u4e00\u4e2aclass\uff0c\u6240\u4ee5\u8981\u7528\u7684\u8bdd\uff0c\u9700\u8981\u5b9e\u4f8b\u5316</li> <li>\u63a5\u4e0b\u6765\uff0c\u770b\u5b9e\u4f8b\u5316\u9700\u8981\u63a5\u6536\u7684\u53c2\u6570\uff1a</li> <li>num features\uff1a\u8f93\u5165\u5f20\u91cf\u7684\u7279\u5f81\u7ef4\u5ea6\uff0c\u6216\u8005\u901a\u9053\u7684\u6570\u76ee\uff0c\u6216\u8005embedding\u7684\u5927\u5c0f</li> <li>eps\uff1a5\u79cd\u5f52\u4e00\u5316\u90fd\u9700\u8981\u7684eps\uff0c\u5206\u6bcd\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u8ba9\u5206\u6bcd\u52a0\u4e0a\u4e00\u4e2a\u5fae\u5c0f\u7684\u91cf\uff0c\u4f7f\u5f97\u9664\u6cd5\u80fd\u591f\u6b63\u5e38\u8fdb\u884c\uff0c\u9ed8\u8ba41e-05</li> <li>momentum\uff1a\u52a8\u91cf<ul> <li>\u6279\u5f52\u4e00\u5316\u5728\u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\u7684\u65f6\u5019\uff0cmomentum\u901a\u5e38\u9700\u8981\u8ddftrack_running_sate\u8054\u5408\u8d77\u6765\u7406\u89e3\uff0c\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u7684\u7edf\u8ba1\u91cf \u901a\u5e38\u662f\u901a\u8fc7\u6ed1\u52a8\u5e73\u5747\u8ba1\u7b97\u51fa\u6765\u4e86\uff0c\u800c\u4e0d\u662f\u5355\u4e00\u65f6\u523b\u7684mini batch\uff0c\u662f\u4e00\u4e2a\u7d2f\u8ba1\u7684\u8fc7\u7a0b\uff0c\u4e3a\u4e86\u63d0\u9ad8\u4f30\u8ba1\u7684\u51c6\u786e\u5ea6</li> </ul> </li> <li>affine\uff1a<ul> <li>\u4e5f\u5c31\u662f gamma &amp; beta\uff0c\u4e5f\u5c31\u662f\u518d\u505a\u5b8c\u5f52\u4e00\u5316\u4ee5\u540e\uff0c\u4e5f\u53ef\u4ee5\u52a0\u4e00\u4e2a\u6620\u5c04\uff0c\u5c06\u5176\u6620\u5c04\u5230\u4e00\u4e2a\u65b0\u7684\u5206\u5e03\u4e0a\uff0c\u505a\u4e00\u4e2arescale\u548crecenter</li> </ul> </li> </ul> <p>\u5b98\u7f51\u5b9a\u4e49\uff1a</p> <p></p> <p>\uff08\u89e3\u91ca\u5b98\u7f51\u5b9a\u4e49\uff09\u5747\u503c\u548c\u6807\u51c6\u5dee\u662f\u7ecf\u8fc7\u6574\u4e2amini_batch</p> <p>\u4e00\u53e5\u8bdd\u8bf4\u660e BatchNorm\uff1aper channel across mini-batch</p> <p>\u8d2f\u7a7f\u6574\u4e2amini batch\u8ba1\u7b97\u7edf\u8ba1\u91cf\uff0c\u6bcf\u4e2a\u901a\u9053\u5355\u72ec\u53bb\u7b97\u7684</p> <p>gamma \u548c beta \u662f\u53ef\u5b66\u4e60\u7684\u5411\u91cf\uff0c\u7ef4\u5ea6\u90fd\u662fC\uff0c\u9ed8\u8ba4\u7684\u60c5\u51b5\u4e0b $\\gamma = 1\u3001\\beta=0 $</p> <p>\u6807\u51c6\u5dee\u7528\u7684\u662f\u6709\u504f\u4f30\u8ba1\uff0c\u4e5f\u5c31\u662f\u8ba1\u7b97\u7684\u6807\u51c6\u5dee\u662f \\(\\frac{1}{n}\\)\uff0c\u5f3a\u8c03\u8fd9\u53e5\u8bdd\u7684\u76ee\u7684\u662f \uff0c\u5728\u8ba1\u7b97\u65b9\u5dee\u7684\u65f6\u5019\uff0c\u8981\u7528 \\(\\mathrm{unbiased=False}\\)\uff0c\u8fd9\u91cc\u7528\u5f97\u662f\u6709\u504f\u4f30\u8ba1</p> <p>\u5728\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5728\u8bad\u7ec3\u4e2d\uff0c\u4f1a\u4e0d\u65ad\u7684\u8bb0\u5f55\u5386\u53f2\u7684\u5747\u503c\u548c\u65b9\u5dee\uff0c\u5e76\u4e14\u4f7f\u75280.1\u7684\u52a8\u91cf\uff0c\u6765\u505a\u79fb\u52a8\u7684\u4f30\u8ba1\uff0c\u5f53\u8bad\u7ec3\u7ed3\u675f\u4ee5\u540e\uff0c\u7528\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u4f30\u8ba1\u91cf\u6765\u505a inference</p> <p>\u4e5f\u53ef\u4ee5\u8bbe\u7f6e track running states\u7b49\u4e8efalse\uff0c\u5c31\u662f\u4e0d\u8981\u8bb0\u5f55\u5386\u53f2\u7684\u79fb\u52a8\u7684\u503c</p> <p>\u4ee5\u4e0a\u662fapi\u7684\u4ecb\u7ecd</p> <p>\u63a5\u4e0b\u6765 \u81ea\u5df1\u5199\u4e00\u4e2aBatchNorm \u66f4\u597d\u7684\u7406\u89e3</p> <ul> <li> <p> NLP\u7684\u6807\u51c6\u6570\u636e\u683c\u5f0f\uff1ainputx = torch.randn(batch_size,times_steps,embedding_dim) # \\(N*L*C\\)</p> </li> <li> <p> \u5b9e\u4f8b\u5316\uff0c\u63a5\u6536\u7684\u8f93\u5165\uff08\u7279\u5f81\u7ef4\u5ea6\uff0c\u662f\u5426\u8fdb\u884c\u4eff\u5c04\u53d8\u6362\uff09\uff1abatch_norm_op = torch.nn.BatchNorm1d(embedding_dim,affine=False)</p> </li> <li> <p> batchnorm\u7684forward\u51fd\u6570 \u63a5\u6536\u7684\u6570\u636e\u96c6\u683c\u5f0f\u662f BDN  b\u8868\u793abatch size\uff1bD\u8868\u793amodel dim\uff1bN\u8868\u793a\u5e8f\u5217\u957f\u5ea6\uff08\u7b26\u53f7\u8868\u793a\u65b9\u6cd5\u7684\u4e0d\u540c</p> </li> </ul> <p><code>bn_y = batch_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)</code></p> Python<pre><code>import torch\n\nbatch_size = 2\ntimes_steps = 3\nembedding_dim = 4\n\ninputx = torch.randn(batch_size,times_steps,embedding_dim) # N*L*C\n\n# 1. \u5b9e\u73b0batch_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528 batch_norm API\nbatch_norm_op = torch.nn.BatchNorm1d(embedding_dim,affine=False)\nbn_y = batch_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n\n## \u624b\u5199batch_norm\nbn_mean = inputx.mean(dim=(0,1),keepdim=True)\nbn_std = inputx.std(dim=(0,1),unbiased=False,keepdim=True)\nverify_bn_y = (inputx - bn_mean)/(bn_std+1e-5)\nprint(bn_y)\nprint(verify_bn_y)\nprint(torch.allclose(bn_y,verify_bn_y))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Python<pre><code>tensor([[[-0.3771,  1.7863, -1.0572,  0.2856],\n         [-0.7956, -0.0363, -0.7429, -0.1670],\n         [ 2.0838,  0.7039,  1.1345,  0.7286]],\n\n        [[-0.5775, -0.3680, -1.1160, -1.3169],\n         [ 0.3298, -1.0699,  1.2153, -1.0909],\n         [-0.6634, -1.0160,  0.5663,  1.5606]]])\ntensor([[[-0.3771,  1.7863, -1.0572,  0.2856],\n         [-0.7956, -0.0363, -0.7429, -0.1670],\n         [ 2.0838,  0.7039,  1.1345,  0.7286]],\n\n        [[-0.5775, -0.3680, -1.1160, -1.3169],\n         [ 0.3298, -1.0699,  1.2153, -1.0909],\n         [-0.6634, -1.0160,  0.5663,  1.5606]]])\nTrue\n</code></pre> <p>\u89e3\u91ca\uff1a\u53bb\u770b\u56fe\u89e3BN&amp;LN</p> <p>\u9700\u8981\u5f3a\u8c03\uff1a</p> <ul> <li>\u5728batch\u548c\u957f\u5ea6\u8fd9\u4e00\u7ef4\u8ba1\u7b97\u7edf\u8ba1\u91cf</li> <li>\u8ba1\u7b97\u6807\u51c6\u5dee\u7684\u65f6\u5019\uff0c\u7528\u7684\u662f\u6709\u504f\u4f30\u8ba1\uff0c\u8bbe\u7f6eunbiased=false</li> </ul>"},{"location":"learning/1/#layernorm","title":"LayerNorm","text":"<p>\u5c42\u5f52\u4e00\u5316\u7684\u6982\u62ec\uff1aper sample\u3001per Layer\uff0c\u5bf9\u5355\u4e00\u6837\u672c\u3001\u6bcf\u4e00\u4e2a\u5c42 \u5355\u72ec\u8ba1\u7b97\uff0c\u4e0d\u9700\u8981\u8003\u8651minibatch</p> <p>LayerNorm\u6700\u5178\u578b\u7684\u4f7f\u7528\u573a\u666f\uff1aNLP</p> <p>\u628a\u7f51\u7edc\u4e2d \u6bcf\u4e00\u6b21 \u6bcf\u4e00\u4e2a\u65f6\u523b \u5f53\u6210\u4e00\u5c42</p> <p>\u6bcf\u4e2a\u65f6\u523b embedding dim\u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee </p> <ul> <li> \u4e3a\u4ec0\u4e48nlp\u4e2d\u4f7f\u7528LN\uff1f</li> </ul> <p>\u5e94\u4e3anlp\u4e2d\uff0c\u4e0d\u540c\u53e5\u5b50\u957f\u5ea6\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4 \u5bf9\u4e8e\u6bcf\u4e2abatch\u4e2d\u7684 \u6216\u8005 \u53e5\u5b50\u4e2d \u8bcd\u6570\u662f\u4e0d\u4e00\u6837\u7684\uff1b\u6216\u8005\u6d4b\u8bd5\u65f6\uff0c\u53e5\u5b50\u7684\u957f\u5ea6\u53ef\u80fd\u8bad\u7ec3\u65f6\u4e5f\u6ca1\u89c1\u8fc7\uff0c\u800cBatchNorm\u662facross batch\u7684\uff0c\u6240\u4ee5\u6700\u597d\u4fdd\u8bc1batch\u5185\u90e8L\u662f\u56fa\u5b9a\u7684</p> <p>\u4e00\u53e5\u8bdd\uff1a\u53e5\u5b50\u4e2d\u8bcd\u7684\u6570\u91cf\u5e76\u4e0d\u4e00\u6837</p>"},{"location":"learning/1/#_2","title":"\u56fe\u793a","text":""},{"location":"learning/1/#_3","title":"\u8bed\u8a00\u63cf\u8ff0\u5b9e\u9645\u610f\u4e49","text":""},{"location":"learning/1/#for-nlp","title":"for nlp","text":"<ul> <li> LayerNorm\u5bf9 \u6bcf\u4e2a\u8bcd\u8fdb\u884c\u5f52\u4e00\u5316  bnd   dim=2\uff1f  \uff08\u6709\u51e0\u4e2a\u8bcd\u5c31\u6709\u5f97\u5230\u51e0\u4e2a\u5747\u503c\u548c\u65b9\u5dee\uff0c\u7136\u540e\u8fdb\u884c\u5f52\u4e00\u5316\uff09b\u00d7n\u00d71</li> </ul> <p>\u4e3e\u6570\u5b66\u4f8b\u5b50\uff1a2\u4e2a\u53e5\u5b50\u3001\u6bcf\u4e2a\u53e5\u5b503\u4e2a\u8bcd\uff0c\u6bcf\u4e2a\u8bcd\u7684\u7ef4\u5ea64\uff0c\u90a3\u4e48\u6211\u4eec\u5f97\u52306\u4e2a\u5747\u503c\u548c\u65b9\u5dee\uff0c\u6240\u4ee5\u5f52\u4e00\u5316\u540e\u7684\u7ef4\u5ea6  2\u00d73\u00d71</p> <p>\\(\\rightarrow\\)</p> <p>\\(\\rightarrow\\)</p> <p>\\(\\rightarrow\\)</p> <p>\\(\\rightarrow\\)</p> <p>\\(\\rightarrow\\)</p> <p>\\(\\rightarrow\\)</p> <ul> <li> BatchNorm \u5bf9\u8bcd\u7684\u7279\u5f81\u7ef4\u5f52\u4e00\u5316 bnd dim=0,1  1\u00d71\u00d7d\uff08\u6709\u51e0\u4e2a\u7279\u5f81\u7ef4\u5ea6\uff0c\u5c31\u4f1a\u5f97\u5230\u51e0\u4e2a\u5747\u503c\u548c\u65b9\u5dee\uff09  \\(\\downarrow\\) \\(\\downarrow\\) \\(\\downarrow\\) \\(\\downarrow\\) \\(\\downarrow\\) \\(\\downarrow\\)</li> </ul> <p>2\u00d73\u00d74 \u5f97\u5230 1\u00d71\u00d74 \u4e5f\u5c31\u662f4\u4e2a\u5747\u503c\uff0c\u7ec6\u8282\u4e5f\u4e0d\u7528\u6263\u8fd9\u4e48\u7ec6\uff0c\u76f4\u63a5keepdim=true</p>"},{"location":"learning/1/#for-cv","title":"for cv","text":"<ul> <li> <p> LayerNorm  bchw \u770b\u505a chw \u540c\u65f6\u5f52\u4e00\u5316\uff0c\u6709\u51e0\u4e2achw\u6709\u51e0\u4e2a\u5f52\u4e00\u5316\u5747\u503c\u548c\u65b9\u5dee\uff1bbnd\uff0c\u6709\u51e0\u4e2abn\u6709\u51e0\u4e2anlp\u5f52\u4e00\u5316\u7684\u5747\u503c\u548c\u65b9\u5dee \uff1bc \u4f9d\u7136\u662f\u72ec\u7acb\u7684\u8bcd\uff0c\u8868\u8fbe\u4e0d\u540c\u7684\u8bed\u4e49\uff1b</p> </li> <li> <p> BatchNorm \u628a \u901a\u9053 \u4f5cnlp\u4e2d\u7684\u72ec\u7acb \u8bcd\u3001token\uff0c\u5bf9\u4e8e\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u4ee5\u53ca\u7a7a\u95f4\u5206\u5e03 \u4e0d\u505a\u533a\u5206 \u53ef\u4ee5\u7406\u89e3\u4e3a bc(hw)\uff0c\u7c7b\u6bd4\u5230nlp\uff0c\u4e00\u4e2a\u901a\u9053\u7684\u4fe1\u606f\uff0c\u7531\u957f\u5ea6\u4e3ah*w\u7684\u5411\u91cf\u8868\u793a\uff0c\u4fdd\u7559\u901a\u9053\u4fe1\u606f\uff0c\u6cbf\u7740\u6837\u672c\u7ef4\u5ea6\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u5176\u5b9e\u4e5f\u662f\u5f15\u5165\u4e86\u5176\u4ed6\u6837\u672c\u7684\u566a\u58f0   bchw  $ \\rightarrow$  b\u00d7c\u00d7hw  dim=0,2,3</p> </li> </ul> <p>\u6570\u5b66\u5c0f\u4f8b\u5b50\uff1a4\u5f20\u56fe\uff0c3\u901a\u9053\uff0c2\u00d72\u7684\u56fe\uff0cBN\u4ee5\u540e\uff0c\u5f97\u5230 3\u4e2a\u5747\u503c\u548c\u65b9\u5dee </p> <p>4\u00d73\u00d72\u00d72 \\(\\rightarrow\\) 1\u00d73\u00d71\u00d71</p> <p>BatchNorm\u7684api\u4e2d\uff0c\u9700\u8981\u7684\u6570\u636e\u683c\u5f0f\u662fNCL\uff0c\u800c\u4e0d\u662f\u5e38\u7528\u7684NLC\uff0c\u53ef\u80fd\u539f\u56e0\u5c31\u662fbn\u901a\u5e38\u7528\u5728cv</p>"},{"location":"learning/1/#cv-nlp-bn-ln","title":"cv nlp bn ln","text":"<ul> <li> <p> \u5927\u6982\u662f \u7406\u89e3\u4e3a</p> </li> <li> <p>bn\uff08\u5f97\u5230\u5747\u503c\u5411\u91cf\uff09</p> </li> </ul> <p>4\u5f20\u56fe\uff0c\u6bcf\u5f20\u56fe\u7247 3\u4e2a\u901a\u9053\u7279\u5f81\uff0c\u6bcf\u4e2a\u901a\u9053 \u75314\u4e2a\u5143\u7d20\u8868\u8fbe\uff082\u00d72\uff09\uff08\u5f97\u52303\u4e2a\u5747\u503c\uff09\uff08cv&amp;bn\uff09</p> <p>2\u4e2a\u53e5\u5b50\uff0c\u6bcf\u4e2a\u53e5\u5b503\u4e2a\u8bcd\uff0c4\u7ef4\u5ea6\uff08\u5f97\u52304\u4e2a\u5747\u503c\uff09\uff08nlp&amp;bn\uff09</p> <ul> <li> <p>ln</p> </li> <li> <p> 4\u5f20\u56fe\uff0c3\u4e2a\u901a\u9053\u7279\u5f81\uff0c\u6bcf\u4e2a\u901a\u9053\u7531\u957f\u5ea6\u4e3a4\u7684\u5411\u91cf\u8868\u8fbe\uff082\u00d72\uff09\uff0c\u5f97\u52304\u4e2a\u5747\u503c\u548c\u65b9\u5dee\uff08per sample\u3001per layer\uff09\uff08cv  ln\uff09</p> </li> <li> 4\u4e2a\u53e5\u5b50\uff0c\u6bcf\u4e2a\u53e5\u5b503\u4e2a\u8bcd\uff0c\u6bcf\u4e2a\u8bcd\u5d4c\u51654\u4e2a\u7ef4\u5ea6\uff0c\u5f97\u523012\u4e2a\u5747\u503c\u548c\u65b9\u5dee\uff08ln\u3001nlp\uff09</li> </ul>"},{"location":"learning/1/#api","title":"\u5b98\u65b9api","text":"<p>LayerNorm\u53ea\u6709\u4e00\u4e2aapi</p> <p>\u540c\u6837\u4e5f\u662f\u4e00\u4e2aclass\uff0c\u5982\u679c\u8981\u53bb\u5b9e\u4f8b\u5316\u7684\u8bdd\uff0c\u53ea\u9700\u8981\u6307\u5b9a\u4e00\u4e0b \u88ab\u5f52\u4e00\u5316\u7684\u5f62\u72b6\uff0c\u4ee5\u53ca\u662f\u5426\u9700\u8981\u8fdb\u884c\u7f29\u653e\u53d8\u6362</p> <p>\u4e5f\u5c31\u662f\u8bf4\u63a5\u6536\u7684\u8f93\u5165\uff1a</p> <ul> <li>normalized_shape\uff1a\u88ab\u5f52\u4e00\u5316\u7684\u5f62\u72b6</li> <li>elementwise_affine\uff1a\u662f\u5426\u9700\u8981\u8fdb\u884c\u7f29\u653e\u53d8\u6362</li> </ul> <p>\u63a5\u4e0b\u6765\u770b\u5b9a\u4e49\uff1a</p> <p></p> <ul> <li>\u8fd9\u91cc\u7684\u5747\u503c\u548c\u65b9\u5dee\u662f\u5728\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u8ba1\u7b97\u7684\uff08over the last dimension\uff09\u5bf9\u4e8e over across minibatch</li> <li>D\u5c31\u662f \u6211\u4eec\u8981\u4f20\u5165\u7684 normalized shape</li> <li>\u5728nlp\u4e2d \u901a\u5e38\u53ea\u9700\u8981\u4f20\u5165\u6807\u91cf\u5c31\u597d\u4e86\uff0c\u5c31\u662f\u8ba1\u7b97\u6700\u540e\u7684embedding\u7684\u7ef4\u5ea6</li> </ul>"},{"location":"learning/1/#_4","title":"\u4ee3\u7801\u5b9e\u73b0","text":"Python<pre><code>import torch\n\nbatch_size = 2\ntimes_steps = 3\nembedding_dim = 4\n\ninputx = torch.randn(batch_size,times_steps,embedding_dim) # N*L*C\n# 2. \u5b9e\u73b0layer_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528 layer_norm API\nlayer_norm_op = torch.nn.LayerNorm(embedding_dim,elementwise_affine=False)\nln_y = layer_norm_op(inputx)\n\n## \u624b\u5199layer_norm\nln_mean = inputx.mean(dim=-1,keepdim=True)\nln_std = inputx.std(dim=-1,keepdim=True,unbiased=False)\nverify_bn_y = (inputx - ln_mean)/(ln_std + 1e-05)\n# print(ln_mean.shape) torch.Size([2, 3, 1])\n# print(ln_std.shape)  torch.Size([2, 3, 1])\n# print(ln_y.shape)   torch.Size([2, 3, 4])\n# print(verify_bn_y.shape)    torch.Size([2, 3, 4])\n# print(torch.allclose(ln_y,verify_bn_y)) True\n</code></pre> <p>bn\uff08\u5f97\u5230\u5747\u503c\u5411\u91cf\uff09</p> <p>4\u5f20\u56fe\uff0c\u6bcf\u5f20\u56fe\u7247 3\u4e2a\u901a\u9053\u7279\u5f81\uff0c\u6bcf\u4e2a\u901a\u9053 \u75314\u4e2a\u5143\u7d20\u8868\u8fbe\uff082\u00d72\uff09\uff08\u5f97\u52303\u4e2a\u5747\u503c\uff09\uff08cv&amp;bn\uff09</p> <p>4322\u21921311</p> <p>2\u4e2a\u53e5\u5b50\uff0c\u6bcf\u4e2a\u53e5\u5b503\u4e2a\u8bcd\uff0c4\u7ef4\u5ea6\uff08\u5f97\u52304\u4e2a\u5747\u503c\uff09\uff08nlp&amp;bn\uff09</p> <p>234\u2192114</p> <p>ln(\u5f97\u5230\u5747\u503c\u77e9\u9635)</p> <p>\u5bf9\u4e8eLN \u4e00\u5b9a\u8981\u660e\u767d\uff1aper sample\u3001per layer</p> <p>\u5bf9\u4e8eCV per sample\u5c31\u662f\u4e00\u5f20\u56fe\u7247</p> <p>\u5bf9\u4e8eNLP per layer \u5c31\u662f\u4e00\u4e2a\u8bcd</p> <p>4\u5f20\u56fe\uff0c\u6bcf\u5f20\u56fe\u7247 3\u4e2a\u901a\u9053\u7279\u5f81\uff0c\u6bcf\u4e2a\u901a\u9053 \u75314\u4e2a\u5143\u7d20\u8868\u8fbe\uff082\u00d72\uff09\uff08\u5f97\u52304\u4e2a\u5747\u503c per sample\uff09</p> <p>4322 \u21924111</p> <p>2\u4e2a\u53e5\u5b50\uff0c\u6bcf\u4e2a\u53e5\u5b503\u4e2a\u8bcd\uff0c4\u7ef4\u5ea6\uff08\u5f97\u52306\u4e2a\u5747\u503c\uff09\uff08nlp&amp;bn\uff09</p> <p>\uff08234\u2192231\uff09</p>"},{"location":"learning/1/#bnlnnlpcv","title":"\u4ee3\u7801\u5b9e\u73b0 BN\u3001LN&amp;NLP&amp;CV","text":"<p>nlp&amp;BN&amp;LN</p> Python<pre><code>import torch\n\nbatch_size = 2\ntimes_steps = 3\nembedding_dim = 4\n\ninputx = torch.randn(batch_size,times_steps,embedding_dim) # N*L*C\n\n# 1. \u5b9e\u73b0batch_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528 batch_norm API\nbatch_norm_op = torch.nn.BatchNorm1d(embedding_dim,affine=False)\nbn_y = batch_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n\n## \u624b\u5199batch_norm\nbn_mean = inputx.mean(dim=(0,1),keepdim=True)\nbn_std = inputx.std(dim=(0,1),unbiased=False,keepdim=True)\nverify_bn_y = (inputx - bn_mean)/(bn_std+1e-5)\n# print(bn_mean.shape) torch.Size([1, 1, 4])\n# print(bn_std.shape) torch.Size([1, 1, 4])\n# print(bn_y.shape)   torch.Size([2, 3, 4])\n# print(verify_bn_y.shape)    torch.Size([2, 3, 4])\n# print(torch.allclose(bn_y,verify_bn_y)) True\n\n# 2. \u5b9e\u73b0layer_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528 layer_norm API\nlayer_norm_op = torch.nn.LayerNorm(embedding_dim,elementwise_affine=False)\nln_y = layer_norm_op(inputx)\n\n## \u624b\u5199layer_norm\nln_mean = inputx.mean(dim=-1,keepdim=True)\nln_std = inputx.std(dim=-1,keepdim=True,unbiased=False)\nverify_bn_y = (inputx - ln_mean)/(ln_std + 1e-05)\n# print(ln_mean.shape) torch.Size([2, 3, 1])\n# print(ln_std.shape)  torch.Size([2, 3, 1])\n# print(ln_y.shape)   torch.Size([2, 3, 4])\n# print(verify_bn_y.shape)    torch.Size([2, 3, 4])\n# print(torch.allclose(ln_y,verify_bn_y)) True\n</code></pre> <p>CV&amp;BN&amp;LN</p> Python<pre><code>import torch\n\nbatch_size = 4\nchannels = 3\nh,w = 2,2\n\ninputx = torch.randn(batch_size,channels,h,w) # BCHW \u53ea\u8981\u7ef4\u5ea6\u662f\u6b63\u786e\u7684\uff0c\u6570\u5b57\u53ef\u4ee5\u968f\u4fbf\u751f\u6210\n\n# 1. \u5b9e\u73b0batch_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528 batch_norm API\nbatch_norm_op = torch.nn.BatchNorm2d(channels,affine=False)\nbn_y = batch_norm_op(inputx) # torch.Size([4, 3, 2, 2])\n\n## \u624b\u5199batch_norm\nbn_mean = inputx.mean(dim=(0,2,3),keepdim=True) # torch.Size([1, 3, 1, 1])\nbn_std = inputx.std(dim=(0,2,3),unbiased=False,keepdim=True) # torch.Size([1, 3, 1, 1])\nverify_bn_y = (inputx - bn_mean)/(bn_std+1e-5) # torch.Size([4, 3, 2, 2])\n\n# print(bn_mean.shape) \n# print(bn_std.shape) \n# print(bn_y.shape)   \n# print(verify_bn_y.shape)    \n# print(torch.allclose(bn_y,verify_bn_y))\n'''\n    torch.Size([1, 3, 1, 1])\n    torch.Size([1, 3, 1, 1])\n    torch.Size([4, 3, 2, 2])\n    torch.Size([4, 3, 2, 2])\n    True\n'''\n# 2. \u5b9e\u73b0layer_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528 layer_norm API\nlayer_norm_op = torch.nn.LayerNorm((channels,h,w),elementwise_affine=False)\nln_y = layer_norm_op(inputx)  # torch.Size([4, 3, 2, 2])\n\n## \u624b\u5199layer_norm\nln_mean = inputx.mean(dim=(1,2,3),keepdim=True)  # torch.Size([4, 1, 1, 1])\nln_std = inputx.std(dim=(1,2,3),keepdim=True,unbiased=False)  # torch.Size([4, 1, 1, 1])\nverify_bn_y = (inputx - ln_mean)/(ln_std + 1e-05)   # torch.Size([4, 3, 2, 2])\nprint(ln_mean.shape)\nprint(ln_std.shape)\nprint(ln_y.shape)\nprint(verify_bn_y.shape)\nprint(torch.allclose(ln_y,verify_bn_y))\n'''\n    torch.Size([4, 1, 1, 1])\n    torch.Size([4, 1, 1, 1])\n    torch.Size([4, 3, 2, 2])\n    torch.Size([4, 3, 2, 2])\n    True\n'''\n</code></pre> <p>\u7eaf\u4eab\u7248\uff1a</p> <p>for \u53e5\u5b50</p> Python<pre><code>import torch\n\nbatch_size = 2\ntimes_steps = 3\nembedding_dim = 4\n\ninputx = torch.randn(batch_size,times_steps,embedding_dim) # N*L*C\n\n# 1. \u5b9e\u73b0batch_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528 batch_norm API\nbatch_norm_op = torch.nn.BatchNorm1d(embedding_dim,affine=False)\nbn_y = batch_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n\n## \u624b\u5199batch_norm\nbn_mean = inputx.mean(dim=(0,1),keepdim=True)\nbn_std = inputx.std(dim=(0,1),unbiased=False,keepdim=True)\nverify_bn_y = (inputx - bn_mean)/(bn_std+1e-5)\nprint(torch.allclose(bn_y,verify_bn_y)) \n\n# 2. \u5b9e\u73b0layer_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528 layer_norm API\nlayer_norm_op = torch.nn.LayerNorm(embedding_dim,elementwise_affine=False)\nln_y = layer_norm_op(inputx)\n\n## \u624b\u5199layer_norm\nln_mean = inputx.mean(dim=-1,keepdim=True)\nln_std = inputx.std(dim=-1,keepdim=True,unbiased=False)\nverify_bn_y = (inputx - ln_mean)/(ln_std + 1e-05)\nprint(torch.allclose(ln_y,verify_bn_y)) \n</code></pre> <p>for  \u56fe\u7247</p> Python<pre><code>import torch\n\nbatch_size = 4\nchannels = 3\nh,w = 2,2\n\ninputx = torch.randn(batch_size,channels,h,w) # BCHW \u53ea\u8981\u7ef4\u5ea6\u662f\u6b63\u786e\u7684\uff0c\u6570\u5b57\u53ef\u4ee5\u968f\u4fbf\u751f\u6210\n\n# 1. \u5b9e\u73b0batch_norm\u5e76\u9a8c\u8bc1API\n## \u8c03\u7528 batch_norm API\nbatch_norm_op = torch.nn.BatchNorm2d(channels,affine=False)\nbn_y = batch_norm_op(inputx) \n\n## \u624b\u5199batch_norm\nbn_mean = inputx.mean(dim=(0,2,3),keepdim=True) \nbn_std = inputx.std(dim=(0,2,3),unbiased=False,keepdim=True) \nverify_bn_y = (inputx - bn_mean)/(bn_std+1e-5)\nprint(torch.allclose(bn_y,verify_bn_y))\n\n\n# 2. \u5b9e\u73b0layer_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528 layer_norm API\nlayer_norm_op = torch.nn.LayerNorm((channels,h,w),elementwise_affine=False)\nln_y = layer_norm_op(inputx) \n\n## \u624b\u5199layer_norm\nln_mean = inputx.mean(dim=(1,2,3),keepdim=True) \nln_std = inputx.std(dim=(1,2,3),keepdim=True,unbiased=False)  \nverify_bn_y = (inputx - ln_mean)/(ln_std + 1e-05)  \nprint(torch.allclose(ln_y,verify_bn_y))\n</code></pre>"},{"location":"learning/1/#instance-norm","title":"Instance Norm","text":"<p>\u5b9e\u4f8b\u5f52\u4e00\u5316\uff0c\u901a\u5e38\u7528\u5728 \u98ce\u683c\u8fc1\u79fb\u4e0a</p> <p>per sample\u3001per channel</p> <p>\u8fd9\u65f6\u8ba1\u7b97\u5747\u503c\u548c\u6807\u51c6\u5dee\u7684\u65f6\u5019\uff0c\u662f\u5bf9\u6bcf\u4e00\u4e2a\u6837\u672c\u7684\u3001\u6bcf\u4e00\u4e2a\u7ef4\u5ea6</p> <p>\u5b98\u7f51api</p> <p></p> <ul> <li>\u662f\u4e00\u4e2aclass</li> <li><code>num_features</code>\uff1a\u8981\u5b9e\u73b0\u4e00\u4e2aInstance Norm\u7684\u8bdd\uff0c\u9700\u8981\u4f20\u5165\u7279\u5f81\u7ef4\u5ea6\u6216\u8005\u8bf4 \u901a\u9053\u7ef4\u5ea6\uff08model dim \u53ef\u4ee5\u7406\u89e3\u4e3a channel\uff09\uff0c\u56e0\u4e3a \u6211\u4eec\u8981\u9010\u6837\u672c\uff0c\u9010\u901a\u9053\u7684\u8fdb\u884c\u5f52\u4e00\u5316</li> <li><code>affine</code>\uff1a\u4e5f\u53ef\u4ee5\u8fdb\u884c\u4eff\u5c04\u53d8\u6362\uff0c\u4f46\u5927\u90e8\u5206\u60c5\u51b5\u4e0b\uff0c\u662f\u8bbe\u7f6e\u4e3afalse\u7684\uff0c\u4e00\u822c\u662f\u76f4\u63a5\u5f52\u4e00\u5316\u5373\u53ef</li> </ul>"},{"location":"learning/1/#instance1d","title":"INSTANCE1D","text":"<p>\u4ee3\u7801\u5b9e\u73b0\u9700\u8981\u6ce8\u610f\uff0c\u63a5\u6536\u7684\u8f93\u5165\u6570\u636e\u683c\u5f0f\u662f\u4ec0\u4e48\u6837\u7684\uff0c\u8f93\u51fa\u7684\u6570\u636e\u683c\u5f0f\u53c8\u662f\u4ec0\u4e48\u6837\u7684\uff0c\u770b\u5b98\u7f51api</p> <p></p> <p>NCL</p> <p>for nlp\uff1a\u5d4c\u5165\u7ef4\u5ea6\u653e\u5230\u4e2d\u95f4\u3001\u8bcd\u6570\u6ede\u540e</p> <p>for cv\uff1aINSTANCE2D \uff1abchw \u4e0d\u53d8</p> <p>\u5c31\u5f88\u7c7b\u4f3cBatchNorm</p> <p>\u6240\u4ee5\u4f1a\u6709\u4e24\u6b21\u8f6c\u7f6e</p>"},{"location":"learning/1/#_5","title":"\u56fe\u793a","text":""},{"location":"learning/1/#for-nlp_1","title":"for NLP","text":""},{"location":"learning/1/#for-cv_1","title":"for CV","text":""},{"location":"learning/1/#_6","title":"\u4ee3\u7801\u5b9e\u73b0","text":""},{"location":"learning/1/#for-nlp-instancenorm1d","title":"For nlp InstanceNorm1d","text":"Python<pre><code># 3. \u5b9e\u73b0instance_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528ins_norm\u5e76\u9a8c\u8bc1API\nins_norm_op = torch.nn.InstanceNorm1d(embedding_dim)\nin_y = ins_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n\n## \u624b\u5199ins_norm\nin_mean = inputx.mean(dim=1,keepdim=True)\nin_std = inputx.std(dim=1,keepdim=True,unbiased=False)\nverify_in_y = (inputx - in_mean)/(in_std+1e-5)\nprint(torch.allclose(in_y,verify_in_y))\n</code></pre> <p>\u89e3\u91ca\uff1a</p> <ul> <li> <p> <code>in_y = ins_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)</code> \u5148\u8f6c\u7f6e\u518d\u8f6c\u7f6e\u56de\u6765</p> </li> <li> <p> inputx.shape = torch.Size([2, 3, 4])</p> </li> <li> in_y.shape = torch.Size([2, 3, 4])</li> <li> <p> in_mean.shape = torch.Size([2, 1, 4])</p> </li> <li> <p> \u89e3\u91ca\u4e3a\u4ec0\u4e48instanceNorm\u80fd\u591f\u5b9e\u73b0\u98ce\u683c\u8fc1\u79fb\uff1f</p> </li> </ul> <p>\u8f93\u5165 batch size\u00d7sequence length\u00d7embedding dim\uff0c\u5982\u679c\u6211\u4eec\u53ea\u5bf9\u4e2d\u95f4\u8fd9\u4e00\u7ef4\u6c42\u5747\u503c\u7684\u8bdd\uff0c\u4e5f\u5c31\u662f\u8bf4 \u628a\u6240\u6709\u65f6\u523b\u7684embedding\u6c42\u4e00\u4e2a\u5747\u503c\uff0c\u76f8\u5f53\u4e8e\u5747\u503c\u662f\u5f53\u524d\u8fd9\u4e2a\u6837\u672c\u5728\u6240\u6709\u65f6\u523b \u4e0d\u53d8\u7684\u4e1c\u897f\uff0c\u90a3\u6211\u4eec\u628a\u4e0d\u53d8\u7684\u4e1c\u897f\u6d88\u6389\uff0c\u5c31\u662f\u8bf4 \u628a \u8fd9\u4e2a\u65f6\u5e8f\u6837\u672c\u5728 \u6240\u6709\u65f6\u523b\u4e2d \u90fd\u6709\u7684\u4e1c\u897f \u6d88\u6389\uff0c\u90a3\u4ec0\u4e48\u4e1c\u897f\u662f\u5728\u6240\u6709\u65f6\u523b\u90fd\u6709\u7684\u5462\uff1f\u5176\u5b9e\u5c31\u662f\u8fd9\u6837\u5427\u6837\u672c\u7684\u98ce\u683c\uff0c\u5982\u679c\u662f\u4e00\u53e5\u6587\u672c \u6216\u8005\u8bf4 \u4e00\u5f20\u56fe\u7247 \u6216\u8005\u8bf4\u4e00\u53e5\u8bdd \u4e00\u6bb5\u97f3\u9891\uff0c\u4e00\u5f20\u56fe\u7247\u5c31\u662f\u98ce\u683c\uff0c\u4e00\u53e5\u97f3\u9891\uff0c\u4e00\u53e5\u56e0\u4e3a\u4ec0\u4e48\u4e1c\u897f\u662f\u65f6\u4e0d\u53d8\u7684\uff1f\u5047\u5982\u8bf4 \u662f\u4e00\u4e2a\u4eba\u8bf4\u7684\u8bdd\u7684\u8bdd\uff0c\u90a3\u5c31\u662f\u8bf4 \u8fd9\u4e2a\u4eba\u7684\u8eab\u4efd\u662f\u65f6\u4e0d\u53d8\u7684\uff1b</p> <p>\u4e5f\u5c31\u662f\u8bf4 \u901a\u8fc7instanceNorm\uff0c\u5982\u679c\u662f\u56fe\u50cf\u7684\u8bdd\uff0c\u5c31\u53ef\u4ee5\u628a\u56fe\u50cf\u7684\u98ce\u683c\u7ed9\u6d88\u6389\uff0c\u90a3\u5982\u679c\u5728\u8bed\u97f3\u4e2d\uff0c\u5c31\u53ef\u4ee5\u628a\u8fd9\u4e2a\u4eba\u7684\u8eab\u4efd\u6d88\u6389\uff0c\u56e0\u4e3a\u6211\u4eec\u627e\u7684\u662f\u8de8\u65f6\u95f4\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\uff0c\u6211\u4eec\u505a\u7684\u5f52\u4e00\uff0c\u4e5f\u5c31\u662f\u8bf4 \u6211\u4eec\u628a\u56fe\u7247\u4e2d\u7684\u98ce\u683c\u6d88\u6389\u4e86\uff0c\u628a\u8bed\u97f3\u4e2d\u8bf4\u8bdd\u4eba\u7684\u8eab\u4efd\u6d88\u6389\u4e86\uff0c\u5982\u679c\u662f\u6587\u672c\u7684\u8bdd\uff0c\u53ef\u80fd\u662f\u6587\u672c\u4e2d \u67d0\u4e00\u4e2a\u5171\u6709\u7684\u7279\u5f81\uff1b</p> <p>\u6240\u4ee5instanceNorm\u4e00\u822c\u7528\u5728\u98ce\u683c\u8fc1\u79fb\u4e2d\uff0c\u628a\u65f6\u4e0d\u53d8\u7684\u4e1c\u897f\u53bb\u6389\u4e86</p>"},{"location":"learning/1/#for-cv-instancenorm2d","title":"For cv InstanceNorm2d","text":"Python<pre><code># 3. \u5b9e\u73b0instance_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528ins_norm\u5e76\u9a8c\u8bc1API\nins_norm_op = torch.nn. (channels)\nin_y = ins_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n# print(inputx.shape) torch.Size([4, 3, 2, 2])\n## \u624b\u5199ins_norm\nin_mean = inputx.mean(dim=(2,3),keepdim=True)\n# dim=(2,3) print(in_mean.shape) torch.Size([4, 3, 1, 1])\n#dim=1  print(in_mean.shape) torch.Size([4, 1, 2, 2])\nin_std = inputx.std(dim=(2,3),keepdim=True,unbiased=False)\nverify_in_y = (inputx - in_mean)/(in_std+1e-5)\nprint(torch.allclose(in_y,verify_in_y))\n</code></pre> <ul> <li> dim=(2,3) || in_mean = inputx.mean(dim=(2,3),keepdim=True)</li> </ul>"},{"location":"learning/1/#groupnormalization","title":"GroupNormalization","text":"<p>\u5206\u7ec4\u5f52\u4e00\u5316\u3001\u7fa4\u5f52\u4e00\u5316</p> <p></p> <p>per sample\u3001per group</p> <p>\u8fd9\u4e2a\u8ddfLayerNorm\u662f\u6700\u50cf\u7684</p> <p>\u9700\u8981\u5c06channel\u5212\u5206\u6210group\uff0c\u7c7b\u4f3c\u5206\u7ec4\u5377\u79ef\u3001\u628a\u8f93\u5165\u901a\u9053\u5212\u5206\u6210\u4e0d\u540c\u7684group</p> <p>\u9996\u5148\u5bf9input tensor\u5212\u5206\u6210\u4e0d\u540c\u7684group\uff0c\u7136\u540e\u5bf9\u4e8e\u6bcf\u4e2a\u6837\u672c\uff0c\u6bcf\u4e2agroup\u8ba1\u7b97\u5f52\u4e00\u5316\u5373\u53ef</p> <p>\u8fd9\u91cc\u4ecd\u7136\u662f\u8ddfbatch size\u65e0\u5173\u7684\uff0cbatch Norm\u662f\u8ddfbatch size\u6709\u5173\u7684</p>"},{"location":"learning/1/#api_1","title":"\u5b98\u65b9api","text":"<p>\uff081\uff09\u662f\u4e00\u4e2aclass</p> <p>\uff082\uff09\u5b9e\u73b0\u7fa4\u5f52\u4e00\u5316\u7684\u8bdd\uff0c\u9700\u8981\u7684\u4f20\u5165\u53c2\u6570\uff1a</p> <ul> <li>num_groups\uff1agroup\u7684\u6570\u76ee\uff0c\u4e3e\u4e2a\u4f8b\u5b50\uff0c\u5982\u679cchannel=4\uff0c\u5212\u5206\u62102\u4e2agroup\uff0c\u90a3\u8fd9\u91cc\u6211\u4eec\u5c31\u53ef\u4ee5\u4f20\u51652</li> <li>num_channels\uff1a\u4f8b\u5b50\u4e2d num_channels=4</li> <li>affine\uff1a\u4e00\u822c\u9ed8\u8ba4=false</li> </ul>"},{"location":"learning/1/#nlpgn","title":"NLP&amp;GN","text":""},{"location":"learning/1/#_7","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<ul> <li>\u5b9e\u4f8b\u5316class</li> <li>\u8f93\u5165\u7684\u53c2\u6570\uff0c\u4ee5\u53ca\u8f93\u5165\u7684\u5f62\u72b6</li> </ul> <p>\u8f93\u5165\u901a\u9053\u6570 \u9700\u8981\u653e\u5728\u4e2d\u95f4\u7684\u7ef4\u5ea6\uff0c\u8c03\u7528groupNorm\u9700\u8981\u7c7b\u4f3cBatchNorm\uff0c\u505a\u4e00\u4e2a\u8f6c\u7f6e\uff0c\u4e5f\u662f\u8ddfinstanceNorm\u662f\u7c7b\u4f3c\u7684</p> Python<pre><code># 4. \u5b9e\u73b0group_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528group_norm\u5e76\u9a8c\u8bc1API\nnum_groups = 2\ngroup_norm_op = torch.nn.GroupNorm(num_groups,embedding_dim,affine=False)\ngn_y = group_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n</code></pre> <p>\u9996\u5148\u9700\u8981\u5c06inputx\u5212\u5206\u6210 num_groups\u7ec4\uff0c\u9700\u8981\u8c03\u7528\u5212\u5206\u7684api\uff0c\u4e5f\u5c31\u662fsplit\uff0c\u5207\u6210\u591a\u4e2atensor</p> <p>\u6307\u5b9a\u597d\u7ef4\u5ea6\u4ee5\u53ca\u5207\u5206\u7684\u5927\u5c0f</p> <p>\u5b98\u7f51api\uff0ctorch.split\u51fd\u6570\u600e\u4e48\u7528\uff0c\u9700\u8981\u4f20\u5165\u4ec0\u4e48\u53c2\u6570</p> <p></p> <p>\u9700\u8981\u4f20\u5165\u7684\u53c2\u6570\uff1a</p> <p></p> <ul> <li>tensor\uff1a\u5207\u8c01</li> <li>split_size_or_sections:\u5207\u6210\u591a\u5927\u7684</li> <li>dim\uff1a\u5207\u54ea\u4e2a\u7ef4\u5ea6</li> </ul> Python<pre><code>group_inputx = torch.split(inputx,split_size_or_sections=embedding_dim//num_groups,dim=-1)\n</code></pre> <p>\u5206\u7ec4\uff0c\u5206\u7ec4\u8fc7\u540e\u5728\u6bcf\u4e2a\u7ec4\u8ba1\u7b97</p> <p>per smaple\u3001per group </p> Python<pre><code># 4. \u5b9e\u73b0group_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528group_norm\u5e76\u9a8c\u8bc1API\nnum_groups = 2\ngroup_norm_op = torch.nn.GroupNorm(num_groups,embedding_dim,affine=False)\ngn_y = group_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n\n## \u624b\u5199group_norm\ngroup_inputxs = torch.split(inputx,split_size_or_sections=embedding_dim//num_groups,dim=-1)\nresults = []\nfor g_inputx in group_inputxs:\n    gn_mean = g_inputx.mean(dim=(1,2),keepdim=True)\n    # print(gn_mean.shape) # torch.Size([2, 1, 1])\n    gn_std = g_inputx.std(dim=(1,2),keepdim=True,unbiased=False)\n    gn_result = (g_inputx - gn_mean)/(gn_std + 1e-5)\n    results.append(gn_result)\n\nverify_gn_y = torch.cat(results,dim=-1)\nprint(torch.allclose(gn_y,verify_gn_y))\n</code></pre>"},{"location":"learning/1/#_8","title":"\u56fe\u793a","text":""},{"location":"learning/1/#cvgn","title":"CV&amp;GN","text":"<p>\u5199\u4ee3\u7801\u65f6\u9700\u8981\u6ce8\u610f\uff1a</p> <p><code>ValueError: num_channels must be divisible by num_groups</code></p>"},{"location":"learning/1/#_9","title":"\u4ee3\u7801\u5b9e\u73b0","text":"Python<pre><code># 4. \u5b9e\u73b0group_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528group_norm\u5e76\u9a8c\u8bc1API\n\nbatch_size = 4\nchannels = 6\nh,w = 2,2\ninputx = torch.randn(batch_size,channels,h,w)\n\nnum_groups = 3\ngroup_norm_op = torch.nn.GroupNorm(num_groups,channels,affine=False)\ngn_y = group_norm_op(inputx)\nprint(gn_y.shape)  # torch.Size([4, 6, 2, 2])\n## \u624b\u5199group_norm\n# BCHW\ngroup_inputxs = torch.split(inputx,split_size_or_sections=channels//num_groups,dim=1)\nresults = []\nfor g_inputx in group_inputxs:\n    gn_mean = g_inputx.mean(dim=(1,2,3),keepdim=True)\n    print(gn_mean.shape) # 3 \u4e2a torch.Size([4, 1, 1, 1])\n    gn_std = g_inputx.std(dim=(1,2,3),keepdim=True,unbiased=False)\n    gn_result = (g_inputx - gn_mean)/(gn_std + 1e-5)\n    results.append(gn_result)\n\nverify_gn_y = torch.cat(results,dim=1)\nprint(verify_gn_y.shape)  # torch.Size([4, 6, 2, 2])\nprint(torch.allclose(gn_y,verify_gn_y)) # True\n</code></pre>"},{"location":"learning/1/#_10","title":"\u56fe\u793a","text":"<p>6\u901a\u9053\uff0c\u5206\u62103\u7ec4\uff0c\u6bcf\u7ec4\u4e24\u901a\u9053</p> <p></p>"},{"location":"learning/1/#_11","title":"\u6743\u91cd\u5f52\u4e00\u5316","text":"<p>\u6587\u5b57\u3001\u6570\u5b66\u3001\u56fe\u793a\u3001\u4ee3\u7801</p> <p></p> <ul> <li>\u6743\u91cd\u5f52\u4e00\u5316\u4e0e\u4e4b\u524d\u4ecb\u7ecd\u7684\u5f52\u4e00\u5316\u4e0d\u592a\u4e00\u6837</li> <li>\u628a\u6743\u91cd\u8fdb\u884c\u89e3\u8026\uff0c\u5e45\u5ea6\u548c\u65b9\u5411\u89e3\u8026</li> <li>\u770b\u5b98\u7f51api\u7684\u4ecb\u7ecd</li> <li>\u641c\u7d22\uff1a<code>torch.nn.utils.weight_norm</code>  \u662f\u5bf9\u6743\u91cd\u8fdb\u884c\u5f52\u4e00\u5316</li> </ul> <p></p> <ul> <li>\u662f\u4e00\u4e2a\u51fd\u6570\uff0c\u4e14\u662f\u4e00\u4e2a\u5305\u88f9\u7684\u51fd\u6570\uff0c\u5305\u88f9\u7684\u5bf9\u8c61\u662fmodule</li> <li>\u9700\u8981\u7684\u8f93\u5165</li> </ul> <ol> <li><code>module</code></li> <li>\u89e3\u91ca\u51fd\u6570\u529f\u80fd\uff1a</li> </ol> <p>\u5bf9\u4e00\u4e2a\u53c2\u6570\uff08\u6307\u7684\u662f\u6743\u91cd\u53c2\u6570\u3001\u4e0d\u5305\u62ec\u504f\u7f6e\uff09</p> <p>\u5bf9\u53c2\u6570\u8fdb\u884c \\(w = g \\frac{v}{||v||}\\) \u53d8\u6362\uff0c\u672c\u6765\u7684\u53c2\u6570\u662fv\uff0c\u628av\u5148\u9664\u4ee5 v\u7684\u6a21\uff0c\u5f97\u5230v\u7684\u5355\u4f4d\u5411\u91cf\uff0c\u4e5f\u5c31\u662fv\u7684\u5355\u4f4d\u5411\u91cf\uff0c\u518d\u4e58\u4ee5\u65b0\u7684\u5e45\u5ea6g\uff0cg\u662f\u53ef\u5b66\u4e60\u7684\uff0c\u5f97\u5230\u65b0\u7684\u6743\u91cdw</p> <p>\u5047\u8bbe\u4e00\u4e2alinear\u5c42\uff0c\u6743\u91cd\u4e3av\uff0c\u5957\u4e0a\u4e00\u4e2aweight_norm\u51fd\u6570\u4ee5\u540e\uff0c\u5bf9\u5b83\u65b0\u589e\u4e00\u4e2a\u53c2\u6570g\uff0c\u8fd9\u6837\u65b0\u7684\u6743\u91cd\u53d8\u6210\u4e86w\uff0c  w\u4fdd\u7559\u4e86v\u7684\u65b9\u5411\uff0c\u4f46\u662f\u65b0\u589e\u7684\u4e00\u4e2a\u5e45\u5ea6g</p> <ul> <li>\u8fd4\u56de\u503c\uff0c\u8fd8\u662fmodule</li> </ul> <p></p>"},{"location":"learning/1/#_12","title":"\u4ee3\u7801\u5b9e\u73b0","text":"Python<pre><code># 5.\u5b9e\u73b0weight_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528weight_norm \u5e76\u9a8c\u8bc1api\nlinear = nn.Linear(embedding_dim,3,bias=False)\nwh_linear = torch.nn.utils.weight_norm(linear)\nwh_linear_output = wh_linear(inputx)\n# print(wh_linear_output.shape) # torch.Size([2, 3, 3])\n## \u624b\u5199weight_norm\nweight_direction = linear.weight/(linear.weight.norm(dim=1,keepdim=True))\nweight_magnitude = wh_linear.weight_g\nprint(weight_direction.shape)  # torch.Size([3, 4])\nprint(weight_magnitude.shape)  # torch.Size([3, 1])\nverify_wh_linear_output = inputx @ (weight_direction.transpose(-1,-2))*(weight_magnitude.transpose(-1,-2))\n\nprint(\"weight norm\",torch.allclose(wh_linear_output,verify_wh_linear_output))\n</code></pre> <p>\u8c03\u7528api\u5b9e\u73b0weight norm</p> <ul> <li>\u8f93\u5165\u53c2\u6570\uff1amodule</li> </ul> <p>\u2460 linear\u5c42\u7684\u8f93\u5165\u5927\u5c0f\u662fembedding_dim=4\u3001\u8f93\u51fa\u5927\u5c0f\u8bbe\u4e3a3</p> <p>\u9996\u5148\uff0c\u9700\u8981\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u662fmodule\uff0c\u6240\u4ee5\u9700\u8981\u9996\u5148\u5b9e\u4f8b\u5316module\uff0c\u4ee5linear\u5c42\u4e3e\u4f8b</p> <p>\u200b \u2461 \u4e0d\u8003\u8651bias</p> <p><code>linear = nn.Linear(embedding_dim,3,bias=False)</code></p> <ul> <li>\u5c06\u5b9e\u4f8b\u5316\u597d\u7684linear\uff0c\u4f20\u5165\u6743\u91cd\u5f52\u4e00\u5316\u51fd\u6570 <code>torch.nn.utils.weight_norm</code>\uff0c\u5f97\u5230\u6743\u91cd\u5f52\u4e00\u5316\u4ee5\u540e\u7684linear</li> </ul> <p><code>wh_linear = torch.nn.utils.weight_norm(linear)</code></p> <ul> <li>\u5c06\u8f93\u5165 <code>inputx</code> \u4f20\u5165\u5230 \u6743\u91cd\u5f52\u4e00\u5316\u540e\u7684\u5c42\uff0c\u5f97\u5230\u6743\u91cd\u5f52\u4e00\u5316api\u7684\u7ed3\u679c</li> </ul> <p><code>wh_linear_output = wh_linear(inputx)</code></p> <p>\u624b\u5199weight norm</p> <ul> <li>\u67e5\u770b \u6743\u91cd\u5f52\u4e00\u5316\u7ebf\u6027\u5c42 \u8f93\u51fa\u7684\u5f62\u72b6\uff1a233</li> </ul> <p>print(wh_linear_output.shape) # torch.Size([2, 3, 3])</p> <p>\u89e3\u91ca\u4e3a\u4ec0\u4e48\u662f233\uff1f</p> <p>\u9996\u5148 \u8f93\u5165\u662f234\uff0clinear\u5c42\u662f\u4ece4\u7ef4\u6620\u5c04\u52303\u7ef4\u7684\uff0c\u6240\u4ee5\u7ed3\u679c\u662f233\uff0c\u4e5f\u5c31\u662f \u7ecf\u8fc7\u6743\u91cd\u5f52\u4e00\u5316\u5c42\u7684\u8f93\u51fa\u662f 233</p> <p>233\u662f\u600e\u4e48\u6765\u7684\uff1f</p> <p>\u9996\u5148 \u516c\u5f0f\uff1a\\(w = g \\frac{v}{||v||}\\) ,\u5148\u5bf9\u6743\u91cd v  \u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u5f97\u5230\u65b9\u5411\u5411\u91cf\uff0c\u7136\u540e\u4e58\u4ee5\u4e00\u4e2a \u53ef\u5b66\u4e60\u7684\u5e45\u5ea6\u5411\u91cf g</p> <p>\u6240\u4ee5\u5728\u624b\u52a8\u5b9e\u73b0\u7684\u65f6\u5019\uff0c\u9996\u5148 \u5f97\u5230 linear\u7684\u6743\u91cd <code>linear.weight</code>\uff0c\u63a5\u7740 \u5bf9linear\u7684\u6743\u91cd\u9664\u4ee5\u4e00\u4e2a \u8303\u6570</p> <p><code>linear.weight</code> \u662f\u4e00\u4e2a\u4e8c\u7ef4\u5f20\u91cf\uff0c\u6839\u636e\u516c\u5f0f\u662f v\u9664\u4ee5v\u7684\u6a21</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c<code>linear.weight/linear.weight.norm(dim=1,keepdim=True)</code></p> <p>\u89e3\u91ca\uff1a\u9664\u4ee5\u6a21 \u5e76\u4e0d\u662f \u9664\u4ee5\u6574\u4e2a\u77e9\u9635\u7684\u6a21\uff0c\u800c\u662f \u8ddf\u6bcf\u4e00\u4e2asample\uff0c\u5185\u79ef\u76f8\u4e58\u7684\u5411\u91cf\u7684\u6a21\uff0c\u6240\u4ee5\u8fd9\u91ccdimension\u53d61\uff0c\u8ba1\u7b97linear\u7684\u65f6\u5019 \u662f x\u4e58\u4ee5 w\u7684\u8f6c\u7f6e\uff0c\u4e5f\u5c31\u662fx\u7684\u6bcf\u4e00\u884c \u4e0e w\u7684\u8f6c\u7f6e\u7684\u6bcf\u4e00\u5217\u76f8\u4e58\uff0c\u4e0ew\u8f6c\u7f6e\u7684\u6bcf\u4e00\u5217\u76f8\u4e58 \u76f8\u5f53\u4e8e\u8ddf w\u7684\u6bcf\u4e00\u884c\u76f8\u4e58\uff0cw\u7684\u6bcf\u4e00\u884c\u5c31\u662fdimension=1\uff0c\uff080\u7ef4\u662fbatchsize\uff09\uff0c\u5e76\u4e14\u8bbe\u7f6ekeepdim=True,\u5e76\u4e14\u5c06 \u53d8\u91cf\u540d\u547d\u540d\u4e3a <code>weight_direction</code></p> Python<pre><code>weight_direction = linear.weight/(linear.weight.norm(dim=1,keepdim=True))\n</code></pre> <p>\u63a5\u4e0b\u6765 \u8fd8\u9700\u8981\u5e45\u5ea6\u53c2\u6570 <code>weight_magnitude</code>\uff0c\u4e5f\u5c31\u662f \u516c\u5f0f\u4e2d\u7684g\uff0c\u8981\u4fdd\u8bc1\u8ddfapi\u7684g\u4e00\u6837\uff0c\u5728\u5b98\u7f51api\u4e2d\u7ed9\u51fa weight_g\u8868\u793a\u5e45\u5ea6\uff0cweight_v\u8868\u793a\u65b9\u5411</p> <p></p> Text Only<pre><code>weight_magnitude = wh_linear.weight_g\n</code></pre> <p>\u67e5\u770b \u65b9\u5411\u7684\u5f62\u72b6\u548c\u5e45\u5ea6\u7684\u5f62\u72b6</p> Python<pre><code>print(weight_direction.shape)  # torch.Size([3, 4])\nprint(weight_magnitude.shape)  # torch.Size([3, 1])\n</code></pre> <p>\u65b9\u5411\u7684\u5f62\u72b6\u662f 3\u00d74\uff0c\u5e45\u5ea6\u7684\u5f62\u72b6\u662f 3\u00d71</p> <p>\u63a5\u4e0b\u6765 \u6309\u7167 \u516c\u5f0f \\(w = g \\frac{v}{||v||}\\) \u8ba1\u7b97\u51fa\u65b0\u7684 w</p> Python<pre><code>verify_wh_linear_output = inputx @ (weight_direction.transpose(-1,-2))*(weight_magnitude.transpose(-1,-2))\n</code></pre> <p>\u8f93\u5165\u4e0e\u6743\u91cd\u76f8\u4e58\uff0c\u7136\u540e\u4e58\u4ee5 \u65b9\u5411\u5411\u91cf\uff0cinputx.shape=234\uff0c\u9700\u8981\u5bf9weight\u8f6c\u7f6e\u4e00\u4e0b</p>"},{"location":"learning/1/#_13","title":"\u603b\u7ed3","text":""},{"location":"learning/1/#_14","title":"\u6846\u67b6","text":"<p>batch size\uff1aper channel across minibatch\uff0c\u5f52\u4e00\u5316\u7684\u65f6\u5019\u5bf9\u6bcf\u4e2a\u901a\u9053\u5355\u72ec\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u7b2c\u4e8c\u4e2a\u5f52\u4e00\u5316\u662f\u5c42\u5f52\u4e00\u5316\uff0c\u5bf9\u6bcf\u4e2a\u6837\u672c\u5355\u72ec\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u5e76\u4e14\u5bf9\u6bcf\u4e00\u4e2a\u5c42\u5355\u72ec\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3anlp\u4e2d\u7684\u65f6\u95f4\uff0c\u7b2c\u4e09\u4e2a\u662f\u5b9e\u4f8b\u5f52\u4e00\u5316\uff0c\u98ce\u683c\u8fc1\u79fb\u4e2d\u7ecf\u5e38\u4f7f\u7528\uff0c\u505a\u6cd5\u662fper sample\u3001per channel\uff0c\u5bf9\u6bcf\u4e2a\u6837\u672c\u7684\u6bcf\u4e2a\u901a\u9053\u5355\u72ec\u505a\uff0c\u7b2c\u56db\u4e2a\u662f\u7fa4\u5f52\u4e00\u5316\uff0c\u5bf9\u6bcf\u4e2a\u6837\u672c\u5206\u7ec4\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u7ec4\u662f\u6307\u5bf9channel\u8fdb\u884c\u5206\u7ec4\uff0c\u7b2c\u4e94\u4e2a\u6743\u91cd\u5f52\u4e00\u5316\uff0c\u5bf9\u6743\u91cd\u8fdb\u884c\u5f52\u4e00\u5316\u518dscale</p> <p>\u603b\u7ed3\u7edf\u8ba1\u91cf\u7ef4\u5ea6\uff1a</p> <p>batchnorm</p> <ul> <li>nlp\uff1aNLC\u2192C</li> <li>cv\uff1aNCHW\u2192C</li> </ul> <p>LayerNorm</p> <ul> <li>nlp\uff1aNLC\u2192NL\uff08per sample\u3001per layer \u4fdd\u7559sample\u7ef4\u5ea6\uff0c\u4fdd\u7559layer\u7ef4\u5ea6\uff09</li> <li>cv\uff1aNCHW\u2192NHW?</li> </ul> <p>\u5b9e\u4f8b\u5f52\u4e00\u5316</p> <ul> <li>nlp\uff1aNLC\u2192NC</li> <li>cv\uff1aNCHW\u2192NC</li> </ul> <p>groupnorm</p> <ul> <li>nlp\uff1aN\uff0cG\uff0cL\uff0cC//G \u2192 N\uff0cG</li> <li>cv\uff1aN\uff0cG\uff0cC//G\uff0cH\uff0cW\u2192N\uff0cG</li> </ul>"},{"location":"learning/1/#_15","title":"\u4ee3\u7801","text":""},{"location":"learning/1/#nlp","title":"nlp","text":"Python<pre><code>import torch\nimport torch.nn as nn\n\nbatch_size = 2\ntimes_steps = 3\nembedding_dim = 4\n\ninputx = torch.randn(batch_size,times_steps,embedding_dim) # N*L*C\n\n# 1. \u5b9e\u73b0batch_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528 batch_norm API\nbatch_norm_op = torch.nn.BatchNorm1d(embedding_dim,affine=False)\nbn_y = batch_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n\n## \u624b\u5199batch_norm\nbn_mean = inputx.mean(dim=(0,1),keepdim=True)\nbn_std = inputx.std(dim=(0,1),unbiased=False,keepdim=True)\nverify_bn_y = (inputx - bn_mean)/(bn_std+1e-5)\nprint(\"batch norm:\",torch.allclose(bn_y,verify_bn_y)) \n\n# 2. \u5b9e\u73b0layer_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528 layer_norm API\nlayer_norm_op = torch.nn.LayerNorm(embedding_dim,elementwise_affine=False)\nln_y = layer_norm_op(inputx)\n\n## \u624b\u5199layer_norm\nln_mean = inputx.mean(dim=-1,keepdim=True)\nln_std = inputx.std(dim=-1,keepdim=True,unbiased=False)\nverify_bn_y = (inputx - ln_mean)/(ln_std + 1e-05)\nprint(\"layer norm:\",torch.allclose(ln_y,verify_bn_y)) \n\n# 3. \u5b9e\u73b0instance_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528ins_norm\u5e76\u9a8c\u8bc1API\nins_norm_op = torch.nn.InstanceNorm1d(embedding_dim)\nin_y = ins_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n\n## \u624b\u5199ins_norm\nin_mean = inputx.mean(dim=1,keepdim=True)\nin_std = inputx.std(dim=1,keepdim=True,unbiased=False)\nverify_in_y = (inputx - in_mean)/(in_std+1e-5)\nprint(\"instance norm:\",torch.allclose(in_y,verify_in_y))\n\n# 4. \u5b9e\u73b0group_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528group_norm\u5e76\u9a8c\u8bc1API\nnum_groups = 2\ngroup_norm_op = torch.nn.GroupNorm(num_groups,embedding_dim,affine=False)\ngn_y = group_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n\n## \u624b\u5199group_norm\ngroup_inputxs = torch.split(inputx,split_size_or_sections=embedding_dim//num_groups,dim=-1)\nresults = []\nfor g_inputx in group_inputxs:\n    gn_mean = g_inputx.mean(dim=(1,2),keepdim=True)\n    # print(gn_mean.shape) # torch.Size([2, 1, 1])\n    gn_std = g_inputx.std(dim=(1,2),keepdim=True,unbiased=False)\n    gn_result = (g_inputx - gn_mean)/(gn_std + 1e-5)\n    results.append(gn_result)\n\nverify_gn_y = torch.cat(results,dim=-1)\nprint(\"group norm:\",torch.allclose(gn_y,verify_gn_y))\n\n\n# 5.\u5b9e\u73b0weight_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528weight_norm \u5e76\u9a8c\u8bc1api\nlinear = nn.Linear(embedding_dim,3,bias=False)\nwh_linear = torch.nn.utils.weight_norm(linear)\nwh_linear_output = wh_linear(inputx)\n# print(wh_linear_output.shape) # torch.Size([2, 3, 3])\n## \u624b\u5199weight_norm\nweight_direction = linear.weight/(linear.weight.norm(dim=1,keepdim=True))\nweight_magnitude = wh_linear.weight_g\nprint(weight_direction.shape)  # torch.Size([3, 4])\nprint(weight_magnitude.shape)  # torch.Size([3, 1])\nverify_wh_linear_output = inputx @ (weight_direction.transpose(-1,-2))*(weight_magnitude.transpose(-1,-2))\n\nprint(\"weight norm\",torch.allclose(wh_linear_output,verify_wh_linear_output))\n</code></pre>"},{"location":"learning/1/#cv","title":"cv","text":"Python<pre><code>import torch\n\nbatch_size = 4\nchannels = 3\nh,w = 2,2\n\ninputx = torch.randn(batch_size,channels,h,w) # BCHW \u53ea\u8981\u7ef4\u5ea6\u662f\u6b63\u786e\u7684\uff0c\u6570\u5b57\u53ef\u4ee5\u968f\u4fbf\u751f\u6210\n\n# 1. \u5b9e\u73b0batch_norm\u5e76\u9a8c\u8bc1API\n## \u8c03\u7528 batch_norm API\nbatch_norm_op = torch.nn.BatchNorm2d(channels,affine=False)\nbn_y = batch_norm_op(inputx) \n\n## \u624b\u5199batch_norm\nbn_mean = inputx.mean(dim=(0,2,3),keepdim=True) \nbn_std = inputx.std(dim=(0,2,3),unbiased=False,keepdim=True) \nverify_bn_y = (inputx - bn_mean)/(bn_std+1e-5)\nprint(\"batch norm:\",torch.allclose(bn_y,verify_bn_y))\n\n\n# 2. \u5b9e\u73b0layer_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528 layer_norm API\nlayer_norm_op = torch.nn.LayerNorm((channels,h,w),elementwise_affine=False)\nln_y = layer_norm_op(inputx) \n\n## \u624b\u5199layer_norm\nln_mean = inputx.mean(dim=(1,2,3),keepdim=True) \nln_std = inputx.std(dim=(1,2,3),keepdim=True,unbiased=False)  \nverify_bn_y = (inputx - ln_mean)/(ln_std + 1e-05)  \nprint(\"layer norm:\",torch.allclose(ln_y,verify_bn_y))\n\n\n# 3. \u5b9e\u73b0instance_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528ins_norm\u5e76\u9a8c\u8bc1API\nins_norm_op = torch.nn.InstanceNorm2d(channels)\nin_y = ins_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n# print(inputx.shape) torch.Size([4, 3, 2, 2])\n## \u624b\u5199ins_norm\nin_mean = inputx.mean(dim=(2,3),keepdim=True)\n# dim=(2,3) print(in_mean.shape) torch.Size([4, 3, 1, 1])\n#dim=1  print(in_mean.shape) torch.Size([4, 1, 2, 2])\nin_std = inputx.std(dim=(2,3),keepdim=True,unbiased=False)\nverify_in_y = (inputx - in_mean)/(in_std+1e-5)\nprint(\"instance norm:\",torch.allclose(in_y,verify_in_y))\n\n# 4. \u5b9e\u73b0group_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528group_norm\u5e76\u9a8c\u8bc1API\n\nbatch_size = 4\nchannels = 6\nh,w = 2,2\ninputx = torch.randn(batch_size,channels,h,w)\n\nnum_groups = 3\ngroup_norm_op = torch.nn.GroupNorm(num_groups,channels,affine=False)\ngn_y = group_norm_op(inputx)\n# print(gn_y.shape)  # torch.Size([4, 6, 2, 2])\n## \u624b\u5199group_norm\n# BCHW\ngroup_inputxs = torch.split(inputx,split_size_or_sections=channels//num_groups,dim=1)\nresults = []\nfor g_inputx in group_inputxs:\n    gn_mean = g_inputx.mean(dim=(1,2,3),keepdim=True)\n    # print(gn_mean.shape) # 3 \u4e2a torch.Size([4, 1, 1, 1])\n    gn_std = g_inputx.std(dim=(1,2,3),keepdim=True,unbiased=False)\n    gn_result = (g_inputx - gn_mean)/(gn_std + 1e-5)\n    results.append(gn_result)\n\nverify_gn_y = torch.cat(results,dim=1)\n# print(verify_gn_y.shape)  # torch.Size([4, 6, 2, 2])\nprint(\"group norm:\",torch.allclose(gn_y,verify_gn_y)) # True\n</code></pre>"},{"location":"learning/12_KLdivergence/","title":"KL divergence","text":""},{"location":"learning/12_KLdivergence/#kl-divergence","title":"KL divergence","text":"2024-12-10 22:56:232025-09-28 12:54:04 <p> \u7ea6 1819 \u4e2a\u5b57  7 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 9 \u5206\u949f</p> <p>\u4fe1\u606f\u91cf \uff5c\u71b5 \uff5c \u4ea4\u53c9\u71b5 \uff5cKL\u6563\u5ea6 \uff08\u76f8\u5bf9\u71b5\uff09\uff5c\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570</p>"},{"location":"learning/12_KLdivergence/#1","title":"1 \u524d\u8a00","text":"<p>\u4fe1\u606f\u91cf </p> <p>\\(I(x) = \\log_2{\\frac{1}{p(x)}} = -\\log_2{p(x)}\\) </p> <p>\u71b5</p> <p>\\(H(P)=\\sum p_iI_i^p=-\\sum p_i \\log_2(p_i)\\)</p> <p>\u4ea4\u53c9\u71b5</p> <p>\\(H(p,q) = \\sum p_i I_i^q = -\\sum p_i log_2(q_i)\\)</p> <p>\u76f8\u5bf9\u71b5\uff08KL\u6563\u5ea6\uff09</p> <p>\\(D_{KL}(p||q) = \\sum p_i \\log_2 \\frac{p_i}{q_i}\\)</p> <p>\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff08Cross Entropy Loss\uff09</p> <p>\\(H(p,q) = -\\log_2 (q_{class})\\)</p> <p>\u9010\u6b65\u9012\u8fdb\uff0c\u540e\u9762\u7684\u6982\u5ff5\u5efa\u7acb\u5728\u524d\u9762\u7684\u6982\u5ff5\u57fa\u7840\u4e4b\u4e0a</p>"},{"location":"learning/12_KLdivergence/#2","title":"2 \u4fe1\u606f\u91cf","text":"<p>\u4fe1\u606f\u91cf Amount of Information</p> <p>\u5b9a\u4e49\uff1a</p> <p>\u4e8b\u4ef6\u5305\u542b\u7684\u4fe1\u606f\u91cf\u5927\u5c0f\uff08\u4e8b\u4ef6\u53d1\u751f\u7684\u96be\u5ea6\u6709\u591a\u5927\uff09</p> <ul> <li>\u5c0f\u6982\u7387\u4e8b\u4ef6\uff0c\u5b83\u53d1\u751f\u7684\u96be\u5ea6\u6bd4\u8f83\u5927\uff0c\u6240\u4ee5\u6709\u8f83\u5927\u7684\u4fe1\u606f\u91cf</li> <li>\u5927\u6982\u7387\u4e8b\u4ef6\uff0c\u5b83\u53d1\u751f\u7684\u96be\u5ea6\u6bd4\u8f83\u5c0f\uff0c\u6240\u4ee5\u6709\u8f83\u5c0f\u7684\u4fe1\u606f\u91cf</li> </ul> <p>\u4f8b\u5b50\uff1a</p> <p></p> <p>\u6027\u8d28\uff1a</p> <p>\u5bf9\u4e8e\u72ec\u7acb\u4e8b\u4ef6A\u3001B\uff1a\\(P(AB)=P(A)P(B)\\)</p> <p>\u4e24\u4e2a\u4e8b\u4ef6\u540c\u65f6\u53d1\u751f\u7684\u4fe1\u606f\u91cf \u7b49\u4e8e \u4e24\u4e2a\u4e8b\u4ef6\u7684\u4fe1\u606f\u91cf \u76f8\u52a0 \uff1a\\(I(AB)=I(A)+I(B)\\)</p> <p>\u4fe1\u606f\u91cf\u516c\u5f0f\uff1a</p> <p>\\(I(x):= \\log_2(\\frac{1}{p(x)})=-log_2(p(x))\\)</p> <ul> <li><code>:=</code>  \u8868\u793a <code>\u5b9a\u4e49\u4e3a</code> \uff0c\u662f\u4e00\u79cd\u4eba\u4e3a\u5b9a\u4e49</li> <li><code>=</code>  \u662f\u6570\u5b66\u610f\u4e49\u4e0a\u7684 <code>\u5de6\u8fb9 = \u53f3\u8fb9</code></li> <li><code>I</code>  : <code>information</code></li> <li>\u516c\u5f0f\u600e\u4e48\u8bbe\u8ba1\u7684\uff1f</li> </ul> <p>\uff081\uff09\\(p(x)\\) \uff1a\u8868\u793a\u4e8b\u4ef6\u53d1\u751f\u7684\u6982\u7387\uff0c\u53d6\u503c\u8303\u56f4\uff1a \\(0 \\leq p(x) \\leq 1\\)</p> <p>\uff082\uff09\u6982\u7387 \\(p(x)\\) \u548c \u4fe1\u606f\u91cf \\(I(x)\\)  \u662f \u8d1f\u76f8\u5173\u7684 \\(\\rightarrow\\) \\(I(x):=\\frac{1}{p(x)}\\)</p> <p>\uff083\uff09\u4e24\u4e2a\u4e8b\u4ef6\u540c\u65f6\u53d1\u751f\u7684\u4fe1\u606f\u91cf \u7b49\u4e8e \u4e24\u4e2a \u4e8b\u4ef6\u7684\u4fe1\u606f\u91cf\u76f8\u52a0 \\(I(AB)=I(A)+I(B)\\)</p> <p>\\(I(AB)=log_2\\frac{1}{P(AB)}=log_2\\frac{1}{P(A)P(B)}=log_2\\frac{1}{P(A)}+log_2\\frac{1}{P(B)} = I(A)+I(B)\\)</p> <p>\u4fe1\u606f\u91cf\u7684\u5b9a\u4e49\uff1alog\u4ee52\u4e3a\u5e95\u6982\u7387\u5206\u4e4b\u4e00</p> <p>\uff084\uff09\u4ee52\u4e3a\u5e95\uff0c\u662f\u8f6c\u6362\u5230\u4e8c\u8fdb\u5236\u4e0b\u8868\u793a\u590d\u6742\u5ea6\uff08\u4ee5e\u4e3a\u5e95\u3001\u4ee510\u4e3a\u5e95\u90fd\u53ef\u4ee5\uff0c\u53ea\u662f\u4ee52\u4e3a\u5e95\u66f4\u4f18\uff09</p> <p>\u8ba1\u7b97\u4fe1\u606f\u91cf\u7684\u4f8b\u5b50\uff1a</p> <p></p> <p>\u4fe1\u606f\u91cf\u7684\u5b9a\u4e49\uff1alog\u4ee52\u4e3a\u5e95\u6982\u7387\u5206\u4e4b\u4e00</p>"},{"location":"learning/12_KLdivergence/#3","title":"3 \u71b5","text":"<p>\u71b5 Entropy</p> <p>\u5b9a\u4e49\uff1a</p> <p>1\u3001\u6982\u7387\u5206\u5e03\u7684\u4fe1\u606f\u91cf\u671f\u671b</p> <p>2\u3001\u7cfb\u7edf\u6574\u4f53\u7684\u4fe1\u606f\u91cf</p> <p>\u7cfb\u7edf\u6574\u4f53\u7531\u6240\u6709\u53ef\u80fd\u53d1\u751f\u7684\u4e8b\u4ef6\u6784\u6210</p> <p>\u4f8b\u5b50\uff1a\u629b\u786c\u5e01\uff0c\u6b63\u9762\u548c\u53cd\u9762 \u6784\u6210\u4e00\u4e2a\u7cfb\u7edf</p> <p>\u516c\u5f0f\uff1a</p> <p>\\(H(P)=\\sum p_i I_i = \\sum p_i \\log_2 \\frac{1}{p_i} = -\\sum p_i \\log_2 p_i\\)</p> <p>\u8ba1\u7b97\u5b9e\u4f8b\uff1a</p> <p></p> <p>\u4f5c\u7528\uff1a</p> <p>\u7528\u6765\u8bc4\u4f30 \u6982\u7387\u6a21\u578b \u7684\u4e0d\u786e\u5b9a\u7a0b\u5ea6</p> <ul> <li>\u4e0d\u786e\u5b9a\u6027\u8d8a\u5927\uff0c\u71b5\u8d8a\u5927</li> <li>\u4e0d\u786e\u5b9a\u6027\u8d8a\u5c0f\uff0c\u71b5\u8d8a\u5c0f</li> </ul> <p>\u56fe\u793a\uff1a</p> <p></p> <ul> <li>\u6982\u7387\u5b8c\u5168\u76f8\u7b49\u65f6\uff0c\u6211\u4eec\u5b8c\u5168\u4e0d\u786e\u5b9a\u54ea\u4e2a\u4f1a\u53d1\u751f</li> <li>\u5bf9\u4e8e \u7b2c\u4e8c\u5f20\u56fe\uff0c\u7b2c\u4e09\u4e2a\u4e8b\u4ef6\u7684\u6982\u7387\u9ad8\u4e00\u4e9b\uff0c\u6240\u4ee5\u66f4\u6709\u53ef\u80fd\u53d1\u751f\uff0c\u4e5f\u5c31\u662f\u8bf4 \u8fd9\u4e2a\u7cfb\u7edf\u7684\u71b5\u5c0f\u4e00\u4e9b</li> </ul> <p>\u4f8b\u5b50\uff1a</p> <p></p> <p>\u4ece\u4f8b\u5b50\u4e2d\u53ef\u4ee5\u5f97\u51fa\u7ed3\u8bba\uff1a\uff08\u4f8b1 \u7cfb\u7edf\u7684\u71b5 &gt; \u4f8b2 \u7684\u71b5\uff09</p> <ul> <li>\u82e5\u6982\u7387\u5bc6\u5ea6\u5747\u5300\uff0c\u4ea7\u751f\u7684\u968f\u673a\u53d8\u91cf\u4e0d\u786e\u5b9a\u6027\u5c31\u66f4\u9ad8\uff0c\u5219\u71b5\u7684\u503c\u5c31\u66f4\u5927</li> <li>\u82e5\u6982\u7387\u5bc6\u5ea6\u805a\u62e2\uff0c\u4ea7\u751f\u7684\u968f\u673a\u53d8\u91cf\u4e0d\u786e\u5b9a\u6027\u5c31\u66f4\u4f4e\uff0c\u5219\u71b5\u7684\u503c\u5c31\u66f4\u5c0f</li> </ul> <p>\u603b\u7ed3\uff1a</p> <p>\u5982\u679c\u4e00\u4e2a\u7cfb\u7edf\u4e2d\u53ea\u6709\u4e24\u4e2a\u4e8b\u4ef6A\u3001B\uff0c\u4e14\u4e8b\u4ef6A\u53d1\u751f\u7684\u6982\u7387P(A)\uff0c\u4e8b\u4ef6B\u53d1\u751f\u7684\u6982\u7387 P(B)\uff0c\u90a3\u4e48\u8fd9\u4e2a\u7cfb\u7edf\u7684\u71b5\uff1a</p> <p>H(P) = P(A)I(A)+P(B)I(B)</p> <p>\\(= P(A)log_2\\frac{1}{P(A)} + P(B)log_2\\frac{1}{P(B)}\\)</p> <p>\\(H(P)=\\sum_{i=1}^nP_iI(i)\\) \\(\\sum_iP_i = 1\\)</p>"},{"location":"learning/12_KLdivergence/#4","title":"4 \u4ea4\u53c9\u71b5","text":"<p>\u4ea4\u53c9\u71b5 cross entropy  </p> <p>\u5b9a\u4e49\uff1a</p> <p>\u5047\u8bbe \u771f\u5b9e\u6982\u7387\u5206\u5e03\u4e3a p\uff0c\u9884\u6d4b\u6982\u7387\u5206\u5e03\u4e3a q\uff0c\u5219\u9884\u6d4b\u6982\u7387\u5206\u5e03q \u5bf9 \u771f\u5b9e\u6982\u7387\u5206\u5e03p\u7684\u5e73\u5747\u4fe1\u606f\u91cf\u7684\u4f30\u8ba1\uff0c\u53eb\u505a\u4ea4\u53c9\u71b5</p> <ul> <li>\uff08\u9884\u6d4b\u6982\u7387\u5206\u5e03 \u4e5f\u53eb \u4f30\u8ba1\u6982\u7387\u5206\u5e03\uff09</li> </ul> <p>\u516c\u5f0f\uff1a</p> <p>\\(H(p,q)=\\sum p_iI_i^q=-\\sum p_i \\log_2(q_i)\\)</p> <p>\\(H(p,q) = \\sum p_iI(q_i)\\)</p> <p>\u4f8b\u5b50\uff1a</p> <p></p> <p>\u7531\u4f8b\u5b50\u7684\u7ed3\u679c\uff0c\u89c2\u5bdf\u53ef\u77e5\uff1a</p> <p>\uff081\uff09\u9884\u4f30\u7231\u4fa3\u5206\u5e03 \u4e0e \u771f\u5b9e\u6982\u7387\u5206\u5e03 \u8d8a\u63a5\u8fd1\uff0c\u4ea4\u53c9\u71b5\u8d8a\u5c0f</p> <p>\uff082\uff09\u4ea4\u53c9\u71b5\u7684\u503c \u603b\u662f\u5927\u4e8e \u71b5\u7684\u503c \uff08\u6839\u636e \u5409\u5e03\u65af\u4e0d\u7b49\u5f0f\uff09</p> <p>\uff083\uff09\u5bf9\u4e8e\u4f8b\u5b50\u4e2d\uff0c\\(P(A)=P(B)=\\frac{1}{2}\\)</p> <p>\u71b5 \\(H(P)=1\\)</p> <p>\u4f46\u662f\u8ba1\u7b97\u51fa\u6765\u7684 \u4ea4\u53c9\u71b5 \\(H(p,q)&gt;H(p)\\)</p> <p>\u8865\u5145\uff1a\u5409\u5e03\u65af\u4e0d\u7b49\u5f0f</p> <p>\u82e5 \\(\\sum_{i=1}^np_i=\\sum_{i=1}^nq_i=1\\)\uff0c\u4e14 \\(p_i\uff0cq_i \\in (0,1]\\)\uff0c\u5219\u6709\uff1a</p> <p>\\(-\\sum_{i=1}^np_ilogp_i\\leq-\\sum_{i=1}^np_ilogq_i\\)</p> <p>\u7b49\u53f7\u6210\u7acb\uff0c\u5f53\u4e14\u4ec5\u5f53 \\(p_i =q_i \\ {\\forall} i\\)</p> <p>\u771f\u5b9e\u6982\u7387\u7684\u71b5 \u6c38\u8fdc \u5c0f\u4e8e\u7b49\u4e8e \u4ea4\u53c9\u71b5</p>"},{"location":"learning/12_KLdivergence/#5-kl","title":"5 KL\u6563\u5ea6\uff08\u76f8\u5bf9\u71b5\uff09","text":"<p>\u76f8\u5bf9\u71b5 Relative Entropy\u3001KL\u6563\u5ea6 \uff08KL divergence\u3001Kullback-Leibler divergence\uff09</p> <p>\u4f5c\u7528\uff1a </p> <p>\u7528\u4e8e\u8861\u91cf2\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u5dee\u5f02</p> <p>\u6839\u636e\u540e\u9762\u7684\u516c\u5f0f\uff0c\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u5c31\u662f\u4e24\u4e2a\u5206\u5e03\u4fe1\u606f\u91cf\u7684\u5dee</p> <p>\u516c\u5f0f\uff1a</p> <p>\\(D_{KL}(p||q) = \\sum p_i (I_q-I_p)\\)  \u3001 \\(I_q - I_p\\)  \u4e3a\u4fe1\u606f\u91cf\u4e4b\u5dee</p> <p>\\(=\\sum p_i(log_2\\frac{1}{q_i}-log_2\\frac{1}{p_i})\\)</p> <p>\\(=\\sum p_ilog_2\\frac{1}{q_i}-p_ilog_2\\frac{1}{p_i}\\)</p> <p>\\(=H(p,q)-H(p)\\)  \uff08\u6240\u4ee5\u53eb \u76f8\u5bf9\u71b5\u3001\u6216\u8005 \\(H(p)=H(p,p)\\)\uff09</p> <p>\\(= \\sum p_i log_2\\frac{p_i}{q_i}\\)  (\u5e38\u7528\u7684\u5c55\u5f00\u5f0f)</p> <ul> <li>\\(p\u548cq\u7684\u4ea4\u53c9\u71b5 - p\u7684\u71b5\\)</li> </ul> <p>\u91cd\u8981\u6027\u8d28\uff1a</p> <p>\uff081\uff09\\(D(p||q)\\) \u4e0e \\(D(q||p)\\) \u4e0d\u4e00\u6837\uff0c\u5373 \\(D(p||q) \\neq D(q||p)\\)</p> <ul> <li>\\(D(p||q)\\)  \u8868\u793a \u4ee5\\(p\\)\u4e3a\u57fa\u51c6\uff08\\(p\\)\u4e3a\u771f\u5b9e\u6982\u7387\u5206\u5e03\uff09\uff0c\u4f30\u8ba1\u6982\u7387\u5206\u5e03 \\(q\\) \u4e0e \u771f\u5b9e\u6982\u7387\u5206\u5e03 \\(p\\)\u4e4b\u95f4\u7684\u5dee\u8ddd</li> <li>\\(D(q||p)\\) \u8868\u793a \u4ee5\\(q\\)\u4e3a\u57fa\u51c6\uff08\\(q\\)\u4e3a\u771f\u5b9e\u6982\u7387\u5206\u5e03\uff09\uff0c\u4f30\u8ba1\u6982\u7387\u5206\u5e03\\(p\\)\u4e0e\u771f\u5b9e\u6982\u7387\u5206\u5e03\\(q\\)\u4e4b\u95f4\u7684\u5dee\u8ddd</li> <li>\u524d\u9762\u7684\u5206\u5e03\u4f5c\u4e3a \u771f\u5b9e\u6982\u7387\u5206\u5e03\uff0c\u8ba1\u7b97<code>\u771f\u5b9e\u5206\u5e03\u4e0e\u4f30\u8ba1\u5206\u5e03\u4e4b\u95f4\u7684\u4ea4\u53c9\u71b5-\u771f\u5b9e\u5206\u5e03\u7684\u4fe1\u606f\u71b5</code></li> </ul> <p>\uff082\uff09\\(KL\u6563\u5ea6\u7684\u503c \\geq 0\\) \\(\\iff\\) \\(D_{KL}(p||q) \\geq 0\\)</p> <p>\u5409\u5e03\u65af\u4e0d\u7b49\u5f0f\u8bf4\u660e\uff1a</p> <p></p> <p>\u6240\u4ee5   \\(D_{KL}(p||q) \\geq 0\\)</p> <p>\u7279\u522b\u7684\uff0c\u5f53\u5206\u5e03 \\(q\\)\u4e0e\u5206\u5e03\\(p\\)\u5b8c\u5168\u4e00\u6837\u65f6\uff0c\\(D(p||q)=0\\)</p> <p>\u771f\u5b9e\u6982\u7387p\u7684\u71b5 \\(\\leq\\)  p\u548cq\u7684\u4ea4\u53c9\u71b5</p> <p>\u6240\u4ee5 \\(D_{KL}(p||q)=H(p,q)-H(p) \\geq 0\\)</p>"},{"location":"learning/12_KLdivergence/#6","title":"6 \u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570","text":"<p>\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570 Cross Entropy Loss</p> <p>\u7531\u4e0a\u53ef\u77e5\uff0cKL\u6563\u5ea6\\(D(p||q)\\) \u8868\u793a \u9884\u6d4b\u5206\u5e03q \u4e0e\u771f\u5b9e\u5206\u5e03p \u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u6240\u4ee5 \u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u5c06 \u635f\u5931\u51fd\u6570 \u5b9a\u4e49\u4e3a KL\u6563\u5ea6\uff1a\\(Loss = D(p||q)\\)</p> <p>\u635f\u5931\u51fd\u6570 = KL\u6563\u5ea6</p> <p>\u5e76\u4e14\u6211\u4eec\u5e0c\u671b \u6a21\u578b\u7684\u9884\u6d4b\u5206\u5e03q \u4e0e \u771f\u5b9e\u5206\u5e03p \u5b8c\u5168\u76f8\u540c\uff0c\u5373\uff1a\u635f\u5931\u51fd\u6570 \\(Loss=D(p||q)=0\\)</p> <p>\u635f\u5931\u51fd\u6570\uff1a</p> <p>\\(Loss = D(p||q)=H(p,q)-H(p)\\)</p> <ul> <li>p\u4e0eq\u7684\u4ea4\u53c9\u71b5 - p\u7684\u4fe1\u606f\u71b5</li> <li>p\u662f\u771f\u5b9e\u5206\u5e03</li> <li>\\(D(p||q)=H(p,q)-H(p)=\\sum p_i log_2(\\frac{1}{q_i})-\\sum p_ilog_2\\frac{1}{p_i}\\)</li> </ul> <p>\u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff1a</p> <ul> <li>\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u4e00\u822c\u7528\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c\u5206\u7c7b\u95ee\u9898\u4e00\u822c\u662f\u4e00\u4e2a\u5355\u70b9\u5206\u5e03</li> <li>\\(\\iff\\) \u7b49\u4ef7\u4e8e \u771f\u5b9e\u7c7b\u522b \u6982\u7387 = 1\uff0c\u5176\u4ed6\u7c7b\u522b\u6982\u7387 = 0</li> </ul> <p>\u771f\u5b9e\u5206\u5e03\u662f\u4e00\u4e2a\u5355\u70b9\u5206\u5e03\uff0c\u771f\u5b9e\u7c7b\u522b\u7684\u6982\u7387\u4e3a1\uff0c\u5176\u4ed6\u7c7b\u522b\u7684\u6982\u7387\u4e3a0\uff0c\u7c7b\u4f3c\u5982\u4e0b\uff1a</p> \u7c7b\u522b class1 class2 class3 class4 \u6982\u7387 0 0 1 0 <ul> <li>\\(p_{class1} = p_{class2} = p_{class4} = 0\\)</li> <li>$\\log2(\\frac{1}{p_{classs3}}) = 0 $ </li> <li>\u6240\u4ee5\uff0c\\(H(p)=\\sum p_i I(p_i) = \\sum p_i log_2{\\frac{1}{p_i}}=0\\)</li> </ul> <p>\u63a8\u5bfc\uff1a</p> <p>\u9996\u5148\u6709 \u635f\u5931\uff1a</p> <p>\\(Loss = D(p||q)=H(p,q)-H(p) = \\sum p_i log_2(\\frac{1}{q_i})-\\sum p_ilog_2\\frac{1}{p_i}\\)</p> <p>\u7531\uff0c\\(H(p)=0\\)</p> <p>\u2234 \\(Loss = H(p,q)-H(p) = H(p,q)\\)</p> <p>\u7531 \\(H(p,q)\\) \u662f\u4ea4\u53c9\u71b5\uff0c\u6240\u4ee5\u635f\u5931\u51fd\u6570 \u53c8\u79f0\u4e3a \u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff1a</p> <p>\\(Cross\\_Entropy\\_Loss = H(p,q) = \\sum p_i log_2\\frac{1}{q_i}\\)</p>"},{"location":"learning/13_RNN/","title":"RNN","text":""},{"location":"learning/13_RNN/#rnn","title":"RNN","text":"2024-12-20 22:49:272025-09-28 12:54:04 <p> \u7ea6 10598 \u4e2a\u5b57  277 \u884c\u4ee3\u7801  83 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 56 \u5206\u949f</p> <p>ref\uff1a\u301029\u3001PyTorch RNN\u7684\u539f\u7406\u53ca\u5176\u624b\u5199\u590d\u73b0\u3011</p> <p></p> <p>topic\uff1a</p> <p>\uff081\uff09\u4e0d\u540c\u7c7b\u578b\u7684RNN\u7684\u56fe\u793a\u4ee5\u53ca\u5e94\u7528\u573a\u666f\u7684\u56fe\u793a</p> <p>\uff082\uff09\u4ecb\u7ecdpytorch\u4e2dRNN\u7684api\u7684\u4f7f\u7528</p> <p>\uff083\uff09\u901a\u8fc7\u4ee3\u7801\u9a8c\u8bc1 RNN \u5185\u90e8\u662f\u5982\u4f55\u8ba1\u7b97\u7684\uff0c\u901a\u8fc7\u4ee3\u7801\u6765 \u9a8c\u8bc1 pytorch\u7684RNN\u7684api \u5e76\u5bf9\u6bd4\u7ed3\u679c</p>"},{"location":"learning/13_RNN/#k1","title":"k1 \u8bb0\u5fc6\u5355\u5143\u5206\u7c7b","text":"<ul> <li> \u4ec0\u4e48\u662f\u8bb0\u5fc6\u5355\u5143\uff1f</li> </ul> <p>\u8bb0\u5fc6\u5355\u5143\u5c31\u662f \u5b58\u50a8\u7684 \u8fc7\u53bb\u7684\u5386\u53f2\u4fe1\u606f</p> <ul> <li> \u4ec0\u4e48\u662f\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff1f</li> </ul> <p>\u6240\u8c13\u5faa\u73af\u795e\u7ecf\u7f51\u7edc \u5c31\u662f\u8bf4\uff0c\u5728\u5bf9\u5e8f\u5217\u8fdb\u884c\u5efa\u6a21\u7684\u65f6\u5019\uff0c\u5728\u7b97\u6bcf\u4e00\u65f6\u523b\u7684\u8868\u5f81\u7684\u65f6\u5019\uff0c\u4e00\u822c\u8003\u8651\u8fc7\u53bb\u7684 \u5386\u53f2\u4fe1\u606f\u3002\u8fd9\u4e2a\u5386\u53f2\u4fe1\u606f \u5c31\u662f\u901a\u8fc7 \u8bb0\u5fc6\u5355\u5143 \u4fdd\u5b58\u7684\u3002\u7136\u540e\u6bcf\u4e2a\u65f6\u523b \u6211\u4eec\u90fd\u4f1a\u4ece \u8bb0\u5fc6\u5355\u5143\u4e2d \u83b7\u53d6 \u8fc7\u53bb\u7684 \u5386\u53f2\u4fe1\u606f\uff0c\u7136\u540e\u8f85\u52a9\u5f53\u524d\u65f6\u523b \u505a\u9884\u6d4b\u3002</p> <ul> <li> \u8bb0\u5fc6\u5355\u5143\u5206\u7c7b</li> </ul> <p>\u5173\u4e8e\u8bb0\u5fc6\u5355\u5143 \u4e00\u822c\u6709\u4e09\u7c7b</p> <ol> <li>RNN</li> <li>LSTM</li> <li>GRU </li> </ol> <p>\u4e00\u7c7b \u6bd4\u5982\u8bf4 RNN\uff0c\u6bd4\u5982\u8bf4 Simple RNN\uff0c\u7b80\u5355\u7684RNN \u7ed3\u6784\uff0c\u7b49\u4e0b\u5b9e\u73b0\u7684\u4e5f\u662f \u7b80\u5355\u7684RNN\u7ed3\u6784</p> <p>\u53e6\u5916\u4e24\u79cd\u662f GRU\u548cLSTM\uff0c\u8fd9\u4e24\u79cd\u7f51\u7edc\u7684\u8bb0\u5fc6\u6027\u4f1a\u66f4\u5f3a\u4e00\u70b9\uff1b\u8ba1\u7b97\u590d\u6742\u5ea6\u4e5f\u4f1a\u66f4\u9ad8\u4e00\u70b9\uff1b\u4f7f\u7528\u9891\u7387\u4e5f\u4f1a\u66f4\u9ad8\u4e00\u70b9\uff0c\u5c31\u662f\u8bf4 \u73b0\u5728\u5f88\u591a\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u6211\u4eec\u57fa\u672c\u4f7f\u7528\u7684\u662fLSTM\u6216\u8005GRU\uff1b\u4f46\u662f\u5b83\u4eec\u90fd\u662fRNN\u7684\u4e00\u4e2a\u53d8\u4f53\uff0c\u6240\u4ee5RNN\u662f\u57fa\u7840\uff1b</p>"},{"location":"learning/13_RNN/#k2","title":"k2 \u6a21\u578b\u7684\u5206\u7c7b","text":"<p>\uff081\uff09\u5355\u5411\u5faa\u73af</p> <p>\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e5f\u53ef\u5206\u4e3a\u5355\u5411\u5faa\u73af\uff0c\u6240\u8c13\u5355\u5411\u5faa\u73af\u5c31\u662f\uff0c\u5f53\u524d\u65f6\u523b\u7684\u9884\u6d4b \u53ea\u8ddf \u8fc7\u53bb\u6709\u5173\uff0c\u4ece\u5de6\u5230\u53f3 \u9012\u5f52\u7684\u8ba1\u7b97\u3002</p> <p>\uff082\uff09\u53cc\u5411\u5faa\u73af</p> <p>\u53cc\u5411\u5faa\u73af\uff0c\u53cc\u5411\u5faa\u73af\u5c31\u662f\u8bf4 \u4e0d\u53ea\u6709 \u4ece\u5de6\u5230\u53f3\u7684 \u4e5f\u6709 \u4ece\u53f3\u5230\u5de6\u7684\uff0c\u5c31\u662f\u8bf4\u6709\u4e24\u6761\u94fe\uff0c\u53e6\u5916\u4e00\u6761\u94fe\uff0c\u5728\u8ba1\u7b97\u5f53\u524d\u65f6\u523b\u7684\u9884\u6d4b\u7684\u65f6\u5019 \u4f1a\u8003\u8651 \u672a\u6765\u4fe1\u606f\u3002</p> <p>\uff083\uff09\u591a\u4e2a\u5355\u5411 \u3001 \u591a\u4e2a\u53cc\u5411</p> <p>\u8fd9\u4e2a\u5c31\u662f\u53cc\u5411\u5faa\u73af\uff1b\u90a3\u8fd8\u53ef\u4ee5\u628a \u591a\u4e2a\u5355\u5411 \u6216\u8005\u8bf4 \u591a\u4e2a\u53cc\u5411 \u53e0\u52a0\u8d77\u6765\uff0c\u4e5f\u5c31\u662fdeep RNN \u6df1\u5ea6\u5faa\u73af\u795e\u7ecf\u7f51\u7edc</p> <p></p> <p>\uff081\uff09\u5355\u5411\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc</p> <p></p> <p>\u53ef\u4ee5\u5206\u4e3a\u4e09\u5c42\uff1a</p> <ol> <li>\u6700\u4e0b\u9762\u4e00\u5c42\u662f input layer\uff0c\u4e5f\u5c31\u662f\u8f93\u5165\u5c42\uff1b</li> <li>\u4e2d\u95f4\u662f\u9690\u542b\u5c42\uff1b</li> <li>\u6700\u540e\u662f\u8f93\u51fa\u5c42\uff1b</li> </ol> <p>\u4e0b\u9762\u7684\u8f93\u5165\u5c42\u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143 \u53ef\u4ee5\u770b\u505a \u6bcf\u4e00\u4e2a\u65f6\u523b\uff1b</p> <p>\u4e5f\u5c31\u662f\u8bf4 \u6bcf\u4e00\u4e2a\u65f6\u523b \u4e0d\u4ec5\u8ddf\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u6709\u5173\uff0c\u8fd8\u8ddf\u4e0a\u4e00\u65f6\u523b\u7684\u8bb0\u5fc6\u5355\u5143\u6709\u5173\uff1b</p> <p>\u5e76\u4e14\u5728\u5355\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc \u4e2d \u59cb\u7ec8\u662f \u4ece\u5de6\u5230\u53f3\u7684\uff1b</p> <p>\u5c31\u662f\u8bf4\u5f53\u524d\u65f6\u523b\u7684\u9884\u6d4b \u53ea\u8ddf \u8fc7\u53bb\u7684\u8bb0\u5fc6\u5355\u5143 \u6709\u5173\uff0c\u8ddf\u672a\u6765\u7684 \u662f\u65e0\u5173\u7684\uff1b</p> <p>\uff082\uff09\u53cc\u5411\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc</p> <p></p> <ol> <li>\u6709\u4e24\u6761\u94fe</li> <li>\u5206\u4e3a4\u4e2a\u90e8\u5206\uff1a  input layer\u3001output layer\u3001forward layer\u3001backward layer</li> <li>\uff08forward layer\uff09  forward layer\u662f\u4ece\u5de6\u5230\u53f3\u7684\u5faa\u73af \uff0c\u610f\u601d\u5c31\u662f\u8bf4 \u5728 forward layer\u7684\u8f93\u51fa\u4e2d\uff0c\u5b83\u7684\u8f93\u51fa\u4e0d\u4ec5\u8ddf\u5f53\u524d\u8f93\u5165\u6709\u5173 \u4e5f\u8ddf\u8fc7\u53bb\u7684\u8bb0\u5fc6\u5355\u5143\u6709\u5173\uff1b</li> <li>\uff08backward layer\uff09  backward layer\u5f53\u4e2d\uff0c\u5b83\u7684\u5f53\u524d\u65f6\u523b\u7684\u8f93\u51fa \u4e0d\u4ec5\u8ddf\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u6709\u5173\uff0c\u8fd8\u8ddf\u672a\u6765\u65f6\u523b\u7684\u8bb0\u5fc6\u5355\u5143\u6709\u5173\uff0c\u6240\u4ee5\u662f \u4ece\u53f3\u5230\u5de6\u7684 \u9012\u5f52\u8fd0\u7b97\u7684\u3002</li> <li>**\uff08\u5c06forward\u548cbackward\u7ed3\u5408\uff09**\u8d77\u6765\u6709\u4ec0\u4e48\u597d\u5904\u5462\uff1f \u5c31\u662f\u8bf4 \u65e2\u80fd\u770b\u5230\u8fc7\u53bb \u53c8\u80fd\u770b\u5230\u672a\u6765</li> </ol>"},{"location":"learning/13_RNN/#k3","title":"k3 \u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u6027\u80fd\u6bd4\u8f83","text":"<p>\u8fd9\u5f20\u8868\u683c \u6765\u81ea\u67d0\u7bc7\u8bba\u6587\uff0c\u8fd9\u5f20\u8868\u683c \u5f88\u597d\u7684 \u5c55\u793a\u4e86 RNN\u3001LSTM\u3001 \u53cc\u5411 \u5355\u5411\u3001MLP\u3001\u4ee5\u53ca\u662f\u5426delay\u7b49 \u5728\u53c2\u6570\u6570\u91cf\u76f8\u7b49\u7684\u60c5\u51b5\u4e0b \u5728\u8bed\u97f3\u8bc6\u522b\u4e0a\u7684\u8868\u73b0\uff1b\u53ef\u4ee5\u770b\u5230 \u7b2c\u4e8c\u5217 \u7b2c\u4e09\u5217 \u5206\u522b\u662f\u8bad\u7ec3\u8bef\u5dee\u548c\u6d4b\u8bd5\u8bef\u5dee\uff1b </p> <p>\u901a\u8fc7\u8868\u683c \u53ef\u4ee5\u770b\u5230 \u4e0d\u540c\u7684\u6a21\u578b\u5728 \u8bed\u97f3\u8bc6\u522b \u8fd9\u79cd \u5e8f\u5217\u5efa\u6a21\uff0c\u5e8f\u5217\u5206\u7c7b\u8fd9\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0</p> <p></p> <p>\uff081\uff09\u7b2c\u4e00\u884c\u662fMLP\uff0cMLP\u5c31\u662f\u7b80\u5355\u7684DNN \u662fno window\u7684\uff08\u4ec0\u4e48\u610f\u601d\uff1f\uff09</p> <p>\u6211\u4eec\u628a\u8bed\u97f3 \u5206\u6210\u5f88\u591a\u5e27\uff0c\u6bd4\u65b9\u8bf4\u4e00\u5e27\u662f 15\u6beb\u79d2 \u6216\u8005 20\u6beb\u79d2\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u5e27 \u63d0\u53d6\u4e00\u4e2a\u7279\u5f81 \u6bd4\u5982\u8bf4 \u5085\u91cc\u53f6\u53d8\u6362 \u5f97\u5230\u4e00\u4e2a\u9891\u8c31\u7279\u5f81\uff0c\u7136\u540e \u6211\u4eec\u5bf9\u6bcf\u4e00\u5e27 \u8fdb\u884c\u5355\u72ec\u5efa\u6a21\uff0c\u6240\u8c13 no window\u5c31\u662f \u6211\u4eec\u4e0d\u8003\u8651 \u5468\u56f4\u7684\u5e27\uff0c\u53ea\u8003\u8651 \u5f53\u524d\u8fd9\u4e2a15\u6beb\u79d2\uff0c\u7136\u540e \u6211\u4eec \u628a\u5b83\u9001\u5165 DNN\u4e2d\uff0c\u6765\u53bb \u8fdb\u884c\u4e00\u4e2a \u9884\u6d4b \u5206\u7c7b\uff0c\u8fd9\u6837\u505a\u7684\u8bdd \u5b83\u7684 \u8bad\u7ec3\u8bef\u5dee \u548c\u6d4b\u8bd5\u8bef\u5dee \u5927\u6982\u90fd\u662f\u5728 40% \u5de6\u53f3\uff1b</p> <p></p> <p>\uff082\uff09\uff0810 frame window\u3001stride\uff09</p> <p>\u7b2c\u4e8c\u884c MLP 10\u5e27\u4f5c\u4e3a\u4e00\u4e2a\u7a97 \u610f\u601d\u662f \u6211\u4eec\u73b0\u5728 \u540c\u6837\u8fd8\u662fMLP\uff0c\u4f46\u662f \u73b0\u5728MLP\u7684 \u8f93\u5165 \u4e0d\u4ec5\u662f \u53ea\u6709\u4e00\u5e27\u7684\u7279\u5f81\uff0c\u800c\u662f\u628a \u6bcf10\u5e27 \u653e\u5230\u4e00\u8d77\uff0c\u90a3\u4e48\u8fd9\u91cc\u662f\u5426\u6709stride\uff0c\u5c31\u662f\u8bf4 \u8fd910\u5e27 \u5230\u5e95\u6709\u6ca1\u6709\u4ea4\u53e0 \u5e76\u6ca1\u6709\u4ecb\u7ecd\uff0c\u603b\u4e4b \u7b2c\u4e8c\u884c\u8fd9\u4e2a \u8f93\u5165 \u6bd4 \u7b2c\u4e00\u884c \u8986\u76d6\u7684 \u65f6\u95f4\u7a97\u53e3 \u4f1a\u66f4\u5927\u4e00\u70b9 \uff1b</p> <p>\u90a3\u4e48\u8fd9\u6837\u53ef\u4ee5\u770b\u5230 \u8fd9\u4e2a\u8bef\u5dee\uff0c\u663e\u8457\u7684\u4ece 46% \u964d\u5230 32%\uff0c\u8fd9\u4e2a\u7ed3\u679c\u8bf4\u660e \u5728\u8bed\u97f3\u8bc6\u522b \u8fd9\u4e2a\u5e8f\u5217\u5efa\u6a21 \u4efb\u52a1\u4e2d\uff0c\u5f53\u6211\u4eec\u628a \u4e0a\u4e0b\u6587\u7279\u5f81 \u4e00\u8d77\u8003\u8651\u7684\u8bdd \u6548\u679c\u4f1a \u66f4\u597d\uff1b\u8fd9\u662f\u7b2c\u4e8c\u884c\u3002</p> <p></p> <p>\uff083\uff09delay</p> <p>\u7b2c\u4e09\u884c\uff0c\u5c06MLP\u6362\u6210\u4e86 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u4e00\u4e2a\u7b80\u5355\u7684RNN \u6a21\u578b\uff0c\u5e76\u4e14\u62ec\u53f7 delay 0\uff0c\u7b49\u4e0b\u4f1a\u89e3\u91ca \u4ec0\u4e48\u53ebdelay\uff0c\u8fd9\u91cc\u7684\u610f\u601d\u5c31\u8bf4\uff0c\u5c31\u662f\u8bf4 \u628a \u6bcf\u4e00\u5e27\u7279\u5f81 \u50cf \u7b2c\u4e00\u5e45\u56fe\u4e00\u6837\uff0c\u6bd4\u5982\u8bf4</p> <p></p> <p>\u8fd9\u91cc\u662f\u7b2c\u4e00\u5e27\u7684\u7279\u5f81\uff0c\u8fd9\u91cc\u662f\u7b2c\u4e8c\u5e27\u7684\u7279\u5f81\uff0c\u8fd9\u91cc\u662f\u7b2c\u4e09\u5e27\u7684\u7279\u5f81\uff0c\u6211\u4eec\u628a\u6bcf\u4e00\u5e27\u7684\u7279\u5f81 \u9001\u5165\u5230RNN\u4e2d\uff0c\u901a\u8fc7\u4e2d\u95f4\u7684\u9690\u542b\u5c42 \u5bf9\u5386\u53f2\u4fe1\u606f \u8fdb\u884c\u66f4\u65b0\uff0c\u8fd9\u6837\u7684\u7f51\u7edc \u9519\u8bef\u7387\u4e5f\u662f\u76f8\u6bd4MLP \u66f4\u8fdb\u4e00\u6b65\uff0c\u770b\u5230\u8bad\u7ec3\u8bef\u5dee\u523030%\uff0c\u6d4b\u8bd5\u8bef\u5dee\u662f35%\uff0c\u76f8\u6bd4\u4e8e\u4e0a\u9762 10\u5e27\u7684MLP\uff0c\u6548\u679c\u66f4\u597d\u3002</p> <p>\uff084\uff09LSTM</p> <p></p> <ul> <li>\u63a5\u4e0b\u6765 \u5982\u679c\u6211\u4eec\u628aRNN\uff0c\u66ff\u6362\u6210LSTM\uff0c\u6548\u679c\u66f4\u8fdb\u4e00\u6b65</li> <li>\u90fd\u662fdelay 0</li> </ul> <p>\uff085\uff09LSTM+backwards</p> <p></p> <p>\u518d\u4e0b\u9762\u4e00\u6b65\uff0c\u8fd8\u662fLSTM\uff0c\u53ea\u662f\u628a\u8f93\u5165 \u7ffb\u8f6c\u8fc7\u6765\uff0c\u4e5f\u5c31\u662f\u628ainput\u5e8f\u5217\u5012\u8fc7\u6765\uff0c\u518d\u8f93\u5165\u5230\u7f51\u7edc\u4e2d\uff0c\u8bef\u5dee\u662f\u5dee\u4e0d\u591a\u7684\uff0c\u6240\u4ee5 \u4ec5\u4ec5\u662f\u4e00\u6761\u94fe\u7684\u8bdd\uff0c\u4e0d\u8bba\u662f\u6b63\u5411\u8bc6\u522b\uff0c\u8fd8\u662f\u53cd\u5411\u8bc6\u522b \u5176\u5b9e\u6548\u679c\u662f\u5dee\u4e0d\u591a\u7684</p> <p>\uff086\uff09RNN delay 3</p> <p></p> <p>\u5bf9\u8f93\u5165\u8fdb\u884c\u6539\u9020\uff0c\u9996\u5148\u53ef\u4ee5\u770b\u5230 \u540c\u6837\u662f\u7528 RNN\u7f51\u7edc\uff0c\u8fd9\u91cc \u5bf9\u5b83 \u8fdb\u884c delay \u4e09\u5e27\uff0c\u7136\u540e\u53ef\u4ee5\u770b\u5230 \u5b83\u7684\u6548\u679c \u76f8\u6bd4\u4e8e\u539f\u672c\u7684 RNN \u4ece30% \u964d\u4f4e\u5230 29%\uff0c\u6d4b\u8bd5\u8bef\u5dee \u4e5f\u662f\u4ece 35% \u964d\u4f4e\u5230 34%\uff1b</p> <ul> <li> \u90a3\u4e48\u8fd9\u4e2a delay 3 \u5e27\u662f\u4ec0\u4e48\u610f\u601d\u5462\uff1f</li> </ul> <p></p> <p>delay 3 \u5e27\u7684\u610f\u601d\u5c31\u662f\u8bf4\uff0c\u5f53 \u5582\u5165 \u4e09\u5e27 \u4f5c\u4e3a \u8f93\u5165\u7684\u65f6\u5019\uff0c\u524d\u9762 \u8fd9\u4e09\u4e2a\u8f93\u51fa\uff0c\u5148\u4e0d\u8981\uff0c</p> <p>\u5c31\u662f\u8bf4 \u5148\u62ff \u4e09\u5e27\u8f93\u5165 \u9001\u5165\u5230\u7f51\u7edc\u4e2d \u8ba9\u5b83\u5148\u5bf9\u8bb0\u5fc6\u5355\u5143 \u53bb \u66f4\u65b0\u4e09\u6b65 \uff0c\u7136\u540e\u5230\u7b2c\u56db\u6b65\uff08\u5e27\uff09\u7684 \u8f93\u5165\u7684\u65f6\u5019\uff0c\u624d \u628a \u8f93\u51fa\u62ff\u51fa\u6765\uff0c \u4f5c\u4e3a \u7b2c\u4e00\u5e27\u7684\u9884\u6d4b\u503c\uff0c\u8fd9\u4e2a\u5c31\u662fdelay 3\u7684\u610f\u601d</p> <ul> <li> \u4e3a\u4ec0\u4e48 delay 3 \u5e27\u6548\u679c\u6709\u6548\uff1f</li> </ul> <p>\u5982\u679c \u4e0d\u505adelay\u7684\u8bdd \uff0c\u5728 \u8f93\u5165 \u7b2c\u4e00\u5e27\u7684 \u7279\u5f81\u7684\u65f6\u5019\uff0c\u5b83\u7684\u9884\u6d4b\u7684\u8f93\u51fa \u53ea\u80fd \u770b\u5230\u5f53\u524d\u7684\u7b2c\u4e00\u5e27\uff0c\u8303\u56f4\u5c31\u5f88\u5c0f\uff1b</p> <p>\u4f46\u662f\u5f53 delay \u4e09\u5e27\u7684\u65f6\u5019 \u9884\u6d4b\u7b2c\u4e00\u5e27\u7684\u8f93\u51fa \u5176\u5b9e\u5c31\u770b\u5230\u4e86 \u4e09\u5e27\uff0c\u5b83\u770b\u5230\u4e86 \u7b2c\u4e00\u5e27\u3001\u7b2c\u4e8c\u5e27\u3001\u7b2c\u4e09\u5e27 \u90fd\u8fdb\u5165\u4e86 \u8bb0\u5fc6\u5355\u5143\u4e2d\uff1b</p> <p>\u4ee5\u4e0a\u5c31\u662f delay RNN\u7684\u7ed3\u6784\uff1b</p> <ul> <li> \u518d\u6b21\u89e3\u91ca delay</li> </ul> <p>delay \u80fd\u591f\u5728 \u77ed\u6682 \u7684 \u727a\u7272 \u65f6\u5ef6\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u9ad8\u7cbe\u5ea6\uff0c\u770b\u5230\u66f4\u5bbd\u7684\u4e0a\u4e0b\u6587</p> <p>\u6709 delay \u7684\u8bdd\uff0c\u5728\u9884\u6d4b\u7b2c\u4e00\u5e27\u7684\u8f93\u51fa\u7684\u65f6\u5019 \u80af\u5b9a\u4f1a \u7a0d\u5fae \u5ef6\u8fdf\u4e00\u70b9\uff0c\u56e0\u4e3a \u5982\u679c \u4e0d\u505a delay\u7684\u8bdd\uff0c\u6211\u4eec\u5c31\u76f4\u63a5 \u7b97\u4e00\u6b65\u5c31\u597d\u4e86\uff0c\u5982\u679cdelay \u4e09\u5e27\u7684\u8bdd\uff0c\u90a3\u5728\u9884\u6d4b\u7b2c\u4e00\u5e27\u7684\u8f93\u51fa\u7684\u65f6\u5019\uff0c\u9700\u8981\u8ba1\u7b97 \u4e09\u6b65\uff0c\u6240\u4ee5\u80af\u5b9a\u4f1a\u6709 \u4e00\u5b9a\u65f6\u5ef6\u7684\u3002\u4f46\u662f\u8fd9\u4e2a\u65f6\u5ef6 \u786e\u5b9e\u80fd\u591f \u4f7f\u5f97 \u9884\u6d4b\u7684\u6548\u679c\u66f4\u597d\uff0c\u56e0\u4e3a\u5b83\u770b\u5230\u7684\u4e0a\u4e0b\u6587 \u4f1a \u66f4\u5bbd\u4e00\u70b9\uff1b\u4ee5\u4e0a\u662fdelay\u7684\u610f\u601d\u3002</p> <p>\uff087\uff09B </p> <p></p> <p>\u53cc\u5411\u7684LSTM\u3001RNN</p> <p></p> <ul> <li>RNN delay\u4e09\u5e27 \u548cLSTM delay \u4e94\u5e27 \u6548\u679c\u90fd\u6709\u4e0d\u540c\u7a0b\u5ea6\u7684\u589e\u52a0\uff1b</li> <li>\u53cc\u5411\u7684\u7ed3\u679c\u6bd4delay \u548c \u5355\u5411\u7684 \u6548\u679c\u90fd\u8981\u597d\uff1b</li> <li>\u8bad\u7ec3\u96c6 \u9519\u8bef\u7387\u4ece29%\u964d\u4f4e\u523024%\uff1b</li> <li>\u6d4b\u8bd5\u96c6\u9519\u8bef\u7387\u4e5f\u662f\u660e\u663e\u964d\u4f4e\uff1b</li> </ul> <p>\u53cc\u5411\u3001delay </p> <ul> <li>\u8868\u793a \u770b\u5230\u4e86\u672a\u6765\u7684\u4fe1\u606f\uff1b</li> <li>\u5f53 delay\u4e09\u5e27\u7684\u8bdd\uff0c\u5728\u9884\u6d4b\u7b2c\u4e00\u5e27\u7684\u8f93\u51fa\u7684\u65f6\u5019 \u5176\u5b9e\u662f\u770b\u5230\u4e86\u7b2c\u4e8c\u5e27\u3001\u7b2c\u4e09\u5e27\u3001\u7b2c\u56db\u5e27  \u6307\u7684\u662f \u770b\u5230\u4e86\u672a\u6765\u7684\u4e09\u5e27\u7684</li> <li>\u5f53\u9884\u6d4b \u7b2c\u4e8c\u5e27\u7684\u8f93\u51fa\u7684\u65f6\u5019 \u540c\u6837 \u770b\u5230\u7b2c\u4e09\u5e27\u3001\u7b2c\u56db\u5e27\u3001\u7b2c\u4e94\u5e27</li> <li> <p>\u867d\u7136\u4e5f\u770b\u5230\u4e86\u672a\u6765\u7684\u4fe1\u606f\uff0c\u4f46\u770b\u5230\u672a\u6765\u7684\u4fe1\u606f\u8fd8\u662f\u4e0d\u591f\u957f\uff1b</p> </li> <li> <p>\u5982\u679c\u628a\u5355\u5411 \u6362\u6210\u53cc\u5411\u7684\u7f51\u7edc\u7684\u8bdd\uff0c\u90a3\u4e48\u6574\u4e2a\u672a\u6765\u7684\u7279\u5f81 \u548c \u8fc7\u53bb\u7684 \u7279\u5f81\uff0c\u7f51\u7edc\u90fd\u80fd\u770b\u5230\uff0c\u8fd9\u5c31\u662f\u8bf4\u53cc\u5411\u7684\u8303\u56f4 \u66f4\u5927\u4e00\u70b9\uff1b</p> </li> </ul> <ul> <li> <p>\u5355\u5411delay 3\uff1a\u8f93\u51fa\u7b2c\u4e00\u5e27\u770b\u5230\u7684\u662f \u8f93\u5165\u7b2c\u4e00\u5e27\u3001\u7b2c\u4e8c\u5e27\u3001\u7b2c\u4e09\u5e27</p> </li> <li> <p>\u53cc\u5411delaye 3\uff1a\u8f93\u51fa\u7b2c\u4e00\u5e27\uff0c\u770b\u5230\u7684\u662f\u7b2c\u4e00\u5e27\u3001\u7b2c\u4e8c\u5e27\u3001\u7b2c\u4e09\u5e27+\u7b2c\u56db\u5e27\u3001\u7b2c\u4e94\u5e27\u3001\u7b2c\u516d\u5e27 </p> </li> </ul> <p>\u53cc\u5411\u7684\u7f3a\u70b9</p> <p>\u9700\u8981\u5b8c\u5168\u7684 \u628a\u6574\u4e2a\u8f93\u5165\u7279\u5f81\u5e8f\u5217 \u9001\u5165\u5230\u7f51\u7edc\u4e2d \uff0c\u6700\u540e\u624d\u80fd\u5f97\u5230\u8f93\u51fa</p> <p>\u800c\u5355\u5411\u5e26\u65f6\u5ef6\u7684\u60c5\u51b5\u5c31\u4e0d\u9700\u8981\u628a\u6574\u4e2a\u7279\u5f81 \u90fd\u7b97\u51fa\u6765 \u624d\u80fd\u9884\u6d4b\u7b2c\u4e00\u5e27\uff0c\u53ea\u8981\u6709\u4e09\u5e27\u4e86\uff0c\u5c31\u53ef\u4ee5\u9884\u6d4b\u7b2c\u4e00\u5e27\u4e86\uff1b</p> <p>\u6240\u4ee5\u5355\u5411\u5e26\u65f6\u5ef6\u7684\uff0c\u54cd\u5e94\u901f\u5ea6\u4f1a\u66f4\u5feb\uff1b</p> <p>\u53cc\u5411\u7684\u54cd\u5e94\u901f\u5ea6\u80af\u5b9a\u662f\u6700\u6162\u7684\uff1b</p> <p>\u6240\u4ee5\u5728\u901f\u5ea6 \u548c\u6548\u679c\u4e0a \u9700\u8981 \u53d6\u5f97\u4e00\u4e2a\u6bd4\u8f83\u597d\u7684\u5e73\u8861 \u624d\u80fd\u6ee1\u8db3\u5177\u4f53\u7684\u4e1a\u52a1\u9700\u6c42\u3002</p>"},{"location":"learning/13_RNN/#k4","title":"k4 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u7f3a\u70b9","text":"<p>\u4e00\u3001\u4f18\u70b9</p> <p>\uff081\uff09\u6743\u91cd\u5171\u4eab\u53ef\u4ee5\u5904\u7406\u53d8\u957f\u5e8f\u5217</p> <p>\uff082\uff09\u6a21\u578b\u7684\u5927\u5c0f \u4e0e \u5e8f\u5217\u957f\u5ea6\u65e0\u5173</p> <p>\uff083\uff09\u8ba1\u7b97\u91cf\u4e0e\u5e8f\u5217\u957f\u5ea6\u5448\u73b0\u7ebf\u6027\u5173\u7cfb</p> <p>\uff084\uff09\u8003\u8651\u5386\u53f2\u4fe1\u606f</p> <p>\uff085\uff09\u4fbf\u4e8e\u6d41\u5f0f\u8f93\u51fa</p> <p>\uff086\uff09\u6743\u91cd\u65f6\u4e0d\u53d8</p> <p>\u4e8c\u3001\u7f3a\u70b9</p> <p>\uff081\uff09\u4e32\u884c\u8ba1\u7b97\u901f\u5ea6\u6162</p> <p>\uff082\uff09\u65e0\u6cd5\u83b7\u53d6\u592a\u957f\u7684\u5386\u53f2\u4fe1\u606f</p> <p>\u7b2c\u4e00\u70b9</p> <p>\u4f18\u70b9\u53ef\u4ee5\u5904\u7406\u53d8\u957f\u5e8f\u5217</p> <p>\u8fd9\u4e2a\u662fDNN\u548cCNN\u5904\u7406\u4e0d\u4e86\u7684\uff0c\u6bd4\u5982DNN\uff0c\u8f93\u5165\u7684\u7279\u5f81\u662f\u56fa\u5b9a\u7684\uff0c\u800cCNN\u7684\u4e0d\u4ec5\u548ckernel size\u6709\u5173\uff0c\u8fd8\u8ddf\u8f93\u5165\u7684\u901a\u9053\u6570\u6709\u5173\uff0c\u6240\u4ee5\u5982\u679cCNN \u8f93\u5165\u901a\u9053\u6570\u6709\u53d8\u5316\u7684\u8bdd \u8fd8\u9700\u8981\u91cd\u65b0\u642d\u5efa\u4e00\u4e2a\u7f51\u7edc\uff0c\u800cRNN \u662f\u53ef\u4ee5\u5904\u7406\u53d8\u957f\u5e8f\u5217\u7684</p> <ul> <li> \u4e3a\u4ec0\u4e48RNN \u80fd\u5904\u7406\u53d8\u957f\u5e8f\u5217\u5462\uff1f</li> </ul> <p></p> <p>\u539f\u56e0\u662f\u56e0\u4e3a\uff0c\u53ef\u4ee5\u770b\u5230\u56fe\u4e2d \u6709\u4e00\u4e2aw</p> <p>\u4e5f\u5c31\u662f \u6743\u91cd\uff0c\u8fd9\u4e2aw\u5728\u6bcf\u4e2a\u65f6\u523b \u90fd\u662f\u76f8\u7b49\u7684\uff0c\u6b63\u662f\u56e0\u4e3a \u6240\u6709\u7684\u6743\u91cd\uff0c\u5728\u6bcf\u4e00\u4e2a\u65f6\u523b\u90fd\u662f\u76f8\u7b49\u7684\uff1b\u4e0d\u8bba\u662f \u8f93\u5165 \u8ddf\u65e2\u6709\u5355\u5143\u7684\u8fde\u63a5\uff0c\u8fd8\u662f\u5386\u53f2\u4fe1\u606f \u8ddf\u5f53\u524d\u7684\u795e\u7ecf\u5143\u7684\u8fde\u63a5 \u5b83\u7684\u6743\u91cd\u90fd\u662f\u56fa\u5b9a\u7684\uff0c\u6b63\u662f\u56e0\u4e3a \u6743\u91cd \u5728\u6bcf\u4e00\u65f6\u523b \u5171\u4eab\uff0c\u6240\u4ee5 RNN \u80fd\u591f\u5904\u7406\u53d8\u957f\u5e8f\u5217\uff1b</p> <p>\u4e00\u65e6\u53bb\u6389\u4e86 \u6743\u91cd \u5171\u4eab \u8fd9\u4e2a\u5f52\u7eb3\u504f\u7f6e\u7684\u8bdd\uff0c\u5c31\u662f\u8bf4\uff0c\u5982\u679c\u6bcf\u4e00\u65f6\u523b \u90fd\u6709\u4e00\u4e2a \u4e0d\u4e00\u6837\u7684 w\u7684\u8bdd\uff0c\u8fd9\u4e2a\u65f6\u5019 \u5c31\u4e0d\u80fd\u5904\u7406 \u53d8\u957f\u5e8f\u5217\u4e86\uff0c\u5c31\u7c7b\u4f3c position embedding \u4e00\u6837\uff0c\u53ea\u8981\u9047\u5230\u4e86 \u957f\u5ea6 \u6bd4\u8bad\u7ec3\u96c6\u5927\u7684\uff0c\u90a3\u5c31\u5904\u7406\u4e0d\u4e86\u4e86\uff08\u4e5f\u4e0d\u662f\uff0c\u4e09\u89d2\u53d8\u6362\uff09\uff1b</p> <p>\u7b2c\u4e8c\u70b9</p> <p></p> <p>\u7b2c\u4e8c\u70b9\uff0c\u6a21\u578b\u7684\u5927\u5c0f \u4e0e \u5e8f\u5217\u957f\u5ea6\u65e0\u5173\uff0c\u8fd9\u91cc\u8bf4\u7684\u662f \u6a21\u578b\u7684\u5927\u5c0f\uff0c\u662f\u8bf4\u6a21\u578b\u7684\u53c2\u6570\u6570\u91cf \u4e0e \u957f\u5ea6\u65e0\u5173\uff0c\u6a21\u578b\u7684\u5168\u90e8\u53c2\u6570 \u548c\u5e8f\u5217\u957f\u5ea6 \u90fd\u662f\u65e0\u5173\u7684\uff0c\u53ea\u8f93\u5165\u7279\u5f81 \u548c\u8f93\u5165\u901a\u9053\u6570 \u4ee5\u53caRNN\u7684\u9690\u542b\u5355\u5143\u6709\u5173</p> <p>\u7b2c\u4e09\u70b9</p> <p></p> <p>\u7b2c\u4e09\u4e2a\u4f18\u70b9\u5c31\u662f RNN\u7684\u8ba1\u7b97\u91cf \u8ddf \u5e8f\u5217\u957f\u5ea6 \u5448\u7ebf\u6027\u589e\u957f\uff0c\u7c7b\u6bd4Transformer\uff0c\u5728\u539f\u672c\u7684Transformer\u4e2d \u6700\u5927\u7684\u4e00\u4e2a \u8bdf\u75c5\u7684\u5730\u65b9 \u5c31\u662f \u8ba1\u7b97\u590d\u6742\u5ea6 \u8ddf\u5e8f\u5217\u957f\u5ea6 \u662f\u5448\u4e00\u4e2a\u5e73\u65b9\u5173\u7cfb\u7684\uff0c\u4f46\u662f\u5728RNN\u4e2d\uff0c\u8ba1\u7b97\u91cf \u662f\u8ddf\u957f\u5ea6 \u5448\u73b0 \u7ebf\u6027\u589e\u957f\u7684\uff1b</p> <p>\u4e3e\u4f8b\u5b50\uff1a</p> <p>\u5f53 \u5e8f\u5217\u957f\u5ea6 \u4e3a2\u7684 \u65f6\u5019\uff0c\u8ba1\u7b97\u91cf \u53ef\u80fd\u5c31\u662f2t</p> <p>\uff08t\u6307\u7684\u662f\u65f6\u95f4\uff1f\u6a21\u578b \u56fa\u6709\u7684\u8ba1\u7b97\u91cf\uff09</p> <p>\u5f53\u5e8f\u5217\u957f\u5ea6\u4e3a3 \u7684\u65f6\u5019\uff0c\u8ba1\u7b97\u91cf \u5c31\u662f3t\uff0c\u5c31\u4e0d\u662f\u8bf4 \u4ece 4\u53d8\u62109\uff0c\u5448\u73b0 \u5e73\u65b9\u5173\u7cfb\u3002</p> <p>\u5728RNN\u4e2d \u5448\u73b0 \u7ebf\u6027\u5173\u7cfb\uff1b\u8fd9\u662f\u8ddf Transformer \u5728\u8ba1\u7b97\u91cf\u4e0a \u4e00\u4e2a\u660e\u663e\u7684\u533a\u522b\u3002</p> <p>\u7b2c\u56db\u70b9</p> <p></p> <p>\u76f8\u6bd4DNN\u800c\u8a00\uff0cRNN\u662f\u53ef\u4ee5\u8003\u8651\u5230 \u5386\u53f2\u4fe1\u606f\u7684\uff0c\u56e0\u4e3a\u6709\u94fe\u5f0f\u7684\u7ed3\u6784\uff0c\u53ef\u4ee5\u901a\u8fc7\u9690\u542b\u5c42 \u6765\u79ef\u7d2f \u5386\u53f2\u4fe1\u606f\uff1b</p> <p>\u7b2c\u4e94\u70b9</p> <p></p> <p>\u6d41\u5f0f \u8f93\u51fa\uff0c\u53ef\u4ee5\u770b\u5230\uff1a</p> <p></p> <ul> <li> \u6d41\u5f0f\u8f93\u51fa\u662f\u4ec0\u4e48\uff1f</li> </ul> <p>\u6bcf \u8ba1\u7b97\u4e00\u6b65\uff0c\u90fd\u53ef\u4ee5\u5f97\u5230 \u4e00\u4e2a\u8f93\u51fa\uff0c\u8fd9\u4e2a\u8f93\u51fa \u53ef\u4ee5\u76f4\u63a5 \u9001\u7ed9 \u7528\u6237\uff0c\u8fd9\u5c31\u662f \u6d41\u5f0f \u7684\u610f\u601d\u3002</p> <p>\u4f46\u662f\u5bf9\u4e8e Transformer\u800c\u8a00\u7684\u8bdd\uff0c\u7531\u4e8e\u5b83\u662f\u8003\u8651\u5230\u5168\u5c40\u7684\u4fe1\u606f \u8ba1\u7b97\u4e00\u4e2a \u5168\u5c40\u7684self attention\uff0c\u6240\u4ee5\u5c31\u4e0d\u80fd\u5355\u6b65 \u7684\u8ba1\u7b97 \u6bcf\u4e00\u6b65\u7684 \u8f93\u51fa\uff0c\u8fd9\u5c31\u662f Transformer\u7684\u4e00\u4e2a\u7f3a\u70b9\uff0c\u4e0d\u80fd\u76f4\u63a5\u7684 \u5e94\u7528\u5230 \u6d41\u5f0f\u7684\u573a\u666f\uff1b</p> <p>\u4f46\u662f\u5728\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u53ea\u8981\u6bcf\u7b97\u4e00\u6b21 \u9012\u5f52\u8fd0\u7b97\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\uff0c\u8fd9\u4e2a \u8f93\u51fa\u5c31\u53ef\u4ee5\u76f4\u63a5\u8fd4\u56de\u7ed9\u7528\u6237\uff0c\u8fd9\u5c31\u662f\u6d41\u5f0f\u7684\uff0c\u4e5f\u5c31\u662f \u4e0d\u9700\u8981 \u628a \u6574\u4e2a\u5e8f\u5217 \u90fd\u7b97\u5b8c \u624d\u8fd4\u56de\u7ed9\u7528\u6237\uff0c\u800c\u662f\u8bf4 \u6bcf\u7b97\u51fa\u4e00\u4e2a \u65f6\u523b \u90fd\u53ef\u4ee5\u8fd4\u56de\u7ed9\u7528\u6237</p> <p>\u7b2c\u516d\u70b9</p> <p></p> <p>\u6743\u91cd\u65f6\u4e0d\u53d8</p> <p>\u6743\u91cd\u662f \u65f6\u4e0d\u53d8\u7684\uff0c\u6b63\u662f\u56e0\u4e3aRNN \u6743\u91cd \u65f6\u4e0d\u53d8\uff0c\u6240\u4ee5RNN \u53ef\u4ee5\u5904\u7406 \u53d8\u957f\u5e8f\u5217\uff1b</p> <p>\u4e8c\u3001\u7f3a\u70b9</p> <p></p> <ul> <li> \u4e3a\u4ec0\u4e48\u8bf4 \u4e32\u884c\u8ba1\u7b97\u6162</li> </ul> <p>\u56e0\u4e3a \u5728\u7b97 \u6bcf\u4e00\u65f6\u523b\u7684\u65f6\u5019 \u90fd\u9700\u8981\u7b49 \u4e0a\u4e00\u65f6\u523b\u7684\u5386\u53f2\u4fe1\u606f\uff0c\u7b49\u4e0a\u4e00\u65f6\u523b\u7684\u7b97\u51fa\u6765 \u624d\u80fd\u7b97 \u4e0b\u4e00\u65f6\u523b\uff0c\u662f\u4e00\u4e2a \u4e32\u884c\u7684\u8fc7\u7a0b\uff0c\u6bd4\u8f83\u6162</p> <ul> <li> \u600e\u4e48\u7406\u89e3 RNN \u4e5f\u662f\u65e0\u6cd5\u83b7\u53d6\u592a\u957f\u7684\u5386\u53f2\u4fe1\u606f</li> </ul> <p>\u4e5f\u5c31\u662f\u8bf4 \u7531\u4e8e\u68af\u5ea6\u6d88\u5931\u7684\u95ee\u9898\uff0c\u5bfc\u81f4RNN\u65e0\u6cd5 \u4ece\u5f53\u524d\u65f6\u523b \u83b7\u53d6\u5f88\u4e45\u8fdc\u7684\u4fe1\u606f</p> <p>RNN \u7531\u4e8e\u68af\u5ea6\u6d88\u5931\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u83b7\u5f97\u592a\u957f\u7684\u5386\u53f2\u4fe1\u606f\u3002</p> <p>\u8fd9\u4e00\u70b9\u6b63\u662fTransformer\u7684\u4f18\u70b9\u3002</p> <p>Transformer\u7684\u5f52\u7eb3\u504f\u7f6e \u662f\u6bd4\u8f83\u5f31\u7684\uff0c\u662f\u901a\u8fc7\u4e00\u4e2a \u5168\u5c40\u7684self attention\uff0c\u6765\u8ba1\u7b97 \u4e24\u4e24\u4f4d\u7f6e\u4e4b\u95f4\u7684\u4e00\u4e2a\u76f8\u5173\u6027\uff0c\u6240\u4ee5Transformer\u662f\u53ef\u4ee5\u4e0a\u4e0b\u53bb\u6355\u6349 \u5f88\u957f\u7684\u5386\u53f2\u5173\u8054\u6027\u7684\u3002</p>"},{"location":"learning/13_RNN/#k5-rnn","title":"k5 RNN \u7684\u5e94\u7528\u573a\u666f","text":"<p>\uff081\uff09\u751f\u6210\u4efb\u52a1</p> <p>\u751f\u6210\u4efb\u52a1\uff0c\u6bd4\u5982\u6b4c\u8bcd\u751f\u6210\u3001\u5bf9\u8054\u751f\u6210\u3001\u50cfGPT\u4e00\u6837\u5199\u5c0f\u8bf4</p> <p>\u751f\u6210\u4efb\u52a1\uff0c\u5982\u679c\u7528\u4e00\u5e45\u56fe\u6765\u8868\u793a\uff1a</p> <p></p> <p>1\u3001\u5982\u56fe\u8868\u793aRNN\u5728\u8bd7\u6b4c\u3001\u8bed\u97f3\u3001\u7b26\u53f7\u751f\u6210\u4e2d\u7684\u8868\u793a</p> <p>2\u3001\u8fd9\u7c7b\u4efb\u52a1\u53ef\u4ee5\u770b\u6210one to many\u7684\u8fc7\u7a0b\uff0c\u4e5f\u5c31\u662f\u8bf4 \u53ea\u8981\u7ed9\u4e86 \u4e00\u4e2a\u8f93\u5165\uff0c\u6216\u8005\u4e00\u4e2a\u5f88\u77ed\u7684 \u8f93\u5165\uff0cRNN\u5c31\u53ef\u4ee5\u5229\u7528\u81ea\u5df1\u7684 \u9012\u5f52\u673a\u5236 \u4e0d\u65ad\u7684\u9884\u6d4b \u65b0\u7684\u8f93\u51fa\uff0c\u5c31\u6bd4\u5982 \u7ed9\u51fa \u4e00\u4e24\u53e5\u8bdd\uff0cRNN \u5199\u51fa\u4e00\u6bb5\u8bdd \u6216\u8005 \u4e00\u7bc7\u6587\u7ae0\uff0c\u5c31\u662f one to many\uff0cRNN\u5728\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5e94\u7528</p> <p>\uff082\uff09\u60c5\u611f\u5206\u7c7b</p> <p>RNN\u4e5f\u80fd\u505a\u60c5\u611f\u5206\u7c7b</p> <p>\u6bd4\u5982\u8bf4\u5f88\u53e4\u8001\u7684\u4e00\u4e2a\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\uff0c\u5bf9\u5f71\u8bc4\u8fdb\u884c\u5206\u7c7b\uff0c\u5224\u65ad\u4e00\u53e5\u8bdd\u662f\u6b63\u5411\u60c5\u611f\u8fd8\u662f\u8d1f\u5411\u60c5\u611f\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\uff0c\u53ef\u4ee5\u770b\u6210many to one\u7684\u4efb\u52a1</p> <p></p> <p>\u8f93\u5165\u662f\u4e00\u6bb5\u8bdd\u6216\u8005\u8bf4\u4e00\u7bc7\u6587\u7ae0\uff0c\u4f46\u662f\u8f93\u51fa \u53ea\u6709\u4e00\u4e2a\uff0c\u53ea\u9700\u8981\u5bf9\u4e00\u6bb5\u8bdd\u9884\u6d4b\u4e00\u4e2a\u7c7b\u522b\u5c31\u597d\u4e86\uff0c\u8fd9\u4e2a\u5c31\u662fmany to one\u7684\u4efb\u52a1\uff0c\u5178\u578b\u7684\u5e94\u7528\u573a\u666f\u5c31\u662f\u53bb\u60c5\u611f\u5206\u7c7b</p> <p></p> <p>many to many\u7684\u4efb\u52a1\uff1a</p> <ul> <li>\u8bcd\u6cd5\u8bc6\u522b</li> <li>\u673a\u5668\u7ffb\u8bd1</li> </ul> <p>\u8bcd\u6cd5\u8bc6\u522b\u5c31\u662f\u8bc6\u522b\u5f53\u524d\u8fd9\u4e2a\u8bcd\u662f\u540d\u8bcd\u8fd8\u662f\u52a8\u8bcd\uff0c\u5f53\u524d\u8fd9\u4e2a\u5355\u8bcd\u591a\u97f3\u5b57\u7b49\u7b49</p> <p>\u673a\u5668\u7ffb\u8bd1\uff0c\u5728Transformer\u4e2d\u662f\u5e94\u7528\u6bd4\u8f83\u591a\u7684\uff1b</p> <p>\u4f46\u662f\u8fd9\u4e24\u79cd many  to many\u7684\u6a21\u578b\u7ed3\u6784\u8fd8\u662f\u6709\u4e00\u4e9b\u533a\u522b\u7684\uff0c\u53ef\u4ee5\u770b\u5230\u4e0b\u9762\u4e24\u5e45\u56fe\uff1a</p> <p>\uff08\u4e00\uff09\u8bcd\u6cd5\u8bc6\u522b</p> <p></p> <ul> <li> <p>\u8bc6\u522b\u4e00\u53e5\u8bdd\u4e2d\uff0c\u6bcf\u4e2a\u5b57\u7684\u62fc\u97f3\u662f\u4ec0\u4e48\uff0c\u6216\u8005\u8bc6\u522b\u6bcf\u4e2a\u8bcd\u7684\u8bcd\u6027\uff0c\u8fd9\u79cd\u5c31\u662fmany to many</p> </li> <li> <p>\u5c5e\u4e8e\u76f4\u8fdb\u76f4\u51fa\u7684many to many</p> </li> </ul> <p>\uff08\u4e8c\uff09\u673a\u5668\u7ffb\u8bd1</p> <p></p> <ul> <li>sequence to sequence \u7ed3\u6784\uff1b</li> <li>\u6709\u7f16\u7801\u5668\uff0c\u6709\u89e3\u7801\u5668\uff0c\u4e2d\u95f4\u4f9d\u9760\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6765\u5e2e\u52a9\u89e3\u7801\u5668\u9884\u6d4b\u6bcf\u4e00\u65f6\u523b\u7684\u8f93\u51fa\uff0c\u4e5f\u662fmany to many\uff1b</li> <li>\u5e38\u89c1\u7684\u5e94\u7528\u573a\u666f\uff1a\u673a\u5668\u7ffb\u8bd1\u3001\u8bed\u97f3\u5408\u6210\u7b49</li> </ul> <p></p> <p>\u8bed\u8a00\u6a21\u578b RNNLM\uff1b</p> <p>\u603b\u4e4b\u5c31\u662f</p> <ul> <li>one to one</li> <li>Many to one</li> <li>many to many</li> </ul>"},{"location":"learning/13_RNN/#k6-rnn","title":"k6  RNN\u6846\u56fe","text":""},{"location":"learning/13_RNN/#torchnnrnn","title":"torch.nn.RNN","text":"<ul> <li> <p>\u53ef\u4ee5\u7528\u6765\u6784\u9020\u4e00\u5c42 \u6216\u8005\u591a\u5c42 \u7b80\u5355\u7684RNN\u7ed3\u6784\uff1b </p> </li> <li> <p>RNN\u8fd8\u6709\u53e6\u5916\u4e00\u79cd\u7ed3\u6784\uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u53ef\u4ee5\u7528tanh\u6fc0\u6d3b\u51fd\u6570 \u6216\u8005 ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4f7f\u5f97RNN\u6709\u66f4\u5f3a\u7684\u975e\u7ebf\u6027\u5efa\u6a21\u80fd\u529b\uff1b</p> </li> <li> <p> RNN \u8ba1\u7b97\u516c\u5f0f\u662f\u4ec0\u4e48\u5462\uff1f</p> </li> </ul> <p></p> <ul> <li> <p>\u6bcf\u4e00\u65f6\u523b\u7684\u8f93\u51fa\uff0c\u6216\u8005\u8bf4\u6bcf\u4e00\u65f6\u523b\u7684\u72b6\u6001</p> </li> <li> <p>\u5728\u7b80\u5355RNN\u4e2d\uff0c\u8f93\u51fa\u662f\u7b49\u4e8e\u72b6\u6001\u7684\uff0c \\(h_t\\)\u4e5f\u5c31\u662f \\(t\\) \u65f6\u523b\u7684\u8f93\u51fa\uff1b</p> </li> <li> <p>\u6216\u8005\u8bf4 t \u65f6\u523bRNN\u7684\u72b6\u6001 \u7b49\u4e8e tanh\u51fd\u6570\uff0c\u5c31\u662f\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u91cc\u9762\u5206\u522b\u662f \\(W_{ih}\u00d7x_t\\) \u518d\u52a0\u4e0a \\(b_{ih}\\)\uff0c\u90a3\u4e48\u8fd9\u91cc\u7684\\(x_t\\)\uff0c\u5c31\u662f\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\uff0c\u7136\u540e\\(w_{ih}\\)\uff0c\u5c31\u662f\u5728\u8fd9\u4e2aRNN\u4e2d\uff0c\u5b83\u5bf9\u8f93\u5165\u7684\u6743\u91cd\u77e9\u9635\uff0c\u5c31\u662f \u4f1a\u7528\u8fd9\u4e2a\u77e9\u9635 \u6765\u5bf9\u6743\u91cd \u505a\u4e00\u4e2a\u6620\u5c04\uff0c\u7136\u540e\u6574\u4f53\u4e0a\uff0c\u8fd9\u4e2a\u4e1c\u897f \u53ef\u4ee5\u770b\u505a linear\u5c42\uff0c\u6709\u6743\u91cd \u8fd8\u6709 \u504f\u7f6e\uff0c\\(b_{ih}\\)\uff0c\u5c31\u662f\u5173\u4e8e \u6743\u91cd\u7684\u4e00\u4e2a\u504f\u7f6e</p> </li> <li> <p>\u540e\u9762 \u8fd8\u6709\u4e00\u9879\uff0c\u8ddf \u5386\u53f2\u72b6\u6001\u6709\u5173\u7684\uff0c\u8ddf \\(h_{t-1}\\) \u6709\u5173\u7684</p> </li> <li>\u4e5f\u5c31\u662f\u8bf4\uff0c\u9700\u8981\u5c06 \u4e0a\u4e00\u65f6\u523b\u7684 \u8f93\u51fa \u6216\u8005\u8bf4 \u4e0a\u4e00\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001 \u62ff\u8fc7\u6765\uff0c\u7136\u540e\u5bf9\u5b83\u8fdb\u884c\u4e00\u4e2a \u6620\u5c04\uff0c\u7528 \\(w_{hh}\\) \u7684\u6743\u91cd \u6765\u8fdb\u884c\u76f8\u4e58\uff0c\u6765\u8fdb\u884c\u6620\u5c04\uff0c\u7136\u540e\u518d\u52a0\u4e0a\u4e00\u4e2a\u504f\u7f6e</li> <li>\u603b\u4f53\u800c\u8a00 \u5c31\u662f\u8bf4 \u6bcf\u4e00\u65f6\u523b\u7684\u8f93\u51fa \u6216\u8005\u8bf4 \u9690\u542b\u72b6\u6001 \u4e0d\u5149\u8ddf\u5f53\u524d\u65f6\u523b \u7684 \u8f93\u5165 \\(x_t\\) \u6709\u5173\uff0c\u540c\u65f6\u4e5f\u8ddf\u4e0a\u4e00\u65f6\u523b\u7684\u8bb0\u5fc6\u5355\u5143  \\(h_{t-1}\\)\u6709\u5173\uff0c\u5e76\u4e14\u90fd\u662f\u7ebf\u6027\u7ec4\u5408\u7684\u5173\u7cfb\uff0c\u6700\u540e\u901a\u8fc7\u4e00\u4e2a\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u5c31\u80fd\u5f97\u5230\u5f53\u524d\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001\uff1b</li> </ul> <p></p> <ul> <li> \u89e3\u91ca\uff1a</li> </ul> <p>\\(h_t\\) \u662f \\(t\\)\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001</p> <p>\\(x_t\\)\u662f t \u65f6\u523b\u7684\u8f93\u5165</p> <p>\\(h_{t-1}\\)\u662f  \\(t-1\\)\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001</p> <p>\\(h_0\\) \u8868\u793a\u521d\u59cb\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001</p> <p>pytorch\u4e2d\u4e5f\u63d0\u4f9b\u4e86\u4e24\u79cd \u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1atanh\u548crelu\u6fc0\u6d3b\u51fd\u6570\uff0c\u9ed8\u8ba4\u7528tanh\u6fc0\u6d3b\u51fd\u6570</p> <p></p> <ul> <li>\u8fd9\u662f\u4e00\u4e2a class</li> <li>\u5728\u7528RNN\u65f6\u5019\uff0c\u9996\u5148\u8981 \u5b9e\u4f8b\u5316 \u8fd9\u4e2aclass</li> <li>\u5b9e\u4f8b\u5316 class\u4ee5\u540e\uff0c\u5f97\u5230RNN\u7684\u4e00\u4e2a\u6a21\u578b</li> <li>\u7136\u540e \u518d\u628a \u8f93\u5165 \u5582\u5165\u5230 \u6a21\u578b\u4e2d\uff0c\u800c\u4e0d\u76f4\u63a5\u628a \u8f93\u5165 \u5582\u5165\u5230\u6a21\u578b\u4e2d\uff1b</li> <li> <p>\u4e00\u822c\u6240\u6709\u6a21\u578b\u7684 class\uff0c\u90fd\u9700\u8981 \u5148\u8fdb\u884c\u4e00\u4e2a\u5b9e\u4f8b\u5316\uff0c\u7136\u540e\u624d\u80fd\u5f97\u5230\u4e00\u4e2alayer\uff1b</p> </li> <li> <p> \u5b9e\u4f8b\u5316RNN\u6240\u9700\u8981\u7684\u53c2\u6570</p> </li> </ul> <p></p> <ul> <li> <p>\u7b2c\u4e00\u4e2a\u53c2\u6570\u662f <code>input_size</code>,\u4e5f\u5c31\u662f \u8f93\u5165\u7279\u5f81\u7684\u5927\u5c0f\uff0c\u4e5f\u5c31\u662f <code>x</code> \u7684\u7279\u5f81\u7684\u7ef4\u5ea6</p> </li> <li> <p>\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f <code>hidden_size</code>\uff0c<code>hidden_size</code>\u51b3\u5b9a\u4e86 \\(h_t\\)\u7684\u5927\u5c0f\uff0c\u5c31\u662f\u6bcf\u4e00\u65f6\u523b\u7684 \\(h_t\\)\u5c31\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u5bf9\u4e8e\u5355\u4e00\u6837\u672c\u800c\u8a00\uff0c\u6bcf\u4e00\u65f6\u523b \\(h_t\\)\u5c31\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u90a3\u4e48\u8fd9\u4e2a\u5411\u91cf\u957f\u5ea6\u662f\u591a\u5c11\u5462\uff1f\u5c31\u662f\u7531 <code>hidden_size</code> \u6765\u51b3\u5b9a</p> </li> <li> <p>\u7b2c\u4e09\u4e2a\u53c2\u6570 \u5c31\u662f <code>num_layers</code>\uff0c\u5c31\u662f\u8bf4 \u8fd9\u4e2aRNN\uff0c\u53ef\u4ee5\u9ed8\u8ba4\u5b9e\u4f8b\u5316\u7684\u65f6\u5019 \u53ea\u6709\u4e00\u5c42\uff0c\u4f46\u662f\u4e5f\u53ef\u4ee5\u6539\u53d8 <code>num_layers</code>\u7684\u503c\uff0c\u53d8\u6210\u591a\u5c42\uff0c\u5806\u53e0\u8d77\u6765\u7684\u7ed3\u6784\uff0c\u4e4b\u524d\u5728\u4ecb\u7ecd\u7684\u65f6\u5019\u4e5f\u8bb2\u8fc7\uff0c\u53ef\u4ee5\u5806\u53e0\u8d77\u6765\uff0c\u5355\u5411\u7684\u53ef\u4ee5\u5806\u53e0\uff0c\u53cc\u5411\u7684 \u4e5f\u53ef \u5806\u53e0</p> </li> <li> <p>\u7b2c\u56db\u4e2a\u53c2\u6570 \u5c31\u662f \u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u8fd9\u91cc\u9ed8\u8ba4\u662f<code>tanh</code>\u51fd\u6570\uff0c\u4e5f\u53ef\u4ee5\u6539\u6210 <code>ReLu</code>\u51fd\u6570</p> </li> <li>\u7b2c\u4e94\u4e2a\u662f<code>bias</code> \u4e00\u822c\u4f1a\u52a0\u4e0a \u8fd9\u4e24\u4e2abias</li> <li>\u7b2c\u516d\u4e2a\u53c2\u6570\u662f <code>batch first</code>\uff0c\u8fd9\u4e2a\u9700\u8981\u6ce8\u610f\u4e00\u4e0b\uff0c\u8fd9\u4e2a\u53c2\u6570\u5c31\u51b3\u5b9a\u4e86 \u8f93\u5165\u548c\u8f93\u51fa\u7684\u683c\u5f0f</li> </ul> <ul> <li>\u5982\u679c\u8bbe\u7f6e <code>batch first=true</code>\u7684\u8bdd\uff1a</li> </ul> <p>\u63d0\u4f9b\u7684\u8f93\u5165\u5f20\u91cf \u548c \u8f93\u51fa\u5f20\u91cf\u7684 \u683c\u5f0f\u5c31\u662f <code>batch \u00d7 sequence length\u00d7feature</code> \u8fd9\u6837\u7684\u683c\u5f0f</p> <p>\u9ed8\u8ba4\u662f<code>false</code>\u7684\uff0c\u5982\u679c\u662f <code>false</code>\u7684\u60c5\u51b5\u4e0b\uff1a</p> <p>\u9700\u8981\u4fdd\u8bc1 \u8f93\u5165\u7684\u683c\u5f0f\u662f <code>sequence length</code>\uff0c\u4e5f\u5c31\u662f\u5e8f\u5217\u957f\u5ea6 \u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff0c<code>batch size</code>\u5728\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\uff0c<code>feature size</code>\u5728\u7b2c\u4e09\u4e2a\u7ef4\u5ea6</p> <ul> <li>\u7b2c\u4e03\u4e2a\u53c2\u6570 <code>dropout</code></li> <li>\u6700\u540e\u4e00\u4e2a\u53c2\u6570<code>bidirectional</code>\uff0c\u6700\u540e\u4e00\u4e2a\u53c2\u6570 \u8868\u793a \u53cc\u5411\u7684\u610f\u601d</li> </ul> <p>\u4e5f\u5c31\u662f\u628a\u8fd9\u4e2a\u53c2\u6570\u8bbe\u7f6e\u4e3a <code>true</code>\u7684\u8bdd\uff0c\u5c31\u53ef\u4ee5\u6784\u5efa\u4e00\u4e2a\u53cc\u5411\u7684RNN\u7ed3\u6784\uff1b</p> <p>\u65e2\u7136\u662f \u53cc\u5411RNN\u7ed3\u6784\uff0c\u8f93\u51fa\u7684\u7279\u5f81\u5927\u5c0f\u5c31\u662f<code>2\u00d7feature size</code>\uff0c\u5c31\u662f2\u500d\u7684<code>feature size</code>\uff1b</p> <p>\u53cc\u5411\u7ed3\u6784\u56fe</p> <p></p> <ul> <li> <p>\u8fd9\u5e45\u56fe \u5c31\u662f \u53cc\u5411\u7684\uff0c\u4e00\u65e6\u628aRNN\u8bbe\u7f6e\u6210 \u53cc\u5411\u7684\u8bdd\uff0c\u6700\u7ec8\u7684\u8f93\u51fa \u662f\u7531<code>forward\u8f93\u51fa</code>\u548c<code>backward\u8f93\u51fa</code>\u4e00\u8d77\u62fc\u8d77\u6765\u7684\uff0c\u6240\u4ee5\u8fd9\u4e2a \u8f93\u51fa\u72b6\u6001\u662f \u4e8c\u500d\u7684 <code>hidden size</code>\uff0c\u53ef\u4ee5\u6307\u5b9a <code>concat</code>\u548c<code>sum</code>\uff0c\u4e00\u822c\u7528 <code>concat</code> \u66f4\u591a\u4e00\u70b9</p> </li> <li> <p>\u4e5f\u5c31\u662f\u8bf4 \u5982\u679c \u8bbe\u7f6e <code>hidden size\u662f16</code>\u7684\u8bdd\uff0c\u90a3\u4e48 <code>output layer</code>\u5927\u5c0f\uff0c\u5c31\u662f32\uff0c\u5982\u679c\u662f\u53cc\u5411\u7684\u8bdd</p> </li> </ul> <p>\u4ee5\u4e0a\u662fRNN\u5b9e\u4f8b\u5316\u7684\u53c2\u6570\u8bb2\u89e3\uff1b</p> <ul> <li>\u5f53\u5b9e\u4f8b\u5316\u5b8c\u4ee5\u540e\uff0c\u5c31\u5f97\u5230\u4e86RNN\u5c42</li> <li>\u7136\u540e\u5c31\u53ef\u4ee5 \u63d0\u4f9b \u8f93\u5165 \u548c \u521d\u59cb\u7684\u9690\u542b\u72b6\u6001\uff0c\u6765\u53bb\u9012\u5f52\u7684\u7b97\u51fa \u6bcf\u4e00\u65f6\u523b\u7684 \u8f93\u5165 \u6240\u5bf9\u5e94\u7684\u8f93\u51fa\u662f\u4ec0\u4e48\uff1b</li> </ul> <p>\u5f53\u5b9e\u4f8b\u5316\u5b8c \u4e00\u4e2aRNN\uff0c\u5c31\u53ef\u4ee5 \u63d0\u4f9b <code>input</code> \u548c \\(h_0\\)\uff0c\u6765\u7ed9\u51fa\u771f\u6b63\u7684\u8f93\u5165\u5e8f\u5217\uff1a</p> <p></p> <ul> <li> \u89e3\u91cainput</li> </ul> <p>\u8f93\u5165\u4e00\u822c\u662f\u4e09\u7ef4\u7684\uff1a</p> <p></p> <p>\u5982\u679c\u8bbe\u7f6e\u7684<code>batch size first\u7b49\u4e8etrue</code>\u7684\u8bdd\uff0c\u90a3\u5bf9\u5e94\u7684\u8f93\u5165\u683c\u5f0f\u5c31\u662f <code>batch size\u00d7sequence length\u00d7hidden size</code>\uff1b</p> <p>\u53cd\u4e4b \u5982\u679c<code>\u6ca1\u6709\u8bbe\u7f6ebatch size\u7b49\u4e8etrue</code>\u7684\u8bdd\uff0c\u63d0\u4f9b\u7684\u683c\u5f0f\u5c31\u662f <code>sequence length\u00d7batch size\u00d7hidden size</code></p> <ul> <li> <p> \u89e3\u91ca \\(h_0\\)</p> </li> <li> <p>\\(h_0\\)\u7684\u683c\u5f0f\u662f (\\(d\u00d7{num\\_layers}\\)\uff0c \\(N\\)\uff0c\\(H_{out}\\) )</p> </li> <li> <p>\\(h_0\\) \u662f \u521d\u59cb\u72b6\u6001\uff0c\u53ea\u6709 \u8fd9\u4e00\u4e2a\u65f6\u523b\uff0c\u6240\u4ee5\u8fd9\u91cc\u4e0d\u9700\u8981\u8003\u8651 <code>sequence_length</code> \u8fd9\u4e2a\u7ef4\u5ea6</p> </li> <li> <p> \u90a3\u8fd9\u91cc\u4e5f\u662f \u4e09\u4e2a\u7ef4\u5ea6\uff0c\u4e3a\u4ec0\u4e48\u5462\uff1f</p> </li> </ul> <p>\u56e0\u4e3a  RNN \u53ef\u4ee5\u662f \u591a\u5c42 \u4e5f\u53ef\u4ee5\u662f \u53cc\u5411\uff0c\u6240\u4ee5\u7b2c\u4e00\u4e2a\u7ef4\u5ea6 \u5176\u5b9e\u5c31\u662f \u662f\u5426\u662f \u53cc\u5411  \u8ddf \u591a\u5c42 \u8fd9\u4e24\u4e2a\u56e0\u7d20 \u51b3\u5b9a\u7684\uff1b</p> <p><code>case1\uff1a</code>\u5982\u679c\u6a21\u578b\u662f\u4e00\u5c42\uff0c\u5e76\u4e14\u662f\u5355\u5411\u7684\u8bdd\uff0c\u90a3\u4e48\u7b2c\u4e00\u4e2a\u7ef4\u5ea6 \u5c31\u662f 1 \uff1b</p> <p><code>case2\uff1a</code>\u5982\u679c\u662f \u6709\u4e24\u5c42\uff0c\u5e76\u4e14\u662f \u5355\u5411\u7684\u8bdd\uff0c\u90a3\u4e48\u5c31\u662f 1\u00d72\uff1b</p> <p><code>case3\uff1a</code>\u5982\u679c\u662f\u53cc\u5411 \u5e76\u4e14\u662f \u4e24\u5c42\u7684\u8bdd\uff0c\u90a3\u5c31\u662f 2\u00d72=4\uff1b</p> <p>\u6240\u4ee5\u8fd9\u91cc\u7684 \u7b2c\u4e00\u4e2a\u7ef4\u5ea6 \\(d \\times num\\_layers\\) \u7531\u662f\u5426\u53cc\u5411 \u4ee5\u53ca \u5c42\u6570\u6709\u5173</p> <p></p> <p>\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6 \\(N\\)\uff0c\u5c31\u662f <code>batch size</code>\uff0c\u6bcf\u4e2a\u6837\u672c \u90fd\u53ef\u4ee5 \u8bbe\u7f6e\u4e00\u4e2a \u521d\u59cb\u72b6\u6001</p> <p>\u7b2c\u4e09\u4e2a\u7ef4\u5ea6 \\(H_{out}\\) \u5c31\u662f <code>hidden size</code>\u7684\u5927\u5c0f\uff0c\u56e0\u4e3a \u521d\u59cb\u72b6\u6001 \u5c31\u662f\u4e00\u4e2a\u5411\u91cf,\u7b2c\u4e09\u7ef4 \u5c31\u662f \u5411\u91cf\u7684\u957f\u5ea6</p>"},{"location":"learning/13_RNN/#_1","title":"\u4ee3\u7801\u793a\u4f8b","text":""},{"location":"learning/13_RNN/#1-rnn","title":"1 \u5355\u5c42\u5355\u5411 RNN","text":"<p>\u8fd9\u4e2aRNN \u662f\u4e00\u4e2a class</p> <p>\u6240\u4ee5\uff0c\u9996\u5148\u5b9e\u4f8b\u5316\u4e00\u4e2a\u5355\u5411\u5355\u5c42\u7684RNN</p> <p>step1\uff1aimport  torch.nn as nn</p> <p>step2\uff1a\u5b9e\u4f8b\u5316 nn.RNN</p> <p>step3\uff1a\u4f20\u5165 \u5b9e\u4f8b\u5316\u53c2\u6570\uff1b</p> <ul> <li> <p>input_size=4</p> </li> <li> <p>hidden_size\u4e5f\u53ef\u4ee5 \u968f\u4fbf\u5199\u4e00\u4e2a hidden_size=3 </p> </li> <li> <p>num_layers\u53ef\u4ee5\u4f20\u51651</p> </li> <li>batch first\u8bbe\u7f6e\u6210true</li> <li>\u5b9a\u4e49\u4e3a<code>single_rnn</code></li> </ul> Python<pre><code>import torch\nimport torch.nn as nn\n# 1.\u5355\u5411\u3001\u5355\u5c42RNN\nsingle_rnn = nn.RNN(input_size=4,hidden_size=3,num_layers=1,batch_first=True)\n</code></pre> <p>\u4ee5\u4e0a\u662f \u5355\u5c42\u5355\u5411RNN\uff0c\u63a5\u4e0b\u6765\u6784\u5efa\u4e00\u4e2a\u8f93\u5165</p> <p>\u8f93\u5165\u7684\u7ef4\u5ea6\u4e00\u822c\u662f <code>batch_size\u00d7sequence length\u00d7\u8f93\u5165\u7279\u5f81</code></p> <p>\u8f93\u5165\u7279\u5f81\u5c31\u662fRNN\u5b9e\u4f8b\u5316\u65f6\u7684 <code>input size=4\uff0cbatch size=1\uff0csequence length=2\uff0c\u7279\u5f81\u7ef4\u5ea6=4</code></p> <p>\u4ee5\u4e0a\u6784\u5efa\u597d\u4e86input\u5e8f\u5217\uff0c\u5206\u522b\u662f\uff1a <code>batch_size \u00d7 sequence length\u00d7\u8f93\u5165\u7279\u5f81</code></p> Python<pre><code>input = torch.randn(1,2,4) \n# batch_size*sequence_length*feature_size\n</code></pre> <p>\u628a\u8fd9\u4e2a<code>input</code>\u4f5c\u4e3a <code>single_rnn</code>\u7684\u8f93\u5165\uff1b</p> <p>\u4e5f\u53ef\u4ee5\u4e0d\u4f20\u5165\\(h_0\\),\u5b83\u9ed8\u8ba4\u4ee5\\(0\\)\u5411\u91cf\u586b\u5145</p> <p></p> <p>\u540c\u65f6\u4e5f\u53ef\u4ee5\u770b\u770b \u5b98\u7f51 api \u8f93\u51fa\u662f\u4ec0\u4e48</p> <p></p> <p>\u8f93\u51fa\u662f\u4e24\u4e2a\u503c\uff0c\u4e00\u4e2a\u662f\u6574\u4e2a\u7684\uff0c\u6240\u6709\u65f6\u523b\u7684\u8f93\u51fa\uff1b</p> <p>\u53e6\u5916\u4e00\u4e2a\u8f93\u51fa\u7684\u91cf\u5c31\u662f\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u72b6\u6001\uff0c\u8981\u5b9a\u4e49\u53d8\u91cf\u63a5\u6536\u8f93\u51fa</p> Python<pre><code>output,h_n = single_rnn(input)\n</code></pre> <p>\u8fd9\u6837\u6574\u4e2a\u8f93\u51fa\u5c31\u7b97\u5b8c\u4e86\uff0c\u63a5\u4e0b\u6765\u770b\u4e00\u4e0b\\(output\\)\u548c \\(h_n\\)</p> <p></p> <p>\u4ee3\u7801\u89e3\u8bfb\uff1a</p> <p>\uff081\uff09 <code>input</code>\u7684\u5f62\u72b6 <code>1\u00d72\u00d74 = batch size\u00d7sequence length\u00d7feature dim</code></p> <p>\uff082\uff09<code>single_rnn</code> \u7684\u53c2\u6570\u542b\u4e49\uff1a<code>4,3,1=input_size,hidden_size;num_layers</code></p> <p>\uff083\uff09<code>output</code>\u5927\u5c0f\u5c31\u662f <code>1\u00d72\u00d73</code></p> <ul> <li>1\u8868\u793a batch size\uff0c\u8f93\u5165batch size=1\uff0c\u8f93\u51fa batch size\u4e5f\u662f1\uff0c\u6ca1\u6709\u6539\u53d8</li> <li>2\u662f sequence length\uff0c\u5e8f\u5217\u957f\u5ea6\uff0c\u6211\u4eec\u5582\u5165\u7684\u8f93\u5165\u957f\u5ea6\u662f2\uff0c\u6240\u4ee5\u8f93\u51fa\u7684\u957f\u5ea6\u4e5f\u662f2</li> <li>3\uff0c\u7b2c\u4e09\u4e2a\u7ef4\u5ea6\u4e3a\u4ec0\u4e48\u662f3\u5462\uff1f\u56e0\u4e3a\u6211\u4eec\u8bbe\u7f6e\u7684hidden size=3\uff0c\u4e5f\u5c31\u662f\u8bf4 \u6bcf\u4e2a\u8f93\u51fa\u7684\u72b6\u6001\u5411\u91cf \u957f\u5ea6\u662f3</li> </ul> <p>\uff084\uff09\\(h_n\\)\uff1a \u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001\uff0c\u5728\u7b80\u5355RNN\u4e2d\uff0c\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001\u7b49\u4e8e\u6700\u540e\u65f6\u523b\u7684\u8f93\u51fa\u7684\uff0coutput\u6700\u540e\u4e00\u884c\u7684\u503c \u7b49\u4e8e \\(h_n\\)</p> <p></p>"},{"location":"learning/13_RNN/#2-rnn","title":"2 \u53cc\u5411\u3001\u5355\u5c42RNN","text":"Python<pre><code>single_rnn = nn.RNN(input_size=4,hidden_size=3,num_layers=1,batch_first=True)\n</code></pre> <ul> <li> <p>input size\u4e0d\u53d8</p> </li> <li> <p>hidden size\u4e0d\u53d8</p> </li> <li>num_layers\u4e0d\u53d8</li> <li>batch first\u4e5f\u4e0d\u53d8</li> <li>\u4f46\u662f\u9700\u8981\u65b0\u589e\u4e00\u4e2a\u53c2\u6570\uff0c\u53eb\u505a\uff1a</li> </ul> <p></p> <p>\uff1abidirectional\uff0c\u8fd9\u4e2a\u53c2\u6570\u9ed8\u8ba4\u662ffalse\uff0c\u628a\u5b83\u7f6e\u6210true</p> <p>\u7136\u540e\u547d\u540d\u4e3a bidirectional_rnn\uff1a</p> Python<pre><code>bidirectional_rnn = nn.RNN(input_size=4,hidden_size=3,num_layers=1,batch_first=True,bidirectional=True)\n</code></pre> <p>\u4ee5\u4e0a\u662f\u5b9e\u4f8b\u5316\u7684\u53cc\u5411RNN</p> <ul> <li>\u8f93\u5165\u7279\u5f81\u5927\u5c0f\u662f4</li> <li>\u8f93\u51fa or \u9690\u542b\u5c42\u5927\u5c0f\u662f3</li> <li>\u53ea\u6709\u4e00\u5c42</li> <li>batch first=true</li> <li>\u5e76\u4e14\u8fd8\u662f\u53cc\u5411\u7684</li> </ul> <p>\u540c\u6837\u628a\u4e0a\u9762\u7684\u8f93\u5165 \u9001\u5165\u53cc\u5411RNN\u4e2d\uff0c\u4ee5<code>input</code>\u4f5c\u4e3a\u8f93\u5165<code>bidirectional_rnn(input)</code>\uff0c\u56e0\u4e3a\u65e0\u8bba\u53cc\u5411\u3001\u5355\u5411\uff0c\u8f93\u51fa\u90fd\u662f\u4e00\u6837\u7684\uff0c\u90fd\u662f<code>output</code> \u548c <code>h_n</code>\uff0c\u8868\u793a\u533a\u522b\u52a0\u524d\u7f00<code>bi</code></p> Python<pre><code>bi_output,bi_h_n = bidirectional_rnn(input)\n</code></pre> <p>\u9996\u5148 \u6253\u5370 output\u7684\u5f62\u72b6</p> Python<pre><code>bi_output.shape\n</code></pre> <p></p> <p>\u8fd8\u6709h_n\u7684\u5f62\u72b6\uff1a</p> Python<pre><code>bi_h_n.shape\n</code></pre> <p></p> <p>\u5bf9\u6bd4\uff0c\u628a\u5355\u5411\u5355\u5c42RNN\u7684output\u7684\u5f62\u72b6\uff0ch_n\u7684\u5f62\u72b6\uff0c\u90fd\u6253\u5370\u51fa\u6765\uff1a</p> <p></p> <ul> <li>\u9996\u5148\u4ece\u8f93\u51fa\u4e0a\u6765\u8bb2\uff1a</li> </ul> <p>\uff081\uff09\u5355\u5411\u7684\u8f93\u51fa\u5927\u5c0f\u662f 1\u00d72\u00d73\u7684</p> <p>\uff082\uff09\u53cc\u5411\u7684\u8bdd\u53d8\u6210\u4e86 1\u00d72\u00d76\uff08\u4e00\u4e2abatch size\uff1b2\u4e2asequence length\uff1b6\u4e2a\u7279\u5f81\u7ef4\u5ea6\uff09</p> <p>\u8fd9\u662f\u4e3a\u4ec0\u4e48\u5462\uff1f</p> <p>\u8fd9\u662f\u56e0\u4e3a\u5728\u53cc\u5411RNN\u4e2d\u6700\u540e\u662f\u628a<code>forward layer</code>\u548c<code>backward layer</code>\u4e24\u4e2a\u8f93\u51fa\u62fc\u8d77\u6765\uff0c\u6240\u4ee5\u7279\u5f81\u5927\u5c0f\u53d8\u6210\u4e86\u4e24\u500d\u7684<code>hidden size</code>\uff1b</p> <ul> <li>\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u72b6\u6001\u4e5f\u662f\u4e0d\u4e00\u6837\u7684</li> </ul> <p>\uff081\uff09\u5728\u53cc\u5411RNN\u4e2d\uff0c\u5b83\u7684\u7ef4\u5ea6\u662f 2\u00d71\u00d73\uff08\u524d\u5411\u7684\u8f93\u51fa\u662f\u4e2a 1\u00d73\uff0c\u540e\u5411\u7684\u8f93\u51fa\u4e5f\u662f\u4e00\u4e2a1\u00d73\uff09</p> <p>\uff082\uff09\u5728\u5355\u5411\u4e2d\uff0c\u7ef4\u5ea6\u662f1\u00d71\u00d73</p> <p>\u4e3a\u4ec0\u4e48\u5462\uff1f</p> <p>\u56e0\u4e3a\u53cc\u5411\u4e2d\uff0c\u5176\u5b9e\u662f\u6709\u4e24\u4e2a\u5c42\u7684\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u72b6\u6001\uff0c\u6709\u4e00\u4e2a<code>forward layer</code>\u548c\u4e00\u4e2a<code>backward layer\uff0c</code>\u8fd9\u4e24\u4e2a\u72b6\u6001\u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u62fc\u8d77\u6765\u4e86\uff0c\u4f46\u662f\u5728\u5355\u5411\u4e2d\uff0c\u53ea\u6709\u4e00\u5c42\u7684\u6700\u540e\u4e00\u4e2a\u72b6\u6001\uff1b</p>"},{"location":"learning/13_RNN/#3-rnn-api","title":"3 RNN api \u4ee3\u7801\u6c47\u603b","text":""},{"location":"learning/13_RNN/#4-rnnrnn","title":"4 \u5355\u5411RNN&amp;\u53cc\u5411RNN \u4ece\u77e9\u9635\u8fd0\u7b97\u7684\u89d2\u5ea6\u5b9e\u73b0","text":"<p>\u6ce8\u610f\uff1a\u4ee5\u4e0b\u6f14\u793a\u4e2d\uff0c\u6ca1\u6709\u8bbe\u7f6e\u591a\u5c42\uff0c num layers\u90fd\u5b9a\u4e49\u76841\u5c42</p> <p>\uff081\uff09\u5f15\u5165\u5e93\uff0c\u53ef\u4ee5\u4f7f\u7528\u5e38\u89c1\u7684pytorch\u51fd\u6570</p> Python<pre><code>import torch\nimport torch.nn as\n</code></pre> <p>\uff082\uff09\u5b9a\u4e49\u5e38\u91cf</p> <p>\u7136\u540e\u5b9a\u4e49\u4e00\u4e9b\u5e38\u91cf\uff0c\u6bd4\u5982batch size\u3001\u5e8f\u5217\u957f\u5ea6</p> Python<pre><code>bs,T = 2,3  #\u6279\u5927\u5c0f \u548c \u5e8f\u5217\u957f\u5ea6\n</code></pre> <p>\u8fd8\u9700\u8981\u5b9a\u4e49 input size\u548chidden size\uff0c\u5206\u522b\u8868\u793a\u8f93\u5165\u7279\u5f81\u5927\u5c0f \u548c \u9690\u542b\u5c42 \u7279\u5f81\u5927\u5c0f</p> Python<pre><code>input_size,hidden_size=2,3 #\u8f93\u5165\u7279\u5f81\u5927\u5c0f\uff0c\u9690\u542b\u5c42\u7279\u5f81\u5927\u5c0f\n</code></pre> <p>\u6709\u4e00\u4e2a\u95ee\u9898\uff1a\u600e\u4e48\u7406\u89e3 \u65f6\u5e8f\u6a21\u578b\u4e2d\u7684 batchsize\uff1f</p> <p>\uff083\uff09\u751f\u6210 input</p> <p>\u6709\u4e86\u8fd9\u4e9b\u91cf\u4ee5\u540e\uff0c\u751f\u6210\u4e00\u4e2a  input \uff0c\u8fd8\u662f\u8003\u8651batch first\u7b49\u4e8etrue\u7684\u60c5\u51b5\uff1a\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u5199batch size\u3001\u7b2c\u4e8c\u4e2a\u4f4d\u7f6e\u5199\u5e8f\u5217\u957f\u5ea6\u3001\u7b2c\u4e09\u4e2a\u4f4d\u7f6e\u5199feature dim\uff0c\u4e5f\u5c31\u662f input size</p> Python<pre><code>input = torch.randn(bs,T,input_size) # \u968f\u673a\u521d\u59cb\u5316\u4e00\u4e2a\u8f93\u5165\u7279\u5f81\u5e8f\u5217\n</code></pre> <p>\uff084\uff09\u521d\u59cb\u5316\u9690\u72b6\u6001</p> <p>\u521d\u59cb\u5316\u4e00\u4e2a\u521d\u59cb\u7684\u9690\u542b\u72b6\u6001 <code>h_0</code>\uff0c\u521d\u59cb\u7684\u9690\u542b\u72b6\u6001\u4e00\u822c\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u5982\u679c\u8003\u8651\u4e86<code>batch size</code>\uff0c\u5c31\u5e94\u8be5\u662f <code>batch size</code>\u4e2a\u8fd9\u6837\u7684\u72b6\u6001\uff0c\u4e5f\u53ef\u4ee5\u5148\u5199\u62100\uff1a</p> Python<pre><code>h_prev=torch.zeros(bs,hidden_size)  # \u6bcf\u4e00\u4e2a\u72b6\u6001\u5411\u91cf\u5927\u5c0f\u662f hidden size\n</code></pre> <p>\u4e5f\u5c31\u662f\u5728\u7b2c\u4e00\u4e2a\u65f6\u523b\u7684\u65f6\u5019\uff0c\u9700\u8981\u4e00\u4e2a\u521d\u59cb\u7684\u9690\u542b\u72b6\u6001\u6765\uff0c\u6765\u4f5c\u4e3a\u7b2c0\u65f6\u523b\u7684\u521d\u59cb\u72b6\u6001</p> <p></p> <p>\uff085\uff09\u8c03\u7528pytorch RNN\u7684API</p> <p>\u8fd8\u662f\u7528<code>nn.RNN()</code>\u7684api\uff0c\u9700\u8981\u4f20\u5165<code>input_size</code>\uff0c<code>hidden size</code>\u8fd8\u6709<code>batch first=True</code>\uff0c\u8fd9\u6837\u6211\u4eec\u5f97\u5230\u4e00\u4e2arnn</p> Python<pre><code>rnn = nn.RNN(input_size,hidden_size,batch_first=True)\n</code></pre> <p>\uff086\uff09\u4f20\u5165\u53c2\u6570</p> <p>\u9700\u8981\u628a input \u4ee5\u53ca\u521d\u59cb\u72b6\u6001\u4e5f\u4f20\u5165RNN\u4e2d\uff0c\u4f46\u662f\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0capi\u4e2d\u521d\u59cb\u72b6\u6001\u662f\u4e09\u7ef4\u7684</p> <p></p> <p>\u521a\u521a\u521d\u59cb\u5316\u7684\u662f \u540e\u9762\u4e24\u7ef4\uff0c\u7b2c\u4e09\u7ef4 \u6211\u4eec\u6ca1\u6709\u521d\u59cb\u5316\uff0c\u56e0\u4e3a\u8fd9\u91cc\u662f\u5355\u5411\u7684 \u5e76\u4e14 \u53ea\u6709\u4e00\u5c42\u7684\uff0c\u6240\u4ee5\u5bf9\u5b83\u6269\u4e00\u7ef4\u5c31\u597d\u4e86\uff0c\u62690\u7ef4\uff0c\u5f97\u5230rnn output\u548ch_finall\uff0c\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u72b6\u6001\uff0c\u6216\u8005\u53ebstate_finall</p> Python<pre><code>rnn_output,state_finall = rnn(input,h_prev.unsqueeze(0))\n</code></pre> <p>\u8fd9\u4e2a\u662f\u8c03\u7528pytorch \u5b98\u65b9\u7684api\uff0c\u8fd0\u884c\u6253\u5370\uff0c\u770b\u7ed3\u679c</p> <p></p> <p>\uff087\uff09\u624b\u5199RNN forward \u51fd\u6570</p> <p>\u5b9a\u4e49<code>RNN forward</code>\u51fd\u6570\uff0c\u5b9e\u73b0RNN\u8ba1\u7b97\u539f\u7406 <code>def rnn_forward():</code>\uff0c\u5bf9\u4e8e\u8fd9\u4e2a\u51fd\u6570 \u9996\u5148\u8981\u4f20\u5165\u53c2\u6570\uff1a</p> <p></p> <p>\u6839\u636e\u516c\u5f0f\uff0c\u8981\u60f3\u7b97\u51fa\\(h_t\\)\u7684\u8bdd\uff1a</p> <ul> <li>\u9700\u8981\u6709\\(x\\)\uff0c\\(x\\)\u5c31\u662f\u8f93\u5165\uff0c\u6240\u4ee5\u7b2c\u4e00\u4e2a\u53c2\u6570\uff0c\u9700\u8981\u5199\u7684\u662f\\(input\\)</li> <li>\u8f93\u5165\u9700\u8981\u4e00\u4e2a\u6295\u5f71\u77e9\u9635\uff0c\u5c31\u662f\\(W_{ih}\\)\uff0c\u9700\u8981\u4e00\u4e2aweight</li> <li>\u540c\u65f6\u8fd8\u9700\u8981\u504f\u7f6e\u9879\\(\\mathrm{bias_{ih}}\\)</li> <li>\u8fd8\u6709\u4e0a\u4e00\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001 \uff1a \\(W_{hh}\\) </li> <li>\u8fd8\u6709 \\(b_{hh}\\)</li> <li>\u516c\u5f0f\u4e2d\u8fd8\u6709 \\(h_{t-1}\\) \uff0c\u5199\u6210 <code>h_prev</code> \uff0c\u5c31\u662f\u524d\u4e00\u65f6\u523b\u7684\u72b6\u6001</li> </ul> <p>\u4ee5\u4e0a\uff0c\u5c31\u80fd\u7b97\u51faRNN\u7684\u8f93\u51fa</p> <p>\u7b2c\u4e00\u6b65\uff1a\u83b7\u53d6\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u7279\u5f81\u5f97\u5230<code>x</code></p> Python<pre><code>def rnn_forward(input,weight_ih,weight_hh,bias_ih,bias_hh,h_prev):\n</code></pre> <ul> <li>input \u9ed8\u8ba4 \u4e09\u7ef4\u7684\u7ed3\u6784\uff0c\u5148\u628ainput\u7684\u5f62\u72b6\u62c6\u89e3\u51fa\u6765\uff0c\u5f62\u72b6\u5e94\u8be5\u662f <code>batch size\u00d7sequence length\u00d7input size</code> \uff0c\u8c03\u7528 <code>input.shape</code></li> </ul> Python<pre><code>bs,T,input_size = input.shape\n</code></pre> <ul> <li>\u901a\u8fc7\u62c6\u89e3 <code>input</code> \uff0c\u8fd8\u53ef\u4ee5\u77e5\u9053 <code>hidden size</code>\uff0c\u4e5f\u5c31\u662f<code>h_dim</code>\uff0c\u4e5f\u5c31\u662f <code>weight_ih</code>\uff0c\u53ef\u4ee5\u6839\u636e\u5b83\u7684\u6743\u91cd\u6240\u5f97\u5230\uff0c\u4e5f\u5c31\u662f<code>weight_ih.shape</code>\uff0c\u90a3\u5230\u5e95\u662f<code>shape[0]</code>\u8fd8\u662f <code>shape[1]</code>\u5462\uff1f\u770b\u516c\u5f0f\uff1a</li> </ul> <p></p> <p><code>weight ih</code>\u8ddf <code>xt</code> \u662f\u5de6\u4e58\u7684\u5173\u7cfb\uff0c\u6240\u4ee5<code>weight</code>\u7684\u7b2c2\u4e2a\u7ef4\u5ea6\u8ddf<code>x</code>\u662f\u76f8\u540c\u7684\uff0c\u6240\u4ee5\u7b2c\u4e00\u4e2a\u7ef4\u5ea6 \u5c31\u662f\u9690\u542b\u5355\u5143\u7684\u7ef4\u5ea6\uff0c\u6240\u4ee5\u5199\u6210<code>.shape[0]</code>\uff0c\u5f97\u5230<code>hidden dim \uff1a</code></p> Python<pre><code>h_dim = weight_ih.shape[0]\n</code></pre> <p>\u4ee5\u4e0a\u662f\u5f97\u5230\u4e86\u4e00\u4e9b\u7ef4\u5ea6\uff0c\u63a5\u4e0b\u6765\uff0c\u53ef\u4ee5\u5199\u51fa <code>h out</code>\uff0c\u9996\u5148 \u521d\u59cb\u5316\u4e00\u4e2a \u8f93\u51fa\uff0c\u8f93\u51fa\u5927\u5c0f\u662f <code>batch size\u00d7T\u00d7h dim</code>\uff0c\u521d\u59cb\u5316\u4e00\u4e2a\u8f93\u51fa\u77e9\u9635 \u6216\u8005 \u72b6\u6001\u77e9\u9635</p> Python<pre><code>h_out = torch.zeros(bs,T,h_dim)  # \u521d\u59cb\u5316\u4e00\u4e2a\u8f93\u51fa\uff08\u72b6\u6001\uff09\u77e9\u9635\n</code></pre> <ul> <li> <p><code>bs</code>\u8ddf\u8f93\u5165\u662f\u4e00\u6837\u7684</p> </li> <li> <p>\u5e8f\u5217\u957f\u5ea6 \u6216\u8005\u53eb \u65f6\u95f4\u957f\u5ea6 \u4e5f\u662f\u8ddf \u8f93\u5165\u4e00\u6837\u7684\u7ef4\u5ea6</p> </li> <li>\u9700\u8981\u6539\u6210 <code>hidden size</code>\u8fd9\u4e2a\u7ef4\u5ea6</li> </ul> <p>\u63a5\u4e0b\u6765 \u6839\u636e\u8fd9 6 \u4e2a\u53c2\u6570\uff0c\u7b97\u51fa <code>h out</code></p> <p></p> <p>RNN\u662f\u4e00\u4e2a\u9012\u5f52\u7684\u8ba1\u7b97\uff0c\u6240\u4ee5\u9700\u8981\u6839\u636e<code>x1</code>\u8ba1\u7b97<code>h1</code>\uff0c\u6839\u636e<code>x2</code>\u8ba1\u7b97<code>h2</code>\u7b49\u7b49\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a<code>for</code>\u5faa\u73af <code>for t in range(T):</code> </p> <p>\u56e0\u4e3aRNN\u7684\u8ba1\u7b97\u590d\u6742\u5ea6 \u8ddf\u5e8f\u5217\u957f\u5ea6 \u5448\u7ebf\u6027\u5173\u7cfb\uff0c\u6240\u4ee5\u5bf9\u5e8f\u5217\u957f\u5ea6\u8fdb\u884c\u904d\u5386\u5c31\u597d\u4e86</p> Python<pre><code>for t in range(T):\n</code></pre> <p>\u9996\u5148\u5f97\u5230\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u5411\u91cf\uff0c<code>input</code>\uff0c\u56e0\u4e3ainput\u662f\u4e09\u7ef4\uff1a</p> <ul> <li>\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u662f batch size\uff0c\u5168\u90fd\u53d6\u51fa\u6765</li> <li>\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u662f\u65f6\u95f4\uff0c\u5c31\u62ff\u5f53\u524d t \u65f6\u523b\u7684\u8f93\u5165\u5411\u91cf</li> <li>\u7b2c\u4e09\u7ef4\u662f\u7279\u5f81\u7ef4\u5ea6\uff0c\u4e5f\u662f\u5168\u90e8\u62ff\u51fa\u6765</li> </ul> Python<pre><code>x = input[:,t,:]  # \u83b7\u53d6\u5f53\u524d\u65f6\u523b\u8f93\u5165\u7279\u5f81\uff0cbs*input_size\n</code></pre> <p>\u4ee5\u4e0a\u662f\u7b2c\u4e00\u6b65\uff1a\u83b7\u53d6\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u7279\u5f81\u5f97\u5230<code>x</code></p> <p>\u7b2c\u4e8c\u6b65\uff1a\u6269\u5145 batch \u7ef4\u5ea6</p> <p>\u6839\u636e\u516c\u5f0f\uff0c\u8ba9<code>w</code>\u8ddf<code>x</code>\u8fdb\u884c\u76f8\u4e58</p> <ul> <li>\u8fd9\u91cc<code>weight</code>\u4e00\u822c\u9ed8\u8ba4\u4f20\u5165 \u662f\u4e8c\u7ef4\u7684</li> <li>\u800c<code>x</code>\u7684\u5927\u5c0f\uff0c\u9ed8\u8ba4\u662f <code>batch size\u00d7input size</code></li> </ul> <p><code>weight ih</code>\u7684\u5f62\u72b6\u662f <code>h dim\u00d7input size</code></p> <p>\u6240\u4ee5\u4e3a\u4e86\u8fdb\u884c<code>batch</code>\u7ef4\u5ea6\u65e0\u5173\u7684\u4e58\u6cd5\u8fd0\u7b97\u7684\u8bdd\uff1a</p> <p>\u9996\u5148\u5bf9<code>weight ih</code>\u8fdb\u884c\u4e00\u4e2a\u6269\u5145\uff0c\u628a<code>weight</code>\u53d8\u6210\u4e00\u4e2a <code>batch</code>\u7684\u5f62\u5f0f\uff0c<code>weight ih</code>\u662f<code>hidden size\u00d7input size</code>\u7684\u5927\u5c0f\uff0c\u5bf9\u5b83 \u589e\u52a0\u4e00\u7ef4\uff0c<code>batch</code> \u7ef4\u5ea6\uff0c\u5bf9\u5b83\u8fdb\u884c\u590d\u5236\uff0c\u590d\u5236\u6210\u8ddf<code>input</code>\u4e00\u6837\u7684\u5927\u5c0f\uff0c\u5927\u5c0f\u5c31\u53d8\u6210\u4e86 <code>batch size\u00d7h dim\u00d7input size</code></p> Python<pre><code>w_ih_batch = weight_ih.unsqueeze(0).tile(bs,1,1) \n# bs*h_dim*input_size\n</code></pre> <p>\u8fd9\u662f <code>w ih</code>\uff0c\u53d8\u6210 <code>batch</code>\u7684\u5f62\u72b6</p> <p>\u540c\u6837\u5bf9\u4e8e<code>weight hh</code>\uff0c\u4e5f\u662f\u4e00\u6837\u7684\uff0c\u4e5f\u8f6c\u6362\u4e00\u4e0b\uff0c\u5bf9\u5b83\u589e\u52a0\u4e00\u4e2a<code>batch</code>\u7ef4\u5ea6\uff0c\u7136\u540e\u628a\u5b83\u7684<code>batch</code>\u7ef4\u5ea6\u6269\u5145\u6210 <code>batch size</code>\u7ef4\u5ea6\u5927\u5c0f</p> Python<pre><code>w_hh_batch = weight_hh.unsqueeze(0).title(bs,1,1)\n# bs * h_dim * h_dim\n</code></pre> <p>\u8fd9\u91cc <code>w hh</code>\u5927\u5c0f\u5c31\u662f <code>batch size\u00d7 h dim\u00d7h dim</code>\uff0c\u56e0\u4e3a\u8ddf<code>hidden state</code>\u76f8\u8fde\u7684\uff0c\u6240\u4ee5\u662f\u4e00\u4e2a\u65b9\u9635</p> <p>\\(h_t = \\mathrm{tanh(W_{ih}x_t+b_{ih}+W_{hh}h_{t-1}+b_{hh})}\\)</p> <p>\u7b2c\u4e09\u6b65\uff1a\u5f00\u59cb\u8ba1\u7b97 \\(w_{ih}\u00d7 x_t\u3001w_{hh}\u00d7 h_{t-1}\\)</p> <p>\u7b2c\u4e00\u9879\uff1a<code>w_times_x</code></p> <p>\u9996\u5148\u8ba1\u7b97 <code>x</code>\uff0c\u5c31\u662f\u8ba1\u7b97 <code>Wih</code>\u4e58\u4ee5<code>x</code>\u8fd9\u4e2a\u91cf <code>w_times_x</code>\u8fd9\u4e2a\u91cf\uff0c\u53ef\u4ee5\u8c03\u7528 <code>torch.bmm</code>\u8fd9\u4e2a\u51fd\u6570</p> <p><code>batch matrix multiplication</code>\uff0c\u662f\u542b\u6709\u6279\u5927\u5c0f\u7684\u77e9\u9635\u76f8\u4e58\uff0c\u4e0e \u6279 \u65e0\u5173\u7684 \u8ba1\u7b97\u77e9\u9635\u76f8\u4e58</p> <ul> <li>\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u4f20\u5165 <code>w ih batch</code></li> <li>\u7b2c\u4e8c\u4e2a\u4f4d\u7f6e \u4f20\u5165 <code>x</code></li> </ul> <p>\u5f53\u524d\u8fd9\u4e2a<code>x</code>\u662f<code>batch size\u00d7 input_size</code>\u7684\uff0c\u4e3a\u4e86\u8ddf <code>w ih batch</code>\u76f8\u4e58\uff0c\u9700\u8981\u5c06\u5b83 \u6269\u5145\u4e00\u7ef4\uff0c\u6269\u5145\u6210 <code>batch size\u00d7input size\u00d71</code>\u7684\uff0c\u8fd9\u91cc \u9700\u8981 \u5bf9\u5b83 \u6269\u5145\u4e00\u4e0b\uff0c\u8c03\u7528\u4e00\u4e0b<code>unsqueeze</code></p> Python<pre><code>x = input[:,t,:].unsqueeze(2)\n</code></pre> <p>\u672c\u6765\u662f\u4e8c\u7ef4\u7684\uff0c\u73b0\u5728\u5728\u7b2c\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u6269\u5145\uff0c\u53d8\u6210 <code>batch size\u00d7input size\u00d71</code>\uff0c\u6b64\u65f6\u8ddf<code>x</code>\u76f8\u4e58\uff0c\u5f97\u5230 <code>batch size\u00d7 h dim\u00d71</code>\uff0c\u6700\u540e<code>1</code>\u7684\u7ef4\u5ea6\u53bb\u6389\uff0c\u8c03\u7528<code>unsqueeze</code>\u51fd\u6570\uff0c\u5f97\u5230\u7684\u7ed3\u679c <code>batch size\u00d7h dim</code>\uff0c\u5f97\u5230<code>w times x</code>\u7684\u7ed3\u679c\uff0c\u504f\u7f6e\u6700\u540e\u518d\u52a0</p> Python<pre><code>x = input[:,t,:].unsqueeze(2)  # \u83b7\u53d6\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u7279\u5f81 bs*input_size*1\nw_ih_batch = weight_ih.unsqueeze(0).tile(bs,1,1) #bs*h_dim*input_size\nw_hh_batch = weight_hh.unsqueeze(0).tile(bs,1,1) #bs*h_dim*h_dim\n\nw_times_x = torch.bmm(w_ih_batch,x).squeeze(-1) # bs*h_dm\n</code></pre> <p>\u7b2c\u4e8c\u9879 <code>w_times_h</code></p> <p><code>Whh</code> \u77e9\u9635 \u8ddf\u4e0a\u4e00\u65f6\u523b\u7684\u72b6\u6001\u76f8\u4e58\u7684\u7ed3\u679c</p> <p>\u540c\u6837\u8c03\u7528 <code>torch.bmm</code>\u51fd\u6570\uff0c\u5e26\u6709\u6279\u5927\u5c0f\u7684\u77e9\u9635\u76f8\u4e58\uff0c\u8ddf\u4e0a\u4e00\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001 \u8fdb\u884c\u76f8\u4e58</p> <p>\u540c\u6837\u5bf9<code>h prev</code>\u8fdb\u884c\u6269\u5145\uff0c<code>h_prev.unsqueeze(2)</code>\uff0c\u628a\u5b83\u6269\u5145\u4e09\u7ef4</p> <p>\u56e0\u4e3a<code>h prev</code>\u672c\u6765\u662f\uff0c<code>batch size\u00d7hidden size</code>\uff0c\u73b0\u5728\u53d8\u6210 <code>batch size\u00d7hidden size\u00d71</code>\uff0c\u4e58\u51fa\u6765\u4ee5\u540e \u662f <code>batch size\u00d7hidden size \u00d71</code>\uff0c\u6700\u540e\u518d\u628a1 \u53bb\u6389\uff0c\u6324\u6389</p> <p>\u8fd9\u91cc\u4e58\u7684\u6743\u91cd\u662f\u65b9\u9635\uff0c\u4e0d\u6539\u53d8\u5927\u5c0f\uff0c\u6240\u4ee5\u8fd8\u662f <code>h prev</code>\u7684\u5f62\u72b6</p> Python<pre><code>w_times_h = torch.bmm(w_hh_batch,h_prev.unsqueeze(2)).squeeze(-1)\n</code></pre> <p>\u8c03\u7528 <code>squeeze</code>\u51fd\u6570\uff0c\u628a\u6700\u540e\u76841\u53bb\u6389 \u6700\u540e\u53d8\u6210\u4e86 <code>batch size\u00d7 h dim</code></p> <p>\u8fd9\u662f\u8fd9\u4e24\u4e2a\u91cf\uff0c\u6700\u540e\u628a\u8fd9\u4e9b\u4e1c\u897f\u5168\u90e8\u52a0\u8d77\u6765\uff0c\u8ddf<code>bias</code>\u52a0\u8d77\u6765\uff0c\u7136\u540e\u901a\u8fc7\u4e24\u4e2atanh\u51fd\u6570</p> <p></p> <p>\u9996\u5148\u662f <code>w_times_x</code>\u8fd9\u4e2a\u91cf \u7136\u540e\u52a0\u4e0a <code>bias ih</code>\uff0c\u6700\u540e\u52a0\u4e0a <code>w times h</code>\uff0c\u4e0a\u4e00\u65f6\u523b\u9690\u542b\u72b6\u6001\u76f8\u5173\u7684\uff0c\u6700\u540e\u662f<code>bias hh</code>\uff0c\u7136\u540e\u8fc7\u4e00\u4e2a <code>tanh</code>\u6fc0\u6d3b\u51fd\u6570\uff0c\u6700\u7ec8\u5f97\u5230\u5f53\u524d\u65f6\u523b\u7684\u8fd9\u4e00\u72b6\u6001</p> Python<pre><code>torch.tanh(w_times_x + bias_ih + w_times_h + bias_hh)\n</code></pre> <p>\u5b9a\u4e49\u4e3a<code>h_prev</code>\uff0c\u56e0\u4e3a\u8fdb\u884c\u7684\u662f\u9012\u5f52\u7684\u8fd0\u7b97</p> Python<pre><code>h_prev = torch.tanh(w_times_x + bias_ih + w_times_h + bias_hh)\n</code></pre> <p>\u73b0\u5728\u8ba1\u7b97\u4e86\\(t\\)\u65f6\u523b\u7684\u8f93\u51fa\uff0c\u63a5\u7740\u628a\\(t\\)\u65f6\u523b\u7684\u8f93\u51fa\uff0c\u653e\u5165\u5230 <code>h out</code>\u4e2d\uff0c</p> <p>\u600e\u4e48\u653e\uff0c\u53ea\u8981\u653e\u5230\u65f6\u95f4\u957f\u5ea6\u8fd9\u4e00\u7ef4\uff0c\\(t\\)\u884c\u5373\u53ef</p> Python<pre><code>h_out[:,t,:] = h_prev\n</code></pre> <p>\u4ee5\u4e0a\u5b8c\u6210\u4e86\u9012\u5f52\u7684\u8fd0\u7b97\uff0c\u6700\u540e\u8fd4\u56de \u8ddf pytorch\u5b98\u65b9api\u4e00\u6837</p> <p>\u9996\u5148\u8fd4\u56de<code>h_out</code></p> <p>\u7136\u540e\u8fd4\u56de \u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001\uff0c\u5176\u5b9e\u4e5f\u5c31\u662f<code>h_prev</code></p> <p>\u4f46\u662f\u8fd9\u91cc\u7684<code>h_prev</code>\u662f\u4e8c\u7ef4\u7684\uff0c\u5b98\u65b9api\u662f\u4e09\u7ef4\u7684\uff0c\u6240\u4ee5\u8981 \u6269\u4e00\u7ef4\uff0c\u6269\u4e00\u7ef4\u7684\u539f\u56e0\u5c31\u662f\u56e0\u4e3a \u81ea\u5df1\u5b9e\u73b0\u7684\u662f \u5355\u5411\u3001\u5355\u5c42\u7684\uff0c\u6240\u4ee5\u5728 \u7b2c0\u7ef4 \u6269\u5145\u4e00\u4e2a1 \u5c31\u597d\u4e86</p> Python<pre><code>return h_out,h_prev.unsqueeze(0)\n</code></pre> <p>\u4ee5\u4e0a\u662f\u6240\u6709\u5168\u624b\u5199\u7684RNN forward\u51fd\u6570\uff0c\u5176\u5b9e\u5c31\u662f\u5355\u5411\u7684RNN</p>"},{"location":"learning/13_RNN/#torchtile","title":"torch.tile\u51fd\u6570","text":"<p>\u8865\u5145 torch.tile\u51fd\u6570\uff1a\u6cbf\u6307\u5b9a\u7ef4\u5ea6\u91cd\u590d\u5f20\u91cf\u51fd\u6570</p> <p>\u4f8b\u5b50\uff1a</p> Python<pre><code>import torch\n\n# \u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\nweight_hh = torch.tensor([[1, 2], [3, 4]])\n\n# \u5047\u8bbe\u6279\u91cf\u5927\u5c0f\u4e3a3\nbs = 3\n\n# \u4f7f\u7528 unsqueeze \u5728\u7b2c0\u7ef4\u5ea6\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u7136\u540e\u4f7f\u7528 tile \u6cbf\u7b2c0\u7ef4\u5ea6\u91cd\u590d bs \u6b21\nw_hh_batch = weight_hh.unsqueeze(0).tile(bs, 1, 1)\n\nprint(\"\u539f\u59cb\u5f20\u91cf:\")\nprint(weight_hh)\nprint(\"\u589e\u52a0\u7ef4\u5ea6\u5e76\u91cd\u590d\u540e\u7684\u5f20\u91cf:\")\nprint(w_hh_batch)\n</code></pre> <p>\u5728\u8fd9\u4e2a\u793a\u4f8b\u4e2d\uff1a</p> <ol> <li><code>weight_hh</code> \u662f\u4e00\u4e2a\u5f62\u72b6\u4e3a <code>[2, 2]</code> \u7684\u5f20\u91cf\u3002</li> <li><code>weight_hh.unsqueeze(0)</code> \u5728\u7b2c0\u7ef4\u5ea6\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u4f7f\u5176\u5f62\u72b6\u53d8\u4e3a <code>[1, 2, 2]</code>\u3002</li> <li><code>tile(bs, 1, 1)</code> \u6cbf\u7b2c0\u7ef4\u5ea6\u91cd\u590d <code>bs</code> \u6b21\uff08\u8fd9\u91cc <code>bs</code> \u4e3a3\uff09\uff0c\u4f7f\u5176\u5f62\u72b6\u53d8\u4e3a <code>[3, 2, 2]</code>\u3002</li> </ol> <p>\u8f93\u51fa\u7ed3\u679c\uff1a</p> Python<pre><code>\u539f\u59cb\u5f20\u91cf:\ntensor([[1, 2],\n        [3, 4]])\n\u589e\u52a0\u7ef4\u5ea6\u5e76\u91cd\u590d\u540e\u7684\u5f20\u91cf:\ntensor([[[1, 2],\n         [3, 4]],\n\n        [[1, 2],\n         [3, 4]],\n\n        [[1, 2],\n         [3, 4]]])\n</code></pre> <p>\u8fd9\u6837\uff0c<code>w_hh_batch</code> \u5c31\u662f\u4e00\u4e2a\u5f62\u72b6\u4e3a <code>[3, 2, 2]</code> \u7684\u5f20\u91cf\uff0c\u5176\u4e2d\u6bcf\u4e2a\u6279\u6b21\u90fd\u5305\u542b\u539f\u59cb\u7684 <code>weight_hh</code> \u5f20\u91cf</p>"},{"location":"learning/13_RNN/#5","title":"5 \u9a8c\u8bc1","text":"<p>\u9a8c\u8bc1\u601d\u8def\uff1a</p> <p>\u628a\u4e4b\u524d\u5b9e\u4f8b\u5316\u7684RNN\u7f51\u7edc\uff0c\u53c2\u6570\u62ff\u51fa\u6765\uff0c\u586b\u5145\u5230\u81ea\u5b9a\u4e49\u7684\u7f51\u7edc\u4e2d</p> <p>\u7136\u540e\u7b97\u51fa\u6765\u7684\u7ed3\u679c \u5982\u679c\u662f\u8ddf\u5b98\u65b9API\u7ed3\u679c\u4e00\u81f4\u7684\u8bdd\uff0c\u5c31\u8868\u660e\u81ea\u5b9a\u4e49\u7684\u51fd\u6570\u662f\u6b63\u786e\u7684</p> <p>\u9996\u5148\uff0c\u62ff\u51faRNN\u7684\u53c2\u6570\uff1a</p> <p>\uff081\uff09RNN\u6709\u54ea\u4e9b\u53c2\u6570\uff1f</p> <p><code>nn.Module</code>\u8fd9\u4e2a\u7c7b\uff0c</p> <p>\u2460 \u5728<code>pytorch</code>\u4e2d \u6240\u6709\u7684\u5c42\uff0c\u90fd\u662f\u7ee7\u627f\u81ea<code>nn.Module</code>\u8fd9\u4e2a\u7c7b</p> <p>\u2461 <code>nn.Module</code>\u7684\u51fd\u6570\uff1a<code>name.parameters</code>\u8fd9\u4e2a\u51fd\u6570\uff0c\u67e5\u770b RNN\u4e2d \u6709\u54ea\u4e9b\u53c2\u6570</p> <p><code>name.parameters</code>\u662f\u4e00\u4e2a\u751f\u6210\u5668\uff0c\u53ef\u4ee5\u7528\u5faa\u73af\u5f97\u5230 <code>for p,n in</code> </p> <p>p\uff1a\u53c2\u6570</p> <p>n\uff1aname</p> <p><code>in rnn.named_parameters():</code> \u5c31\u80fd\u770b\u5230 rnn\u6709\u54ea\u4e9b\u53c2\u6570</p> Python<pre><code>for p,n in rnn.named_parameters():\n</code></pre> <p>\u6253\u5370\u67e5\u770b\u7ed3\u679c\uff1aRNN\u6709\u54ea\u4e9b\u53c2\u6570 \u4ee5\u53ca \u5b83\u7684\u540d\u79f0</p> <p></p> <p>\u53ef\u4ee5\u770b\u5230 RNN\u7684\u6240\u6709\u7684\u53c2\u6570\u3001\u540d\u79f0\u3001\u5177\u4f53\u5730\u5f20\u91cf\u7684\u6570\u503c </p> <p>\u4e00\u5171\u6709\u56db\u4e2a\u53c2\u6570\uff0c\u5206\u522b\u662f</p> <p>\u2460\u7b2c\u4e00\u4e2a\u53c2\u6570\uff1a <code>weight ih l0</code></p> <ul> <li><code>weight ih</code> \uff1a \u516c\u5f0f\u91cc\u7684 <code>wih</code></li> <li><code>l0</code>\uff1a\u7f51\u7edc\u5b9a\u4e49\u53ea\u6709\u4e00\u5c42\uff0c\u5c42\u6570\u662f\u4ece\\(0\\)\u5f00\u59cb\u7684\uff0c\u6240\u4ee5\u662f\u4ece<code>l0</code></li> </ul> <p>\u2461 \u7b2c\u4e8c\u4e2a\u53c2\u6570\uff1a<code>weight hh l0</code></p> <p>\u8868\u793a\u5f53\u524d\u5c42 <code>w hh</code>\u7684\u53c2\u6570</p> <p>\u53e6\u5916\u4e24\u4e2a\u5c31\u662f\u504f\u7f6e\u4e86\uff0c\u5206\u522b\u662f</p> <p>\u2462\u7b2c\u4e09\u4e2a\u53c2\u6570\uff1a <code>bias ih</code></p> <p>\u2463\u7b2c\u56db\u4e2a\u53c2\u6570\uff1a <code>bias hh</code> </p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff1a</p> <ul> <li>\u524d\u9762\u4e24\u4e2a\u6743\u91cd\u5f20\u91cf \u662f \u4e8c\u7ef4\u5f20\u91cf</li> <li>\u540e\u9762\u4e24\u4e2a\u504f\u7f6e\u662f \u4e00\u7ef4\u7684\u5411\u91cf</li> </ul> <p>\uff082\uff09\u73b0\u5728\u628a\u8fd9\u4e9b\u53c2\u6570 \u4ee3\u5165\u5230\u81ea\u5df1\u5199\u7684<code>RNN forward</code>\u51fd\u6570\u4e2d</p> <p>\u9996\u5148\uff0c\u590d\u5236\u4e00\u4e0b \u81ea\u5df1\u5199\u7684\u51fd\u6570\u7b7e\u540d</p> Python<pre><code>rnn_forward(input,weight_ih,weight_hh,bias_ih,bias_hh,h_prev):\n</code></pre> <ul> <li><code>input</code>\u8fd8\u662f<code>input</code></li> <li><code>weight ih</code>\u53ef\u4ee5\u6539\u6210 <code>rnn.</code>\uff0c\u76f4\u63a5\u7528<code>rnn.\u53c2\u6570\u540d\u79f0</code>\uff0c\u5c31\u53ef\u4ee5\u8bbf\u95ee\u8fd9\u4e2a\u53c2\u6570 \uff0c<code>rnn.weight_ih_l0</code></li> <li><code>weight hh</code>\u4e5f\u662f\u4e00\u6837\uff0c\u7528<code>rnn.</code>\u6765\u8fdb\u884c\u8bbf\u95ee\uff1a<code>rnn.weight_hh_l0</code></li> <li><code>bias</code>\u4e5f\u662f\u4e00\u6837\u7684 \u5bf9\u5e94\u7684\u662f <code>rnn.bias_ih_l0</code></li> <li>\u540c\u6837<code>hh bias</code>\u4e5f\u662f\u4e00\u6837\u7684 <code>rnn.bias_hh_l0</code></li> <li><code>h_prev</code>\uff0c\u5c31\u662f\u81ea\u5b9a\u4e49\u597d\u7684\uff0c\u5c31\u76f4\u63a5\u7528<code>h_prev</code></li> </ul> Python<pre><code>rnn_forward(input,rnn.weight_ih_l0,rnn.weight_hh_l0,rnn.bias_ih_l0,rnn.bias_hh_l0,h_prev)\n</code></pre> <p>\u53d8\u91cf\u540d\u547d\u4ee4\uff1a</p> <p>\u524d\u9762\u5199\u7684\u662f<code>rnn output</code>\u548c<code>state finall</code></p> <p></p> <p>\u52a0\u524d\u7f00 <code>custom</code>\uff0c\u8868\u793a\u81ea\u5df1\u5199\u7684</p> Python<pre><code>custom_rnn_output,custom_state_finall = rnn_forward(input,rnn.weight_ih_l0,rnn.weight_hh_l0,rnn.bias_ih_l0,rnn.bias_hh_l0,h_prev)\n</code></pre> <p>\u8fd9\u6837\u5c31\u8c03\u7528\u4e86\u81ea\u5df1\u5199\u7684<code>RNN forward</code>\u51fd\u6570</p> <p>\u7136\u540e\u5bf9\u6bd4<code>pytorch api</code>\u7684\u7ed3\u679c \u548c \u81ea\u5df1\u5199\u7684\u7ed3\u679c</p> <p></p> <p>\u7b2c\u4e00\u4e2a\u5f20\u91cf \u6574\u4f53RNN \u9884\u6d4b\u7684\u8f93\u51fa\uff0c\u662f\u4e00\u81f4\u7684</p> <p>\u7b2c\u4e8c\u4e2a\u5f20\u91cf\u662f\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u8f93\u51fa</p> <p>\u5b98\u65b9\u7684\u7ed3\u679c \u548c \u81ea\u5b9a\u4e49\u7684\u7ed3\u679c\u4e00\u6837 </p>"},{"location":"learning/13_RNN/#rnn_1","title":"\u81ea\u5b9a\u4e49 RNN\u4ee3\u7801","text":""},{"location":"learning/13_RNN/#6-rnn","title":"6 \u9a8c\u8bc1\u53cc\u5411RNN","text":"Python<pre><code>h_t = tanh(x_t)\n</code></pre> <p>\u53cc\u5411\u7684\u8bdd\u8c03\u7528\u5355\u5411\u7684\u51fd\u6570</p> <p>\u53cc\u5411\u9700\u8981\u6ce8\u610f \u6240\u6709\u7684\u53c2\u6570 \u90fddouble\u4e86\uff0c\u6240\u6709\u7684weight\u548cbias \u90fd\u6709\u4e24\u4e2a</p> Python<pre><code># step3 \u624b\u5199\u4e00\u4e2abidirectional_rnn_forward\u51fd\u6570\uff0c\u5b9e\u73b0\u53cc\u5411RNN\u7684\u8ba1\u7b97\u539f\u7406\n</code></pre> <ul> <li>\u53cc\u5411\u8981\u8003\u8651\u4e24\u500d\u7684 <code>forward\u51fd\u6570</code>\u548c<code>backward\u5c42</code></li> <li><code>weight</code>\u6709<code>forward</code>\u5c42\u548c<code>backward</code>\u5c42</li> <li><code>bias</code>\u4e5f\u6709<code>forward</code>\u5c42\u548c<code>backward</code>\u5c42</li> <li><code>h prev</code>\u4e5f\u662f\u6709\u4e24\u4efd\u7684</li> </ul> <p>\u7b2c\u4e00\u4efd\u662f <code>forward layer</code>\uff0c\u8fd8\u6709 <code>backward</code>\uff0c\u590d\u5236\u7136\u540e\u6539\u540d\uff0c\u6309\u7167\u5b98\u65b9\u7684\u540d\u79f0\uff0c\u6539\u6210<code>reverse</code></p> <p>\u8fd9\u65f6\u5019\u6240\u6709\u7684\u53c2\u6570\u90fd\u662f\u4e24\u4efd\u7684\uff1a</p> <p><code>forward</code>\u4e00\u4efd\uff0c<code>backward</code>\u4e00\u4efd</p> <p>RNN\u662f\u6bd4\u8f83\u7b80\u5355\u7684\uff0c\u5982\u679c\u662f<code>LSTM</code> \u3001<code>GRU</code> \u66f4\u590d\u6742</p> <p>\u51fd\u6570\u7b7e\u540d\u5199\u6210\uff1a</p> <p></p> <p>\u63a5\u4e0b\u6765\uff0c\u8fd8\u662f\u4e00\u6837\u7684\uff0c\u5f97\u5230\u4e00\u4e9b\u57fa\u672c\u7684\u4fe1\u606f</p> <p>\u9996\u5148\uff0c\u4e0a\u9762\u590d\u5236\u4e0b\u6765\uff1a</p> <p></p> <p>\u7b2c\u4e00\u6b65 <code>batch size</code>\uff0c<code>\u65f6\u95f4</code> \u548c <code>input size</code></p> <p>\u7136\u540e\uff0c\u5f97\u5230 <code>hidden size</code>  \u3001<code>h_dim</code></p> <p>\u5173\u4e8e<code>h_out</code>\uff0c\u8fd9\u91cc<code>batch size</code>\u4e0d\u53d8\uff0c<code>T</code>\u4e0d\u53d8\uff0c\u4f46\u662f<code>h dim</code>\u8981\u53d8\u6210\u4e24\u500d\uff0c\u56e0\u4e3a\u662f\u53cc\u5411\u7684\u7ed3\u6784\uff1a</p> Python<pre><code>h_out = torch.zeros(bs,T,h_dim*2)\n# \u521d\u59cb\u5316\u8f93\u51fa\u72b6\u6001\u77e9\u9635\uff0c\u6ce8\u610f\u53cc\u5411\u662f\u4e24\u500d\u7684\u7279\u5f81\u5927\u5c0f\n</code></pre> <p>\u8be5\u5b9a\u4e49\u7684\u5b9a\u4e49\u597d\u4e86\uff0c\u63a5\u4e0b\u6765 \u8c03\u7528<code>RNN forward</code>\u51fd\u6570</p> <p>\u8c03\u7528\u4e24\u6b21<code>RNN forward</code>\u51fd\u6570</p> <p>\u7b2c\u4e00\u6b65\u4e00\u6a21\u4e00\u6837</p> <p></p> <p>\u7ea2\u6846\u662f\u9700\u8981\u4f20\u5165\u7684\u53c2\u6570</p> <p>\u8fd9\u662f<code>forward</code>\u5c42\u7684\u8c03\u7528\uff0c\u53d6\u540d\u4e3a <code>forward_output</code>\uff0c\u8fd9\u91cc\u53ea\u53d6 \u7b2c\u4e00\u4e2a\u8fd4\u56de\u503c\uff0c\u6240\u4ee5\u52a0\u4e2a[0]</p> <p></p> <p>\u5f97\u5230 <code>forward layer</code></p> <p>\u4e0b\u9762 <code>backward layer</code></p> <p>\u8fd9\u91cc\u8981\u53d8\u6362\u4e00\u4e0b\uff0c\u9664\u4e86\u6240\u6709\u7684\u53c2\u6570\u90fd\u7528reverse\u7248\u672c\u7684\uff0c\u5bf9input \u4e5f\u8981reverse\u4e00\u4e0b\uff0c\u5c31\u662f\u56e0\u4e3a\u5982\u679c\u662f\u53cd\u5411\u7684\u8bdd\uff0c\u8981\u4fdd\u8bc1\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u4e0a\uff0cinput\u662f\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff1b\u5bf9input \u9700\u8981 \u5728\u957f\u5ea6\u8fd9\u4e00\u7ef4 \u8fdb\u884c\u7ffb\u8f6c\uff1a</p> <p></p> <p>\u8c03\u7528 <code>torch.flip  api</code>\uff0c\u8fd9\u4e2a<code>api</code>\uff0c\u5bf9\u5f20\u91cf\u8fdb\u884c\u7ffb\u8f6c\uff1a</p> <p></p> <p>\u6709\u4e24\u4e2a\u53c2\u6570\uff1a</p> <ul> <li> <p>\u4e00\u4e2a\u662finput</p> </li> <li> <p>\u4e00\u4e2a\u662fdim\uff0c\u4e5f\u5c31\u662f\u8bf4 \u4f20\u5165\u7684\u662f \u54ea\u4e2a dim\uff0c\u5c31\u4f1a\u5bf9\u54ea\u4e2a dim \u8fdb\u884c\u7ffb\u8f6c\uff0c\u5b8c\u5168\u76f8\u53cd\u7684\u987a\u5e8f</p> </li> </ul> <p>\u8fd8\u662f\u5148\u62f7\u8d1d\u6240\u6709\u7684\u53c2\u6570\uff0c\u8c03\u7528 rnn_forward\u51fd\u6570\uff1a</p> <p></p> <ul> <li>\u7b2c\u4e00\u4e2a\u53c2\u6570 <code>input</code>\uff0c\u8fdb\u884c\u7ffb\u8f6c\uff0c\u8c03\u7528 <code>torch.flip</code>\uff0c<code>flip</code>\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u662f <code>input</code>\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f<code>\u7ef4\u5ea6</code>\uff0c\u7ef4\u5ea6\u5b98\u65b9api\u4e2d\u89c4\u5b9a\uff1a</li> </ul> <p></p> <p>\u8981\u4e48\u662f\u5217\u8868 \u8981\u4e48\u662f\u5143\u7ec4</p> <p>\u8fd9\u91cc\u7684input\u662f\u4e09\u7ef4\uff0c\u8981\u7ffb\u8f6c\u7684\u662f \u4e2d\u95f4\u8fd9\u4e00\u7ef4\uff0c<code>T</code>\u8fd9\u7ef4\uff1a</p> <p></p> <p>\u4f20\u5165\u4e00\u4e2a\u5217\u8868\uff0c<code>1</code>\u8fd9\u4e00\u7ef4\u5ea6\uff0c\u8868\u793a\u4e2d\u95f4\u8fd9\u4e00\u7ef4\u5ea6\uff0c\u8fdb\u884c\u7ffb\u8f6c</p> Python<pre><code>rnn_forward(torch.flip(input,[1]),\n            weight_ih_reverse,\n            weight_hh_reverse,\n            bias_ih_reverse,\n            bias_hh_reveerse,\n            h_prev_reverse)\n</code></pre> <p>\u540c\u6837 \u5bf9\u5b83\u7684\u8c03\u7528 \u4e5f\u53ea\u53d6 <code>output</code>\uff0c\u5b9a\u4e49\u4e3a <code>backward output</code></p> Python<pre><code>backward_output = rnn_forward(torch.flip(input,[1]),\n                              weight_ih_reverse,\n                              weight_hh_reverse,\n                              bias_ih_reverse,\n                              bias_hh_reveerse,\n                              h_prev_reverse)[0] # backward layer\n</code></pre> <p>\u4ee5\u4e0a \u5f97\u5230\u4e86 <code>forward output</code>\u548c<code>backward output</code></p> <p>\u4e3a\u4ec0\u4e48 \u53ea\u4fdd\u7559\u4e86 <code>h_out</code>\uff0c\u6ca1\u6709\u4fdd\u7559<code>h prev</code>\u5462\uff1f</p> <p>\u56e0\u4e3a\u5728RNN\u4e2d\uff0c<code>h prev</code>\u53ef\u4ee5\u4ece <code>h out</code>\u4e2d\u5f97\u5230\uff0c\u6240\u4ee5\u4e3a\u4e86\u65b9\u4fbf \u53ea\u53d6\u4e86 <code>h out</code></p> <p></p> <p>\u63a5\u4e0b\u6765\uff0c\u628a <code>forward output</code> \u548c <code>backward output</code> \u586b\u5145\u5230 <code>h out</code>\u4e2d</p> <p>\u9996\u5148 <code>h out</code>\u662f\u4e09\u7ef4\u7684\uff0c\u5e76\u4e14\u6700\u540e\u4e00\u7ef4 \u7531 <code>forward \u548c backward</code> \u586b\u5145\u8d77\u6765\u7684\uff0c\u6240\u4ee5\u586b\u5145\u65f6\uff0c\u7d22\u5f15\u7684\u5199\u6cd5\uff1a\u4ece\\(0\\)\u5230 <code>h_dim</code></p> Python<pre><code>h_out[:,:,:h_dim] = forward_output\n</code></pre> <p>\u4ece<code>h_dim:</code>\u5230\u6700\u540e</p> <p>\u524d\u5411\u7684\u8f93\u51fa\uff0c\u586b\u5145\u5230\u524d\u4e00\u534a\u4e2d\uff0c\u540e\u4e00\u534a\u7684\u7ef4\u5ea6\uff0c\u7528<code>backward output</code>\u586b\u5145</p> Python<pre><code>h_out[:,:,h_dim:] = backward_output\n</code></pre> <p>\u628a <code>\u524d\u5411\u8f93\u51fa</code> \u548c <code>\u540e\u5411\u8f93\u51fa</code> \u62fc\u8d77\u6765\uff0c\u7136\u540e\u8fd4\u56de</p> <p>\u540c\u6837\u6309\u7167<code>\u5b98\u65b9api</code>\uff0c\u8fd4\u56de\u4e24\u4e2a\u6570\uff1a</p> <ul> <li>\u7b2c\u4e00\u4e2a\u6570\u662f <code>h_out</code></li> <li>\u7b2c\u4e8c\u4e2a\u6570\u5c31\u662f <code>state finall</code></li> </ul> <p></p> <p><code>Sate finall</code>\u7ef4\u5ea6\u662f \\(D*num\\_layers\\) \u00d7 N \u00d7 \\(H_{out}\\)</p> <ul> <li>\u524d\u9762\u8868\u793a \u53cc\u5411 \u548c \u5c42\u6570\u7684\u4e58\u79ef</li> <li>\u4e2d\u95f4\u662f<code>batch size</code></li> <li>\u540e\u9762\u662f <code>H_out</code></li> </ul> <p>\u600e\u4e48\u5199\u5462\uff1f</p> <p>\u9996\u5148 \u8981\u53d6\u51fa  <code>h out</code>\u7684\u6700\u540e\u4e00\u4e2a\u65f6\u523b\uff0c\u56e0\u4e3a\u65f6\u523b\u662f\u5728\u4e2d\u95f4\u90a3\u4e2a\u7ef4\u5ea6\uff0c\u6240\u4ee5\u7528 <code>-1</code>\u7d22\u5f15</p> Python<pre><code>return h_out,h_out[:,-1,:].reshape(())\n</code></pre> <p>\u5148\u53d6\u51fa \u6700\u540e\u4e00\u4e2a\u65f6\u523b\uff0c\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u72b6\u6001\u5411\u91cf\uff0c\u5f62\u72b6 \\(batch \\_size\u00d72\u500d\u7684h\\_dim\\)\uff0c\u5148<code>reshape</code>\uff0c\u628a2\u5355\u72ec\u62ce\u51fa\u6765\uff0c\u7136\u540ereshape\uff1a</p> <ul> <li>Batch size\u4e0d\u53d8</li> <li>2\u5355\u72ec\u62ce\u51fa\u6765</li> <li>h dim\u5c31\u5199\u6210 h dim</li> </ul> <p>\u9996\u5148\u628a\u4e8c\u7ef4\u5f20\u91cf \u53d8\u6210\u4e09\u7ef4\u5f20\u91cf</p> Python<pre><code>return h_out,h_out[:,-1,:].reshape((bs,2,h_dim))\n</code></pre> <p>\u7136\u540e \u628a2\u63d0\u5230\u524d\u9762\uff0c\u6839\u636e\u5b98\u65b9api\uff1a</p> <ul> <li>2 \u5728\u524d\u9762</li> </ul> <p></p> <ul> <li>batch size\u5728\u4e2d\u95f4</li> </ul> <p>\u6240\u4ee5\u628a2 \u63d0\u5230\u524d\u9762\uff0c\u8c03\u7528\u4e00\u4e0b\u8f6c\u7f6e\u51fd\u6570\uff0c\u5c31\u662f\u628a <code>\u7b2c0\u7ef4\u5ea6</code> \u548c <code>\u7b2c1\u7ef4\u5ea6</code> \u4ea4\u6362\u4e00\u4e0b\uff1a</p> Python<pre><code>return h_out,h_out[:,-1,:].reshape((bs,2,h_dim)).transpose(0,1)\n</code></pre> <p>\u4ee5\u4e0a\u53cc\u5411\u81ea\u5b9a\u4e49RNN \u51fd\u6570\u7684\u5b9e\u73b0</p>"},{"location":"learning/13_RNN/#rnn_2","title":"\u81ea\u5b9a\u4e49\u53cc\u5411 RNN\u4ee3\u7801","text":"Python<pre><code># step3 \u624b\u5199\u4e00\u4e2a bidirectional_rnn_forward\u51fd\u6570\uff0c\u5b9e\u73b0\u53cc\u5411RNN\u7684\u8ba1\u7b97\u539f\u7406\ndef bidirectional_rnn_forward(input,\n                              weight_ih,\n                              weight_hh,\n                              bias_ih,\n                              bias_hh,\n                              h_prev,\n                              weight_ih_reverse,\n                              weight_hh_reverse,\n                              bias_ih_reverse,\n                              bias_hh_reverse,\n                              h_prev_reverse):\n    bs,T,input_size = input.shape\n    h_dim = weight_ih.shape[0]\n    h_out = torch.zeros(bs,T,h_dim*2) # \u521d\u59cb\u5316\u4e00\u4e2a\u8f93\u51fa\uff08\u72b6\u6001\uff09\u77e9\u9635\uff0c\u6ce8\u610f\u53cc\u5411\u662f\u4e24\u500d\u7684\u7279\u5f81\u5927\u5c0f\n\n    forward_output = rnn_forward(input,\n                                 weight_ih,\n                                 weight_hh,\n                                 bias_ih,\n                                 bias_hh,\n                                 h_prev)[0]  # forward layer\n    backward_output = rnn_forward(torch.flip(input,[1]),\n                                  weight_ih_reverse,\n                                  weight_hh_reverse,\n                                  bias_ih_reverse, \n                                  bias_hh_reverse,\n                                  h_prev_reverse)[0] # backward layer\n\n    # \u5c06input\u6309\u7167\u65f6\u95f4\u7684\u987a\u5e8f\u7ffb\u8f6c\n    h_out[:,:,:h_dim] = forward_output\n    h_out[:,:,h_dim:] = torch.flip(backward_output,[1]) #\u9700\u8981\u518d\u7ffb\u8f6c\u4e00\u4e0b \u624d\u80fd\u548cforward output\u62fc\u63a5\n\n\n    h_n = torch.zeros(bs,2,h_dim)  # \u8981\u6700\u540e\u7684\u72b6\u6001\u8fde\u63a5\n\n    h_n[:,0,:] = forward_output[:,-1,:]\n    h_n[:,1,:] = backward_output[:,-1,:]\n\n    h_n = h_n.transpose(0,1)\n\n    return h_out,h_n\n    # return h_out,h_out[:,-1,:].reshape((bs,2,h_dim)).transpose(0,1)\n\n# \u9a8c\u8bc1\u4e00\u4e0b bidirectional_rnn_forward\u7684\u6b63\u786e\u6027\nbi_rnn = nn.RNN(input_size,\n                hidden_size,\n                batch_first=True,\n                bidirectional=True)\nh_prev = torch.zeros((2,bs,hidden_size))\nbi_rnn_output,bi_state_finall = bi_rnn(input,h_prev)\n\nfor k,v in bi_rnn.named_parameters():\n    print(k,v)\n</code></pre> <p>\u4ee3\u7801\u601d\u8def\uff1a</p> <ol> <li>\u9996\u5148\u628a <code>input</code>\u4f20\u5165\u5230 <code>forward layer</code>\u4e2d</li> <li>\u7136\u540e\u518d\u628a<code>input</code> \u6309\u7167 \u65f6\u95f4\u7684\u987a\u5e8f \u7ffb\u8f6c\u4e00\u4e0b\uff0c\u518d\u4f20\u5165<code>backwardward layer</code>\u4e2d</li> <li>\u518d\u628a <code>forward output</code>\u548c<code>backward output</code>\u62fc\u8d77\u6765\uff0c\u5f62\u6210\u6574\u4f53\u7684<code>h out</code></li> <li>\u6700\u540e\u8fd4\u56de\u5e8f\u5217 \u6574\u4f53\u7684\u9690\u542b\u72b6\u6001\u548c \u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u72b6\u6001</li> </ol> <p>\u73b0\u5728\u9a8c\u8bc1  \u53cc\u5411 rnn  forward \u6b63\u786e\u6027</p> <p>\u9996\u5148 \u5b9e\u4f8b\u5316\u53cc\u5411RNN \u5c42</p> <p>\u590d\u5236\u4e0b\u6765\uff0c\u5e76\u8bbe\u7f6e bidirection=True</p> Python<pre><code># \u9a8c\u8bc1\u4e00\u4e0b bidirectional_rnn_forward\u7684\u6b63\u786e\u6027\nbi_rnn = nn.RNN(input_size,hidden_size,batch_first=True,bidirectional=True)\n</code></pre> <p>\u540c\u6837\u5b9a\u4e49\u4e00\u4e2a<code>h_prev</code></p> Python<pre><code>h_prev = torch.zeros()\n</code></pre> <p>\u5927\u5c0f\u662f <code>2\u00d7 batch size\u00d7 hidden size</code></p> <p></p> Python<pre><code>h_prev = torch.zeros(2,bs,hidden_size)\n</code></pre> <p>\u8c03\u7528RNN\uff0c\u4f20\u5165<code>input</code>\u548c<code>h_prev</code>\uff0c\u5f97\u5230\u53cc\u5411RNN\u7684<code>output</code>\u548c\u53cc\u5411<code>state finall</code></p> Python<pre><code>bi_rnn_output,bi_state_finall = bi_rnn(input,h_prev)\n</code></pre> <p>\u5f97\u5230\u5b98\u65b9api\u7684\u7ed3\u679c</p> <p></p> <p>\u5bf9\u4e8eRNN \u67e5\u770b\u4e00\u4e0b \u53c2\u6570\u7684\u540d\u5b57\uff0c\u7136\u540e\u628a\u8fd9\u4e9b\u53c2\u6570\u4ee3\u5165\u5230\u81ea\u5b9a\u4e49\u7684\u53cc\u5411RNN\u51fd\u6570\u4e2d\u53bb</p> Python<pre><code>for k,v in bi_rnn.named_parameters():\n    print(k,v)\n</code></pre> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u5728pytorch\u53cc\u5411RNN \u4e2d\u7684\u53c2\u6570\uff1a</p> <ol> <li>weight ih l0</li> <li>weight hh l0</li> <li>bias ih l0</li> <li>bias hh l0</li> <li>weight ih l0 reverse</li> <li>weight hh l0 reverse</li> <li>bias ih l0</li> <li>bias hh l0 reverse</li> </ol> <p>\u4e00\u5171\u67098\u4e2a\u53c2\u6570\uff0c\u8fd9\u662f\u56e0\u4e3a <code>forward layer</code>\u67094\u4e2a\u53c2\u6570\uff0c<code>reverse layer</code>\u4e5f\u67094\u4e2a\u53c2\u6570</p> <p>\u6709\u4e86\u8fd98\u4e2a\u53c2\u6570\uff0c\u5c31\u53ef\u4ee5\u628a\u8fd98\u4e2a\u53c2\u6570\u4f20\u5165\u5230\u53cc\u5411RNN\u4e2d</p> <p>\u9996\u5148\u628a \u7b7e\u540d copy\u4e0b\u6765\uff1a</p> <p></p> Python<pre><code>bidirectional_rnn_forward(input,\n                          weight_ih,\n                          weight_hh,\n                          bias_ih,\n                          bias_hh,\n                          h_prev,\n                          weight_ih_reverse,\n                          weight_hh_reverse,\n                          bias_ih_reverse,\n                          bias_hh_reverse,\n                          h_prev_reverse)\n</code></pre> <ul> <li><code>input</code>\u4e0d\u53d8</li> <li><code>weight ih</code>\u6539\u6210<code>weight ih l0</code></li> <li><code>weight hh</code>\uff0c\u540c\u6837<code>weight hh l0</code></li> </ul> <p>\u8fd8\u8981\u52a0\u4e0a<code>bi_rnn.</code>\uff0c\u4e5f\u5c31\u662f\u8bf4\u628a\u5b9e\u4f8b\u5316\u7684RNN\u5c42\u4f20\u8fdb\u6765</p> <p><code>bi_rnn.bias ih l0</code> </p> <p><code>bi_rnn.bias hh l0</code></p> <p></p> <p><code>h prev</code>\u9700\u8981\u6ce8\u610f\uff1a\u662f\u4e09\u7ef4\u7684</p> <p>\u524d\u9762\u6709\u4e2a 2 \uff0c\u53ea\u9700\u8981\u4f20\u5165\u7b2c\u4e00\u4e2a\u5c31\u597d\u4e86 <code>h prev[0]</code></p> <p>\u53cd\u5411\u7684\u4e5f\u662f\u7c7b\u4f3c\u7684</p> <p><code>bi_rnn.weight ih l0 reverse</code></p> <p>\u540e\u9762\u4e5f\u662f\u4e00\u6837 <code>bi_rnn.weight hh l0 reverse</code></p> <p><code>bi_rnn.bias ih l0 reverse</code> </p> <p><code>bi_rnn.bias hh l0 reverse</code></p> <p><code>h prev reverse</code>\uff0c\u7528<code>h prev [1]</code></p> <p></p> <p>\u5b9a\u4e49  <code>custom_bi_rnn_output,custom_bi_state_finall</code>\u63a5\u6536\u8f93\u51fa</p> <p>\u63a5\u4e0b\u6765\u5206\u522b\u6253\u5370api\u7684\u7ed3\u679c \u548c \u81ea\u5df1\u5199\u7684\u51fd\u6570\u7684\u7ed3\u679c\uff1a</p> <p></p> <p>\u8fd9\u4e2a \u7ed3\u679c\u6709\u95ee\u9898\uff0c\uff08\u540e\u9762\u6539\u4e86 \u5c31\u662f\u5404\u79cd\u7ffb\u8f6c ) </p> <p>\u7531\u4e8e\u662f\u53cc\u5411\u7684 <code>hidden size=3</code>\uff0c\u4f46\u662f\u8f93\u51fa\u72b6\u6001\u957f\u5ea6\u662f6\uff0c\u8fd9\u662f\u56e0\u4e3a\u53cc\u5411\u7684\u6709\u62fc\u63a5</p>"},{"location":"learning/13_RNN/#_2","title":"\u6c47\u603b\u6240\u6709\u4ee3\u7801","text":"Python<pre><code>import torch\nimport torch.nn as nn\n</code></pre> Python<pre><code>bs,T=2,3  # \u6279\u5927\u5c0f\uff0c\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\ninput_size,hidden_size = 2,3 # \u8f93\u5165\u7279\u5f81\u5927\u5c0f\uff0c\u9690\u542b\u5c42\u7279\u5f81\u5927\u5c0f\ninput = torch.randn(bs,T,input_size)  # \u968f\u673a\u521d\u59cb\u5316\u4e00\u4e2a\u8f93\u5165\u7279\u5f81\u5e8f\u5217\nh_prev = torch.zeros(bs,hidden_size) # \u521d\u59cb\u9690\u542b\u72b6\u6001\n</code></pre> Python<pre><code># step1 \u8c03\u7528pytorch RNN API\nrnn = nn.RNN(input_size,hidden_size,batch_first=True)\nrnn_output,state_finall = rnn(input,h_prev.unsqueeze(0))\n\nprint(rnn_output)\nprint(state_finall)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>tensor([[[-0.7709,  0.7301, -0.9299],\n         [-0.6976, -0.8241, -0.1903],\n         [-0.6485, -0.2633, -0.1093]],\n\n        [[-0.2035,  0.7439, -0.1369],\n         [-0.4805, -0.5790,  0.1787],\n         [-0.6185,  0.4854, -0.4907]]], grad_fn=&lt;TransposeBackward1&gt;)\ntensor([[[-0.6485, -0.2633, -0.1093],\n         [-0.6185,  0.4854, -0.4907]]], grad_fn=&lt;StackBackward0&gt;)\n</code></pre> Python<pre><code># step2 \u624b\u5199 rnn_forward\u51fd\u6570\uff0c\u5b9e\u73b0RNN\u7684\u8ba1\u7b97\u539f\u7406\ndef rnn_forward(input,weight_ih,weight_hh,bias_ih,bias_hh,h_prev):\n    bs,T,input_size = input.shape\n    h_dim = weight_ih.shape[0]\n    h_out = torch.zeros(bs,T,h_dim) # \u521d\u59cb\u5316\u4e00\u4e2a\u8f93\u51fa\uff08\u72b6\u6001\uff09\u77e9\u9635\n\n    for t in range(T):\n        x = input[:,t,:].unsqueeze(2)  # \u83b7\u53d6\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u7279\u5f81\uff0cbs*input_size*1\n        w_ih_batch = weight_ih.unsqueeze(0).tile(bs,1,1) # bs * h_dim * input_size\n        w_hh_batch = weight_hh.unsqueeze(0).tile(bs,1,1)# bs * h_dim * h_dim\n\n        w_times_x = torch.bmm(w_ih_batch,x).squeeze(-1) # bs*h_dim\n        w_times_h = torch.bmm(w_hh_batch,h_prev.unsqueeze(2)).squeeze(-1) # bs*h_him\n        h_prev = torch.tanh(w_times_x + bias_ih + w_times_h + bias_hh)\n\n        h_out[:,t,:] = h_prev\n\n    return h_out,h_prev.unsqueeze(0)\n</code></pre> Python<pre><code># \u9a8c\u8bc1\u7ed3\u679c\ncustom_rnn_output,custom_state_finall = rnn_forward(input,\n                                                    rnn.weight_ih_l0,\n                                                    rnn.weight_hh_l0,\n                                                    rnn.bias_ih_l0,\n                                                    rnn.bias_hh_l0,\n                                                    h_prev)\nprint(custom_rnn_output)\nprint(custom_state_finall)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>tensor([[[-0.7709,  0.7301, -0.9299],\n         [-0.6976, -0.8241, -0.1903],\n         [-0.6485, -0.2633, -0.1093]],\n\n        [[-0.2035,  0.7439, -0.1369],\n         [-0.4805, -0.5790,  0.1787],\n         [-0.6185,  0.4854, -0.4907]]], grad_fn=&lt;CopySlices&gt;)\ntensor([[[-0.6485, -0.2633, -0.1093],\n         [-0.6185,  0.4854, -0.4907]]], grad_fn=&lt;UnsqueezeBackward0&gt;)\n</code></pre> Python<pre><code>print(torch.allclose(rnn_output,custom_rnn_output))\nprint(torch.allclose(state_finall,custom_state_finall))\n</code></pre> <p>\u8f93\u51fa\uff1aTrue\u3001True</p> Python<pre><code># step3 \u624b\u5199\u4e00\u4e2a bidirectional_rnn_forward\u51fd\u6570\uff0c\u5b9e\u73b0\u53cc\u5411RNN\u7684\u8ba1\u7b97\u539f\u7406\ndef bidirectional_rnn_forward(input,\n                              weight_ih,\n                              weight_hh,\n                              bias_ih,\n                              bias_hh,\n                              h_prev,\n                              weight_ih_reverse,\n                              weight_hh_reverse,\n                              bias_ih_reverse,\n                              bias_hh_reverse,\n                              h_prev_reverse):\n    bs,T,input_size = input.shape\n    h_dim = weight_ih.shape[0]\n    h_out = torch.zeros(bs,T,h_dim*2) # \u521d\u59cb\u5316\u4e00\u4e2a\u8f93\u51fa\uff08\u72b6\u6001\uff09\u77e9\u9635\uff0c\u6ce8\u610f\u53cc\u5411\u662f\u4e24\u500d\u7684\u7279\u5f81\u5927\u5c0f\n\n    forward_output = rnn_forward(input,\n                                 weight_ih,\n                                 weight_hh,\n                                 bias_ih,\n                                 bias_hh,\n                                 h_prev)[0]  # forward layer\n    backward_output = rnn_forward(torch.flip(input,[1]),\n                                  weight_ih_reverse,\n                                  weight_hh_reverse,\n                                  bias_ih_reverse, \n                                  bias_hh_reverse,\n                                  h_prev_reverse)[0] # backward layer\n\n    # \u5c06input\u6309\u7167\u65f6\u95f4\u7684\u987a\u5e8f\u7ffb\u8f6c\n    h_out[:,:,:h_dim] = forward_output\n    h_out[:,:,h_dim:] = torch.flip(backward_output,[1]) #\u9700\u8981\u518d\u7ffb\u8f6c\u4e00\u4e0b \u624d\u80fd\u548cforward output\u62fc\u63a5\n\n\n    h_n = torch.zeros(bs,2,h_dim)  # \u8981\u6700\u540e\u7684\u72b6\u6001\u8fde\u63a5\n\n    h_n[:,0,:] = forward_output[:,-1,:]\n    h_n[:,1,:] = backward_output[:,-1,:]\n\n    h_n = h_n.transpose(0,1)\n\n    return h_out,h_n\n    # return h_out,h_out[:,-1,:].reshape((bs,2,h_dim)).transpose(0,1)\n\n# \u9a8c\u8bc1\u4e00\u4e0b bidirectional_rnn_forward\u7684\u6b63\u786e\u6027\nbi_rnn = nn.RNN(input_size,hidden_size,batch_first=True,bidirectional=True)\nh_prev = torch.zeros((2,bs,hidden_size))\nbi_rnn_output,bi_state_finall = bi_rnn(input,h_prev)\n\nfor k,v in bi_rnn.named_parameters():\n    print(k,v)\n</code></pre> <p>\u8f93\u51fa</p> Text Only<pre><code>weight_ih_l0 Parameter containing:\ntensor([[ 0.5458,  0.5512],\n        [-0.5077, -0.0750],\n        [ 0.3572,  0.1419]], requires_grad=True)\nweight_hh_l0 Parameter containing:\ntensor([[-0.4093,  0.2012,  0.0746],\n        [-0.5619, -0.3820, -0.4060],\n        [-0.4412,  0.2706, -0.2816]], requires_grad=True)\nbias_ih_l0 Parameter containing:\ntensor([-0.5063, -0.1391, -0.0587], requires_grad=True)\nbias_hh_l0 Parameter containing:\ntensor([ 0.0343, -0.2352,  0.3234], requires_grad=True)\nweight_ih_l0_reverse Parameter containing:\ntensor([[ 0.1298,  0.5538],\n        [ 0.4151,  0.2533],\n        [-0.4401,  0.5322]], requires_grad=True)\nweight_hh_l0_reverse Parameter containing:\ntensor([[-0.4232,  0.2246,  0.4265],\n        [ 0.3016, -0.4142, -0.3064],\n        [-0.1960,  0.2845,  0.3770]], requires_grad=True)\nbias_ih_l0_reverse Parameter containing:\ntensor([-0.4372, -0.2452,  0.4506], requires_grad=True)\nbias_hh_l0_reverse Parameter containing:\ntensor([ 0.3957, -0.4655, -0.2143], requires_grad=True)\n</code></pre> Python<pre><code>custom_bi_rnn_output,custom_bi_state_finall = bidirectional_rnn_forward(input,\n                                                                        bi_rnn.weight_ih_l0,\n                                                                        bi_rnn.weight_hh_l0,\n                                                                        bi_rnn.bias_ih_l0,\n                                                                        bi_rnn.bias_hh_l0,\n                                                                        h_prev[0],\n                                                                        bi_rnn.weight_ih_l0_reverse,\n                                                                        bi_rnn.weight_hh_l0_reverse,\n                                                                        bi_rnn.bias_ih_l0_reverse,\n                                                                        bi_rnn.bias_hh_l0_reverse,\n                                                                        h_prev[1])\n</code></pre> Python<pre><code>print(\"Pytorch API output\")\nprint(bi_rnn_output)\nprint(bi_state_finall)\n\nprint(\"\\n custom bidirectional_rnn_forward function output:\")\nprint(custom_bi_rnn_output)\nprint(custom_bi_state_finall)\nprint(torch.allclose(bi_rnn_output,custom_bi_rnn_output))\nprint(torch.allclose(bi_state_finall,custom_bi_state_finall))\n</code></pre> Text Only<pre><code>True\nTrue\n</code></pre>"},{"location":"learning/14_LSTM/","title":"LSTM","text":""},{"location":"learning/14_LSTM/#lstm","title":"LSTM","text":"2024-12-21 22:57:342025-09-28 12:54:04 <p> \u7ea6 9218 \u4e2a\u5b57  349 \u884c\u4ee3\u7801  77 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 50 \u5206\u949f</p>"},{"location":"learning/14_LSTM/#rnncell","title":"RNNCELL","text":"<p>RNNCELL\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a \u5355\u6b65 \u7684\u8fed\u4ee3</p> <p>\u56e0\u4e3a\u6240\u6709\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc \u90fd\u662f\u6709\u5f88\u591a\u6b65\u53bb\u8fed\u4ee3\uff0c\u6700\u7ec8\u628a\u6bcf\u4e00\u6b65\u7684\u72b6\u6001 \u53d6\u51fa\u6765\u4f5c\u4e3a\u8f93\u51fa</p> <p>\u8fd9\u91cc\u7684RNNCELL\uff0c\u4e5f\u5c31\u662f\u8bf4 \u591a\u4e2a\uff0c\u6bcf\u4e2a\u65f6\u523b\u7684\u8ba1\u7b97 \u5c31\u662f\u4e00\u4e2aRNNCELL\uff0c\u7136\u540e\u628a \u591a\u4e2aRNNCELL \u8fde\u8d77\u6765 \uff0c\u5176\u5b9e\u5c31\u6784\u6210\u4e86 \u4e00\u4e2aRNN\uff0c\u6240\u4ee5 \u65e0\u8bba\u662fRNN\u4e5f\u597d\uff0c\u8fd8\u662f GRU\u4e5f\u597d\uff0c\u8fd8\u662f LSTM\u4e5f\u597d\uff0c\u5b83\u4eec \u90fd\u6709\u5404\u81ea\u7684CELL\uff0c\u7136\u540e\u6bcf\u4e2aCELL\uff0c\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a \u5355\u6b65\u7684\u8fd0\u7b97\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a \u5355\u4e2a\u65f6\u523b\u7684\u8fd0\u7b97\uff0c\u4e0b\u9762 \u6709\u4e00\u4e2a\u4f8b\u5b50</p> <p></p> <p>\u4ee3\u7801\u89e3\u91ca\uff1a</p> <ul> <li>\u9996\u5148\u5b9e\u4f8b\u5316 RNNCELL</li> <li>RNNCELL\u7684 <code>input size</code>\u548c<code>hidden size</code>\u5206\u522b\u4e3a10\u548c20</li> <li>\u5b9a\u4e49 <code>input</code> \u7684\u8bad\u7ec3\u7279\u5f81\uff0c<code>batch size</code>\u662f3\uff0c\u7136\u540e <code>\u65f6\u95f4\u957f\u5ea6</code>\u662f6\uff0c\u7136\u540e<code>\u7279\u5f81\u7ef4\u5ea6</code>\u662f10</li> <li>\u5b9a\u4e49\u521d\u59cb\u7684 <code>hidden state</code>[<code>hx</code>]</li> <li>\u7528RNNCELL\u505a\u6bcf\u4e00\u6b21\u8fed\u4ee3</li> </ul> <p>\u6240\u4ee5\u5b9a\u4e49\u4e00\u4e2a for\u5faa\u73af\uff0c\u7136\u540e \u6bcf\u4e00\u6b65\u8c03\u7528RNNCELL\u5b9e\u4f8b\u5316\u7684\u64cd\u4f5c\uff0c\u7b97\u51fa\u6bcf\u4e00\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001 <code>hx=rnn(input[i],hx)</code>  \uff0c\u5b9a\u4e49 \\(h_x\\)\u63a5\u6536\u8f93\u51fa\u7ed3\u679c</p> <ul> <li>RNNCELL \u5c31\u662f \u5355\u6b65 \u7684\u8ba1\u7b97\uff0c\u5305\u62ec GRUCELL \u548cLSTMCELL\uff0c\u90fd\u662f\u5355\u6b65\u7684</li> <li>RNN \u5c31\u662f\u628a\u591a\u4e2aRNNCELL \u8fde\u8d77\u6765 \uff0c\u6240\u4ee5\u662f\u591a\u6b65\u7684</li> </ul>"},{"location":"learning/14_LSTM/#lstm-api","title":"LSTM \u5b98\u65b9 api","text":"<p>LSTM \u539f\u7406\u53ef\u89c1\u535a\u5ba2\uff1a</p> <p></p>"},{"location":"learning/14_LSTM/#rnn","title":"&amp; RNN","text":"<ul> <li>LSTM\u6bd4RNN\u591a\u4e86\u51e0\u4e2a\u95e8</li> <li>RNN\u6bd4\u8f83\u7b80\u5355 \uff1a \u8f93\u5165 + \u9690\u542b\u72b6\u6001\uff0c\u53ea\u6709\u8fd9\u4e24\u4e2a\u72b6\u6001</li> </ul> <p>\u5728LSTM\u4e2d\uff0c\u591a\u4e86\u4e00\u4e9b\u95e8\uff1a</p> <p>\uff081\uff09\u8f93\u5165\u95e8</p> <p>\uff082\uff09\u8f93\u51fa\u95e8</p> <p>\uff083\uff09\u9057\u5fd8\u95e8</p> <p>\uff084\uff09\u8bb0\u5fc6\u5355\u5143</p>"},{"location":"learning/14_LSTM/#lstm_1","title":"LSTM \u56fe\u793a","text":"<p>\u56fe\u7247\u7406\u89e3\uff1a</p> <p>\u6700\u4e0a\u9762\u7684\u6a2a\u7ebf\uff0c\u957f\u5f97\u50cf\u4f20\u9001\u5e26\u7684\u4e1c\u897f\uff0c\u662f\u4e00\u4e2a\u7ec6\u80de\u5355\u5143\uff0c\u6216\u8005\u8bf4\u7ec6\u80de\u72b6\u6001</p> <p>\u6574\u4e2aLSTM\u5c31\u662f\u9760\u8fd9\u4e2a\u7ec6\u80de\u72b6\u6001\uff0c\u6765\u4e0d\u65ad\u7684 \u66f4\u65b0 \u5386\u53f2\u4fe1\u606f\u7684</p>"},{"location":"learning/14_LSTM/#lstm_2","title":"LSTM \u6709\u54ea\u4e9b\u95e8\uff1f","text":"<p>\u5bf9\u7167\u5b98\u65b9 api\uff1a</p> <p></p> <ol> <li><code>i</code>\u5c31\u662f \u8f93\u5165\u95e8</li> <li><code>f</code>\u5c31\u662f\u9057\u5fd8\u95e8</li> <li><code>g</code>\u5c31\u662f\u7ec6\u80de</li> <li><code>o</code>\u5c31\u662f\u8f93\u51fa\u95e8</li> <li><code>c</code>\u6210\u4e3a<code>cell</code>\uff0c\u53eb\u7ec6\u80de\u5355\u5143\uff0c\u6216\u8005\u53eb \u7ec6\u80de\u72b6\u6001</li> <li><code>h</code>\u5c31\u662f<code>LSTM</code>\u7684\u9690\u542b\u72b6\u6001\uff0c\u6216\u8005\u8bf4 \u8f93\u51fa\u3002\u56e0\u4e3a\u6a21\u578b\u6700\u7ec8\u8f93\u51fa\u7684\u662f \\(h_t\\)</li> </ol>"},{"location":"learning/14_LSTM/#api","title":"<code>api</code> \u5bf9\u5e94\u5230\u56fe\u3001\u6570\u5b66\u516c\u5f0f","text":"<p>\u56fe\u793a\uff1a</p> <p></p> <p>\u56fe\u793a &amp; \u7b26\u53f7\uff1a</p> <p></p> <p>\uff081\uff09\u9057\u5fd8\u95e8\uff1a\\(f_t \\odot c_{t-1}\\) </p> <p></p> <p><code>step1\uff1a</code>\u9057\u5fd8\u95e8\u7684\u8f93\u51fa(\u5f97\u5230\u7ecf\u8fc7\u9057\u5fd8\u95e8\u7684\u7b5b\u9009\u4fe1\u606f ) \\(f_t\\) </p> <p>\u9057\u5fd8\u95e8\u7684\u8f93\u51fa \\(f_t\\) \u600e\u4e48\u8ba1\u7b97\u7684\uff1f</p> <p>\\(x_t\\) \u8ddf\u5386\u53f2\u7684\u8f93\u51fa\u8fdb\u884c\u4ea4\u4e92\uff0c\u7136\u540e\u7ecf\u8fc7 \\(\\sigma\\)\u7ebf\u6027\u51fd\u6570\uff0c\u5f97\u5230 \\(f_t\\)</p> <p><code>step2\uff1a</code>\u9057\u5fd8\u95e8\u7684\u8f93\u51fa\u8ddf\u4e0a\u4e00\u65f6\u523b\u7684  \\(c_{t-1}\\) \u76f8\u4e58\uff0c\u5bf9\u5e94\u7684\u6570\u5b66\u516c\u5f0f\uff1a</p> \\[f_t \\odot c_{t-1}\\] <p>\uff082\uff09\u8f93\u5165\u95e8 \\(i_t\\) \u3001\u7ec6\u80de \\(g_t\\)</p> <p></p> <p>\u5982\u56fe\u6846\uff1a</p> <ol> <li>\u540c\u6837 \\(x_t\\)\u8ddf\u8fc7\u5f80\u7684 \\(x_{t-1}\\)\u8fdb\u884c\u4ea4\u4e92\uff0c\u7136\u540e\u7ecf\u8fc7\u4e00\u4e2a \\(\\sigma\\)\u51fd\u6570\uff0c\u5f97\u5230\u8f93\u5165\u95e8 \\(i_t\\)</li> <li>\u7136\u540e \\(x_t\\) \u8ddf\u4e0a\u4e00\u65f6\u523b\u7684 \\(x_{t-1}\\)\uff0c\u7ecf\u8fc7  \\(\\tanh\\)\u6fc0\u6d3b\u51fd\u6570 \uff0c\u5f97\u5230\u7684\u662f \\(g_t\\)\uff0c\u79f0\u4f5c\u7ec6\u80de</li> <li>\\(g_t\\) \u8ddf\u8f93\u5165\u95e8\u76f8\u4e58\uff0c\u76f8\u5f53\u4e8e\u5bf9\u5f53\u524d\u7684\u8f93\u5165\u4fe1\u606f\u8fdb\u884c\u7b5b\u9009</li> </ol> <p>\u516c\u5f0f\uff1a</p> \\[g_t \\odot i_t\\] <p>\uff083\uff09\u6700\u65b0\u7ec6\u80de\u72b6\u6001\u7684 \\(c_t\\) </p> <p>\u2460 \u628a\u4fe1\u606f\\(g_t \\odot i_t\\)\u52a0\u5230\u76ee\u524d\u6700\u65b0\u7684 \\(c_t\\) \u4e0a</p> <p>\u2461 \u6700\u65b0\u7684 \\(c_t\\)\u662f\u4e0a\u4e00\u65f6\u523b \\(c_t\\)\u4e58\u9057\u5fd8\u95e8\\(f_t\\)\uff0c\u5f97\u5230\u65b0\u7684 \\(c_t\\)</p> <p>\u4e5f\u5c31\u662f\u8bf4\u8be5\u4e22\u6389\u7684\u4fe1\u606f\u4e22\u6389\u4e86\u518d\u52a0\u4e0a\u8f93\u5165\u95e8 \uff0c\u66f4\u65b0\u7ec6\u80de\u72b6\u6001\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5bf9\u5e94\u7684\u516c\u5f0f\u8868\u793a\uff1a</p> \\[c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\\] <p>\uff084\uff09\u8f93\u51fa\u95e8 \\(\\ o_t\\)</p> <p></p> <p>\u6700\u540e\u4e00\u6839\u7ebf\u53eb\u505a \u8f93\u51fa\u95e8</p> <p>\u540c\u6837\u662f \\(x_t\\)\u8ddf\\(h_{t-1}\\)\uff0c\u8fdb\u884c\u4ea4\u4e92\uff0c\u7ecf\u8fc7sigmoid\u51fd\u6570\uff0c\u5f97\u5230\\(o_t\\)\uff0c\u5c31\u662f\u8f93\u51fa\u95e8\uff0c\u6700\u7ec8\u7684\u8f93\u51fa \uff1a \\(o_t \u00d7 \\tanh (c_t)\\)\uff0c\u6570\u5b66\u516c\u5f0f\u8868\u8fbe\uff1a</p> \\[h_t = o_t \\odot \\tanh(c_t)\\] <p></p> <p>\\(h_t\\) \u8ddf\u6bcf\u4e00\u65f6\u523b\u7684\u8f93\u5165\u8fdb\u884c\u4ea4\u4e92\u7684\uff0c\u4e5f\u5c31\u662f\u7ebf\u6027\u7ec4\u5408</p> <p>\\(c_t\\)\u4e0d\u65ad\u5bf9 \u5386\u53f2\u4fe1\u606f\u8fdb\u884c\u4e00\u4e2a \u66f4\u65b0</p> <p>\u901a\u8fc7\u9057\u5fd8\u95e8\u3001\u8f93\u5165\u95e8\uff0c\u4e0d\u65ad\u5bf9 \\(c_t\\)\u8fdb\u884c\u4e00\u4e2a \u66f4\u65b0</p> <p>\u4ee5\u4e0a\u662fLSTM\u7684\u516c\u5f0f \u548c \u7ed3\u6784\uff0c\u518d\u6765\u770b\u4e00\u904d\u6570\u5b66\u516c\u5f0f\uff1a</p> \\[i_t = \\sigma(W_{ii}x_t+b_{ii}+W_{hi}h_{t-1}+b_{hi})\\] \\[f_t = \\sigma(W_{if}x_t + b_{if}+W_{hf}h_{t-1}+b_{hf})\\] \\[g_t = \\tanh(W_{ig}x_t + b_{ig}+W_{hg}h_{t-1}+b_{hg})\\] \\[o_t = \\sigma(W_{io}x_t+b_{io}+W_{ho}h_{t-1}+b_{ho})\\] \\[c_t = f_t \\odot c_{t-1}+i_t \\odot g_t\\] \\[h_t = o_t \\odot \\tanh(c_t)\\] <p>\u8865\u5145\uff1a</p> <p>\uff081\uff09\u4f46\u4ece\u516c\u5f0f\u6765\u8bf4\uff0c\\(i\u3001f\u3001g\u3001o\\) \u9700\u8981\u7684\u5c31\u662f \\(x_t\\) \u548c \\(h_{t-1}\\)\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u548c\u5386\u53f2\u4fe1\u606f</p> <p>\uff082\uff09\u5bf9\u6bd4 RNN \u7684\u516c\u5f0f\uff1a</p> \\[h_t = \\tanh(x_tW_{ih}^T+b_{ih}+h_{t-1}W_{hh}^T+b_{hh})\\] <p></p> <p>\u5355\u4ece\u516c\u5f0f\u6765\u8bf4\uff0cRNN \u5386\u53f2\u4fe1\u606f\u7684\u4fdd\u5b58\u4ec5\u901a\u8fc7 \u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165 \\(x_t\\) \u548c \u4e0a\u4e00\u65f6\u523b\u7684\u5386\u53f2\u4fe1\u606f \\(h_{t-1}\\)</p> <p>\uff083\uff09\u518d\u653e\u4e00\u904d\u516c\u5f0f\uff0c\u4f53\u4f1a\uff1a</p> <p></p> <p>\uff084\uff09LSTM \u591a\u4e86\u4e00\u4e2a\u7ec6\u80de\u72b6\u6001\uff0c\u95ee\u9898\uff1a\u4e3a\u4ec0\u4e48 LSTM \u8981\u8bbe\u7f6e\u7ec6\u80de\u72b6\u6001\uff0c\u4e3a\u4ec0\u4e48\u8981\u8fd9\u4e48\u8bbe\u8ba1\u516c\u5f0f\u66f4\u65b0\u7ec6\u80de\u72b6\u6001\u548c\u9690\u85cf\u72b6\u6001\uff1f</p> <p>\uff085\uff09\u67e5\u9605\u8d44\u6599</p> <p>ref\uff1aLSTM</p> <p>0\u3001\u6838\u5fc3\u662f \u7ec6\u80de\u95e8\uff08\u5bf9\u6bd4 RNN \u8fd9\u4e2a\u662f\u6bd4\u8f83\u597d\u7406\u89e3\u7684\u3002\u53ef\u662f\u4e3a\u4ec0\u4e48\u8981\u6709\u7ec6\u80de\u95e8\u5462\uff1f\uff09</p> <p></p> <p>1\u3001\u5fd8\u8bb0\u4e00\u4e9b\u4fe1\u606f</p> <p>\u9057\u5fd8\u95e8\u7684\u4f5c\u7528\u662f \u51b3\u5b9a\u4e22\u5f03\u4ec0\u4e48\u4fe1\u606f</p> <p></p> <p>2\u3001\u65b0\u4e1c\u897f\u52a0\u5165 \u7ec6\u80de\u72b6\u6001</p> <p>\u8f93\u5165\u95e8 &amp; \u4e0d\u77e5\u9053\u600e\u4e48\u79f0\u547c\u5408\u9002\u7684\u4e1c\u897f\uff08\u5b66\u540d\uff1a\\(\\tilde{C}_t\\)\uff09</p> <p></p> <p>\\(\\sigma\\) \u51fd\u6570 \u548c \\(\\tanh\\) \u51fd\u6570\u6709\u4ec0\u4e48\u533a\u522b\uff1f\u4e3a\u4ec0\u4e48 \\(\\sigma\\)\u51fd\u6570\u5c31\u8d77\u4e86\u90a3\u6837\u7684\u4f5c\u7528\uff0c\\(\\tanh\\)\u51fd\u6570\u53c8\u8d77\u4e86\u8fd9\u6837\u7684\u4f5c\u7528\uff1f</p> <p>3\u3001</p> <p></p> <p>\uff086\uff09RNN\u3001LSTM\u3001GRU\u901a\u7528\u7f51\u7edc\u6846\u67b6</p> <p></p> <p>\uff087\uff09RNN &amp; LSTM \u7684\u5e94\u7528\u4f8b\u5b50\uff08\u5e2e\u52a9\u7406\u89e3\uff09\uff1a</p> <p>RNN \u5c31\u8db3\u591f\uff1a</p> <p></p> <p>LSTM \u624d\u53ef\u4ee5\uff08\u95f4\u9694\u592a\u5927\uff09\uff1a</p> <p></p> <p>\uff089\uff09LSTM \u7684\u7406\u89e3\uff1a</p> <p>\u8f93\u5165\uff1a\\(x_t\\) \u3001\\(h_{t-1}\\)\u3001\\(c_{t-1}\\)</p> <p>\u4e2d\u95f4\uff1a\\(i\u3001f\u3001g\u3001o\\)</p> <p>\u8f93\u51fa\uff1a\\(c_t\\)\u3001\\(h_t\\)</p> <p>\u4e00\u3001\u5fd8\u8bb0\u95e8 \\(f\\)</p> <ul> <li>\u8981\u4e22\u5f03\u4ec0\u4e48\u4fe1\u606f</li> </ul> <p>LSTM\u7684\u7b2c\u4e00\u6b65\u662f\u51b3\u5b9a\u6211\u4eec\u8981\u4ece\u7ec6\u80de\u72b6\u6001\u4e2d\u4e22\u5f03\u4ec0\u4e48\u4fe1\u606f\u3002</p> <p>\u600e\u4e48\u5b9e\u73b0\u7684\uff1f</p> <p>\u8be5\u51b3\u5b9a\u7531\u88ab\u79f0\u4e3a\"\u5fd8\u8bb0\u95e8\"\u7684\\(\\ Sigmoid\\)\u5c42\u5b9e\u73b0</p> <p>\u5177\u4f53\u600e\u4e48\u5b9e\u73b0\uff1f </p> <p>\u67e5\u770b<code>ht-1(\u524d\u4e00\u4e2a\u8f93\u51fa)</code>\u548c<code>xt(\u5f53\u524d\u8f93\u5165)</code>\uff0c\u5e76\u4e3a\u5355\u5143\u683c\u72b6\u6001<code>Ct-1(\u4e0a\u4e00\u4e2a\u72b6\u6001)</code>\u4e2d\u7684\u6bcf\u4e2a\u6570\u5b57\u8f93\u51fa<code>0</code>\u548c<code>1</code>\u4e4b\u95f4\u7684\u6570\u5b57\u3002</p> <p>\u4e3a\u4ec0\u4e48\u7528 sigmoid \u51fd\u6570\uff0c\u8f93\u51fa\u4ee3\u8868\u4ec0\u4e48\u610f\u601d\uff1f</p> <p><code>1</code>\u4ee3\u8868\u5b8c\u5168\u4fdd\u7559\uff0c\u800c<code>0</code>\u4ee3\u8868\u5f7b\u5e95\u5220\u9664\uff0c\u6240\u4ee5\u7528 <code>sigmoid \u51fd\u6570</code></p> <p>\u56fe\u793a</p> <p></p> <p>\u4e8c\u3001\\(i_t\\)\u3001\\(g_t\\)</p> <ul> <li>\u8981\u4fdd\u7559\u4ec0\u4e48\u4fe1\u606f\uff1f</li> </ul> <p>\u5c31\u662f\u51b3\u5b9a\u6211\u4eec\u8981\u5728\u7ec6\u80de\u72b6\u6001\u4e2d\u5b58\u50a8\u4ec0\u4e48\u4fe1\u606f</p> <p>\u8fd9\u90e8\u5206\u5206\u4e3a\u4e24\u6b65\uff1a</p> <p>1\u3001\u9996\u5148\uff0c\u79f0\u4e3a\"\u8f93\u5165\u95e8\u5c42\"\u7684Sigmoid\u5c42\u51b3\u5b9a\u4e86\u5c06\u66f4\u65b0\u54ea\u4e9b\u503c</p> <p>2\u3001\u63a5\u4e0b\u6765\u4e00\u4e2atanh\u5c42\u521b\u5efa\u5019\u9009\u5411\u91cfCt\uff0c\u8be5\u5411\u91cf\u5c06\u4f1a\u88ab\u52a0\u5230\u7ec6\u80de\u7684\u72b6\u6001\u4e2d</p> <p>\u5728\u4e0b\u4e00\u6b65\u4e2d\uff0c\u6211\u4eec\u5c06\u7ed3\u5408\u8fd9\u4e24\u4e2a\u5411\u91cf\u6765\u521b\u5efa\u66f4\u65b0\u503c\u3002</p> <p></p> <p>\u56fe\u793a\uff1a</p> <p></p> <p>\u8fd9\u91cc\u7684 \\(\\tilde{C}_t\\) \u548c \\(g_t\\)  \u662f\u4e00\u4e2a\u4e1c\u897f\uff0c\u5b66\u540d\uff1a\u5019\u9009\u5411\u91cf</p> <p>\u95ee\u9898\uff1a\\(\\tanh\\) \u8f93\u51fa\u7684\u542b\u4e49\u662f\u4ec0\u4e48\uff1f</p> <p>\u7c7b\u4f3c sigmoid \u7684\u8f93\u51fa <code>0 \u8868\u793a\u9057\u5fd8\uff0c1 \u8868\u793a\u8bb0\u4f4f</code></p> <p>\u4e09\u3001\u66f4\u65b0\u7ec6\u80de\u72b6\u6001\u5f97\u5230 \\(c_t\\)</p> <p>\u66f4\u65b0\u4e0a\u4e00\u4e2a\u72b6\u6001\u503c\\(C_{t\u22121}\\)\u4e86\uff0c\u5c06\u5176\u66f4\u65b0\u4e3a\\(C_t\\)</p> <p>\u5c06\u4e0a\u4e00\u4e2a\u72b6\u6001\u503c\u4e58\u4ee5\\(f_t\\)\uff0c\u4ee5\u6b64\u8868\u8fbe\u671f\u5f85\u5fd8\u8bb0\u7684\u90e8\u5206 $ \\iff f_t \\odot c_{t-1}$</p> <p>\u4e4b\u540e\u5c06\u5f97\u5230\u7684\u503c\u52a0\u4e0a \\(i_t\u2217\\tilde{C}_t\\) \\(\\iff + i_t \\odot \\tilde{C}_t\\)</p> <p>\u8fd9\u4e2a\u5f97\u5230\u7684\u662f\u65b0\u7684\u5019\u9009\u503c \\(C_t\\)\uff0c \u6309\u7167\u6211\u4eec\u51b3\u5b9a\u66f4\u65b0\u6bcf\u4e2a\u72b6\u6001\u503c\u7684\u591a\u5c11\u6765\u8861\u91cf\uff0c\u6700\u7ec8\u7684\u516c\u5f0f\uff1a</p> \\[c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\] <p>\u4ee5\u4e0a\u5f97\u5230\u4e86 \u7b2c\u4e00\u4e2a \u8f93\u51fa \\(c_t\\)\uff0c\u73b0\u5728\u5f00\u59cb\u7b2c\u4e8c\u4e2a\u8f93\u51fa \\(h_t\\)</p> <p>\u56db\u3001\u8f93\u51fa\u4ec0\u4e48</p> <p>\u6700\u540e\u9700\u8981\u51b3\u5b9a\u8981\u8f93\u51fa\u4ec0\u4e48</p> <p>\u6b64\u8f93\u51fa\u5c06\u57fa\u4e8e\u7ec6\u80de\u72b6\u6001\uff0c\u4f46 \u662f\u4e00\u4e2a\u8fc7\u6ee4\u7248\u672c\u3002  \\(tanh(C_t)\\)</p> <ul> <li>\u9996\u5148\uff0c\u7ecf\u8fc7\u4e00\u4e2asigmoid\u5c42\uff0c\u51b3\u5b9a\u4e86\u8981\u8f93\u51fa\u7684\u7ec6\u80de\u72b6\u6001\u7684\u54ea\u4e9b\u90e8\u5206  \\(o_t = \\sigma(f(h_{t-1},x_t))\\)</li> <li>\u7136\u540e\uff0c\u5c06\u5355\u5143\u683c\u72b6\u6001\u901a\u8fc7tanh\uff08\u5c06\u503c\u89c4\u8303\u5316\u5230-1\u548c1\u4e4b\u95f4\uff09\uff0c\u5e76\u5c06\u5176\u4e58\u4ee5Sigmoid\u95e8\u7684\u8f93\u51fa   \\(h_t = o_t \\odot \\tanh(c_t)\\)</li> </ul> <p>\u81f3\u6b64\u5c31\u8f93\u51fa\u4e86\u51b3\u5b9a\u7684\u90a3\u4e9b\u90e8\u5206</p> <p></p> <p>\u628a\u516c\u5f0f\u7cbe\u7b80\u4e00\u4e0b\uff1a</p> <p></p> <p>\u8f93\u5165\uff1a\\(x_t\\)\u3001\\(h_{t-1}\\)</p> <p>\u64cd\u4f5c\uff1a(\u8fd9\u91cc\u7684\u7b26\u53f7\u662f\u53c2\u7167\u5b98\u7f51 api \u7684)</p> <p>\\(f_t = \\sigma(f(x_t,h_{t-1})) \\iff \\sigma(W_f[x_t,h_{t-1}]+b_f)\\)</p> <p>\\(i_t = \\sigma(f(x_t,h_{t-1})) \\iff \\sigma(W_i[x_t,h_{t-1}]+b_i)\\)</p> <p>\\(g_t = \\sigma(f(x_t,h_{t-1})) \\iff \\sigma(W_g[x_t,h_{t-1}]+b_g)\\)</p> <p>\\(o_t = \\sigma(f(x_t,h_{t-1})) \\iff \\sigma(W_o[x_t,h_{t-1}]+b_o)\\)</p> <p>\\(f\\) \u4ee3\u8868\u4eff\u5c04\u53d8\u6362 \\(Wx+b\\)</p> <p>\u8f93\u51fa\uff1a\\(c_t\u3001h_t\\)\uff08\u8fd9\u4e2a\u56fe\u793a\uff0c\u753b\u5f97\u592a\u7ec6\uff0c\u53cd\u800c\u6655\u4e4e\uff09</p> <p>\\(c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\\)</p> <p>\u7406\u89e3\uff1a</p> <p>1\u3001\\(f_t\\) \u6307\u793a \u8981\u5fd8\u8bb0\u7684\u5386\u53f2\u4fe1\u606f\uff08\u767d\u8bdd\uff1a\\(\u66f4\u65b0\u5386\u53f2\u4fe1\u606f\\)\uff0c\u8be5\u8bb0\u4f4f\u7684\u8bb0\u4f4f\uff0c\u8be5\u5fd8\u8bb0\u7684\u5fd8\u8bb0\uff0c\u5fd8\u8bb0\u591a\u5c11\u4e5f\u8868\u8fbe\u4e86\u8bb0\u4f4f\u591a\u5c11\uff0c\u9700\u8981\u770b\u53c2\u7167\uff09</p> <p>2\u3001\\(i_t\\) \u4fdd\u7559\u591a\u5c11\u8f93\u5165\u4fe1\u606f\uff0c\u4e3a\u8f93\u5165\u4fe1\u606f\u52a0\u6743\uff1b</p> <p>\\(g_t\\) \u8868\u793a\u8f93\u5165\u4fe1\u606f\uff0c\u6700\u540e\u5f97\u5230\u7684\u662f\u8981\u8bb0\u4f4f\u591a\u5c11\u8f93\u5165\u4fe1\u606f</p> <p>3\u3001\u6700\u540e\u540c\u65f6\u5b58\u5230 \\(c_t\\) \u4e2d</p> <p>\\(h_t = \\tanh({c_t}) \\odot o_t\\)</p> <p>\u7406\u89e3\uff1a</p> <p>\u6700\u540e\uff0c\u9700\u8981\u51b3\u5b9a\u8f93\u51fa\u4ec0\u4e48</p> <p>\u8f93\u51fa\u57fa\u4e8e\u7ec6\u80de\u72b6\u6001\uff0c\u662f\u8fc7\u6ee4\u7248\u672c</p> <p>step1\uff1a\u9996\u5148\uff0c\u901a\u8fc7sigmoid\u5c42\uff0c\u51b3\u5b9a\u8981\u8f93\u51fa\u7684\u7ec6\u80de\u72b6\u6001\u7684\u54ea\u4e9b\u90e8\u5206</p> <p>step2\uff1a\u7136\u540e\uff0c\u5c06\u5355\u5143\u683c\u72b6\u6001\u901a\u8fc7tanh\uff08\u5c06\u503c\u89c4\u8303\u5316\u5230-1\u548c1\u4e4b\u95f4\uff09</p> <p>step3\uff1a\u5e76\u5c06\u5176\u4e58\u4ee5Sigmoid\u95e8\u7684\u8f93\u51fa\uff0c\u81f3\u6b64\u8f93\u51fa\u51b3\u5b9a\u7684\u90a3\u4e9b\u90e8\u5206</p> <p>\u4ee5\u4e0a\u662f\u5173\u4e8e LSTM \u5185\u90e8\u7684\u8ba1\u7b97\u7406\u89e3</p>"},{"location":"learning/14_LSTM/#torchnnlstm","title":"torch.nn.LSTM","text":"<p>\u4e0e RNN \u5bf9\u6bd4\uff1a</p> <p>\u5728\u53c2\u6570\u76f8\u540c\u7684\u6761\u4ef6\u4e0b\uff0cLSTM\u7684\u5e8f\u5217\u5efa\u6a21\u80fd\u529b\u662f\u5f3a\u4e8eRNN\u7684\uff0c\u6240\u4ee5\u6bd4\u8f83\u5927\u7684\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u90fd\u662f\u7528 LSTM\u505a</p> <p>pytorch \u7684\u5b98\u65b9 api\uff1a<code>torch.nn.LSTM</code></p> <p></p> <ul> <li>\u8fd9\u662f\u4e00\u4e2aclass\uff0c\u662f\u4e00\u4e2a\u7c7b</li> <li>\u8981\u7528\u7684\u8bdd</li> </ul> <p>\uff081\uff09\u9996\u5148\u8fdb\u884c\u5b9e\u4f8b\u5316\uff0c\u5f97\u5230\u4e00\u4e2a\u7b97\u5b50</p> <p>\uff082\uff09\u5582\u5165\u8f93\u5165\u5e8f\u5217\uff0c\u8f93\u5165\u5e8f\u5217\u7ecf\u8fc7LSTM\u7f51\u7edc\uff0c\u5f97\u5230\u7684 \u6bcf\u4e2a\u8f93\u5165\u72b6\u6001\u7684\u8f93\u51fa\uff0c\u6700\u540e\u5c06\u5f97\u5230\u72b6\u6001\u7684\u8f93\u51fa\uff1a \\(h_t\\)</p> <p>\uff083\uff09\u6bcf\u4e00\u65f6\u523b\u7684 \\(h_t\\) \u7ec4\u5408\u8d77\u6765\u7684\u8f93\u51fa\u5e8f\u5217</p> <p>\u660e\u786e LSTM \u7684\u516c\u5f0f\uff1a</p> <p>\u9996\u5148\uff0c<code>LSTM\u6838\u5fc3\uff1a\u7ec6\u80de\u72b6\u6001</code></p> <p>\u4e00\u5171\u6d89\u53ca\u7684\u4e1c\u897f\uff1a\\(f\u3001i\u3001g\u3001o\u3001h\u3001c\\)</p> <p>\u8f93\u5165\uff1a\\(x_t\u3001h_{t-1}\\)</p> <p>\u516c\u5f0f\uff1a</p> <p></p> <p>\\(f_t=\\sigma(w_f[x_t,h_{t-1}]+b_f)\\) </p> <p>\\(i_t = \\sigma(w_i[x_t,h_{t-1}]+b_i)\\)</p> <p>\\(g_t = \\tanh(w_g[x_t,h_{t-1}]+b_g)\\)</p> <p>$o_t = \\sigma(w_o[x_t,h_{t-1}]+b_o) $</p> <p>\\(c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\\)</p> <p>\\(h_t = o_t \\odot \\tanh(c_t)\\)</p> <p>\u56db\u4e2a\u95e8\uff0c\u5206\u522b\u662f\\(i\u3001f\u3001g\u3001o\\)</p> <p>\u8fd9\u91cc\u6709\u56db\u4e2a\u95e8\uff1a</p> <p>\uff081\uff09\u5176\u4e2d\u6709\u4e09\u4e2a\u95e8\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u90fd\u662f <code>sigmoid</code></p> <p>\uff082\uff09\\(g_t\\)\u7684\u6fc0\u6d3b\u51fd\u6570\u662f tanh\u51fd\u6570</p> <p>\u5176\u5b9e\u8fd9\u56db\u4e2a\u95e8\u7684\u8fd0\u7b97\u6709\u5f88\u5927\u7684\u76f8\u4f3c\u6027</p> <p>\u6709 \u56db\u4e2a \\(W\\)</p> <p>\u5e76\u4e14\u56db\u4e2a\\(W\\)\u90fd\u662f\u8ddf\\(x_t\\)\u8fdb\u884c\u4e00\u4e2a\u77e9\u9635\u76f8\u4e58</p> <p>\u540c\u6837\u7684 \\(W_{hi} \u3001W_{hf}\\)\u53f3\u8fb9\u7684\u56db\u4e2a\\(W\\)\uff0c\u4e5f\u662f\u8ddf \\(h_{t-1}\\)\uff0c\u8fdb\u884c\u77e9\u9635\u76f8\u4e58</p> <p>\u6240\u4ee5\u867d\u7136\u770b\u4e0a\u53bb\u67094\u4e2a\\(W_i\\)\uff0c\u4f46\u662f\u53ef\u4ee5\u628a \u8fd9\u4e2a \u56db\u4e2a \\(W_i\\)\u53e0\u8d77\u6765</p> <p>\u6bd4\u65b9\u8bf4 \u6bcf\u4e2a\\(W_i\\)\u662f\\(2\\)\u884c\uff0c\u90a3\u4e48\\(4\\)\u4e2a\\(W_i\\)\uff0c\u5c31\u53ef\u4ee5 \u53e0\u6210\\(8\\)\u884c</p> <p></p> <p>\u7136\u540e\u518d\u8ddf \\(x_t\\) \u8fdb\u884c\u4e00\u4e2a\u76f8\u4e58\uff0c\u5c31\u662f\u628a \u8fd9\u4e2a \\(\u56db\u4e2a W\u4e58\u4ee5x\\)</p> <p>\\(W\u00d7x\\) \u7ec4\u5408\u8d77\u6765\uff0c\u4e00\u8d77\u7b97</p> <p>\u540c\u6837\u8fd9\u91cc\u7684\\(W\u4e58\u4ee5h(W\u00d7h)\\)\u4e5f\u662f\u4e00\u6837\u7684</p> <p>\u7531\u4e8e\u90fd\u662f \u4e58\u4ee5 \u540c\u4e00\u4e2a\\(h\\)</p> <p>\u540c\u6837\u628a \u56db\u4e2a \\(W\\)\u5806\u53e0\u8d77\u6765\uff0c\\(stack\\)\u5806\u53e0\u6765\uff0c\u7b97\u5b8c\u4e86 \u518d\\(split\\)</p> <p></p> <p>\u5982\u56fe\uff0c\u8fd8\u6709\\(4\\)\u4e2a\\(b_i\\)\u548c\\(b_h\\)\uff0c\u8f93\u5165 \\(linear\\)\u7684\u504f\u7f6e \u548c\u4e0a\u4e00\u65f6\u523b \u9690\u542b\u72b6\u6001\u7ebf\u6027\u5c42\u7684\u504f\u7f6e</p> <p>\u540c\u6837\u8fd9\u91cc \\(4\\)\u4e2a\u504f\u7f6e\uff0c\\(4\\)\u4e2a\\(b_i\\) \u5c31\u662f\u76f4\u63a5\u52a0\uff0c\u4e0d\u9700\u8981\u8054\u5408\u7b97</p> <p>\u540c\u6837\u8fd9\u91cc\u7684\\(b_h\\)\uff0c\u4e5f\u662f\\(4\\)\u4e2a\u504f\u7f6e</p> <p>\u7ef4\u5ea6\u90fd\u662f\u8ddf\\(i_t\u3001 f_t\\) \u7ef4\u5ea6\u662f\u4e00\u6837\u7684\uff0c\u5f97\u5230\u7684 \\(i\u3001f\u3001g\u3001o\\)\u4ee5\u540e\uff0c\u5c31\u53ef\u4ee5\u7b97\u51fa\u5f53\u524d\u65f6\u523b\u7ec6\u80de\u7684\u72b6\u6001 \\(c_t\\)</p> <p></p> <p>About \\(c_t\\) \uff1a</p> <p>\uff081\uff09\\(c_t= f_t\u00d7c_{t-1}\\)\uff0c\u4e2d\u95f4\u7684\u4e58\u662f\u9010\u5143\u7d20\u7684\u4e58\uff0c\u4e0d\u662f\u77e9\u9635\u4e58\u6cd5</p> <p>\uff082\uff09\u9ed8\u8ba4\\(f_t\\)\u8ddf\\(c_{t-1}\\)\u7ef4\u5ea6\u662f\u4e00\u6837\u7684\uff0c\u540c\u4e00\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u4e24\u4e24\u76f8\u4e58</p> <p>\uff083\uff09\u540c\u6837 \\(i_t\\)\u548c\\(g_t\\)\u4e5f\u662f\u4e00\u6837\uff0c\u540c\u4e00\u4f4d\u7f6e\u7684\u4e24\u4e24\u5143\u7d20 \u76f8\u4e58</p> <p>\uff084\uff09\u4e58\u5b8c\u4ee5\u540e\u5143\u7d20\u518d\u52a0\u8d77\u6765\uff0c\u5f97\u5230\\(c_t\\)</p> <p>\\(c_t\\) \u662f\u5f53\u524d\u65f6\u523b\u7684\u7ec6\u80de\u72b6\u6001\uff0c\u5c31\u662f\u4e0a\u9762\u7684\u9ed1\u7ebf\uff0c\u8fd9\u9ed1\u7ebf\u662f LSTM \u7684\u521b\u65b0</p> \uff08\u4f5c\u8005\u548b\u60f3\u7684\uff0c\u8981\u52a0\u6761\u9ed1\u7ebf\uff0c\u8fd8\u6709\u8fd9\u4e9b\u95e8\u7684\u8bbe\u8ba1\uff0cwhy\uff1f\uff09 <p></p> <p>\u6574\u4e2aLSTM\u5c31\u662f\u9760\u9ed1\u7ebf\uff0c\u6765\u4e0d\u65ad\u5bf9\u5386\u53f2\u4fe1\u606f \u8fdb\u884c\u7b5b\u9009\u548c\u66f4\u65b0\uff0c\u5f97\u5230\\(c_t\\)\u4ee5\u540e\uff0c\u6700\u7ec8 \u5f97\u5230 \\(h_t\\)</p> <p>$c_t=f_t \\odot c_{t-1} + i_t \\odot g_t $</p> <p>\\(h_t = o_t \\odot \\tanh{c_t}\\)</p> <p>\\(c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\\)</p> <p>\\(= \\sigma{(W_f{[x_t,h_{t-1}]}+b_f)} \\odot c_{t-1} + \\sigma(W_i[x_t,h_{t-1}]+b_i) \\odot \\tanh(W_g[x_t,h_{t-1}]+b_g)\\)</p> <p>\\(h_t = o_t \\odot \\tanh{c_t}\\)</p> <p>\\(h_t = \\sigma (W_o[x_t,h_{t-1}]+b_o) \\odot \\tanh{c_t}\\)</p> <p>\u5bf9\u6bd4RNN \u7684\u516c\u5f0f\uff1a</p> <p>\\(h_t = \\tanh(W_h[x_t,h_{t-1}]+b_h)\\)</p> <p>\\(=\\tanh(x_tW_{ih}^T+b_{ih}+h_{t-1}W_{hh}^T+b_{hh})\\)</p> <p>\\(c_t\\) \u4e5f\u662f\u4e3a\u4e86\u6700\u7ec8 \\(h_t\\) \u7684\u8f93\u51fa</p> <p>\u6574\u4e2aLSTM\u7684\u8f93\u51fa\u5c31\u662f \\(h_t\\)</p> <p>ht\uff1a\u7531\\(\u8f93\u51fa\u95e8\u00d7\u7ec6\u80de\u72b6\u6001 (\u7ecf\u8fc7 \u6fc0\u6d3b\u51fd\u6570 \\tanh\u51fd\u6570)\\)\uff0c\u6240\u5f97\u5230\u7684\u503c\uff0c\u5c31\u662f\\(h_t\\)\uff0c\\(h_t\\)\u5c31\u662fLSTM\u7684\u8f93\u51fa</p> <p>\u521d\u59cb\u72b6\u6001</p> <p>\uff081\uff09LSTM\u4e2d\u7684\u521d\u59cb\u72b6\u6001\u6709 2 \u4e2a</p> <p>RNN\u6709\u521d\u59cb\u72b6\u6001\uff0c\u540c\u6837\u5728LSTM\u7f51\u7edc\u4e2d\uff0c\u4e5f\u6709\u521d\u59cb\u72b6\u6001\uff0c\u4f46\u662fLSTM \u4e2d\u7684\u521d\u59cb\u72b6\u6001\uff0c\u6709\u4e24\u4e2a\u3002</p> <p>\uff082\uff09\u9700\u8981\u63d0\u4f9b\u4ec0\u4e48\u521d\u59cb\u72b6\u6001\uff1f </p> <p>\u4ece\u516c\u5f0f\u91cc\u627e\u521d\u59cb\u72b6\u6001\uff0c\u54ea\u4e9b\u7b26\u53f7\u4ee5 \\(t-1\\)\u4e3a\u4e0b\u6807\u7684\uff0c\u53ea\u8981\u4ee5\\(t-1\\)\u4e3a\u4e0b\u6807\u7684\u5c31\u662f\u8bf4\u9700\u8981\u63d0\u4f9b\u521d\u59cb\u72b6\u6001\uff0c\u4e5f\u5c31\u662f\u8bf4\u9700\u8981\u63d0\u4f9b\u8fd9\u4e9b\u91cf\u7684\u521d\u59cb\u503c</p> <p>\u4ece\\(t\\)\u4ece\\(1\\)\u5f00\u59cb\uff0c\u5e26\\(t-1\\)\u4e0b\u6807\u7684\uff0c\u9700\u8981\u63d0\u4f9b\\(t_0\\)\uff0c\u6240\u4ee5\u4e00\u5b9a\u6709\u521d\u59cb\u72b6\u6001</p> <p>\u4ece\u516c\u5f0f\u6765\u770b \u4e00\u5171\u6709\u4e24\u4e2a\u5e26 \\(t-1\\) \u4e0b\u6807\u7684</p> <p>\\(f_t,i_t,o_t = \\sigma(W[x_t,h_{t-1}]+b)\\)</p> <p>\\(g_t = \\tanh(W[x_t,h_{t-1}]+b)\\)</p> <p>\\(c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\\)</p> <p>\\(h_t = o_t \\odot \\tanh{c_t}\\)</p> <p>\u5206\u522b\u662f\\(h_{t-1}\\)\uff0c\\(c_{t-1}\\)</p> <p>\u4e5f\u5c31\u662f\u8bf4 \u5728\\(t=1\\)\u65f6\u523b\u7684\u65f6\u5019\uff0c\u9700\u8981\u63d0\u4f9b\\(h_0\\)\u3001\\(c_0\\)\uff0c\u6765\u7b97\u51fa\\(t=1\\)\u65f6\u523b\u7684\\(h_1\\)\u548c\\(c_1\\)</p> <p>LSTM\u7f51\u7edc\uff0c\u76f8\u6bd4\u4e8e\u7b80\u5355\u7684RNN\u7f51\u7edc\uff0c\u521d\u59cb\u72b6\u6001\u5c31\u591a\u4e86 \\(c_0\\)</p> <p>ReCall RNN</p> <p></p> <p>(1) RNN\u7684\u516c\u5f0f\u66f4\u7b80\u5355\uff0c\\(h_t\\)\u662f\\(x_t\\)\u8ddf\\(h_{t-1}\\)\u7684\u7ebf\u6027\u7ec4\u5408</p> <p>\\(h_t = \\tanh{(W_h[x_t,h_{t-1}]+b_h)}\\)</p> <p>(2)RNN\u9700\u8981\u7684\u521d\u59cb\u72b6\u6001\u53ea\u6709 \\(h_0\\) </p> <p>\u4eceRNN\u7684\u516c\u5f0f\u4e2d\u53ef\u4ee5\u770b\u51fa\u6765\uff0c\u53ea\u6709\u4e00\u4e2a\u7b26\u53f7\uff0c\u5c31\u662f\\(h\\)\u4e0b\u6807\u662f\\(t-1\\)\uff0c\u4e5f\u5c31\u662f\u8bf4 \u53bb\u7b97RNN\u7684\u7f51\u7edc\u7684\u65f6\u5019\uff0c\u9700\u8981\u63d0\u4f9b \\(h_0\\)\u4f5c\u4e3a\u521d\u59cb\u72b6\u6001\uff0c\u56e0\u4e3a\u5982\u679c\u8981\u7b97\\(h_1\\)\u7684\u8bdd\uff0c\u6211\u4eec\u5fc5\u987b\u8981\u6709\\(h_0\\)\uff0c\u6240\u4ee5\u5fc5\u987b\u8981\u63d0\u4f9b\\(h_0\\)\uff0c\u5f53\u7136\u6846\u67b6\u5df2\u7ecf\u9ed8\u8ba4\u63d0\u4f9b\u4e86\\(h_0\\)\u7b49\u4e8e\u4e00\u4e2a\u51680\u7684\u5411\u91cf</p> <p>VS LSTM</p> <p></p> <p>\\(i_t,f_t,o_t = \\sigma(W[x_t,h_{t-1}]+b)\\)</p> <p>\\(g_t = \\tanh(W[x_t,h_{t-1}]+b)\\)</p> <p>\\(c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\\)</p> <p>\\(h_t = o_t \\odot \\tanh{c_t}\\)</p> <ul> <li>\u5728LSTM\u4e2d\uff0c\u6839\u636e\u516c\u5f0f\u53ef\u4ee5\u770b\u5230\u5fc5\u987b\u8981\u63d0\u4f9b\\(h_0\\)\u548c\\(c_0\\)</li> <li>LSTM\u76f8\u6bd4\u4e8eRNN\u53c8\u591a\u4e86\u4e00\u4e2a\u521d\u59cb\u72b6\u6001\uff0c\u4e0d\u4ec5\u6709\\(h_0\\)\uff0c\u8fd8\u6709\\(c_0\\)</li> <li>\u5728\u6846\u67b6\u4e2d\uff0c\u540c\u6837\u63d0\u4f9b\u4e86 \u9ed8\u8ba4\u7684\u503c\uff1a\u51680</li> </ul> <p>\u8865\u5145\uff1a</p> <p>\u6211\u4eec\u4e5f\u53ef\u4ee5\u4e0d\u7528\u5168\\(0\\) \u7684\u9ed8\u8ba4\u503c\uff0c\u4e5f\u53ef\u4ee5\u7528\u5176\u4ed6\u7684\u503c\uff0c\u81ea\u5df1\u6784\u9020\\(h_0\\)\u548c\\(c_0\\)</p> <p>\u6b64\u65f6\uff0c\\(h_0\\)\u548c\\(c_0\\)\uff0c\u53ef\u80fd\u662f\u4ece\u67d0\u4e00\u4e2a\u8f93\u5165\u6620\u5c04\u6765\u7684\uff0c\u8fd9\u79cd\u521d\u59cb\u5316\u65b9\u6cd5\u4e5f\u53eb<code>Meta learning</code>\uff0c\u5373\u6211\u4eec\u7684\u521d\u59cb\u503c \u90fd\u662f\u9760\u5b66\u6765\u7684</p> <p>\u53ef\u4ee5\u8ba9\u521d\u59cb\u72b6\u6001\uff0c\u4e0d\u662f\u5b8c\u5168\u968f\u673a\u7684\uff0c\u53ef\u4ee5\u8bbe\u7f6e\u4e3a\u4e0e\u8f93\u5165\u6709\u5173\uff0c\u6216\u8005\u8ddf condition\u6709\u5173 </p> <p>LSTM \u521d\u59cb\u5316\u9700\u8981\u7684\u53c2\u6570</p> <p></p> <p>\u9700\u8981\u5b9e\u4f8b\u5316LSTM\u7684\u53c2\u6570\uff1a</p> <ul> <li><code>input_size</code>\uff1a\u8f93\u5165\u5e8f\u5217\u7279\u5f81\u7684\u5927\u5c0f</li> <li><code>hidden_size</code> \uff1a  \u2460 LSTM\u7f51\u7edc \\(h\\)\u7684\u5927\u5c0f \u2461 <code>hidden_size</code> \u4e5f\u662f\\(c\\)\u7684\u5927\u5c0f</li> <li><code>num_layers</code> \uff1a\u5c42\u6570\uff0c\u6784\u5efa\u591a\u5c42\u7684LSTM\uff0c\u591a\u5c42\u5806\u53e0\u8d77\u6765\uff0c\u524d\u4e00\u5c42\u7684\u8f93\u51fa\\(h_t\\)\uff0c\u662f\u4f5c\u4e3a\u4e0b\u4e00\u5c42LSTM\u7684\u8f93\u5165\\(x_t\\)</li> <li><code>bias</code>\uff1a\u51b3\u5b9a\u4e86\\(b_i\\)\u548c\\(b_h\\)\u662f\u5426\u53ef\u4ee5\u4e22\u5f03</li> <li><code>batch_first</code>\uff1a\u2460 \u5728pytorch\u4e2d\uff0c\u9ed8\u8ba4\u7684\u662f<code>batch</code>\u662f\u653e\u5728\u4e2d\u95f4\u4e00\u7ef4\u7684  \u2461 \u53ef\u4ee5\u628a<code>batch_firs</code>t\u8bbe\u7f6e\u6210<code>true</code>\uff0c\u6b64\u65f6 <code>batch</code> \u5c31\u5728 \u7b2c\u4e00\u7ef4</li> <li><code>dropout</code> \u4ee5\u53ca \u53cc\u5411  <code>bidirectional</code> </li> </ul> <p>\u2460 \u5982\u679c\u8981\u6784\u5efa\u53cc\u5411\u7684\u8bdd\uff0c\u6709<code>forward layer</code>\u548c<code>backward layer</code></p> <p>\u2461 \u6700\u540e\u7684\u72b6\u6001\u662f\u7531<code>forward layer</code>\u548c<code>backward layer</code>\u62fc\u63a5\u8d77\u6765\u7684\u72b6\u6001</p> <ul> <li><code>proj_size</code>  \uff1a\u6700\u540e\u4e00\u4e2a\u53c2\u6570\uff0c\u8fd9\u4e2a\u53c2\u6570\u76f8\u5f53\u4e8eLSTM\u7f51\u7edc\u7684\u53d8\u4f53\uff1aLSTMP</li> </ul>"},{"location":"learning/14_LSTM/#lstmlstmp","title":"LSTM\u548cLSTMP\u7684\u539f\u7406\u4e0e\u6e90\u7801\u5b9e\u73b0","text":"<p>LSTM &amp; LSTMP</p> <p>\u4f5c\u7528\uff1a\u4e3a\u4e86\u51cf\u5c0fLSTM\u7684\u53c2\u6570\u548c\u8ba1\u7b97\u91cf</p> <p>\u56e0\u4e3aLSTM\u7684\u8ba1\u7b97\u91cf\u662f\u6bd4\u8f83\u5927\u7684\uff0cLSTMP\u901a\u8fc7\u5bf9\\(h_t\\)\u8fdb\u884c\u538b\u7f29\uff0c\\(h_t\\)\u7684\u7ef4\u5ea6\u4f1a\u53d8\u5c0f\uff0c\u6574\u4e2a\u7f51\u7edc\u7684\u53c2\u6570\u91cf\u548c\u8fd0\u7b97\u91cf \u90fd\u4f1a\u53d8\u5c0f\uff0c\u6709\u8bba\u6587\u8868\u660e\u901a\u8fc7\u5bf9 \\(h_t\\) \u8fdb\u884c\u538b\u7f29\uff0c\u6027\u80fd\u635f\u5931\u4e0d\u662f\u5f88\u5927\uff0c\u6240\u4ee5\u5728\u5177\u4f53\u5730\u5b9e\u9a8c\u4e2d\uff0c\u53ef\u4ee5\u5c1d\u8bd5LSTMP</p> <ul> <li> \u5b9e\u4f8b\u5316 LSTM \u9700\u8981\u4f20\u5165\u7684\u53c2\u6570 \\(\\uparrow\\)</li> <li> LSTM input parameters \\(\\downarrow\\)</li> <li> LSTM output \\(\\downarrow\\) </li> </ul> <p>LSTM input parameters </p> <p></p> <p>1\ufe0f\u20e3 <code>input</code></p> <p>\u683c\u5f0f\uff1a\u5982\u679c\u662f batch first=true\u7684\u8bdd\uff1a <code>batch size\u00d7sequence length\u00d7input size</code>\u3002</p> <p>2\ufe0f\u20e3 <code>(h_0\uff0cc_0)</code></p> <p>\u683c\u5f0f\uff1a\u5143\u7ec4</p> <p>\u4e3a\u4ec0\u4e48\u662f\u5143\u7ec4\u7684\u5f62\u5f0f\uff1f</p> <p>\u4e3a\u4e86\u8ddfRNN\u7684api\u4fdd\u6301\u4e00\u81f4</p> <p>RNN\u7684api\u8f93\u5165\u5c31\u662f\u4e24\u4e2a\u91cf\uff0cLSTM\u662fRNN\u4e00\u4e2a\u7279\u6b8a\u7684\u53d8\u4f53\uff0c\u6240\u4ee5\u867d\u7136\u6709\u4e24\u4e2a\u521d\u59cb\u72b6\u6001\uff0c\u7528\u4e24\u4e2a\u66f4\u5408\u4e4e\u5e38\u7406\uff0c\u4f46\u8fd8\u662f\u7528\u5143\u7ec4\u7684\u5f62\u5f0f\u7ec4\u5408\u8d77\u6765</p> <p>\u4e24\u4e2a\u521d\u59cb\u72b6\u6001\u5206\u522b\u662f <code>h_0</code>\u548c<code>c_0</code></p> <p>\u5c31\u662f\u6240\u6709\u5e26 t-1 \u4e0b\u6807\u7684\uff0c\u8fd9\u4e9b\u7b26\u53f7\u90fd\u9700\u8981\u63d0\u4f9b\u4e00\u4e2a\u521d\u59cb\u503c</p> <p>LSTM output</p> <p></p> <p>\u867d\u7136\u662f\u8f93\u51fa <code>c_n</code>\uff0c\u4f46\u662f <code>h_n = o_n \u00d7 tanh(c_n)</code>\uff0c<code>h_n</code> \u4e0e <code>c_n</code> \u662f\u7531 <code>c_n</code> \u8ba1\u7b97\u6765\u7684\uff0c\u5373\u4f7f\u8bf4 <code>c_n</code> \u662f\u4e2d\u95f4\u7ed3\u679c\u4e5f\u53ef\u4ee5\uff0c\u4f46 <code>c_n</code> \u662f LSTM \u7684\u6838\u5fc3</p> <p><code>Outputs\uff1aoutput,(h_n,c_n)</code></p> <ul> <li> <p><code>output</code>\uff1a\u6574\u4e2a\u6a21\u578b\u5e8f\u5217\u7684\u8f93\u51fa\uff0c<code>shape= batch size\u00d7sequence length\u00d7hidden size</code>\uff0coutput \u53cd\u5e94\u6574\u4e2a\u5e8f\u5217\u7684\u72b6\u6001\u8f93\u51fa\uff1b</p> </li> <li> <p><code>(h_n,c_n)</code> \uff1a\u5143\u7ec4\u5f62\u5f0f\uff0c<code>h_n</code>\u548c<code>c_n</code>\uff0c\u8868\u793a\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684<code>\u9690\u542b\u72b6\u6001</code>\u548c<code>\u7ec6\u80de\u72b6\u6001</code></p> </li> </ul> <p>\u601d\u8003\uff1a<code>output,(h_n,c_n)</code>\u6709\u4ec0\u4e48\u4f5c\u7528\uff1f</p> <p>1\ufe0f\u20e3 <code>output</code></p> <p><code>output</code>\u662f\u4e00\u4e2a<code>many to many</code>\u7684\u5efa\u6a21</p> <p>\u8f93\u5165\u662f\u4e00\u4e2a\u5e8f\u5217\uff0c\u8f93\u51fa\u4e5f\u662f\u4e00\u4e2a\u5e8f\u5217\uff0c\u4fdd\u7559\u5e8f\u5217\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\uff0c\u6bd4\u65b9\u8bf4\uff0c\u5bf9\u4e00\u4e2a\u6587\u672c\u7684\u591a\u97f3\u5b57\u8fdb\u884c\u9884\u6d4b\uff0c\u6216\u8005\u8bf4\u8bcd\u6027\u8fdb\u884c\u9884\u6d4b\uff0c\u90fd\u662f <code>many to many</code>\u7684\u4efb\u52a1\uff0c\u9700\u8981\u6bcf\u4e00\u65f6\u523b\u7684\u8f93\u51fa</p> <p>2\ufe0f\u20e3 <code>h_n</code></p> <p><code>h_n</code>\u662f\u4e00\u4e2a<code>many to one</code>\u7684\u4efb\u52a1</p> <p>\u6bd4\u65b9\u8bf4\u8f93\u5165\u4e00\u6bb5\u8bdd\u5230LSTM\u7f51\u7edc\u4e2d\uff0c\u6700\u7ec8\u53ea\u53d6\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u72b6\u6001\uff0c\u5e76\u4e14\u5e0c\u671b\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u72b6\u6001\uff0c\u5c31\u80fd\u53bb\u8868\u5f81\u6574\u53e5\u8bdd\u7684\u7279\u5f81\uff0c\u7136\u540e\u518d\u5bf9\u6700\u540e\u4e00\u4e2a\u72b6\u6001\u8fdb\u884c\u5206\u7c7b\uff0c\u6216\u8005\u8fdb\u884c <code>sequence embedding</code>\uff0c\u8fd9\u4e2a\u662f <code>many to one</code>\u7684\u4efb\u52a1\uff0c\u5c31\u53ef\u4ee5\u7528\u5230<code>h_n</code></p> <p>\u4ee5\u4e0a\uff1a</p> <ul> <li> \u5b9e\u4f8b\u5316 LSTM \u9700\u8981\u7684\u4f20\u5165\u53c2\u6570</li> <li> LSTM \u7b97\u5b50\u7684 input parameters</li> <li> LSTM \u7684 outputs</li> </ul> <p>RECall BiRNN </p> Python<pre><code># step3 \u624b\u5199\u4e00\u4e2a bidirectional_rnn_forward\u51fd\u6570\uff0c\u5b9e\u73b0\u53cc\u5411RNN\u7684\u8ba1\u7b97\u539f\u7406\ndef bidirectional_rnn_forward(input,\n                              weight_ih,\n                              weight_hh,\n                              bias_ih,\n                              bias_hh,\n                              h_prev,\n                              weight_ih_reverse,\n                              weight_hh_reverse,\n                              bias_ih_reverse,\n                              bias_hh_reverse,\n                              h_prev_reverse):\n    bs,T,input_size = input.shape\n    h_dim = weight_ih.shape[0]\n    h_out = torch.zeros(bs,T,h_dim*2) # \u521d\u59cb\u5316\u4e00\u4e2a\u8f93\u51fa\uff08\u72b6\u6001\uff09\u77e9\u9635\uff0c\u6ce8\u610f\u53cc\u5411\u662f\u4e24\u500d\u7684\u7279\u5f81\u5927\u5c0f\n\n    forward_output = rnn_forward(input,\n                                 weight_ih,\n                                 weight_hh,\n                                 bias_ih,\n                                 bias_hh,\n                                 h_prev)[0]  # forward layer\n    backward_output = rnn_forward(torch.flip(input,[1]),\n                                  weight_ih_reverse,\n                                  weight_hh_reverse,\n                                  bias_ih_reverse, bias_hh_reverse,\n                                  h_prev_reverse)[0] # backward layer\n\n    # \u5c06input\u6309\u7167\u65f6\u95f4\u7684\u987a\u5e8f\u7ffb\u8f6c\n    h_out[:,:,:h_dim] = forward_output\n    h_out[:,:,h_dim:] = torch.flip(backward_output,[1]) #\u9700\u8981\u518d\u7ffb\u8f6c\u4e00\u4e0b \u624d\u80fd\u548cforward output\u62fc\u63a5\n\n\n    h_n = torch.zeros(bs,2,h_dim)  # \u8981\u6700\u540e\u7684\u72b6\u6001\u8fde\u63a5\n\n    h_n[:,0,:] = forward_output[:,-1,:]\n    h_n[:,1,:] = backward_output[:,-1,:]\n\n    h_n = h_n.transpose(0,1)\n\n    return h_out,h_n\n    # return h_out,h_out[:,-1,:].reshape((bs,2,h_dim)).transpose(0,1)\n\n# \u9a8c\u8bc1\u4e00\u4e0b bidirectional_rnn_forward\u7684\u6b63\u786e\u6027\nbi_rnn = nn.RNN(input_size,\n                hidden_size,\n                batch_first=True,\n                bidirectional=True)\nh_prev = torch.zeros((2,bs,hidden_size))\nbi_rnn_output,bi_state_finall = bi_rnn(input,h_prev)\n\nfor k,v in bi_rnn.named_parameters():\n    print(k,v)\n</code></pre> <ul> <li>\u6709<code>forward layer</code>\u8fd8\u6709<code>backward layer</code></li> </ul> Python<pre><code>    forward_output = rnn_forward(input,\n                                 weight_ih,\n                                 weight_hh,\n                                 bias_ih,\n                                 bias_hh,\n                                 h_prev)[0]  # forward layer\n    backward_output = rnn_forward(torch.flip(input,[1]),\n                                  weight_ih_reverse,\n                                  weight_hh_reverse,\n                                  bias_ih_reverse, bias_hh_reverse,\n                                  h_prev_reverse)[0] # backward layer\n</code></pre> <p>\u4e3b\u8981\u770b<code>backward layer</code></p> <p>\u9996\u5148\u5bf9\u8f93\u5165\u8fdb\u884c\u4e00\u4e2a\u7ffb\u8f6c <code>torch.flip(input,[1])</code> \uff0c\u6309\u7167\u65f6\u95f4\u7ef4\u5ea6\u8fdb\u884c\u7ffb\u8f6c\uff0c\u540c\u6837\u5582\u5165\u5230RNN forward\u51fd\u6570\u4e2d\uff0c\u6709\u5404\u79cd\u7ffb\u8f6c</p> <p>\u518d\u628a<code>forward output</code>\u548c<code>backward output</code>\u62fc\u8d77\u6765\uff0c\u5728\u7279\u5f81\u7ef4\u5ea6\u4e0a\u62fc\u8d77\u6765 \u5c31\u6784\u6210\u4e86 <code>h_out</code>\uff0c\u4e5f\u5c31\u662f\u53cc\u5411RNN\u7f51\u7edc</p> Python<pre><code>    # \u5c06input\u6309\u7167\u65f6\u95f4\u7684\u987a\u5e8f\u7ffb\u8f6c\n    h_out[:,:,:h_dim] = forward_output\n    h_out[:,:,h_dim:] = torch.flip(backward_output,[1])\n    #\u9700\u8981\u518d\u7ffb\u8f6c\u4e00\u4e0b \u624d\u80fd\u548cforward output\u62fc\u63a5\n\n    h_n = torch.zeros(bs,2,h_dim)  # \u8981\u6700\u540e\u7684\u72b6\u6001\u8fde\u63a5\n    h_n[:,0,:] = forward_output[:,-1,:]\n    h_n[:,1,:] = backward_output[:,-1,:]\n    h_n = h_n.transpose(0,1)\n    return h_out,h_n\n</code></pre> <p>\u53cc\u5411GRU\u548c \u53cc\u5411 LSTM \u539f\u7406\u4e5f\u662f\u4e00\u6837\u7684</p> <p>\u5b9e\u73b0 LSTM</p> <p>\u8c03\u7528\u5b98\u65b9 api</p> Python<pre><code># \u5b9e\u73b0LSTM\u548cLSTMP\u7684\u6e90\u7801\n</code></pre> <p></p> <p>\u7b2c 1 \u6b65\uff1a\u5b9a\u4e49\u5e38\u91cf </p> <ul> <li>batch size</li> <li>\u65f6\u95f4\uff1aT</li> <li>\u8f93\u5165\u7279\u5f81\u5927\u5c0f\uff1ai_size</li> <li>h_size\uff1ahidden size\u7f51\u7edc\u7ec6\u80de\u72b6\u6001\u7684\u5927\u5c0f</li> </ul> Python<pre><code># \u5b9a\u4e49\u5e38\u91cf\nbs,T,i_size,h_size = 2,3,4,5\n</code></pre> <p><code>projection size</code> \u4e5f\u5c31\u662f\u6295\u5f71\u7684\u5927\u5c0f\uff08\u6682\u8df3\uff09</p> Python<pre><code># proj_size\n</code></pre> <p>\u7b2c 2 \u6b65\uff1a\u6784\u5efa\u8f93\u5165 input</p> <p>\u5582\u5165\u5230LSTM\u7f51\u7edc\u7684\u7279\u5f81\u5e8f\u5217</p> <p>\u7528\u6b63\u6001\u5206\u5e03\u521d\u59cb\u5316 torch.randn \u8f93\u5165</p> Python<pre><code>input = torch.randn(bs,T,i_size) #\u8f93\u5165\u5e8f\u5217\n</code></pre> <p>\u7b2c 3 \u6b65\uff1a\u521d\u59cb\u5316\u521d\u59cb\u72b6\u6001\uff1a<code>c_0\u3001h_0</code></p> <p>\u9664\u4e86\u8f93\u5165\u5e8f\u5217\uff0c\u8fd8\u9700\u8981\u521d\u59cb\u5316\u4e24\u4e2a\u521d\u59cb\u72b6\u6001\uff0c\u5206\u522b\u662f<code>c_0</code>\u548c<code>h_0</code></p> <p>c_0</p> <p>\u5047\u8bbe\u53ea\u8003\u8651\u4e00\u5c42\uff0c<code>c_0</code>\u7684\u521d\u59cb\u72b6\u6001\u5c31\u662f <code>batch size\u00d7hidden size</code></p> Text Only<pre><code>c0 = torch.randn(bs,h_size)\n</code></pre> <p>\u56e0\u4e3a<code>c</code>\u672c\u8eab\u5c31\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u5411\u91cf\u957f\u5ea6\u5c31\u662f <code>hidden_size</code></p> <p>\u8003\u8651\u5230 <code>batch</code>\u7ef4\u5ea6\uff0c\u6240\u4ee5\u5199\u6210 <code>batch size\u00d7hidden size</code></p> <p>\u4ee5\u4e0a\uff0c\u521d\u59cb\u5316 <code>c_0</code> </p> Python<pre><code>c0 = torch.randn(bs,h_size) # \u521d\u59cb\u503c \u4e0d\u9700\u8981\u53c2\u4e0e\u8bad\u7ec3\n</code></pre> <p>h_0</p> <p><code>c_0</code> \u4e0d\u9700\u8981\u8bad\u7ec3\uff0c<code>h_0</code>\u4e5f\u662f\u4e00\u6837\u7684\uff0c\u5c31\u662f\u63d0\u4f9b\u4e86<code>h</code>\u7684\u521d\u59cb\u503c</p> <p>\u5199 <code>batch_size \u00d7hidden_size</code></p> <p>\u5148\u5199 <code>hidden_size</code>\uff0c\u6682\u65f6\u4e0d\u8003\u8651\u8003\u8651<code>projection size</code></p> Text Only<pre><code>h0 = torch.randn(bs,h_size)\n</code></pre> <p>\u4ee5\u4e0a\uff0c\u5b9a\u4e49\u597d\u4e86\u4e09\u4e2a\u57fa\u672c\u7684\u91cf\uff1a\u8f93\u5165 <code>input</code> \u548c\u521d\u59cb\u503c<code>(c_0,h_0)</code></p> <p></p> <p>\u7b2c 4 \u6b65\uff1a\u8c03\u7528\u5b98\u65b9LSTM API\uff0c\u5b9e\u4f8b\u5316</p> Python<pre><code># \u8c03\u7528\u5b98\u65b9LSTM API\n</code></pre> <p>\u5b98\u65b9api\u5c31\u662f<code>nn.LSTM</code></p> <p></p>Python<pre><code>nn.LSTM()\n</code></pre> \u5b9e\u4f8b\u5316\u9700\u8981\u4f20\u5165\u7684\u53c2\u6570 <p></p> <p>\u4f20\u5165\u7684\u53c2\u6570\u987a\u5e8f\u5206\u522b\u662f input size\u3001hidden size\u3001batch first</p> <p>projection size\u6682\u65f6\u4e0d\u7528</p> <ul> <li><code>input_size</code> \u5c31\u662f <code>i_size</code></li> <li><code>hidden_size</code>\u5c31\u662f<code>h_size</code></li> <li><code>batch_first</code>\u8bbe\u7f6e\u6210 <code>true</code></li> </ul> <p>\u4ee5\u4e0a\u5b9e\u4f8b\u5316\u4e86\u7b80\u5355\u7684LSTM layer\uff0c\u5b9a\u4e49\uff1a<code>lstm_layer</code></p> Python<pre><code>lstm_layer = nn.LSTM(i_size,h_size,batch_size=True)\n</code></pre> <p>\u7b2c 5 \u6b65\uff1a<code>LSTM</code> \u7b97\u5b50 <code>input parameters</code></p> <p>\u5728\u5b9a\u4e49\u597dLSTM layer\u4ee5\u540e\uff0c\u628a<code>\u8f93\u5165</code>\u548c<code>\u521d\u59cb\u72b6\u6001</code>\u5206\u522b\u4f20\u5165\u5230LSTM layer\u4e2d</p> <p>\u5177\u4f53\u600e\u4e48\u4f20\u5165\u53c2\u6570?</p> <p>\u53bb\u770bapi</p> <p></p> <p>\u4ece<code>api</code>\u53ef\u4ee5\u770b\u5230\uff0c<code>inputs</code>\u662f <code>input</code>\u548c<code>\u4e00\u4e2a\u5143\u7ec4</code></p> <p>\u5728\u5143\u7ec4\u4e2d\uff0c\u9700\u8981\u4f20\u5165<code>h0</code>\u548c<code>c0</code></p> <p>\u6240\u4ee5\u4ee3\u7801\u5199<code>input</code>\uff0c\u7136\u540e\u518d\u5199<code>\u4e00\u4e2a\u5143\u7ec4</code></p> Python<pre><code>lstm_layer(input,())\n</code></pre> <p>\u5143\u7ec4\u5206\u522b\u4f20\u5165 <code>h0</code> \u548c<code>c0</code></p> Python<pre><code>lstm_layer(input,(h0,c0))\n</code></pre> <p>\u90a3\u7ef4\u5ea6\u662f\u591a\u5c11\u5462\uff1f\u5b98\u65b9\u6587\u6863\uff1a</p> <p></p> <p><code>h0</code>\u7684\u7ef4\u5ea6\u662f<code>D*num_layers\u00d7N\u00d7H_out</code></p> <p><code>c0</code>\u4e5f\u662f\u4e00\u6837\u7684\uff0c\u9996\u5148\u521d\u59cb\u5316 <code>N\u00d7H_out</code></p> Python<pre><code>output,(h_finall,c_finall) = lstm_layer(input,\n                                        (h0.unsqueeze(0),c0.unsqueeze(0)))\n</code></pre> <p>\u6f14\u793a\u7684\u662f\u5355\u5411\u7684LSTM\u7f51\u7edc\uff0c\u662f\u4e00\u5c42\u7684\uff0c\u6240\u4ee5\u524d\u9762\u7684\u6570\u5b57\u5728\u521d\u59cb\u5316\u65f6\u7701\u6389\u4e86</p> <p>\u73b0\u5728\u5148\u6269\u4e00\u4e0b\uff0c\u6269\u6210 \u4e09\u7ef4</p> <p>\u5bf9<code>h0</code>\u8c03\u7528<code>unsqueeze</code>\u51fd\u6570\uff0c\u5728\u7b2c0\u7ef4\u6269\u4e00\u7ef4</p> <p><code>c0</code>\u4e5f\u540c\u6837\u6269\u7ef4\uff0c\u53d8\u6210\u4e09\u7ef4\u5f20\u91cf\uff0c\u7b2c0\u7ef4\u662f1</p> <p>\u4ee5\u4e0a\u662f\u5355\u5c42\u5355\u5411LSTM \u7b97\u5b50\uff0c\u53ef\u4ee5\u5f97\u5230\u8f93\u51fa</p> Python<pre><code># \u5b9a\u4e49\u5e38\u91cf\nbs,T,i_size,h_size = 2,3,4,5\n# proj_size\ninput = torch.randn(bs,T,i_size) # \u8f93\u5165\u5e8f\u5217\nc0 = torch.randn(bs,h_size)  # \u521d\u59cb\u503c\u4e0d\u9700\u8981\u8bad\u7ec3\nh0 = torch.randn(bs,h_size)\n# \u8c03\u7528\u5b98\u65b9LSTM API\nlstm_layer = nn.LSTM(i_size,h_size,batch_first=True)\noutput,(h_finall,c_finall) = lstm_layer(input,\n                                (h0.unsqueeze(0),c0.unsqueeze(0)))\n\nfor k,v in lstm_layer.named_parameters():\n    print(k,v.shape)\n</code></pre> <p>\u7b2c 6 \u6b65\uff1a\u8f93\u51fa <code>Outputs:output,(h_n,c_n)</code></p> <p></p> <p>\u8fd9\u91cc\u5199\u8f93\u51fa\uff1a</p> Python<pre><code># \u8c03\u7528\u5b98\u65b9LSTM api\nlstm_layer = nn.LSTM(i_size,\n                     h_size,\n                     batch_first=True)\noutput,(hn,cn) = lstm_layer(input,\n                            (h0.unsqueeze(0),c0.unsqueeze(0)))\n</code></pre> <p>\u4ee5\u4e0a\u8c03\u7528\u597d\u4e86api\uff0c\u63a5\u4e0b\u6765\u6253\u5370output</p> Python<pre><code>print(output)\n</code></pre> <p>\u6539\u540d\u5b57\uff0c\u5b9a\u4e49<code>h_finall</code>\u548c<code>c_finall</code>\uff0c\u8868\u793a\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001\u548c\u7ec6\u80de\u72b6\u6001</p> Python<pre><code>output,(h_finall,c_finall) = lstm_layer(input,\n                                        (h0.unsqueeze(0),c0.unsqueeze(0)))\n</code></pre> <p>\u7b2c 7 \u6b65\uff1a\u6253\u5370LSTM \u6a21\u578b\u53c2\u6570</p> <p>\u5b98\u65b9 api \u5b9e\u73b0 LSTM\uff0c\u53ef\u4ee5\u8c03\u7528 LSTM layer \u7684 <code>named_parameter</code> \u51fd\u6570\uff0c\u6253\u5370\u6743\u91cd\u548c\u540d\u5b57\uff0c\u67e5\u770b LSTM \u6a21\u578b\u53c2\u6570</p> Python<pre><code>for k,v in named_parameters():\n    print(k,v)\n</code></pre> <p></p> <p>\u53ef\u4ee5\u770b\u5230LSTM\u7684\u53c2\u6570\u540d\u4ee5\u53ca\u5177\u4f53\u7684\u5f20\u91cf\uff1a</p> <ul> <li><code>weight_ih_l0</code> \u5bf9\u5e94\u516c\u5f0f\u91cc\u7684 \\(W_{ii}\\) \\(W_{if}\\) \\(W_{ig}\\) \\(W_{io}\\)  \u56db\u4e2a \\(W_i\\)\u653e\u5230\u4e86\u4e00\u4e2a <code>weight_ih</code>\u91cc\u9762</li> <li><code>weight_hh_l0</code> \u8fd9\u4e2a\u53c2\u6570\u662f\u516c\u5f0f\u7684 \u56db\u4e2a \\(W_{hi}\\) \\(W_{hf}\\) \\(W_{hg}\\) \\(W_{ho}\\) \\(W_h\\)\u62fc\u8d77\u6765\u7684</li> <li><code>bias_ih_l0</code> </li> <li><code>bias_hh_l0</code></li> </ul> <p>\u6700\u540e\u4e24\u4e2a\u504f\u7f6e\u9879\uff0c\u540c\u6837\u662f\u62fc\u8d77\u6765\u7684\uff0c\u8fd9\u6837\u76f4\u63a5\u770b\u5f20\u91cf\u4e0d\u6e05\u6670\uff0c\u63a5\u4e0b\u6765\u770bshape</p> <p></p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a<code>LSTM layer</code>\u4e2d\u4e00\u5171\u67094\u4e2a\u53c2\u6570\uff1b</p> <p>\u7b2c\u4e00\u4e2a\u53c2\u6570  \u662f <code>weight_ih_l0</code> \uff1a 20\u00d74</p> <p>\u4e3a\u4ec0\u4e48\u662f 20\u00d74\u5462\uff1f </p> <ul> <li><code>20</code>\u662f<code>hidden_size</code>\uff0c\u5c31\u662f<code>5</code>\u8fd9\u4e2a\u7ef4\u5ea6\uff0c\u7136\u540e\u628a<code>4</code>\u4e2a<code>W</code>\u62fc\u8d77\u6765</li> </ul> <p>\u672c\u6765\u6bcf\u4e00\u4e2a\u662f<code>5</code>\u884c\uff0c\u73b0\u5728\u62fc\u6210\u4e86<code>20</code>\u884c\uff0c<code>20</code>\u5c31\u662f<code>5\u00d74</code></p> <ul> <li><code>4</code>\u662f <code>input_size</code>\uff0c\u56e0\u4e3a\u8fd9\u4e2a<code>w_ih</code>\u662f\u8ddf <code>input</code> \u76f8\u4e58\u7684\uff0c\u662f\u5bf9<code>input</code>\u8fdb\u884c\u7ebf\u6027\u53d8\u6362\u7684\u53c2\u6570</li> </ul> <p></p> <p>\u89e3\u91ca\u8fd9\u91cc\u7684\u6743\u91cd\uff1a</p> <p>\\(T=3\uff0cinput\\_size = 4\uff0chidden\\_size = 5\\)</p> <p>\\(4(4\u00d71) \\stackrel{5\u00d74}{\\rightarrow} 5(5\u00d71)\\)</p> <p>\\(\u2234 weight\\_ih = 5 \u00d7 4 \u5806\u53e0 4 \u4e2a \u2192 20\u00d74\\)</p> <p>\u7b2c\u4e8c\u4e2a\u53c2\u6570\u00a0 <code>weight_hh_l0</code> \u53c2\u6570\u662f <code>20\u00d75</code>\u7684</p> <ul> <li><code>20</code> \u662f <code>4\u00d75</code> \u6765\u7684</li> <li><code>5</code> \u662f<code>weight_hh</code>\u662f\u8ddf<code>\u4e0a\u4e00\u65f6\u523b\u7684\u9690\u542b\u72b6\u6001</code>\u8fdb\u884c\u7ebf\u6027\u53d8\u6362\u7684\uff0c\u7ef4\u5ea6\u662f<code>5</code> </li> <li>\\(\u2234 1 \u4e2a weight\\_hh shape = 5 \u00d7 5\\)</li> </ul> <p>\u9690\u85cf\u5c42\u662f<code>linear</code>\u5c42\uff1a<code>y=wx+b</code></p> <p><code>w</code>\u7684\u7ef4\u5ea6\u5c31\u662f<code>hidden size\u00d7input size</code></p> <p>\u8fd9\u91cc\u7684<code>hidden_size</code>\u5c31\u662f5\uff0c<code>input_size</code>\u662f4</p> <p>\u7b2c\u4e09\u4e2a\u3001\u7b2c\u56db\u4e2a\u53c2\u6570\uff1a\u4e24\u4e2a<code>bias</code></p> <p><code>bias_ih</code>\u548c<code>bias_hh</code> \u90fd\u662f<code>20</code>\uff0c<code>20</code>\u662f <code>4\u00d75</code>\u6765\u7684\uff0c\u5c31\u662f\u6709<code>4</code>\u4e2a<code>bias</code>\uff08<code>4</code>\u4e2a<code>bi</code>\u548c<code>4</code>\u4e2a<code>bh</code>\uff09\uff0c\u628a\u8fd9\u56db\u4e2a\u62fc\u8d77\u6765\uff0c\u6bcf\u4e00\u4e2a\u957f\u5ea6\u90fd\u662f20\u7684</p> <p>\u4ee5\u4e0a\u662fLSTM\u4e0d\u5e26projection\u7684\u5b9e\u73b0</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# \u5b9a\u4e49\u5e38\u91cf\nbs,T,i_size,h_size = 2,3,4,5\ninput = torch.randn(bs,T,i_size) # \u8f93\u5165\u5e8f\u5217\nc0 = torch.randn(bs,h_size)  # \u521d\u59cb\u503c\u4e0d\u9700\u8981\u8bad\u7ec3\nh0 = torch.randn(bs,h_size)\n\n# \u8c03\u7528\u5b98\u65b9LSTM API\nlstm_layer = nn.LSTM(i_size,h_size,batch_first=True)\noutput,(h_finall,c_finall) = lstm_layer(input,(h0.unsqueeze(0),c0.unsqueeze(0)))\n\nfor k,v in lstm_layer.named_parameters():\n    print(k,v.shape)\n</code></pre> <p>OUT\uff1a</p> Python<pre><code>weight_ih_l0 torch.Size([20, 4])\nweight_hh_l0 torch.Size([20, 5])\nbias_ih_l0 torch.Size([20])\nbias_hh_l0 torch.Size([20])\n</code></pre> <p>\u53ef\u4ee5\u6839\u636e\u8fd9\u4e9b\u53c2\u6570\uff0c\u6765\u81ea\u5df1\u5199\u4e00\u4e2aLSTM\u6a21\u578b</p>"},{"location":"learning/14_LSTM/#lstm_3","title":"\u81ea\u5b9a\u4e49 LSTM \u5b9e\u73b0","text":"Python<pre><code># \u81ea\u5df1\u5199\u4e00\u4e2aLSTM\u6a21\u578b\n</code></pre> <p>\u6839\u636e<code>\u4e0a\u9762\u7684\u53c2\u6570\u3001h0\u3001c0\u3001input</code>\uff0c\u53ef\u4ee5\u81ea\u5df1\u5199\u4e00\u4e2aLSTM</p> Python<pre><code>def lstm_forward():\n    pass\n</code></pre> <p>\u7b2c 1 \u6b65\uff1a\u51fd\u6570\u7b7e\u540d </p> <p>\u9996\u5148\u601d\u8003\u8fd9\u4e2a LSTM \u6a21\u578b\uff0c\u9700\u8981\u54ea\u4e9b\u8f93\u5165\u5462\uff1f</p> <p>\u7b2c\u4e00\u4e2a\uff1a\u9700\u8981\u4f20\u5165\u7684 <code>input</code></p> <p>\u7b2c\u4e8c\u4e2a\uff1a \u5143\u7ec4\u5f62\u5f0f\u7684 <code>initial states</code></p> <p>\u7b2c\u4e09\u4e2a\uff1a \u6743\u91cd\u548c\u504f\u7f6e\uff0c\u5305\u62ec<code>W_ih\u3001W_hh\u3001b_ih\u3001b_hh</code></p> <p>\u4ee5\u4e0a\u662f<code>LSTM forward</code>\u7684\u7b7e\u540d</p> Python<pre><code>def lstm_forward(input,\n                 initial_states,\n                 w_ih,\n                 w_hh,\n                 b_ih,\n                 b_hh):\n</code></pre> <p>\u5982\u679c\u5e26 projection\u7684\u8bdd\uff0c\u540e\u9762\u8fd8\u9700\u8981\u518d\u52a0\u53c2\u6570</p> <p>\u7b2c 2 \u6b65\uff1a\u62c6\u89e3<code>initial states</code>\uff1a <code>h0</code>\u548c<code>c0</code></p> Python<pre><code>h0,c0 = initial_states  # \u521d\u59cb\u72b6\u6001\n</code></pre> <p>\u7b2c 3 \u6b65\uff1a\u62c6\u89e3  <code>input.shape</code></p> <p>\u901a\u8fc7<code>input shape</code>\u5f97\u5230<code>batch size\u3001\u65f6\u95f4T\uff0cinput size</code></p> <p>\u5f97\u5230<code>\u65f6\u95f4T</code>\uff0c\u8fdb\u884c<code>for\u5faa\u73af</code>\uff0c\u4e0d\u65ad\u7684\u8fed\u4ee3\uff0c\u4e0d\u65ad\u7684\u8fd0\u7b97</p> Python<pre><code>bs,T,i_size = input.shape\n</code></pre> <p>\u4ee5\u4e0a\u662f<code>input_size</code> </p> <p>\u8fd8\u6709<code>h_size</code></p> <p><code>h_size</code>\u600e\u4e48\u5f97\u5230\u5462\uff1f</p> <p><code>h_size</code>\u6839\u636e <code>W</code> \u7684\u7ef4\u5ea6 \u6765\u786e\u5b9a</p> <p>\u6bd4\u5982<code>weight_ih</code>\uff0c\u9664\u4ee5<code>4</code>\u5c31\u597d\u4e86\uff0c\u56e0\u4e3a\u662f<code>4</code>\u4e2a <code>W</code> \u62fc\u8d77\u6765\u7684</p> Python<pre><code>h_size = w_ih.shape[0]//4\n</code></pre> <p>\u7b2c<code>0</code>\u7ef4\u9664\u4ee5<code>4</code>\uff0c\u5c31\u662f\u6bcf\u4e00\u7ef4\u7684<code>hidden_size</code></p> <p>\u7b2c 4 \u6b65\uff1afor \u5faa\u73af\u521d\u59cb\u5316</p> <p>\u628a<code>h0</code>\u548c<code>c0</code>\u6362\u540d\u5b57\uff1a<code>prev_h</code> \u548c <code>prev_c</code></p> <p>\u56e0\u4e3a\u4f1a\u5728 <code>for</code>\u5faa\u73af\u4e2d\uff0c\u4e0d\u65ad\u7684\u66f4\u65b0 <code>prev_h</code>\u548c<code>prev_c</code></p> Python<pre><code>prev_h = h0\nprev_c = c0\n</code></pre> <p>\u628a\u6bcf\u4e00\u65f6\u523b\u7684<code>h</code>\u548c<code>c</code>\u5f53\u505a\u4e0b\u4e00\u65f6\u523b\u7684 <code>prev_h</code>\u548c<code>prev_c</code></p> <p>\u7b2c 5 \u6b65\uff1aoutput size</p> <p>\u53e6\u5916\u8fd8\u6709\u4e00\u4e2a <code>size</code> \u53eb\u505a <code>output size</code>\uff0c\u4e5f\u5c31\u662f <code>\u8f93\u51fa\u7684\u72b6\u6001\u5927\u5c0f</code> \u5c31\u662f <code>hidden size</code></p> Python<pre><code>output_size = h_size\n</code></pre> <p>\u4ee5\u4e0a\u662f\u521d\u59cb\u5316output</p> <p>\u5728\u5199\u795e\u7ecf\u7f51\u7edc\u6216\u8005\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff1a</p> <p>\uff081\uff09\u9996\u5148\u521d\u59cb\u5316\u77e9\u9635\uff1b</p> <p>\uff082\uff09\u7136\u540e\u5bf9\u77e9\u9635\u8fdb\u884c\u586b\u5145\uff0c<code>\u77e9\u9635\u7684\u5927\u5c0f</code>\u8ddf<code>\u8f93\u5165\u7279\u5f81\u5927\u5c0f</code>\u662f\u4e00\u6837\u7684</p> <p>\u8f93\u5165\u5e8f\u5217\u5927\u5c0f\uff1a<code>bs\u00d7T\u00d7input_size</code></p> <ul> <li><code>batch size</code>\u548c <code>T</code> \u7ef4\u5ea6\u662f\u4e0d\u53d8</li> <li>\u7136\u540e\u7279\u5f81\u7ef4\u5ea6 <code>input size</code> \u6539\u6210 <code>output size</code> </li> </ul> <p>\u4ee5\u4e0a\u5b8c\u6210 <code>output</code> \u7684\u521d\u59cb\u5316</p> Python<pre><code>output = torch.zeros(bs,T,output_size) # \u8f93\u51fa\u5e8f\u5217\n</code></pre> <p>\u7b2c 6 \u6b65\uff1afor \u5faa\u73af</p> <p>\u5b8c\u6210\u521d\u59cb\u5316\u4ee5\u540e\uff0c\u63a5\u4e0b\u6765\u5bf9\u65f6\u95f4\u8fdb\u884c\u904d\u5386</p> <p>LSTM\u5c31\u662f<code>\u6bcf\u4e00\u65f6\u523b</code>\u90fd\u5728\u5bf9<code>\u4e0a\u4e00\u65f6\u523b</code>\u7684\\(c\\)\u548c \\(h\\)\u8fdb\u884c\u66f4\u65b0\uff0c<code>for\u5faa\u73af</code>\u5b9e\u73b0\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u5bf9\u6bcf\u4e00\u65f6\u523b\u8fdb\u884c\u8fd0\u7b97\uff0c\u5faa\u73af\u7684\u6b65\u6570\u5c31\u662f\u5927<code>T</code>\u6b65</p> Python<pre><code>for t in range(T):\n</code></pre> <p>\u5728\u6bcf\u4e00\u4e2a\u5faa\u73af\u7684\u5f00\u59cb\uff1a</p> <ul> <li>\u9700\u8981\u62ff\u5230\u5f53\u524d\u8fd9\u4e00\u65f6\u523b\u7684\\(x\\)\uff0c\u53ef\u4ee5\u901a\u8fc7\\(input\\)\u62ff</li> </ul> <p>\u56e0\u4e3a\\(input\\)\u8fd9\u4e2a\u7ef4\u5ea6\u5c31\u662f <code>batch size\u00d7T\u00d7input size</code>\uff0c\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u62ff\u5230 <code>t</code> \u8fd9\u4e00\u7ef4\u5ea6\u5c31\u597d\uff0c\u5c31\u662f\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u5411\u91cf</p> Python<pre><code>x = input[:,t,:]  # \u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u5411\u91cf\n</code></pre> <p>\u63a5\u4e0b\u6765\uff0c\u6839\u636e\u516c\u5f0f\u8fdb\u884c\u8ba1\u7b97\uff1a</p> <p></p> <p>\\(weight_{ih} = [w_{ii},w_{if},w_{ig},w_{io}]'\\)</p> <ul> <li>\\(\\mathrm{w_{ii}}\\) \uff1a 5 \u00d7 4 </li> <li>\\(\\mathrm{weight_{ih}}\\) \uff1a20\u00d74</li> </ul> <p>\u516c\u5f0f\u7684\u4ee3\u7801\u5b9e\u73b0\u903b\u8f91\uff1a</p> <ul> <li>\u9996\u5148\u8ba1\u7b97 \\(W \u00d7 x\\)\uff0c\u518d\u8ba1\u7b97 \\(W \u00d7 h\\)</li> </ul> <p>\u5148\u628a <code>\u5927\u7684\u4e00\u5757</code> \u7b97\u51fa\u6765</p> <p>\u62fc\u8d77\u6765\u7684<code>W</code>\u5206\u522b\u4e0e<code>x</code>\u548c<code>h</code>\u8fdb\u884c\u4e00\u4e2a\u76f8\u4e58\uff0c\u8003\u8651\u5230 <code>batch</code>\uff0c\u9700\u8981\u8fd0\u7528\u7684\u5e26batch\u7684\u77e9\u9635\u76f8\u4e58\uff1b</p> <ul> <li>\u660e\u786e <code>W_ih</code>\u548c<code>W_hh</code>\u7684\u7ef4\u5ea6\u662f\u4ec0\u4e48\uff1a</li> </ul> Python<pre><code>w_ih #  \nw_hh\n</code></pre> <ul> <li> <p><code>w ih</code> \u662f <code>4\u500d\u7684hidden size</code>\u00d7 <code>input size</code></p> </li> <li> <p><code>w hh</code> \u662f <code>4\u500d\u7684hidden size\u00d7 hidden size</code></p> </li> </ul> <p>\u4ee5\u4e0a \u662f\u4e24\u4e2a\u6743\u91cd\u7684\u7ef4\u5ea6</p> Python<pre><code>w_ih  # [4*h_size,i_size]\nw_hh  # [4*h_size,h_size]\n</code></pre> <ul> <li>\u8ba1\u7b97 \\(w_{ih} \\cdot x\\)</li> </ul> <p>\u601d\u8003\uff1a \\(x\\)\u7684\u7ef4\u5ea6\u662f\u591a\u5c11\u5462\uff1f <code>batch size\u00d7input size</code></p> Python<pre><code>x = input[:,t,:]  # \u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u5411\u91cf\uff0c[bs,i_size]\n</code></pre> <p>\u5206\u6790\uff1a</p> <p>\ud83d\udc3e \\(x\\) \u662f<code>\u5e26 batch</code>\u7684\uff0c\u4f46\u662f\\(w\\)\u662f<code>\u4e0d\u5e26batch</code>\u7684</p> <p>\ud83d\udc3e  \u6240\u4ee5\u9996\u5148\u8981\u5bf9 <code>w</code> \u6269\u7ef4\u5ea6\uff0c\u628a <code>batch</code> \u7ef4\u5ea6\u6269\u51fa\u6765\uff0c<code>batch</code>\u7ef4\u653e\u5728\u5f00\u59cb\uff0c\u6240\u4ee5\u6269 0\u7ef4</p> Python<pre><code>w_ih.unsqueeze(0)  # [4*h_size,i_size]\nw_hh  # [4*h_size,h_size]\n</code></pre> <p>\u9700\u8981<code>batch size(bs)</code>\u4e2a\uff0c\u6240\u4ee5\u7528<code>.tile\u51fd\u6570</code>\u5bf9\u7b2c<code>0</code>\u7ef4\u590d\u5236<code>bs\u500d</code>\uff0c\u540e\u9762\u4e24\u4e2a\u7ef4\u5ea6<code>\u4e0d\u53d8</code>\uff0c\u628a\u8fd9\u4e2a\u53d8\u91cf\u53eb\u505a <code>batch_w_ih</code></p> Python<pre><code>batch_w_ih = w_ih.unsqueeze(0).tile(bs,1,1) # [bs,4*h_size,i_size]\n</code></pre> <p>\u4ee5\u4e0a\u5b9e\u73b0\u4e86\u6743\u91cd\u7684\u6269\u7ef4\uff0c\u53d8\u6210\u4e86 \u4e09\u7ef4</p> <p>\u540c\u6837<code>w hh</code>\u4e5f\u662f \u4e00\u6837\u7684\uff0c\u5148\u6269\u4e00\u4e2a <code>batch\u7ef4\u5ea6</code>\uff0c\u7136\u540e<code>tile\u590d\u5236</code>\u4e00\u4e0b\uff0c\u5b9a\u4e49\u4e3a<code>batch_w_hh</code></p> Python<pre><code>batch_w_hh = w_hh.unsqueeze(0).tile(bs,1,1)\n</code></pre> <p>\u7ef4\u5ea6\u53d8\u6210\u4e86 \\(\\mathrm{bs \u00d7 4\u500d\u7684hidden\\_size \u00d7 hidden\\_size}\\)</p> Python<pre><code>batch_w_ih = w_ih.unsqueeze(0).tile(bs,1,1) # [bs,4*h_size,i_size]\nbatch_w_hh = w_hh.unsqueeze(0).tile(bs,1,1) # [bs,4*h_size,h_size]\n</code></pre> <p>\u4ee5\u4e0a\u5bf9\u6743\u91cd\u8fdb\u884c \u6269\u7ef4\uff0c\u6269\u7ef4\u4ee5\u540e\uff1a</p> <ul> <li>\u5f53\u524d\u7684 <code>batch_w_ih\u5f62\u72b6</code>\u662f \\(\\mathrm{bs \u00d7 4\u500d\u7684hidden\\ size\u00d7input\\ size}\\)</li> <li>\u5f53\u524d\u7684 <code>\u8f93\u5165\u5411\u91cf x</code> \u7684\u5f62\u72b6\u662f \uff1a \\(\\mathrm{batch\\  size\u00d7input\\ size}\\)</li> </ul> <p>\u8ba9\u8fd9\u4e24\u4e2a\u77e9\u9635\u8fdb\u884c <code>bmm</code> \u7684\u76f8\u4e58\uff0c\u4e5f\u5c31\u662f<code>batch matrix multiplication</code></p> <ul> <li>\u90a3\u5c31\u8981\u4fdd\u6301 <code>batch</code> \u8fd9\u4e2a\u7ef4\u5ea6\u662f\u76f8\u540c\u7684</li> <li>\u540e\u9762\u7684\u4e24\u4e2a\u7ef4\u5ea6 \u8981\u6ee1\u8db3 \u77e9\u9635\u4e58\u6cd5\u7684\u57fa\u672c\u89c4\u5219\uff1a<code>\u7b2c\u4e00\u4e2a\u77e9\u9635\u7684\u5217\u6570 \uff1d \u7b2c\u4e8c\u4e2a\u77e9\u9635\u7684 \u884c\u6570</code></li> </ul> <p>\u6240\u4ee5\u8981\u5bf9 <code>x</code>  \u8fdb\u884c\u6269\u7ef4\uff0c\u540c\u6837\u5bf9<code>x</code>\u7684 <code>\u7b2c\u4e09\u7ef4</code> \u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6</p> Python<pre><code>x.unsqueeze(-1)\n</code></pre> <p>\u8ba1\u7b97 <code>w_times_x</code>\uff1a\u8c03\u7528\u4e00\u4e0b <code>torch.bmm\u51fd\u6570</code>\uff1a</p> <ul> <li>\u9996\u5148\u4f20\u5165 <code>batch w ih</code></li> </ul> Python<pre><code>w_times_x = torch.bmm(batch_w_ih,)\n</code></pre> <ul> <li>\u7136\u540e\u4f20\u5165 <code>x</code>\uff0c\u5e76\u5bf9 <code>x</code>\u8fdb\u884c\u6269\u7ef4</li> </ul> <p>\u5728<code>-1\u7ef4</code> \u6269\u4e00\u7ef4 \uff0c\u53d8\u6210 \\(\\mathrm{batch\\ size \u00d7 input\\ size \u00d71}\\)</p> <ul> <li>\u5f97\u5230\u4e58\u6cd5\u7684\u7ed3\u679c <code>w_times_x</code> \uff1a </li> </ul> Python<pre><code>w_times_x = torch.bmm(batch_w_ih,x.unsqueeze(-1))  # [bs,4*h_size,1]\n</code></pre> <p>\u76f8\u4e58 \u4ee5\u540e\u7684\u7ef4\u5ea6\u662f\u591a\u5c11\u5462\uff1f </p> <ul> <li>\u76f8\u4e58\u4ee5\u540e\u7684\u7ef4\u5ea6\uff1a \\(\\mathrm{batch\\ size\u00d7 4\u500d\u7684hidden\\ size \u00d7 1}\\)</li> <li>\u6700\u540e\u7684<code>1</code>\u7ef4\u5ea6 \u4e0d\u8981\uff0c\u628a <code>1</code> \u8fd9\u4e2a\u7ef4\u5ea6\u53bb\u6389\uff1a</li> </ul> Python<pre><code>w_times_x = w_times_x.squeeze(-1) # [bs,4*h_size]\n</code></pre> <p>\u4ee5\u4e0a \u628a <code>1</code> \u8fd9\u4e2a\u7ef4\u5ea6\u53bb\u6389\u4e86\uff0c\u5f62\u72b6\u662f <code>batch size \u00d7 4\u500d\u7684hidden size</code></p> <p>\u4ee5\u4e0a\u662f <code>w times x</code> \u7684\u8ba1\u7b97\u8fc7\u7a0b</p> <p></p> <p>\u5b9e\u73b0\u5b8c <code>w_times_x</code>\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f \\(W_{ii}x_t\\) \u3001 \\(W_{if}x_t\\) \u3001 \\(W_{ig}x_t\\) \u3001 \\(W_{io}x_t\\)</p> <p>\u8fd8\u6709 <code>w_times_h</code>\uff0c\u5c31\u662fLSTM\u7f51\u7edc\u4e2d\u540e\u56db\u9879</p> <p></p> <p>\u5b9e\u73b0\u601d\u8def\u662f\u4e00\u6837\u7684\uff0c\u590d\u5236\u4e0b\u6765\u6539\u6210</p> <ul> <li> <p><code>w_hh</code></p> </li> <li> <p><code>prev_h</code></p> </li> <li> <p>\u56e0\u4e3a\u662f\u8ddf <code>h_{t-1}</code> \u8fdb\u884c \u7ebf\u6027\u7ec4\u5408\uff0c\u6240\u4ee5\u4e5f\u8981\u5199\u6210  <code>h_prev</code></p> </li> <li>\u540c\u6837\u4e5f\u8981\u628a <code>\u7ef4\u5ea6</code> \u53d8\u6210 <code>\u4e8c\u7ef4</code>\u7684</li> </ul> Python<pre><code>w_times_h = torch.bmm(batch_w_hh,h_prev.unsqueeze(-1))  \n# [bs,4*h_size,1]\nw_times_h = w_times_h.squeeze(-1) # [bs,4*h_size]\n</code></pre> <p>\u4ee5\u4e0a\u7b97\u51fa <code>w_times_h</code></p> <p>\u6700\u540e\u628a\u540d\u79f0\u6539\u6210 <code>h_prev</code>\u66f4\u597d\uff0c\u56e0\u4e3a\u662f\u8ddf\u4e0a\u4e00\u65f6\u523b\u7684 <code>hidden state</code> \u8fdb\u884c\u7ebf\u6027\u7ec4\u5408</p> Python<pre><code>w_times_h_prev = torch.bmm(batch_w_hh,h_prev.unsqueeze(-1))  \n# [bs,4*h_size,1]\nw_times_h_prev = w_times_h.squeeze(-1) # [bs,4*h_size]\n</code></pre> <p>\u63a5\u4e0b\u6765\uff0c\u5206\u522b\u7b97\u51fa \u8f93\u5165\u95e8\u3001\u9057\u5fd8\u95e8\u3001cell\u548c\u8f93\u51fa\u95e8</p> <p>\u4e5f\u5c31\u662f <code>i\u3001f\u3001g\u3001o</code></p> <p></p> Text Only<pre><code># \u5206\u522b\u8ba1\u7b97\u8f93\u5165\u95e8(i)\u3001\u9057\u5fd8\u95e8(f)\u3001cell\u95e8(g)\u3001\u8f93\u51fa\u95e8(o)\n</code></pre> <p>\u9996\u5148\u8ba1\u7b97\\(i_t\\)\uff0c\u6839\u636e\u516c\u5f0f\uff1a</p> <p>\\(i_t = \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1}+b_{ii})\\)</p> <p><code>i_t</code> \u662f  \\(Wx\\)\u7684\u7b2c\u4e00\u90e8\u5206\u7ed3\u679c+\\(b\\)+\\(Wh\\)\u7684\u7b2c\u4e00\u90e8\u5206\u7ed3\u679c+\\(b\\)</p> <p>\uff081\uff09\u9996\u5148 <code>w_times_x</code>\u7684\u7b2c\u4e00\u90e8\u5206\u7ed3\u679c\u53d6\u51fa\u6765</p> <p>\uff082\uff09 <code>w_times_x</code>\u7684\u7ed3\u679c\u662f <code>batch size \u00d74\u500d\u7684hidden size</code></p> <ul> <li><code>batch size</code>\u8fd9\u4e00\u7ef4\u5ea6\u5168\u90e8\u62ff\u51fa\u6765</li> <li><code>hidden size</code>\u8fd9\u4e00\u7ef4 \u53ea\u62ff\u7b2c\u4e00\u90e8\u5206\u7684 <code>hidden size</code></li> </ul> <p><code>w_times_x</code> \u662f\u4e00\u4e2a\u5927\u7684\u62fc\u8d77\u6765\u7684\u7ed3\u679c\uff0c\u76ee\u524d\u53ea\u9700\u8981\u53d6\u524d \\(\\frac{1}{4}\\)\uff1a</p> Python<pre><code>i_t = w_times_x[:,:h_size]+\n</code></pre> <p>\u540e\u9762 <code>w_times_h_prev</code>\u4e5f\u662f\u53d6\u524d \\(\\frac{1}{4}\\) \uff1a</p> Python<pre><code>i_t = w_times_x[:,:h_size]+w_times_h_prev[:,:h_size]+\n</code></pre> <p>\u8fd8\u6709\u4e24\u4e2a\u504f\u7f6e\\(b_{ih}\\)\u548c\\(b_{hh}\\)\u4e5f\u662f\u4e00\u6837\u7684\uff0c\u53ea\u53d6 \u524d  \\(\\frac{1}{4}\\) \uff1a</p> Python<pre><code>i_t = w_times_x[:,:h_size]+w_times_h_prev[:,:h_size]+b_ih[:h_size]+b_hh[:h_size]\n</code></pre> <p>\u6700\u540e\u8fd8\u6709\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570  \\(\\sigma\\)\uff0c\u5728\u524d\u9762\u52a0\u4e0a <code>torch.sigmoid</code></p> <p></p> <p>\u4ee5\u4e0a\u662f \\(i_t\\)</p> <p>\u8f93\u5165\u95e8\u7684\u8ba1\u7b97= <code>w\u4e58\u4ee5x\u7684\u524d\u56db\u5206\u4e4b\u4e00\u90e8\u5206</code>\uff0c <code>w\u4e58\u4ee5h prev\u4e5f\u662f\u524d\u56db\u5206\u4e4b\u4e00\u90e8\u5206</code>\uff0c\u7136\u540e<code>\u4e24\u4e2abias</code>\u52a0\u8d77\u6765\uff0c\u7ecf\u8fc7\u4e00\u4e2a <code>\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570 sigmoid</code> \u5c31\u5f97\u5230 \u8f93\u5165\u95e8</p> <p></p> <p>\u63a5\u4e0b\u6765 \u9057\u5fd8\u95e8 </p> <p>\u9057\u5fd8\u95e8\u4e5f\u662f\u7c7b\u4f3c\u7684\uff0c\u540c\u6837\u4e5f\u662f sigmoid\uff0c\u76f4\u63a5\u590d\u5236</p> <p>\u4f46\u662f\u9057\u5fd8\u95e8\u4e0d\u662f\u524d\u56db\u5206\u4e4b\u4e00</p> Python<pre><code>i_t = torch.sigmoid(w_times_x[:,:h_size]+w_times_h_prev[:,:h_size]+b_ih[:h_size]+b_hh[:h_size])\n\ni_t = torch.sigmoid(w_times_x[:,:h_size]+w_times_h_prev[:,:h_size]+b_ih[:h_size]+b_hh[:h_size])\n</code></pre> <p>\u800c\u662f<code>\u524d\u56db\u5206\u4e4b\u4e00</code> \u5230<code>\u4e8c\u5206\u4e4b\u4e00</code>\u7684\u90e8\u5206\uff1a</p> Python<pre><code>w_times_x[:,h_size:2*h_size]\n</code></pre> <p>\u5373\uff0c</p> Python<pre><code>f_t = torch.sigmoid(w_times_x[:,h_size:2*h_size]+w_times_h_prev[:,h_size:2*h_size]+b_ih[h_size:2*h_size]+b_hh[h_size:2*h_size])\n</code></pre> <p><code>hidden  size</code> \u5230 <code>2\u500d\u7684hidden size</code></p> <p>\u4ee5\u4e0a\u662f\u9057\u5fd8\u95e8</p> <p></p> <p>\u63a5\u4e0b\u6765\uff0c\u7ec6\u80de\u95e8 $g_t $\uff1a </p> <p>\u7ec6\u80de\u95e8\\(g_t\\)\u4e5f\u662f\u7c7b\u4f3c\u7684\uff0c\u53ea\u4e0d\u8fc7\u5f53\u524d <code>sigmoid</code> \u66ff\u6362\u6210\u4e86<code>tanh\u51fd\u6570</code></p> <p></p> <p>\u6240\u4ee5\u7ee7\u7eed\u590d\u5236\u4e0b\u6765 \uff0c\u518d\u6539\uff0c\u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa\u7ec6\u80de\u72b6\u6001 \\(g_t\\) \uff1a</p> Python<pre><code>g_t = torch.tanh(w_times_x[:,2*h_size:3*h_size]+w_times_h_prev[:,2*h_size:3*h_size]+b_ih[2*h_size:3*h_size]+b_hh[2*h_size:3*h_size])\n</code></pre> <p>gt\u662f<code>\u4e8c\u500d\u7684hidden size</code> \u5230 <code>\u4e09\u500d\u7684 hidden size</code>\u8fd9\u4e2a\u533a\u95f4</p> <p>\u540c\u6837\u540e\u9762\u7684\u504f\u7f6e\u4e5f\u662f\u4e00\u6837\u7684</p> <p>\u6362\u4e00\u4e2a\u533a\u95f4\uff0c\u7136\u540e \u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u6539\u6210 <code>tanh\u51fd\u6570</code></p> <p>\u6700\u540e\u662f\\(o_t\\)\uff0c \u8f93\u51fa\u95e8\uff1a</p> <ul> <li> <p><code>tanh\u51fd\u6570</code> \u6362\u6210 <code>sigmoid\u51fd\u6570</code></p> </li> <li> <p>\u6700\u540e\u533a\u95f4\u662f\u6700\u540e\u7684\u56db\u5206\u4e4b\u4e00\uff0c\u53ef\u4ee5\u5199\u6210 <code>3\u500d\u7684hidden size</code>\u5230<code>4\u500d\u7684hidden size</code></p> </li> </ul> Python<pre><code>o_t = torch.sigmoid(w_times_x[:,3*h_size:4*h_size]+w_times_h_prev[:,3*h_size:4*h_size]+b_ih[3*h_size:4*h_size]+b_hh[3*h_size:4*h_size])\n</code></pre> <ul> <li>\u6216\u8005\u76f4\u63a5 <code>w_times_x[:,3*h_size:]</code>  \uff1a<code>3</code>\u500d\u7684 <code>hidden size</code>\uff0c<code>4</code>\u53ef\u4ee5\u7701\u7565</li> </ul> <p>\u4ee5\u4e0a\u662f\u6240\u6709\u7684 <code>i\u3001f\u3001g\u3001o</code></p> <p></p> <p></p> <p>\u5199\u5b8c\u4e86 \\(i\u3001f\u3001g\u3001o\\)\uff0c\u63a5\u4e0b\u6765\u5199\u7ec6\u80de\u72b6\u6001 \\(c_t\u3001 h_t\\)</p> <p>\\(c_t\\)\u600e\u4e48\u5199\u5462\uff1f</p> <p>\\(c_t\\) \u76f4\u63a5\u662f\u5143\u7d20\u76f8\u4e58\uff0c\u5b9e\u73b0\u7684\u65f6\u5019\u4e0d\u7528 \\(c_t\\)\uff0c\u7528\\(\\mathrm{prev_c}\\)</p> <p>\u56e0\u4e3a\u73b0\u5728\u7528 <code>for\u5faa\u73af</code>\u8fed\u4ee3</p> <p>\u8981\u4fdd\u8bc1\u4e0b\u4e00\u65f6\u523b\\(\\mathrm{prev_c}\\)\u7684\u91cf\u662f\u5b58\u5728\u7684\uff0c\u7528\\(\\mathrm{prev_c}\\)\u8868\u793a\\(c_t\\)</p> <p>\u90a3\\(prev_c\\)= \\(f_t\u00d7 c_{t-1}\u52a0\u4e0a i_t\u00d7g_t \\iff f_t\u00d7prev_ c + i_t\u00d7 g_t\\)</p> <p>\u4ee5\u4e0a\u662f\u5bf9 \\(prev_c\\) \u7684\u66f4\u65b0</p> Python<pre><code>prev_c = f_t * prev_c + i_t * g_t\n</code></pre> <p>\u6709\u4e86 <code>prev_c</code>\u4ee5\u540e\u5c31\u80fd\u8ba1\u7b97 <code>prev_h</code></p> <p></p> <ul> <li> <p>\\(prev_h\\) \u5c31\u662f\u5f53\u524d\u65f6\u523b LSTM\u7684\u8f93\u51fa </p> </li> <li> <p>\u6309\u7167\u516c\u5f0f \u5c31\u662f \\(\u8f93\u51fa\u95e8 \u00d7 tanh \u7ec6\u80de\u72b6\u6001\\)</p> </li> </ul> Python<pre><code>prev_h = o_t * torch.tanh(prev_c)\n</code></pre> <p>\u4ee5\u4e0a\u662f\u5bf9 \\(c\\)\u548c \\(h\\) \u7684\u66f4\u65b0</p> <p>\u6709\u4e86 \\(h\\)\u4ee5\u540e\uff0c\u5c31\u53ef\u4ee5\u5bf9<code>\u8f93\u51fa\u77e9\u9635</code>\u4e5f\u66f4\u65b0\u4e00\u4e0b\uff0c\u628a\u6bcf\u4e00\u65f6\u523b\u7684\u9690\u85cf\u5c42\u72b6\u6001\u5b58\u50a8\uff0c\u5b58\u5230 <code>output \u77e9\u9635</code>\u4e2d\uff1a</p> Python<pre><code>output[:,t,:] = prev_h\n</code></pre> <p>\u4ee5\u4e0a\u662f\u6240\u6709\u81ea\u5b9a\u4e49 LSTM \u51fd\u6570\u7684\u5b9e\u73b0</p> <p>\u73b0\u5728\u8fd4\u56de\uff1a</p> <ul> <li>\u7b2c\u4e00\u4e2a\u8fd4\u56de\u503c\u662f \u8f93\u51fa\u5e8f\u5217</li> <li>\u7b2c\u4e8c\u4e2a\u8fd4\u56de\u503c\u662f\u4e24\u4e2a\u72b6\u6001 \u6784\u6210\u7684\u5143\u7ec4\uff0c\u8fd9\u4e24\u4e2a\u72b6\u6001\u5206\u522b\u662f <code>\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u8f93\u51fa</code> \u548c  <code>\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u7ec6\u80de\u72b6\u6001</code></li> </ul> Python<pre><code>return output,(prev_h,prev_c)\n</code></pre> <p></p> <p>\u4ee5\u4e0a\u662f\u4e0d\u5e26 projection\u7684\u81ea\u5b9a\u4e49LSTM</p> <p>\u63a5\u4e0b\u6765\u6d4b\u8bd5</p> <p>\u6d4b\u8bd5\u5c31\u662f\u628a <code>LSTM layer</code>\u7684<code>4</code>\u4e2a\u53c2\u6570\u53d6\u51fa\u6765\uff0c\u7136\u540e\u5582\u5165\u5230\u81ea\u5b9a\u4e49 LSTM\u51fd\u6570\u4e2d\uff0c\u7136\u540e\u5bf9\u6bd4\u7ed3\u679c</p> <p>\uff081\uff09\u5b9e\u4f8b\u5316LSTM \u7b97\u5b50\uff0c\u4f20\u5165<code>input parameters</code></p> <p>\u9996\u5148\u628a\u51fd\u6570\u7b7e\u540d\u590d\u5236\u4e0b\u6765\uff1a</p> <p></p> <ul> <li><code>input</code>\u8fd8\u662f<code>input</code></li> <li><code>initial state</code>\u5c31\u662f<code>h0</code>\u548c<code>c0</code>\uff0c\u5c31\u662f\u4e4b\u524d\u521d\u59cb\u5316\u7684<code>h0</code>\u548c<code>c0</code></li> </ul> Python<pre><code>lstm_forward(input,(h0,c0),w_ih,w_hh,b_ih,b_hh)\n</code></pre> <ul> <li><code>w_ih</code>\u5c31\u7528\u4e4b\u524dpytorch\u4e2d\u5b9e\u4f8b\u5316\u7684<code>lstm layer</code>\u7684\u53c2\u6570\u62ff\u51fa\u6765</li> </ul> <p></p> <p>\u5c31\u662f<code>lstm_layer.\u53c2\u6570</code></p> <p></p> <p>\u5373\uff0c</p> Text Only<pre><code>lstm_forward(input,(h0,c0),lstm_layer.weight_ih_l0,w_hh,b_ih,b_hh)\n</code></pre> <p><code>w_hh</code>\u4e5f\u662f\u4e00\u6837\u7684\uff0c\u540e\u9762\u8fd8\u6709\u4e24\u4e2a\u504f\u7f6e\uff0c\u6700\u540e\u5b9e\u4f8b\u5316\u7684\u81ea\u5b9a\u4e49 LSTM \u51fd\u6570\uff1a</p> Python<pre><code>lstm_forward(input,\n             (h0,c0),\n             lstm_layer.weight_ih_l0,\n             lstm_layer.weight_hh_l0,\n             lstm_layer.bias_ih_l0,\n             lstm_layer.bias_hh_l0)\n</code></pre> <p>\u5b9e\u4f8b\u5316\u597d\u81ea\u5b9a\u4e49 LSTM \u7b97\u5b50\u4ee5\u540e\uff0c\u5b9a\u4e49\u53d8\u91cf\u63a5\u6536\u8f93\u51fa</p> <p>\u590d\u5236\u524d\u9762\u7684\u53d8\u91cf\u540d\uff0c\u52a0\u540e\u7f00 custom</p> <p></p> <p>\u52a0\u540e\u7f00 custom\uff0c\u8868\u793a\u81ea\u5b9a\u4e49\u7684LSTM</p> Python<pre><code>output_custom,(h_finall_custom,c_finall_custom) = lstm_forward(\n    input,\n    (h0,c0),      \n    lstm_layer.weight_ih_l0,\n    lstm_layer.weight_hh_l0,\n    lstm_layer.bias_ih_l0,\n    lstm_layer.bias_hh_l0)\n</code></pre> <p>\u63a5\u4e0b\u6765\u5bf9\u6bd4\u524d\u9762\u7684 <code>output</code> \u548c\u81ea\u5b9a\u4e49\u5b9e\u73b0\u7684 <code>output_custom</code>\uff0c\u67e5\u770b\u662f\u4e0d\u662f\u4e00\u81f4\u7528<code>torch.allclose()</code></p> Python<pre><code>print(torch.allclose(output,output_custom))\nprint(torch.allclose(h_finall,h_finall_custom))\nprint(torch.allclose(c_finall,c_finall_custom))\n</code></pre> <p>\u8f93\u51fa\u4e09\u4e2aTrue</p>"},{"location":"learning/14_LSTM/#lstm_4","title":"LSTM \u5168\u90e8\u4ee3\u7801","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n</code></pre> Python<pre><code># \u5b9a\u4e49\u5e38\u91cf\nbs,T,i_size,h_size = 2,3,4,5\n# proj_size\ninput = torch.randn(bs,T,i_size) # \u8f93\u5165\u5e8f\u5217\nc0 = torch.randn(bs,h_size)  # \u521d\u59cb\u503c\u4e0d\u9700\u8981\u8bad\u7ec3\nh0 = torch.randn(bs,h_size)\n</code></pre> Python<pre><code># \u8c03\u7528\u5b98\u65b9LSTM API\nlstm_layer = nn.LSTM(i_size,h_size,batch_first=True)\noutput,(h_finall,c_finall) = lstm_layer(input,(h0.unsqueeze(0),c0.unsqueeze(0)))\n\nfor k,v in lstm_layer.named_parameters():\n    print(k,v.shape)\n</code></pre> <p>OUT\uff1a</p> Text Only<pre><code>weight_ih_l0 torch.Size([20, 4])\nweight_hh_l0 torch.Size([20, 5])\nbias_ih_l0 torch.Size([20])\nbias_hh_l0 torch.Size([20])\n</code></pre> Python<pre><code># \u81ea\u5df1\u5199\u4e00\u4e2aLSTM\ndef lstm_forward(input,initial_states,w_ih,w_hh,b_ih,b_hh):\n    # \u4ee5\u4e0a\u5199\u597d\u4e86 \u51fd\u6570\u7b7e\u540d\n    h0,c0 = initial_states #\u521d\u59cb\u72b6\u6001\n    bs,T,i_size = input.shape\n    h_size = w_ih.shape[0] // 4\n\n    prev_h = h0\n    prev_c = c0\n    batch_w_ih = w_ih.unsqueeze(0).tile(bs,1,1)\n    batch_w_hh = w_hh.unsqueeze(0).tile(bs,1,1)\n\n    output_size = h_size\n    output = torch.zeros(bs,T,output_size) # \u8f93\u51fa\u5e8f\u5217\n\n    for t in range(T):\n        x = input[:,t,:]  # \u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u5411\u91cf\uff0c[bs,i_size]\n\n        w_times_x = torch.bmm(batch_w_ih,x.unsqueeze(-1))  #[bs,4*h_size,1]\n        w_times_x = w_times_x.squeeze(-1)  # [bs,4*h_size]\n\n        w_times_h_prev = torch.bmm(batch_w_hh,prev_h.unsqueeze(-1))  #[bs,4*h_size,1]\n        w_times_h_prev = w_times_h_prev.squeeze(-1)  # [bs,4*h_size]\n\n        # \u5206\u522b\u8ba1\u7b97 \u8f93\u5165\u95e8(i)\uff0c\u9057\u5fd8\u95e8(f)\uff0ccell\u95e8(g)\uff0c\u8f93\u51fa\u95e8(o)\n        i_t = torch.sigmoid(w_times_x[:,:h_size] + w_times_h_prev[:,:h_size]+b_ih[:h_size]+b_hh[:h_size])\n        f_t = torch.sigmoid(w_times_x[:,h_size:2*h_size] + w_times_h_prev[:,h_size:2*h_size]+\n                            b_ih[h_size:2*h_size]+b_hh[h_size:2*h_size])\n        g_t = torch.tanh(w_times_x[:,2*h_size:3*h_size] + w_times_h_prev[:,2*h_size:3*h_size]+\n                            b_ih[2*h_size:3*h_size]+b_hh[2*h_size:3*h_size])\n        o_t = torch.sigmoid(w_times_x[:,3*h_size:4*h_size] + w_times_h_prev[:,3*h_size:4*h_size]+\n                            b_ih[3*h_size:4*h_size]+b_hh[3*h_size:4*h_size])\n\n\n        prev_c = f_t * prev_c + i_t * g_t\n        prev_h = o_t * torch.tanh(prev_c)\n\n        output[:,t,:] = prev_h\n\n    return output,(prev_h,prev_c)\n\noutput_custom,(h_finall_custom,c_finall_custom) = lstm_forward(input,(h0,c0),lstm_layer.weight_ih_l0,\n                                                               lstm_layer.weight_hh_l0,\n                                                               lstm_layer.bias_ih_l0,lstm_layer.bias_hh_l0)\n</code></pre> Python<pre><code>print(torch.allclose(output,output_custom))\nprint(torch.allclose(h_finall,h_finall_custom))\nprint(torch.allclose(c_finall,c_finall_custom))\n</code></pre> <p>OUT\uff1a</p> Text Only<pre><code>True\nTrue\nTrue\n</code></pre>"},{"location":"learning/14_LSTM/#lstmp","title":"LSTMP","text":"<p>\u8981\u89e3\u51b3\u7684\u95ee\u9898\uff1a</p> <ul> <li>\u4ec0\u4e48\u662f <code>projection</code>\u5462</li> <li>\u5982\u679c\u8981\u5199 <code>projection</code>\uff0c\u9700\u8981\u600e\u4e48\u6539\u9020\uff1f</li> </ul>"},{"location":"learning/14_LSTM/#api-lstmp","title":"\u5b98\u65b9 api\u5b9e\u73b0 LSTMP","text":"<p>\u6ce8\u610f\u770b\u53c2\u6570\u53d8\u5316</p> <p>\u8c03\u7528\u5b98\u65b9 api \u9700\u8981\u52a0\u4e00\u4e2a\u91cf <code>proj_size</code></p> <p><code>proj size</code> \u7b49\u4e8e\u591a\u5c11\u5462\uff1f</p> <p></p> <p>\u4e00\u822c <code>projection size</code>\u6bd4<code>hidden size</code>\u5c0f</p> <p>\u5373\u8981\u5bf9<code>hidden state</code>\u8fdb\u884c\u538b\u7f29\uff0c \u538b\u7f29\u80af\u5b9a\u662f\u8981\u5f80\u5c0f\u7684\u7ef4\u5ea6\u538b\u7f29</p> <p>\u5982\u679c<code>hidden size</code>\u7b49\u4e8e<code>5</code>\u7684\u8bdd\uff0c\u90a3<code>projection size</code>\u5c31\u8bbe\u7f6e\u6210<code>3</code>\uff0c\u6bd4<code>hidden size</code>\u5c0f\u4e00\u70b9\u5c31\u597d\uff0c\u4ee5\u4e0a\u5b9e\u73b0\u4e86 <code>projection layer</code></p> <p></p> <p>\u73b0\u5728\u518d\u6765\u770b <code>lstm layer</code>\u7684\u53c2\u6570\u8f93\u51fa</p> <p>\u4f20\u5165<code>proj size</code>\u4ee5\u540e\uff0c\u8fd8\u8981\u6539\u53d8<code>h0</code></p> <p>\u56e0\u4e3a\u5982\u679c<code>LSTM</code>\u5e26\u4e86<code>projection</code>\u7684\u8bdd</p> <p>\u5219<code>h</code>\u5b9e\u9645\u4e0a\u662f\u8981\u538b\u7f29\u7684\uff0c\u7ef4\u5ea6\u4e0d\u518d\u662f<code>h_size</code>\uff1b\u800c\u662f<code>projection_size</code>\uff0c\u6240\u4ee5 <code>h_0</code>\u4e5f\u8981\u6539\u4e00\u4e0b  </p> <p><code>projection</code>\u7684\u4f5c\u7528\u5b9e\u9645\u4e0a\u5c31\u662f\u5bf9 <code>h0</code>\u8fdb\u884c\u4e00\u4e2a\u538b\u7f29\uff0c\u63a5\u4e0b\u6765\u67e5\u770b\u6a21\u578b\u53c2\u6570\uff1a</p> <p></p> <p>\u76f8\u6bd4\u4e8e<code>lstm</code>\uff0c<code>lstmp</code>\u591a\u4e86\u4e00\u4e2a\u7ed3\u679c\uff1a<code>weight_hr_l0</code> \uff0c \u8fd9\u4e2a\u53c2\u6570\u5c31\u662f\u5bf9 <code>hidden state</code> \u8fdb\u884c\u538b\u7f29</p> <p><code>hidden state</code>\u7684\u5927\u5c0f\u5b9e\u9645\u53d8\u6210\u4e86<code>3</code>\uff0c\u4e0d\u518d\u662f<code>5</code></p> <p>\u63a5\u4e0b\u6765\uff0c\u6253\u5370<code>output.shape</code>\u548c<code>h_finall.shape</code>\u3001<code>c_finall.shape</code></p> <p></p> <p>\u53ef\u4ee5\u770b\u5230<code>lstmp</code>\u7684<code>output shape</code>\u662f<code>2\u00d72\u00d73</code>\u7684\uff0c\u4e0d\u662f <code>2\u00d73\u00d75</code> \uff0c\u56e0\u4e3a\u5bf9\u8f93\u51fa\u8fdb\u884c\u4e86\u538b\u7f29</p> <p><code>h_finall</code>\u548c<code>c_finall</code>\u5206\u522b\u662f <code>1\u00d72\u00d73</code> \u548c <code>1\u00d72\u00d75</code>\u7684</p> <p>\u53ef\u4ee5\u770b\u5230 <code>h_finall</code>\u7684\u5927\u5c0f\u4e5f\u53d8\u6210\u4e86<code>3</code>\uff0c\u4f46\u662f<code>c</code>\u7684\u5927\u5c0f\u4ecd\u7136\u662f<code>5</code></p> <p>\u7406\u7531\uff1a\u53ea\u5bf9\u8f93\u51fa\u8fdb\u884c\u4e86\u538b\u7f29\uff0c\u4e0d\u4f1a\u5bf9\u7ec6\u80de\u72b6\u6001\u8fdb\u884c\u538b\u7f29</p> <p>\u4ee5\u4e0a\u662fprojection\u7684\u539f\u7406\uff0c</p>"},{"location":"learning/14_LSTM/#lstmp_1","title":"\u81ea\u5b9a\u4e49 LSTMP \u4ee3\u7801\u5b9e\u73b0","text":"<p>\u63a5\u4e0b\u6765\u4fee\u6539\u81ea\u5b9a\u4e49\u51fd\u6570\uff1a</p> <p>\u591a\u4e86\u4e00\u4e2a<code>projection</code>\u53c2\u6570\uff0c\u6240\u4ee5\u7b7e\u540d\u4e2d\u52a0\u5165<code>w_hr</code> \u5e76\u4e14\u8bbe\u7f6e\u9ed8\u8ba4\u4e3a<code>None</code></p> <p></p> <ul> <li>\u5982\u679c\u662f<code>None</code>\u7684\u8bdd\uff0c\u5c31\u662f\u4e00\u4e2a\u666e\u901a\u7684<code>lstm</code></li> <li>\u5982\u679c\u4e0d\u662f<code>None</code> \u5c31\u662f\u5e26\u6709<code>projection</code>\u7684</li> </ul> <p>\u65b0\u52a0\u5165\u53c2\u6570\u4ee5\u540e\uff0c\u540e\u7eed\u9700\u8981\u505a\u54ea\u4e9b\u4fee\u6539\u5462\uff1f</p> <p>\u9996\u5148\u5bf9<code>output size</code>\u505a\u4e00\u4e2a\u5224\u65ad\uff0c\u5982\u679c\u6709<code>projection size</code>\uff0c<code>output size</code> \u5c31\u4e0d\u662f <code>h size</code></p> Python<pre><code>if w_hr is not None:\n</code></pre> <p>\u8981\u5224\u65ad\uff0c\u9996\u5148\u9700\u8981\u627e\u5230<code>projection size</code>\uff0c\u7b80\u5199\u4e3a<code>p_size</code>\uff1a</p> Python<pre><code>p_size,_ = w_hr.shape[0]\n</code></pre> <p>\u5b83\u662f<code>w_hr</code>\u7684\u7b2c<code>0</code>\u7ef4</p> <p></p> <p>\u7ea2\u6846\u5c31\u662f<code>projection size</code>\uff0c\u7136\u540e <code>output size</code>\u7b49\u4e8e <code>p_size</code></p> Python<pre><code>output_size = p_size\n</code></pre> <p>\u5982\u679c <code>else</code>\u7684\u8bdd\uff0c<code>output size</code>\u5c31\u7b49\u4e8e <code>h size</code></p> Python<pre><code>else:\n    output_size = h_size\n</code></pre> <p>\u5168\u90e8\u7684\u4ee3\u7801\uff1a</p> <p></p> <p>\u4ee5\u4e0a\u662f\u5f15\u5165<code>projection</code>\u4ee5\u540e\u505a\u7684\u6539\u53d8</p> <p>\u53e6\u5916 <code>w_hr</code>\uff0c\u540c\u6837\u8981\u5f15\u5165<code>batch</code>\u7684\u7ef4\u5ea6 </p> <p></p> <p>\u540c\u6837\u5f15\u5165<code>batch</code>\u7684\u7ef4\u5ea6\uff0c\u4f46\u662f\u8fd9\u65f6\u5019\uff0c\u5f62\u72b6\u5c31\u662f <code>bs\u00d7p_size \u00d7h_size</code></p> <p></p> <p>\u8fd9\u662f\u5bf9<code>output size</code>\u505a\u7684\u53d8\u66f4</p> <p>\u56e0\u4e3a\u5f15\u5165\u4e86<code>projection</code>\uff0c\u6240\u4ee5<code>output</code>\u5927\u5c0f\u662f\u53d8\u5c0f\u4e86</p> <p>\u90a3\u4e48\u63a5\u4e0b\u6765\u8981\u53d8\u66f4\u54ea\u91cc\u5462\uff1f</p> <ul> <li>\u73b0\u5728\u5f15\u5165\u4e86<code>projection</code>\u4e4b\u540e\uff0c\u8fd9\u91cc\u7684<code>hidden_size</code>\u662f\u53d8\u5c0f\u7684\uff0c\u5df2\u7ecf\u53d8\u6210\u4e86 <code>projection_size</code></li> <li>\u4e5f\u5c31\u662f\u8bf4 <code>w_times_h_prev</code>\u5927\u5c0f\u4ecd\u7136\u662f\uff1a<code>bs\u00d74\u500d\u7684hidden size</code></li> </ul> <p>\u4f46\u5b83\u662f\u600e\u4e48\u5f97\u5230\u5462\uff1f</p> <ul> <li>\u5b83\u662f \\(batch\\_w\\_hh\\) (<code>bs\u00d74\u500d\u7684hidden size\u518d\u4e58\u4ee5p size</code>)\uff0c\u518d\u8ddf \\(prev\\_h\\) <code>(p_size</code>)\u8fdb\u884c\u76f8\u4e58\uff0c\u7136\u540e<code>p_size</code>\u8fd9\u4e2a\u7ef4\u5ea6\u5c31\u6d88\u6389\u4e86</li> <li>\u6700\u7ec8\uff0c\u5f97\u5230 \\(\\mathrm{batch\\_size \u00d7 4*hidden\\_size}\\) </li> </ul> <p></p> <ul> <li><code>batch_w_hh.shape = torch.Size([2, 20, 3])</code></li> <li><code>prev_h.shape = torch.Size([2, 3])</code></li> <li> <p><code>w_times_h_prev.shape = torch.Size([2, 20, 1])</code> </p> </li> <li> <p><code>h_size = 5</code></p> </li> <li><code>bs = 2</code></li> <li><code>proj_size = 3</code></li> </ul> <p>\u5982\u679c\u5f15\u5165\u4e86 <code>projection</code>\uff0c\u9700\u8981\u5728\u5f97\u5230\u7684<code>prev_h</code>\u8fd9\u91cc\uff0c\u8fdb\u884c\u538b\u7f29</p> <p></p> <p>\u73b0\u5728 <code>prev_h</code>\u8fd9\u91cc\uff0c\u5927\u5c0f\u662f <code>bs\u00d7h_size</code></p> <p>\u4f46\u8f93\u51fa\u7684<code>h</code> \u8981\u662f <code>p_size</code>\u7684\uff0c\u6240\u4ee5 \u8981\u8fdb\u884c\u4e00\u4e2a\u538b\u7f29</p> <p></p> <p>\u540c\u6837\uff0c\u5982\u679c <code>w_hr</code>\u4e0d\u662f<code>None</code>\u7684\u8bdd\uff0c\u5c31\u8981\u505a<code>projection</code>\uff0c\u8981\u5bf9 <code>prev_h</code>\u8fdb\u884c\u4e00\u4e2a\u538b\u7f29</p> <p>\u538b\u7f29\u539f\u7406\u4ecd\u7136\u662f\u7528\uff0c\u77e9\u9635\u76f8\u4e58\u7684\u7b97\u6cd5</p> <p>\u7528\u538b\u7f29\u77e9\u9635 <code>w_hr</code>\u8ddf<code>prev_h</code>\u76f8\u4e58\uff0c\u9700\u8981\u5bf9 <code>prev_h</code>\u8fdb\u884c\u6269\u4e00\u7ef4\uff0c\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u6269\u4e00\u7ef4</p> Python<pre><code>if w_hr is not None:# \u505aprojection\n    prev_h = torch.bmm(batch_w_hr,prev_h.unsqueeze(-1))\n</code></pre> <p>\u8fd9\u6837 <code>prev_h</code>\u7684\u7ef4\u5ea6\u5c31\u53d8\u6210\u4e86 <code>bs\u00d7p_size\u00d71</code></p> <p>\u628a\u8fd9\u4e2a<code>1</code>\uff0c\u6700\u540e\u518d\u53bb\u6389</p> Python<pre><code>if w_hr is not None:# \u505aprojection\n    prev_h = torch.bmm(batch_w_hr,prev_h.unsqueeze(-1)) \n    # [bs,p_size,1]\n    prev_h = prev_h.squeeze(-1) # bs\u00d7 p_size\n</code></pre> <p>\u4ee5\u4e0a\u5b9e\u73b0\u4e86<code>projection</code></p> <p><code>lstm projection</code>\u7684\u539f\u7406\uff0c\u4f1a\u5bf9\u8f93\u51fa\u72b6\u6001\u8fdb\u884c\u4e00\u4e2a\u538b\u7f29\uff0c\u7136\u540e\u6574\u4e2a <code>output</code>\u7684\u7ef4\u5ea6\u5c31\u53d8\u5c0f\u4e86\uff0c\u53e6\u5916\u5f15\u5165<code>projection</code>\uff0c\u6574\u4e2a\u8ba1\u7b97\u91cf\u90fd\u662f\u53d8\u5c0f\u7684</p> <p></p> <ul> <li>batch_w_hh\uff1a<code>batch size\u00d7 4\u500d\u7684hidden size\u00d7 hidden size</code></li> </ul> <p>\u2192 \u53d8\u6210\u4e86 <code>4\u500d\u7684hidden_size \u00d7 p_size</code></p> <ul> <li> <p>\u6240\u4ee5\u5b83\u7684\u53c2\u6570\u6570\u76ee\u662f\u964d\u4f4e\u7684\uff0c\u8fd0\u7b97\u91cf\u662f\u964d\u4f4e\u7684</p> </li> <li> <p>\u53e6\u5916  <code>prev_c</code>\u7684\u7ef4\u5ea6\u662f<code>\u6ca1\u6709\u53d8</code>\u5f97\uff0c\u4ecd\u7136\u662f <code>hidden_size</code></p> </li> <li> <p>\u4f46\u662f<code>prev_h</code>\u7684\u7ef4\u5ea6\u662f<code>\u964d\u4f4e</code>\u7684</p> </li> </ul> <p>\u4ee5\u4e0a\u5728\u81ea\u5b9a\u4e49\u7684 <code>lstm forward</code> \u5f15\u5165\u4e86 <code>projection</code></p> <p>\u63a5\u4e0b\u6765\u7ee7\u7eed\u6d4b\u8bd5\uff0c\u5e76\u4e14\u628a <code>weight_hr_l0</code>\u4f20\u5165\u8fdb\u6765\uff0c\u5f97\u5230<code>\u5e26\u6709projection\u7684\u81ea\u5b9a\u4e49\u51fd\u6570</code></p> <p>\u63a5\u4e0b\u6765\u8fdb\u884c\u6d4b\u8bd5\uff0c\u67e5\u770b\u7ed3\u679c\u662f\u5426\u4e00\u81f4\u3002</p> <p><code>lstmp</code> \u7b80\u5355\u6765\u8bf4\uff1a</p> <ul> <li>\u5bf9\u8f93\u51fa\u7684\u72b6\u6001\uff0c\u4e5f\u5c31\u662f<code>prev_h</code>\u8fdb\u884c\u538b\u7f29\uff0c\u4f7f\u5f97\u6574\u4e2aLSTM\u7f51\u7edc\uff0c\u8fd0\u7b97\u91cf\u548c\u53c2\u6570\u91cf\u90fd\u6709\u51cf\u5c0f</li> <li>\u4e3b\u8981\u662f<code>w_hh</code> \u6743\u91cd\u7684\u7ef4\u5ea6\u662f\u6709\u964d\u4f4e\u7684\uff0c\u8fd0\u7b97\u91cf\u4e5f\u662f\u51cf\u5c11\u7684</li> </ul>"},{"location":"learning/14_LSTM/#lstmp_2","title":"LSTMP\u7684\u5168\u90e8\u4ee3\u7801","text":"Python<pre><code># \u5b9a\u4e49\u5e38\u91cf\nbs,T,i_size,h_size = 2,3,4,5\nproj_size = 3\ninput = torch.randn(bs,T,i_size) # \u8f93\u5165\u5e8f\u5217\nc0 = torch.randn(bs,h_size)  # \u521d\u59cb\u503c\u4e0d\u9700\u8981\u8bad\u7ec3\nh0 = torch.randn(bs,proj_size)\n</code></pre> Python<pre><code># \u8c03\u7528\u5b98\u65b9LSTM API\nlstm_layer = nn.LSTM(i_size,h_size,batch_first=True,proj_size = proj_size)\noutput,(h_finall,c_finall) = lstm_layer(input,(h0.unsqueeze(0),c0.unsqueeze(0)))\n\nprint(output.shape,h_finall.shape,c_finall.shape)\n\nfor k,v in lstm_layer.named_parameters():\n    print(k,v.shape)\n</code></pre> Text Only<pre><code>torch.Size([2, 3, 3]) torch.Size([1, 2, 3]) torch.Size([1, 2, 5])\nweight_ih_l0 torch.Size([20, 4])\nweight_hh_l0 torch.Size([20, 3])\nbias_ih_l0 torch.Size([20])\nbias_hh_l0 torch.Size([20])\nweight_hr_l0 torch.Size([3, 5])\n</code></pre> Python<pre><code># \u81ea\u5df1\u5199\u4e00\u4e2aLSTM\ndef lstm_forward(input,initial_states,w_ih,w_hh,b_ih,b_hh,w_hr=None):\n    # \u4ee5\u4e0a\u5199\u597d\u4e86 \u51fd\u6570\u7b7e\u540d\n    h0,c0 = initial_states #\u521d\u59cb\u72b6\u6001\n    bs,T,i_size = input.shape\n    h_size = w_ih.shape[0] // 4\n\n    prev_h = h0\n    prev_c = c0\n    batch_w_ih = w_ih.unsqueeze(0).tile(bs,1,1)\n    batch_w_hh = w_hh.unsqueeze(0).tile(bs,1,1)\n\n    if w_hr is not None:\n        p_size = w_hr.shape[0]\n        output_size = p_size\n        batch_w_hr = w_hr.unsqueeze(0).tile(bs,1,1)  # [bs,p_size,h_size]\n    else:\n        output_size = h_size\n\n    output = torch.zeros(bs,T,output_size) # \u8f93\u51fa\u5e8f\u5217\n\n    for t in range(T):\n        x = input[:,t,:]  # \u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u5411\u91cf\uff0c[bs,i_size]\n\n        w_times_x = torch.bmm(batch_w_ih,x.unsqueeze(-1))  #[bs,4*h_size,1]\n        w_times_x = w_times_x.squeeze(-1)  # [bs,4*h_size]\n\n        w_times_h_prev = torch.bmm(batch_w_hh,prev_h.unsqueeze(-1))  #[bs,4*h_size,1]\n        w_times_h_prev = w_times_h_prev.squeeze(-1)  # [bs,4*h_size]\n\n        # \u5206\u522b\u8ba1\u7b97 \u8f93\u5165\u95e8(i)\uff0c\u9057\u5fd8\u95e8(f)\uff0ccell\u95e8(g)\uff0c\u8f93\u51fa\u95e8(o)\n        i_t = torch.sigmoid(w_times_x[:,:h_size] + w_times_h_prev[:,:h_size]+b_ih[:h_size]+b_hh[:h_size])\n        f_t = torch.sigmoid(w_times_x[:,h_size:2*h_size] + w_times_h_prev[:,h_size:2*h_size]+\n                            b_ih[h_size:2*h_size]+b_hh[h_size:2*h_size])\n        g_t = torch.tanh(w_times_x[:,2*h_size:3*h_size] + w_times_h_prev[:,2*h_size:3*h_size]+\n                            b_ih[2*h_size:3*h_size]+b_hh[2*h_size:3*h_size])\n        o_t = torch.sigmoid(w_times_x[:,3*h_size:4*h_size] + w_times_h_prev[:,3*h_size:4*h_size]+\n                            b_ih[3*h_size:4*h_size]+b_hh[3*h_size:4*h_size])\n\n\n        prev_c = f_t * prev_c + i_t * g_t\n        prev_h = o_t * torch.tanh(prev_c)\n\n        if w_hr is not None: # \u505aprojection\n            prev_h = torch.bmm(batch_w_hr,prev_h.unsqueeze(-1)) # [bs,p_size,1]\n            prev_h = prev_h.squeeze(-1) # bs\u00d7 p_size\n\n\n        output[:,t,:] = prev_h\n\n    return output,(prev_h,prev_c)\n\noutput_custom,(h_finall_custom,c_finall_custom) = lstm_forward(input,(h0,c0),lstm_layer.weight_ih_l0,\n                                                               lstm_layer.weight_hh_l0,\n                                                               lstm_layer.bias_ih_l0,lstm_layer.bias_hh_l0,\n                                                               lstm_layer.weight_hr_l0)\n</code></pre> Python<pre><code>print(torch.allclose(output,output_custom))\nprint(torch.allclose(h_finall,h_finall_custom))\nprint(torch.allclose(c_finall,c_finall_custom))\n</code></pre> Text Only<pre><code>True\nTrue\nTrue\n</code></pre>"},{"location":"learning/15_CausualConv/","title":"\u56e0\u679c\u5377\u79ef","text":""},{"location":"learning/15_CausualConv/#_1","title":"\u56e0\u679c\u5377\u79ef","text":"2025-04-18 15:33:402025-09-28 12:54:04 <p> \u7ea6 12 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <ul> <li>\u6269\u5f20\u5377\u79ef+\u56e0\u679c\u5377\u79ef</li> </ul>"},{"location":"learning/16_KAN/","title":"KAN","text":""},{"location":"learning/16_KAN/#kan","title":"KAN","text":"2025-04-18 15:33:402025-09-28 12:54:04 <p> \u7ea6 56 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u7528\u52a8\u753b\u7684\u65b9\u5f0f\u8bb2\u89e3 KAN</p> <p>\u4f20\u7edf\u7684\u795e\u7ecf\u7f51\u7edc\uff1a\u57fa\u4e8e\u901a\u7528\u8fd1\u4f3c\u5b9a\u7406</p> <p>KAN\uff1a\u57fa\u4e8e\u6837\u6761\u51fd\u6570\u8fd1\u4f3c</p> <ul> <li>\u5e38\u6570\u6837\u6761</li> <li>\u7ebf\u6027\u6837\u6761</li> <li>\u4e8c\u6b21\u6837\u6761</li> </ul> <p>\u4e24\u5c42\uff0c\u5bbd\u5ea6\u592a\u5bbd \u2192 \u5806\u53e0\u591a\u5c42</p>"},{"location":"learning/17_1_SENet/","title":"SENet","text":""},{"location":"learning/17_1_SENet/#senet","title":"SENet","text":"2025-04-20 14:04:312025-09-28 12:54:04 <p> \u7ea6 2873 \u4e2a\u5b57  8 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 14 \u5206\u949f</p> <p>\u901a\u9053\u6ce8\u610f\u529b</p> <p>\u8c37\u6b4c\u5b66\u672f\u5f15\u7528\u8d852\u4e07\u6b21</p> <p>\u6df1\u5ea6\u5b66\u4e60\u5728\u5927\u91cf\u6570\u636e\u7684\u57fa\u7840\u4e0a\\\u5728\u9ad8\u7ef4\u7684\u5411\u91cf\u7a7a\u95f4\u6765\u8fdb\u884c\u8ba1\u7b97,\u4ece\u800c\u6765\u6316\u6398\u6570\u636e\u6f5c\u5728\u7684\u6700\u91cd\u8981\u7684\u4e00\u4e2a\u7279\u5f81</p> <p> </p> <ul> <li>\u4f8b\u5982\u53ef\u4ee5\u5b66\u4e60\u4e00\u4e2a\u6a21\u578b,\u6765\u8bc6\u522b\u5c0f\u72d7\u548c\u5c0f\u732b,\u8fd9\u4e2a\u6a21\u578b\u4e00\u5b9a\u662f\u638c\u63e1\u4e86\u732b\u72d7\u6700\u91cd\u8981\u7684\u7279\u5f81,\u8fd9\u6837\u624d\u80fd\u591f\u5c06\u5b83\u4eec\u533a\u5206\u5f00</li> <li>\u6216\u8005\u662f\u5b66\u4e60\u4e00\u4e2a\u6a21\u578b,\u6765\u9884\u6d4b\u672a\u6765\u7684\u5929\u6c14\u72b6\u51b5,\u6a21\u578b\u901a\u8fc7\u5206\u6790\u91cd\u8981\u7684\u7279\u5f81,\u638c\u63e1\u6570\u636e\u7684\u53d8\u5316\u89c4\u5f8b</li> <li>\u901a\u9053\u6ce8\u610f\u529b\u7684\u63d0\u51fa\u5c31\u662f\u4e3a\u4e86\u5e2e\u52a9\u6a21\u578b\u53bb\u5f3a\u8c03\u4e00\u4e9b\u91cd\u8981\u7684\u7279\u5f81,\u5ffd\u7565\u6389\u4e00\u4e9b\u4e0d\u91cd\u8981\u7684\u7279\u5f81</li> <li>\u4f8b\u5982\u8981\u5f3a\u8c03\u8fd9\u4e2a\u5c0f\u732b\u7684\u80e1\u5b50\u7279\u5f81\\\u773c\u775b\u7279\u5f81,\u8fd9\u90fd\u662f\u5c0f\u732b\u7684\u72ec\u7279\u4e4b\u5904</li> <li>\u901a\u9053\u6ce8\u610f\u529b,\u53ef\u4ee5\u628a \u770b\u4e2d\u7684\u67d0\u4e2a\u6307\u6807  \u6743\u91cd\u52a0\u5927,\u4e0d\u611f\u5174\u8da3\u7684\u5730\u65b9\u51cf\u5c0f,\u751a\u81f3\u5ffd\u7565\u6389\u5b83</li> </ul> <p>\u901a\u9053\u6ce8\u610f\u529b\u7684\u7406\u8bba\u57fa\u7840,\u5206\u4e3a\u4e24\u4e2a\u6b65\u9aa4,\u538b\u7f29\u548c\u6fc0\u52b1</p> <p>\u524d\u63d0:\u7ed9\u5b9a\u56fe\u50cf,\u8868\u793a\u5148\u8fdb\u884c\u53d8\u6362,\u8fd9\u4e2a\u53d8\u6362\u53ef\u4ee5\u662f\u7b80\u5355\u7684\u5377\u79ef\u64cd\u4f5c,\u6216\u8005\u662f\u4e00\u4e2a\u7f51\u7edc,\u5b83\u8f93\u51fa\u7684\u7ef4\u5ea6\u662f\u4e00\u4e2aH\u00d7W\u00d7C\u7684\u7279\u5f81,HW\u5206\u522b\u662f\u56fe\u7247\u7684\u9ad8\u548c\u5bbd,C\u662f\u901a\u9053\u7684\u6570\u91cf\u6216\u8005\u8bf4\u662f\u7279\u5f81\u7684\u6570\u91cf</p> <p> </p> <p>(1)\u538b\u7f29:\u4f5c\u8005\u5728\u8fd9\u4e2a\u7a7a\u95f4\u65b9\u5411\u4e0a\u5373H\u00d7W\u8fd9\u4e2a\u5c42\u9762\u4e0a\u8fdb\u884c\u538b\u7f29,\u5c06\u539f\u672cH\u00d7W\u5927\u5c0f\u7684\u56fe\u7247,\u538b\u7f29\u52301\u00d71\u7684\u5927\u5c0f,\u53d8\u62101\u00d71\u00d7C\u7684\u5411\u91cf,\u5728\u6bcf\u4e00\u4e2a\u7279\u5f81\u5bf9\u5e94\u7684\u7a7a\u95f4\u56fe\u4e0a,\u90fd\u8fdb\u884c\u538b\u7f29,\u8fd9\u91cc\u7684\u538b\u7f29\u4f7f\u7528\u7684\u662f\u5e73\u5747\u6c60\u5316,\u5f53\u538b\u7f29\u5b8c\u6210\u4e4b\u540e,\u5c31\u8fdb\u5165\u5230\u4e86\u7b2c\u4e8c\u4e2a\u9636\u6bb5</p> <p>(2)\u6fc0\u52b1:\u9996\u5148\u901a\u8fc7\u4e24\u5c42\u7684\u5168\u8fde\u63a5\u5c42,\u6765\u5b66\u4e60\u901a\u9053\u548c\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u5173\u6027,\u8fd9\u4e24\u5c42\u5168\u8fde\u63a5\u5148\u964d\u7ef4,\u4eceC\u964d\u5230\\(\\frac{C}{r}\\) ,\u518d\u5347\u7ef4</p> <p>\u5148\u964d\u7ef4\u518d\u5347\u7ef4\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387</p> <p>r \u662f\u964d\u7ef4\u7684\u500d\u6570,\u518d\u901a\u8fc7\u4e24\u5c42\u5168\u8fde\u63a5\u4e4b\u540e,\u518d\u901a\u8fc7Sigmoid\u7684\u95e8\u63a7\u673a\u5236,\u6765\u751f\u6210\u6743\u91cd\u8868\u793a</p> <ul> <li>sigmoid\u4f1a\u628a\u6bcf\u4e2a\u6570\u503c\u6620\u5c04\u52300~1\u4e4b\u95f4\u7684\u8303\u56f4\u5185,\u4e00\u4e2a\u5929\u7136\u7684\u6743\u91cd\u751f\u6210\u5668</li> <li>\u8fd8\u6709\u4e00\u70b9\u9700\u8981\u6ce8\u610f,Sigmoid\u51fd\u6570\u662f\u6ca1\u6709\u53c2\u6570\u7684,\u5982\u679c\u8f93\u5165\u4e0d\u53d8\u7684\u8bdd,\u5b83\u751f\u6210\u7684\u6743\u91cd\u4e5f\u662f\u4e0d\u4f1a\u53d8\u5316\u7684,\u6240\u4ee5\u4e3a\u4e86\u589e\u5f3a\u8868\u8fbe\u80fd\u529b,\u901a\u5e38\u548c\u5168\u8fde\u63a5\u5c42\u4e00\u5757\u4f7f\u7528</li> <li>\u4e24\u5c42\u5168\u8fde\u63a5\u5c42\u7684\u53e6\u5916\u4e00\u4e2a\u4f5c\u7528:\u4e3a\u4e86\u53c2\u6570\u5316\u95e8\u63a7\u673a\u5236,\u6700\u540e\u5c06\u5f97\u5230\u7684\u6743\u91cd,\u4e0e\u8f93\u5165\u7684\u7279\u5f81\u56fe\u8fdb\u884c\u76f8\u4e58,\u901a\u9053\u5bf9\u5e94\u76f8\u4e58,\u6bcf\u4e00\u4e2a\u901a\u9053\u90fd\u6709\u5bf9\u5e94\u7684\u6743\u91cd,\u4e0e\u4e4b\u76f8\u4e58,(\u5e7f\u64ad\u64cd\u4f5c), \u5f97\u5230\u8f93\u51fa</li> </ul> \u968f\u624b\u8865\u5145 <p> \u4e24\u5c42\u5168\u8fde\u63a5\u7684\u597d\u5904:  (1)\u51cf\u5c11\u53c2\u6570  (2)\u53c2\u6570\u5316\u95e8\u63a7\u673a\u5236  </p> <p>\u6d41\u7a0b\u56fe </p> <p> </p> <p>(1)\u8f93\u5165X,\u901a\u8fc7\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u63d0\u53d6,\u7136\u540e\u5728\u7a7a\u95f4\u5c42\u9762\u4e0a\u901a\u8fc7\u5e73\u5747\u6c60\u5316\u64cd\u4f5c,\u538b\u7f29\u4e3a\u4e00\u4e2a\\(1\u00d71\u00d7C\\)\u7684\u4e00\u4e2a\u5411\u91cf\u8868\u793a,\u7136\u540e\u8fdb\u5165\u5230\u7eff\u8272\u6846(\u6fc0\u52b1\u7684\u9636\u6bb5)</p> <p>(2)\u9996\u5148\u901a\u8fc7\u4e24\u5c42\u7684\u5168\u8fde\u63a5\u7f51\u7edc,(FC-ReLU-FC),\u5148\u964d\u7ef4\u5230 \\(\\frac{C}{r}\\) ,\u7136\u540e\u518d\u5347\u7ef4\u5230 \\(1\u00d71\u00d7C\\) ,\u4e3a\u4e86\u63d0\u53d6\u901a\u9053\u95f4\u7684\u4f9d\u8d56\u6027\u5173\u7cfb</p> <p>(3)\u7136\u540e\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u4e4b\u540e,\u518d\u63a5 Sigmoid \u51fd\u6570\u751f\u6210\u6743\u91cd\u8868\u793a,\u7136\u540e\u5c06\u751f\u6210\u7684\u6743\u91cd\u4e0e\u4e4b\u524d\u7684\u8f93\u5165\u8fdb\u884c\u76f8\u4e58,\u5bf9\u4e0d\u540c\u7684\u901a\u9053\u8fdb\u884c\u5f3a\u8c03 \u6216\u8005\u6291\u5236,\u8fd9\u5c31\u662f\u901a\u9053\u6ce8\u610f\u529b</p> \u968f\u624b\u8865\u5145:\u62d3\u5c55 <p> \u591a\u5c3a\u5ea6\u901a\u9053\u5efa\u6a21\\\u7a7a\u95f4\u5efa\u6a21\\\u901a\u9053\u7a7a\u95f4\u4ea4\u4e92\u5efa\u6a21  \u5b66\u4e60\u901a\u9053\u6ce8\u610f\u529b,\u4e0d\u80fd\u53ea\u5b66SENet,\u8981\u597d\u597d\u5b66\u522b\u4eba\u7684\u8bba\u6587\u662f\u600e\u4e48\u5e94\u7528\u901a\u9053\u6ce8\u610f\u529b\u7684,\u600e\u4e48\u628a\u5b83\u8fc1\u79fb\u5230\u5176\u4ed6\u9886\u57df\u4e2d\u53bb\u7684,\u5b66\u4e60\u6539\u8fdb\u5b66\u4e60\u8fc1\u79fb  </p>"},{"location":"learning/17_1_SENet/#_1","title":"\u62d3\u5c55","text":"<p>(1)\u6700\u7b80\u5355\u7684\u601d\u8def:\u4e32\u8054</p> <p>\u4e00\u4e2a\u6a21\u5757\u540e\u9762\u7d27\u63a5\u7740\u901a\u9053\u6ce8\u610f\u529b</p> <p>(2)\u538b\u7f29\u5c42\u9762:</p> <p>\u4f5c\u8005\u5728\u538b\u7f29\u90e8\u5206,\u4e5f\u5c31\u662f\u5728\u7a7a\u95f4\u5c42\u9762 \\(H \u00d7 W\\) ,\u5e94\u7528\u5e73\u5747\u6c60\u5316\u64cd\u4f5c,\u83b7\u5f97 \\(1\u00d71\u00d7C\\) \u7684\u901a\u9053\u63cf\u8ff0\u7b26\u8868\u793a</p> <p>\u6709\u4e24\u4e2a\u53ef\u4ee5\u6539\u8fdb\u7684\u65b9\u5411 </p> <ul> <li>\u2460 \u538b\u7f29\u64cd\u4f5c\u5982\u4f55\u538b\u7f29</li> <li>\u2461 \u662f\u5426\u53ef\u4ee5\u5728\u5176\u4ed6\u5c42\u9762\u8fdb\u884c\u538b\u7f29</li> </ul> <p>\u2460 \u538b\u7f29\u64cd\u4f5c</p> <p>\u5e73\u5747\u6c60\u5316\\\u6700\u5927\u6c60\u5316\\\u5377\u79ef,\u90fd\u53ef\u4ee5\u8d77\u5230\u538b\u7f29\u7684\u4f5c\u7528,\u8fd8\u53ef\u4ee5\u4f7f\u7528\u805a\u7c7b\u7b97\u6cd5,\u6216\u8005\u4f7f\u7528\u7ebf\u6027\u5c42,\u6620\u5c04\u5230\u4f4e\u7ef4\u5411\u91cf</p> <p>\u2461\u538b\u7f29\u5c42\u9762</p> <p>\u5728\u8fd9\u4e2aH\u65b9\u5411\u6216\u8005W\u65b9\u5411\u4e0a,\u5355\u72ec\u8fd0\u7528\u6c60\u5316\u64cd\u4f5c</p> <p>\u9664\u4e86\u7a7a\u95f4\u5c42\u9762,\u8fd8\u80fd\u5728C\u65b9\u5411,\u901a\u9053\u65b9\u5411\u4e0a\u5355\u72ec\u5e94\u7528\u6c60\u5316\u64cd\u4f5c</p> <p>\u7a7a\u95f4(H\u00d7W)\u548c\u901a\u9053(C/\u7279\u5f81)\u90fd\u80fd\u591f\u8fd0\u7528\u6c60\u5316\u64cd\u4f5c,\u8fd8\u80fd\u5728\u7a7a\u95f4\u548c\u901a\u9053\u5c42\u9762,\u8054\u5408\u5e94\u7528\u6c60\u5316\u64cd\u4f5c(eg.\\(W\u00d7C\\)/\\(H\u00d7C\\))</p> <p>\u2462 \u6fc0\u52b1\u5c42\u9762:</p> <p>\u4f5c\u8005\u4f7f\u7528\u7684\u662f\u4e24\u5c42\u7684\u5168\u8fde\u63a5\u7f51\u7edc,\u5148\u964d\u7ef4\u5230 \\(\\frac{C}{r}\\) ,\u518d\u5347\u7ea7\u5230\u901a\u9053 \\(C\\),\u5b66\u4e60\u6240\u6709\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u5173\u6027</p> <p>\u6539\u8fdb:(\u901a\u9053\u5efa\u6a21)</p> <p>(1)\u901a\u9053\u65b9\u5411\u7684\u5377\u79ef,\u8fdb\u884c\u5c40\u90e8\u901a\u9053\u5efa\u6a21(?)</p> <p>(2)\u5728\u901a\u9053\u4e0a\u6267\u884c\u6ce8\u610f\u529b,\u8fdb\u884c\u5168\u5c40\u6027\u5efa\u6a21</p> <p>(3)\u5377\u79ef\u548c\u6ce8\u610f\u529b\u4e00\u5757\u4f7f\u7528,\u540c\u65f6\u5efa\u6a21\u5c40\u90e8\u548c\u5168\u5c40\u7684\u901a\u9053\u76f8\u5173\u6027</p> <p>(4)\u4f7f\u7528\u591a\u4e2a\u4e0d\u540c\u5927\u5c0f\u7684\u5377\u79ef,\u5efa\u6a21\u591a\u5c3a\u5ea6\u901a\u9053\u76f8\u5173\u6027</p> <p>\u4ee5\u4e0a\u662f\u538b\u7f29\u548c\u6fc0\u52b1(\u5bf9\u5355\u4e2a\u8f93\u5165\u7684\u6240\u6709\u901a\u9053,\u8fdb\u884c\u52a0\u6743),\u662f\u6a21\u578b\u5c42\u9762,\u4e0b\u9762\u662f\u8f93\u5165\u8f93\u51fa\u5c42\u9762</p> <p>\u6784\u9020\u591a\u4e2a\u8f93\u5165,\u5bf9\u591a\u4e2a\u8f93\u5165\u5206\u522b\u8fdb\u884c\u52a0\u6743,\u6765\u83b7\u5f97\u591a\u5c3a\u5ea6\u7684\u7279\u5f81</p> <p>(1)\u6700\u76f4\u89c2\u7684\u60f3\u6cd5,\u591a\u4e2aSENet,\u901a\u9053\u6ce8\u610f\u529b,\u5e76\u884c,\u5404\u81ea\u6ca1\u6709\u4ea4\u96c6,\u4ec5\u4ece\u8f93\u51fa\u5c42\u9762\u4e0a\u8fdb\u884c\u76f8\u52a0</p> <p> </p> <p>emmm...\u4e0d\u884c,\u6beb\u65e0\u521b\u65b0\u70b9,\u6539\u8fdb\u601d\u8def:</p> <p> </p> <p>(\u4e00)</p> <ul> <li>\u9996\u5148,\u8981\u77e5\u9053\u591a\u4e2a\u8f93\u5165\u7684\u5173\u7cfb\u662f\u4ec0\u4e48</li> <li>input1/input2/input3,\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u4ec0\u4e48</li> <li>\u4e00\u822c\u6765\u8bf4\u5b83\u4eec\u662f\u540c\u4e00\u79cd\u4fe1\u606f\u7684\u4e0d\u540c\u8868\u8fbe\u2460\u901a\u8fc7\u4e09\u4e2a\u4e0d\u540c\u7684\u5168\u8fde\u63a5\u5c42,\u5f97\u5230\u4e09\u4e2a\u4e0d\u540c\u7684\u8868\u793a\u2461\u901a\u8fc7\u4e09\u4e2a\u4e0d\u540c\u5927\u5c0f\u7684\u5377\u79ef\u5c42,\u6765\u83b7\u5f97\u4e09\u79cd\u4e0d\u540c\u5c3a\u5ea6\u7684\u4fe1\u606f;\u540c\u4e00\u79cd\u4fe1\u606f\u7684\u4e0d\u540c\u8868\u8fbe,\u8fd9\u6837\u624d\u66f4\u52a0\u7684\u6709\u610f\u4e49</li> </ul> <p>(\u4e8c)\u538b\u7f29\u9636\u6bb5</p> <p>\u5c06\u4e09\u4e2a\u8f93\u5165\u8fdb\u884c\u76f8\u52a0,\u878d\u5408\u4e86\u591a\u5c3a\u5ea6\u4fe1\u606f\u4e4b\u540e,\u901a\u8fc7\u4e00\u4e2a\u5168\u5c40\u6c60\u5316\u64cd\u4f5c,\u83b7\u5f97\u4e00\u4e2a\u901a\u9053\u63cf\u8ff0\u7b26,\u8868\u793a\u5c06\u5176\u538b\u7f29\u4e3a \\(1\u00d71\u00d7C\\)</p> <p>(\u4e09)</p> <p>\u5728\u6fc0\u52b1\u9636\u6bb5,\u7ee7\u7eed\u7167\u732b\u753b\u864e,\u4e5f\u662f\u901a\u8fc7\u4e24\u5c42\u7684\u5168\u8fde\u63a5\u5c42,\u6765\u5efa\u7acb\u901a\u9053\u4e4b\u95f4\u7684\u5173\u7cfb,\u4f46\u662f\u9700\u8981\u6ce8\u610f,\u5728\u7b2c\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42,\u5148\u5c06C\u964d\u7ef4\u5230 \\(\\frac{C}{r}\\) ,\u4f46\u662f\u5728\u7b2c\u4e8c\u4e2a\u5168\u8fde\u63a5\u5c42,\u5c31\u4e0d\u80fd\u4ec5\u4ec5\u7684\u6062\u590d\u5230C,\u56e0\u4e3a\u6700\u5f00\u59cb\u63a5\u6536\u6709\u4e09\u4e2a\u8f93\u5165,\u4e5f\u5c31\u610f\u5473\u7740\u8981\u4ea7\u751f\u4e09\u4e2a\u6743\u91cd\u624d\u884c,\u6240\u4ee5\u5728\u7b2c\u4e8c\u4e2a\u5168\u8fde\u63a5\u5c42,\u9700\u8981\u5c06\u5b83\u5347\u7ef4\u52303C,\u7136\u540e\u518d\u5728\u901a\u9053\u4e0a\u8fdb\u884c\u5206\u5272\u64cd\u4f5c,\u5e73\u5747\u5206\u5272\u4e3a\u4e09\u4efd,\u7136\u540e\u5206\u522b\u901a\u8fc7Sigmoid\u51fd\u6570\u6765\u751f\u6210\u6743\u91cd\u8868\u793a,\u7136\u540e\u5c06\u6743\u91cd\u4e0e\u5bf9\u5e94\u7684\u4e09\u4e2a\u8f93\u5165\u5206\u522b\u8fdb\u884c\u76f8\u4e58,\u6700\u540e\u518d\u901a\u8fc7\u52a0\u6743\u548c,\u5f97\u5230\u6700\u540e\u7684\u8f93\u51fa</p>"},{"location":"learning/17_1_SENet/#sknet","title":"SKNet","text":"<p>CVPR2019</p> <p>\u53ef\u9009\u62e9\u5377\u79ef\u6838\u7684\u7f51\u7edc</p> <p>\u52a8\u673a:SENet\u53ea\u8fdb\u884c\u5355\u4e00\u5c3a\u5ea6\u7684\u6620\u5c04,\u9650\u5236\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b,\u56e0\u6b64SKNet\u4ece\u591a\u5c3a\u5ea6\u51fa\u53d1,\u591a\u5c3a\u5ea6\u662f\u4e3b\u8981\u52a8\u673a</p> <p>\ud83d\udea9 :\u5f53\u53ea\u6709\u4e00\u4e2a\u8f93\u5165\u7684\u65f6\u5019,\u4e00\u5b9a\u8981\u60f3\u529e\u6cd5\u6784\u9020\u591a\u79cd\u8f93\u5165</p> <p>\u6709\u4e86\u591a\u4e2a\u8f93\u5165,\u6846\u67b6\u4f1a\u66f4\u5bb9\u6613\u642d\u5efa,\u6a21\u5757\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f1a\u66f4\u52a0\u7684\u7075\u6d3b</p> \u968f\u624b\u8865\u5145:\u56de\u987e\u901a\u9053\u6ce8\u610f\u529b <p> \u5206\u4e3a\u538b\u7f29\u548c\u6fc0\u52b1\u4e24\u4e2a\u90e8\u5206,\u53ef\u521b\u65b0\u7684\u5207\u5165\u70b9\u6709\u56db\u79cd,\u5206\u522b\u662f\u76f4\u63a5\u5e94\u7528\u5728\u538b\u7f29\u90e8\u5206\u6216\u8005\u662f\u6fc0\u52b1\u90e8\u5206\u4e0a\u505a\u6539\u8fdb,\u6700\u540e\u662f\u6784\u9020\u591a\u5c3a\u5ea6,SKNet\u5c5e\u4e8e\u6700\u540e\u4e00\u79cd\u6784\u9020\u591a\u5c3a\u5ea6\u7684\u6027\u8d28  </p> <p>SKNet\u7684\u6846\u67b6\u56fe</p> <p>\u4f5c\u8005\u5c06\u5176\u5206\u4e3a\u4e09\u90e8\u5206,\u7b2c\u4e00\u90e8\u5206\u662f\u5206\u5272,\u7b2c\u4e8c\u90e8\u5206\u662f\u878d\u5408,\u7b2c\u4e09\u90e8\u5206\u662f\u9009\u62e9</p> <p> </p> <p>\u9996\u5148\u770b\u7b2c\u4e00\u90e8\u5206,\u5206\u5272</p> <p>\u4f5c\u8005\u901a\u8fc7\u4e24\u4e2a\u4e0d\u540c\u5927\u5c0f\u7684\u5377\u79ef\u6838,\u6765\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81,\u5206\u522b\u662f3\u00d73\u7684\u5377\u79ef\u6838\u548c5\u00d75\u7684\u5377\u79ef\u6838,\u7136\u540e\u5c06\u5b83\u4eec\u7684\u7279\u5f81\u6765\u8fdb\u884c\u76f8\u52a0,\u5bf9\u6bd4 SENet\u4e2d\u53ea\u662f\u7ecf\u8fc7\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u53d8\u6362, \u56e0\u6b64\u76f8\u6bd4SENet,\u672c\u6a21\u578b\u5173\u6ce8\u4e86\u4e0d\u540c\u533a\u57df\u5927\u5c0f\u7684\u4e00\u4e2a\u7a7a\u95f4\u7279\u5f81,\u5728\u4e00\u822c\u60c5\u51b5\u4e0b,\u63d0\u53d6\u591a\u4e2a\u7279\u5f81\u6709\u52a9\u4e8e\u6027\u80fd\u63d0\u9ad8</p> <p>\u5212\u91cd\u70b9\u63d0\u53d6\u591a\u5c3a\u5ea6\u591a\u7279\u5f81/\u81ea\u8eab\u95e8\u63a7</p> <p>\u7b2c\u4e8c\u90e8\u5206\u662f\u878d\u5408</p> <p>\u5bf9\u76f8\u52a0\u540e\u7684\u7279\u5f81U,\u9996\u5148\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\u6765\u538b\u7f29\u7a7a\u95f4\u7279\u5f81,\u6765\u751f\u6210\u901a\u9053\u63cf\u8ff0\u7b26\u8868\u793a,\u4e5f\u5c31\u662f\u8fd9\u4e2aS,\u5bf9\u6bd4\u4e00\u4e0bSENet\u5728\u538b\u7f29\u7a7a\u95f4\u7279\u5f81\u7684\u65f6\u5019,\u6bcf\u4e2a\u7a7a\u95f4\u50cf\u7d20\u70b9\u53ea\u6709\u81ea\u5df1\u7684\u672c\u8eab\u7279\u5f81,\u800cSKNet\u7684\u6bcf\u4e2a\u50cf\u7d20\u70b9,\u5305\u542b\u4e86\u5468\u56f4\u50cf\u7d20\u70b9\u7684\u4fe1\u606f,\u5c31\u662f\u6bd4SENet\u4fe1\u606f\u591a,\u540c\u6837\u5728\u6c60\u5316\u4e4b\u540e,\u4fe1\u606f\u8fd8\u662f\u6bd4 SENet \u591a,\u8fd9\u5c31\u662fSKNet\u7684\u4f18\u70b9,\u7136\u540e\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u6765\u5b66\u4e60\u901a\u9053\u4e4b\u95f4\u7684\u76f8\u5173\u6027,\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387,\u5148\u6682\u65f6\u964d\u7ef4\u4e00\u4e0b,\u5f97\u5230Z</p> <p>\u7b2c\u4e09\u90e8\u5206\u9009\u62e9\u90e8\u5206,\u65e2\u7136\u6709\u9009\u62e9,\u5fc5\u987b\u6709\u6743\u91cd,\u786e\u4fdd\u80fd\u8bc6\u522b\u7279\u5f81\u7684\u91cd\u8981\u6027,\u83b7\u5f97\u6743\u91cd\u7684\u4e3b\u6d41\u51fd\u6570:Sigmoid(\u751f\u62100~1\u5185\u7684\u503c,\u5929\u7136\u7684\u6743\u91cd\u751f\u6210\u5668,\u4f46\u5b83\u662f\u72ec\u7acb\u7684,\u8003\u8651\u4e0d\u5230\u4ea4\u4e92,)  Softmax(\u4f46\u4e0d\u591f\u72ec\u7acb,\u5fc5\u987b\u4f9d\u9760\u5bf9\u6bd4,\u624d\u80fd\u5f97\u5230\u91cd\u8981\u6027),SKNet\u901a\u8fc7\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u5206\u522b\u751f\u6210A\u5411\u91cf\u548cB\u5411\u91cf,\u8fd9\u662f\u4e24\u4e2a\u4e0d\u540c\u7a7a\u95f4\u4e0b\u7684\u901a\u9053\u63cf\u8ff0\u7b26,\u4e3a\u4e86\u8868\u793a\u7279\u5f81\u7684\u76f8\u5bf9\u91cd\u8981\u6027,\u7528softmax\u4e3a\u5b83\u4eec\u5206\u51fa\u9ad8\u4f4e,\u6743\u91cd\u5c31\u5927,\u8868\u793a\u7684\u4fe1\u606f\u5c31\u591a\u4e00\u70b9,\u6743\u91cd\u5c0f\u7684\u8868\u793a\u7684\u4fe1\u606f\u5c31\u5c11\u4e00\u70b9,\u6700\u540e\u5c06\u8fd9\u4e24\u90e8\u5206\u8fdb\u884c\u52a0\u6743\u6c42\u548c.</p> <p>\u6700\u540e,\u4e09\u4e2a\u7b97\u6cd5\u7684\u5bf9\u6bd4,</p> <p>(1)\u7b2c\u4e00\u4e2a\u8001\u7956SENet</p> <p>(2)\u7b2c\u4e8c\u4e2a\u7ee7\u627f\u4ebaSKNet</p> <p>(3)\u81ea\u5b9a\u4e49\u6784\u9020\u7684\u6539\u8fdb\u6a21\u5757</p> <p> </p> <p>\u76f8\u540c\u70b9:\u5206\u5272\\\u878d\u5408\\\u538b\u7f29,\u601d\u60f3\u90fd\u662f\u6784\u9020\u591a\u5c3a\u5ea6,\u7136\u540e\u5728\u7a7a\u95f4\u5c42\u9762\u4e0a\u8fdb\u884c\u538b\u7f29</p> <p>\u770b\u533a\u522b:</p> <ul> <li>SKNet\u901a\u8fc7\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42,FC1\u548cFC2,\u751f\u6210\u4e24\u4e2a\u5b50\u7a7a\u95f4\u4e0b\u7684\u5411\u91cf\u8868\u793a, \\(1\u00d71\u00d7C\\)  \u548c \\(1\u00d71\u00d7C\\) </li> <li>\u81ea\u5b9a\u4e49\u7684\u6a21\u5757:\u5c06\u901a\u9053\u63cf\u8ff0\u7b26\u76f4\u63a5\u5347\u7ef4\u5230\u4e863C,\u505a\u6cd5\u662f\u4e0d\u540c\u7684,\u4f46\u662f\u601d\u60f3\u662f\u4e00\u81f4\u7684</li> <li>SKNet\u901a\u8fc7softmax\u8ba9\u591a\u4e2a\u5c3a\u5ea6\u8fdb\u884c\u5bf9\u6bd4,\u8ba4\u6e05\u81ea\u5df1\u51e0\u65a4\u51e0\u4e24</li> <li>\u81ea\u5b9a\u4e49\u7684\u6a21\u5757:\u5c06\u5b83\u4eec\u5728\u901a\u9053\u4e0a\u8fdb\u884c\u5206\u5272,\u5206\u5272\u4e3a\u4e09\u4e2a\u901a\u9053\u63cf\u8ff0\u7b26,\u8ba9\u5b83\u4eec\u81ea\u5df1\u7ed9\u81ea\u5df1\u4e00\u4e2a\u8bc4\u4ef7,SKNet\u597d\u50cf\u66f4\u6709\u9053\u7406,\u56e0\u4e3a\u5bf9\u6bd4,\u5dee\u8ddd\u662f\u5bf9\u6bd4\u4ea7\u751f\u7684</li> <li>\u57fa\u4e8e\u6b64,\u6539\u8fdb\u81ea\u5b9a\u4e49\u7684\u6a21\u5757:\u8ba9\u591a\u4e2a\u5c3a\u5ea6\u8fdb\u884c\u4ea4\u4e92,\u5728FC\u7684\u4e0b\u9762\u518d\u6b21\u6dfb\u52a0\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42,\u5c31\u53ef\u4ee5\u57283C\u7684\u901a\u9053\u4e4b\u95f4,\u6355\u6349\u5168\u5c40\u7684\u4f9d\u8d56\u6027,\u8d77\u5230\u4e86\u4ea4\u4e92\u4f5c\u7528(\u5168\u8fde\u63a5\u5c42\u4e5f\u53ef\u4ee5\u4ea4\u4e92)</li> <li>\u5f53\u5efa\u6a21\u5b8c\u901a\u9053\u4e4b\u95f4\u4f9d\u8d56\u6027,\u518d\u5206\u5272\u4e3a\u4e09\u4e2a\u901a\u9053\u63cf\u8ff0\u7b26\u8868\u793a,\u8fd9\u6837\u7684\u8fc7\u7a0b\u5c31\u662f\u4e09\u4e2a\u5bf9\u8c61\u5148\u4ea4\u6d41\u4e00\u4e0b,\u518d\u8ba9\u5b83\u4eec\u7ed9\u51fa\u81ea\u5df1\u7684\u8bc4\u4ef7</li> </ul>"},{"location":"learning/17_1_SENet/#cbam","title":"CBAM","text":"<p>\u5377\u79efblock\u6ce8\u610f\u529b\u6a21\u5757</p> <p>ECCV2018</p> <p>\u8865\u5145:SENet 2017\u5e749\u67085\u53f7fabn \u5728 arxiv \u4e0a\u7684</p> <p>ECCV2018\u622a\u7a3f\u65f6\u95f4\u662f2018\u5e743\u670814\u53f7(\u534a\u5e74\u7684\u65f6\u95f4)</p> <p>for us:\u5e73\u65f6\u4e5f\u8981\u591a\u5173\u6ce8\u4e00\u4e0b\u9876\u4f1a\u9876\u520a\u7684\u5f55\u7528\u5217\u8868</p>"},{"location":"learning/17_ManBa/","title":"Mamba","text":""},{"location":"learning/17_ManBa/#mamba","title":"Mamba","text":"2025-04-20 14:04:312025-09-28 12:54:04 <p> \u7ea6 577 \u4e2a\u5b57  57 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p> <p>\u5f15\u5165:</p> <p>(1)\u9996\u5148,\u7cbe\u8bfb\u4e00\u7bc7\u8bba\u6587,\u81f3\u5c11\u9700\u8981\u641e\u61c280%\u7684\u5185\u5bb9,\u5269\u4e0b20%\u7684\u5185\u5bb9,\u9700\u8981\u5728\u4ee3\u7801\u4e2d\u5bfb\u627e\u7b54\u6848</p> <p>(2)\u7b2c\u4e8c\u6b65,\u5df2\u7ecf\u8dd1\u5f97\u901a\u7684\u4ee3\u7801,\u7ecf\u5178\u8bba\u6587\u7684\u4ee3\u7801,\u8dd1\u901a\u76f8\u5bf9\u6765\u8bf4\u8fd8\u662f\u6bd4\u8f83\u5bb9\u6613\u7684</p> <p>(3)\u7b2c\u4e09\u6b65,\u4ee3\u7801\u5403\u900f\u4e8680%,\u81f3\u5c11\u9700\u8981\u5b8c\u6574\u7684debug \u8fc7\u4e00\u6b21</p> <ul> <li>\u81f3\u5c11\u77e5\u9053\u6bcf\u4e2a\u53c2\u6570\u4ee3\u8868\u4ec0\u4e48\u610f\u601d</li> <li>\u81f3\u5c11\u77e5\u9053\u6bcf\u4e2a\u64cd\u4f5c\u524d\u540e\u7684shape</li> </ul> <p>PART02:</p> <p>\u8bfb\u61c2\u8bba\u6587,\u77e5\u9053\u6bcf\u4e2a\u6a21\u5757\u7684\u4f5c\u7528\u662f\u4ec0\u4e48,\u77e5\u9053\u6bcf\u4e00\u4e2a\u6a21\u5757\u7684\u8f93\u5165\u548c\u8f93\u51fa\u662f\u4ec0\u4e48</p> <p>\u63a5\u4e0b\u6765,GITHUB\u628a\u8fd9\u7bc7\u8bba\u6587\u7684\u4ee3\u7801\u4e0b\u8f7d\u5230\u672c\u5730,\u6839\u636e\u4f5c\u8005\u63d0\u4f9b\u7684readme\u6587\u4ef6,\u5b89\u88c5\u76f8\u5e94\u7684\u5305,\u6700\u7ec8\u76ee\u7684\u5c31\u662f\u8ba9\u8fd9\u4e2a\u4ee3\u7801\u987a\u5229\u5730\u8dd1\u8d77\u6765</p> <p>PART03:</p> <p>\u65f6\u7a7a\u6ce8\u610f\u529bblock,\u4e24\u5206\u652f\u7ed3\u6784,\u5de6\u5206\u652f\u662f\u7a7a\u95f4\u6ce8\u610f\u529b,\u53f3\u5206\u652f\u662f\u65f6\u95f4\u6ce8\u610f\u529b,\u7136\u540e\u4e24\u90e8\u5206\u901a\u8fc7\u95e8\u63a7\u878d\u5408\u5355\u5143\u76f4\u63a5\u878d\u5408</p> <p>PART04:</p> <p>\u4ee3\u7801Debug \u7b14\u8bb0,\u8be6\u7ec6\u8bb0\u5f55\u6bcf\u4e2a\u64cd\u4f5c\u524d\u540e\u7279\u5f81\u7684 shape\u7684\u53d8\u5316\u8fc7\u7a0b</p> <p>\u6ce8\u610f,\u5728GITHUB\u4e0a\u4e0b\u8f7d\u7684\u4ee3\u7801\u662f\u5149\u79c3\u79c3\u79c3\u7684,\u6ca1\u6709\u6ce8\u91ca,\u4e00\u5b9a\u8981\u597d\u597d\u8bb0\u7b14\u8bb0</p>"},{"location":"learning/17_ManBa/#_1","title":"\u5b89\u88c5","text":"<p>mamba \u4ecb\u7ecd,mamba\u662f\u5e8f\u5217\u5efa\u6a21\u65b9\u6cd5,\u7528\u6765\u66ff\u6362\u8fd9\u4e2a\u65f6\u95f4\u6ce8\u610f\u529b\u6a21\u5757,manba \u539f\u7406\u6709\u70b9\u96be,\u6240\u5e78,\u4f5c\u8005\u5c01\u88c5\u597d\u4e86,\u76f4\u63a5\u8c03\u7528\u5373\u53ef.</p> Python<pre><code>from manba_ssm import Manba\n</code></pre> <p>\u5373\u53ef\u76f4\u63a5\u8c03\u7528 manba</p> <p>\u8fd9\u91cc\u7684\u5b89\u88c5\u5bb9\u6613\u51fa\u73b0\u5f88\u591a\u95ee\u9898:</p> <ul> <li>\u7248\u672c\u548ccuda\u5bf9\u4e0d\u4e0a</li> <li>\u8fdc\u7a0b\u4e0b\u8f7d\u4e0d\u4e0b\u6765</li> </ul> <ul> <li>manba \u4e3b\u9875:https://github.com/state-spaces/mamba</li> </ul> <p>\u8981\u6c42:Linux\\NVIDIA GPU\\Pytorch1.12+\\CUDA 11.6+</p> <ul> <li>\u6ca1\u6709 cuda GPU \u522b\u60f3\u4e86</li> </ul> <ul> <li>manba\u539f\u6587:https://arxiv.org/pdf/2312.00752</li> </ul> <ul> <li>\u53d1\u5e03\u65e5\u671f\uff1a2023 \u5e74 12 \u6708</li> <li>Albert Gu \u548c Tri Dao - \u5361\u8010\u57fa\u6885\u9686\u5927\u5b66\u548c\u666e\u6797\u65af\u987f\u5927\u5b66</li> </ul> <p>\u7a33\u5b9a\u5b89\u88c5\u7684\u65b9\u6cd5:</p> Python<pre><code># \u73af\u5883: Cuda 11.8, python 3.8(ubuntu20.04), PyTorch  2.0.0\n\n### \u4e0d\u7a33\u5b9a\u5b89\u88c5\u65b9\u6cd5\n# \u8fd0\u6c14\u597d\u7684\u8bdd,\u4e00\u6b21\u6027\u5b89\u88c5\u5b8c\u6210,\u8fd0\u6c14\u4e0d\u597d,\u4e00\u5929\u4e5f\u5b89\u88c5\u4e0d\u597d, \u56e0\u4e3a\u662f\u4ecegithub\u76f4\u63a5\u62c9\u53d6\u8d44\u6e90,\u975e\u5e38\u4e0d\u7a33\u5b9a: pip install mamba-ssm --timeout=200\n### \u7a33\u5b9a\u5b89\u88c5\u65b9\u6cd5\n# 1. \u901a\u8fc7\u6b64\u547d\u4ee4\u884c\u67e5\u770b\u5b89\u88c5\u7684\u662f\u54ea\u4e2awheel\u6587\u4ef6:pip install mamba-ssm --no-cache-dir --verbose\n# 2. \u590d\u5236\u7ed9\u5b9a\u7684.wheel\u94fe\u63a5\u5230\u6d4f\u89c8\u5668,\u76f4\u63a5\u4e0b\u8f7d\n# 3. \u7136\u540e\u5728\u5bf9\u5e94\u7684\u73af\u5883\u4e2d\u76f4\u63a5pip install mamba_ssm-2.2.2+cu118torch2.0cxx11abiFALSE-cp38-cp38-linux_x86_64.whl\n</code></pre>"},{"location":"learning/17_ManBa/#_2","title":"\u865a\u62df\u73af\u5883","text":"<p>\u529d\u4f60 \u8fd8\u662f\u65b0\u5efa\u865a\u62df\u73af\u5883,\u7701\u53bb\u5f88\u591a\u9ebb\u70e6\ud83d\ude16</p> Bash<pre><code># \u521b\u5efa\u65b0\u7684conda\u73af\u5883\uff08\u81ea\u52a8\u786e\u8ba4\u6240\u6709\u63d0\u793a\uff09\nconda create -n mamba_env python=3.8 -y\n\n# \u6fc0\u6d3b\u73af\u5883\nconda activate mamba_env\n\n# \u5b89\u88c5\u517c\u5bb9\u7248\u672c\u7684PyTorch\uff08\u81ea\u52a8\u786e\u8ba4\u6240\u6709\u63d0\u793a\uff09\nconda install pytorch=2.0.0 torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y\n\n# \u5b89\u88c5Mamba-SSM\uff08\u81ea\u52a8\u786e\u8ba4\u6240\u6709\u63d0\u793a\uff09\npip install \u5e93\u540d -y\n\npip install mamba-ssm --no-cache-dir --verbose\n</code></pre>"},{"location":"learning/17_ManBa/#docker","title":"docker","text":"<p>\u4e24\u79cd\u89e3\u51b3\u601d\u8def:</p> <p>(1)mamba \u955c\u50cf</p> <p>(2)torch \u955c\u50cf(\u56e0\u4e3a,\u6ca1\u6709\u63d0\u4f9b mamba \u955c\u50cf,\u4f46\u662f\u62a5cuda\u51b2\u7a81\u95ee\u9898)</p> <p>\u601d\u8def\u662f:</p> <ul> <li>docker pull  \u62c9\u955c\u50cf</li> <li>docker run \u6302\u8f7d \u76ee\u5f55</li> <li></li> </ul> <p>\u6211\u653e\u5f03\u4e86,\u88c5\u4e0d\u4e0a,\u4f7f\u7528 docker\u62c9\u53d6\u955c\u50cf,\u6302\u8f7d\u76ee\u5f55,\u95ee\u9898\u662f\u670d\u52a1\u5668\u4e0a\u62c9\u4e0d\u4e0b\u6765,\u65b9\u6cd5\u662f\u672c\u5730 pull,\u518d\u4e0a\u4f20</p> Bash<pre><code># \u62c9\u53d6\u5b98\u65b9Docker\u955c\u50cf\ndocker pull statespaces/mamba:latest\n\n# \u8fd0\u884c\u5bb9\u5668\u5e76\u6302\u8f7d\u60a8\u7684\u4ee3\u7801\u76ee\u5f55\ndocker run --gpus all -it -v /home/student2023/xiehr2023/UnetTSF:/workspace statespaces/mamba\n\n# \u5728\u5bb9\u5668\u5185\u8fd0\u884c\u4ee3\u7801\npython /workspace/customLayers/module_4.py\n</code></pre> <p>\u5173\u4e8e\u547d\u4ee4:</p> Bash<pre><code>docker run --gpus all -it -v /home/student2023/xiehr2023/UnetTSF:/workspace statespaces/mamba\n</code></pre> <p>\u89e3\u91ca</p> Bash<pre><code>--gpus all: \u5141\u8bb8\u5bb9\u5668\u8bbf\u95ee\u6240\u6709GPU\n-it: \u4ea4\u4e92\u5f0f\u7ec8\u7aef\n-v /home/student2023/xiehr2023/UnetTSF:/workspace: \u5c06\u60a8\u7684\u672c\u5730\u4ee3\u7801\u76ee\u5f55\u6302\u8f7d\u5230\u5bb9\u5668\u5185\u7684/workspace\u76ee\u5f55\nstatespaces/mamba: \u4f7f\u7528\u5b98\u65b9Mamba\u955c\u50cf\n</code></pre> <p>\u5e38\u7528\u547d\u4ee4:</p> Bash<pre><code># \u67e5\u770b\u8fd0\u884c\u4e2d\u7684\u5bb9\u5668\ndocker ps\n\n# \u91cd\u65b0\u8fde\u63a5\u5230\u8fd0\u884c\u4e2d\u7684\u5bb9\u5668\uff08\u5982\u679c\u60a8\u9000\u51fa\u4e86\uff09\ndocker exec -it \u5bb9\u5668ID /bin/bash\n\n# \u505c\u6b62\u5bb9\u5668\ndocker stop \u5bb9\u5668ID\n\n# \u5220\u9664\u5bb9\u5668\ndocker rm \u5bb9\u5668ID\n</code></pre> <p>\u6301\u4e45\u5316:\u5bb9\u5668\u4fdd\u5b58\u4e3a\u955c\u50cf,\u4f7f\u7528\u955c\u50cf\u6302\u8f7d\u76ee\u5f55</p> Bash<pre><code># \u5c06\u5f53\u524d\u5bb9\u5668\u4fdd\u5b58\u4e3a\u65b0\u955c\u50cf\ndocker commit \u5bb9\u5668ID my-mamba-env\n\n# \u4f7f\u7528\u65b0\u955c\u50cf\u8fd0\u884c\u5bb9\u5668\ndocker run --gpus all -it -v /home/student2023/xiehr2023/UnetTSF:/workspace my-mamba-env\n</code></pre> <p>\u6211\u7684 mamba \u5b89\u88c5(\u6210\u529f\u7248):</p> Python<pre><code>conda create -n mamba39 python=3.9 -y\nconda activate mamba39\nconda install pytorch==2.0.0 torchvision torchaudio pytorch-cuda==11.8 -c pytorch -c nvidia -y\ngit clone https://github.com/state-spaces/mamba.git\ncd mamba\npip install -e .\n</code></pre>"},{"location":"learning/1_clip/","title":"CLIP","text":""},{"location":"learning/1_clip/#clip","title":"CLIP","text":"2025-02-22 22:04:482025-09-28 12:54:04 <p> \u7ea6 4097 \u4e2a\u5b57  23 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 20 \u5206\u949f</p> <p></p>"},{"location":"learning/1_clip/#_1","title":"\u52a8\u673a","text":"<p>\u4e4b\u524d\u7684\u56fe\u7247\u5206\u7c7b\u7f51\u7edc\u90fd\u53ea\u80fd\u5bf9\u56fa\u5b9a\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b\uff0c\u4e0d\u8bba\u662f ImageNet \u7684 1000 \u7c7b\uff0cCIFAR10 \u7684 10 \u7c7b\uff0c\u8fd8\u662fCIFAR100 \u7684 100 \u7c7b\uff0c\u5e26\u6765\u7684\u95ee\u9898\u6709\u4e24\u4e2a\uff1a</p> <p>\uff081\uff09\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u80fd\u5bf9\u56fa\u5b9a\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b\uff0c\u4e0d\u80fd\u8fc1\u79fb\u5230\u5176\u4ed6\u7c7b\u522b</p> <p></p> <p>\uff082\uff09\u56fa\u5b9a\u597d\u7684\u7c7b\u522b\u9700\u8981\u6839\u636e\u7c7b\u522b\u6765\u6807\u6ce8\u6570\u636e\uff0c\u8d39\u65f6\u8d39\u529b</p> <p>\u7531\u6b64\u5f15\u53d1\u601d\u8003\uff1a\u6709\u6ca1\u6709\u89c6\u89c9\u6a21\u578b\u4e0d\u7528\u5bf9\u6570\u636e\u8fdb\u884c\u6807\u6ce8\u5c31\u53ef\u4ee5\u8bad\u7ec3\uff0c\u5e76\u4e14\u53ef\u4ee5\u5bf9\u4efb\u610f\u7c7b\u522b\u8fdb\u884c\u9884\u6d4b\uff0c\u4e0d\u7528\u4e8b\u5148\u56fa\u5b9a\u5206\u7c7b\u7684\u7c7b\u522b\uff1f</p>"},{"location":"learning/1_clip/#_2","title":"\u542f\u53d1","text":"<p>\u5728\u4f5c\u8005\u63d0\u51fa CLIP \u6a21\u578b\u7684\u540c\u65f6\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u56e0\u4e3a Transformer \u67b6\u6784\u7684\u63d0\u51fa\u53d1\u751f\u4e86\u7ffb\u5929\u8986\u5730\u7684\u53d8\u5316</p> <p></p> <p>Encoder\u7684\u90e8\u5206\u6210\u5c31\u4e86 Bert\uff1bdecoder \u90e8\u5206\u6210\u5c31\u4e86 GPT</p> <p></p> <p>\u9996\u5148\u770b Bert \u6a21\u578b\uff0c\u9884\u6d4b\u4efb\u52a1\u6709\u4e24\u4e2a\uff0c\u4f46\u90fd\u662f\u81ea\u76d1\u7763\u7684\uff0c\u4e0d\u9700\u8981\u4eba\u5de5\u6807\u6ce8\u6570\u636e</p> <p>\uff081\uff09\u7b2c 1 \u4e2a\u4efb\u52a1\u662f\u8bad\u7ec3\u5e26\u63a9\u7801\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5c31\u662f\u628a\u4e00\u53e5\u8bdd\u91cc\u9762\u7684\u90e8\u5206\u8bcd\u906e\u4f4f\uff0c\u8ba9\u6a21\u578b\u6839\u636e\u4e0a\u4e0b\u6587\u9884\u6d4b\u88ab\u906e\u4f4f\u7684\u8bcd</p> <p>\uff082\uff09\u7b2c 2 \u4e2a\u4efb\u52a1\u662f\u7ed9\u51fa\u4e24\u53e5\u8bdd\uff0c\u8ba9\u6a21\u578b\u5224\u65ad\u4e24\u53e5\u8bdd\u662f\u5426\u5728\u539f\u6587\u4e2d\u662f\u8fde\u7eed\u7684</p> <p>\u8fd9\u4e24\u4e2a\u4ee3\u7406\u4efb\u52a1\uff0c\u4e00\u4e2a\u8bad\u7ec3\u4e86\u6a21\u578b\u5bf9\u8bcd\u8bed\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4e00\u4e2a\u8bad\u7ec3\u4e86\u6a21\u578b\u5bf9\u6574\u4e2a\u53e5\u5b50\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4e8e\u662f\u5f97\u5230\u4e86\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u9884\u8bad\u7ec3\u6a21\u578b</p> <p>\uff08Bert \u6a21\u578b\uff09</p> <p>Bert \u89e3\u51b3\u4e86\u8bad\u7ec3\u6570\u636e\u7684\u6807\u6ce8\u95ee\u9898\uff0c\u4f46\u662f\u6ca1\u6709\u89e3\u51b3\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u4f9d\u7136\u9700\u8981\u5fae\u8c03\u7684\u95ee\u9898\uff0c\u4e0d\u8bba\u662f\u5355\u8bcd\u7ea7\u522b\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u8fd8\u662f\u53e5\u5b50\u7ea7\u522b\u7684\u60c5\u7eea\u8bc6\u522b\uff0c\u90fd\u8fd8\u662f\u9700\u8981\u52a0\u4e00\u5c42\u7ebf\u6027\u5206\u7c7b\u5934\u8fdb\u884c\u5fae\u8c03</p> <p>\uff08GPT \u6a21\u578b\uff09</p> <p>\u4ee5 GPT3 \u4e3a\u4f8b\uff0c\u5b83\u7684\u8bad\u7ec3\u6570\u636e\u4e5f\u4e0d\u9700\u8981\u4eba\u5de5\u6807\u6ce8\uff0c\u4efb\u52a1\u5c31\u662f\u6587\u5b57\u63a5\u9f99\uff0c\u6839\u636e\u524d\u6587\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5b57</p> <p>\u540c\u65f6\u4e5f\u89e3\u51b3\u4e86\u6a21\u578b\u8fc1\u79fb\u7684\u95ee\u9898\uff0cGPT3 \u901a\u8fc7 prompt \u53ef\u4ee5\u5b8c\u6210\u5404\u79cd\u4efb\u52a1\u5305\u62ec\u7ffb\u8bd1\u3001\u60c5\u7eea\u8bc6\u522b\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7b49</p> <p>\u53ea\u8981\u628a\u4efb\u52a1\u901a\u8fc7 prompt \u544a\u8bc9 GPT3\uff0c\u5b83\u5c31\u80fd\u5b8c\u6210\u5bf9\u5e94\u7684\u4efb\u52a1\uff0c\u800c\u4e0d\u9700\u8981\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60</p> <p>GPT3 \u662f OpenAI \u7684\u5de5\u4f5c\uff0cCLIP \u4e5f\u662f OpenAI \u63d0\u51fa\u7684\uff0c\u6240\u4ee5\u81ea\u7136\u5c31\u60f3\u5230\u662f\u5426\u80fd\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u89e3\u51b3\u6570\u636e\u9700\u8981\u6807\u6ce8\u7684\u95ee\u9898\uff0c\u540c\u65f6\u5229\u7528 Prompt \u6765\u5b9e\u73b0\u4e0b\u6e38\u4efb\u52a1\u9700\u8981\u8fc1\u79fb\u5b66\u4e60\u7684\u95ee\u9898</p>"},{"location":"learning/1_clip/#_3","title":"\u5173\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60","text":"<p>\u81ea\u76d1\u7763\u5b66\u4e60 &amp; \u6768\u7acb\u6606\u86cb\u7cd5\u56fe</p> <p>\u89e3\u8bfb \u6768\u7acb\u6606\u86cb\u7cd5\u56fe</p> <p>\u5982\u679c\u628a\u6a21\u578b\u5b66\u5230\u7684\u4e1c\u897f\u6bd4\u4f5c 1 \u4e2a\u86cb\u7cd5\u7684\u8bdd\uff1a</p> <ul> <li>\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u5b66\u5230\u7684\u4e1c\u897f\u5c31\u662f\u86cb\u7cd5\u4e0a\u7684\u6a31\u6843\uff0c\u975e\u5e38\u5c11</li> <li>\u76d1\u7763\u5b66\u4e60\u80fd\u591f\u5b66\u5230\u7684\u4e1c\u897f\u5c31\u662f\u86cb\u7cd5\u5916\u5c42\u7684\u7cd6\u971c</li> <li>\u800c\u81ea\u76d1\u7763\u5b66\u4e60\u80fd\u591f\u5b66\u5230\u7684\u4e1c\u897f\u624d\u662f\u8fd9\u4e2a\u86cb\u7cd5\u7684\u672c\u8d28</li> </ul> <p>\u600e\u4e48\u7406\u89e3 \u6768\u7acb\u6606\u86cb\u7cd5\u56fe\uff1f</p> <ul> <li>\u5f3a\u5316\u5b66\u4e60\u7684\u6a21\u578b\u76d1\u7763\u4fe1\u53f7\u53ea\u6709\u5355\u4e00\u7684\u5956\u52b1\u5236\uff0c\u4fe1\u606f\u975e\u5e38\u5c11</li> <li>\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u7684\u76d1\u7763\u4fe1\u53f7\u662f\u4eba\u9020\u7684\u7c7b\u522b\u4fe1\u606f</li> <li>\u800c\u81ea\u76d1\u7763\u5b66\u4e60\u76d1\u7763\u4fe1\u53f7\u5c31\u662f\u771f\u5b9e\u7684\u8f93\u5165</li> </ul> <p>\u6bd4\u5982 GPT3 \u6a21\u578b\u7528\u7684\u5927\u91cf\u771f\u5b9e\u6587\u672c\u8bad\u7ec3\uff0c\u9884\u6d4b\u7684\u5c31\u662f\u771f\u5b9e\u7684\u6587\u672c\uff0c\u4e5f\u5c31\u4f7f\u5f97 GPT3 \u53d6\u5f97\u4e86\u5f88\u597d\u7684\u6548\u679c</p>"},{"location":"learning/1_clip/#_4","title":"\u6570\u636e","text":"<p>OpenAI \u4f5c\u4e3a\u5927\u516c\u53f8\uff0c\u5728\u8bad\u7ec3 CLIP \u65f6\uff0c\u6536\u96c6\u4e864 \u4ebf\u4e2a\u6587\u672c\u56fe\u7247\u5bf9\uff0c\u5176\u4e2d\u5149\u6587\u672c\u7684\u91cf\u5c31\u548c\u8bad\u7ec3 GPT2 \u7684\u6587\u672c\u76f8\u5f53</p> <p>\u5982\u56fe\u662f\u6587\u672c\u5bf9\u7684\u4f8b\u5b50</p> <p>\u5982\u679c\u4f20\u7edf\u7684\u5206\u7c7b\u6a21\u578b\uff0c\u7b2c\u4e00\u5f20\u56fe\u7247\u53ef\u80fd\u88ab\u6253\u4e0a\u8349\u5730\u7684\u6807\u7b7e\uff0c\u76d1\u7763\u4fe1\u53f7\u5c31\u53ea\u6709\"\u8349\u5730\"\uff0c\u7b2c\u4e8c\u5f20\u56fe\u7247\u56fe\u7247\u5c31\u88ab\u6253\u4e0a\"\u623f\u95f4\"\u7684\u6807\u7b7e</p> <p>\u63a5\u4e0b\u6765\uff0c\u770b\u5b9e\u9645\u7684\u6587\u672c\u662f\u5982\u4f55\u63cf\u8ff0\u7b2c\u4e00\u5f20\u56fe\u7684\"\u6e7f\u6f09\u6f09\u7684\u94f6\u674f\u6d12\u6ee1\u8349\u576a......\"\uff0c\u7b2c\u4e8c\u5f20\u56fe\u7684\u6587\u5b57\"\u5c0f\u732b\uff0c\u8737\u7f29\u5728\u5e8a\u4e0a......\"</p> <p>\u53ef\u4ee5\u660e\u663e\u770b\u5230\"\u8349\u5730\"\u3001\"\u623f\u95f4\"\u8fd9\u6837\u7684\u6807\u7b7e\u76f8\u6bd4\u5b9e\u9645\u6536\u96c6\u5230\u7684\u6587\u672c\u542b\u6709\u66f4\u591a\u7684\u4fe1\u606f\u91cf\uff0c\u5bf9\u56fe\u7247\u7684\u63cf\u8ff0\u4e5f\u66f4\u52a0\u7ec6\u8282\uff0c\u4e5f\u5c31\u662f\u8bf4\u6709\u66f4\u591a\u7684\u76d1\u7763\u4fe1\u53f7</p> <p>\u5982\u679c\u80fd\u5145\u5206\u5229\u7528\u8fd9\u4e9b\u76d1\u7763\u4fe1\u53f7\uff0c\u4e00\u5b9a\u53ef\u4ee5\u8bad\u7ec3\u51fa\u66f4\u597d\u7684\u6a21\u578b</p>"},{"location":"learning/1_clip/#_5","title":"\u8bba\u6587\u9898\u76ee","text":"<p>\u770b CLIP \u539f\u8bba\u6587\u7684\u9898\u76ee\uff1a\u5229\u7528\u81ea\u7136\u8bed\u8a00\u7684\u76d1\u7763\u4fe1\u53f7\u5b66\u4e60\u4e00\u4e2a\u53ef\u8fc1\u79fb\u7684\u89c6\u89c9\u6a21\u578b</p> <p>\u8fd9\u91cc\u7684\u53ef\u8fc1\u79fb\u6307\u7684\u662f\u5728\u4e0b\u6e38\u4efb\u52a1\u65f6\u4e0d\u9700\u8981\u518d\u8bad\u7ec3\u6a21\u578b\uff0c\u54ea\u6015\u662f\u5206\u7c7b\u5934\u4e5f\u4e0d\u518d\u9700\u8981\u3002</p> <p>\u601d\u8003\uff1a\u90a3\u5982\u4f55\u5229\u7528\u81ea\u7136\u8bed\u8a00\u7684\u76d1\u7763\u4fe1\u53f7\u5462\uff1f</p>"},{"location":"learning/1_clip/#_6","title":"\u8bad\u7ec3\u4efb\u52a1","text":"<p>\u521a\u5f00\u59cbOpenAI \u60f3\u5230\u7684\u662f\u901a\u8fc7\u56fe\u7247\u6765\u9884\u6d4b\u6587\u672c\uff0c\u53ef\u662f\u8bad\u7ec3\u65f6\u53d1\u73b0\u8bad\u7ec3\u901f\u5ea6\u592a\u6162\u4e86\uff0c\u4e3a\u4ec0\u4e48\u5462\uff1f</p> <p>\u56e0\u4e3a\u6839\u636e\u4e00\u5f20\u56fe\u7247\u751f\u6210\u6587\u672c\u672c\u6765\u5c31\u662f\u4e00\u4e2a\u5f88\u96be\u7684\u4efb\u52a1\uff0c\u5bf9\u4e8e\u540c\u4e00\u5f20\u56fe\u7247\u53ef\u4ee5\u6709\u65e0\u6570\u79cd\u6b63\u786e\u7684\u7b54\u6848</p> <p>\u6bd4\u5982\u5de6\u56fe\u63cf\u8ff0\u53ef\u4ee5\u662f</p> <p>\uff081\uff09\u6e7f\u6f09\u6f09\u7684\u94f6\u674f\u6d12\u6ee1\u8349\u576a\uff0c\u5ba3\u544a\u7740\u79cb\u5929\u7684\u7ed3\u675f</p> <p>\uff082\uff09\u8def\u8fb9\u7684\u7eff\u8272\u8349\u5730\u4e0a\u6709\u5f88\u591a\u9ec4\u8272\u53f6\u5b50</p> <p>\uff083\uff09\u6df1\u79cb\u7684\u8def\u8fb9\u6ee1\u662f\u843d\u53f6</p> <p>\u6240\u4ee5\u4f5c\u8005\u5c31\u6539\u4e3a\u4e86\u53f3\u56fe\u4e2d\u7684 <code>\u56fe\u7247\u548c\u6587\u672c\u7684\u914d\u5bf9\u4efb\u52a1</code></p> <p>\u53ef\u4ee5\u660e\u663e\u770b\u5230\u56fe\u6587\u914d\u5bf9\u7684\u4efb\u52a1\u76f8\u5bf9\u7b80\u5355\uff0c\u6a21\u578b\u4e5f\u66f4\u5bb9\u6613\u8bad\u7ec3\uff0cCLIP \u505a\u56fe\u7247\u548c\u6587\u672c\u914d\u5bf9\u4e5f\u975e\u5e38\u7b80\u5355\u76f4\u63a5</p>"},{"location":"learning/1_clip/#_7","title":"\u6a21\u578b\u8bad\u7ec3","text":"<p>\u6587\u672c\u901a\u8fc7 <code>Text Encoder</code> </p> <p>\u56fe\u7247\u901a\u8fc7 <code>Image Encoder</code></p> <p>\u7136\u540e\u5206\u522b\u5f97\u5230\u6587\u672c\u7684\u5411\u91cf\u8868\u793a\u548c\u56fe\u7247\u7684\u5411\u91cf\u8868\u793a\uff0c\u518d\u5206\u522b\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u6295\u5c04\u5c42\uff0c\u6295\u5c04\u5230\u4e00\u4e2a\u5171\u540c\u7684\u591a\u6a21\u6001\u5411\u91cf\u7a7a\u95f4\u4e2d\uff0c\u5728\u8fd9\u4e2a\u5411\u91cf\u7a7a\u95f4\u4e2d\uff0c\u5c3d\u91cf\u62c9\u8fd1\u914d\u5bf9\u6587\u672c\u548c\u56fe\u7247\u7684\u5411\u91cf\uff0c\u800c\u8ba9\u4e0d\u914d\u5bf9\u7684\u6587\u672c\u548c\u56fe\u7247\u5411\u91cf\u8ddd\u79bb\u5c3d\u53ef\u80fd\u7684\u8fdc</p> <p>\u8fd9\u91cc\u7684\u6587\u672c Encoder \u548c\u56fe\u7247 Encoder \u7528\u4ec0\u4e48\u6a21\u578b\u90fd\u53ef\u4ee5\uff0c\u53ea\u8981\u80fd\u628a\u56fe\u7247\u548c\u6587\u672c\u53d8\u6210\u5411\u91cf\u5373\u53ef</p> <p></p> <p>\u4f5c\u8005\u5b9e\u9a8c\u65f6\uff0c\u5bf9\u4e8e\u56fe\u50cf\u7f16\u7801\u5668\u5c1d\u8bd5\u4e86 ResNet50\u3001ResNet101\u3001\u4ee5\u53ca\u5bf9 ResNet50 \u7684\u6df1\u5ea6\u5bbd\u5ea6\u8fdb\u884c\u6269\u5c55\u7684 ResNet50\u00d74\u3001ResNet50\u00d716\u3001ResNet50\u00d764</p> <p>\u00d74 \u7684\u610f\u601d\u662f ResNet50\u00d74 \u7684\u8ba1\u7b97\u4ee3\u4ef7\u662f ResNet50 \u7684 4 \u500d</p> <p>\u540c\u65f6\u4f5c\u8005\u4e5f\u5c1d\u8bd5\u4e86 ViT\u6a21\u578b\uff0cViT-B/32\u3001ViT-B/16\u3001ViT-L/14</p> <p>B\uff1aBase\u3001L\uff1aLarge\u3001<code>32 16 14</code>\uff1a\u56fe\u7247 patch \u7684\u5927\u5c0f</p> <p>patch \u8d8a\u5c0f\uff0c\u56fe\u7247\u5e8f\u5217\u8d8a\u957f\uff0c\u8ba1\u7b97\u4ee3\u4ef7\u8d8a\u5927\uff0c\u5176\u4e2d ResNet \u91cc\u6700\u5927\u7684\u6a21\u578b\u662f ResNet50\u00d764\uff0c\u8bad\u7ec3\u4e86 1(w)0656 \u4e2a V100 \u5929\uff0c\u800c ViT-L/14 \u53ea\u7528\u4e86 3072 \u4e2a V100 \u5929</p> <p>\u800c\u4e14  ViT-L/14  \u662f\u6548\u679c\u6700\u597d\u7684\uff0c\u8fd9\u4e5f\u8bc1\u660e\u4e86\u5728\u8bad\u7ec3\u4ebf\u7ea7\u522b\u7684\u56fe\u7247\u65f6\uff0cViT \u6a21\u578b\u66f4\u8282\u7701\u7b97\u529b\uff0c\u6548\u679c\u4e5f\u66f4\u597d</p> <p>\u6700\u540e\u4f5c\u8005\u8fd8\u5728  ViT-L/14   \u8fd9\u4e2a\u6a21\u578b\u4e0a\uff0c\u5728\u9ad8\u5206\u8fa8\u7387\u4e0b \\(336*336\\)\u7684\u56fe\u7247\u4e0a\u989d\u5916\u8bad\u7ec3\u4e86\u4e00\u4e2a epoch\uff0c\u6765\u63d0\u5347\u6027\u80fd</p> <p>\u53e6\u5916\u4f5c\u8005\u53d1\u73b0\uff0c\u5982\u679c\u60f3\u901a\u8fc7\u6269\u5927\u6a21\u578b\u6765\u63d0\u5347\u7cbe\u5ea6\u6700\u597d\u662f\u5728\u6a21\u578b\u7684\u6df1\u5ea6\u3001\u5bbd\u5ea6\u3001\u56fe\u50cf\u7684\u5206\u8fa8\u7387\u4e0a\u7b49\u540c\u65f6\u589e\u52a0\uff0c\u8fd9\u6837\u6536\u76ca\u6700\u5927\uff0c\u800c\u4e0d\u662f\u628a\u6240\u6709\u7684\u8ba1\u7b97\u91cf\u90fd\u589e\u52a0\u5728\u5176\u4e2d\u4e00\u9879\u4e0a</p> <p>\u5bf9\u4e8e\u6587\u672c\u7f16\u7801\u5668\uff0c\u4f5c\u8005\u91c7\u7528\u4e86\u7c7b\u4f3c GPT \u7684\u7ed3\u6784\uff0c\u6bcf\u4e2a token \u90fd\u53ea\u80fd\u770b\u5230\u81ea\u5df1\u524d\u9762\u7684 token</p> <p>\u8f93\u5165\u6587\u672c\u524d\u8fb9\u4f1a\u52a0\u4e00\u4e2a SOS token\uff0c\u8868\u793a start of sentence\uff0c\u6587\u672c\u540e\u8fb9\u4f1a\u589e\u52a0\u4e00\u4e2a EOS token\uff0c\u8868\u793a end of sentence</p> <p>\u7136\u540e\u62ff\u6700\u540e\u4e00\u5c42 EOS \u4f4d\u7f6e token \u7684\u8f93\u51fa\u6765\u4f5c\u4e3a\u6574\u4e2a\u53e5\u5b50\u7684 embedding\uff0c\u56e0\u4e3a\u53ea\u6709EOS token \u53ef\u4ee5\u770b\u5230\u6574\u4e2a\u5e8f\u5217\u7684\u5176\u4ed6 token \u6765\u603b\u7ed3\u6574\u4e2a\u53e5\u5b50\u7684\u610f\u601d</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u867d\u7136\u8fd9\u91cc\u6a21\u578b\u7ed3\u6784\u7c7b\u4f3c\u4e8e GPT\uff0c\u4f46\u662f\u8fd9\u91cc\u662f\u4f5c\u4e3a\u7f16\u7801\u5668\u4f7f\u7528\u7684\uff0c\u53ea\u63d0\u53d6\u6700\u540e\u4e00\u4e2a EOS token \u7684\u8f93\u51fa\u4f5c\u4e3a\u6574\u4e2a\u53e5\u5b50\u7684\u7f16\u7801\uff0c\u6587\u672c\u7f16\u7801\u5668\u53ea\u6709 6300 \u4e07\u7684\u53c2\u6570</p> <p></p> <p>\u4f5c\u8005\u53d1\u73b0\u6587\u672c\u7f16\u7801\u5668\u7684\u5927\u5c0f\u5bf9\u4e8e CLIP \u6a21\u578b\u7684\u6027\u80fd\u5f71\u54cd\u4e0d\u5927\uff0c\u6240\u4ee5\u5e76\u6ca1\u6709\u5c1d\u8bd5\u4e0d\u540c\u5927\u5c0f\u7684\u6587\u672c\u7f16\u7801\u5668\uff0c\u8bad\u7ec3\u7684 batchsize \u4e3a3(w)2(k)768\uff0c\u4e00\u4e2a\u975e\u5e38\u5927\u7684 batchsize\uff0c\u800c\u4e14\u4ece\u5de6\u8fb9\u56fe\u4e0a\u4e5f\u53ef\u4ee5\u770b\u5230 \u968f\u7740\u89c6\u89c9\u7f16\u7801\u5668\u6a21\u578b\u8ba1\u7b97\u91cf\u7684\u589e\u5927\uff0cCLIP \u6a21\u578b\u7684\u9519\u8bef\u7387\u662f\u7a33\u6b65\u51cf\u5c0f\u7684</p> <p>\u800c\u4e14\u56e0\u4e3a\u8bad\u7ec3\u6570\u636e\u6709 4 \u4ebf\u4e2a\u56fe\u6587\u5bf9\uff0c\u6570\u636e\u91cf\u8db3\u591f\u5927\uff0c\u6240\u4ee5\u56fe\u7247\u7f16\u7801\u5668\u548c\u6587\u672c\u7f16\u7801\u5668\u90fd\u6ca1\u6709\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u76f4\u63a5\u4ece\u968f\u673a\u521d\u59cb\u5316\u5f00\u59cb\u8bad\u7ec3\uff0c\u56fe\u7247\u4e5f\u6ca1\u6709\u505a\u8fc7\u591a\u7684\u56fe\u50cf\u589e\u5f3a\uff0c\u552f\u4e00\u505a\u7684\u5c31\u662f\u968f\u673a\u88c1\u526a\uff0c\u6574\u4e2a CLIP \u5b9e\u73b0\u975e\u5e38\u7b80\u5355</p>"},{"location":"learning/1_clip/#_8","title":"\u6a21\u578b\u8bad\u7ec3\u4f2a\u4ee3\u7801","text":"<p>i \u4ee3\u8868 batch \u7684 n \u4e2a\u56fe\u7247\u6570\u636e</p> <p>t \u4ee3\u8868 1 \u4e2a batch \u7684 n \u4e2a\u6587\u672c\u6570\u636e</p> <p></p> <ul> <li>\u56fe\u7247\u6570\u636e\u7ecf\u8fc7\u56fe\u7247\u7f16\u7801\u5668\uff0c\u6587\u672c\u6570\u636e\u7ecf\u8fc7\u6587\u672c\u7f16\u7801\u5668\uff0c\u5206\u522b\u5f97\u5230\u539f\u59cb\u7684\u56fe\u50cf\u5411\u91cf\u8868\u793a\u548c\u6587\u672c\u5411\u91cf\u8868\u793a </li> </ul> <p></p> <ul> <li>\u63a5\u7740\u901a\u8fc7\u5404\u81ea\u7684\u7ebf\u6027\u6620\u5c04\u5c42\u6620\u5c04\u5230\u5171\u540c\u7684\u591a\u6a21\u6001\u5411\u91cf\u7a7a\u95f4 </li> </ul> <p>\u7ebf\u6027\u6620\u5c04\u5c42\u662f\u901a\u8fc7\u4e24\u4e2a\u70b9\u79ef\u5b9e\u73b0\u7684</p> <ul> <li>\u7136\u540e\u8fdb\u884c L2 \u5f52\u4e00\u5316\uff0c\u65b9\u4fbf\u540e\u9762\u76f4\u63a5\u901a\u8fc7\u70b9\u79ef\uff0c\u6765\u8ba1\u7b97\u4f59\u5f26\u76f8\u4f3c\u5ea6</li> <li>\u4e0b\u9762 \u901a\u8fc7\u4e24\u4e2a\u70b9\u79ef\u8ba1\u7b97\uff0c\u5f97\u5230\u4efb\u610f\u4e24\u4e2a\u56fe\u7247\u548c\u6587\u672c\u7684\u76f8\u4f3c\u5ea6</li> </ul> <p></p> <ul> <li>\u540e\u9762 \\(*np.\\exp(t)\\) \u7684\u90e8\u5206\uff0c\u662f\u6e29\u5ea6\u7cfb\u6570\uff0c\u4e00\u822c\u8bad\u7ec3\u5bf9\u6bd4\u6a21\u578b\u65f6\uff0c\u90fd\u4f1a\u6709\u4e00\u4e2a \\(&gt;0\\) \u7684\uff0c\u53ef\u4ee5\u8c03\u8282\u7684\u8d85\u53c2\u6570\uff0c\u6e29\u5ea6\u7cfb\u6570 t \uff0c\u4f46\u662f CLIP \u4e2d\u76f4\u63a5\u628a\u6e29\u5ea6\u7cfb\u6570\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u4ee5\u5b66\u4e60\u7684\u53c2\u6570</li> </ul> <p>\u4e3a\u4e86\u9632\u6b62\u6e29\u5ea6\u7cfb\u6570\u4e3a\u8d1f\u6570\uff0c\u6240\u4ee5\u5bf9 t \u8fdb\u884c \u6307\u6570\u8fd0\u7b97</p> <p>\u6e29\u5ea6\u7cfb\u6570 \u4f5c\u4e3a \u53ef\u8c03\u8282\u7684\u8d85\u53c2\u6570\u65f6\uff0c\u4e00\u822c\u90fd\u662f\u7528 logits \u7684\u503c\u9664\u4ee5\u6e29\u5ea6\u7cfb\u6570</p> <p>\u6e29\u5ea6\u7cfb\u6570\u7684\u4f5c\u7528\u5c31\u662f\u8c03\u8282\u5206\u5e03\u7684\u9661\u5ced\u7a0b\u5ea6</p> <p>\u6e29\u5ea6\u8d8a\u9ad8\uff0clogits \u901a\u8fc7 softmax \u540e\uff0c\u5dee\u522b\u4f1a\u88ab\u5e73\u6ed1</p> <p>\u6e29\u5ea6\u8d8a\u4f4e\uff0clogits \u901a\u8fc7 softmax \u540e\uff0c\u5dee\u522b\u4f1a\u66f4\u52a0\u9661\u5ced</p> <p>\u4f46\u662f\u56e0\u4e3a\u8fd9\u91cc t \u662f\u53ef\u5b66\u4e60\u7684\u53c2\u6570\uff0c\u7528\u4e58\u6cd5\u548c\u9664\u6cd5\u90fd\u662f\u4e00\u6837\u7684\uff0c\u8ba9\u6a21\u578b\u81ea\u5df1\u53bb\u5b66\u4e60</p> <p></p> <ul> <li>\u4e0b\u4e00\u6b65\uff0c\u751f\u6210 label\uff0c\u53ef\u4ee5\u770b\u53f3\u8fb9\u7684\u56fe\uff0c\u548c batch \u7684\u7b2c\u4e00\u4e2a\u56fe\u7247\u5bf9\u5e94\u7684\u662f batch \u91cc\u7684\u7b2c\u4e00\u4e2a\u6587\u672c</li> <li>\u7b2c 2 \u4e2a\u56fe\u7247\u5bf9\u5e94\u7684\u662f\u7b2c 2 \u4e2a\u6587\u672c\uff0c\u4e5f\u5c31\u662f label \u90fd\u662f\u5728\u5bf9\u89d2\u7ebf\u4e0a\u7684\u5143\u7d20\uff0c\u6240\u4ee5\u8fd9\u91cc\u7528\u4e86 <code>np.arrang</code>\uff0c\u6765\u751f\u6210 label</li> <li>\u7136\u540e\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u56fe\u7247\u4e0e\u6240\u6709\u6587\u672c\u4e4b\u95f4\u76f8\u4f3c\u5ea6\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u662f\u5728\u884c\u7ef4\u5ea6</li> <li>\u63a5\u7740\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u6587\u672c\u4e0e\u6240\u6709\u56fe\u7247\u4e4b\u95f4\u76f8\u4f3c\u5ea6\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u662f\u5728\u5217\u7ef4\u5ea6\u4e0a</li> <li>\u6700\u540e\uff0c\u603b\u7684\u635f\u5931\u7b49\u4e8e\u4e24\u4e2a\u635f\u5931\u7684\u5e73\u5747\u503c</li> </ul>"},{"location":"learning/1_clip/#_9","title":"\u6a21\u578b\u63a8\u7406","text":"<p>\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5982\u4f55\u8fdb\u884c\u63a8\u7406\uff1f</p> <p>\u4ee5 ImageNet \u91cc\u7684 1k \u4e2a\u7c7b\u522b\u4e3a\u4f8b\uff0c\u53ef\u4ee5\u5148\u751f\u6210 1k \u53e5\u8bdd\uff0c\u5206\u522b\u662f\uff1a</p> <ul> <li>\uff08\u770b\u56fe\uff09A photo of a plane</li> <li>A photo of a car</li> <li>A photo of a dog</li> <li>.......</li> <li>A photo of a bird</li> </ul> <p>\u5982\u6b64\uff0c\u5f97\u5230 1k \u53e5\u8bdd\uff0c\u5e76\u5bf9\u8fd9 1k \u53e5\u8bdd\uff0c\u901a\u8fc7\u6587\u672c Encoder \u8fdb\u884c\u7f16\u7801\uff0c\u7136\u540e\u8fdb\u884c\u7ebf\u6027\u6620\u5c04\u5c42\uff0c\u5f97\u5230 1k \u4e2a\u4ee3\u8868\u4e0d\u540c\u7c7b\u522b\u7684\u6587\u672c\u5411\u91cf</p> <p>\u51c6\u5907\u597d\u8fd9 1k \u4e2a\u5411\u91cf\u4e4b\u540e\uff0c\u5c31\u53ef\u4ee5\u5bf9\u56fe\u7247\u8fdb\u884c\u9884\u6d4b</p> <p>\u5047\u8bbe\u7ed9\u5b9a\u4e00\u5f20\u56fe\u7247\uff0c\u901a\u8fc7\u56fe\u50cf\u7f16\u7801\u5668 \u548c \u7ebf\u6027\u6620\u5c04\u5c42\u540e\uff0c\u5f97\u5230\u56fe\u7247\u7684\u5411\u91cf\u8868\u793a\uff0c\u548c\u4e4b\u524d\u5f97\u5230\u7684 1k \u4e2a\u7c7b\u522b\u7684\u6587\u672c\u5411\u91cf\u8ba1\u7b97\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u54ea\u4e2a\u76f8\u4f3c\u5ea6\u6700\u5927\uff0c\u5c31\u5bf9\u5e94\u54ea\u4e2a\u7c7b\u522b</p>"},{"location":"learning/1_clip/#prompt-enginerring-ensembling","title":"Prompt Enginerring &amp; Ensembling","text":"<p>\u4e3a\u4ec0\u4e48\u8981\u628a\u7c7b\u522b\u540d\u5d4c\u5165\u5230\u53e5\u5b50\u4e2d\u518d\u505a\u6587\u672c \u7f16\u7801\u5462\uff1f</p> <p>\u8bba\u6587\u7684\u4f5c\u8005\u4e5f\u505a\u4e86\u5b9e\u9a8c\uff0c\u548c\u76f4\u63a5\u7528\u7c7b\u522b\u540d\u505a\u7f16\u7801\u5411\u91cf\u76f8\u6bd4\uff0c\u628a\u7c7b\u522b\u540d\u5d4c\u5165\u5230\u4e00\u4e2a\u7c7b\u4f3c\u4e8e\"\u8fd9\u662f\u4ec0\u4e48\u4ec0\u4e48\u4ec0\u4e48\u7684\u7167\u7247\"\u8fd9\u6837\u7684\u7b80\u5355\u53e5\u5b50\u4e2d\uff0c\u5728 ImageNet \u4e0a\u7684\u7cbe\u5ea6\u53ef\u4ee5\u63d0\u5347 1.3%</p> <p>\u5982\u679c\u662f\u9488\u5bf9\u7279\u5b9a\u7684\u6570\u636e\u96c6\u6bd4\u5982\u5bf9\u4e8e\u5ba0\u7269\u5206\u7c7b\u7684\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u5728\u7f16\u7801\u65f6\u5728\u53e5\u5b50\u4e2d\u660e\u786e\u7684\u8bf4\u660e\"\u8fd9\u662f\u4e00\u4e2a\u4ec0\u4e48\u4ec0\u4e48\u5ba0\u7269\u7684\u7167\u7247\"\uff0c\u628a\"\u5ba0\u7269\"\u8fd9\u4e2a\u4fe1\u606f\u7f16\u7801\u5230\u6587\u672c\u5411\u91cf\u4e2d\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347 clip \u6a21\u578b\u7684\u7cbe\u5ea6</p> <p>\u53e6\u5916\u4f5c\u8005\u8fd8\u63d0\u5230\u4e00\u79cd\u63d0\u5347\u7cbe\u5ea6\u7684\u529e\u6cd5\uff0c\u5c31\u662f\u505a Prompt ensembling\uff0c\u5b83\u7684\u505a\u6cd5\u662f\u751f\u6210\u591a\u4e2a Prompt \u7684\u6a21\u7248\uff0c\u628a\u4e00\u4e2a\u7c7b\u522b\u5206\u522b\u5d4c\u5165\u5230\u591a\u4e2a\u6a21\u7248\uff0c\u6700\u540e\u7528\u591a\u4e2a\u6a21\u7248\u751f\u6210\u7684\u7c7b\u522b\u7684\u6587\u672c\u5411\u91cf\u5206\u522b\u548c\u56fe\u7247\u5411\u91cf\u8ba1\u7b97\u76f8\u4f3c\u5ea6\uff0c\u5c06\u591a\u4e2a\u5411\u91cf\u76f8\u4f3c\u5ea6\u7684\u503c\u8fdb\u884c\u5e73\u5747\u4f5c\u4e3a\u6700\u7ec8\u8be5\u56fe\u7247\u548c\u7c7b\u522b\u7684\u76f8\u4f3c\u5ea6</p> <p>\u53f3\u56fe\u8868\u660e\uff0c\u901a\u8fc7 Prompt engineering \u548c ensembling \u4e4b\u540e\u6a21\u578b\u7cbe\u5ea6\u53ef\u4ee5\u63d0\u5347 5 \u4e2a\u70b9</p>"},{"location":"learning/1_clip/#_10","title":"\u5b9e\u9a8c\u6548\u679c","text":"<p>\u7b2c 1 \u4e2a\u56fe</p> <p>CLIP\u5728\u81ea\u5df14 \u4ebf\u4e2a\u56fe\u6587\u5bf9\u4e0a\u8bad\u7ec3\u540e\uff0c\u4e0d\u5728\u5176\u4ed6\u6570\u636e\u96c6\u4e0a\u505a\u4efb\u4f55\u8bad\u7ec3\uff0c\u76f4\u63a5\u8fdb\u884c zero-shot \u7684\u9884\u6d4b</p> <p>ResNet50 \u662f\u5728 ImageNet \u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5728\u8fd9\u4e9b\u6570\u636e\u96c6\u4e0a\u51bb\u7ed3\u6a21\u578b\u53c2\u6570\uff0c\u53ea\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5934\u7684\u7ed3\u679c\uff0c\u8fd9\u660e\u663e\u5bf9 ResNet50 \u66f4\u5360\u4f18\u52bf\uff0c\u56e0\u4e3a\u53ef\u4ee5\u5728\u8fd9\u4e9b\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03</p> <p>\u800c CLIP \u662f\u5b8c\u5168\u4e0d\u8bad\u7ec3\uff0c\u53ea\u662f\u901a\u8fc7 Prompt \u6765\u63d0\u793a\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b\uff0c\u7ed3\u679c\u5728\u5927\u90e8\u5206\u6570\u636e\u96c6\u4e0a\u8fd8\u662f CLIP \u9886\u5148</p> <p>\u7b2c 2 \u5f20\u56fe</p> <p>zero-shot CLIP \u9886\u5148\uff0c\u4f5c\u8005\u5c31\u60f3\u5982\u679c\u7ed9 CLIP \u4e2d\u7684\u56fe\u7247 Encoder \u4e5f\u52a0\u4e0a\u5206\u7c7b\u5934\uff0c\u505a few shot \u7684\u5fae\u8c03\u4f1a\u53d1\u751f\u4ec0\u4e48\uff1f</p> <p>\u5b9e\u9a8c\u53d1\u73b0\u4e0d\u8bba\u662f\u5728\u6bcf\u4e2a\u7c7b\u522b\u7ed9 1 \u4e2a\u4f8b\u5b50\u30012 \u4e2a\u4f8b\u5b50\u3001\u8fd8\u662f\u7ed9 16\u4e2a\u4f8b\u5b50\u90fd\u662f CLIP \u9886\u5148\uff0c\u7279\u522b\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u53ea\u7528 CLIP \u91cc\u56fe\u7247 Encoder+\u5206\u7c7b\u5934 \u5728\u6bcf\u4e2a\u7c7b\u522b \u53ea\u7ed9 4 \u4e2a\u6837\u672c\u8fdb\u884c\u5fae\u8c03\u7684\u6548\u679c\uff0c\u8fd8\u662f\u4e0d\u5982\u76f4\u63a5\u7528 Prompt zero shot \u7684 CLIP \u6548\u679c\u597d</p> <p>zero shot \u548c few shot \u90fd\u662f CLIP \u9886\u5148</p> <p>\u7b2c 3 \u5f20\u56fe </p> <p>\u4f5c\u8005\u601d\u8003\u5982\u679c\u7528\u4e0b\u6e38\u6240\u6709\u7684\u6570\u636e\u6765\u5fae\u8c03\u5206\u7c7b\u5934\uff0c\u7ed3\u679c\u53d1\u73b0\u8fd8\u662f CLIP \u9886\u5148</p> <p></p> <p>\u5728 ImageNet \u4e0a\u8bad\u7ec3\u7684 ResNet101 \u5bf9 ImageNet \u91cc\"\u9999\u8549\"\u8bc6\u522b\u7684\u51c6\u786e\u7387 \u548c zero-shot \u7684 CLIP \u662f\u4e00\u6837\u7684\uff0c\u90fd\u662f 76.2%</p> <p>\u4f46\u662f\u5982\u679c\u6362\u4e86\u5176\u4ed6\u6570\u636e\u96c6\uff0c\u6bd4\u5982\u5361\u901a\u7684\u3001\u7d20\u63cf\u7684\u6570\u636e\u96c6\u7b49\u5728 ImageNet \u4e0a\u8bad\u7ec3\u7684 ResNet \u6027\u80fd\u9a6c\u4e0a\u4e0b\u964d\uff0c\u800c zero-shot CLIP \u8bc6\u522b\u51c6\u786e\u7387\u6bd4\u8f83\u7a33\u5065\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u6027\u80fd</p> <p>\u56e0\u4e3a CLIP \u901a\u8fc7\u6587\u672c\u7406\u89e3\u4e86\u4ec0\u4e48\u662f\u9999\u8549\uff0cCLIP \u4ece\u6587\u672c\u91cc\u5b66\u5230\u4e86\u9999\u8549\u7684\u5f62\u72b6\u3001\u5927\u5c0f\u3001\u989c\u8272\u3001\u7ed3\u6784\u7b49\u7ec6\u8282\u4fe1\u606f\uff0c\u800c\u4e0d\u662f\u53ea\u627e\u5230\u4e86 1 \u4e2a\u6377\u5f84</p>"},{"location":"learning/1_clip/#_11","title":"\u5bf9\u6bd4\u5b66\u4e60","text":"<p>\u5bf9\u6bd4\u5b66\u4e60\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u5b66\u4e60\uff0c\u4e0d\u9700\u8981\u5b9a\u4e49\u5177\u4f53\u5730\u7c7b\u522b\uff0c\u53ea\u9700\u8981\u7ed9\u51fa\u54ea\u4e9b\u6837\u672c\u662f\u76f8\u540c\u7684\uff0c\u54ea\u4e9b\u662f\u4e0d\u540c\u7684</p> <p>\u6bd4\u5982 CLIP \u4e2d\u5b9a\u4e49\u53ea\u6709\u5bf9\u5e94\u7684\u56fe\u6587\u5bf9\u662f\u76f8\u540c\u7684\uff0c\u4e0d\u5bf9\u5e94\u7684\u56fe\u6587\u5bf9\u662f\u4e0d\u540c\u7684\uff0c\u5bf9\u6bd4\u5b66\u4e60\u901a\u8fc7\u5b9a\u4e49\u4ee3\u7406\u4efb\u52a1\u6765\u5b66\u4e60\u6837\u672c\u7684\u7279\u5f81\u8868\u793a\uff0c\u5b66\u5230\u7684\u7279\u5f81\u8ba9\u76f8\u540c\u7684\u6837\u672c\u7279\u5f81\u5c3d\u53ef\u80fd\u7684\u76f8\u4f3c\uff0c\u4e0d\u540c\u7684\u6837\u672c\u7279\u5f81\u5dee\u8ddd\u5c3d\u53ef\u80fd\u7684\u5927\uff0c\u6700\u7ec8\u5f97\u5230\u7684\u6a21\u578b\u5c31\u662f\u4e00\u4e2a\u7279\u5f81\u7f16\u7801\u5668</p> <p>\u5bf9\u6bd4\u5b66\u4e60\u4e00\u822c\u91c7\u7528 InfoNCE \u4f5c\u4e3a\u635f\u5931\u51fd\u6570</p>"},{"location":"learning/1_clip/#clip_1","title":"CLIP \u6a21\u578b\u7684\u4f18\u70b9","text":"<p>CLIP \u6a21\u578b\u7684\u597d\u5904\u6709\u54ea\u4e9b\uff1f</p> <p></p> <p>\u7b2c\u4e00\uff0c\u5229\u7528\u4e86\u4e30\u5bcc\u7684\u8bed\u4e49\u6765\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u8ba9\u6a21\u578b\u53ef\u4ee5\u5b66\u4e60\u56fe\u7247\u4e2d\u5f88\u591a\u7ec6\u8282\u8bed\u4e49\u7279\u5f81\uff0c\u505a\u5230\u771f\u6b63\u7684\u7406\u89e3\u56fe\u7247\uff0c\u80fd\u66f4\u597d\u7684\u6cdb\u5316</p> <p>\u7b2c\u4e8c\uff0c\u662f\u591a\u6a21\u6001\u7684\u6a21\u578b\uff0c\u8fde\u901a\u4e86\u56fe\u7247\u548c\u6587\u672c\uff0c\u53ef\u4ee5\u901a\u8fc7\u6587\u672c\u6765\u67e5\u8be2\u56fe\u7247</p> <p>\u7b2c\u4e09\uff0c\u6446\u8131\u4e86\u56fe\u7247\u5206\u7c7b\u5fc5\u987b\u662f\u56fa\u5b9a\u7684\u7c7b\u522b\uff0c\u521b\u65b0\u7684\u63d0\u51fa\u4e86\u5229\u7528 Prompt \u6765\u5206\u7c7b\u7684\u65b9\u6cd5\uff0c\u505a\u5230\u53ef\u4ee5\u5bf9\u4efb\u610f\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b</p> <p>\u4e4b\u524d\u5c06 CLIP \u7684\u56fe\u7247\u5206\u7c7b\u662f\u5148\u751f\u6210\u4e0d\u540c\u7c7b\u522b\u7684\u6587\u672c\u5411\u91cf\uff0c\u7136\u540e\u6765\u4e86\u56fe\u7247\u901a\u8fc7\u56fe\u7247\u5411\u91cf\u67e5\u627e\u6700\u76f8\u4f3c\u7684\u6587\u672c\u7c7b\u522b\u5411\u91cf</p>"},{"location":"learning/1_clip/#_12","title":"\u5e94\u7528","text":"<p>\u4ee5\u4e0a\u662f CLIP \u7684\u4e00\u4e2a\u4f8b\u5b50</p> <p>\u540c\u6837\u662f\u7528 CLIP\uff0c\u53ef\u4ee5\u5148\u628a\u89c6\u9891\u4e2d\u6240\u6709\u7684\u5173\u952e\u5e27\u56fe\u7247\u751f\u6210\u56fe\u7247\u5411\u91cf\uff0c\u7136\u540e\u8f93\u5165\u4e00\u4e2a\u53e5\u5b50\uff0c\u751f\u6210\u53e5\u5b50\u5411\u91cf\uff0c\u67e5\u627e\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u56fe\u7247\uff0c\u6bd4\u5982</p> <p>\uff081\uff09\u67e5\u627e\u6587\u672c\u4e3a\"\u7a7f\u7740\u84dd\u8272\u4e0a\u8863\u9a91\u81ea\u884c\u8f66\u7684\u4eba\"\uff0c\u53ef\u4ee5\u68c0\u7d22\u5230\u53f3\u56fe\u663e\u793a\u7684\u76d1\u7763\u753b\u9762</p> <p>\uff082\uff09\u67e5\u627e\u6587\u672c\u4e3a\"\u4e00\u4e2a\u5370\u6709 JCN \u7684\u5361\u8f66\"\uff0c\u53ef\u4ee5\u68c0\u7d22\u5230\u5de6\u4e0a\u56fe</p> <p>\uff083\uff09\u67e5\u627e\u6587\u672c\u4e3a\"\u4e00\u4e2a\u767d\u8272\u7684\u5b9d\u9a6c\u8f66\"\uff0c\u53ef\u4ee5\u68c0\u7d22\u5230\u5de6\u4e0b\u56fe\u3002</p> <p>CLIP\u5f7b\u5e95\u6253\u901a\u4e86\u6587\u672c\u548c\u56fe\u7247\uff0c\u53ef\u4ee5\u901a\u8fc7\u56fe\u7247\u67e5\u627e\u6587\u672c\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u6587\u672c\u67e5\u627e\u56fe\u7247\uff0c\u4e4b\u524d\u867d\u7136\u4e5f\u7814\u7a76\u8005\u505a\u8fc7\u7c7b\u4f3c\u7684\u5de5\u4f5c\uff0c\u4f46\u662f\u4e0d\u8bba\u6570\u636e\u96c6\u3001\u6a21\u578b\u7ed3\u6784\u7b49\uff0c\u90fd\u4e0d\u5982 CLIP</p>"},{"location":"learning/2/","title":"\u56fe\u89e3LayerNorm &amp; BatchNorm","text":""},{"location":"learning/2/#layernorm-batchnorm","title":"\u56fe\u89e3LayerNorm &amp; BatchNorm","text":"2024-11-25 22:33:462025-09-28 12:54:04 <p> \u7ea6 897 \u4e2a\u5b57  119 \u884c\u4ee3\u7801  30 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 6 \u5206\u949f</p> <p></p> <p></p> <p></p>"},{"location":"learning/2/#batchnorm1dnlp","title":"BatchNorm1D\u3001NLP","text":"<p>b=2\uff0cn=3\uff0cd=4</p> <ul> <li> \u7406\u89e3 3\u7ef4\u5f20\u91cf\u30014\u7ef4\u5f20\u91cf\uff1a</li> </ul> <p>\\(\\begin{cases} \u77e9\u9635\u6cd5:2\u4e2a3\u00d74\u7684\u77e9\u9635 \\\\  \\\\ \u62bd\u5c49\u6cd5:\u4e00\u76f4\u5212\u5206\u540c\u4e00\u4e2a\u65b9\u5411\uff0c\u76f4\u5230\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u753b\u53e6\u4e00\u4e2a\u65b9\u5411 \\end{cases}\\)</p> <p>\u90fd\u662f\u6a2a\u6392\u548c\u7ad6\u6392\u7684\u6570\u5b57\u6392\u5217\uff0c\u4e0d\u540c\u7ef4\u5ea6\u7684\u5f20\u91cf\u8868\u793a\u4e0d\u540c\u7684\u5206\u7ec4</p>"},{"location":"learning/2/#nlp","title":"\u600e\u4e48\u7406\u89e3nlp\u4e2d\u7684\u4e09\u7ef4\u5f20\u91cf\uff1f","text":"<ul> <li> \u77e9\u9635\u6cd5\uff1a</li> </ul> <p>2\u4e2a3\u00d74\u7684\u77e9\u9635\uff0c\u56fe\u89e3\uff1a</p> <p></p> <ul> <li> \u62bd\u5c49\u6cd5</li> </ul> <p>\uff08\u7b2c\u4e00\u6b21\u771f\u6b63\u5f00\u59cb\u7406\u89e3\u591a\u7ef4\u5f20\u91cf\u662f\u597d\u670b\u53cb\u62ff\u62bd\u5c49\u7ed9\u6211\u4e3e\u5f97\u4f8b\u5b50\uff0c\u56db\u7ef4\u5f20\u91cf\u5c31\u662f\u62bd\u5c49\u91cc\u9762\u8fd8\u6709\u62bd\u5c49\uff09</p> <p>\u8981\u70b9\uff1a\u4e00\u76f4\u6cbf\u540c\u4e00\u4e2a\u65b9\u5411\u5212\u5206\uff0c\u76f4\u5230\u6700\u540e\u4e00\u7ef4\u6362\u65b9\u5411</p> <p>2\u00d73\u00d74</p> <p></p> <p>\uff1a\u903b\u8f91\u7406\u987a\u4e86\uff0c\u611f\u89c9\u81ea\u5df1\u505a\u8fd9\u4e9b\u4e1c\u897f\u8822\u8822\u7684......\u4f46\u662f\uff0c\u6211\u8bb0\u6027\u4e0d\u597d\uff0c\u603b\u5fd8......\u7b28\u5c31\u7b28\u5427\uff0c\uff08\u51cc\u5999\u5999\u53e3\u543b\uff1a\u5e08\u5085\u5929\u5929\u8bf4\u4eba\u5bb6\u7b28\uff0c\u53ef\u4eba\u5bb6\u672c\u6765\u5c31\u662f\u7b28\uff09</p> <ul> <li> \u5b9e\u9645\u610f\u4e49</li> </ul> <p>\u5bf9\u4e8enlp\u6765\u8bf4\uff0cbnd=234\u8868\u793ab\u4e2a\u53e5\u5b50\uff0c\u6bcf\u4e2a\u53e5\u5b50n\u4e2a\u8bcd\uff0c\u6bcf\u4e2a\u8bcd\u6709d\u4e2a\u7ef4\u5ea6</p> <p>\\(batch\\_size \u00d7 max\\_sequence\\_length \u00d7 model\\_dim\\)</p> <p>\u5c31\u662f\u8bf4 \u73b0\u5728\u6709 2\u4e2a\u53e5\u5b50\uff0c\u6bcf\u4e2a\u53e5\u5b503\u4e2a\u5355\u8bcd\uff0c\u6bcf\u4e2a\u5355\u8bcd\u75284\u7ef4\u5411\u91cf\u8868\u793a</p> <p></p> <p>\u8fd9\u91cc\u7684\u95ee\u9898\u662f\uff1a\u6211\u4eec\u8fd9\u4e2a\u5143\u7d20\u7684\u4e2a\u6570\u90fd\u662f\u5bf9\u7684\uff0c\u4f46\u662f\u5728\u8ba1\u7b97\u673a\u4e2d\u5b58\u50a8\u4e2d\uff0c\u5e76\u4e0d\u662f\u8fd9\u4e48\u5b58\u7684</p> <ul> <li> \u5b9e\u9645\u610f\u4e49 &amp; \u77e9\u9635\u6cd5 &amp; \u8ba1\u7b97\u673a\u5b58\u50a8\u903b\u8f91</li> </ul> <p></p> Python<pre><code>batch_size = 2\ntimes_steps = 3\nembedding_dim = 4\n\ninputx = torch.randn(batch_size,times_steps,embedding_dim) # N*L*C\nprint(inputx)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Python<pre><code>tensor([[[ 0.8475, -0.3956, -0.5602,  1.4907],\n         [-0.0746, -0.0021,  0.1291, -0.0343],\n         [-0.3636,  1.8378,  0.1954, -1.0180]],\n\n        [[-1.0256,  1.0202,  0.7321,  0.3294],\n         [-0.6416,  0.5399,  0.8733,  1.7110],\n         [-1.1292,  0.2056,  0.6884,  0.2267]]])\n</code></pre> <ul> <li> <code>torch.randn</code> &amp; <code>torch.rand</code></li> </ul> <p>\u73b0\u5728\u5f00\u59cbnlp&amp;BN\uff0c\u56fe\u5f62\u7ed3\u5408\uff0c\u4f8b\u5b50\uff0c\u6570\u5b66\u4f8b\u5b50\uff0c\u4e0d\u8981\u8131\u79bb\u5b9e\u9645\u610f\u4e49</p> <p>\u4e5f\u5c31\u662f\u8bf4</p> <p>\u8f93\u5165\uff1a\u4e09\u7ef4\u5f20\u91cf\uff0c\u4e5f\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e8c\u7ef4\u6570\u8868\uff0c\u7528\u62ec\u53f7\u5206\u7ec4\uff0c\u6240\u4ee5\u6709\u4e86\u4e0d\u540c\u7684\u610f\u4e49</p>"},{"location":"learning/2/#bn1d","title":"\u600e\u4e48\u8ba1\u7b97BN1D\uff1f","text":"Python<pre><code>bn_mean = inputx.mean(dim=(0,1),keepdim=True)\nprint(bn_mean)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Python<pre><code>tensor([[[ 0.0695, -0.6811, -0.1232, -0.5339]]])\n</code></pre> <p>\u597d\u561f\uff0c\u8fd9\u4e32\u4ee3\u7801\u662f\u6ca1\u6709\u4efb\u4f55\u95ee\u9898\u4e86</p>"},{"location":"learning/2/#_1","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u5e93\u51fd\u6570\u8981\u7684\u8f93\u5165\u683c\u5f0f\uff1abnd \\(\\rightarrow\\) bdn</p> <ul> <li> \u8bf4\u4e00\u4e0b\u8fd9\u8fb9\u7684\u8f6c\u7f6e .transpose(-1,-2)</li> </ul> <p></p> <p>\u5b98\u7f51api\u7ed9\u4e86\uff0c\u8f93\u5165bdn\uff0c\u8f93\u51fabdn\uff0c\u6240\u4ee5\u8f93\u51fa\u4ee5\u540e\u518dtranspose\uff0c\u53d8\u6210bnd</p> <p>\u8fd8\u6709\u4e00\u70b9\uff0c\u4e0d\u7ba1\u662fBN\u8fd8\u662fLN\u90fd\u662f\u4e0d\u6539\u53d8\u5f62\u72b6\u7684</p> Python<pre><code>batch_size = 2\ntimes_steps = 3\nembedding_dim = 4\n\ninputx = torch.randn(batch_size,times_steps,embedding_dim) # N*L*C\n# print(inputx)\n# 1. \u5b9e\u73b0batch_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528 batch_norm API\nbatch_norm_op = torch.nn.BatchNorm1d(embedding_dim,affine=False)\nbn_y = batch_norm_op(inputx.transpose(-1,-2)).transpose(-1,-2)\n\n## \u624b\u5199batch_norm\nbn_mean = inputx.mean(dim=(0,1),keepdim=True)\n# print(bn_mean)\nbn_std = inputx.std(dim=(0,1),unbiased=False,keepdim=True)\nverify_bn_y = (inputx - bn_mean)/(bn_std+1e-5)\nprint(bn_y)\nprint(verify_bn_y)\nprint(torch.allclose(bn_y,verify_bn_y))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>tensor([[[ 1.2288e+00,  2.1594e-01, -8.7470e-01,  1.3089e+00],\n         [ 1.2093e+00,  5.8475e-01, -4.2434e-01, -4.7364e-01],\n         [-1.0128e+00, -1.9468e+00, -1.2768e+00,  2.7564e-01]],\n\n        [[-1.1732e+00,  3.5125e-01,  1.5184e+00, -1.3330e+00],\n         [ 4.1865e-01, -4.3382e-01, -4.6577e-04,  1.1563e+00],\n         [-6.7079e-01,  1.2287e+00,  1.0579e+00, -9.3418e-01]]])\ntensor([[[ 1.2288e+00,  2.1594e-01, -8.7470e-01,  1.3089e+00],\n         [ 1.2093e+00,  5.8474e-01, -4.2434e-01, -4.7363e-01],\n         [-1.0128e+00, -1.9468e+00, -1.2768e+00,  2.7564e-01]],\n\n        [[-1.1732e+00,  3.5125e-01,  1.5183e+00, -1.3330e+00],\n         [ 4.1865e-01, -4.3382e-01, -4.6576e-04,  1.1563e+00],\n         [-6.7079e-01,  1.2287e+00,  1.0579e+00, -9.3418e-01]]])\nTrue\n</code></pre>"},{"location":"learning/2/#bn2d","title":"BN2D","text":"<p>\u56fe\u7247\u7684\u5b58\u50a8\u683c\u5f0f\uff1abchw</p> <p>\u8ba1\u7b97BN</p> <p>\u81ea\u5df1\u8111\u888b\u91cc\u60f3\u7684\uff1a</p> <p></p> <p>\u8ba1\u7b97\u673a\u8ba4\u8bc6\u7684\uff1a</p> <p></p> <p>\u52a0\u62ec\u53f7\uff0c\u5c31\u53d8\u6210\u4e86\u5f20\u91cf</p> <p>\u8ba1\u7b97\u673a\u4e0e\u5b9e\u9645\u610f\u4e49\u8054\u7cfb\u8d77\u6765\uff1a\u4f18\u5148\u7ad6\u6392\uff0c\u6700\u540e\u4e00\u7ef4\u6a2a\u6392</p> <p>\u5982\u56fe\uff0c4\u00d73\u00d72\u00d72</p> <p></p>"},{"location":"learning/2/#bncv","title":"BN\u4e0eCV","text":"<p>bchw   \\(\\rightarrow\\) 1c11</p> <p>\u5bf9 bhw\u4e2a\u6570\u6c42\u548c \u8ba1\u7b97 \u5747\u503c\u548c\u65b9\u5dee</p> <p></p> <p></p> <p>step1</p> <p></p> <p>step2</p> <p></p> <p>step3</p> <p>\u7b2c\u4e09\u4e2a\u901a\u9053\u7684\u5747\u503c\u548c\u2f45\u5dee\uff1a</p> <p></p> <p></p>"},{"location":"learning/2/#_2","title":"\u4ee3\u7801","text":"Python<pre><code>import torch\nimport torch.nn as nn\n# \u6a21\u62df\u2f00\u4e2a\u8f93\u2f0a\u5f20\u91cf\nb, c, h, w = 4, 3, 2, 2 # \u4f8b\u5982\uff0c4\u4e2a\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u67093\u4e2a\u901a\u9053\uff0c\u6bcf\u4e2a\u901a\u9053\u7684\u2f24\u2f29\u4e3a2x2\n# \u5b9a\u4e49\u2f00\u4e2a\u6279\u91cf\u5f52\u2f00\u5316\u5c42\nbatch_norm = nn.BatchNorm2d(num_features=c) # c \u662f\u8f93\u2f0a\u7684\u901a\u9053\u6570\ninput_tensor = torch.arange(48).reshape((4,3,2,2)).float()\nprint(input_tensor)\n# \u5e94\u2f64\u6279\u91cf\u5f52\u2f00\u5316\noutput_tensor = batch_norm(input_tensor)\nprint(output_tensor)\nprint(output_tensor.shape) # \u8f93\u51fa\u7684\u5f62\u72b6\u4ecd\u7136\u662f [b, c, h, w]\n</code></pre> <p>\u5747\u503c &amp; \u65b9\u5dee\u4ee3\u7801\uff1a</p> Python<pre><code># \u8ba1\u7b97\u6bcf\u4e2a\u901a\u9053\u7684\u5747\u503c\u548c\u2f45\u5dee\nmean = input_tensor.mean(dim=(0, 2, 3))\nvar = input_tensor.var(dim=(0, 2, 3), unbiased=False)\nprint(f\"\u5747\u503c: {mean}\")\nprint(f\"\u2f45\u5dee: {var}\")\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Python<pre><code>\u5747\u503c: tensor([19.5000, 23.5000, 27.5000])\n\u2f45\u5dee: tensor([181.2500, 181.2500, 181.2500])\n</code></pre> <p></p>"},{"location":"learning/2/#ln1d","title":"LN1D","text":""},{"location":"learning/2/#_3","title":"\u6587\u5b57\u63cf\u8ff0\u3001\u5b9e\u9645\u610f\u4e49","text":"<ul> <li>LN\u662f\u5bf9\u6bcf\u4e2a\u8bcd\u7684\u6240\u6709\u7279\u5f81\u8fdb\u884c\u5f52\u4e00\u5316</li> </ul> <p>\u7c7b\u6bd4\u5230\u4e8c\u7ef4\u6570\u8868\u662f\u5bf9 \u6a2a\u884c\u6837\u672c\u884c\u8fdb\u884c\u5f52\u4e00\u5316</p> <ul> <li>BN\u662f\u5bf9\u540c\u4e00\u4e2a\u7279\u5f81\u7684\u6240\u6709\u6837\u672c\u8fdb\u884c\u5f52\u4e00\u5316</li> </ul> <p>\u7c7b\u6bd4\u5230\u4e8c\u7ef4\u6570\u8868 \u5c31\u662f\u5bf9\u5217\u8fdb\u884c\u5f52\u4e00\u5316</p> <ul> <li>\u6211\u89c9\u5f97\u7406\u89e3LN\u5c31\u4e00\u53e5\u8bdd\u7262\u7262\u8bb0\u4f4f\uff1aper sample\u3001per layer\uff01\u5c24\u5176\u662fper sample</li> </ul> <p>\u6709\u51e0\u4e2a\u6837\u672c\u3001\u5c31\u6709\u51e0\u4e2a\u5747\u503c&amp;\u65b9\u5dee\u3001\u7c7b\u4f3c\u7684</p> <p>\u6709\u51e0\u4e2a\u8bcd\uff0c\u5c31\u6709\u5747\u503c bnd \u2192 1n1</p> <p>\u6709\u51e0\u5f20\u56fe\u7247\uff0c\u5c31\u6709\u51e0\u4e2a\u5747\u503c  bchw\u2192b111</p> <p>\u6765\uff0c\u5728\u6298\u817e\u4e00\u4e0b\uff0cfor BN\uff0c\u7279\u5f81\u591a\u5c11\u7ef4\uff0c\u5c31\u662f\u51e0\u4e2a\u5747\u503c</p> <p>bnd\u219211d</p> <p>bchw\u21921c11</p> <ul> <li>\u4e8c\u7ef4\u6570\u8868\u7684\u683c\u5f0f\uff1a</li> </ul> <p></p>"},{"location":"learning/2/#_4","title":"\u56fe\u793a","text":"<p>\u5bf9\u6bd4\uff1aBN1D &amp; LN1D</p> <p></p>"},{"location":"learning/2/#_5","title":"\u6570\u5b66\u4f8b\u5b50","text":"<p>\u89c1\uff1a5\u79cd\u5f52\u4e00\u5316\u65b9\u6cd5</p>"},{"location":"learning/2/#_6","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u89c1\uff1a5\u79cd\u5f52\u4e00\u5316\u65b9\u6cd5</p>"},{"location":"learning/2/#ln2d","title":"LN2D","text":""},{"location":"learning/2/#_7","title":"\u6587\u5b57\u63cf\u8ff0","text":"<p>per sample</p>"},{"location":"learning/2/#_8","title":"\u6570\u5b66\u4f8b\u5b50","text":"Python<pre><code>import torch\nimport torch.nn as nn\nb, c, h, w = 4, 3, 2, 2 # \u4f8b\u5982\uff0c10\u4e2a\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u67093\u4e2a\u901a\u9053\uff0c\u6bcf\u4e2a\u901a\u9053\u7684\u2f24\u2f29\u4e3a32x32\n# \u5b9a\u4e49\u2f00\u4e2a\u5c42\u5f52\u2f00\u5316\u5c42\nlayer_norm = nn.LayerNorm(normalized_shape=[c, h, w]) # c, h, w \u5206\u522b\u662f\u901a\u9053\u6570\u3001\u2fbc\u5ea6\u548c\u5bbd\u5ea6\n# \u6a21\u62df\u2f00\u4e2a\u8f93\u2f0a\u5f20\u91cf\ninput_tensor = torch.arange(48).reshape((4,3,2,2)).float()\n# \u5e94\u2f64\u5c42\u5f52\u2f00\u5316\noutput_tensor = layer_norm(input_tensor)\n# print(input_tensor)\nprint(output_tensor) # \u8f93\u51fa\u7684\u5f62\u72b6\u4ecd\u7136\u662f [b, c, h, w]\n</code></pre>"},{"location":"learning/2/#_9","title":"\u56fe\u793a","text":"<p>\u5bf9\u6bd4\uff1a</p> <p></p>"},{"location":"learning/2/#_10","title":"\u4ee3\u7801\u5b9e\u73b0","text":"Python<pre><code>import torch\n\nbatch_size = 4\nchannels = 3\nh,w = 2,2\n\ninputx = torch.randn(batch_size,channels,h,w) # BCHW \u53ea\u8981\u7ef4\u5ea6\u662f\u6b63\u786e\u7684\uff0c\u6570\u5b57\u53ef\u4ee5\u968f\u4fbf\u751f\u6210\n\n# 1. \u5b9e\u73b0batch_norm\u5e76\u9a8c\u8bc1API\n\n## \u8c03\u7528 batch_norm API\nbatch_norm_op = torch.nn.BatchNorm2d(channels,affine=False)\nbn_y = batch_norm_op(inputx) # torch.Size([4, 3, 2, 2])\n\n## \u624b\u5199batch_norm\nbn_mean = inputx.mean(dim=(0,2,3),keepdim=True) # torch.Size([1, 3, 1, 1])\nbn_std = inputx.std(dim=(0,2,3),unbiased=False,keepdim=True) # torch.Size([1, 3, 1, 1])\nverify_bn_y = (inputx - bn_mean)/(bn_std+1e-5) # torch.Size([4, 3, 2, 2])\n\n# print(bn_mean.shape) \n# print(bn_std.shape) \n# print(bn_y.shape)   \n# print(verify_bn_y.shape)    \n# print(torch.allclose(bn_y,verify_bn_y))\n'''\n    torch.Size([1, 3, 1, 1])\n    torch.Size([1, 3, 1, 1])\n    torch.Size([4, 3, 2, 2])\n    torch.Size([4, 3, 2, 2])\n    True\n'''\n# 2. \u5b9e\u73b0layer_norm \u5e76\u9a8c\u8bc1api\n\n## \u8c03\u7528 layer_norm API\nlayer_norm_op = torch.nn.LayerNorm((channels,h,w),elementwise_affine=False)\nln_y = layer_norm_op(inputx)  # torch.Size([4, 3, 2, 2])\n\n## \u624b\u5199layer_norm\nln_mean = inputx.mean(dim=(1,2,3),keepdim=True)  # torch.Size([4, 1, 1, 1])\nln_std = inputx.std(dim=(1,2,3),keepdim=True,unbiased=False)  # torch.Size([4, 1, 1, 1])\nverify_bn_y = (inputx - ln_mean)/(ln_std + 1e-05)   # torch.Size([4, 3, 2, 2])\nprint(ln_mean.shape)\nprint(ln_std.shape)\nprint(ln_y.shape)\nprint(verify_bn_y.shape)\nprint(torch.allclose(ln_y,verify_bn_y))\n'''\n    torch.Size([4, 1, 1, 1])\n    torch.Size([4, 1, 1, 1])\n    torch.Size([4, 3, 2, 2])\n    torch.Size([4, 3, 2, 2])\n    True\n'''\n</code></pre>"},{"location":"learning/2/#_11","title":"\u603b\u7ed3","text":"<p>\u6240\u6709\u7684\u56fe\u793a \u518d\u770b\u4e00\u904d</p> <p>BN\u5e38\u7528\u4e8eCV</p> <p>LN\u5e38\u7528\u4e8eNLP</p> <p></p> <p></p>"},{"location":"learning/2_MOCO/","title":"MOCO","text":""},{"location":"learning/2_MOCO/#moco","title":"MOCO","text":"2025-02-22 22:04:482025-09-28 12:54:04 <p> \u7ea6 2975 \u4e2a\u5b57  34 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 15 \u5206\u949f</p> <p></p> <p>why MOCO?</p> <p>MOCO\u7b97\u6cd5\u662f\u4e00\u4e2a\u5bf9\u6bd4\u5b66\u4e60\u7b97\u6cd5\uff0c\u56e0\u4e3a MOCO \u7b97\u6cd5\u7684\u601d\u60f3\u5bf9\u5f88\u591a\u540e\u6765\u7684\u7b97\u6cd5\uff0c\u5305\u62ec\u591a\u6a21\u6001\u7b97\u6cd5\u90fd\u6709\u5f71\u54cd\uff0cso....</p> <p>Momentum Contrast for Unsupervised Visual Representation Learning,MOCO</p> <p>\u52a8\u91cf\u5bf9\u6bd4\u3001\u65e0\u76d1\u7763\u89c6\u89c9\u8868\u793a\u5b66\u4e60</p>"},{"location":"learning/2_MOCO/#_1","title":"\u5bf9\u6bd4\u5b66\u4e60\u662f\u4ec0\u4e48\uff1f","text":"<p>\u5982\u679c\u8981\u517b\u4e00\u53ea\u732b\uff0c\u4f46\u662f\u4f60\u4e4b\u524d\u5b8c\u5168\u4e0d\u4e86\u89e3\u732b\u7684\u54c1\u79cd\uff0c\u53bb\u4e86\u5ba0\u7269\u5e97\u4e4b\u540e\uff0c\u8001\u677f\u6b63\u5728\u5fd9\uff0c\u8ba9\u4f60\u81ea\u5df1\u5148\u770b\u770b\u4f60\u559c\u6b22\u4ec0\u4e48\u6837\u7684\u732b\uff0c\u8001\u677f\u544a\u8bc9\u4f60\u4e0d\u540c\u54c1\u79cd\u7684\u732b\u88ab\u5173\u5728\u4e0d\u540c\u7b3c\u5b50\u91cc\uff0c\u4f60\u4e0d\u77e5\u9053\u6bcf\u4e2a\u7b3c\u5b50\u91cc\u732b\u7684\u5177\u4f53\u54c1\u79cd\uff0c\u4f46\u662f\u4f60\u77e5\u9053\u540c\u4e00\u4e2a\u7b3c\u5b50\u91cc\u7684\u732b\u662f\u540c\u4e00\u4e2a\u54c1\u79cd\uff0c\u4e0d\u540c\u7b3c\u5b50\u91cc\u7684\u732b\u662f\u4e0d\u540c\u7684\u54c1\u79cd\uff0c\u4f60\u5c31\u4ed4\u7ec6\u89c2\u5bdf\u8fd9\u4e9b\u732b\u6709\u4ec0\u4e48\u4e0d\u540c\uff0c\u9010\u6e10\u4f60\u53d1\u73b0\u5b83\u4eec\u6bdb\u53d1\u7684\u957f\u77ed\u3001\u989c\u8272\u3001\u82b1\u7eb9\u3001\u8138\u578b\u7b49\u7b49\u7279\u5f81\u7684\u4e0d\u540c\uff0c\u7ecf\u8fc7\u51e0\u5206\u949f\u7684\u89c2\u5bdf\u540e\uff0c\u4f60\u5c31\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u5b66\u4e60\u7684\u8fd9\u4e9b\u7279\u5f81\u6765\u533a\u5206\u4e24\u53ea\u732b\u662f\u4e0d\u662f\u540c\u4e00\u4e2a\u54c1\u79cd\u4e86\uff0c\u4f46\u6b64\u65f6\u4f60\u8fd8\u662f\u4e0d\u77e5\u9053\u6bcf\u4e2a\u54c1\u79cd\u7684\u540d\u5b57\u3002</p> <p>\u4ee5\u4e0a\u8fdb\u884c\u7684\u5c31\u662f\u5bf9\u6bd4\u5b66\u4e60</p> <p>\u5bf9\u6bd4\u5b66\u4e60\u901a\u8fc7\u6b63\u8d1f\u6837\u672c\u5bf9\u4e92\u76f8\u5bf9\u6bd4\u6765\u5b66\u4e60\u6837\u672c\u7684\u7279\u5f81\uff0c\u62bd\u53d6\u5230\u4e86\u63cf\u8ff0\u732b\u7684\u91cd\u8981\u7279\u5f81\uff0c\u5305\u62ec\u6bdb\u53d1\u957f\u77ed\u3001\u989c\u8272\u3001\u82b1\u7eb9\u3001\u8138\u578b\u7b49</p> <p>\u6b64\u65f6\uff0c\u5982\u679c\u8001\u677f\u5fd9\u5b8c\u4e86\uff0c\u6bcf\u4e2a\u54c1\u79cd\u5206\u522b\u62ff\u4e00\u53ea\u732b\u544a\u8bc9\u4f60\u732b\u7684\u54c1\u79cd\u540d\u79f0\uff0c\u4f60\u5c31\u9a6c\u4e0a\u80fd\u628a\u4f60\u5b66\u5230\u7684\u732b\u7684\u7279\u5f81\u6620\u5c04\u5230\u732b\u7684\u54c1\u79cd\u540d\u79f0\u4e0a\uff0c\u4ece\u800c\u53ef\u4ee5\u5bf9\u732b\u7684\u54c1\u79cd\u8fdb\u884c\u5206\u7c7b</p> <p></p> <p>\u901a\u8fc7\u4e66\u9762\u7684\u5b9a\u4e49\uff0c\u6ce8\u610f</p>"},{"location":"learning/2_MOCO/#_2","title":"\u5bf9\u6bd4\u5b66\u4e60\u4e3a\u4ec0\u4e48\u662f\u65e0\u76d1\u7763\u7684","text":"<p>\uff081\uff09\u4e3a\u4ec0\u4e48\u8bf4 \u5bf9\u6bd4\u5b66\u4e60\u662f\u65e0\u76d1\u7763\u5b66\u4e60\uff1f\u4e0d\u662f\u8fd8\u9700\u8981\u4eba\u51c6\u5907\u6b63\u8d1f\u6837\u672c\u5bf9\u5417\uff1f</p> <p>\u56e0\u4e3a\u6b63\u8d1f\u6837\u672c\u5bf9\u6709\u5f88\u591a\u65b9\u6cd5\u53ef\u4ee5\u7b80\u5355\u7684\u81ea\u52a8\u751f\u6210\uff0c\u4e0d\u7528\u4eba\u624b\u5de5\u6807\u6ce8\uff0c\u6240\u4ee5\u662f\u65e0\u76d1\u7763\u5b66\u4e60</p> <p>\u518d\u5bf9\u56fe\u50cf\u7684\u5bf9\u6bd4\u5b66\u4e60\u4e2d\uff0c\u53ef\u4ee5\u901a\u8fc7\u5b9e\u4f8b\u5224\u522b\uff0c\u6765\u751f\u6210\u6b63\u8d1f\u6837\u672c\u5bf9\uff0c\u5047\u5982\u6211\u4eec\u67094 \u5f20\u56fe\u7247\uff0c\u9996\u5148\u901a\u8fc7\u56fe\u50cf\u589e\u5f3a\u6bd4\u5982\u5bf9\u56fe\u50cf\u8fdb\u884c\u62c9\u4f38\u3001\u65cb\u8f6c\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u56fe\u7247\uff0c\u8fd9\u4e2a\u65b0\u751f\u6210\u7684\u56fe\u7247\u63cf\u8ff0\u7684\u8bed\u4e49\u5e76\u6ca1\u6709\u53d1\u751f\u6539\u53d8\uff0c\u6240\u4ee5\u662f\u6b63\u6837\u672c\u5bf9</p> <p>\u800c\u539f\u59cb\u56fe\u7247\u548c\u5176\u4ed6\u56fe\u7247\u4e4b\u95f4\u5c31\u662f\u8d1f\u6837\u672c\u5bf9</p> <p></p> <p>\u518d\u6bd4\u5982\u5728\u6587\u672c\u7684\u5bf9\u6bd4\u5b66\u4e60\u91cc\uff0c\u6709\u5f88\u591a\u53e5\u8bdd\uff0c\u6bcf\u4e00\u53e5\u8bdd\u548c\u5176\u4ed6\u8bdd\u90fd\u53ef\u4ee5\u8ba4\u4e3a\u662f\u4e0d\u540c\u7684\uff0c\u5b83\u4eec\u662f\u8d1f\u6837\u672c\u5bf9\uff0c\u90a3\u4e48\u5982\u4f55\u6784\u9020\u6b63\u6837\u672c\u5bf9\u5462\uff1f</p> <p></p> <p>\u4e5f\u5c31\u662f\u600e\u4e48\u6784\u9020\u4e24\u53e5\u4e0d\u540c\u7684\u8bdd\u4f46\u662f\u63cf\u8ff0\u7684\u610f\u601d\u662f\u4e00\u6837\u7684\u5462\uff1f\u53ef\u4ee5\u901a\u8fc7\u7ffb\u8bd1\u589e\u5f3a\u7684\u65b9\u6cd5\u6765\u6784\u9020\uff0c\u4e5f\u5c31\u662f\u5148\u628a\u4e00\u53e5\u8bdd\u7ffb\u8bd1\u4e3a\u5176\u5b83\u8bed\u8a00\uff0c\u518d\u7ffb\u8bd1\u56de\u6765\uff0c\u8fd9\u6837\u5c31\u591f\u9020\u6210\u4e86\u8868\u8ff0\u4e0d\u540c\u4f46\u610f\u601d\u76f8\u540c\u7684\u4e24\u53e5\u8bdd</p> <p>\u6bd4\u5982\u56fe\u4e2d\u4f8b\u5b50</p> <p>\"\u8bf7\u4f60\u52a1\u5fc5\u60ac\u5d16\u52d2\u9a6c\"\u7ecf\u8fc7\u7ffb\u8bd1\u4e3a\u82f1\u6587\uff0c\u518d\u7ffb\u8bd1\u56de\u4e2d\u6587\u540e\u5c31\u53d8\u6210\u4e86\"\u8bf7\u5728\u4e3a\u65f6\u5df2\u665a\u4e4b\u524d\u505c\u6b62\"\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u7a0b\u5e8f\u5316\u7684\u6784\u9020\u6b63\u6837\u672c\u5bf9\uff0c\u800c\u65e0\u9700\u624b\u5de5\u6784\u9020\u6216\u8005\u6807\u6ce8</p> <p>\u6700\u540e\uff0c\u5982\u4f55\u5728\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60</p> <p></p> <p>\u5047\u5982\u6536\u96c6\u5230\u4e86\u5f88\u591a\u56fe\u6587\u5bf9\uff0c\u90a3\u4e48\u6bcf\u4e2a\u56fe\u6587\u5bf9\u5c31\u662f\u4e00\u4e2a\u6b63\u6837\u672c\u5bf9\uff0c\u800c\u6bcf\u4e2a\u56fe\u7247\u548c\u5176\u4ed6\u56fe\u7247\u5bf9\u5e94\u7684\u6587\u672c\u5c31\u6784\u6210\u4e86\u8d1f\u6837\u672c\u5bf9\uff0c\u5bf9\u6bd4\u5b66\u4e60\u548c\u76d1\u7763\u5b66\u4e60\u76f8\u6bd4\u96be\u70b9\u662f\u4ec0\u4e48\uff1f</p>"},{"location":"learning/2_MOCO/#_3","title":"\u5bf9\u6bd4\u5b66\u4e60\u7684\u96be\u70b9","text":"<p>\u76d1\u7763\u5b66\u4e60\u6709\u56fa\u5b9a\u7684 label\uff0c\u6a21\u578b\u4e0d\u65ad\u7684\u8c03\u6574\u81ea\u5df1\u7684\u53c2\u6570\u8ba9\u81ea\u5df1\u7684\u8f93\u51fa\u8d8a\u6765\u8d8a\u63a5\u8fd1label\uff0c\u4f46\u662f\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578b\u8981\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u7279\u5f81\u5411\u91cf\uff0c\u8981\u6c42\u6b63\u6837\u672c\u5bf9\u7684\u7279\u5f81\u5411\u91cf\u8ddd\u79bb\u8fd1\uff0c\u8d1f\u6837\u672c\u5bf9\u7684\u7279\u5f81\u5411\u91cf\u8ddd\u79bb\u8fdc</p> <p>\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u6bd4\u4e24\u4e2a\u6837\u672c\u5411\u91cf\u90fd\u662f\u6a21\u578b\u751f\u6210\u7684\uff0c\u800c\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4e00\u76f4\u5728\u8c03\u6574\u53c2\u6570\uff0c\u6bcf\u6b21\u8c03\u6574\u540e\u5bf9\u4e8e\u539f\u6765\u540c\u4e00\u4e2a\u6837\u672c\u751f\u6210\u7684\u7279\u5f81\u4e5f\u4f1a\u53d8\u5316\uff0c\u6240\u4ee5\u5bf9\u6bd4\u5b66\u4e60\u6ca1\u6709\u56fa\u5b9a\u7684 label \u53ef\u4ee5\u5b66\u4e60\uff0c\u4e00\u5207\u90fd\u662f\u5728\u53d8\u5316\u4e2d\u8c03\u6574\u7684</p>"},{"location":"learning/2_MOCO/#label","title":"\u5bf9\u6bd4\u5b66\u4e60\u6ca1\u6709\u56fa\u5b9a\u7684 label","text":"<p>\u5bf9\u6bd4\u5b66\u4e60\u6ca1\u6709\u56fa\u5b9a\u7684 label \u5e26\u6765\u7684\u95ee\u9898\u662f\uff0c\u5982\u679c batchsize \u592a\u5c0f\u4f1a\u9020\u6210\u5b66\u4e60\u56f0\u96be</p> <p>\u5982\u56fe\u662f\u4e00\u4e2a batch\uff0c\u67091\u4e2a\u6b63\u6837\u672c\u5bf9\uff0c3 \u4e2a\u8d1f\u6837\u672c\u5bf9\uff0c\u901a\u8fc7\u8fd9\u4e2a batch \u7684\u8bad\u7ec3\u6a21\u578b\u53ef\u4ee5\u5f88\u597d\u7684\u533a\u5206\u6b63\u8d1f\u6837\u672c\u5bf9</p> <p>\u5047\u8bbe\u5411\u91cf\u7a7a\u95f4\u662f\u56fe\u5f62\u7684</p> <p>\u6bcf\u4e2a\u6837\u672c\u7684\u5411\u91cf\u88ab\u5206\u914d\u5230\u4e86\u5408\u9002\u7684\u4f4d\u7f6e\u4e0a</p> <p>\u4e0b\u4e00\u4e2a batch \u7684\u6570\u636e\u53c8\u6765\u4e86\uff1a</p> <p></p> <p>\u6a21\u578b\u5728\u8fd9\u4e2a batch \u4e0a\u53ef\u4ee5\u5f88\u597d\u7684\u628a\u6b63\u8d1f\u6837\u672c\u5bf9\u8fdb\u884c\u533a\u5206\uff0c\u628a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u7684\u7279\u5f81\u5411\u91cf\u5206\u5e03\u5728\u8fd9\u4e2a\u5411\u91cf\u7a7a\u95f4\u4e0a\uff0c\u4f46\u662f\u6b64\u65f6\u6a21\u578b\u770b\u4e0d\u5230\u4e0a\u4e00\u4e2a batch \u7684\u6837\u672c\uff0c\u6a21\u578b\u5206\u914d\u7684\u5411\u91cf\u4f4d\u7f6e\u53ef\u80fd\u548c\u4e0a\u4e00\u4e2a batch \u5206\u914d\u7684\u5411\u91cf\u4f4d\u7f6e\u91cd\u5408\uff0c\u8ba9\u539f\u672c\u4e0d\u662f\u6b63\u6837\u672c\u5bf9\u7684\u4e24\u4e2a\u6837\u672c\u8ddd\u79bb\u5f88\u8fd1\uff0c\u5982\u679c\u6bcf\u6b21\u90fd\u53ef\u4ee5\u62ff\u6240\u6709\u7684\u6837\u672c\u8fdb\u884c\u8bad\u7ec3\u5c31\u597d\u4e86\uff0c\u4f46\u662f\u663e\u5b58\u53c8\u662f\u6709\u9650\u7684\uff0c\u8fd9\u6837\u505a\u662f\u4e0d\u73b0\u5b9e\u7684</p> <p></p> <p>\u8fd8\u6709\u4e00\u79cd\u529e\u6cd5\u5c31\u662f\u5728\u5185\u5b58\u4e2d\u8bb0\u5f55\u4e4b\u524d batch \u751f\u6210\u5411\u91cf\uff0c\u8fd9\u4e9b\u4e4b\u524d\u751f\u6210\u7684\u5411\u91cf\u4e0d\u8bb0\u5f55\u68af\u5ea6\uff0c\u8ba1\u7b97 loss \u65f6\u4e0d\u8fdb\u884c\u540e\u5411\u4f20\u64ad\uff0c\u53ea\u662f\u7528\u6765\u8ba9\u6a21\u578b\u66f4\u597d\u7684\u5206\u914d\u5411\u91cf\u4f4d\u7f6e\uff0c\u8fd9\u6837\u8fd9\u4e9b\u5411\u91cf\u5c31\u4e0d\u4f1a\u989d\u5916\u5360\u7528\u663e\u5b58</p> <p>\u4f46\u53c8\u4f1a\u6709\u53e6\u4e00\u4e2a\u95ee\u9898\uff0c\u5c31\u662f\u6a21\u578b\u968f\u7740\u8bad\u7ec3\u5728\u4e00\u76f4\u53d8\u5316\uff0c\u6bcf\u4e2a batch \u751f\u6210\u6837\u672c\u7279\u5f81\u5411\u91cf\u7684\u6a21\u578b\u662f\u4e0d\u540c\u7684\uff0c\u4e0d\u80fd\u62ff\u8fc7\u53bb\u6a21\u578b\u751f\u6210\u7684\u5411\u91cf\u6765\u8c03\u6574\u73b0\u5728\u7684\u6a21\u578b\uff0c\u6240\u4ee5\u5bf9\u6bd4\u5b66\u4e60\u60f3\u8981\u6548\u679c\u597d\uff0c\u5c31\u8981\u540c\u65f6\u6ee1\u8db3\u4e24\u4e2a\u6761\u4ef6</p>"},{"location":"learning/2_MOCO/#_4","title":"\u5bf9\u6bd4\u5b66\u4e60\u4e24\u4e2a\u8981\u6c42","text":"<p>\u7b2c\u4e00\u4e2a\uff0c\u8d1f\u4f8b\u8981\u5c3d\u53ef\u80fd\u591a\uff0c\u8fd9\u6837\u5c31\u80fd\u8ba9\u6a21\u578b\u628a\u4e0d\u540c\u7684\u6837\u672c\u5728\u7279\u5f81\u7a7a\u95f4\u5185\u5c3d\u53ef\u80fd\u7684\u533a\u5206\u5f00\u6765</p> <p>\u7b2c\u4e8c\u4e2a\uff0c\u8d1f\u4f8b\u8981\u5c3d\u53ef\u80fd\u7684\u4e00\u81f4\uff0c\u4e5f\u5c31\u662f\u6700\u597d\u662f\u7531\u540c\u4e00\u4e2a\u6a21\u578b\u751f\u6210\u7684\uff0c\u5982\u679c\u4e0d\u662f\u540c\u4e00\u4e2a\u6a21\u578b\u751f\u6210\u7684\uff0c\u4e5f\u4e0d\u8981\u5dee\u522b\u592a\u5927\uff0c\u4e0d\u7136\u8bad\u7ec3\u5c31\u6ca1\u6709\u610f\u4e49</p> <p>MOCO \u540c\u65f6\u6ee1\u8db3\u4e0a\u9762\u4e24\u4e2a\u6761\u4ef6\uff0c\u4ece\u800c\u5728\u89c6\u89c9\u5bf9\u6bd4\u65b9\u9762\u53d6\u5f97\u6210\u529f</p>"},{"location":"learning/2_MOCO/#moco_1","title":"MOCO \u601d\u60f3","text":"<p>MOCO \u8bba\u6587\u540d\u7684\u4e2d\u6587\u7ffb\u8bd1\uff1a\u57fa\u4e8e\u52a8\u91cf\u5bf9\u6bd4\u7684\u65e0\u76d1\u7763\u89c6\u89c9\u8868\u793a\u5b66\u4e60</p> <p>\u52a8\u91cf\u6307\u7684\u662f\u6307\u6570\u79fb\u52a8\u5e73\u5747EMA</p>"},{"location":"learning/2_MOCO/#_5","title":"\u6307\u6570\u79fb\u52a8\u5e73\u5747","text":"<p>\u6307\u6570\u79fb\u52a8\u5e73\u5747\u5728\u80a1\u7968\u5206\u6790\u4e2d\u7ecf\u5e38\u7528\u5230\uff0c\u80a1\u7968\u4ef7\u683c\u6bcf\u5929\u6ce2\u52a8\u5f88\u5927\uff0c\u6709\u6ca1\u6709\u4e00\u4e2a\u53ef\u4ee5\u53cd\u5e94\u80a1\u7968\u957f\u671f\u8d8b\u52bf\u7684\u6307\u6807\u5462\uff1f\u6307\u6570\u79fb\u52a8\u5e73\u5747\u7ebf\u5c31\u662f\u4e00\u4e2a\u63cf\u8ff0\u80a1\u7968\u957f\u671f\u8d8b\u52bf\u7684\u6307\u6807\uff0c\u5b83\u4e0d\u4f1a\u968f\u7740\u80a1\u7968\u4ef7\u683c\u6bcf\u5929\u6ce2\u52a8\u592a\u5927</p> <p>EMA \u7684\u8ba1\u7b97\u516c\u5f0f\uff1a</p> <p>\\(EMA_t= \\alpha * EMA_{t-1} + (1-\\alpha)*x_t\\)</p> <p>\u5728\\(t\\) \u65f6\u523b\u7684\u503c \\(=\\) \u52a8\u91cf\u7cfb\u6570 \\(\\alpha\\) * \u4e0a\u4e00\u65f6\u523b\u7684\u503c \\(EMA_{t-1}\\) + \\((1-\\alpha)\\) * \u5f53\u524d\u65f6\u523b\u7684\u89c2\u5bdf\u503c</p> <p>\u6bd4\u5982\u5728\u672c\u4f8b\u4e2d\uff0c\u5f53\u524d\u65f6\u523b\u7684\u89c2\u5bdf\u503c\u662f \u5f53\u5929\u80a1\u7968\u7684\u4ef7\u683c</p> <p>\\(\\alpha\\) \u4e00\u822c\u90fd\u662f\u4e00\u4e2a\u63a5\u8fd1\u4e8e 1 \u7684\u503c</p> <p>\u4ed4\u7ec6\u89c2\u5bdf\u516c\u5f0f\u4f1a\u53d1\u73b0\uff0c\u5f53\u524d\u65f6\u523b\u7684\u503c\u5927\u90e8\u5206\u90fd\u662f\u53d6\u51b3\u4e8e\u4e0a\u4e00\u4e2a\u65f6\u523b\u7684\u81ea\u5df1\u7684\u503c\uff0c\u53ea\u6709\u5f88\u5c0f\u5f88\u5c0f\u4e00\u90e8\u5206\u53d6\u81ea\u5f53\u524d\u7684\u89c2\u5bdf\u503c\uff0c\u4e5f\u5c31\u662f \u6307\u6570\u79fb\u52a8\u5e73\u5747 \u53d7\u81ea\u8eab\u7684\u5f71\u54cd\u5927\uff0c\u53d7\u5916\u754c\u7684\u5f71\u54cd\u5c0f\uff0c\u6240\u4ee5\u5728 MOCO \u4e2d\u5f88\u7a33\u5b9a\uff0c\u5728 MOCO \u4e2d\u52a8\u91cf\u7cfb\u6570\u4e3a 0.999</p>"},{"location":"learning/2_MOCO/#moco_2","title":"MOCO \u7684\u505a\u6cd5","text":"<p>MOCO \u628a\u56fe\u50cf\u5bf9\u6bd4\u5b66\u4e60\u770b\u6210\u4e00\u4e2a\u5b57\u5178\u68c0\u7d22\u95ee\u9898</p> <p>\u6bcf\u6b21\u6709\u4e00\u4e2a\u6837\u672c\uff0c\u79f0\u4e3a query</p> <p>\u5b57\u5178\u4e2d\u6709\u4e00\u4e2a\u6b63\u6837\u672c\uff0c\u5176\u5b83\u90fd\u662f\u8d1f\u6837\u672c\uff0c\u5206\u522b\u4e3a \\(k_0\\)\u3001\\(k_1\\) \u3001\\(k_2\\)  ......</p> <p>\u5bf9\u6bd4\u5b66\u4e60\u7684\u4efb\u52a1\u5c31\u662f\u6839\u636e query\u4ece\u4e00\u5927\u5806 k \u4e2d\u627e\u5230\u552f\u4e00\u7684\u6b63\u6837\u672c\u7684 k</p> <p>MOCO \u4e2d\u6709\u4e00\u4e2a\u961f\u5217\u5b58\u7740\u5927\u91cf\u7684\u8d1f\u6837\u672c\u7684 k</p> <p>\u6bcf\u4e2a batch \u90fd\u4f1a\u7ed9\u8d1f\u6837\u672c\u961f\u5217\u4e2d\u589e\u52a0\u8d1f\u6837\u672c\u7684 k</p> <p>\u524d\u9762\u4ecb\u7ecd\u6bcf\u4e2a batch\u6a21\u578b\u8bad\u7ec3\u540e\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u751f\u6210\u7684\u8d1f\u6837\u672c\u5411\u91cf\u548c\u4e4b\u524d batch \u751f\u6210\u7684\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u8bad\u7ec3\u6548\u679c\u4e0d\u597d</p> <p>MOCO \u7684\u505a\u6cd5\u662f\u5206\u6210\u4e24\u4e2a\u6a21\u578b\uff0c\u4e00\u4e2a\u662f query \u6a21\u578b\uff0c\u4e00\u4e2a\u662f k \u6a21\u578b\uff0cquery \u6a21\u578b\u662f\u5b9e\u9645\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u6bcf\u4e2a batch \u6839\u636e\u5bf9\u6bd4 loss \u5229\u7528\u4f18\u5316\u5668\u66f4\u65b0\u81ea\u5df1\u7684\u6a21\u578b\u53c2\u6570</p> <p>\u800c k\u6a21\u578b\uff0c\u4e5f\u53eb\u505a\u52a8\u91cf\u6a21\u578b\uff0c\u662f\u4ece query \u6a21\u578b\u521d\u59cb\u5316\u7684\uff0c\u6bcf\u4e2a batch \u4e0d\u66f4\u65b0\u81ea\u5df1\u7684\u6a21\u578b\u53c2\u6570\uff0c\u800c\u662f\u5229\u7528 query \u6a21\u578b\uff1a\u6307\u6570\u79fb\u52a8\u5e73\u5747\u6765\u66f4\u65b0\u81ea\u5df1\u7684\u53c2\u6570</p> <p>\u516c\u5f0f \uff1a \\(\\theta_k^t = 0.999*\\theta_k^{t-1}+0.001*\\theta_q^t\\) </p> <p>\u516c\u5f0f\u7ed9\u51fa\u4e86\u6a21\u578b\u66f4\u65b0\u7684\u8fc7\u7a0b\uff0c\u6bcf\u4e2a batch \u540e\uff0ck \u6a21\u578b\u7684\u53c2\u6570 \\(\\theta_k^t\\) =0.999\u00d7\u4e0a\u4e00\u4e2a\u65f6\u523b\u81ea\u5df1\u7684\u53c2\u6570 \\(\\theta_k^{t-1}\\) +0.001\u00d7query \u6a21\u578b\u8fd9\u4e2a batch \u66f4\u65b0\u540e\u7684\u53c2\u6570 \\(\\theta_q^t\\) </p> <p>\u56e0\u4e3a MOCO \u961f\u5217\u91cc\u5927\u91cf\u8d1f\u6837\u672c\u7684\u7279\u5f81\u5411\u91cf\u90fd\u662f\u901a\u8fc7\u52a8\u91cf\u6a21\u578b\u751f\u6210\u7684\uff0c\u52a8\u91cf\u6a21\u578b\u662f\u901a\u8fc7\u6307\u6570\u79fb\u52a8\u5e73\u5747\u6765\u66f4\u65b0\u7684\uff0c\u8ddf\u968f\u4e86 query \u6a21\u578b\u53c2\u6570\u53d8\u5316\u7684\u8d8b\u52bf\uff0c\u53c8\u4fdd\u8bc1\u4e86 batch \u4e4b\u95f4\u53d8\u5316\u4e0d\u81f3\u4e8e\u592a\u5927\uff0c\u6240\u4ee5\u961f\u5217\u91cc\u4fdd\u5b58\u7684\u8d1f\u6837\u672c\u5411\u91cf\u5bf9\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u6765\u8bf4\u5c31\u662f\u53c8\u591a\u53c8\u4e00\u81f4\uff0c\u53ef\u4ee5\u5f88\u597d\u7684\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60</p>"},{"location":"learning/2_MOCO/#infonce","title":"InfoNCE","text":"<p>MOCO \u4e2d\u5bf9\u6bd4\u5b66\u4e60\u7684 LOSS\u91c7\u7528\u7684\u662f InfoNCE\uff1a</p> <p>\\(Loss_q = -\\log \\frac{\\exp(q\\cdot k_+)}{\\sum_{i=0}^K \\exp(q \\cdot k_i)}\\)</p> <p>\u9996\u5148\uff0cLOSS \u4e2d log \u7684\u771f\u6570\u90e8\u5206 $ \\frac{\\exp(q\\cdot k_+)}{\\sum_{i=0}^K \\exp(q \\cdot k_i)} $</p> <p>\u662f\u4e00\u4e2a softmax</p> <p>\u5206\u5b50\u662f query \u5411\u91cf\u548c\u6b63\u6837\u672c\u5411\u91cf\u7684 cosine \u76f8\u4f3c\u5ea6\u7684\u4e00\u6b21\u65b9\uff0c\u56e0\u4e3a\u8fd9\u4e24\u4e2a\u5411\u91cf\u90fd\u5f52\u4e00\u5316\u8fc7\uff0c\u6240\u4ee5 \u70b9\u4e58 \u5c31\u662f cosine \u76f8\u4f3c\u5ea6</p> <p>\u5206\u6bcd\u90e8\u5206 \u662f\u4e00\u4e2a\u6b63\u6837\u672c\u548c\u961f\u5217\u4e2d\u6240\u6709\u8d1f\u6837\u672c\u4e0e query \u5411\u91cf\u4e4b\u95f4\u7684 cosine \u76f8\u4f3c\u5ea6\u7684\u4e00\u6b21\u65b9\u7684\u7d2f\u52a0</p> <p>\u6700\u540e\u8fdb\u884c \u8d1f\u7684 log \u8ba1\u7b97\uff0c\u5b9e\u9645\u4e0a\u5c31\u662f\u4e00\u4e2a\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u53ef\u4ee5\u770b\u505a\u662f\u4ece k \u4e2a\u8d1f\u6837\u672c\u548c 1 \u4e2a\u6b63\u6837\u672c\u4e00\u5171 k+1 \u4e2a\u6837\u672c\u4e2d\uff0c\u5206\u7c7b\u4e3a\u6b63\u6837\u672c\u7684\u4ea4\u53c9\u71b5\u635f\u5931</p> <p>\u5b9e\u9645\u5728\u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u5bf9\u4e8e\u6bcf\u4e2a cosine \u76f8\u4f3c\u5ea6\u8fd8\u8981\u9664\u4ee5\u4e00\u4e2a\u6e29\u5ea6\u7cfb\u6570 \\(\\tau\\) \uff1a</p> <p>\\(Loss_q = -\\log \\frac{\\exp(q\\cdot k_+/\\tau)}{\\sum_{i=0}^K \\exp(q \\cdot k_i/\\tau)}\\)</p> <p>\u6e29\u5ea6\u7cfb\u6570 \\(\\tau\\) \u8d8a\u5927\uff0c\u7ecf\u8fc7 softmax \u4e4b\u540e\uff0c\u5404\u79cd\u7c7b\u522b\u7684\u6982\u7387\u5dee\u522b\u5c31\u8d8a\u5c0f</p> <p>\u6e29\u5ea6\u7cfb\u6570 \\(\\tau\\) \u8d8a\u5c0f\uff0c\u7ecf\u8fc7 softmax \u4e4b\u540e\uff0c\u5404\u79cd\u7c7b\u522b\u7684\u6982\u7387\u5dee\u522b\u5c31\u8d8a\u5927</p> <p>\uff08why\uff1f\\(\\downarrow\\) \uff09</p> <p>\u6bd4\u5982\u56fe\u4e2d \\(X=1\u3001Y=2\u3001Z=3\\) \u8fd9\u4e09\u4e2a\u503c\u8fdb\u884c softmax \u8ba1\u7b97\uff0c\u5f53 \\(\\tau=1\\)\u65f6 \u5c31\u662f\u4e00\u4e2a\u6807\u51c6\u7684 softmax\uff0c\u8fd9\u4e09\u4e2a\u503c\u7ecf\u8fc7 softmax \u7684\u6982\u7387\u5206\u5e03\u5982\u56fe\uff1a</p> <p></p> <p>\u5982\u679c\u8c03\u4f4e\u6e29\u5ea6\u503c\uff0c\u6bd4\u5982 \\(\\tau=0.5\\) \uff0c\u53ef\u4ee5\u770b\u5230\u7ecf\u8fc7 softmax \u4e4b\u540e\uff0c\u6982\u7387\u5dee\u522b\u88ab\u62c9\u5927</p> <p></p> <p>\u5982\u679c\u8c03\u9ad8\u6e29\u5ea6\u4e3a 2\uff0c\u5b83\u4eec\u4e4b\u95f4\u7684\u6982\u7387\u5dee\u522b\u5c31\u4f1a\u7f29\u5c0f\uff1a</p> <p></p>"},{"location":"learning/2_MOCO/#moco_3","title":"MOCO \u4f2a\u4ee3\u7801","text":"<ul> <li>\\(f_q\\) \u3001\\(f_k\\) \u5206\u522b\u4ee3\u8868 query \u548c k \u7f51\u7edc</li> </ul> <ul> <li>\u9996\u5148\u7528query \u7f51\u7edc\u7684\u53c2\u6570\uff0c\u521d\u59cb\u5316 k \u7f51\u7edc</li> </ul> <ul> <li>\u63a5\u7740\u52a0\u8f7d\u4e00\u4e2a\u6837\u672c x \uff0c\u5bf9 x \u5206\u522b\u8fdb\u884c\u4e24\u4e2a\u4e0d\u540c\u7684\u56fe\u50cf\u589e\u5f3a\u64cd\u4f5c\uff0c\u751f\u6210 \\(x_q\\) \u548c \\(x_k\\)</li> </ul> <p>\u8fd9\u662f\u6b63\u6837\u672c\u5bf9</p> <ul> <li>\u7136\u540e\uff0c\\(x_q\\)\u901a\u8fc7 query \u7f51\u7edc\uff0c\u751f\u6210 \\(q\\)</li> </ul> <p></p> <ul> <li>\\(x_k\\)\u901a\u8fc7 k \u7f51\u7edc\uff0c\u751f\u6210 key</li> </ul> <p></p> <ul> <li>k \u4ece\u8ba1\u7b97\u56fe\u65ad\u5f00\uff0c\u4e0d\u8ba1\u7b97\u68af\u5ea6</li> </ul> <p></p> <ul> <li>\u8ba1\u7b97 query \u5411\u91cf\u548c\u6b63\u6837\u672c\u7684 cosine \u76f8\u4f3c\u5ea6</li> </ul> <p></p> <ul> <li>\u63a5\u7740\u8ba1\u7b97 query \u5411\u91cf\u548c\u961f\u5217\u4e2d\uff0c\u6240\u6709\u8d1f\u6837\u672c\u7684 cosine \u76f8\u4f3c\u5ea6</li> </ul> <p></p> <ul> <li>\u628a\u6b63\u6837\u672c\u76f8\u4f3c\u5ea6\u653e\u5728\u7b2c 1 \u4e2a\u4f4d\u7f6e\uff0c\u548c\u5176\u4ed6\u6240\u6709\u7684\u8d1f\u6837\u672c\u76f8\u4f3c\u5ea6\u62fc\u63a5\u5728\u4e00\u8d77</li> </ul> <p></p> <ul> <li>\u56e0\u4e3a\u6b63\u6837\u672c\u76f8\u4f3c\u5ea6\u5728\u7b2c 0 \u4e2a\u4f4d\u7f6e\uff0c\u6240\u4ee5 label \u5c31\u4e3a 0</li> </ul> <p></p> <ul> <li>\u7136\u540e\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931</li> </ul> <p></p> <p>\u8fd9\u91cc\u9664\u4ee5\u6e29\u5ea6\u7cfb\u6570 \\(\\tau\\) (t)</p> <ul> <li>\u7136\u540e\u8fdb\u884c\u540e\u5411\u4f20\u64ad\uff0c\u66f4\u65b0 query \u7f51\u7edc\u7684\u53c2\u6570</li> </ul> <p></p> <ul> <li>\u63a5\u7740\u52a8\u91cf\u66f4\u65b0 k \u7f51\u7edc\u7684\u53c2\u6570</li> </ul> <p></p> <ul> <li>\u628a\u65b0\u751f\u6210\u7684\u8d1f\u6837\u672c\u7279\u5f81\u52a0\u5165\u5230\u961f\u5217\u4e2d\uff0c\u5c06\u6700\u65e9\u751f\u6210\u7684\u4e00\u4e2a\u8d1f\u6837\u672c\u4ece\u961f\u5217\u4e2d\u79fb\u51fa</li> </ul> <p></p>"},{"location":"learning/2_python/","title":"\u4e0b\u5212\u7ebf\u65b9\u6cd5 &amp; \u865a\u62df\u73af\u5883","text":""},{"location":"learning/2_python/#_1","title":"\u4e0b\u5212\u7ebf\u65b9\u6cd5 &amp; \u865a\u62df\u73af\u5883","text":"2025-04-18 15:33:402025-09-28 12:54:04 <p> \u7ea6 838 \u4e2a\u5b57  14 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p>"},{"location":"learning/2_python/#_2","title":"\u9b54\u6cd5\u65b9\u6cd5\u548c\u53d7\u4fdd\u62a4\u7684\u65b9\u6cd5","text":""},{"location":"learning/2_python/#_3","title":"\u9b54\u6cd5\u65b9\u6cd5","text":"<p>\u5728 Python \u4e2d\uff0c\u53cc\u4e0b\u5212\u7ebf\u65b9\u6cd5\uff08\u4e5f\u79f0\u4e3a\u9b54\u6cd5\u65b9\u6cd5\u6216\u7279\u6b8a\u65b9\u6cd5\uff09\u548c\u5355\u4e0b\u5212\u7ebf\u65b9\u6cd5\u6709\u4e0d\u540c\u7684\u7528\u9014\u548c\u542b\u4e49\u3002\u4ee5\u4e0b\u662f\u5bf9\u8fd9\u4e9b\u65b9\u6cd5\u7684\u8be6\u7ec6\u89e3\u91ca\uff1a</p> <p>\u53cc\u4e0b\u5212\u7ebf\u65b9\u6cd5\uff08\u9b54\u6cd5\u65b9\u6cd5\uff09 \u53cc\u4e0b\u5212\u7ebf\u65b9\u6cd5\uff08\u4ee5\u53cc\u4e0b\u5212\u7ebf\u5f00\u5934\u548c\u7ed3\u5c3e\uff09\u662f Python \u4e2d\u7684\u7279\u6b8a\u65b9\u6cd5\uff0c\u901a\u5e38\u7528\u4e8e\u5b9e\u73b0\u5bf9\u8c61\u7684\u7279\u6b8a\u884c\u4e3a\u3002\u8fd9\u4e9b\u65b9\u6cd5\u7531 Python \u89e3\u91ca\u5668\u81ea\u52a8\u8c03\u7528\uff0c\u901a\u5e38\u4e0d\u9700\u8981\u663e\u5f0f\u8c03\u7528\u3002\u5e38\u89c1\u7684\u9b54\u6cd5\u65b9\u6cd5\u5305\u62ec\uff1a</p> <p>\u5e38\u89c1\u7684\u9b54\u6cd5\u65b9\u6cd5</p> <ul> <li><code>__init__(self, ...)</code>\uff1a\u6784\u9020\u65b9\u6cd5\uff0c\u5728\u521b\u5efa\u5bf9\u8c61\u65f6\u8c03\u7528\uff0c\u7528\u4e8e\u521d\u59cb\u5316\u5bf9\u8c61\u7684\u5c5e\u6027\u3002</li> <li><code>__del__(self)</code>\uff1a\u6790\u6784\u65b9\u6cd5\uff0c\u5728\u5bf9\u8c61\u88ab\u5220\u9664\u65f6\u8c03\u7528\uff0c\u7528\u4e8e\u6e05\u7406\u8d44\u6e90\u3002</li> <li><code>__str__(self)</code>\uff1a\u5728\u4f7f\u7528 print() \u6216 str() \u51fd\u6570\u65f6\u8c03\u7528\uff0c\u8fd4\u56de\u5bf9\u8c61\u7684\u5b57\u7b26\u4e32\u8868\u793a\u3002</li> <li><code>__repr__(self)</code>\uff1a\u5728\u4f7f\u7528 repr() \u51fd\u6570\u6216\u5728\u4ea4\u4e92\u5f0f\u89e3\u91ca\u5668\u4e2d\u67e5\u770b\u5bf9\u8c61\u65f6\u8c03\u7528\uff0c\u8fd4\u56de\u5bf9\u8c61\u7684\u6b63\u5f0f\u5b57\u7b26\u4e32\u8868\u793a\u3002</li> <li><code>__len__(self)</code>\uff1a\u5728\u4f7f\u7528 len() \u51fd\u6570\u65f6\u8c03\u7528\uff0c\u8fd4\u56de\u5bf9\u8c61\u7684\u957f\u5ea6\u3002</li> <li><code>__getitem__(self, key)</code>\uff1a\u5728\u4f7f\u7528\u7d22\u5f15\u8bbf\u95ee\u5bf9\u8c61\u65f6\u8c03\u7528\uff0c\u4f8b\u5982 obj[key]\u3002</li> <li><code>__setitem__(self, key, value)</code>\uff1a\u5728\u4f7f\u7528\u7d22\u5f15\u8bbe\u7f6e\u5bf9\u8c61\u7684\u503c\u65f6\u8c03\u7528\uff0c\u4f8b\u5982 obj[key] = value\u3002</li> <li><code>__delitem__(self, key)</code>\uff1a\u5728\u4f7f\u7528\u7d22\u5f15\u5220\u9664\u5bf9\u8c61\u7684\u503c\u65f6\u8c03\u7528\uff0c\u4f8b\u5982 del obj[key]\u3002</li> <li><code>__iter__(self)</code>\uff1a\u5728\u4f7f\u7528 iter() \u51fd\u6570\u6216 for \u5faa\u73af\u904d\u5386\u5bf9\u8c61\u65f6\u8c03\u7528\uff0c\u8fd4\u56de\u4e00\u4e2a\u8fed\u4ee3\u5668\u3002</li> <li><code>__next__(self)</code>\uff1a\u5728\u4f7f\u7528 next() \u51fd\u6570\u83b7\u53d6\u8fed\u4ee3\u5668\u7684\u4e0b\u4e00\u4e2a\u503c\u65f6\u8c03\u7528\u3002</li> <li><code>__call__(self, ...)</code>\uff1a\u5728\u5c06\u5bf9\u8c61\u4f5c\u4e3a\u51fd\u6570\u8c03\u7528\u65f6\u8c03\u7528\uff0c\u4f8b\u5982 obj()\u3002</li> <li><code>__enter__(self)</code> \u548c <code>__exit__(self, exc_type, exc_value, traceback)</code>\uff1a\u5728\u4f7f\u7528 with \u8bed\u53e5\u65f6\u8c03\u7528\uff0c\u7528\u4e8e\u5b9e\u73b0\u4e0a\u4e0b\u6587\u7ba1\u7406\u3002</li> </ul> Text Only<pre><code>class MyClass:\n    def __init__(self, value):\n        self.value = value\n\n    def __str__(self):\n        return f\"MyClass with value: {self.value}\"\n\n    def __len__(self):\n        return len(self.value)\n\n    def __getitem__(self, index):\n        return self.value[index]\n\n    def __setitem__(self, index, value):\n        self.value[index] = value\n\n    def __delitem__(self, index):\n        del self.value[index]\n\n    def __call__(self, *args, **kwargs):\n        print(\"Called with arguments:\", args, kwargs)\n\n# \u4f7f\u7528\u793a\u4f8b\nobj = MyClass([1, 2, 3])\nprint(obj)  # \u8f93\u51fa: MyClass with value: [1, 2, 3]\nprint(len(obj))  # \u8f93\u51fa: 3\nprint(obj[1])  # \u8f93\u51fa: 2\nobj[1] = 42\nprint(obj[1])  # \u8f93\u51fa: 42\ndel obj[1]\nprint(obj.value)  # \u8f93\u51fa: [1, 3]\nobj(10, 20, key=\"value\")  # \u8f93\u51fa: Called with arguments: (10, 20) {'key': 'value'}\n</code></pre> <p>getitem \u4f7f\u7528\u7d22\u5f15\u8bbf\u95ee\uff1b</p> <p>call \u5f53\u6210\u51fd\u6570\u8bbf\u95ee\u3002</p>"},{"location":"learning/2_python/#_4","title":"\u53d7\u4fdd\u62a4\u7684\u65b9\u6cd5","text":"<p>\u5355\u4e0b\u5212\u7ebf\u65b9\u6cd5\u548c\u53d8\u91cf\uff08\u4ee5\u5355\u4e0b\u5212\u7ebf\u5f00\u5934\uff09\u901a\u5e38\u7528\u4e8e\u8868\u793a\u7c7b\u7684\u5185\u90e8\u5b9e\u73b0\u7ec6\u8282\u6216\u53d7\u4fdd\u62a4\u7684\u6210\u5458\u3002\u867d\u7136 Python \u6ca1\u6709\u771f\u6b63\u7684\u8bbf\u95ee\u63a7\u5236\u673a\u5236\uff08\u5982 private \u548c protected\uff09\uff0c\u4f46\u4f7f\u7528\u5355\u4e0b\u5212\u7ebf\u662f\u4e00\u79cd\u7ea6\u5b9a\uff0c\u8868\u793a\u8fd9\u4e9b\u6210\u5458\u4e0d\u5e94\u5728\u7c7b\u5916\u90e8\u76f4\u63a5\u8bbf\u95ee\u3002</p> <p>\u662f\u4e00\u79cd\u7ea6\u5b9a </p> Text Only<pre><code>class MyClass:\n    def __init__(self, value):\n        self._value = value  # \u53d7\u4fdd\u62a4\u7684\u6210\u5458\n\n    def _internal_method(self):\n        print(\"This is an internal method\")\n\n    def public_method(self):\n        self._internal_method()\n        print(\"This is a public method\")\n\n# \u4f7f\u7528\u793a\u4f8b\nobj = MyClass(42)\nobj.public_method()\n# \u8f93\u51fa:\n# This is an internal method\n# This is a public method\n\n# \u867d\u7136\u53ef\u4ee5\u8bbf\u95ee\uff0c\u4f46\u4e0d\u63a8\u8350\nprint(obj._value)  # \u8f93\u51fa: 42\nobj._internal_method()  # \u8f93\u51fa: This is an internal method\n</code></pre> <ul> <li>\u53cc\u4e0b\u5212\u7ebf\u65b9\u6cd5\uff08\u9b54\u6cd5\u65b9\u6cd5\uff09\uff1a\u7528\u4e8e\u5b9e\u73b0\u5bf9\u8c61\u7684\u7279\u6b8a\u884c\u4e3a\uff0c\u7531 Python \u89e3\u91ca\u5668\u81ea\u52a8\u8c03\u7528\u3002</li> <li>\u5355\u4e0b\u5212\u7ebf\u65b9\u6cd5\u548c\u53d8\u91cf\uff1a\u8868\u793a\u7c7b\u7684\u5185\u90e8\u5b9e\u73b0\u7ec6\u8282\u6216\u53d7\u4fdd\u62a4\u7684\u6210\u5458\uff0c\u7ea6\u5b9a\u4e0d\u5e94\u5728\u7c7b\u5916\u90e8\u76f4\u63a5\u8bbf\u95ee\u3002</li> </ul>"},{"location":"learning/2_python/#_5","title":"\u865a\u62df\u73af\u5883","text":"<p>\uff081\uff09\u65b0\u5efa</p> <p>m1 conda \u5b89\u88c5</p> Bash<pre><code>conda create -n dave python==3.8\nconda activate dave\nconda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=11.8 -c pytorch -c nvidia\nconda install numpy\nconda install scikit-image\nconda install scikit-learn\nconda install tqdm\nconda install pycocotools\n</code></pre> <p>m2 <code>requirements.txt</code> \u5b89\u88c5 </p> Bash<pre><code>conda create -n SegRNN python=3.8\nconda activate SegRNN\npip install -r requirements.txt\n</code></pre> <p>\uff082\uff09\u67e5\u770b</p> Bash<pre><code>conda env list\n</code></pre> <p>\uff083\uff09\u6fc0\u6d3b</p> Bash<pre><code>conda activate Autoformer\n</code></pre> <p>\uff084\uff09\u9000\u51fa</p> Bash<pre><code>conda deactivate\n</code></pre>"},{"location":"learning/3/","title":"\u674e\u6c90 \u76ee\u6807\u68c0\u6d4b\u90e8\u5206","text":""},{"location":"learning/3/#_1","title":"\u674e\u6c90 \u76ee\u6807\u68c0\u6d4b\u90e8\u5206","text":"2024-11-26 22:43:322025-09-28 12:54:04 <p> \u7ea6 1887 \u4e2a\u5b57  178 \u884c\u4ee3\u7801  15 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 12 \u5206\u949f</p>"},{"location":"learning/3/#k1","title":"k1 \u8fb9\u754c\u6846","text":""},{"location":"learning/3/#_2","title":"\u662f\u4ec0\u4e48\uff1f","text":"<p>\u6587\u5b57\uff1abounding box</p> <p>\u56fe\u793a\uff1a</p> <p></p>"},{"location":"learning/3/#_3","title":"\u600e\u4e48\u5b9e\u73b0\uff1f","text":"<ol> <li>\u4e24\u89d2\u8868\u793a\u6cd5\uff1a\u7531\u77e9\u5f62\u5de6\u4e0a\u89d2\u7684\u4ee5\u53ca\u53f3\u4e0b\u89d2\u7684x\u548cy\u5750\u6807\u51b3\u5b9a</li> <li>\u4e2d\u5fc3\u5bbd\u5ea6\u8868\u793a\u6cd5\uff1a\u8fb9\u754c\u6846\u4e2d\u5fc3\u7684(x,y)\u8f74\u5750\u6807\u4ee5\u53ca\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6</li> </ol> <p>pytorch\u4e2d\u5e38\u7528\u7684\u683c\u5f0f\uff1a</p> <p>boxes\uff1a</p> <ul> <li>x1, y1, x2, y2 \uff08shape=n\u00d74\uff09</li> <li>cx, cy, w, h\uff08shape=n\u00d74\uff09</li> </ul> <p>n\u8868\u793a\u6846\u7684\u6570\u91cf\uff0c\u4e0d\u6b62\u4e00\u4e2a\u6846</p>"},{"location":"learning/3/#_4","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u542b\u6d4b\u8bd5\u4ee3\u7801</p> Python<pre><code>import numpy as np\n\n#@save\ndef box_corner_to_center(boxes):\n    \"\"\"\u4ece\uff08\u5de6\u4e0a\uff0c\u53f3\u4e0b\uff09\u8f6c\u6362\u5230\uff08\u4e2d\u95f4\uff0c\u5bbd\u5ea6\uff0c\u9ad8\u5ea6\uff09\"\"\"\n    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n    cx = (x1 + x2) / 2\n    cy = (y1 + y2) / 2\n    w = x2 - x1\n    h = y2 - y1\n    boxes = np.stack((cx, cy, w, h), axis=-1)\n    return boxes\n\n#@save\ndef box_center_to_corner(boxes):\n    \"\"\"\u4ece\uff08\u4e2d\u95f4\uff0c\u5bbd\u5ea6\uff0c\u9ad8\u5ea6\uff09\u8f6c\u6362\u5230\uff08\u5de6\u4e0a\uff0c\u53f3\u4e0b\uff09\"\"\"\n    cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n    x1 = cx - 0.5 * w\n    y1 = cy - 0.5 * h\n    x2 = cx + 0.5 * w\n    y2 = cy + 0.5 * h\n    boxes = np.stack((x1, y1, x2, y2), axis=-1)\n    return boxes\n\n# bbox\u662f\u8fb9\u754c\u6846\u7684\u82f1\u6587\u7f29\u5199\ndog_bbox, cat_bbox = [60.0, 45.0, 378.0, 516.0], [400.0, 112.0, 655.0, 493.0]\n\nboxes = np.array((dog_bbox, cat_bbox))\nbox_center_to_corner(box_corner_to_center(boxes)) == boxes\n</code></pre> <p>OUT\uff1a</p> Python<pre><code>array([[ True,  True,  True,  True],      \n       [ True,  True,  True,  True]])\n</code></pre> <p>\u8fd9\u91cc\u60f3\u5f3a\u8c03\u7684\u4e00\u70b9\uff1a</p> <p>\u6211\u4eec\u7528\u7684\u7535\u8111\u5c4f\u5e55\u548cpytorch\u4e2d\uff0c\u9ed8\u8ba4\u7684\u539f\u70b9\u5728\u5de6\u4e0a\u89d2</p> <p>\u56fe\u50cf\u4e2d\u5750\u6807\u7684\u539f\u70b9\u662f\u56fe\u50cf\u7684\u5de6\u4e0a\u89d2\uff0c\u5411\u53f3\u7684\u65b9\u5411\u4e3ax\u8f74\u7684\u6b63\u65b9\u5411\uff0c\u5411\u4e0b\u7684\u65b9\u5411\u4e3ay\u8f74\u7684\u6b63\u65b9\u5411\u3002</p> <p></p>"},{"location":"learning/3/#k2","title":"K2 \u951a\u6846","text":""},{"location":"learning/3/#_5","title":"\u951a\u6846\u662f\u4ec0\u4e48\uff1f","text":"<ul> <li>anchor box</li> <li>\u4ee5\u6bcf\u4e2a\u50cf\u7d20\u4e3a\u4e2d\u5fc3\uff0c\u751f\u6210\u591a\u4e2a\u7f29\u653e\u6bd4\u548c\u5bbd\u9ad8\u6bd4\uff08aspect ratio\uff09\u4e0d\u540c\u7684\u8fb9\u754c\u6846</li> <li>\u5e94\u7528\uff1a\u57fa\u4e8e\u951a\u6846\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b</li> <li>\u662f\u4e00\u79cd \u533a\u57df\u91c7\u6837\u65b9\u6cd5</li> </ul> <p>\u56fe\u793a\uff1a</p> <p></p>"},{"location":"learning/3/#_6","title":"\u751f\u6210\u591a\u4e2a\u951a\u6846","text":"<p>\u8fd9\u91cc\u8981\u89e3\u51b3\u7684\u95ee\u9898\uff1a\u7ed9\u5b9a\u8f93\u5165\u56fe\u50cf\u9ad8\u5ea6h\u3001\u5bbd\u5ea6w\uff0c\u7f29\u653e\u6bd4s\uff0c\u5bbd\u9ad8\u6bd4r\uff0c\u95ee\u9898\u951a\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff1f</p> <p>\u7f29\u653e\u6bd4\\(s\\)\uff1a\u5bf9\u8f93\u5165\u56fe\u50cf\u8fdb\u884c\u7f29\u653e\uff0c\u8f93\u5165\u56fe\u50cf\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u5206\u522b\u7f29\u653es\u500d\uff0c\u5f97\u5230\u951a\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6</p> <p>\u5bbd\u9ad8\u6bd4\\(r\\)</p> <p>\u2460 \u6307\u7684\u662f\u951a\u6846\u7684\u5bbd\u548c\u9ad8\u4e4b\u6bd4</p> <p>\u2461 \\(r\\)\u662f\u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\u5bbd\u9ad8\u6bd4\u7684\u653e\u7f29\uff0c\u4f8b\u5982\u8f93\u5165\u56fe\u50cf\u7684\u5bbd\u9ad8\u6bd4\u662f\\(w/h\\)\uff0c\u6dfb\u52a0r\u540e\u53d8\u6210\u4e86\\((w/h)*r\\)\uff0c\u5f97\u5230\u951a\u6846\u7684\u5bbd\u9ad8\u6bd4\\((w/h)*r\\)</p> <p>\u5176\u5b9e\u6211\u89c9\u5f97\u8fd9\u4e2ar\u53ef\u4ee5\u7406\u89e3\u4e3a\u8f93\u5165\u56fe\u50cf\u5bbd\u9ad8\u6bd4\u7684\u7f29\u653e\u6bd4\u7387\uff0c\u53ea\u4e0d\u662f\u8fd9\u4e2a\u6bd4\u7387 \\(r&gt;0\\)\u5373\u53ef\uff0c\u56e0\u4e3a\u53ef\u4ee5\u5728\u539f\u59cb\u56fe\u50cf\u5bbd\u9ad8\u6bd4\u7684\u57fa\u7840\u4e0a\u653e\u5927\u5bbd\u9ad8\u6bd4 \u6216\u8005 \u51cf\u5c11\u5bbd\u9ad8\u6bd4</p> <p>\u603b\u7ed3\uff1a</p> <p>s\uff1ascale</p> <p>r\uff1aaspect ratio</p> <p>\u4ece\u539f\u59cb\u56fe\u50cf\u5230\u786e\u5b9a\u951a\u6846\uff0c\u9700\u8981\u77e5\u9053\u951a\u6846\u7684......</p> <p>\u4e66\u4e0a\uff1a </p> <p></p> <p>\u8981\u641e\u6e05\u695a\u7684\u70b9\uff1a</p> <ul> <li> \u7f29\u653e\u6bd4s\u7684\u610f\u4e49</li> <li> \u5bbd\u9ad8\u6bd4r\u7684\u610f\u4e49</li> <li> \u951a\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u600e\u4e48\u6765\uff1f</li> <li> \u4ec0\u4e48\u53eb\u505a\u539f\u59cb\u56fe\u50cf\u5f52\u4e00\u5316\u4e3a\u6b63\u65b9\u5f62\uff1f</li> </ul> <p>\u56e0\u4e3a\u951a\u6846\u7684\u751f\u6210\u662f\u5728\u5355\u4f4d\u50cf\u7d20\u5185\u8fdb\u884c\u7684\uff0c\u53c2\u7167\u7cfb\u53d8\u4e86 </p> <p>\u9996\u5148\u89e3\u91ca(from \u8ba8\u8bba\u533a)\u8fd9\u91cc\u951a\u6846\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff1a</p> <p></p> <p>\u4e66\u4e0a\uff1a </p> <p></p> <p>\u95ee\u9898\uff1a\u8981\u751f\u6210\u591a\u4e2a\u951a\u6846</p> <p>\u89e3\u51b3\uff1a\u8bbe\u7f6e\u591a\u4e2a\\(s\\)\u548c\\(r\\)\u5373\u53ef\uff0c\u7136\u540e\u8003\u8651\u6bcf\u4e2a\u53ef\u80fd\u7684s\u4e0er\u7684\u7ec4\u5408\uff0c\u4f46\u662f\u5b9e\u8df5\u4e2d\u5f80\u5f80\u53ea\u8003\u8651s1\u548cr1\u7684\u6240\u6709\u7ec4\u5408</p>"},{"location":"learning/3/#_7","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<ul> <li> todo\uff1a\u4e3a\u4ec0\u4e48\u9700\u8981\u534a\u5bbd\u3001\u534a\u9ad8\uff0c\u540e\u9762\u90fd\u662f\u4ec0\u4e48\u610f\u601d\uff1f\u951a\u6846\u751f\u6210\u7684\u6b65\u9aa4\u662f\u600e\u4e48\u6837\u7684\uff1f</li> </ul> Python<pre><code># \u9664\u4ee52\u6765\u83b7\u5f97\u534a\u9ad8\u548c\u534a\u5bbd\nanchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(\n                                    in_height * in_width, 1) / 2\n\n# \u6bcf\u4e2a\u4e2d\u5fc3\u70b9\u90fd\u5c06\u6709\u201cboxes_per_pixel\u201d\u4e2a\u951a\u6846\uff0c\n# \u6240\u4ee5\u751f\u6210\u542b\u6240\u6709\u951a\u6846\u4e2d\u5fc3\u7684\u7f51\u683c\uff0c\u91cd\u590d\u4e86\u201cboxes_per_pixel\u201d\u6b21\nout_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],\n            dim=1).repeat_interleave(boxes_per_pixel, dim=0)\noutput = out_grid + anchor_manipulations\n</code></pre> <ul> <li> in_height, in_width = data.shape[-2:]</li> </ul> <p>data format\uff1ab c h w</p> <ul> <li> device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)</li> </ul> <p>num_sizes\u8868\u793ascale\u3001num_ratios\u8868\u793aaspect ratio</p> <ul> <li> <p> boxes_per_pixel = (num_sizes + num_ratios - 1)</p> </li> <li> <p> center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h \u4e58 steps_h\uff1f</p> </li> <li> <p>\u56e0\u4e3a\u539f\u70b9\u5728\u5de6\u4e0a\u89d2\uff0c\u6240\u4ee5\u662f\u951a\u6846\u4e2d\u5fc3\u70b9\u5206\u522b\u52a0offset_h\u3001offset_w</p> </li> <li>\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u70b9\u751f\u6210\u951a\u6846\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u90fd\u6709\u751f\u6210 num_sizes+num_ratios-1\u7684\u951a\u6846</li> <li>\u6240\u4ee5\u5bf9\u4e8e\u5355\u4e2a\u50cf\u7d20\u70b9\u6765\u8bf4\uff0c\u53c2\u8003\u70b9\u53d8\u4e86\uff0c\u5168\u90e8\u53d8\u6210\u4e86\u5355\u4f4d\u5750\u6807\u4e0b\u7684\u5ea6\u91cf\uff0c\u6240\u4ee5\u4e58\u4ee5 steps_h \u548c steps_w</li> <li> <p>steps_h = 1/\u539f\u59cb\u9ad8\u5ea6 &amp;  steps_w = 1/\u539f\u59cb\u5bbd\u5ea6</p> </li> <li> <p> torch.meshgrid\uff1f</p> </li> </ul> <p>shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')</p> <p>shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)</p>"},{"location":"learning/3/#torchmeshgrid","title":"torch.meshgrid()","text":"<ul> <li>\u8f93\u5165\uff1a\u4e00\u7ec4\u4e00\u7ef4\u5f20\u91cf</li> <li>\u8f93\u51fa\uff1a\u4e00\u4e2a\u591a\u7ef4\u7f51\u683c\u5750\u6807</li> <li>deal\uff1a\u6bcf\u4e2a\u8f93\u51fa\u5f20\u91cf\u7684\u5f62\u72b6\u4e0e\u8f93\u5165\u5f20\u91cf\u7684\u5f62\u72b6\u76f8\u540c\uff0c\u4f46\u6bcf\u4e2a\u8f93\u51fa\u5f20\u91cf\u7684\u503c\u662f\u6cbf\u7740\u76f8\u5e94\u7ef4\u5ea6\u7684\u7f51\u683c\u5750\u6807\u3002</li> </ul> <p>\u4e3e\u4f8b\uff1a</p> Python<pre><code>import torch\n\n# \u5b9a\u4e49\u4e00\u7ef4\u5f20\u91cf\nx = torch.tensor([1, 9])\ny = torch.tensor([4, 5,7,10])\n\n# \u751f\u6210\u7f51\u683c\u5750\u6807\ngrid_x, grid_y = torch.meshgrid(x, y, indexing='ij')\n\nprint(\"grid_x:\")\nprint(grid_x)\nprint(\"grid_y:\")\nprint(grid_y)\n</code></pre> <p>Out:</p> Text Only<pre><code>grid_x:\ntensor([[1, 1, 1, 1],\n        [9, 9, 9, 9]])\ngrid_y:\ntensor([[ 4,  5,  7, 10],\n        [ 4,  5,  7, 10]])\n</code></pre> <p>\u89e3\u91ca\u4e3a\u4ec0\u4e48\u7684\u8fd9\u6837\u7684\u8f93\u51fa\uff1a</p> <ul> <li>\u7ed3\u679c\u89e3\u8bfb\uff1a</li> </ul> <p>grid_x \u548c grid_y \u5bf9\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20\u6784\u6210\u4e00\u5bf9\u5750\u6807\uff0c\u6240\u4ee5\u53ef\u4ee5\u770b\u5230 grid_x \u548c grid_y \u5f62\u72b6\u662f\u76f8\u540c\u7684</p> <p>\u5177\u4f53\u6765\u8bf4\u5c31\u662f\uff0cx\u7684\u6240\u6709\u53d6\u503c\u548cy\u7684\u6240\u6709\u53d6\u503c\uff0c\u80fd\u6784\u6210\u591a\u5c11\u5bf9\u5750\u6807</p> <p>x={1,9}\uff0cy={4, 5,7,10}</p> <p>\u6240\u4ee5 x \u548c y \u7684\u6240\u6709\u5750\u6807\u7684\u96c6\u5408\uff1a</p> <p>(1,4)(1,5)(1,7)(1,10)</p> <p>(9,4)(9,5)(9,7)(9,10)</p> <p>\u7136\u540e\u628a\u6240\u6709\u7684x\u53d6\u51fa\u6765\uff0c\u5f97\u5230grid_x\uff1a</p> <p>[1,1,1,1]</p> <p>[9,9,9,9]</p> <p>\u540c\u7406\uff0c\u7531y\u5f97\u5230grid_y\uff1a</p> <p>[4,5,7,10]</p> <p>[4,5,7,10]</p>"},{"location":"learning/3/#_8","title":"\u5168\u90e8\u4ee3\u7801","text":"Python<pre><code>import torch\n\ndef multibox_prior(data, sizes, ratios):\n    \"\"\"\u751f\u6210\u4ee5\u6bcf\u4e2a\u50cf\u7d20\u4e3a\u4e2d\u5fc3\u5177\u6709\u4e0d\u540c\u5f62\u72b6\u7684\u951a\u6846\"\"\"\n    in_height, in_width = data.shape[-2:] # b c h w\n    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)\n    boxes_per_pixel = (num_sizes + num_ratios - 1)\n    # boxes_per_pixel = num_sizes * num_ratios\n    size_tensor = torch.tensor(sizes, device=device) # sizes\uff1ascale input h &amp; w \u5206\u522b\u7f29\u653e size\n    ratio_tensor = torch.tensor(ratios, device=device) # ratio\uff1aaspect ratio\n\n    # \u4e3a\u4e86\u5c06\u951a\u70b9\u79fb\u52a8\u5230\u50cf\u7d20\u7684\u4e2d\u5fc3\uff0c\u9700\u8981\u8bbe\u7f6e\u504f\u79fb\u91cf\u3002\n    # \u56e0\u4e3a\u4e00\u4e2a\u50cf\u7d20\u7684\u9ad8\u4e3a1\u4e14\u5bbd\u4e3a1\uff0c\u6211\u4eec\u9009\u62e9\u504f\u79fb\u6211\u4eec\u7684\u4e2d\u5fc30.5\n    offset_h, offset_w = 0.5, 0.5\n    steps_h = 1.0 / in_height  # \u5728y\u8f74\u4e0a\u7f29\u653e\u6b65\u957f\n    steps_w = 1.0 / in_width  # \u5728x\u8f74\u4e0a\u7f29\u653e\u6b65\u957f\n\n    # \u751f\u6210\u951a\u6846\u7684\u6240\u6709\u4e2d\u5fc3\u70b9\n    # \u56e0\u4e3a\u539f\u70b9\u5728\u5de6\u4e0a\u89d2\uff0c\u6240\u4ee5\u662f\u951a\u6846\u4e2d\u5fc3\u70b9\u5206\u522b\u52a0offset_h\u3001offset_w\n    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\n    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\n    # \u5bf9\u6bcf\u4e2a\u50cf\u7d20\u70b9\u751f\u6210\u951a\u6846\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u90fd\u6709\u751f\u6210 num_sizes+num_ratios-1\u7684\u951a\u6846\uff0c\u6240\u4ee5\u5bf9\u4e8e\u5355\u4e2a\u50cf\u7d20\u70b9\u6765\u8bf4\n    # \u53c2\u8003\u70b9\u53d8\u4e86\uff0c\u5168\u90e8\u53d8\u6210\u4e86\u5355\u4f4d\u5750\u6807\u4e0b\u7684\u5ea6\u91cf\uff0c\u6240\u4ee5\u9664\u4ee5 steps_h \u548c steps_w\n    shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')\n    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\n\n    # \u751f\u6210\u201cboxes_per_pixel\u201d\u4e2a\u9ad8\u548c\u5bbd\uff0c\n    # \u4e4b\u540e\u7528\u4e8e\u521b\u5efa\u951a\u6846\u7684\u56db\u89d2\u5750\u6807(xmin,xmax,ymin,ymax)\n    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\n                   sizes[0] * torch.sqrt(ratio_tensor[1:])))\\\n                   * in_height / in_width  # \u5904\u7406\u77e9\u5f62\u8f93\u5165\n    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),\n                   sizes[0] / torch.sqrt(ratio_tensor[1:])))\n    # \u9664\u4ee52\u6765\u83b7\u5f97\u534a\u9ad8\u548c\u534a\u5bbd\n    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(\n                                        in_height * in_width, 1) / 2\n\n    # \u6bcf\u4e2a\u4e2d\u5fc3\u70b9\u90fd\u5c06\u6709\u201cboxes_per_pixel\u201d\u4e2a\u951a\u6846\uff0c\n    # \u6240\u4ee5\u751f\u6210\u542b\u6240\u6709\u951a\u6846\u4e2d\u5fc3\u7684\u7f51\u683c\uff0c\u91cd\u590d\u4e86\u201cboxes_per_pixel\u201d\u6b21\n    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],\n                dim=1).repeat_interleave(boxes_per_pixel, dim=0)\n    output = out_grid + anchor_manipulations\n    return output.unsqueeze(0)\n\nh = 561\nw = 728\nX = torch.rand(size=(1, 3, h, w)) # \u968f\u673a\u751f\u6210\u8f93\u5165\u56fe\u50cf b c h w\nY = multibox_prior(X, sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5])\nY.shape\n</code></pre>"},{"location":"learning/3/#torchmeshgrid-reshape","title":"torch.meshgrid &amp; reshape","text":"Python<pre><code>import torch\n\nin_height, in_width = 3, 3\ndevice = torch.device('cpu')\noffset_h, offset_w = 0.5, 0.5\nsteps_h = 1.0 / in_height\nsteps_w = 1.0 / in_width\n\ncenter_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\ncenter_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\nshift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')\n\nprint(\"shift_y (before reshape):\")\nprint(shift_y)\nprint(\"shift_x (before reshape):\")\nprint(shift_x)\n\nshift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\n\nprint(\"shift_y (after reshape):\")\nprint(shift_y)\nprint(\"shift_x (after reshape):\")\nprint(shift_x)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>shift_y (before reshape):\ntensor([[0.1667, 0.1667, 0.1667],\n        [0.5000, 0.5000, 0.5000],\n        [0.8333, 0.8333, 0.8333]])\nshift_x (before reshape):\ntensor([[0.1667, 0.5000, 0.8333],\n        [0.1667, 0.5000, 0.8333],\n        [0.1667, 0.5000, 0.8333]])\nshift_y (after reshape):\ntensor([0.1667, 0.1667, 0.1667, 0.5000, 0.5000, 0.5000, 0.8333, 0.8333, 0.8333])\nshift_x (after reshape):\ntensor([0.1667, 0.5000, 0.8333, 0.1667, 0.5000, 0.8333, 0.1667, 0.5000, 0.8333])\n</code></pre> <p>Test </p> Python<pre><code>torch.arange(in_height, device=device) + offset_h\n</code></pre> <p>\u8f93\u51fa\uff1atensor([0.5000, 1.5000, 2.5000])</p> Python<pre><code>center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\ncenter_h    \n</code></pre> <p>\u8f93\u51fa\uff1atensor([0.1667, 0.5000, 0.8333])</p> <ul> <li> \u521b\u5efa\u951a\u6846\u7684\u56db\u89d2\u5750\u6807(xmin,xmax,ymin,ymax)</li> </ul> Python<pre><code>'''\n    h = 561\n\n    w = 728\n\n    X = torch.rand(size=(1, 3, h, w)) # \u968f\u673a\u751f\u6210\u8f93\u5165\u56fe\u50cf b c h w\n\n    Y = multibox_prior(X, sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5])\n'''\n\nw = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\n                sizes[0] * torch.sqrt(ratio_tensor[1:])))\\\n                * in_height / in_width  # \u5904\u7406\u77e9\u5f62\u8f93\u5165\nh = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),\n                sizes[0] / torch.sqrt(ratio_tensor[1:])))\n\n# print(size_tensor)  tensor([0.7500, 0.5000, 0.2500])\n# print(ratio_tensor[0])  tensor(1.)\n# print(size_tensor * torch.sqrt(ratio_tensor[0])) tensor([0.7500, 0.5000, 0.2500])\n\n# print(sizes[0]) 0.75\n# print(ratio_tensor[1:]) tensor([2.0000, 0.5000])\n# print(sizes[0] * torch.sqrt(ratio_tensor[1:]))  tensor([1.0607, 0.5303])\n\n# print(torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\n#                sizes[0] * torch.sqrt(ratio_tensor[1:]))))\n# tensor([0.7500, 0.5000, 0.2500, 1.0607, 0.5303])\n</code></pre>"},{"location":"learning/3/#_9","title":"\u516c\u5f0f\u7684\u6574\u4f53\u903b\u8f91\u662f\u4ec0\u4e48\uff1f","text":"<p>\u4e0b\u6b21\u518d\u770b\uff1a\u8f93\u5165\u4ec0\u4e48\u4e1c\u897f\uff1f\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898\uff1f</p> <ul> <li> <p> todo</p> </li> <li> <p>\u89e3\u91ca1</p> </li> <li> <p>\u89e3\u91ca2</p> </li> </ul> <p>\u5168\u90e8\u6765\u81ea\u8bc4\u8bba\u533a</p> <p>\u7b97\u4e86\uff0c\u641e\u4e0d\u61c2 <code>* in_height / in_width</code>\uff0c\u8fd9\u6b65\u5f88\u8ff7\u60d1\uff0c\u5927\u6982\u7684\u610f\u601d\u5c31\u662f\u5904\u7406\u8f93\u5165\u56fe\u50cf\u662f\u77e9\u5f62\u7684\u60c5\u51b5\uff0c\u4f46\u7b97\u4e86\uff0c\u5b9e\u9645\u5904\u7406\u65f6\uff0c\u5927\u90e8\u5206\u8f93\u5165\u56fe\u50cf\u90fd\u662f \u65b9\u5f62\u7684\uff0c\u6bd4\u503c=1\uff0c\u5176\u4f59\u7684\uff0c\u9047\u5230\u4e86\u518d\u770b\u5427\u3002</p> <p>me\uff1a\u4e5f\u8bb8\u5e38\u8bc6\u662f\uff1a\u8f93\u5165\u56fe\u50cf\u5bbd\u9ad8\u6bd4=1\uff0c\u951a\u6846\u8981\u751f\u6210\u5404\u79cd\u5f62\u72b6\u7684\uff0c\u800c\u4e0d\u80fd\u4ec5\u4ec5\u5c40\u9650\u4e8e\u65b9\u5f62\uff1b</p> <p>\u6211\u7684\u7406\u89e3\uff1a\u5982\u679c\u8f93\u5165\u56fe\u50cf\u662f\u77e9\u9635\uff08\u975e\u65b9\u5f62\uff09\u7684\u8bdd\uff0c\u4f46\u662f\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u53c2\u7167\u7cfb\u8fd8\u662f\u65b9\u5f62\u7684\uff0c\u4e14\u662f\u5355\u4f4d\u65b9\u5f62\uff0c\u5de6\u4e0a\u89d2\u4e3a\u539f\u70b9\uff0c\u90a3\u4e48 \u4ece\u539f\u6765\u7684\u5bbd\u548c\u9ad8 \u53bb\u7f29\u653e \u5230\u5355\u4f4d\u50cf\u7d20\u70b9\uff0c\u5c31\u9700\u8981\u8fd9\u4e2a\u4e1c\u897f\u3002\u8fd8\u662f\u4ece\u4f8b\u5b50\u51fa\u53d1\uff1a</p> <p></p> <p>\u8fd8\u662f\u4e0d\u660e\u767d\uff0c\u7b97\u4e86\u3002</p> <p>\u89e3\u91ca1</p> <p>\\(w = s\\times \\sqrt{r}\\)</p> <p>\\(h = \\frac{s}{ \\sqrt{r}}\\)</p> <p></p> <p></p> <p></p> <p>\u60f3\u5f3a\u8c03\u4e00\u70b9\uff1a\u5b9e\u9645\u5728\u6211\u4eec\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u65f6\uff0c\u7279\u5f81\u56fe\u957f\u548c\u5bbd\u90fd\u662f\u76f8\u540c\u7684\uff0c\u6bd4\u5982 (19, 19)\u3001(7, 7)\uff0c\u6240\u4ee5 <code>in_height / in_width</code> \u6052\u7b49\u4e8e 1\uff0c\u56e0\u6b64\u5bf9\u4e8e\u5b9e\u9645\u7684\u4f7f\u7528\u5e76\u4e0d\u4f1a\u5e26\u6765\u526f\u4f5c\u7528\u3002</p> <p>\u89e3\u91ca2\uff1a</p> <p></p> <p>\u4e3b\u8981\u770b <code>\u4e09\u3001d2l\u4ee3\u7801\u89e3\u6790</code></p> <ul> <li> \u89e3\u91ca\u6700\u540e\u4e00\u53e5\uff0c<code>\u5206\u522b\u5f52\u4e00\u5316</code> \u662f\u4ec0\u4e48\u610f\u601d \uff1f <code>\u79fb\u9879</code></li> </ul> <p></p>"},{"location":"learning/3/#_10","title":"\u7ec6\u8282\uff1a\u4e3a\u4ec0\u4e48\u7d22\u5f15\u662f\u8fd9\u6837\uff1f\uff1f","text":"<ul> <li> solved</li> </ul> <p>w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),                 sizes[0] * torch.sqrt(ratio_tensor[1:]))) *in_height / in_width  # \u5904\u7406\u77e9\u5f62\u8f93\u5165</p> <p>sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5]</p> <p>\u89e3\u91ca\u8fd9\u91cc\u7684\u7d22\u5f15\uff0c\u4e4b\u524d\u5df2\u7ecf\u8bf4\u8fc7\u4e86 \u53ea\u8003\u8651 sizes\u548cratios \u7684\u7b2c\u4e00\u5143\u7d20 \u7684\u7ec4\u5408\uff1a</p> <p>(0.75,1)(0.75,2)(0.75,0.5)</p> <p>(0.75,1)   (0.5,1)(0.25,1)  \u53bb\u91cd\u3001\u5220\u6389\u4e00\u4e2a</p> <p>\u951a\u6846\u8981\u751f\u6210\u4e0d\u540c\u5bbd\u9ad8\u6bd4\u7684\uff0cratio\u8868\u793a\u65b9\u5f62\uff0c\u4e00\u822c\u5728\u8bbe\u7f6e\u5bbd\u9ad8\u6bd4\u7684\u65f6\u5019\uff0cratio\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u4e00\u822c\u90fd\u662f1\uff0c\u4f46\u662f\u951a\u6846\u7684\u8986\u76d6\u8303\u56f4\u4e0d\u80fd\u4ec5\u4ec5\u662f\u65b9\u5f62\uff0c\u8fd9\u4e00\u70b9\u7684\u5b9e\u73b0\u662f\u901a\u8fc7scale\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u4e0eratio\u7684\u5404\u4e2a\u5143\u7d20\u7ec4\u5408\u5b9e\u73b0\u7684</p> <p>\u2234 \u4ee3\u7801\u7684\u5b9e\u73b0\u903b\u8f91\u5982\u4e0b\uff08\u89e3\u91ca\u7d22\u5f15\u4e3a\u4ec0\u4e48\u662f\u90a3\u6837\u7684\uff09</p> <p><code>size_tensor * torch.sqrt(ratio_tensor[0])</code> \uff1a (0.75,1) (0.5,1)(0.25,1)</p> <p><code>sizes[0] * torch.sqrt(ratio_tensor[1:])</code> \uff1a(0.75,2)(0.75,0.5)</p> <ul> <li> ......</li> </ul>"},{"location":"learning/3/#k3","title":"K3 \u4ea4\u5e76\u6bd4","text":"<ul> <li>\u4ec0\u4e48\u662f\u4ea4\u5e76\u6bd4</li> <li>\u4e3a\u4ec0\u4e48\u9700\u8981\u4ea4\u5e76\u6bd4</li> <li>\u600e\u4e48\u5b9e\u73b0\u4ea4\u5e76\u6bd4</li> </ul>"},{"location":"learning/3/#_11","title":"\u4ec0\u4e48\u662f\u4ea4\u5e76\u6bd4","text":"<p>\u50cf\u7d20\u96c6\u7684\u6770\u5361\u5fb7\u7cfb\u6570=\u4ea4\u5e76\u6bd4</p> <p></p> <ul> <li> \u56fe\u89e3\uff1a</li> </ul> <p></p>"},{"location":"learning/3/#_12","title":"\u4e3a\u4ec0\u4e48\u9700\u8981\u4ea4\u5e76\u6bd4\uff1f","text":"<p>\u2460 \u4f7f\u7528\u4ea4\u5e76\u6bd4\u6765\u8861\u91cf\u951a\u6846\u548c\u771f\u5b9e\u8fb9\u754c\u6846\u4e4b\u95f4\u3001\u4ee5\u53ca\u4e0d\u540c\u951a\u6846\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6</p> <p>\u2461 \u67d0\u4e2a\u951a\u6846\u201c\u8f83\u597d\u5730\u201d\u8986\u76d6\u4e86\u56fe\u50cf\u4e2d\u7684\u72d7\u3002 \u5982\u679c\u5df2\u77e5\u76ee\u6807\u7684\u771f\u5b9e\u8fb9\u754c\u6846\uff0c\u90a3\u4e48\u8fd9\u91cc\u7684\u201c\u597d\u201d\u8be5\u5982\u4f55\u5982\u4f55\u91cf\u5316\u5462\uff1f\u5c31\u662f\u4ea4\u5e76\u6bd4</p>"},{"location":"learning/3/#_13","title":"\u600e\u4e48\u5b9e\u73b0\u4ea4\u5e76\u6bd4\uff1f","text":"<p>Tip</p> <p>\u4e00\u5b9a\u8981\u6ce8\u610f\u539f\u70b9\u5728\u5de6\u4e0a\u89d2\uff0c\u6240\u4ee5\uff1a</p> Python<pre><code>inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2])\ninter_lowerrights = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])\n</code></pre> <p>\u5de6\u4e0a\u53d6\u6700\u5927\u3001\u53f3\u4e0b\u89d2\u53d6\u6700\u5c0f\u503c</p> <ul> <li> <code>.clamp</code> \u4ec0\u4e48\u610f\u601d\uff1f</li> </ul> <p><code>inters = (inter_lowerrights - inter_upperlefts).clamp(min=0)</code></p> Python<pre><code>#@save\ndef box_iou(boxes1, boxes2):\n    \"\"\"\u8ba1\u7b97\u4e24\u4e2a\u951a\u6846\u6216\u8fb9\u754c\u6846\u5217\u8868\u4e2d\u6210\u5bf9\u7684\u4ea4\u5e76\u6bd4\"\"\"\n    box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *\n                              (boxes[:, 3] - boxes[:, 1]))\n    # boxes1,boxes2,areas1,areas2\u7684\u5f62\u72b6:\n    # boxes1\uff1a(boxes1\u7684\u6570\u91cf,4),\n    # boxes2\uff1a(boxes2\u7684\u6570\u91cf,4),\n    # areas1\uff1a(boxes1\u7684\u6570\u91cf,),\n    # areas2\uff1a(boxes2\u7684\u6570\u91cf,)\n    areas1 = box_area(boxes1)\n    areas2 = box_area(boxes2)\n    # inter_upperlefts,inter_lowerrights,inters\u7684\u5f62\u72b6:\n    # (boxes1\u7684\u6570\u91cf,boxes2\u7684\u6570\u91cf,2)\n    inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2])\n    inter_lowerrights = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])\n    inters = (inter_lowerrights - inter_upperlefts).clamp(min=0)\n    # inter_areasandunion_areas\u7684\u5f62\u72b6:(boxes1\u7684\u6570\u91cf,boxes2\u7684\u6570\u91cf)\n    inter_areas = inters[:, :, 0] * inters[:, :, 1]\n    union_areas = areas1[:, None] + areas2 - inter_areas\n    return inter_areas / union_areas\n</code></pre> <ul> <li> ...</li> </ul>"},{"location":"learning/3/#_14","title":"\u76ee\u6807\u68c0\u6d4b\u7684\u6b65\u9aa4","text":""},{"location":"learning/3_ViT/","title":"ViT","text":""},{"location":"learning/3_ViT/#vit","title":"ViT","text":"2025-02-22 22:04:482025-09-28 12:54:04 <p> \u7ea6 2800 \u4e2a\u5b57  18 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 14 \u5206\u949f</p> <p></p> <p>\u4e00\u53e5\u8bdd\uff1a\u7eaf Transformer \u89e3\u51b3\u8ba1\u7b97\u673a\u89c6\u89c9\u95ee\u9898</p> <p>\u5e76\u4e14\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u6570\u636e\u96c6\u4e0b\u4e0e CNN \u8fdb\u884c\u5bf9\u6bd4\uff0c\u63a2\u8ba8 Transformer \u7684\u4f18\u52bf</p>"},{"location":"learning/3_ViT/#vit_1","title":"ViT \u7684\u7ed3\u8bba","text":"<ul> <li>ViT \u8bc1\u660e\u4e86 Transformer \u6a21\u578b\u7684\u901a\u7528\u6027</li> </ul>"},{"location":"learning/3_ViT/#transformer","title":"Transformer \u67b6\u6784\u7684\u8bc4\u4ef7\uff1a","text":"<p>\u8bad\u7ec3\u6548\u7387\u9ad8\uff0c\u53ef\u4ee5\u901a\u8fc7\u6ce8\u610f\u529b\u63d0\u53d6\u590d\u6742\u8bed\u4e49\uff0c\u53ef\u4ee5\u652f\u6301\u591a\u79cd\u6a21\u6001\uff0c\u5e76\u4e14\u7ed3\u6784\u7b80\u5355\uff0c\u53ef\u4ee5\u81ea\u7531\u6269\u5c55\u6a21\u578b\u5927\u5c0f\uff0c\u5373\u4f7f\u4f7f\u7528\u5343\u4ebf\u7ea7\u522b\u7684\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u4f9d\u7136\u6ca1\u6709\u51fa\u73b0\u6027\u80fd\u9971\u548c\uff0cViT \u4e3a\u591a\u6a21\u6001\u5927\u6a21\u578b\u94fa\u5e73\u4e86\u9053\u8def\uff0cTransformer \u67b6\u6784\u7684\u7edf\u4e00\uff0c\u4e5f\u8ba9\u57fa\u4e8e Transformer \u67b6\u6784\u7684\u5de5\u7a0b\u4f18\u5316\uff0c\u53ef\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u591a\u6a21\u6001\u9886\u57df</p> <p>\u60f3\u6cd5\u662f\uff1a</p> <p>\u5bf9 Transformer \u6a21\u578b\u4e0d\u505a\u4efb\u4f55\u7684\u4fee\u6539 \u6765\u5b8c\u6210\u5bf9\u56fe\u50cf\u7684\u5206\u7c7b\u4efb\u52a1\uff0c\u5982\u679c\u6a21\u578b\u4e0d\u80fd\u6539\u53d8\uff0c\u90a3\u5c31\u6539\u53d8\u56fe\u7247\u6570\u636e\uff0c\u8ba9\u56fe\u7247\u6570\u636e\u53d8\u5f97\u50cf\u6587\u672c\uff0c\u6240\u4ee5 ViT \u8bba\u6587\u7684\u9898\u76ee\uff1a\u4e00\u5f20\u56fe\u50cf=16\u00d716 \u7684\u8bcd</p>"},{"location":"learning/3_ViT/#vit_2","title":"ViT \u662f\u5982\u4f55\u5c06\u56fe\u7247\u8f6c\u6362\u6210\u6587\u672c\u7684\u5462\uff1f","text":"<p>\u5c06\u56fe\u7247\u5212\u5206\u6210\u56fa\u5b9a\u5927\u5c0f\u7684 patch\uff0c\u8bba\u6587\u4e2d\u8f93\u5165\u56fe\u7247 224\u00d7224\uff0c\u5982\u679c patch \u5927\u5c0f\u4e3a 14\u00d714\uff0c\u5219\u53ef\u4ee5\u5206\u4e3a 16\u00d716 \u7684\u5e8f\u5217\uff0c\u4e0d\u6309\u7167\u5355\u4e2a\u50cf\u7d20\u5212\u5206\u7684\u539f\u56e0\u662f\u4f1a\u5bfc\u81f4\u5e8f\u5217\u957f\u5ea6\u8fc7\u957f\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u592a\u9ad8</p> <p>\uff081\uff09\u4e00\u4e2a\u50cf\u7d20\u53ea\u6709 RGB 3\u4e2a\u503c\uff0c\u8bed\u4e49\u4fe1\u606f\u592a\u5c11\uff0c\u7528\u4e00\u4e2a\u957f\u5ea6\u51e0\u767e\u4e0a\u5343\u7684\u5411\u91cf\u53ea\u505a\u4e00\u4e2a\u50cf\u7d20\u7684 embedding\uff0c\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\uff0c\u6240\u4ee5\u9009\u62e9\u4e00\u4e2a patch \u4f5c\u4e3a\u4e00\u4e2a\u8bed\u4e49\u5355\u5143\uff0c\u5bf9\u5e94\u6587\u672c\u4e2d\u7684\u4e00\u4e2a token</p> <p>\uff082\uff09\u76f8\u90bb\u50cf\u7d20\u8bed\u4e49\u76f8\u4f3c</p>"},{"location":"learning/3_ViT/#patch-embedding","title":"\u56fe\u50cf patch \u5982\u4f55\u6587\u672c\u4e2d\u5bf9\u5e94\u7684 embedding \u5411\u91cf\u5462\uff1f","text":"<p>\u5c06<code>patch</code>\u7684<code>\u957f\u00d7\u5bbd\u00d7\u901a\u9053\u6570</code>\u7684\u591a\u7ef4\u77e9\u9635\u8868\u793a\u5c55\u5e73\uff0c\u7136\u540e\u901a\u8fc7\u4e00\u4e2a\u5171\u4eab\u7684\u7ebf\u6027\u5c42\u6295\u5c04\u5230 Transformer \u6a21\u578b\u91cc\u7684\u7279\u5f81\u7ef4\u5ea6\uff0c\u6bd4\u5982 1024\uff0c\u8fd9\u6837\u5c31\u5b8c\u6210\u4e86\u628a\u4e00\u4e2a\u56fe\u7247\u8f6c\u6362\u6210\u4e00\u4e2a\u5411\u91cf\u5e8f\u5217\u7684\u8f6c\u6362\uff0c\u56fe\u50cf\u5207\u7247\u76f8\u5f53\u4e8e\u6587\u672c\u91cc\u9762\u7684\u5206\u8bcd\uff0c\u7ebf\u6027\u6295\u5c04\u5c42\u76f8\u5f53\u4e8e embedding \u5c42\uff0c\u63a5\u4e0b\u6765\u9700\u8981\u8003\u8651\u4f4d\u7f6e\u7f16\u7801\u3002</p>"},{"location":"learning/3_ViT/#vit_3","title":"ViT \u4e2d\u7684\u4f4d\u7f6e\u7f16\u7801","text":"<p>ViT \u4e2d\u4e3a\u6bcf\u4e2a\u4f4d\u7f6e\u52a0\u4e0a 1 \u4e2a\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c\u6bd4\u5982\u56fe\u4e2d\u6709 9 \u4e2a\u4e0d\u540c\u7684\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c\u56e0\u4e3a ViT \u505a\u7684\u4efb\u52a1\u662f\u8981\u5bf9\u56fe\u7247\u8fdb\u884c\u5206\u7c7b\uff0c\u53c2\u8003\u81ea\u7136\u8bed\u8a00\u5904\u7406\u91cc\u7684 Bert \u6a21\u578b\u7684\u505a\u6cd5\uff0c\u5728\u6700\u524d\u9762\u52a0\u4e0a\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u7528\u6765\u5206\u7c7b\u7684 token\uff0c\u5e76\u4e14\u6709\u81ea\u5df1\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c\u56e0\u4e3a\u540e\u7eed\u91c7\u7528\u7684Transformer \u7684 Encoder \u67b6\u6784\uff0c\u6bcf\u4e2a token \u65e0\u8bba\u662f\u5728\u5e8f\u5217\u91cc\u7684\u4ec0\u4e48\u4f4d\u7f6e\u90fd\u53ef\u4ee5\u770b\u5230\u6240\u6709\u7684\u5176\u4ed6 token\uff0c\u6240\u4ee5\u5373\u4f7f\u628a\u8fd9\u4e2a token \u56fa\u5b9a\u5230\u7b2c 1 \u4e2a\u4f4d\u7f6e\u4e0a\uff0c\u4e5f\u53ef\u4ee5\u6c47\u96c6\u6240\u6709\u56fe\u50cf patch \u7684\u4fe1\u606f\uff0c\u7f51\u7edc\u7ed3\u6784\u91c7\u7528\u7684\u4e5f\u662f Transformer \u4e2d\u7684 Encoder</p> <p></p>"},{"location":"learning/3_ViT/#vit-transformer-encoder","title":"ViT \u91c7\u7528\u7684\u662f Transformer Encoder \u67b6\u6784","text":"<p>\u4f20\u7edf\u7684\u5927\u6a21\u578b\u91c7\u7528\u7684\u662f decoder\uff0c\u56e0\u4e3a\u5927\u6a21\u578b\u4e00\u822c\u662f\u505a\u751f\u6210\u4efb\u52a1\u7684</p> <p>\u800c\u56fe\u7247\u5206\u7c7b\u662f\u505a\u4fe1\u606f\u63d0\u53d6\u7684\uff0c\u6240\u4ee5\u7528\u7c7b\u4f3c Bert \u7684\u67b6\u6784\uff0c\u91c7\u7528 Encoder \u7684\u6a21\u5757\uff0c\u6700\u540e\u901a\u8fc7\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u7684\u5206\u7c7b token \u7684\u4fe1\u606f\uff0c\u52a0\u4e0a\u4e00\u4e2a\u7b80\u5355\u7684 MLP\u5934\u8fdb\u884c\u56fe\u7247\u7684\u5206\u7c7b</p> <p></p> <p>\u7c7b\u4f3c\u4e8e Bert\uff0cViT \u4e5f\u8bad\u7ec3\u4e86\u4e0d\u540c\u5927\u5c0f\u7684\u6a21\u578b\uff0c\u5206\u4e3a Base\u3001Large\u3001Huge\uff0c\u5206\u522b\u6709\u4e0d\u540c\u7684\u5c42\u6570\u3001hidden size\u3001MLP size\u548c\u6ce8\u610f\u529b\u5934</p> <p></p> <p>\u5bf9\u4e8e ViT \u6a21\u578b\u7684\u8868\u793a\uff0c\u4e00\u822c\u4f1a\u7528\u7c7b\u4f3c\u4e8e ViT-L /16\u6765\u8fdb\u884c\u8868\u793a\uff0c\u8868\u793a\u8fd9\u662f\u4e00\u4e2a ViT Large \u6a21\u578b\uff0c\u5176\u4e2d patch \u7684\u5927\u5c0f\u4e3a 16\u00d716</p> <p>patch\u8d8a\u5c0f\uff0c\u4e00\u5f20\u56fe\u7247\u5206\u51fa\u6765\u7684 patch \u5c31\u8d8a\u591a\uff0c\u8f93\u5165\u5230 Transformer \u4e2d\u7684\u5e8f\u5217\u5c31\u8d8a\u957f\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u5c31\u8d8a\u9ad8\uff0c\u6a21\u578b\u6548\u679c\u4e5f\u8d8a\u597d</p>"},{"location":"learning/3_ViT/#_1","title":"\u5b9e\u9a8c\u6548\u679c","text":"<p>\u4f5c\u8005\u9009\u62e9\u4e86\u5f53\u65f6\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u597d\u7684\u5206\u7c7b\u6a21\u578b\uff1aResNet \u548c EfficientNet \u8fdb\u884c\u6bd4\u8f83\uff0c\u53ef\u4ee5\u770b\u5230\u5728 JFT \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5728\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0cViT-H/14 \u6a21\u578b\u51e0\u4e4e\u90fd\u53d6\u5f97\u4e86\u6700\u597d\u7684\u6210\u7ee9</p> <p>\u7279\u522b\u9700\u8981\u6ce8\u610f\u7684\u662f\u6700\u540e\u4e00\u884c\uff0c\u5728 <code>GPU V3 \u7684\u6838\u6570\u00d7\u8bad\u7ec3\u5929\u6570</code> \u8868\u793a\u7684\u8ba1\u7b97\u4ee3\u4ef7\u4e0a\uff0cViT \u6a21\u578b\u5177\u6709\u975e\u5e38\u5927\u7684\u4f18\u52bf\uff0c\u6240\u4ee5\u8bf4\u5728\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\uff0c\u8bad\u7ec3 ViT \u6a21\u578b\u66f4\u6709\u4f18\u52bf</p>"},{"location":"learning/3_ViT/#_2","title":"\u5b9e\u73b0\u7ec6\u8282","text":""},{"location":"learning/3_ViT/#embedding","title":"\u5b9e\u73b0\u7ec6\u8282\uff1a\u56fe\u50cf\u8f6c\u6362\u6210 embedding \u7684\u4e24\u79cd\u65b9\u5f0f\uff08\u770b\u56fe\uff09","text":"<p>\u7ebf\u6027\uff1a</p> <p>input \\(224*224*3\\) </p> <p>patch \\(16 * 16 * 3 = 768\\)</p> <p><code>#num</code> \\(14*14=\\)196\u4e2a patch</p> <p>\\(196*768 \u2192 196 * 1024\\)</p> <p>\u5377\u79ef\uff1a</p> <p>input \\(224*224*3\\) </p> <p>kernel $16 * 16 * 3 $</p> <p><code>#kernel</code> = 1024</p> <p>output \\(1024*14*14\\)</p> <p>flatten feature map \\(1024*14*14 \u2192 1024 * 196\\) </p> <p></p> <ul> <li>\u5377\u79ef\u64cd\u4f5c\u76f8\u6bd4\u7ebf\u6027\u6620\u5c04\u7701\u53bb\u4e86 patch \u5207\u5206\u7684\u64cd\u4f5c</li> <li>\u5377\u79ef\u8f93\u51fa\uff1a<code>1024\u00d7\u8f93\u51fa\u7279\u5f81\u56fe\u5927\u5c0f</code>  \uff08<code>\u56fe \u5377 \u56fe\u2192 \u56fe \u2192 flatten</code>\uff09</li> </ul>"},{"location":"learning/3_ViT/#_3","title":"\u5b9e\u73b0\u7ec6\u8282\uff1a\u4f4d\u7f6e\u7f16\u7801\u7684\u9009\u62e9","text":"<p>\u4f5c\u8005\u539f\u6587\u5173\u4e8e\u4f4d\u7f6e\u7f16\u7801\u6240\u505a\u7684\u5b9e\u9a8c\uff1a</p> <p>\uff081\uff09\u4e0d\u52a0\u4f4d\u7f6e\u7f16\u7801</p> <p>\uff082\uff091 \u7ef4\u4f4d\u7f6e\u7f16\u7801</p> <p>\uff083\uff092 \u7ef4\u4f4d\u7f6e\u7f16\u7801</p> <p>\uff084\uff09\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801</p> <p>\u6bd4\u5982 \u56fe\u4e2d\u5c06\u56fe\u7247\u5207\u5206\u4e3a 9 \u4e2a patch</p> <p>\u5bf9\u4e8e 1 \u7ef4\u4f4d\u7f6e\u7f16\u7801\u800c\u8a00\uff0c\u5c31\u662f\u751f\u6210 9 \u4e2a\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c\u6bcf\u4e2a\u4f4d\u7f6e\u7f16\u7801\u7684\u957f\u5ea6\u90fd\u548c\u7279\u5f81\u7ef4\u5ea6\u4e00\u6837\uff0c\u4e3a 1024</p> <p>\u5bf9\u4e8e 2 \u7ef4\u4f4d\u7f6e\u7f16\u7801\uff0c\u751f\u6210 3 \u4e2a\u8868\u793a\u884c\u7684\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c3 \u4e2a\u8868\u793a\u5217\u7684\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c \u957f\u5ea6\u90fd\u4e3a\u7279\u5f81\u957f\u5ea6\u7684\u4e00\u534a 512 \uff0c\u901a\u8fc7\u884c\u5217\u7279\u5f81\u7684\u62fc\u63a5\u6765\u6784\u6210 1 \u4e2a\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\uff0c\u6bd4\u5982\u5bf9\u4e8e\u7b2c 2 \u884c\u7b2c 1 \u5217\u7684 patch\uff0c\u5b83\u7684\u4f4d\u7f6e\u7f16\u7801\u5c31\u662f\u53d6\u7b2c 2\u4e2a\u884c\u4f4d\u7f6e\u7f16\u7801\u62fc\u63a5\u4e0a\u7b2c 1 \u5217\u4f4d\u7f6e\u7f16\u7801\u6784\u6210\u7684</p> <p>\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u4e0d\u52a0\u4f4d\u7f6e\u7f16\u7801\u6548\u679c\u6700\u5dee\uff0c\u800c\u5176\u4f59\u7684\u4f4d\u7f6e\u7f16\u7801\u7531\u8868\u53ef\u77e5\uff0c\u6548\u679c\u662f\u5dee\u4e0d\u591a\u7684</p> <p>\u601d\u8003\uff1a\u4e3a\u4ec0\u4e48\u4e0d\u52a0\u4f4d\u7f6e\u7f16\u7801\u6548\u679c\u4e5f\u8fd8\u53ef\u4ee5\uff080.61382\uff09\uff0c\u5e76\u6ca1\u6709\u5dee\u592a\u591a\uff1f</p> <p>\u8fd9\u662f\u56e0\u4e3a\u56fe\u7247\u88ab\u5207\u6210\u4e86 patch\uff0cpatch \u5185\u90e8\u662f\u542b\u6709\u4f4d\u7f6e\u4fe1\u606f\u7684\uff0c\u5c31\u50cf\u4e0a\u9762\u7684\u56fe\u7247\uff0c\u5b83\u7684 patch\u5373\u4f7f\u88ab\u6253\u4e71\u4e86\u4f4d\u7f6e\u4e5f\u53ef\u4ee5\u770b\u51fa\u6765\u662f1 \u4e2a\u5efa\u7b51\u7684\u56fe\u7247</p>"},{"location":"learning/3_ViT/#_4","title":"\u4f4d\u7f6e\u7f16\u7801\u7684\u8fdb\u4e00\u6b65\u7814\u7a76","text":"<p>\u5728\u539f\u6587\u4e2d\uff0c\u4f5c\u8005\u5bf9\u4f4d\u7f6e\u7f16\u7801\u8fdb\u884c\u4e86\u8fdb\u4e00\u6b65\u7684\u7814\u7a76</p> <p>\u901a\u8fc7 1 \u7ef4\u4f4d\u7f6e\u7f16\u7801\u4e5f\u662f\u80fd\u591f\u5b66\u4e60\u5230 2 \u7ef4\u4fe1\u606f\u7684\uff0c\u6bd4\u5982\u8fd9\u91cc\u8fd9\u4e2a\u4f4d\u7f6e\u7f16\u7801\u7684\u76f8\u5173\u6027\u7684\u56fe\uff0c\u53ef\u4ee5\u770b\u5230\u548c\u6bcf\u4e2a patch\u4f4d\u7f6e\u7f16\u7801\u6700\u76f8\u5173\u7684\u8fd8\u662f\u81ea\u5df1\u9644\u8fd1\u7684\u4ee5\u53ca\u81ea\u5df1\u6240\u5728\u884c\u5217\u7684 patch</p> <p>\u53e6\u5916\u4f5c\u8005\u7814\u7a76\u53d1\u73b0\u968f\u7740 Encoder \u5c42\u7684\u589e\u52a0\uff0c\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u5173\u6ce8\u7684\u5e73\u5747\u50cf\u7d20\u8ddd\u79bb\u53ef\u4ee5\u770b\u5230\u4e0d\u540c\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u7f51\u7edc\u6d45\u5c42\u6709\u7684\u5934\u5173\u6ce8\u8fd1\u8ddd\u79bb\u7684\u50cf\u7d20\uff0c\u4f46\u662f\u4e5f\u6709\u5f88\u591a\u5934\u5df2\u7ecf\u5173\u6ce8\u5230\u4e86\u8fdc\u8ddd\u79bb\u7684\u50cf\u7d20\uff0c\u968f\u7740\u6a21\u578b\u5c42\u6570\u7684\u52a0\u6df1\uff0c\u6a21\u578b\u8d8a\u6765\u8d8a\u5173\u6ce8\u8fdc\u8ddd\u79bb\u7684\u5168\u5c40\u4fe1\u606f\u4e86</p>"},{"location":"learning/3_ViT/#_5","title":"\u5bf9\u4e8e\u6a21\u578b\u7ed3\u6784\u7684\u5c1d\u8bd5","text":"<p>\u5173\u4e8e\u6a21\u578b\u7ed3\u6784\u7684\u5c1d\u8bd5\uff0c\u4f5c\u8005\u9009\u62e9\u4e86\u4e09\u79cd\u7ed3\u6784\u8fdb\u884c\u5bf9\u6bd4</p> <p>\u4e00\u79cd\u662f\u539f\u59cb\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u6bd4\u5982 ResNet</p> <p>\u4e00\u79cd\u662f\u53ea\u7528 Transformer \u7684 ViT</p> <p>\u6700\u540e\u4e00\u79cd \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c Transformer \u7684\u6df7\u5408\u6a21\u578b</p>"},{"location":"learning/3_ViT/#_6","title":"\u4ecb\u7ecd\u6df7\u5408\u6a21\u578b\u7684\u6a21\u578b\u67b6\u6784","text":"<p>\u9996\u5148\u7531\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u63d0\u53d6\u7279\u5f81\uff0c\u6700\u540e\u5728\u63d0\u53d6\u7684\u7279\u5f81\u6bcf\u4e2a\u7a7a\u95f4\u4f4d\u7f6e\u5c31\u662f\u4e00\u4e2a\u56fe\u50cf\u7684 patch\uff0c\u7136\u540e\u518d\u505a\u7ebf\u6027\u6620\u5c04\u8fdb\u5165 Transformer Encoder</p> <p>\u56fe\u4e2d\uff0c\u5706\u5f62\u8868\u793a ViT\uff0c\u65b9\u5f62\u8868\u793a ResNet\uff0c\u52a0\u53f7\u8868\u793a\u6df7\u5408\u6a21\u578b</p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\uff0c\u5728\u76f8\u540c\u7684\u9884\u8bad\u7ec3\u4ee3\u4ef7\u4e0b\uff0c\u521a\u5f00\u59cb\u6df7\u5408\u6a21\u578b\u6709\u4f18\u52bf\uff0c\u4f46\u662f\u968f\u7740\u8ba1\u7b97\u4ee3\u4ef7\u7684\u589e\u5927\uff0c\u4e5f\u5c31\u662f\u6a21\u578b\u7684\u589e\u5927\uff0c\u6700\u7ec8 ViT \u6a21\u578b\u7684\u6548\u679c\u8fd8\u662f\u7565\u597d\u4e8e\u6df7\u5408\u6a21\u578b\uff0c\u6240\u4ee5\u8bc1\u660e\u4e86 Transformer \u67b6\u6784\u5728\u89c6\u89c9\u9886\u57df\u5b8c\u5168\u53ef\u4ee5\u53d6\u4ee3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc</p>"},{"location":"learning/3_ViT/#_7","title":"\u5bf9\u4e8e\u56fe\u7247\u5206\u7c7b\u901a\u5e38\u4e5f\u6709\u4e24\u79cd\u505a\u6cd5","text":"<p>\u4e00\u79cd\u662f \u901a\u8fc7\u5728\u5e8f\u5217\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u589e\u52a0\u4e00\u4e2a\u5206\u7c7btoken \u6765\u63d0\u53d6\u56fe\u50cf\u7684\u5168\u5c40\u4fe1\u606f</p> <p>\u4e00\u79cd \u4e0d\u989d\u5916\u589e\u52a0 token\uff0c\u5c31\u7528\u6240\u6709\u56fe\u50cf patch \u6700\u540e\u4e00\u5c42\u8f93\u51fa\u7684\u5168\u5c40\u5e73\u5747\u6c60\u5316\u6765\u505a\u5168\u5c40\u4fe1\u606f</p> <p>\u4f5c\u8005\u505a\u4e86\u6bd4\u8f83\uff0c\u4e24\u4e2a\u6548\u679c\u662f\u7c7b\u4f3c\u7684</p>"},{"location":"learning/3_ViT/#_8","title":"\u8bad\u7ec3\u6570\u636e\u96c6\u5927\u5c0f\u5bf9\u6a21\u578b\u7684\u5f71\u54cd","text":"<p>\u56fe\u7247\u4e2d\u65b9\u5757\u8868\u793a\u7684\u662f\u4e0d\u540c\u5927\u5c0f\u7684 ResNet \u5728\u4e0d\u540c\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5706\u5f62\u8868\u793a\u7684\u662f\u4e0d\u540c\u5927\u5c0f\u7684 ViT \u5728\u4e0d\u540c\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u53ef\u4ee5\u770b\u5230\u5728\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u4e0a ResNet \u8868\u73b0\u597d\u4e8e ViT</p> <p>\u800c\u968f\u7740\u6570\u636e\u96c6\u89c4\u6a21\u7684\u589e\u5927\uff0cViT \u7684\u6548\u679c \u662f\u597d\u4e8e ResNet \u7684\uff0c\u6240\u4ee5\u901a\u8fc7\u8fd9\u4e2a\u56fe\u53ef\u4ee5\u77e5\u9053\uff0c\u5728\u767e\u4e07\u7ea7\u522b\u7684\u6570\u636e\u96c6\u4e0a ResNet \u597d\u4e8e ViT\uff0c\u5343\u4e07\u7ea7\u522b\u7684\u6570\u636e\u4e0a ResNet \u548c ViT \u5dee\u4e0d\u591a\uff0c\u4ebf\u7ea7\u522b\u7684\u6570\u636e\u4e0a\uff0cResNet \u4e0d\u5982 ViT</p>"},{"location":"learning/3_ViT/#vit-resnet","title":"\u2b50\ufe0f\u4e3a\u4ec0\u4e48\u5728\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u7684\u8bad\u7ec3 ViT\u4e0d\u5982 ResNet\uff1f","text":"<p>\u8fd9\u662f\u7531\u5f52\u7eb3\u504f\u7f6e\u5f15\u8d77\u7684</p> <p>\u4ec0\u4e48\u662f\u5f52\u7eb3\u504f\u7f6e\uff1f</p> <p></p> <p>\u5f52\u7eb3\u504f\u7f6e\u5c31\u662f\u5728\u8bad\u7ec3\u6a21\u578b\u65f6\u4eba\u4e3a\u5f15\u5165\u7684\u5148\u9a8c\u77e5\u8bc6\u7ed9\u6a21\u578b\uff0c\u8fd9\u4e9b\u77e5\u8bc6\u662f\u4eba\u7ed9\u7684\uff0c\u4e0d\u662f\u6a21\u578b\u4ece\u6570\u636e\u4e2d\u5b66\u6765\u7684\uff0c\u6bd4\u5982\u5377\u79ef\u64cd\u4f5c\u4e2d\uff0c\u6bcf\u4e00\u5c42\u90fd\u6709\u4e24\u4e2a\u5f52\u7eb3\u504f\u7f6e\uff1a\uff081\uff09\u5c40\u90e8\u6027\uff082\uff09\u5e73\u79fb\u4e0d\u53d8\u6027</p> <p>\u5377\u79ef\u6838\u4e3a\u4ec0\u4e48\u53ea\u4f5c\u7528\u5728\u4e00\u5f20\u56fe\u7247\u7684\u5c40\u90e8\u5462\uff1f</p> <p>\u56e0\u4e3a\u56fe\u7247\u76f8\u5173\u4fe1\u606f\u90fd\u96c6\u4e2d\u5728\u5c40\u90e8</p> <p>\u5377\u79ef\u6838\u4e3a\u4ec0\u4e48\u5728\u56fe\u7247\u4e0a\u8fdb\u884c\u5e73\u79fb\uff1f</p> <p>\u56e0\u4e3a\u7269\u4f53\u4e0d\u8bba\u662f\u5728\u56fe\u7247\u4e0a\u7684\u4ec0\u4e48\u4f4d\u7f6e\uff0c\u7269\u4f53\u7684\u7279\u5f81\u662f\u4e0d\u53d8\u7684</p> <p>\u4ee5\u4e0a\u4e24\u70b9\u5148\u9a8c\u77e5\u8bc6\u90fd\u7ed9\u4e86\u6a21\u578b\uff0c\u6240\u4ee5\u6a21\u578b\u5b66\u4e60\u8d77\u6765\u76f8\u5bf9\u7b80\u5355</p> <p>\u8fd9\u4e2a\u5f52\u7eb3\u504f\u7f6e\uff0c\u5728\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6bcf\u4e00\u5c42\u90fd\u8d77\u4f5c\u7528\uff0c\u4f46\u662f ViT \u91c7\u7528\u7684 Transformer\u67b6\u6784\uff0c\u5f15\u5165\u7684\u5f52\u7eb3\u504f\u7f6e\u6bd4\u8f83\u5c11\uff0c\u5c31\u662f\u5728\u5207\u5206 patch \u65f6\u5f15\u5165\u4e86\u5c40\u90e8\u6027\uff0c\u56e0\u4e3a\u628a\u539f\u59cb\u56fe\u7247\u5212\u5206\u6210\u4e86 patch\uff0c\u800c\u4e0d\u662f\u968f\u673a\u53d6\u4e00\u4e9b\u50cf\u7d20\uff0c\u8fd8\u6709\u5c31\u662f\u5bf9\u6240\u6709\u7684 patch\uff0c\u90fd\u7528\u540c\u6837\u7684\u7ebf\u6027\u5c42\u8fdb\u884c embedding\uff0c\u8fd9\u91cc\u76f8\u5f53\u4e8e\u5f15\u5165\u4e86\u5e73\u79fb\u4e0d\u53d8\u6027</p> <p>\u4f46\u662f ViT \u53ea\u662f\u5728\u5207\u5206 patch \u548c\u5bf9 patch \u8fdb\u884c\u7f16\u7801\u65f6\u5f15\u5165\u4e86\u5f52\u7eb3\u504f\u7f6e\uff0c\u540e\u9762\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u662f\u5b8c\u5168\u6ca1\u6709\u5f15\u5165\u5f52\u7eb3\u504f\u7f6e\u7684\uff0c\u6240\u4ee5\u5bfc\u81f4\u4e86 ViT \u5728\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u5b66\u4e60\u6bd4 ResNet \u8981\u6162\u4e00\u4e9b</p>"},{"location":"learning/3_ViT/#_9","title":"\u81ea\u76d1\u7763\u5b66\u4e60","text":"<p>\u6700\u540e\uff0cViT \u7684\u4f5c\u8005\u8fd8\u5c1d\u8bd5\u4e86\u8ba9\u56fe\u7247\u8fdb\u884c\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u56e0\u4e3a\u6709\u6807\u8bb0\u7684\u6570\u636e\u603b\u662f\u5c11\u6570\u7684\uff0c\u60f3\u8ba9\u6a21\u578b\u53d6\u5f97\u5927\u89c4\u6a21\u7684\u6570\u636e\u96c6\u53d6\u5f97\u7a81\u7834\u6027\u7684\u8fdb\u5c55\uff0c\u4e00\u5b9a\u8981\u662f\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u5c31\u50cf Bert \u7684\u6210\u529f\u548c GPT \u7684\u6210\u529f</p> <p>\u4f5c\u8005\u5728\u5c1d\u8bd5\u81ea\u76d1\u7763\u5b66\u4e60\u65f6\uff0c\u501f\u9274\u4e86 Bert \u7684\u505a\u6cd5\uff0c\u5177\u4f53\u64cd\u4f5c\uff1a</p> <p>\u5c06 50%\u7684\u56fe\u50cf patch \u8fdb\u884c\u6807\u8bb0\uff0c\u5728\u8fd9\u4e9b\u6807\u8bb0\u7684 patch \u4e2d 80%\u5c06 embedding \u66ff\u6362\u6210\u53ef\u5b66\u4e60\u7684 mask \u6807\u7b7e\uff0c10%\u7684 embedding \u66ff\u6362\u4e3a\u5176\u4ed6\u7684 patch embedding\uff0c10%\u7684 embedding \u4fdd\u6301\u4e0d\u53d8\uff0c\u6700\u7ec8\u8ba9\u5229\u7528\u6807\u8bb0\u7684\u8fd9\u4e9b patch \u7684\u8f93\u51fa\u9884\u6d4b\u539f\u59cb\u56fe\u7247\u7684\u50cf\u7d20\u503c</p> <p>\u4e3a\u4e86\u7b80\u5316\u95ee\u9898\uff0c\u5c06\u539f\u6765 RGB \\(255*255*255\\) \u4e00\u5171 1658 \u4e07\u591a\u79cd\u989c\u8272\u7b80\u5316\u5230 RGB \u5206\u522b\u5bf9\u5e94 8 \u4e2a\u503c  \\(8*8*8\\) \u4e00\u5171 256 \u79cd\u989c\u8272</p> <p>\u6700\u7ec8\u7684\u6548\u679c\u975e\u5e38\u4e0d\u9519</p> <p>ViT \u6253\u5f00\u4e86 Transformer \u67b6\u6784\u5904\u7406\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u591a\u6a21\u6001\u6570\u636e\u7684\u5927\u95e8\uff0c\u8ba9\u591a\u6a21\u6001\u901a\u7528\u4eba\u5de5\u667a\u80fd\u6210\u4e3a\u53ef\u80fd</p>"},{"location":"learning/4_GAN/","title":"GAN","text":""},{"location":"learning/4_GAN/#gan","title":"GAN","text":"2024-12-03 09:54:572025-09-28 12:54:04 <p> \u7ea6 6957 \u4e2a\u5b57  401 \u884c\u4ee3\u7801  65 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 40 \u5206\u949f</p> <p>About GAN</p> <ul> <li> cycleGAN </li> <li> starGAN </li> <li> C-RNN-GAN</li> </ul> <p>\u89c6\u9891\u94fe\u63a5</p> <p></p> <p>\u6587\u751f\u56fe\u6a21\u578b</p> <p></p> <p>\u4ea4\u4e92\u5f0f\u7684demo</p> <p>text2image\u7684\u6a21\u578b \u6216\u8005\u53eb caption2image\uff1a\u53ef\u4ee5\u600e\u4e48\u6784\u9020\u8fd9\u6837\u4e00\u4e2a\u6a21\u578b\u5462\uff1f</p> <p>\u524d\u63d0\uff1a\u7b97\u529b\u591f\u3001\u6570\u636e\u591f\uff0c\u6709\u5927\u91cf\u7684\u56fe\u50cf\u6587\u672c\u5bf9</p> <p>\u6587\u672c\u8f93\u5165\u5230bert\u4e2d\uff0c\u63d0\u53d6\u6587\u672c\u7279\u5f81\uff0c\u901a\u8fc7Transformer\u6a21\u578b\u751f\u6210\u56fe\u50cfpatch\uff0c\u7136\u540e\u628apatch\u62fc\u8d77\u6765\u6784\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u5047\u8bbe\u91c7\u7528 \u8fd9\u6837\u7684\u6a21\u578b\uff0cLOSS\u8be5\u600e\u4e48\u8bbe\u8ba1\uff1f</p> <p>\u6700\u5e38\u7528\u7684loss\uff0c\u6bd4\u5982L1 loss\uff0cL2 loss\uff0c\u5f52\u4e00\u5316\u52300~1\u4e4b\u95f4\uff0c\u5c06\u9884\u6d4b\u7684\u56fe\u50cf\u50cf\u7d20\u70b9\u503c\u8ddf\u771f\u5b9e\u7684target\u50cf\u7d20\u70b9\u503c\u4f5c\u5dee\uff0c\u7528\u5dee\u7684\u7edd\u5bf9\u503c \u6216\u8005\u5e73\u65b9\u4f5c\u4e3aloss </p> <p>\u53e6\u5916\u4e00\u79cd\u7528\u6cd5\uff1a\u628a\u751f\u6210\u7684\u7167\u7247\u7528\u5728\u53e6\u5916\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0c\u6bd4\u5982\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u5224\u65ad\u7167\u7247\u662f\u751f\u6210\u7684\u7167\u7247\u8fd8\u662f\u8bc6\u522b\u7684\u7167\u7247\uff0c\u8fd9\u79cd\u7f51\u7edc\u7684\u601d\u60f3\u5c31\u662f GAN \u751f\u6210\u5bf9\u6297\u7f51\u7edc  \uff08topic\uff09</p> <p></p> <p>DALLE\u7684\u7528\u7684\u662f diffusion process\uff0cDiffusion process \u4e3b\u8981\u7528\u968f\u673a\u566a\u58f0\u751f\u6210\u76ee\u6807\u5206\u5e03\uff0c\u6570\u5b66\u516c\u5f0f\u6bd4\u8f83\u590d\u6742\uff0c\u901f\u5ea6\u6709\u5f85\u63d0\u5347\uff0c\u751f\u6210\u56fe\u7247\u7684\u8d28\u91cf\u8ddf\u8fed\u4ee3\u6b21\u6570\u6709\u5173\uff0c\u8fed\u4ee3\u6b65\u9aa4\u8d8a\u5927\uff0c\u751f\u6210\u8d28\u91cf\u8d8a\u597d\u3002</p> <p></p> <p>GAN\u601d\u60f3\uff1a\u751f\u6210\u7684\u7167\u7247\u653e\u5230\u8bc6\u522b\u7f51\u7edc\u4e2d\uff0c\u5224\u65ad\u7167\u7247\u6765\u81ea\u771f\u5b9e\u7684\u8fd8\u662f\u751f\u6210\u7684</p> <p>\u8bba\u6587\u5bfc\u8bfb &amp; \u4ee3\u7801\u5b9e\u73b0</p> <p>2024\u5e74\u7684\u8bba\u6587</p> <p>\u5f15\u7528\u91cf\u76ee\u524d4\u4e07\u591a\u3001\u6b8b\u5dee\u7f51\u7edc\u5f15\u7528\u91cf10\u4e07\u591a\u3001\u4e00\u534a\u7684\u5173\u7cfb\uff0c\u56e0\u4e3aGAN\u7f51\u7edc\u4e3b\u8981\u5728\u751f\u6210\u7f51\u7edc\u4e2d\u4f7f\u7528\uff0c\u5bf9\u4e8e\u8bc6\u522b\u5206\u7c7b\u4efb\u52a1\uff0cGAN\u4e0d\u592a\u9002\u7528\uff0c\u800c\u6b8b\u5dee\u7f51\u7edc\u7684\u5e94\u7528\u8303\u56f4\u66f4\u5e7f\u6cdb</p>"},{"location":"learning/4_GAN/#_1","title":"\u6458\u8981","text":"<p>We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: </p> <p>\u63d0\u51fa\u4e86\u65b0\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u5bf9\u6297\u8fc7\u7a0b\u4f30\u8ba1\u751f\u6210\u6a21\u578b</p> <p>a generative model G that captures the data distribution, </p> <p>\u751f\u6210\u6a21\u578bG\u6355\u6349\u6570\u636e\u5206\u5e03</p> <p>and a discriminative model D that estimates the probability that a sample came from the training data rather than G. </p> <p>\u5224\u522b\u6a21\u578bD\u4f30\u8ba1\u6837\u672c\u6765\u81ea\u6765\u81ea\u8bad\u7ec3\u6570\u636e\u8fd8\u662f\u751f\u6210\u5668G</p> <p>The training procedure for G is to maximize the probability of D making a mistake.</p> <p>This framework corresponds to a minimax two-player game.</p> <p>\u8be5\u6846\u67b6\u5bf9\u5e94\u6781\u5927\u6781\u5c0f\u4e24\u4eba\u535a\u5f08</p> <p>In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \\(\\frac{1}{2}\\) everywhere.</p> <p>\u5728\u4efb\u610f\u51fd\u6570G\u548cD\u7684\u7a7a\u95f4\u4e2d\uff0c\u5b58\u5728\u552f\u4e00\u89e3\uff0cG\u6062\u590d\u8bad\u7ec3\u6570\u636e\u5206\u5e03\uff0cD\u5904\u5904\u7b49\u4e8e \\(\\frac{1}{2}\\)</p> <p>D\u6b64\u65f6\u65e0\u6cd5\u533a\u5206\u6570\u636e\u662f\u6765\u81ea\u771f\u5b9e\u7684\u6570\u636e\u8fd8\u662f\u771f\u5b9e\u7684\u6570\u636e</p> <p>In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation.</p> <p>G\u548cD\u90fd\u662f\u7531\u5168\u8fde\u63a5\u5c42\u6784\u6210\u7684</p> <p>There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples.</p> <p>Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.</p>"},{"location":"learning/4_GAN/#intro","title":"Intro","text":"<p>\u4e00\u4e2a\u6bd4\u55bb\uff1a\uff08\u539f\u6587\u7b2c\u4e8c\u6bb5\uff09</p> <p></p> <p>\u5bf9\u6297\u7f51\u7edc\u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u5177\u4f53\u5730\u65b9\u6cd5\u662f\u53ef\u4ee5\u81ea\u5df1\u586b\u5145\u7684</p>"},{"location":"learning/4_GAN/#adversarial-nets","title":"\u6a21\u578b\u65b9\u6cd5 Adversarial nets","text":"<p>\u7b26\u53f7\u8bf4\u660e\uff1a</p> <p>\u751f\u6210\u5668\u7684\u5206\u5e03\uff1a \\(p_g\\)  \u751f\u6210\u5668\u5b66\u4e60 \\(x\\) \u7684\u5206\u5e03</p> <p>\u539f\u59cb\u6570\u636e\uff1a\\(x\\)</p> <p>\u8f93\u5165\u566a\u58f0\u53d8\u91cf\uff1a\\(p_z(z)\\)</p> <p>\u6570\u636e\u7a7a\u95f4\u7684\u6620\u5c04\uff1a\\(G(z;\\theta_g)\\)</p> <p>\u6a21\u578b\u5f00\u59cb\u7684\u5148\u9a8c\u5206\u5e03\u662f \\(p_z(z)\\),\u901a\u8fc7 \\(G(z;\\theta_g)\\)\uff0c\u5b66\u4e60\u5230  \\(p_g\\)\uff0c \\(p_g\\) \u8868\u793a\u4e86 \\(x\\) \u7684\u5206\u5e03</p> <p>\\(G(z;\\theta_g)\\) \u53d8\u91cf\u662f \\(z\\)\uff0c\u53c2\u6570\u662f \\(\\theta_g\\) </p> <p>\u8f93\u5165\u566a\u58f0\u53d8\u91cf \\(z\\)\uff0c\\(z\\)\u6765\u81ea\\(p_z\\)</p> <p>G \u662f\u7531 \u53c2\u6570\u4e3a \\(\\theta_g\\) \u7684\u591a\u5c42\u611f\u77e5\u673a\u8868\u793a\u7684\u53ef\u5fae\u51fd\u6570</p> <p>\u591a\u5c42\u611f\u77e5\u5668 \\(D(x;\\theta_d)\\)  \u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\uff1b\u8868\u793a\u4e00\u4e2a\u6982\u7387\uff0c\u5224\u65ad\u6570\u636e\u6765\u81ea\u751f\u6210\u5668\u8fd8\u662f\u5224\u522b\u5668</p> <p>D \u7684\u8f93\u5165\u662f \\(x\\)\uff0c\u53c2\u6570\u662f \\(\\theta_d\\)\uff0c\u8f93\u51fa\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u53cd\u6620\u6570\u636e...</p> <p>\u8bad\u7ec3 D \u6700\u5927\u5316 \u7ed9\u8bad\u7ec3\u6837\u672c\u548c\u6765\u81ea \\(G\\) \u7684\u6837\u672c\u5206\u914d\u6b63\u786e\u6807\u7b7e\u7684\u6982\u7387</p> <p>D\u7684\u76ee\u7684\u662f\u80fd\u591f\u6b63\u786e\u5206\u7c7b \u8bad\u7ec3\u6837\u672c \u548c G\u7684\u6837\u672c\u6982\u7387</p> <p>\u8bad\u7ec3 G \u6700\u5c0f\u5316 \\(log(1-D(G(z)))\\)</p> <p>\\(log\\)\u5355\u8c03\u9012\u589e\uff0c\u62ec\u53f7\u91cc\u9762 \\(1-D(G(z))\\) \u6700\u5c0f\uff0c\u6240\u4ee5 \\(D(G(z))\\)  \u6700\u5927</p> <p>\\(D(G(z))\\) \u6700\u5927\u8868\u793a \u751f\u6210\u5668\u6240\u751f\u6210\u7684\u6837\u672c \u8f93\u5165\u5230\u5224\u522b\u5668\u7684\u65f6\u5019\uff0c\u5224\u522b\u5668\u5c06\u5b83\u5224\u522b\u6210 \\(1\\)</p> <p>\u4e5f\u5c31\u662f\u8bf4 \u751f\u6210\u5668\u751f\u6210\u7684\u6837\u672c\uff0c\u5224\u522b\u5668\u5c06\u5b83\u5224\u522b\u6210\u6765\u81ea\u771f\u5b9e\u6837\u672c\uff0c\u7b49\u4e8e1\uff0c\u8fd9\u65f6\u5019\u751f\u6210\u5668\u7684\u76ee\u6807\u5c31\u5df2\u7ecf\u8fbe\u6210\u4e86\uff0c\u4eceG\u751f\u6210\u7684\u6570\u636e\uff0c\u5224\u522b\u5668\u8ba4\u4e3a\u662f\u771f\u5b9e\u7684\u6570\u636e</p> <p></p> <p>\u4ef7\u503c\u51fd\u6570 \\(V(G,D)\\)</p> <p>\u89e3\u91ca\u4ef7\u503c\u51fd\u6570:</p> <p>\\(\\min_G \\max_G V(D,G)\\) </p> <p>min\u662f\u5bf9G\u800c\u8a00\uff0c\\(max\\)\u5bf9\\(D\\)\u800c\u8a00</p> <p>\u2460 \u5bf9\\(D\\)\u800c\u8a00 \u6211\u4eec\u8ba9\\(V\\)\u8fbe\u5230\u6700\u5927\uff0c\u8981\u8ba9\\(V\\)\u8fbe\u5230\u6700\u5927\uff0c\u4e5f\u5c31\u662f  \\(logD(x)\\) \u8fbe\u5230\u6700\u5927\uff0c\u540c\u65f6\\(log 1-D(G(z))\\)  \u8fbe\u5230\u6700\u5927\uff0c\u56e0\u6b64\u5bf9\u4e8e\u5224\u522b\u5668\u800c\u8a00\uff0c\u6211\u4eec\u5e0c\u671b\u5224\u522b\u5668 \u80fd\u591f\u628a\u6765\u81ea\u4e8e\u8bad\u7ec3\u96c6\u7684\u6837\u672c \u628a\u5b83\u5206\u7c7b\u6210\u771f\u5b9e\u7684\uff0c\u6765\u81ea\u751f\u6210\u5668\u7684\u6837\u672c \u5206\u7c7b\u6210\u5047\u7684\uff0c\u8fd9\u4e2a\u5bf9\u4e8e\u5224\u522b\u5668\u7684\u8bad\u7ec3\u76ee\u6807</p> <p>\u2461 \u751f\u6210\u5668\u7684\u8bad\u7ec3\u76ee\u6807\uff0cminG\uff0c\u4e5f\u5c31\u662f\u8bf4 \u5bf9\u4e8e\u751f\u6210\u5668\u800c\u8a00\uff0c\u540e\u9762\u4e24\u4e2a\u8fbe\u5230\u6700\u5c0f\uff0c\u7531\u4e8e\u7b2c\u4e00\u9879\\(logD(x)\\)\u4e0eg\u65e0\u5173\uff0c\u6240\u4ee5\u7b2c\u4e00\u9879\u4e0d\u7528\u770b\uff0c\u5728\u8bad\u7ec3\u96c6\u4e2d \u7b2c\u4e00\u9879 \u76f8\u5f53\u4e8e\u4e00\u4e2a\u5e38\u6570 \u4e0d\u91cd\u8981\u3002\u4e3b\u8981\u770b\u7b2c\u4e8c\u9879\uff0c\u7b2c\u4e8c\u9879\u8fbe\u5230\u6700\u5c0f\u7684\u8bdd\uff0c\u4e5f\u5c31\u662f\u8bf4 \u5e0c\u671b\\(DG(z)\\)\u8fbe\u5230\u6700\u5927\uff0c\u4e5f\u5c31\u662f\u8bf4 \u8bad\u7ec3G\u7684\u76ee\u6807 \u5c31\u662f\u5e0c\u671b \\(D(G(z))\\) \u8fbe\u5230\u6700\u5927\uff0c\u4e5f\u5c31\u662f\u8bf4 \u4ece\u751f\u6210\u5668\u751f\u6210\u51fa\u6765\u7684\u6837\u672c \u9001\u5165\u5230\u5224\u522b\u5668\u4e2d \u6211\u4eec\u5e0c\u671b\u5224\u522b\u5668\u8fd9\u65f6\u5019 \u7ed9\u51fa\u7684\u5206\u7c7b\u7ed3\u679c \u5206\u7c7b\u6210 \u771f\u5b9e\u7684\u6837\u672c\uff1b\u5f53\u8fbe\u5230\u8fd9\u6837\u7684\u7ed3\u679c\u65f6\uff0c\u8bf4\u660eG\u8bad\u7ec3\u7684\u7ed3\u679c\u662f\u5f88\u597d\u7684</p> <p>\\(\\mathbb{E}_{{x \\sim p_{data}(x)}}\\)  x\u670d\u4ecep data(x)\uff0c\u4e5f\u5c31\u662f\u8bad\u7ec3\u96c6\uff0cx\u4e5f\u5c31\u662f\u8bad\u7ec3\u96c6\u4e2d\u7684\u6837\u672c</p> <p>\\(\\mathbb{E}_{{x \\sim p_{data}(x)}}[logD(x)]\\) \u8bad\u7ec3\u96c6\u4e2d\u7684\u6837\u672c\u9001\u5165\u5230\u5224\u522b\u5668\u4e2d\uff0c\u4e5f\u5c31\u662f\u6982\u7387\u53d6\u4e00\u4e2a\\(log\\)\uff0c\u4e5f\u5c31\u662f\u5bf9\u6570\u4f3c\u7136</p> <p>\\(\\mathbb{E}_{{z \\sim p_{z}(z)}}\\) \u7b2c\u4e8c\u90e8\u5206\\(z\\)\u670d\u4ece \\(p_z(z)\\)\uff0c\\(z\\)\u5c31\u662f\u521d\u59cb\u7684\u968f\u673a\u7684\u566a\u58f0\uff0c\\(z\\)\u9001\u5165\u5230\u751f\u6210\u5668\u4e4b\u4e2d \u5f97\u5230\\(G(z)\\)</p> <p>\\(\\mathbb{E}_{{x \\sim p_{z}(z)}}[log(1-D(G(z)))]\\) \\(G(z)\\)\u5c31\u662f\u751f\u6210\u5668\u7684\u8f93\u51fa\uff0c\\(G(z)\\)\u8f93\u5165\u5230\\(D\\)\u4e4b\u4e2d\u5f97\u5230\u4e00\u4e2a\u6982\u7387\uff0c\u7136\u540e\u628a1-\u6982\u7387\uff0c\\(1-DG\\)\uff0c\u5c31\u662f\u8868\u793a \u5224\u522b\u5668\u628a \\(G(z)\\) \u5206\u7c7b\u6210 \u5047\u6837\u672c\u7684\u6982\u7387</p> <p></p> <p>\uff081\uff09\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u57fa\u4e8emini batch\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u7b97\u6cd5\uff1b\u8d85\u53c2\u6570k\uff1b</p> <p>\uff082\uff09k\uff1f\u4e00\u822c\u6587\u7ae0\u800c\u8a00\uff0c\u53ef\u4ee5\u5148\u8bad\u7ec3k\u6b65\u7684\u5224\u522b\u5668\uff0c\u7136\u540e\u518d\u8bad\u7ec3\u4e00\u6b65\u751f\u6210\u5668\uff0c\u8fd9\u91cc\u53d6k=1\uff0c\u8868\u793a\u6bcf\u8bad\u7ec3\u4e00\u6b65\u5224\u522b\u5668\uff0c\u5c31\u8bad\u7ec3\u4e00\u6b65\u751f\u6210\u5668\uff0c\u7136\u540e\u518d\u8bad\u7ec3\u4e00\u6b65\u5224\u522b\u5668\uff0c\u518d\u8bad\u7ec3\u4e00\u6b65\u751f\u6210\u5668\uff0c\u4ea4\u66ff\u8fdb\u884c\uff0ck\u662f\u4e00\u4e2a\u8d85\u53c2\u6570\uff0c\u4e00\u822c\u6765\u8bf4k=1\uff1b\u4e5f\u6709\u4e00\u4e9b\u4efb\u52a1\uff0c\u5148\u8bad\u7ec3\u751f\u6210\u5668\uff0c\u8bad\u7ec3\u4e00\u6bb5\u65f6\u95f4\uff0c\u518d\u5f00\u59cb\u4ea4\u66ff\u8bad\u7ec3\u751f\u6210\u5668\u548c\u5224\u522b\u5668</p> <p>\uff083\uff09\u770b\u7b97\u6cd5\u7684\u8fed\u4ee3\u6d41\u7a0b\uff0c\u4e24\u4e2afor\u8bad\u7ec3\uff1b\u7b2c\u4e00\u4e2afor\u5faa\u73af\uff0c\u5faa\u73afepoch\uff0c\u7b2c\u4e8c\u4e2afor\u5faa\u73af\uff0c\u5faa\u73afdataset \u6216\u8005 dataloader \u8fdb\u884c\u904d\u5386</p> <p></p> <p>\uff084\uff09\u9996\u5148\u7b2c\u4e00\u6b65\uff0c\u7b2c\u4e00\u4e2afor\u5faa\u73af\uff0c\u5148\u8bad\u7ec3k\u6b65\u7684\u5224\u522b\u5668\uff0c k\u53ef\u4ee5\u53d61\uff0c\u5728\u8bad\u7ec3\u5224\u522b\u5668\u65f6\uff0c\u9996\u5148\u4ece\u566a\u58f0\u5206\u5e03\u4e2d\uff0c\u968f\u673a\u91c7\u6837m\u4e2a\u6837\u672c\uff0c\u6784\u6210\u4e00\u4e2aminibatch\uff0cm\u4e2a\u6837\u672c\u5206\u522b\u6784\u6210z1\u5230zm\uff0c\u4ece\u5148\u9a8c\u5206\u5e03 \\(p_g(z)\\) \u91c7\u6837\u800c\u6765\uff0c\\(p_g(z)\\)\u53ef\u4ee5\u662f\u4e00\u4e2a\u6b63\u6001\u5206\u5e03\uff1b\u8fd9\u5c31\u662f\u7b2c\u4e00\u6b65\u5148\u91c7\u6837\u8f93\u5165</p> <p></p> <p>\uff085\uff09\u7b2c\u4e8c\u6b65\uff0c\u91c7\u6837\u771f\u5b9e\u7684\u6570\u636e\u5206\u5e03\uff0c\u91c7\u6837m\u4e2a\u6837\u672c\uff0c\u4ece\u8bad\u7ec3\u96c6\u4e2d\u91c7\u6837m\u4e2a\u6837\u672c</p> <p></p> <p>\uff086\uff09\u57fa\u4e8e\u68af\u5ea6\u4e0a\u5347 ascending \u516c\u5f0f\uff0c\u66f4\u65b0\u5224\u522b\u5668 \uff1b\u76ee\u6807\u51fd\u6570\u662f \\(logD+log(1-DG)\\)</p> <p>\u5bf9\u4e8e\u5224\u522b\u5668\u800c\u8a00\uff0c\u5224\u522b\u7684\u6807\u91cf\u6709\u4e24\u4e2a\uff0c\u7b2c\u4e00\u4e2a\u4ee5x\u4f5c\u4e3a\u8f93\u5165\uff0c\u4ece\u8bad\u7ec3\u96c6\u4e2d\u62ff\u51fa\u7684\u6837\u672c\uff0c\u9001\u5230\u5224\u522b\u5668\u4e2d\uff0c\u5f97\u5230\u4e00\u4e2a\u6982\u7387\u503c\uff0c\u8fd9\u65f6\u7684\u6982\u7387\u503c\u53eb\u505a \\(D(x)\\)\uff0c\u7b2c\u4e8c\u4e2a\u4ece\u751f\u6210\u5668\u4e2d\uff0c\u62ff\u5230\u8f93\u51fa\uff0c\u53eb\u505a\\(G(z)\\)\uff0c\\(G(z)\\)\u9001\u5165\u5230\\(D\\)\u4e2d\uff0c\u5f97\u5230\u53e6\u5916\u4e00\u4e2a\u5224\u522b\u7684\u6982\u7387\uff0c\\(1-\u5224\u522b\u6982\u7387\\)\uff0c\u8fdb\u884c\u4e00\u4e2a \\(log\\) \u8fd0\u7b97\uff0c\u5f97\u5230\u7b2c\u4e8c\u9879\uff0c\u5916\u9762\u7684\u6c42\u548c\u662f\u5bf9\u6574\u4e2aminibatch\uff0c\u6bcf\u4e2a\u6837\u672c\u90fd\u8fd9\u6837\u505a\uff0c\u518d\u9664\u4ee5\\(m\\)\uff0c\u5728\u6837\u672c\u7ef4\u5ea6\u53d6\u4e00\u4e2a\u5e73\u5747\u503c\uff0c\u4ee5\u8fd9\u4e2a\u4f5c\u4e3a \\(target\\)\uff0c\u6b64\u65f6\u7684 \\(\\nabla\\)  \u662f\u4f5c\u7528\u5230 \\(\\theta_D\\) \u7684</p> <p>\u4e5f\u5c31\u662f\u8bf4 \u5bf9\u4e8e\u8fd9\u4e2a\u76ee\u6807\u51fd\u6570 \u53ea\u4f1a\u5bf9 \u5224\u522b\u5668\u7684\u53c2\u6570 \u6c42\u68af\u5ea6\uff0c\u6c42\u5b8c\u68af\u5ea6\u4ee5\u540e\uff0c\u518d\u7528\u68af\u5ea6\u4e0a\u5347\u7b97\u6cd5\uff0c\u6765\u66f4\u65b0\u5224\u522b\u5668\u7684\u53c2\u6570\uff0c\u4ee5\u4e0a\u662f\u7b2c\u4e00\u6b65\u66f4\u65b0\u5224\u522b\u5668</p> <p>\u5982\u679c \\(k&gt;1\\)\uff0c\u9700\u8981\u4e0d\u65ad\u7684\u5faa\u73af\uff0c\u8fde\u7eed\u7684\u66f4\u65b0\u5224\u522b\u5668\uff0c\u66f4\u65b0k\u6b65\uff0c\u66f4\u65b0\u5b8c\u5224\u522b\u5668\u4ee5\u540e\uff0c\u66f4\u65b0\u751f\u6210\u5668\u90e8\u5206\uff1a</p> <p></p> <p>\uff081\uff09\u751f\u6210\u5668\u90e8\u5206\uff0c\u7b2c\u4e00\u6b65\uff0c\u540c\u6837\u53d6m\u4e2a\u566a\u58f0\u6837\u672c\uff0c\u6784\u6210\u4e00\u4e2aminibatch\uff0c\u540c\u6837\u7684\u4ece\u4e00\u4e2a\u5148\u9a8c\u5206\u5e03\u4e2d\u53d6\uff0c\u5f3a\u8c03\u4e00\u70b9\uff1a</p> <p></p> <p>\uff082\uff09\u7b2c\u4e8c\u6b65\uff0c\u91c7\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5(descending)\uff0c\u66f4\u65b0\u751f\u6210\u5668\uff0c\u6b64\u65f6\u7684\u76ee\u6807\u51fd\u6570\uff0c\u4e5f\u5c31\u662f\u6700\u5c0f\u5316\u51fd\u6570\u662f \\(log(1-DG)\\) \uff0c\u53ea\u9700\u8981\u628a\u751f\u6210\u5668\u751f\u6210\u7684 \\(G\\)\uff0c\u9001\u5165\u5230\u5224\u522b\u5668\u4e4b\u4e2d\uff0c\u5f97\u5230\\(D\\)\uff0c\\(DG\\)\u5c31\u662f\u5224\u522b\u5668\u9884\u6d4b\u7684\u6982\u7387\uff0c\\(1-\u6982\u7387\\)\u53d6log\uff0c\u5f97\u5230 \\(log(1-DG)\\)\uff0c\u7136\u540e\u5bf9\u6bcf\u4e2a\u6837\u672c\u7684\u635f\u5931\u6c42\u548c\uff0c\u518d\u9664\u4ee5m\uff0c\u53d6\u5e73\u5747\uff0c\u8fd9\u662f\u68af\u5ea6\u53ea\u5bf9\u751f\u6210\u5668\u7684\u53c2\u6570\u8ba1\u7b97\uff0c\u5728\u57fa\u4e8e\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u66f4\u65b0 \u751f\u6210\u5668\u7684\u53c2\u6570\uff0c\u8fd9\u65f6\u4e0d\u9700\u8981\u66f4\u65b0\u5224\u522b\u5668\u7684\u53c2\u6570</p> <p>\u4e0a\u9762\u7684\u5f0f\u5b50\uff0c\u53ea\u66f4\u65b0\u5224\u522b\u5668\u7684\u53c2\u6570\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\u751f\u6210\u5668\u7684\u53c2\u6570</p> <p>\u4e0b\u9762\u7684\u5f0f\u5b50\uff0c\u53ea\u66f4\u65b0\u751f\u6210\u5668\u7684\u53c2\u6570\uff0c\u4e0d\u9700\u8981\u66f4\u65b0\u5224\u522b\u5668\u7684\u53c2\u6570</p> <p>\u4ee5\u4e0a\u662fGNA\u7684\u4e00\u4e2astep\uff0c\u4e0d\u65ad\u7684\u91cd\u590d\uff0c\u4ea4\u66ff\u66f4\u65b0\uff0c\u76f4\u5230\\(D(x)\\)\u548c\\(D(G)\\)\u90fd\u662f0.5\uff0c\u6b64\u65f6\u5224\u522b\u5668\u5df2\u7ecf\u65e0\u6cd5\u518d\u533a\u5206 \u6570\u636e\u662f\u6765\u81ea\u771f\u5b9e\u6570\u636e \u8fd8\u662f\u751f\u6210\u5668\u751f\u6210\u7684\u5047\u6837\u672c</p> <p>\u539f\u65874.1\u8bc1\u660e\uff0c\u8fd9\u6837\u7684\u635f\u5931\u51fd\u6570\u662f\u5426\u80fd\u8ba9 G\u548cD \u540c\u65f6\u627e\u5230\u6700\u4f18\u7684\u503c \u6216\u8005 \u6700\u4f18\u7684\u7ed3\u6784\uff1f</p>"},{"location":"learning/4_GAN/#41","title":"4.1 \u8bc1\u660e","text":"<p>\u8003\u8651\u4efb\u610f\u7ed9\u5b9a\u7684\u751f\u6210\u5668G\uff0c\u6700\u4f18\u7684\u5224\u522b\u5668D\u662f\u600e\u4e48\u6837\u7684</p> <p>\u5b9a\u74061\uff0cG\u56fa\u5b9a\uff0c\u6700\u4f18\u7684\u5224\u522b\u5668D\uff1a</p> <p></p> <p>*\u53f7  \u8868\u793a\u6700\u4f18</p> <p>D_G\uff0c\u8868\u793a G \u662f\u56fa\u5b9a\u7684\uff0cD\u662f\u53d8\u5316\u7684</p> <p>x\u670d\u4ece\u771f\u5b9edata\u7684\u6982\u7387\u3001x\u670d\u4ece\u751f\u6210\u5668g\u7684\u6982\u7387</p> <p></p> <p>\u8bc1\u660e\uff0c\u5bf9\u4e8e\u4efb\u610f\u751f\u6210G\uff0c\u5224\u522b\u5668D\u7684\u8bad\u7ec3\u6807\u51c6\uff0c\u5c31\u662f\u8981\u6700\u5927\u5316\u4ef7\u503c\u51fd\u6570V\uff0c\u4ef7\u503c\u51fd\u6570\u4e4b\u524d\u7528\u671f\u671b\u503c\u8868\u793a\u7684\uff0c\u671f\u671b\u53ef\u4ee5\u5199\u6210\u79ef\u5206\u7684\u5f62\u5f0f\uff0c\u7b2c\u4e00\u4e2a\u79ef\u5206 \\(p_{data}(x)D(x)\\)\uff0c\u5bf9\\(x\\)\u8fdb\u884c\u79ef\u5206\uff0c\u7b2c\u4e8c\u4e2a\u79ef\u5206\\(p_zlog(1-Dg)\\)\uff0c\u5bf9\\(z\\)\u8fdb\u884c\u79ef\u5206\uff0c</p> <p></p> <p>\u5c06\u7b2c\u4e8c\u4e2a\u79ef\u5206\uff0c\u6362\u4e00\u4e0b\u79ef\u5206\u7b26\u53f7  z \u2192 x\uff0c\u7136\u540e\u5408\u5e76</p> <p>\uff08\u6709\u4e2a\u95ee\u9898\uff0c\u4e3a\u4ec0\u4e48 \\(\\int_z p_z(z) (1-D(g(z)))dz\\)    \u2192 $\\int_x p_x(x) (1-D(g(x)))dx $   \u8fd9\u91cc \\(p_x(x)\\)\u53d8\u6210 \\(p_g(x)\\)\uff09</p> <p>\u5f53\u5199\u6210\u8fd9\u6837\u4ee5\u540e\uff1a</p> <p></p> <p>\u5bf9\u4e8e\u8fd9\u6837\u4e00\u4e2a\u51fd\u6570\uff0c\u5bf9\u4e8e\u4efb\u610fa\uff0cb\uff0c\u5c5e\u4e8e\u5b9e\u6570\uff0c\u5e76\u4e14 a,b \u4e0d\u7b49\u4e8e0\uff0c\u6b64\u65f6\u5173\u4e8e y \u7684\u51fd\u6570\uff0c\\(alogy+blog(1-y)\\) \u8fd9\u91cc \\(a=p_{data}(x)\\) \u3001 \\(b=p_g(x)\\)  \u5728  \\(\\frac{a}{a+b}\\) \u8fbe\u5230\u6700\u5927\u503c\uff0c\u4e5f\u5c31\u662f \\(\\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}\\) \u8fbe\u5230\u6700\u5927\u503c</p> <p></p> <p>\u6ce8\u610f \u8bad\u7ec3 D\u7684\u76ee\u6807 \u53ef\u4ee5\u89e3\u91ca\u6210 \u5728\u6700\u5927\u5316 P(Y=y|x)\u7684\u5bf9\u6570\u4f3c\u7136</p> <ul> <li>\\(x\\)\u5c31\u662f\u7ed9\u5b9a\u4e00\u4e2a\u8f93\u5165\uff0c\u8f93\u5165\u5230\u5224\u522b\u5668\u4e2d\u7684\u6837\u672c</li> <li>\\(P(Y=y)\\) \\(Y\\)\u8868\u793a\u4e00\u4e2a\u6982\u7387\uff0c\u8868\u793a\\(x\\) \u6765\u81ea\u751f\u6210\u5668\u7684\u6982\u7387\uff0c\u8fd8\u662f\\(data\\)\uff08\u771f\u5b9e\u6570\u636e\uff09\u7684\u6982\u7387</li> </ul> <p>\u516c\u5f0f1 \u53ef\u4ee5\u91cd\u65b0\u5199\u6210 \\(C(G)\\)\uff0c</p> <p>\\(C(G) = \\max_{D}V(G,D)\\)</p> <p>\u5c31\u662f\u628a\u4ef7\u503c\u51fd\u6570 \u91cd\u65b0\u5199\u6210 \u751f\u6210\u5668\u7684\u51fd\u6570\uff0c\u4e5f\u5c31\u662f \\(V(G,D)\\)\u5728\u627e\u5230 \u6700\u4f18\u7684 D \u53d6\u6700\u5927\u503c</p> <p></p> <p>\u91cd\u70b9\u89e3\u91ca\u7b2c\u4e8c\u884c\uff0c\u628a \\(G(z)\\)\u6362\u6210\\(x\\)\uff0c\\(z \\sim p_z\\) \uff0c\u4e5f\u5c31\u662f \\(x \\sim p_g\\)</p> <p>\u4e5f\u5c31\u662f \\(p_z\\) \u53ef\u4ee5\u7528 \\(x\\) \u7684\u5206\u5e03\u8868\u793a</p> <p>\u7136\u540e\u6211\u4eec\u628a\u627e\u5230\u7684 \\(D^*_G(x)\\) \u4ee3\u5165\uff0c\u5f97\u5230\u7b2c\u4e09\u884c\u7684\u4ef7\u503c\u51fd\u6570</p> <p></p> <ul> <li> \u4e0a\u9762\u6211\u770b\u660e\u767d\u4e86</li> </ul> <p>\u7ee7\u7eed\u770b\uff0c\u540e\u9762\u8fd8\u6709\u8bc1\u660e</p> <p></p> <p>\u5f00\u59cb\uff1a</p> <p></p> <p>\u8bad\u7ec3\u6807\u51c6\\(C\\) \u7684\u5168\u5c40\u6700\u5c0f\u503c\uff0c\u4ec5\u4ec5\u5728 \\(p_g = p_{data}\\) \u65f6\uff0c\u8fbe\u5230\uff0c\u5e76\u4e14\u6700\u5c0f\u503c \u662f \\(-log4\\)</p> <p>\u516c\u5f0f4 \u5df2\u7ecf\u5f97\u5230 \\(C(G)\\) \u7684\u8868\u8fbe\u5f0f</p> <p></p> <p>\u63a5\u4e0b\u6765 \u6211\u4eec\u5c31\u7814\u7a76 C(G)\u7684\u6700\u5c0f\u503c\uff0c\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u53d6\u5230\uff0c\u5e76\u4e14\u6700\u5c0f\u503c\u662f\u4ec0\u4e48\u3002\u770b\u8bc1\u660e\uff1a</p> <p></p> <p>\uff081\uff09\u5047\u8bbe \\(p_g=p_{data}\\)\u65f6\uff0c\u4e5f\u5c31\u662f\u751f\u6210\u5206\u5e03\u548c\u771f\u5b9e\u5206\u5e03\u4e00\u6a21\u4e00\u6837\u65f6\uff0c\u6b64\u65f6\u6700\u4f18\u7684 D\u521a\u597d\u7b49\u4e8e \\(\\frac{1}{2}\\)</p> <p>\u770b\u539f\u6587\u7684\u516c\u5f0f(2)</p> <p></p> <p>\uff082\uff09\u56e0\u6b64\uff0c\u6211\u4eec\u628a\u516c\u5f0f(4)\u6700\u540e\u5f97\u5230\u7684\u5f0f\u5b50\uff0c\u5168\u90e8\u6362\u6210 \\(\\frac{1}{2}\\)</p> <p>\u6b64\u65f6\uff1a</p> <p></p> <p></p> <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u5f53\u6211\u4eec\u5047\u8bbe \\(p_g = p_{data}\\) \u65f6\uff0c\u5f97\u5230 \\(C(G)=-log4\\)\uff0c</p> <p>\u5f97\u5230\u8fd9\u4e9b\u4e1c\u897f\u4ee5\u540e\uff0c\u540e\u9762\u600e\u4e48\u505a\u5462\uff1f</p> <p>\u6211\u4eec\u628a\u516c\u5f0f(4)\uff0c\u51cf\u53bb\u4e00\u4e2a \\(-log4\\)\uff1a (ps\uff1a\u6700\u540e\u53c8\u628a \\(-log4\\) \u52a0\u56de\u6765\u4e86)</p> <p>\\(\\mathbb{E}_{\\boldsymbol{x}\\sim p_\\mathrm{data}}\\left[\\log\\frac{p_\\mathrm{data}(\\boldsymbol{x})}{P_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}\\right]+\\mathbb{E}_{\\boldsymbol{x}\\sim p_g}\\left[\\log\\frac{p_g(\\boldsymbol{x})}{p_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}\\right] -\uff08-log4\uff09\\)</p> <p></p> <p>\u5f97\u5230\uff1a</p> <p>\\(\\mathbb{E}_{\\boldsymbol{x}\\sim p_\\mathrm{data}}\\left[\\log\\frac{p_\\mathrm{data}(\\boldsymbol{x})}{P_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}\\right]+\\mathbb{E}_{\\boldsymbol{x}\\sim p_g}\\left[\\log\\frac{p_g(\\boldsymbol{x})}{p_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}\\right] + log4\\)</p> <p>= \\(\\mathbb{E}_{\\boldsymbol{x}\\sim p_\\mathrm{data}}\\left[\\log\\frac{p_\\mathrm{data}(\\boldsymbol{x})}{P_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}\\right]+\\mathbb{E}_{\\boldsymbol{x}\\sim p_g}\\left[\\log\\frac{p_g(\\boldsymbol{x})}{p_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}\\right] + log2 + log2\\)</p> <p>=  \\(\\mathbb{E}_{\\boldsymbol{x}\\sim p_\\mathrm{data}}\\left[\\log\\frac{2 p_\\mathrm{data}(\\boldsymbol{x})}{P_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}\\right]+\\mathbb{E}_{\\boldsymbol{x}\\sim p_g}\\left[\\log\\frac{2 p_g(\\boldsymbol{x})}{p_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}\\right]\\)</p> <p>= \\(\\mathbb{E}_{\\boldsymbol{x}\\sim p_\\mathrm{data}}\\left[\\log\\frac{ p_\\mathrm{data}(\\boldsymbol{x})}{\\frac{P_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}{2}}\\right]+\\mathbb{E}_{\\boldsymbol{x}\\sim p_g}\\left[\\log\\frac{p_g(\\boldsymbol{x})}{\\frac{p_\\mathrm{data}(\\boldsymbol{x})+p_g(\\boldsymbol{x})}{2}}\\right]\\)</p> <p>\u501f\u52a9 KL\u6563\u5ea6 \u516c\u5f0f\uff1a</p> <p></p> <p>\u5206\u5e03P\u548c\u5206\u5e03Q\u7684KL\u6563\u5ea6\u516c\u5f0f \u5c31\u662f \\(log(\\frac{P(x)}{Q(x)})\\) \u5173\u4e8eP(x) \u7684\u671f\u671b</p> <p>\\(= KL(p_{data}(x) || \\frac{p_{data}(x)+p_g(x)}{2}) +  KL(p_{g}(x) || \\frac{p_{data}(x)+p_g(x)}{2})\\)</p> <p>\u5173\u4e8e\u516c\u5f0f\uff085\uff09\u7684\u5f97\u5230\uff0c\u662f\u4e3a\u4e86C(G)\uff0c\u6211\u4eec\u6700\u5f00\u59cb\\(-(-log4)\uff0c\\)\u4e3a\u4e86\u4fdd\u8bc1\u516c\u5f0f\u603b\u4f53\u4e0d\u53d8\uff0c\u6240\u4ee5\u6700\u540e\u5728 \\(+(-log4)\\) \uff1a</p> <p>\u5f97\u5230\u5b8c\u6574\u7684  \u516c\u5f0f(5)</p> <p></p> <ul> <li> \u4ee5\u4e0a \u516c\u5f0f(5)\u7684\u8bc1\u660e\uff0c\u770b\u61c2\u4e86</li> </ul> <p>\u89e3\u8bfb\u516c\u5f0f5\uff0c\u9996\u5148 \\(KL\u6563\u6b65\u5927\u4e8e0\\)\uff0c\u6052\u6210\u7acb\uff0c\u6240\u4ee5\u6211\u4eec\u770b\u51fa\u5316\u7b80\u51fa\u6765\u7684\u5f0f\u5b50\uff0c\u6700\u5c0f\u503c\u662f \\(-log4\\)</p> <p>\u6700\u5c0f\u503c\u4f55\u65f6\u53d6\u5230\uff0c\u5c31\u662f\\(KL\u6563\u5ea6=0\\) \u4e5f\u5c31\u662f</p> <p>\u2460 \\(p_{data}(x) = \\frac{p_{data}(x)+p_g(x)}{2}\\)</p> <p>\u2461  \\(p_{g}(x) = \\frac{p_{data}(x)+p_g(x)}{2}\\)</p> <p>\u540c\u65f6\u6210\u7acb\uff0c\u4e0d\u5c31\u662f \\(p_{data}=p_{g}\\)</p> <p>\u6211\u4eec \u7528\u8a79\u68ee-\u9999\u519c\u6563\u5ea6\uff0c\u7ee7\u7eed\u5316\u7b80\uff0c\u5f97\u5230\u516c\u5f0f6</p> <p></p> <p>JSD(P||Q)=\\(\u4e8c\u5206\u4e4b\u4e00\u7684\u5206\u5e03M\u548c\u5206\u5e03P\u7684KL\u6563\u5ea6+\\)\\(\u4e8c\u5206\u4e4b\u4e00\u7684\u5206\u5e03M\u4e0e\u5206\u5e03Q\u7684KL\u6563\u5ea6\\)</p> <p>\u5176\u4e2d\\(M=\u4e8c\u5206\u4e4b\u4e00\u7684\u5206\u5e03P\u52a0\u5206\u5e03Q\\)</p> <p>\u57fa\u4e8e \u8a79\u68ee\u9999\u519c\u6563\u5ea6\u7684\u516c\u5f0f\uff0c\u628a\u516c\u5f0f(5)\u5316\u7b80\u6210 \u516c\u5f0f(6)</p> <p></p> <p>\u540c\u7406\uff0c\\(JSD\\)\u4e5f\u662f\u4e00\u4e2a \u5927\u4e8e\u7b49\u4e8e0 \u7684\u4e00\u4e2a\u503c\uff0c\u5e76\u4e14\u4ec5\u5728 \\(p_{data}=p_g\\)\u65f6\u53d60</p> <ul> <li> \u4ee5\u4e0a \u516c\u5f0f(6)\u7684\u8bc1\u660e\uff0c\u61c2\u4e86</li> </ul> <p>\u4ee5\u4e0a\u8bf4\u660e\uff0c\\(p_{data}=p_g\\)\uff0c\u4e5f\u5c31\u662f\u751f\u6210\u5668\u751f\u6210\u7684\u5206\u5e03\uff0c\u521a\u597d\u7b49\u4e8e \u771f\u5b9e\u6570\u636e\u7684\u5206\u5e03\u65f6\uff0c\u6211\u4eec C(G) \u4f1a\u53d6\u6700\u5c0f\u503c \\(-log4\\)\uff0c\u4e5f\u5c31\u662f \\(G\\)\u7684\u4f18\u5316\u8fbe\u5230\u4e86\u6700\u4f18</p> <p>\u672c\u6587\u5b9e\u9a8c\u624b\u5199\u6570\u5b57\u8bc6\u522b\uff0c\u901a\u8fc7GAN\u7f51\u7edc\uff0c\u624b\u5199\u7167\u7247\u7684\u5206\u5e03\uff0c\u968f\u673a\u751f\u6210\u9ad8\u65af\u53d8\u91cf\u9001\u5165\u5230\u751f\u6210\u5668\u4e2d\uff0c\u751f\u6210\u5668\u751f\u6210\u4e00\u5f20\u624b\u5199\u6570\u5b57\u7684\u7167\u7247\uff0c\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u5b66\u4e60\u65b9\u6cd5</p> <p></p>"},{"location":"learning/4_GAN/#_2","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u5168\u90e8\u4ee3\u7801\uff1a</p> Python<pre><code>\"\"\" \u57fa\u4e8eMNIST \u5b9e\u73b0\u5bf9\u6297\u751f\u6210\u7f51\u7edc (GAN) \"\"\"\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport numpy as np\n\nimage_size = [1, 28, 28]\nlatent_dim = 96\nbatch_size = 64\nuse_gpu = torch.cuda.is_available()\n\nclass Generator(nn.Module):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, 128),\n            torch.nn.BatchNorm1d(128),\n            torch.nn.GELU(),\n\n            nn.Linear(128, 256),\n            torch.nn.BatchNorm1d(256),\n            torch.nn.GELU(),\n            nn.Linear(256, 512),\n            torch.nn.BatchNorm1d(512),\n            torch.nn.GELU(),\n            nn.Linear(512, 1024),\n            torch.nn.BatchNorm1d(1024),\n            torch.nn.GELU(),\n            nn.Linear(1024, np.prod(image_size, dtype=np.int32)),\n            #  nn.Tanh(),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, z):\n        # shape of z: [batchsize, latent_dim]\n\n        output = self.model(z)\n        image = output.reshape(z.shape[0], *image_size)\n\n        return image\n\n\nclass Discriminator(nn.Module):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.model = nn.Sequential(\n            nn.Linear(np.prod(image_size, dtype=np.int32), 512),\n            torch.nn.GELU(),\n            nn.Linear(512, 256),\n            torch.nn.GELU(),\n            nn.Linear(256, 128),\n            torch.nn.GELU(),\n            nn.Linear(128, 64),\n            torch.nn.GELU(),\n            nn.Linear(64, 32),\n            torch.nn.GELU(),\n            nn.Linear(32, 1),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, image):\n        # shape of image: [batchsize, 1, 28, 28]\n\n        prob = self.model(image.reshape(image.shape[0], -1))\n\n        return prob\n\n# Training\ndataset = torchvision.datasets.MNIST(\"mnist_data\", train=True, download=True,\n                                     transform=torchvision.transforms.Compose(\n                                         [\n                                             torchvision.transforms.Resize(28),\n                                             torchvision.transforms.ToTensor(),\n                                             #  torchvision.transforms.Normalize([0.5], [0.5]),\n                                         ]\n                                                                             )\n                                     )\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n\ngenerator = Generator()\ndiscriminator = Discriminator()\n\n\ng_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)\nd_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)\n\nloss_fn = nn.BCELoss()\nlabels_one = torch.ones(batch_size, 1)\nlabels_zero = torch.zeros(batch_size, 1)\n\nif use_gpu:\n    print(\"use gpu for training\")\n    generator = generator.cuda()\n    discriminator = discriminator.cuda()\n    loss_fn = loss_fn.cuda()\n    labels_one = labels_one.to(\"cuda\")\n    labels_zero = labels_zero.to(\"cuda\")\n\nnum_epoch = 200\nfor epoch in range(num_epoch):\n    for i, mini_batch in enumerate(dataloader):\n        gt_images, _ = mini_batch\n\n\n        z = torch.randn(batch_size, latent_dim)\n\n        if use_gpu:\n            gt_images = gt_images.to(\"cuda\")\n            z = z.to(\"cuda\")\n\n        pred_images = generator(z)\n        g_optimizer.zero_grad()\n\n        recons_loss = torch.abs(pred_images-gt_images).mean()\n\n        g_loss = recons_loss*0.05 + loss_fn(discriminator(pred_images), labels_one)\n\n        g_loss.backward()\n        g_optimizer.step()\n\n        d_optimizer.zero_grad()\n\n        real_loss = loss_fn(discriminator(gt_images), labels_one)\n        fake_loss = loss_fn(discriminator(pred_images.detach()), labels_zero)\n        d_loss = (real_loss + fake_loss)\n\n        # \u89c2\u5bdfreal_loss\u4e0efake_loss\uff0c\u540c\u65f6\u4e0b\u964d\u540c\u65f6\u8fbe\u5230\u6700\u5c0f\u503c\uff0c\u5e76\u4e14\u5dee\u4e0d\u591a\u5927\uff0c\u8bf4\u660eD\u5df2\u7ecf\u7a33\u5b9a\u4e86\n\n        d_loss.backward()\n        d_optimizer.step()\n\n        if i % 50 == 0:\n            print(f\"step:{len(dataloader)*epoch+i}, recons_loss:{recons_loss.item()}, g_loss:{g_loss.item()}, d_loss:{d_loss.item()}, real_loss:{real_loss.item()}, fake_loss:{fake_loss.item()}\")\n\n        if i % 400 == 0:\n            image = pred_images[:16].data\n            torchvision.utils.save_image(image, f\"image_{len(dataloader)*epoch+i}.png\", nrow=4)\n</code></pre> <p>\u4e0a\u9762\u7684\u4ee3\u7801\u53ef\u4ee5\u76f4\u63a5\u8fd0\u884c  \\(\\uparrow\\)</p> <p>\u4e0b\u9762\u662f\u8bb2\u89e3\uff0c\u6709\u4e9b\u8bb8\u51fa\u5165\uff0c\u4f46\u6574\u4f53\u601d\u60f3\u662f\u4e00\u81f4\u7684 \\(\\downarrow\\)</p> <p>\u67e5\u770b\u8f93\u51fa\u7ed3\u679c\uff0c\u53ef\u4ee5\u770b\u5230\u751f\u6210\u7684\u56fe\u7247\u9010\u6e10\u6e05\u6670\uff1a</p> <p></p> <p>\u9996\u5148\u4ee3\u7801\u7684\u5927\u6846\u67b6\uff0c\u9996\u5148\u751f\u6210\u751f\u6210\u5668\u7684\u7c7b\uff0c\u7136\u540e\u751f\u6210\u5224\u522b\u5668\u7684\u7c7b\uff0c\u7136\u540e\u8fdb\u884c\u8bad\u7ec3\uff1a</p> Python<pre><code>'''\u57fa\u4e8eMINIST\u5b9e\u73b0\u5bf9\u6297\u751f\u6210\u7f51\u7edc\uff08GAN\uff09'''\n\nimport torch\nimport torch.nn as nn\n\nclass Generator(nn.Module):\n    pass\nclass Decrimination(nn.Module):\n    pass\n# training\n</code></pre> <p>\u6211\u4eec\u4e3e\u4f8b\u5b50\uff0c\u4ee5\u751f\u6210\u624b\u5199\u6570\u5b57\u7167\u7247\u4e3a\u4f8b\uff1a</p> <p>\u9996\u5148 \u600e\u4e48\u5bfc\u5165 minist\u6570\u636e\u96c6\uff0c\u8c37\u6b4c\u641c\u7d22\uff1a torch vision mnist \u7b2c\u4e8c\u4e2a\uff0cMNIST</p> <p></p> <p>\u770b\u5230\u5b98\u65b9api\uff1a</p> <p></p> <p>\u9996\u5148\u9700\u8981\u7684\u53c2\u6570\uff1a</p> <ul> <li>root\uff1a\u6570\u636e\u5b58\u50a8\u8def\u5f84</li> <li>train\uff1a\u662f\u5426train\u6a21\u5f0f</li> <li>dowload\uff1a\u662f\u5426\u4e0b\u8f7d</li> <li>transform\uff1aPIL image\u683c\u5f0f\u7684\u8f6c\u6362\u6210 \u6d6e\u70b9\u578b\u7684</li> </ul> <p>\u901a\u8fc7\u8fd9\u6837\u7684class \u5f97\u5230MINST\u6570\u636e\u96c6</p> <p>\u9996\u5148\uff0c\u67e5\u770bminist\u6570\u636e\u96c6\u957f\u4ec0\u4e48\u6837\uff1a</p> Python<pre><code>import torchvision\ndataset = torchvision.datasets.MNIST(\"minist_data\",train=True,download=True)\nprint(len(dataset)) # 60000\n</code></pre> <p>\u628a\u4e0b\u8f7d\u7684minist\u6570\u636e\u96c6\u5b58\u5230 <code>minist_data</code> \u6587\u4ef6\u5939\u4e0b\uff0c\u91c7\u7528\u8bad\u7ec3\u6a21\u5f0f\uff0c\u672c\u5730\u6ca1\u6709\u6240\u4ee5\u8bbe\u7f6e\u4e3aTrue</p> <p>\u4e00\u5171\u67096000\u4e2a\u6837\u672c</p> <p>\u770b\u4e00\u4e0b\u6bcf\u4e2a\u6837\u672c\u957f\u4ec0\u4e48\u6837\uff08\u6253\u5370\u524d5\u4e2a\uff09\uff1a</p> Python<pre><code>import torchvision\ndataset = torchvision.datasets.MNIST(\"minist_data\",train=True,download=True)\nfor i in range(5):\n    print(dataset[i])\n# (&lt;PIL.Image.Image image mode=L size=28x28 at 0x1030AD100&gt;, 5)\n# (&lt;PIL.Image.Image image mode=L size=28x28 at 0x1030AD100&gt;, 0)\n# (&lt;PIL.Image.Image image mode=L size=28x28 at 0x1030AD100&gt;, 4)\n# (&lt;PIL.Image.Image image mode=L size=28x28 at 0x1030AD100&gt;, 1)\n# (&lt;PIL.Image.Image image mode=L size=28x28 at 0x1030AD100&gt;, 9)\n</code></pre> <p>\u524d5\u4e2a\u6bcf\u4e00\u4e2a\u90fd\u662fimage\u7684\u5bf9\u8c61\uff0c\u5927\u5c0f\u662f28\u00d728\u7684\uff0c\u524d\u9762\u662f \\(x\\) \u540e\u9762\u662f \u6807\u7b7e\uff0c\u6570\u636e\u683c\u5f0f\u662f PIL image</p> <p>\u5982\u679c\u6211\u4eec\u6253\u5370shape\u7684\u8bdd\uff0c\u4f1a\u62a5\u9519</p> Python<pre><code>import torchvision\ndataset = torchvision.datasets.MNIST(\"minist_data\",train=True,download=True)\nfor i in range(5):\n    print(dataset[i][0].shape)\n# AttributeError: 'Image' object has no attribute 'shape'\n</code></pre> <p>\u8fd9\u65f6\uff0c\u9700\u8981\u8c03\u7528transform  </p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u4f8b\u5b50\uff1a</p> <p></p> <p>\u4f7f\u7528transforms.Compose()\u4f20\u5165</p> <p>\u6211\u4eec\u53ea\u9700\u8981\u8c03\u6574\u4e00\u4e0b\u5927\u5c0f\uff0c\u4f20\u516528</p> <p></p> <p></p> <p>\u63a5\u7740\uff0c\u628aPIL image\u683c\u5f0f\u8f6c\u5316\u6210 \u6d6e\u70b9\u6570 \u683c\u5f0f</p> <p></p> <p>ToTensor API</p> <p></p> <p>\u5c06PIL image\u683c\u5f0f \u6216\u8005 numpy \u6570\u7ec4 \u8f6c\u6362\u6210tensor\u683c\u5f0f\uff0c\u5e76\u4e14\u53ef\u4ee5\u8f6c\u5316\u5230 0~1\u4e4b\u95f4\u7684\u6d6e\u70b9\u6570</p> <p>\u518d\u6b21\u6253\u5370 shape\uff1a</p> Python<pre><code>import torchvision\ndataset = torchvision.datasets.MNIST(\"minist_data\",\n                                     train=True,\n                                     download=True,\n                                     transform=torchvision.transforms.Compose(\n                                         [torchvision.transforms.Resize(28),\n                                         torchvision.transforms.ToTensor()]\n                                     ))\nfor i in range(5):\n    print(dataset[i][0].shape)\n# torch.Size([1, 28, 28])\n# torch.Size([1, 28, 28])\n# torch.Size([1, 28, 28])\n# torch.Size([1, 28, 28])\n# torch.Size([1, 28, 28])\n</code></pre> <p>\u6bcf\u4e2a\u6837\u672c \u90fd\u662f 1\u00d728\u00d728\uff1b1\u8868\u793a\u901a\u9053\u6570\uff0cminist\u901a\u9053\u6570=1\uff1b\u4ee5\u4e0a\u770b\u5230\u4e86\u6837\u672c\u957f\u4ec0\u4e48\u6837\uff0c\u53ef\u4ee5\u5e2e\u52a9Generator\u751f\u6210\u7167\u7247</p> <p>\u63a5\u4e0b\u6765\uff0c\u7ee7\u7eed\u770bGenerator\u51fd\u6570\uff0c\u5148\u5199init\uff0c\u518d\u5199forward\uff0cinit\u5b9a\u4e49\u6a21\u5757\uff0cforward\u5c06init\u7684\u6a21\u5757\u4e32\u8054\u8d77\u6765\uff0c\u751f\u6210\u7167\u7247</p> Python<pre><code>class Generator(nn.Module):\n    def __init__(self):\n        pass\n    def forward(self):\n        pass\n</code></pre> <p>\u5b9e\u4f8b\u5316\u7236\u7c7b\uff0c\u7ee7\u627f\u81eann.Module\uff0c\u7ee7\u627f\u7236\u7c7b\u7684\u6784\u9020\u65b9\u6cd5</p> Python<pre><code>super(Generator,self).__init__()\n</code></pre> <p>forward\u63a5\u6536z\uff0c\u9ad8\u65af\u968f\u673a\u53d8\u91cf\uff0cz\u7684shape=batchsize\u00d71\u00d728\u00d728,1\u662fchannel\u3001H\u3001W=28\u300128</p> Python<pre><code>    def forward(self,z):\n        # shape of z:batchsize,1,28,28\n</code></pre> <p>init\u51fd\u6570\uff0c\u4f7f\u7528nn.Sequential()\uff0c\u5b9a\u4e49\u7f51\u7edc\u5c42\uff0c\u5b9a\u4e49\u7b2c\u4e00\u4e2a\u7ebf\u6027\u5c42nn.Linear(in_dim,64)\uff0c64\u662f\u968f\u4fbf\u5b9a\u4e49\u7684\uff0cin_dim\u662f\u7ed9\u7684\uff0c\u7ebf\u6027\u5c42\u540e\u9762\u63a5\u7740\u6fc0\u6d3b\u5c42nn.ReLU()\uff0c\u67e5\u770b\u5b98\u7f51api\uff0c\u9ed8\u8ba4inplace=False\uff0c\u6211\u4eec\u6539\u6210True\uff0c\u7136\u540e\u91cd\u590d\u51e0\u904d\uff0c\u7ebf\u6027\u5c42\u3001\u6fc0\u6d3b\u5c42...</p> <p></p> Python<pre><code>image_size = [1,28,28]\n\nclass Generator(nn.Module):\n    def __init__(self,in_dim):\n        super(Generator,self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(in_dim,64),\n            nn.ReLU(inplace=True),\n            nn.Linear(64,128),\n            nn.ReLU(inplace=True),\n            nn.Linear(128,256),\n            nn.ReLU(inplace=True),   \n            nn.Linear(256,512),\n            nn.ReLU(inplace=True),   \n            nn.Linear(512,1024),\n            nn.ReLU(inplace=True), \n            nn.Linear(1024,torch.prod(image_size,dtype=torch.int32)),\n            nn.Tanh(),                                                        \n        )\n</code></pre> <p>\u5148\u4e0d\u65ad\u7684\u5347\u7ef4\u5347\u7ef4\u5347\u7ef4\uff0c\u6700\u540e\u964d\u7ef4 1024\u2192 torch.prod(image_size)\uff0c\u6700\u540e\u4f7f\u7528\u6fc0\u6d3b\u51fd\u6570Tanh\uff0c\u5c06\u5143\u7d20\u53d8\u6210-1\u52301</p> <p></p> <p>torch.prod \u8fd4\u56de\u8f93\u5165\u5f20\u91cf \u5143\u7d20\u7684\u8fde\u4e58\u79ef</p> <p>\u7136\u540e\u770bforward\u51fd\u6570\uff0c\u5c06z\u4f20\u5165\u5230init\u5b9a\u4e49\u7684self.model()</p> Python<pre><code>    def forward(self,z):\n        # shape of z:batchsize,1*28*28\n        output = self.model(z)\n</code></pre> <p>\u5c06\u8f93\u51fa\u7684output\u8f6c\u6362\u4e3a\u56fe\u7247\u683c\u5f0f\uff0c\u8c03\u7528reshape\uff0c\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4ecd\u7136\u7528\uff0cz.shpe[0]\uff0c\u540e\u9762\u7684\u7ef4\u5ea6\u5c31\u7528image_size\uff0cimage_size\u52a0\u661f\u53f7\uff0c\u5c31\u80fd\u628a\u5217\u8868\u4f20\u8fdb\u53bb</p> Python<pre><code>   def forward(self,z):\n        # shape of z:batchsize,1*28*28\n        output = self.model(z)\n        image = output.reshape(z.shape[0],*image_size)\n        pass\n</code></pre> <p>\u5c06image\u8fd4\u56de\uff0c\u4ee5\u4e0a\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u751f\u6210\u5668\u3002</p> Python<pre><code>class Generator(nn.Module):\n    def __init__(self,in_dim):\n        super(Generator,self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(in_dim,64),\n            nn.ReLU(inplace=True),\n            nn.Linear(64,128),\n            nn.ReLU(inplace=True),\n            nn.Linear(128,256),\n            nn.ReLU(inplace=True),   \n            nn.Linear(256,512),\n            nn.ReLU(inplace=True),   \n            nn.Linear(512,1024),\n            nn.ReLU(inplace=True), \n            nn.Linear(1024,torch.prod(image_size,dtype=torch.int32)),\n            nn.Tanh(),                                                        \n        )\n\n    def forward(self,z):\n        # shape of z:batchsize,1*28*28\n        output = self.model(z)\n        image = output.reshape(z.shape[0],*image_size)\n        return image\n</code></pre> <p>\u63a5\u4e0b\u6765\u5b9e\u73b0\u5224\u522b\u5668</p> <p>\u5224\u522b\u5668\u63a5\u6536\u7684\u662f\u4e00\u5f20\u56fe\u7247\u4f5c\u4e3a\u8f93\u5165\uff0c\u751f\u6210\u5668\u63a5\u6536\u7684\u662f\u968f\u673a\u566a\u58f0\u4f5c\u4e3a\u8f93\u5165</p> Python<pre><code>class Decrimination(nn.Module):\n    def __init__(self):\n        super(Decrimination,self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(in_dim,1024),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024,512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512,256),\n            nn.ReLU(inplace=True),   \n            nn.Linear(256,128),\n            nn.ReLU(inplace=True),   \n            nn.Linear(128,1),\n            nn.Sigmoid(),            \n        )\n        pass\n    def forward(self):\n        pass\n</code></pre> <p>\u5224\u522b\u5668\u7684init\u540c\u6837\u5199\u4e00\u4e2amodel\uff0c\u5224\u522b\u5668\u7684nn.Linear\u7684\u7ef4\u5ea6\u53ef\u4ee5\u53cd\u8fc7\u6765\u5199\uff0c\u4e0a\u9762\u662f\u4e00\u6b65\u6b65\u7684\u589e\u5927\u7ef4\u5ea6\uff0c\u5bf9\u4e8e\u5224\u522b\u5668\u800c\u8a00\uff0c\u4e00\u5f00\u59cb\u53ef\u4ee5\u662f\u5927\u7ef4\u5ea6\uff0c\u7136\u540e\u6162\u6162\u7684\u964d\u7ef4\u5ea6\uff0c\u6700\u540e\u8f93\u51fa\u9884\u6d4b\u7684\u6807\u91cf\uff0c\u6700\u540e\u5c06128\u6620\u5c04\u52301\uff0c\u6700\u540e\u8f93\u51fa\u6982\u7387\uff0c\u5c31\u4e0d\u662fTanh\uff0c\u800c\u662fSigmoid</p> <p>\u5224\u522b\u5668\u63a5\u6536\u4e00\u5f20\u7167\u7247\u4f5c\u4e3a\u8f93\u5165\uff0c\u8f93\u51fa\u662fSigmoid\u51fd\u6570 \u8f93\u51fa\u7684\u6982\u7387\u503c</p> <p>forward\u51fd\u6570 \u63a5\u6536\u7684image\u683c\u5f0f batchsize\u00d71\u00d728\u00d728\uff0c\u5bf9image\u8fdb\u884creshape\uff0creshape\u7684\u7b2c\u4e00\u7ef4\u662fimage.shape[0]\uff0cCHW\u7edf\u4e00\u653e\u5230\u6700\u540e\u4e00\u7ef4</p> Python<pre><code>prob = self.model(image.reshape(image.shape[0],-1))\n</code></pre> <p>\u4ee5\u4e0a\u5f97\u5230\u4e86\u6982\u7387prob\uff0c\u6700\u540e\u8fd4\u56de\u5373\u53ef\uff0c\u4ee5\u4e0a\u5b9e\u73b0\u4e86\u5224\u522b\u5668\uff08in_dim \u90a3\u91cc\u6709\u9519\u8bef\uff09</p> Python<pre><code>class Decrimination(nn.Module):\n    def __init__(self):\n        super(Decrimination,self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(in_dim,1024),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024,512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512,256),\n            nn.ReLU(inplace=True),   \n            nn.Linear(256,128),\n            nn.ReLU(inplace=True),   \n            nn.Linear(128,1),\n            nn.Sigmoid(),            \n        )    \n    def forward(self,image):\n        # shape of image:[batchsize,1,28,28]\n        prob = self.model(image.reshape(image.shape[0],-1))\n        return prob\n</code></pre> <p>\u5224\u522b\u5668\u4ee5\u56fe\u7247\u4f5c\u4e3a\u8f93\u5165\uff0c\u8f93\u51fa\u6982\u7387</p> <p>\u63a5\u4e0b\u6765\u8fdb\u884c\u8bad\u7ec3\u90e8\u5206\uff0c\u7b2c\u4e00\u90e8\u5206\uff0c\u6784\u9020\u6570\u636e\u96c6\uff0cdataset\u5df2\u7ecf\u5199\u597d\u4e86\uff0c\u63a5\u4e0b\u6765\u9001\u5165\u5230dataloader\u4e2d\uff0c\u5fd8\u8bb0\u7528\u6cd5\u5c31\u67e5api</p> <p></p> <p>\u770b\u63a5\u6536\u7684\u8f93\u5165</p> <p></p> <ul> <li>dataset</li> <li>batch_size</li> <li>shuffle</li> </ul> <p>dataloader\u7684\u4f5c\u7528\u5c31\u662f\u628adataset\u7684\u6570\u636e\u53d8\u6210\u4e00\u4e2a\u4e2abatch\uff0c\u540e\u9762\u8fdb\u884c\u6279\u8bad\u7ec3</p> Python<pre><code>from torch.utils.data import DataLoader\ndataloader = DataLoader(dataset,batch_size=32,shuffle=True)\n</code></pre> <p>\u63a5\u4e0b\u6765\u5f00\u59cb\u4f18\u5316\u5668\uff0c\u9700\u8981\u4e24\u4e2a\u4f18\u5316\u5668\uff0c\u5bf9\u751f\u6210\u5668\u7684\u53c2\u6570\u8fdb\u884c\u4f18\u5316\u548c\u5bf9\u5224\u522b\u5668\u7684\u53c2\u6570\u8fdb\u884c\u4f18\u5316</p> <p></p> <p>\u751f\u6210\u5668\u7684\u4f18\u5316\u5668Adam\uff0c\u67e5\u770bAdam\u9700\u8981\u7684\u53c2\u6570\uff1a</p> <p></p> <ul> <li>params\uff1a\u7b2c\u4e00\u4e2a\u662f\u53ef\u8fed\u4ee3\u7684\u8bad\u7ec3\u53c2\u6570\uff0c\u5c31\u662f\u628a\u6a21\u578b\u7684parameters\u8c03\u7528\u4e00\u4e0b\u5c31\u53ef\u4ee5\u4e86\uff0c\u5f97\u5230\u53ef\u8fed\u4ee3\u7684\u8bad\u7ec3\u53c2\u6570</li> </ul> Python<pre><code>g_optimizer = torch.optim.Adam(params,lr=0.0001)\n</code></pre> <p>\u56e0\u6b64 \u6211\u4eec\u9700\u8981\u5b9e\u4f8b\u5316Generator,\u4f20\u5165params</p> <p>\u7b2c\u4e00\u4e2a\u7ebf\u6027\u5c42\u4fee\u6539\u4e00\u4e0b\uff0c\u5c11\u4f20\u4e2a\u53c2\u6570\uff1a</p> Python<pre><code>class Generator(nn.Module):\n    def __init__(self):\n        super(Generator,self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(torch.prod(image_size,dtype=torch.int32),64),\n</code></pre> <p>\u63a5\u4e0b\u6765\u5b9e\u4f8b\u5316\u4e00\u4e2aGenerator</p> Python<pre><code>generator = Generator()\n</code></pre> <p>\u7136\u540e\uff0cAdam\u4f18\u5316\u5668\u7684\u53c2\u6570\uff0c\u5c31\u662fgenerator.parameters()\uff0c\u53ea\u5bf9\u751f\u6210\u5668\u7684\u53c2\u6570\u8fdb\u884c\u4f18\u5316</p> Python<pre><code>g_optimizer = torch.optim.Adam(generator.parameters(),lr=0.0001)\n</code></pre> <p>\u540c\u6837\u5b9e\u4f8b\u5316 \u5224\u522b\u5668\uff0c\u540c\u65f6\u4f18\u5316\u5224\u522b\u5668\u7684\u53c2\u6570</p> Python<pre><code>generator = Generator()\ndiscriminator = Decriminator()\n\ng_optimizer = torch.optim.Adam(generator.parameters(),lr=0.0001)\nd_optimizer = torch.optim.Adam(discriminator.parameters(),lr=0.0001)\n</code></pre> <p>\u751f\u6210\u5668\u53c2\u6570 \u548c \u5224\u522b\u5668\u53c2\u6570 \u5b8c\u5168\u9694\u79bb\uff0c\u4f18\u5316\u4e5f\u5206\u522b\u4f18\u5316</p> <p>\u63a5\u4e0b\u6765 \u5b9a\u4e49loss_fn\uff0c\u903b\u8f91\u56de\u5f52\uff0c\u5224\u65ad\u7167\u7247\u6765\u81ea\u771f\u5b9e\u7684 \u8fd8\u662f \u5047\u7684\uff0closs function \u662fBCELOSS \u4e8c\u6b21\u7684\u4ea4\u53c9\u71b5</p> <p></p> <p>BCE\u63a5\u6536\u7684\u53c2\u6570\uff1a</p> <p></p> <ul> <li>input\u53ef\u4ee5\u662f\u4efb\u610f\u7684\u7ef4\u5ea6</li> <li>output\u4e5f\u662f\u4efb\u610f\u7684\u7ef4\u5ea6\uff0coutput\u9ed8\u8ba4\u60c5\u51b5\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u5982\u679c\u628areduction\u8bbe\u7f6e\u4e3a\"none\"\u7684\u8bdd\uff0c\u5f62\u72b6\u5c31\u4f1a\u548c\u8f93\u5165\u4e00\u6837</li> <li>target\u4e5f\u662f\u4efb\u610f\u7684\u7ef4\u5ea6</li> <li>\u4e0b\u9762\u7ed9\u51fa\u4f8b\u5b50</li> </ul> <p>\u5b9e\u4f8b\u5316\u4e00\u4e2aloss function</p> <p>input\u662f\u4e00\u4e2a\u957f\u5ea6\u4e3a3\u7684\u5411\u91cf</p> <p>target\u4e5f\u662f\u4e00\u4e2a\u957f\u5ea6\u4e3a3\u7684\u5411\u91cf</p> <p>\u7136\u540e\u8ddf\u4e00\u4e2aloss\u8ba1\u7b97 \u5f97\u5230\u4e00\u4e2a\u6807\u91cf</p> <p>\u8c03\u7528\u662f\u5f88\u7b80\u5355\u7684\uff0c\u5c31\u8c03\u7528\u4e00\u4e2ann.BCELoss()\u5373\u53ef</p> <ul> <li>BCELoss\u7684\u516c\u5f0f</li> </ul> <p></p> <p>\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u91cc \\(x_n=1\\)  \u6216\u8005 \\(x_n=0\\) \\(log\\) \u4e0d\u4f1a\u5d29\u6e83\uff0c\u56e0\u4e3apytorch\u5185\u90e8\u4fdd\u8bc1\u4e86\u6570\u503c\u7a33\u5b9a\u6027</p> <p></p> <p>\u6700\u540e\u4e00\u6bb5\uff0c\u5bf9loss function\u8fdb\u884c\u4e86\u622a\u65ad\uff0c\u622a\u65ad\u5230-100\u4e3a\u6b62\uff0c\u907f\u514d\u4e86\u8d1f\u65e0\u7a77\u5927 \u5d29\u6e83\u7684\u95ee\u9898</p> Python<pre><code>loss_fn = nn.BCELoss()\n</code></pre> <p>\u4ee5\u4e0a\u5b8c\u6210\u4e86\u6240\u6709\u5b9a\u4e49\u7684\u90e8\u5206\uff1a</p> Python<pre><code># Training\n\ndataset = torchvision.datasets.MNIST(\"minist_data\",\n                                     train=True,\n                                     download=True,\n                                     transform=torchvision.transforms.Compose(\n                                         [torchvision.transforms.Resize(28),\n                                         torchvision.transforms.ToTensor()]\n                                     ))\n\ndataloader = DataLoader(dataset,batch_size=32,shuffle=True)\n\ngenerator = Generator()\ndiscriminator = Decriminator()\n\ng_optimizer = torch.optim.Adam(generator.parameters(),lr=0.0001)\nd_optimizer = torch.optim.Adam(discriminator.parameters(),lr=0.0001)\n\nloss_fn = nn.BCELoss()\n</code></pre> <p>\u63a5\u4e0b\u6765 \u5f00\u59cb\u8bad\u7ec3 \u5c31\u662f\u8bba\u6587\u4e2d\u6240\u63cf\u8ff0\u7684 \u4e24\u4e2a for\u5faa\u73af</p> <p>\u7b2c\u4e00\u4e2afor\u5faa\u73af \u5bf9 epoch\u8fdb\u884c\u5faa\u73af\uff0c\u8868\u793a\u8bad\u7ec3\u591a\u5c11\u4e2a\u5468\u671f</p> Python<pre><code>num_epoch = 100\nfor epoch in range(num_epoch):\n</code></pre> <p>\u7b2c\u4e8c\u4e2afor\u5faa\u73af \u5bf9dataloader\u8fdb\u884c\u4e00\u4e2a\u679a\u4e3e\u7684\u904d\u5386\uff0c\u91c7\u7528enmerate(dataloader)\uff0c\u8fd4\u56de\u4e24\u4e2a\uff0c\u7b2c\u4e00\u4e2a\u662findex\uff0c\u7b2c\u4e8c\u4e2a\u4f4d\u7f6e\u4e0a\u662fsample \u6216\u8005\u8bf4 mini_batch\uff0cmini_batch \u4e0d\u4ec5\u5305\u542b \\(x\\) \u8fd8\u5305\u542b \\(y\\)\uff0c\u56e0\u6b64 \u6211\u4eec\u8981\u5bf9mini_batch \u8fdb\u884c\u89e3\u6790\u4e00\u4e0b</p> Python<pre><code>    for i,mini_batch in enumerate(dataloader):\n        gt_image,_ = mini_batch\n</code></pre> <p>labels\u4e0d\u8981\u4e86 \uff0c\u56e0\u4e3a\u8fd9\u91cc\u8fdb\u884c\u7684\u662f\u65e0\u76d1\u7763\u7684\u751f\u6210\u4efb\u52a1\uff0c\u8fd9\u91cc\u7684image\u5c31\u662f\u771f\u5b9e\u7684\u56fe\u7247\uff0c\u6240\u4ee5\u547d\u540dgt_image\uff0cground truth\uff0c\u8868\u793a\u771f\u5b9e\u7684\u7167\u7247</p> <p>\u63a5\u4e0b\u6765\uff0c\u9996\u5148\u968f\u673a\u751f\u6210\u4e00\u4e2az\uff0cz\u670d\u4ece\u6b63\u6001\u5206\u5e03\uff0c\u5f62\u72b6\u662f \\(batch\\_size\u00d7latent\\_dim\\)\uff0c</p> Python<pre><code>batch_size = 32\nlatent_dim = 64\nfor epoch in range(num_epoch):\n    for i,mini_batch in enumerate(dataloader):\n        gt_image,_ = mini_batch\n        z = torch.randn(batch_size,latent_dim)\n</code></pre> <p>\u5173\u4e8elatent_dim\uff1f</p> <p>z\u7684\u7ef4\u5ea6\u662fbatch size\u00d7latent dim</p> <p>z\u7684\u7ef4\u5ea6\u5728\u6700\u5f00\u59cb\u7684\u5b9a\u4e49\u4e2d\uff0c\u5199\u6210\u7684\u662f\uff1a</p> <p></p> <p>\u5c31\u662f\u5047\u8bbe \u8ddf \u56fe\u7247\u4e00\u6837\u7684\u7ef4\u5ea6\uff0c\u4f46\u662f\uff0c\u4e5f\u53ef\u4ee5\u5047\u8bbe\u662f latent_dim\uff0c\u4e00\u822c\u5728\u751f\u6210\u6a21\u578b\u4e2d\uff0c\u90fd\u662flatent dim\u5305\u62ec\u5728VAE\u4e2d\uff0c\u90fd\u662flatent dim</p> <p></p> <p>z\u662f \u751f\u6210\u5668\u7684\u8f93\u5165</p> <p>\u5c31\u662f\u8bf4z\u7684\u7ef4\u5ea6\uff0c\u53ef\u4ee5\u662f\u4efb\u610f\u7684</p> <p>\u56e0\u6b64 \u6211\u4eec\u9700\u8981 \u5b9a\u4e49\u4e00\u4e2alatent_dim </p> <p>\u5c06latent_dim \u8bbe\u7f6e\u4e3a64\uff0c\u6b64\u65f6z\u7684\u5927\u5c0f\u662f batch size\u00d7latent dim</p> <p>\u7136\u540e\u628a \\(z\\) \u5582\u5165\u5230generator\u4e4b\u4e2d\uff0c\u5f97\u5230prod_image\uff0c\u9884\u6d4b\u51fa\u6765\u7684\u7167\u7247</p> Python<pre><code>prod_images = generator(z)\n</code></pre> <p>\u5f97\u5230\u9884\u6d4b\u7684\u7167\u7247\uff0c\u7ef4\u5ea6\u662f4\u7ef4\u7684</p> <p></p> <p>batch size\u00d7\u901a\u9053\u00d7\u9ad8\u5ea6\u00d7\u5bbd\u5ea6\uff0c\u8ddfDiscriminator\u7684\u8f93\u5165\u662f\u4e00\u6837\u7684</p> <p></p> <p>\u6240\u4ee5 \u53ef\u4ee5\u628a\u5f97\u5230\u7684\u9884\u6d4b\u7167\u7247 \u9001\u5165\u5230 discriminator\u4e4b\u4e2d\uff0c\u5f97\u5230\u5224\u522b\u7684\u6982\u7387</p> <p></p> <p>\u5c31\u662f\u539f\u6587\u4e2d\u7684D(G(z))</p> Python<pre><code>pred_images = generator(z)\n</code></pre> <p>\u63a5\u4e0b\u6765 \u628a \u751f\u6210\u5668 \u751f\u6210\u7684\u7167\u7247 \u9001\u5165\u5230 \u5224\u522b\u5668\u4e4b\u4e2d\uff0c\u5f97\u5230\u4e00\u4e2a\u6982\u7387\uff0c\u7136\u540e\u628a\u76ee\u6807\u4e5f\u9001\u5165\u8fdb\u53bb\uff0c\u9001\u5165\u5230BCELoss function\u4e4b\u4e2d\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230g_loss </p> Python<pre><code>g_loss = loss_fn( discriminator(pred_images) , target )\n</code></pre> <p>\u63a5\u4e0b\u6765\uff0c\u53cd\u5411\u4f20\u64ad\uff0c\u66f4\u65b0\u53c2\u6570</p> Python<pre><code>        g_loss.backward()\n        g_optimizer.step()\n</code></pre> <p>\u6700\u5f00\u59cb\u7684\u65f6\u5019\uff0c\u9700\u8981\u628a \u68af\u5ea6\u7f6e 0</p> Python<pre><code>        g_optimizer.zero_grad()\n        g_loss = loss_fn(discriminator(pred_images),target)\n        g_loss.backward()\n        g_optimizer.step()\n</code></pre> <p>\u4f46\u662f target\u8fd8\u6ca1\u6709\u5b9a\u4e49\uff0c\u5199\u62101\u8fd8\u662f \u5199\u62100\uff1f\u76ee\u6807\u662f\u5bf9\u751f\u6210\u5668\u8fdb\u884c\u4f18\u5316\uff0c\u6240\u4ee5\u5e0c\u671b \u5224\u522b\u5668\u628a \u751f\u6210\u5668\u751f\u6210\u7684\u56fe\u7247 \u4f18\u5316\u6210\u771f\u5b9e\u56fe\u7247\uff0c\u6240\u4ee5\u5199\u6210\u9884\u6d4b\u4e3a1\uff0c\u5373\u5b9a\u4e49target = 1\uff0c\u5f62\u72b6\u5c31\u662f batch_size\u00d71</p> Python<pre><code>        target = torch.ones(batch_size,1)\n</code></pre> <p>\u4ee5\u4e0a\u662f\u5bf9\u751f\u6210\u5668\u7684\u4f18\u5316</p> Python<pre><code>        g_optimizer.zero_grad()\n\n        target = torch.ones(batch_size,1)\n\n        g_loss = loss_fn(discriminator(pred_images),target)\n        g_loss.backward()\n        g_optimizer.step()\n</code></pre> <p>\u63a5\u4e0b\u6765\uff0c\u5224\u522b\u5668\u7684\u4f18\u5316</p> <ul> <li>\u5224\u522b\u5668\u4e00\u5f00\u59cb\u4e5f\u9700\u8981\u7f6e\u96f6\u64cd\u4f5c</li> </ul> Python<pre><code>d_optimizer.zero_grad()\n</code></pre> <ul> <li>\u5224\u522b\u5668\u7684\u76ee\u6807\u51fd\u6570\u6709\u4e24\u4e2a\uff1a</li> </ul> <p></p> <p>\u7b2c\u4e00\u9879\u662f\u9700\u8981\u628a\u771f\u5b9e\u7684\u76ee\u6807\u56fe\u7247\u9001\u5165\u8fdb\u53bb</p> Python<pre><code>target = torch.ones(batch_size,1)        \nd_loss = loss_fn(discriminator(gt_images),target)\n</code></pre> <p>\u4f18\u5316\u7b2c\u4e00\u9879\u7684\u76ee\u6807\u662f\u5224\u522b\u5668\u80fd\u591f\u628a\u771f\u5b9e\u56fe\u7247\u9884\u6d4b\u6b63\u786e\uff0c\u6807\u7b7e\u662ftarget=1</p> <p>\u4ee5\u4e0a\u5199\u597d\u4e86\u7b2c\u4e00\u9879\uff0c\u7b2c\u4e8c\u9879\u628a pred_images\u9001\u5165\u8fdb\u53bb\uff0c\u4e0d\u8fc7\u8981\u628atarget\u7684torch.ones\u6539\u6210torch.zeros\uff0c\u56e0\u4e3a\u7b2c\u4e8c\u9879\u7684\u4f18\u5316\u76ee\u6807\u662f \u5224\u522b\u5668\u628a\u9884\u6d4b\u7167\u7247\u5206\u7c7b\u62100\uff1a</p> Python<pre><code>d_loss = 0.5*loss_fn(discriminator(gt_images),torch.ones(batch_size,1)) \n        + 0.5*loss_fn(discriminator(pred_images.detach()),torch.zeros(batch_size,1))\n</code></pre> <p>\u8fd9\u91cc\u6709\u9700\u8981\u6ce8\u610f\u7684\u70b9\uff0c\u5728\u66f4\u65b0\u5224\u522b\u5668\u7684\u65f6\u5019\uff0c\u4e0d\u8981\u66f4\u65b0\u751f\u6210\u5668\u7684\u53c2\u6570\uff0c\u6240\u4ee5\u7528 detach\u628a\u53c2\u6570\u9694\u79bb\u51fa\u6765\uff0c\u4ece\u8ba1\u7b97\u56fe\u4e2d\u5206\u79bb\u51fa\u6765\uff0c\u800c\u4e0d\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\uff0c\u7531\u4e8e\u662f\u4e24\u4e2aloss</p> <p>\u63a5\u4e0b\u6765\u540c\u6837\u8fdb\u884c backward\u548cstep</p> Python<pre><code>d_loss.backward()\nd_optimizer.step()\n</code></pre> <p>\u4ee5\u4e0a\u662fg\u548cd\u7684\u4f18\u5316</p> <p>\u8003\u8651\u4fdd\u5b58\u4e2d\u95f4\u7ed3\u679c\uff0c\u6bd4\u5982 \u6bcf\u6b21\u5904\u7406\u5b8c1000\u5f20\u7167\u7247\uff08\u4e00\u51716w\u5f20\u7167\u7247\uff09\uff0c\u4fdd\u5b58\u7167\u7247\u7684\u7ed3\u679c</p> Python<pre><code>if i%1000 ==0:\n    pass\n</code></pre> <p>\u5b98\u65b9api \uff1atorchvision \u4fdd\u5b58\u7167\u7247</p> <p></p> <p>save_image\u51fd\u6570\uff1a</p> <p></p> <p>\u63a5\u6536\u53c2\u6570\uff1a</p> <ul> <li>tensor\uff1a\u63a5\u53d7\u4e00\u4e2atensor\uff0ctensor\u5c31\u662f\u6211\u4eec\u4fdd\u7559\u7684\u7167\u7247\uff0c\u5982\u679c\u7ed9\u5b9aminibatchbatch\u7684\u8bdd\uff0c\u4e5f\u662f\u53ef\u4ee5\u7684\uff0c\u4f1a\u7528\u7f51\u683c\u72b6\u4fdd\u5b58</li> <li>fp\uff1a\u6587\u4ef6\u540d\u79f0</li> <li>format\uff1a\u786e\u5b9a\u6587\u4ef6\u7684\u540e\u7f00</li> </ul> <p>\u63a5\u4e0b\u6765\u8c03\u7528\u8fd9\u4e2a\u51fd\u6570\uff0c\u4fdd\u5b58\u7167\u7247</p> <p>\u7b2c\u4e00\u4e2a\u53c2\u6570\uff1a\u4f20\u5165pred_images\uff0c\u662f4\u7ef4\u7684\u3001minibatch\u7684\u683c\u5f0f</p> Python<pre><code>if i%1000 == 0:\n     torchvision.utils.save_image(pred_images,)\n</code></pre> <p>\u7b2c\u4e8c\u4e2a\u53c2\u6570\uff1a\u6587\u4ef6\u540d\u79f0</p> <p>\u6587\u4ef6\u540d\u79f0\u9700\u8981\u904d\u5386\u547d\u540d\u6bcf\u4e2a\u5355\u72ec\u7684pred_image\uff0c\u91c7\u7528<code>enumerate</code>\u904d\u5386\uff0c\u904d\u5386\u5f97\u5230\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u662findex\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u7167\u7247</p> Python<pre><code>        if i%1000 == 0:\n            for index,image in enumerate(pred_images):\n                torchvision.utils.save_image(pred_images,f\"image_{index}.png\")\n</code></pre> <p>\u8865\u5145\u4e4b\u524d\u7684 transform\u8fd8\u9700\u8981\u4e00\u4e2a normalize\u53c2\u6570</p> <p></p> <p></p> <p>\u662f\u56e0\u4e3a\u5728\u8bc6\u522b\u65f6\uff0c\u9700\u8981\u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee</p> <p>\u8fd9\u91cc\u6709\u4e00\u4e2atrick\uff0c\u8ba1\u7b97\u662f0.3\uff0c0.3\uff0c\u4f46\u5b9e\u9645\u4f7f\u7528\u65f6\u7528\u7684\u662f0.5\uff0c0.5\uff0c\u800c\u4e14\u5728\u5b9e\u9645\u7684\u5b9e\u9a8c\u4e2d\uff0c\u786e\u5b9e\u662f0.5\u7684\u5b9e\u9a8c\u6548\u679c\u66f4\u597d</p> Python<pre><code>dataset = torchvision.datasets.MNIST(\"minist_data\",\n                                     train=True,\n                                     download=True,\n                                     transform=torchvision.transforms.Compose(\n                                         [torchvision.transforms.Resize(28),\n                                         torchvision.transforms.ToTensor(),\n                                         torchvision.transforms.Normalize(mean=[0.5],std=[0.5])]\n\n                                     ))\n</code></pre> <p>\u4ee5\u4e0a\u5b9e\u73b0\u4e86GAN\u7684\u6574\u4f53\u6846\u67b6</p> <ol> <li>\u5148\u5199\u4e00\u4e2a\u751f\u6210\u5668</li> <li>\u7136\u540e\u5199\u5224\u522b\u5668</li> <li>\u6784\u5efa\u6570\u636e</li> <li>\u5b9e\u4f8b\u5316\u4e24\u4e2aoptimizer\uff0c\u5206\u522b\u662f\u751f\u6210\u5668\u7684\u4f18\u5316\u5668\uff0c\u7136\u540e\u662f\u5224\u522b\u5668\u7684\u4f18\u5316\u5668</li> <li>loss function</li> <li>\u8bad\u7ec3\u8fc7\u7a0b\u4e2d \uff0c\u5148\u8bad\u7ec3\u751f\u6210\u5668\u6216\u8005\u5148\u8bad\u7ec3\u5224\u522b\u5668\u90fd\u662f\u53ef\u4ee5\u7684</li> <li>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4e0d\u8bba\u662f\u751f\u6210\u5668\u8fd8\u662f\u5224\u522b\u5668\u4f18\u5316\u5668\uff0c\u90fd\u9700\u8981\u6307\u5b9a\u597d\u53c2\u6570</li> </ol> <p></p> <p>\u751f\u6210\u5668\u4f18\u5316\u5668\u53ea\u4f18\u5316\u751f\u6210\u5668\u7684\u53c2\u6570\u3001\u5224\u522b\u5668\u4f18\u5316\u5668\u53ea\u4f18\u5316\u5224\u522b\u5668\u7684\u53c2\u6570</p> Python<pre><code>for epoch in range(num_epoch):\n    for i,mini_batch in enumerate(dataloader):\n        gt_images,_ = mini_batch\n        z = torch.randn(batch_size,latent_dim)\n\n        pred_images = generator(z)\n\n        g_optimizer.zero_grad()\n\n        g_loss = loss_fn(discriminator(pred_images),torch.ones(batch_size,1))\n        g_loss.backward()\n        g_optimizer.step()\n\n        d_optimizer.zero_grad()\n        d_loss = 0.5*loss_fn(discriminator(gt_images),torch.ones(batch_size,1))+ 0.5*loss_fn(discriminator(pred_images).detach(),torch.zeros(batch_size,1))\n        d_loss.backward()\n        d_optimizer.step()\n\n        if i%1000 == 0:\n            for index,image in enumerate(pred_images):\n                torchvision.utils.save_image(pred_images,f\"image_{index}.png\")\n</code></pre> <p>\u4ee3\u7801\u5bf9\u5e94\u7b97\u6cd5\u6d41\u7a0b\uff1a</p> <p></p> <p>\u9996\u5148\u751f\u6210\u5668\u63a5\u6536\u9ad8\u65af\u968f\u673a\u566a\u58f0\u4f5c\u4e3a\u8f93\u5165</p> Python<pre><code>z = torch.randn(batch_size,latent_dim)\n</code></pre> <p>\u751f\u6210\u5668\u63a5\u6536\u9884\u6d4b\u7684\u7167\u7247\u4f5c\u4e3a\u4f18\u5316</p> Python<pre><code>        g_optimizer.zero_grad()\n\n        g_loss = loss_fn(discriminator(pred_images),torch.ones(batch_size,1))\n        g_loss.backward()\n        g_optimizer.step()\n</code></pre> <p>\u4f18\u5316\u7684\u76ee\u7684\u662f\u4f7f\u5f97\u751f\u6210\u7684\u7167\u7247\u63a5\u8fd1\u771f\u5b9e\u7167\u7247\uff0c\u4e5f\u5c31\u662f\u5224\u522b\u5668\u7684\u8f93\u51fa <code>discriminator(pred_images)</code> \u63a5\u8fd1\u771f\u5b9e\u6807\u7b7e1    <code>torch.ones(batch_size,1)</code></p> <p>\u5224\u522b\u5668\u7684\u4f18\u5316\u5305\u62ec\u4e24\u90e8\u5206\uff0c\u5c06\u771f\u5b9e\u56fe\u50cf\u5224\u522b\u4e3a1\uff0c\u5c06\u751f\u6210\u56fe\u50cf\u5224\u522b\u4e3a0\uff0c\u4e24\u4e2a\u635f\u5931\u76f8\u52a0\uff0c\u4fdd\u8bc1\u635f\u5931\u7684\u5e73\u8861\uff0c\u6240\u4ee5*0.5</p> Python<pre><code>        d_optimizer.zero_grad()\n        d_loss = 0.5*loss_fn(discriminator(gt_images),torch.ones(batch_size,1))+ 0.5*loss_fn(discriminator(pred_images).detach(),torch.zeros(batch_size,1))\n        d_loss.backward()\n        d_optimizer.step()\n</code></pre> <p>\u53ef\u4ee5\u5c06\u8fd9\u4e2a\u635f\u5931\u62c6\u5f00\uff1a<code>real_loss</code> \u8868\u793a\u771f\u5b9e\u7167\u7247\u7684\u635f\u5931\uff1b<code>fake_loss</code> \u8868\u793a\u751f\u6210\u56fe\u50cf\u7684\u635f\u5931\uff1b\u63a5\u7740 \\(0.5\u500d\u7684\\mathrm{real\\_loss}\\) + \\(0.5\u500d\u7684 \\mathrm{fake\\_loss}\\) \u5f97\u5230\u6700\u7ec8\u7684loss</p> Python<pre><code>        real_loss = loss_fn(discriminator(gt_images),torch.ones(batch_size,1))\n        fake_loss = loss_fn(discriminator(pred_images),torch.zeros(batch_size,1))\n        d_loss = 0.5 * real_loss + 0.5 * fake_loss \n        # \u89c2\u5bdf real_loss \u4e0e fake_loss\uff0c\u540c\u65f6\u4e0b\u964d\u540c\u65f6\u8fbe\u5230\u6700\u5c0f\u503c\uff0c\u5e76\u4e14\u503c\u5dee\u4e0d\u591a\u5927\uff0c\u8bf4\u660eD\u5df2\u7ecf\u7a33\u5b9a\u4e86   \n</code></pre> <p>\u62c6\u5f00\u5199\u7684\u76ee\u7684\u662f\u901a\u8fc7\u89c2\u5bdf\u635f\u5931 \u5224\u522b \u5224\u522b\u5668\u7684\u8bad\u7ec3\u662f\u5426\u8d8b\u4e8e\u7a33\u5b9a\uff0c\u6807\u51c6\u662f \u89c2\u5bdfreal_loss \u548c fake_loss\uff0c\u540c\u65f6\u4e0b\u964d\u8fbe\u5230\u6700\u5c0f\u503c\uff0c\u5e76\u4e14\u503c\u5dee\u4e0d\u591a\u5927\uff0c\u8bf4\u660e D \u5df2\u7ecf\u7a33\u5b9a\u4e86</p> <p>\u540e\u9762\u4ee3\u7801\u7684\u4f18\u5316\uff1a</p> <p>\uff081\uff09\u5f15\u5165batchnorm\u53ef\u4ee5\u63d0\u9ad8\u6536\u655b\u901f\u5ea6\uff0c\u5177\u4f53\u505a\u6cd5\u662f\u5728\u751f\u6210\u5668\u7684Linear\u5c42\u540e\u9762\u6dfb\u52a0BatchNorm1d\uff0c\u6700\u540e\u4e00\u5c42\u9664\u5916\uff0c\u5224\u522b\u5668\u4e0d\u8981\u52a0 </p> <p>\uff082\uff09\u76f4\u63a5\u9884\u6d4b\u30100,1\u3011\u4e4b\u95f4\u7684\u50cf\u7d20\u503c\u5373\u53ef\uff0c\u4e0d\u505a\u5f52\u4e00\u5316\u7684transform\uff1b\u6216\u8005\u4e5f\u53ef\u4ee5\u653e\u5927\uff0c\u9884\u6d4b\u3010-1,1\u3011\u4e4b\u95f4\uff0c\u7528mean=0.5 std=0.5\u8fdb\u884c\u5f52\u4e00\u5316transform\u90fd\u53ef\u4ee5 </p> <p>\uff083\uff09\u5c06\u6fc0\u6d3b\u51fd\u6570ReLU\u6362\u6210GELU\u6548\u679c\u66f4\u597d </p> <p>\uff084\uff09real_loss\u57fa\u4e8e\u771f\u5b9e\u56fe\u7247\uff0cfake_loss\u57fa\u4e8e\u751f\u6210\u56fe\u7247\uff0creal_loss = loss_fn(discriminator(gt_images), torch.ones(batch_size, 1))\uff0cfake_loss = loss_fn(discriminator(pred_images.detach()), torch.zeros(batch_size, 1)) </p> <p>\uff085\uff09\u9002\u5f53\u5f15\u5165\u91cd\u6784loss\uff0c\u8ba1\u7b97\u50cf\u7d20\u503c\u7684L1\u8bef\u5dee </p> <p>\uff086\uff09\u5efa\u8bae\u5f15\u5165loss\u6253\u5370\u8bed\u53e5\uff0c\u5982\uff1a</p> Python<pre><code>  print(f\"step:{len(dataloader)*epoch+i}, g_loss:{g_loss.item()}, d_loss:{d_loss.item()}, real_loss:{real_loss.item()}, fake_loss:{fake_loss.item()}\") \n</code></pre> <p>\uff087\uff09\u5224\u522b\u5668\u6a21\u578b\u5bb9\u91cf\u4e0d\u5b9c\u8fc7\u5927 </p> <p>\uff088\uff09save_image\u4e2d\u7684normalize\u8bbe\u7f6e\u6210True\uff0c\u76ee\u7684\u662f\u5c06\u50cf\u7d20\u503cmin-max\u81ea\u52a8\u5f52\u4e00\u5230\u30100,1\u3011\u8303\u56f4\u5185\uff0c\u5982\u679c\u5df2\u7ecf\u9884\u6d4b\u4e86\u30100,1\u3011\u4e4b\u95f4\uff0c\u5219\u53ef\u4ee5\u4e0d\u7528\u8bbe\u7f6eTrue </p> <p>\uff089\uff09\u5224\u522b\u5668\u7684\u5b66\u4e60\u7387\u4e0d\u80fd\u592a\u5c0f </p> <p>\uff0810\uff09Adam\u7684\u4e00\u9636\u5e73\u6ed1\u7cfb\u6570\u548c\u4e8c\u9636\u5e73\u6ed1\u7cfb\u6570 betas \u9002\u5f53\u8c03\u5c0f\u4e00\u70b9\uff0c\u53ef\u4ee5\u5e2e\u52a9\u5b66\u4e60\uff0c\u8bbe\u7f6e\u4e00\u5b9a\u6bd4\u4f8b\u7684weight decay</p>"},{"location":"learning/5_Bert/","title":"BERT\u4ece\u96f6\u8be6\u7ec6\u89e3\u8bfb","text":""},{"location":"learning/5_Bert/#bert","title":"BERT\u4ece\u96f6\u8be6\u7ec6\u89e3\u8bfb","text":"2024-12-03 09:54:572025-09-28 12:54:04 <p> \u7ea6 5186 \u4e2a\u5b57  63 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 26 \u5206\u949f</p> <p></p> <p>\u76ee\u5f55\uff1a</p> <p></p>"},{"location":"learning/5_Bert/#1-bert","title":"1 Bert\u7684\u6574\u4f53\u67b6\u6784","text":"<ul> <li>Bert\u7684\u57fa\u7840\u7ed3\u6784\u662fTransformer Encoder\u7684\u90e8\u5206</li> <li>Encoder\u53ef\u4ee5\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a\u8f93\u5165\u90e8\u5206 + \u591a\u5934\u6ce8\u610f\u529b\u673a\u5236 + \u524d\u9988\u795e\u7ecf\u7f51\u7edc\u90e8\u5206</li> <li>Bert\u4f7f\u7528\u7684\u662f\u591a\u4e2aTransformer Encoder \u5806\u53e0\u5728\u4e00\u8d77\u7684\uff0c\u5176\u4e2dBert base\u4f7f\u7528\u7684\u662f12\u5c42\u7684Encoder\uff0cBert large\u4f7f\u7528\u7684\u662f24\u5c42\u7684Encoder</li> </ul> <ul> <li> <p>\u56fe\u4e2d\u5c55\u793a\u7684\u662f 12\u5c42\u7684 Encoder \u5806\u53e0\u5728\u4e00\u8d77\u7684Bert base</p> </li> <li> <p>\u5bb9\u6613\u6df7\u6dc6\u7684\u70b9\uff1a</p> </li> </ul> <p>\u8fd9\u91cc\u662f12\u5c42\u7684Encoder\u5806\u53e0\u5728\u4e00\u8d77\u7ec4\u6210\u7684Bert\uff0c\u800c\u4e0d\u662f12\u5c42\u7684Transformer\u5806\u53e0\u5728\u4e00\u8d77\uff0c\u4e00\u5b9a\u8981\u533a\u5206Encoder\u548cTransformer</p> <p>Transformer\u5728\u539f\u8bba\u6587\u4e2d\u662f6\u4e2aEncoder\u5806\u53e0\u5728\u4e00\u8d77\u53d8\u6210\u7f16\u7801\u7aef\uff0c6\u4e2adecoder\u5806\u53e0\u5728\u4e00\u8d77\u53d8\u6210\u89e3\u7801\u7aef</p> <p></p> <p></p> <ul> <li> <p>\u5982\u56fe\u662f\u4e00\u4e2aEncoder\uff0c\u5bf9\u4e8eBert\u7684Encoder\u90e8\u5206\uff0c\u91cd\u70b9\u5173\u6ce8\u8f93\u5165\u90e8\u5206</p> </li> <li> <p>\u5bf9\u4e8eTransformer\u6765\u8bf4\uff0c\u8f93\u5165\u90e8\u5206\u5305\u62ec\u4e24\u90e8\u5206\uff1a</p> </li> </ul> <ul> <li>\u4e00\u90e8\u5206\u662fembedding\uff0c\u5c31\u662f\u505a\u8bcd\u7684\u8bcd\u5411\u91cf\uff0c\u6bd4\u5982\u4f7f\u7528\u968f\u673a\u521d\u59cb\u5316 \u6216\u8005 word2vector</li> <li>\u7b2c\u4e8c\u90e8\u5206\uff1aPosition Encoding\uff0c\u5728Transformer\u4e2d\u4f7f\u7528\u7684\u662fPosition encoding \u4f4d\u7f6e\u7f16\u7801\uff0c\u4f7f\u7528\u7684\u662f\u4e09\u89d2\u51fd\u6570\uff0c\u6b63\u4f59\u5f26\u51fd\u6570</li> </ul> <ul> <li>\u5bf9\u4e8eBert\u6765\u8bf4\uff0c\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a</li> </ul> <ul> <li> <p>\u7b2c\u4e00\u90e8\u5206\u662f token embedding</p> </li> <li> <p>\u7b2c\u4e8c\u90e8\u5206\u662fsegment embedding</p> </li> <li> <p>\u7b2c\u4e09\u90e8\u5206\u662fPositional embedding</p> </li> </ul> <p>\u533a\u5206Transformer\u7684Position encoding\u548cBert\u7684Position embedding</p>"},{"location":"learning/5_Bert/#11-bert","title":"1.1 \u8be6\u7ec6\u770bBert\u7684\u8f93\u5165\u90e8\u5206","text":"<ul> <li> <p>Bert \u7684\u8f93\u5165\u90e8\u5206\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff0c\u5206\u522b\u662ftoken embedding\u3001segment embedding\u548cPosition embedding</p> </li> <li> <p>\u9996\u5148\u7c89\u8272\u7684\u4e00\u884c\u662f\u8f93\u5165\uff0c\u91cd\u70b9\u5173\u6ce8\u4e24\u4e2a\u90e8\u5206</p> </li> </ul> <p>\u7b2c\u4e00\u90e8\u5206\u662f\u6b63\u5e38\u8bcd\u6c47\uff1a</p> <p></p> <p>\u8fd9\u4e9b\u8bcd\u662fBert\u5206\u8bcd\u5668\u4e4b\u540e\u7684\u8bcd\u6c47</p> <p>\u7b2c\u4e8c\u90e8\u5206\u662f\u7279\u6b8a\u8bcd\u6c47\uff1a</p> <p>[CLS]</p> <p>[SEP]</p> <p>\u4e24\u79cd\u7279\u6b8a\u7b26\u53f7</p> <p>\u8fd9\u4e24\u79cd\u7279\u6b8a\u7b26\u53f7\u7684\u5b58\u5728\u662f\u56e0\u4e3a Bert\u7684\u9884\u8bad\u7ec3\u4e2d \u6709\u4e00\u4e2a\u662f NSP\u4efb\u52a1\uff0cnext sentence prediction\uff0c\u5224\u65ad\u4e24\u4e2a\u53e5\u5b50\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5177\u4f53\u5730\u4e1c\u897f\u540e\u9762\u8bb2\u89e3</p> <p>[SEP]</p> <p>NSP\u4efb\u52a1\u662f\u5904\u7406\u4e24\u4e2a\u53e5\u5b50\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u56e0\u4e3a\u5904\u7406\u7684\u662f\u4e24\u4e2a\u53e5\u5b50\uff0c\u6240\u4ee5\u9700\u8981\u4e00\u4e2a\u7279\u6b8a\u7b26\u53f7\uff0c\u544a\u8bc9\u6a21\u578b\uff0c\u5728[SEP]\u7b26\u53f7\u4e4b\u524d\u7684\u662f\u4e00\u4e2a\u53e5\u5b50\uff0c\u5728[SEP]\u7b26\u53f7\u4e4b\u540e\u7684\u662f\u4e00\u4e2a\u53e5\u5b50</p> <p>\u4ee5\u4e0a\u662f[SEP]\u7684\u4f5c\u7528</p> <p>[CLS]</p> <p>\u63a5\u7740NSP\u4efb\u52a1\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u5c31\u662f\u53e5\u5b50\u4e4b\u95f4\u662f\u4ec0\u4e48\u5173\u7cfb\u7684\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u90a3\u4e48\u600e\u4e48\u5b9e\u73b0\u4e8c\u5206\u7c7b\u4efb\u52a1\uff1f\u6240\u4ee5\u5728\u53e5\u5b50\u524d\u9762\u52a0\u4e86\u4e00\u4e2a[CLS]\u7684\u7279\u6b8a\u7b26\u53f7\uff0c\u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u5c06[CLS]\u7684\u7279\u6b8a\u5411\u91cf\u63a5\u4e00\u4e2a\u4e8c\u5206\u7c7b\u5668\u505a\u4e00\u4e2a\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u662f[CLS]\u7684\u4f5c\u7528</p> <p>\u5173\u4e8e[CLS]\u7684\u6269\u5c55\u5185\u5bb9\uff1a</p> <p>[CLS]\u7684\u5e38\u89c1\u8bef\u89e3\uff1a\u5f88\u591a\u4eba\u8ba4\u4e3a[CLS]\u8fd9\u4e2a\u7279\u6b8a\u5411\u91cf\u8868\u793a\u4e00\u4e2a\u53e5\u5b50\u6216\u8005\u6574\u4e24\u4e2a\u53e5\u5b50\u7684\u8bed\u4e49\u4fe1\u606f</p> <p>\u8fd9\u79cd\u8bf4\u6cd5\u662f\u4e0d\u6b63\u786e\u7684</p> <p>\u5728\u9884\u8bad\u7ec3\u7ed3\u675f\u4ee5\u540e\uff0c[CLS]\u8fd9\u4e2a\u5411\u91cf\u7684\u8f93\u51fa\u5411\u91cf\uff0c\u5e76\u4e0d\u80fd\u8bf4\u4ee3\u8868\u6574\u4e2a\u53e5\u5b50\u7684\u8bed\u4e49\u4fe1\u606f</p> <p>[CLS]\u8fd9\u4e2a\u5411\u91cf\u7528\u5728\u4e86NSP\u4efb\u52a1\u4e2d\uff0cNSP\u4efb\u52a1\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u548c\u7f16\u7801\u6574\u4e2a\u53e5\u5b50\u7684\u8bed\u4e49\u4fe1\u606f\u4efb\u52a1 \u662f\u4e0d\u4e00\u6837\u7684\uff0c\u6240\u4ee5\u5728\u7528 [CLS] \u8fd9\u4e2a\u5411\u91cf \u6765\u65e0\u76d1\u7763\u7684\u505a\u6587\u672c\u76f8\u4f3c\u5ea6 \u4efb\u52a1\u7684\u65f6\u5019 \u6548\u679c\u975e\u5e38\u5dee</p> <p>\u53ef\u4ee5\u770b\u4e0b\u9762\u8fd9\u5f20\u56fe</p> <p></p> <p>[CLS]\u5411\u91cf \u5e76\u4e0d\u80fd\u4ee3\u8868\u6574\u4e2a\u53e5\u5b50\u7684\u8bed\u4e49\u4fe1\u606f</p> <p>\u9884\u8bad\u7ec3\u6a21\u578b\u76f4\u63a5\u62ffsentence embedding\u6548\u679c\u751a\u81f3\u4e0d\u5982word embedding\uff0ccls\u7684embedding\u6548\u679c\u6700\u5dee</p> <p>\u4e3a\u4ec0\u4e48\u505a\u65e0\u76d1\u7763\u7684\u6587\u672c\u76f8\u4f3c\u5ea6\uff0ccls\u7684\u8f93\u51fa\u5411\u91cf\u6548\u679c\u5f88\u5dee\uff0c\u6709\u4e13\u95e8\u7684\u8ba8\u8bba</p> <p>\u73b0\u5728\u7684\u95ee\u9898\u662f cls embedding\u662f\u5426\u80fd\u505a\u65e0\u76d1\u7763\u7684\u6587\u672c\u76f8\u4f3c\u5ea6\uff1f\u4e5f\u6709\u7814\u7a76</p> <ul> <li>\u63a5\u4e0b\u6765\u770b\u9ec4\u8272\u7684\u90e8\u5206\uff1atoken embedding</li> </ul> <p></p> <p>token embedding\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u5bf9input\u4e2d\u7684\u6240\u6709\u8bcd\u6c47\uff08\u5305\u62ec\u6b63\u5e38\u8bcd\u6c47\u548c\u7279\u6b8a\u8bcd\u6c47\uff09\u505a\u6b63\u5e38\u7684embedding\uff0c\u6bd4\u5982\u968f\u673a\u521d\u59cb\u5316</p> <ul> <li>\u7b2c\u4e8c\u90e8\u5206\uff0c\u7eff\u8272\u90e8\u5206\uff1asegment embedding</li> </ul> <p></p> <p>\u4e5f\u662f\u7531\u4e8e\u5904\u7406\u7684\u662f\u4e24\u4e2a\u53e5\u5b50\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u4e24\u4e2a\u53e5\u5b50\u8fdb\u884c\u533a\u5206\uff0c\u6bd4\u5982\u7b2c\u4e00\u4e2a\u53e5\u5b50\u5168\u90e8\u75280\u6765\u8868\u793a\uff0c\u5305\u62ec[CLS]\u5230[SEP]</p> <p></p> <p>\u540e\u9762\u7684\u53e5\u5b50\u5168\u90e8\u75281\u6765\u8868\u793a\uff0c\u5206\u522b\u8868\u793a\u4e86\u4e24\u4e2a\u53e5\u5b50</p> <ul> <li>\u7b2c\u4e09\u90e8\u5206\u662fPosition embeddings\uff0c\u4e5f\u5c31\u662fBert\u7684\u8f93\u5165\u90e8\u5206\u548cTransformer\u7684\u8f93\u5165\u90e8\u5206\u5f88\u5927\u7684\u4e0d\u540c\u70b9</li> </ul> <p>Transformer\u4e2d\u4f7f\u7528\u7684\u662f\u6b63\u4f59\u5f26\u51fd\u6570\uff0c\u8fd9\u91cc\u4f7f\u7528\u7684\u662f\u968f\u673a\u521d\u59cb\u5316\uff0c\u8ba9\u6a21\u578b\u81ea\u5df1\u5b66\u4e60\uff0c\u6bd4\u5982\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u8bbe\u7f6e\u4e3a0\uff0c\u7b2c\u4e8c\u4e2a\u90e8\u5206\u8bbe\u7f6e\u4e3a1\uff0c\u7b2c\u4e09\u4e2a\u90e8\u5206\u8bbe\u7f6e\u4e3a2\u7b49\u7b49\u7b49\uff0c\u4e00\u76f4\u5230511\uff0c512\u8868\u793a\u53e5\u5b50\u7684\u6700\u5927\u957f\u5ea6\uff0c\u7d22\u5f15\u7684\u6700\u5927\u503c\u662f512</p> <p></p> <p>\u6a21\u578b\u81ea\u5df1\u5b66\u4e60 \u6bcf\u4e2a\u4f4d\u7f6e\u7684embedding\u662f\u4ec0\u4e48\u6837\u7684</p> <p>tips</p> <p>encoding\uff1a\u4f4d\u7f6e\u7f16\u7801\uff0c\u5e38\u6570\u4f4d\u7f6e\u7f16\u7801</p> <p>embedding\uff1a\u4f4d\u7f6e\u5d4c\u5165\uff0c\u9700\u8981\u81ea\u5df1\u5b66\u4e60\u4f4d\u7f6e\u8868\u793a</p> <p>\u5173\u4e8e\u4e3a\u4ec0\u4e48\u4f7f\u7528embedding\u800c\u4e0d\u662fencoding\uff0c\u4e5f\u6709\u5f88\u591a\u8ba8\u8bba</p>"},{"location":"learning/5_Bert/#2-mlmnsp","title":"2 \u5982\u4f55\u505a\u9884\u8bad\u7ec3\uff1aMLM+NSP","text":"<p>\u5982\u4f55\u5bf9Bert\u8fdb\u884c\u9884\u8bad\u7ec3\uff1f</p> <p>\u9884\u8bad\u7ec3Bert\u4e3b\u8981\u6d89\u53ca\u4e24\u4e2a\u4efb\u52a1\uff1a</p> <ul> <li>MLM\u4efb\u52a1\uff1amasked language model\u8868\u793a\u63a9\u7801\u8bed\u8a00\u6a21\u578b</li> <li>NSP\u4efb\u52a1\uff1a\u5224\u65ad\u4e24\u4e2a\u53e5\u5b50\u4e4b\u95f4\u7684\u5173\u7cfb</li> </ul>"},{"location":"learning/5_Bert/#21-mlm","title":"2.1 MLM\u4efb\u52a1","text":"<p>\u9996\u5148\u660e\u786eBert\u5728\u9884\u8bad\u7ec3\u65f6 \u4f7f\u7528\u7684\u662f\u5927\u91cf\u7684\u65e0\u6807\u6ce8\u7684\u8bed\u6599\u5e93\uff0c\u968f\u5904\u53ef\u89c1\u7684\u65e0\u6807\u6ce8\u6587\u672c\uff0c\u6240\u4ee5\u5728\u9884\u8bad\u7ec3\u4efb\u52a1\u8bbe\u8ba1\u7684\u65f6\u5019\uff0c\u4e00\u5b9a\u8981\u8003\u8651\u65e0\u76d1\u7763\u6765\u505a\uff0c\u56e0\u4e3a\u662f\u6ca1\u6709\u6807\u7b7e\u7684\uff0c\u5bf9\u4e8e\u65e0\u76d1\u7763\u7684\u76ee\u6807\u51fd\u6570\u6765\u8bf4\uff0c\u6709\u4e24\u79cd\u76ee\u6807\u51fd\u6570 \u6bd4\u8f83\u53d7\u5230\u91cd\u89c6\uff1a</p> <p></p> <p>\u7b2c\u4e00\u79cd\u662fAR\u6a21\u578b\uff0c\u4e5f\u5c31\u662fAuto Regressive\uff0c\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u7279\u70b9\u662f\u53ea\u80fd\u8003\u8651\u5230\u5355\u4fa7\u4fe1\u606f\uff0c\u5178\u578b\u5e94\u7528\u662fGPT</p> <p>\u53e6\u4e00\u79cd\u76ee\u6807\u51fd\u6570\u5c31\u662fAE\u6a21\u578b\uff0cAutoencoding\uff0c\u81ea\u7f16\u7801\u6a21\u578b\uff0c\u7279\u70b9\u662f\u4ece\u635f\u574f\u7684\u8f93\u5165\u6570\u636e\u4e2d\u91cd\u5efa\u539f\u59cb\u6570\u636e\uff0c\u53ef\u4ee5\u4f7f\u7528\u5230\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f</p> <ul> <li> \u6587\u5b57\u63cf\u8ff0</li> <li> \u4f8b\u5b50\uff08\u6570\u5b66\u4f8b\u5b50\u3001\u5b9e\u9645\u4f8b\u5b50\uff09</li> <li> \u4ee3\u7801</li> </ul> <p></p> <p>\u4ee5 <code>\u6211\u7231\u5403\u996d</code> \u8fdb\u884c\u4e3e\u4f8b</p> <p>AR\u6a21\u578b</p> <p></p> <p>\u5047\u8bbe\u539f\u59cb\u8f93\u5165\u8bed\u6599 \u662f <code>\u6211\u7231\u5403\u996d</code>\uff0c\u90a3\u4e48AR\u6a21\u578b\u5728\u505a\u7684\u65f6\u5019\uff0c\u4e0d\u4f1a\u5bf9 <code>\u6211\u7231\u5403\u996d</code> \u672c\u8eab\u8fd9\u53e5\u8bdd\u8fdb\u884c\u64cd\u4f5c\uff0cAR\u6a21\u578b\u7684\u4f18\u5316\u76ee\u6807\u662f \\(P(\u6211\u7231\u5403\u996d)\\)  = P(\u6211) \u3010''\u6211''\u51fa\u73b0\u7684\u6982\u7387\u3011\u00d7 P(\u7231|\u6211)\u3010\u5728\"\u6211\"\u51fa\u73b0\u7684\u6761\u4ef6\u4e0b\uff0c\"\u7231\"\u51fa\u73b0\u7684\u6982\u7387\u3011 \u00d7 P(\u5403|\u6211\u7231)\u3010 \"\u6211\u7231\" \u51fa\u73b0\u7684\u6761\u4ef6\u4e0b \"\u5403\" \u51fa\u73b0\u7684\u6982\u7387\u3011 \u00d7 P(\u996d|\u6211\u7231\u5403)\u3010\u5728 \"\u6211\u7231\u5403\"\u7684\u6761\u4ef6\u4e0b\uff0c\"\u996d\"\u51fa\u73b0\u7684\u6982\u7387\u3011</p> <p>AR\u6a21\u578b\u7684\u4f18\u5316\u76ee\u6807 \u5b58\u5728\u524d\u540e\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u53ef\u4ee5\u770b\u5230AR\u6a21\u578b\u53ea\u7528\u5230\u4e86\u5355\u4fa7\u4fe1\u606f\uff0c\u4e5f\u5c31\u662f\u987a\u5e8f\u8fc7\u6765\u7684\uff0c\u4e5f\u5c31\u662f\u4ece\u5de6\u5230\u53f3\u7684\u5355\u4fa7\u4fe1\u606f\uff0c\u63a5\u4e0b\u6765\u770b AE\u6a21\u578b</p> <p>AE\u6a21\u578b</p> <p></p> <p>AE\u6a21\u578b\u662f\u5bf9\u53e5\u5b50\u505a\u4e00\u4e2a mask</p> <p>mask\u672c\u610f \u9762\u5177 \u7684\u610f\u601d\uff0c\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u7528 \u9762\u5177 \u63a9\u76d6\u53e5\u5b50\u4e2d\u7684 \u67d0\u4e9b \u6216\u8005\u67d0\u51e0\u4e2a \u5355\u8bcd</p> <p>\u6bd4\u5982 mask\u4e4b\u540e \u662f \uff1a\u6211\u7231mask\u996d\uff0c\u6211\u4eec\u77e5\u9053mask\u7684\u4f4d\u7f6e\u662f \"\u5403\"</p> <p>\u6211\u4eec\u7684\u4f18\u5316\u76ee\u6807\u5c31\u662f P(\u6211\u7231\u5403\u996d|\u6211\u7231mask\u996d)   \"\u6211\u7231mask\u996d\" \u6761\u4ef6\u4e0b\uff0c\u51fa\u73b0\u7684\u662f \"\u6211\u7231\u5403\u996d\" \u51fa\u73b0\u7684\u6982\u7387</p> <p>=  P(mask = \u5403|\u6211\u7231\u996d)  \"\u6211\u7231\u996d\"\u7684\u6761\u4ef6\u4e0b\uff0cmask=\"\u5403\" \u7684\u6982\u7387</p> <p></p> <ul> <li> <p>\u4ed4\u7ec6\u4f53\u4f1a\u8fd9\u4e2a AE\u7684\u4f18\u5316\u76ee\u6807\uff0c\u672c\u8d28\u662f\u5728\u6253\u7834\u6587\u672c\u539f\u6709\u7684\u4fe1\u606f\uff0c\u539f\u672c\u662f\"\u6211\u7231\u5403\u996d\"\uff0c\u6211\u4eec\u628a \"\u5403\" \u8fd9\u4e2a\u5b57 \u63a9\u76d6\u6389\uff0c\u8ba9\u6a21\u578b\u4e0d\u77e5\u9053\uff0c\u7136\u540e\u5728 \u8bad\u7ec3\u7684\u65f6\u5019 \u8ba9 \u6587\u672c\u91cd\u5efa</p> </li> <li> <p>\u5728\u505a \u6a21\u578b\u91cd\u5efa\u7684\u65f6\u5019\uff0c\u8ba9\u6a21\u578b \u81ea\u5df1 \u4ece\u524d\u540e\u7684\u8bcd\u4e2d\uff0c\u5b66\u4e60\u5404\u79cd\u4fe1\u606f\uff0c\u4f7f\u5f97\u6a21\u578b\u80fd\u591f \u4ece\u524d\u540e\u7684\u4fe1\u606f\u4e2d\u65e0\u9650\u63a5\u8fd1\u7684\u9884\u6d4b\u4e2d \u539f\u672c\u7684\u8bcd\u6c47</p> </li> <li>\u901a\u4fd7\u70b9\u5c31\u662f\u8bf4\uff1a\"\u6211\u7231\"\u4f1a\u544a\u8bc9\u6a21\u578b \u540e\u9762\u5927\u6982\u7387\u8ddf\u7740\u52a8\u8bcd\u8bcd\u7ec4\uff0c\u6bd4\u5982 \"\u6211\u7231\u653e\u98ce\u7b5d\"\uff0c\"\u6211\u7231\u4e0a\u5b66\"\u7b49\u7b49\u7b49\uff0c\"\u996d\" \u4f1a\u544a\u8bc9\u6a21\u578b\u524d\u9762\u5927\u6982\u7387\u662f\u4e2a {\u52a8\u8bcd}\uff0c\u8fd9\u5c31\u662f\u6a21\u578b\u4ece\u6587\u672c\u4e2d\u52aa\u529b\u5b66\u5230\u7684\u89c4\u5f8b\uff0c\u5b66\u5230\u8fd9\u4e9b\u89c4\u5f8b\u4ee5\u540e\uff0c\u6a21\u578b\u5c31\u4f1a\u628a\u6587\u672c\u91cd\u5efa\u51fa\u6765\uff0c\u53d8\u4e3a \"\u5403\"</li> <li>\u63a5\u4e0b\u6765\u8ba8\u8bba mask \u6a21\u578b\u7684\u7f3a\u70b9</li> </ul> <p></p> <p>\u6bd4\u5982\u8bf4 \u6211\u4eecmask\u6389\u4e24\u4e2a\u5355\u5b57\"\u5403\"\u3001\"\u996d\"</p> <p>\u6b64\u65f6\u4f18\u5316\u76ee\u6807\u53d8\u4e3a \\(P(\u6211\u7231\u5403\u996d|\u6211\u7231\\mathrm{mask \\quad mask})\\) \u5c31\u662f \"\u6211\u7231maskmask\"\u6761\u4ef6\u4e0b\uff0c\"\u6211\u7231\u5403\u996d\"\u7684\u6982\u7387\uff0c\u8fd9\u4e2a\u5f0f\u5b50\\(= P(\u5403|\u6211\u7231)P(\u996d|\u6211\u7231)\\) \u901a\u8fc7\u8fd9\u4e2a\u4f18\u5316\u76ee\u6807\uff0c\u53ef\u4ee5\u770b\u51fa \u8fd9\u4e2a\u4f18\u5316\u76ee\u6807\u8ba4\u4e3a \"\u5403\" \u548c \"\u996d \"\u662f\u76f8\u4e92\u72ec\u7acb\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4 AE\u6a21\u578b \u8ba4\u4e3a mask\u548cmask\u4e4b\u95f4 \u662f\u76f8\u4e92\u72ec\u7acb\u7684\uff0c\u4f46\u5176\u5b9emask\u4e4b\u95f4\uff0c\u6bd4\u5982\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0cmask\u5c31\u4e0d\u662f\u76f8\u4e92\u72ec\u7acb\u7684</p> <p>\u4ee5\u4e0a\u8bf4\u660e\u4e86 mask \u6a21\u578b\u7684\u7f3a\u70b9</p> <ul> <li>Bert\u5728\u9884\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u7b2c\u4e00\u4e2a\u4efb\u52a1\u5c31\u662fMLM\uff0c\u5c31\u662f\u7528\u5230\u4e86mask\u7b56\u7565\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cmask\u7684\u6982\u7387\u95ee\u9898\uff0c\u5177\u4f53\u600e\u4e48\u505a\u7684\uff1f \\(\\downarrow\\)</li> </ul> <p></p> <p>\u968f\u673amask 15%\u7684\u5355\u8bcd\uff0c\u4e5f\u5c31\u662f100\u4e2a\u5355\u8bcd\u91cc\u9762\uff0c\u6311\u51fa 15\u4e2a\u5355\u8bcd\u6765mask\uff0c\u4f46\u662f15\u4e2a\u5355\u8bcd\u53c8\u4e0d\u662f\u5168\u90e8\u90fd\u771f\u7684\u6765mask\uff0c\u800c\u662f10%\u66ff\u6362\u6210\u5176\u4ed6\u5355\u8bcd\uff0c10%\u539f\u5c01\u4e0d\u52a8\uff0c80%\u66ff\u6362\u6210\u771f\u6b63\u7684mask\uff0c\u5173\u4e8e\u8fd9\u4e2a\u6982\u7387\u4e3a\u4ec0\u4e48\u662f\u8fd9\u6837\u7684\uff0c\u60f3\u5b66\u81ea\u5df1\u641c\uff0c\u7406\u89e3\u5c31\u597d</p>"},{"location":"learning/5_Bert/#211mask","title":"2.1.1\u4ee3\u7801\u5b9e\u73b0mask","text":"<ul> <li>\u9996\u5148 \u968f\u673a mask\u6389 15%\u7684\u5355\u8bcd\uff0c\u5bf9\u5e94 <code>mask_indices</code></li> <li>\u63a5\u4e0b\u6765811\u5212\u5206\uff0c\u4e5f\u5c31\u662f 8\u4efd \u66ff\u6362\u6210 mask\uff0c1\u4efd\u539f\u5c01\u4e0d\u52a8\uff0c1\u4efd\u66ff\u6362\u6210\u5176\u4ed6</li> <li>\u5bf9\u5e94\u5230\u4ee3\u7801\uff0c\u5c31\u662f <code>random.randowm()&lt;0.8</code> \u5c31 mask\u6389 \u8fd9\u4e2a\u8bcd\u6c47\uff0c\u66ff\u6362\u6210 \"[mask]\" \u8fd9\u4e2a\u5355\u8bcd</li> <li>\u5269\u4e0b\u7684 20% \u4e2d\u7684\uff0c50%\uff0c\u4e5f\u5c31\u662f\u4e24\u8005\u76f8\u4e58\uff0c\u5c31\u662f\u603b\u4f53\u4e2d\u7684 10% \u4fdd\u6301\u4e0d\u53d8\uff0c\u5269\u4f59\u7684 10% \u968f\u673a\u62bd\u53d6\u4e00\u4e2a\u5355\u8bcd</li> <li>\u4f46\u4ece\u4ee3\u7801\u6765\u770b\uff0c\u8fd9\u4e2a\u968f\u673a\u62bd\u53d6\u7684\u8fc7\u7a0b\uff0c\u4e5f\u6709\u53ef\u80fd\u62bd\u53d6\u5230 \u81ea\u5df1\u672c\u8eab\uff0c\u4e5f\u5c31\u662f \u5b83\u7531\u522b\u7684\u5355\u8bcd\u66ff\u6362\u5b8c\u4ee5\u540e\uff0c\u53c8\u62bd\u53d6\u5230\u8fd9\u4e2a \u66ff\u6362\u540e\u7684\u8bcd\uff0c\u4e5f\u5c31\u662f\u6ca1\u6709\u53d8\uff08\uff1f</li> </ul>"},{"location":"learning/5_Bert/#22-nsp","title":"2.2  NSP\u4efb\u52a1","text":"<p>\u63a5\u4e0b\u6765 \u7b2c\u4e8c\u4e2a\u4efb\u52a1 NSP\u4efb\u52a1</p> <p></p> <ul> <li>\u7406\u89e3NSP\u4efb\u52a1 \u7684\u5173\u952e\u4e00\u70b9\u662f\u7406\u89e3 \u6837\u672c\u7684\u6784\u9020\u6a21\u5f0f</li> <li>NSP\u4efb\u52a1 \u5728\u505a input embedding\u7684\u65f6\u5019\uff0c\u8981\u533a\u5206\uff0c\u6709\u4e24\u4e2a\u7279\u6b8a\u7b26\u53f7\uff0c[CLS]\u548c[SEP]</li> <li>\u63a5\u4e0b\u6765\u770b \u6837\u672c\u7684\u6784\u9020\u6a21\u5f0f\uff1a</li> </ul> <ul> <li>\u7b2c\u4e00\u4e2a\u6b63\u6837\u672c\u662f \u4ece\u8bad\u7ec3\u8bed\u6599\u4e2d\uff0c\u53d6\u51fa\u4e24\u4e2a\u8fde\u7eed\u7684\u6bb5\u843d</li> </ul> <p>\u7406\u89e3\uff1a</p> <p>\u53d6\u51fa\u4e24\u4e2a\u8fde\u7eed\u7684\u6bb5\u843d\uff1a\u8bf4\u660e\u4e24\u4e2a\u6bb5\u843d\u6765\u81ea\u540c\u4e00\u7bc7\u6587\u6863\uff0c\u4e00\u4e2a\u6587\u6863\u662f\u4e00\u4e2a\u4e3b\u9898\uff0c\u5c31\u662f\u8bf4 \u540c\u4e00\u4e2a\u4e3b\u9898\u4e0b \u4e24\u4e2a\u8fde\u7eed\u7684\u6bb5\u843d\uff0c\u987a\u5e8f\u4e5f\u6ca1\u6709\u98a0\u5012\uff0c\u4f5c\u4e3a\u6b63\u6837\u672c</p> <ul> <li>\u8d1f\u6837\u672c\uff0c\u4ece\u4e0d\u540c\u6587\u6863\u4e2d\u968f\u673a\u521b\u5efa\u4e00\u5bf9\u6bb5\u843d \u4f5c\u4e3a\u8d1f\u6837\u672c\uff0c\u533a\u522b\u5c31\u5728 \u8d1f\u6837\u672c\u662f\u4ece\u4e0d\u540c\u7684\u6587\u6863\u4e2d\u62bd\u53d6\u3001\u968f\u673a\u521b\u5efa\u4e00\u5bf9\u6bb5\u843d\uff0c\u4e5f\u5c31\u662f\u4e0d\u540c\u7684\u4e3b\u9898\uff0c\u968f\u4fbf\u521b\u5efa</li> </ul> <ul> <li>\u7f3a\u70b9\u662f\uff1a\u4e3b\u9898\u9884\u6d4b\u548c\u8fde\u8d2f\u6027\u9884\u6d4b\u5408\u5e76\u4e3a\u4e00\u4e2a\u5355\u9879\u4efb\u52a1</li> </ul> <ul> <li> <p>\u4e3b\u9898\u9884\u6d4b \u5c31\u662f \u5224\u65ad\u4e24\u4e2a\u6837\u672c \u662f\u5426\u6765\u81ea\u540c\u4e00\u7bc7\u6587\u6863</p> </li> <li> <p>\u8fde\u8d2f\u6027\u9884\u6d4b\u5c31\u662f \u5224\u65ad\u4e24\u4e2a\u6bb5\u843d \u662f\u4e0d\u662f\u987a\u5e8f\u5173\u7cfb</p> </li> </ul> <ul> <li> <p>\u4e3b\u9898\u9884\u6d4b\u662f\u6bd4\u8f83\u7b80\u5355\u7684\uff0c\u6240\u4ee5\u6574\u4e2a\u4efb\u52a1\u5728\u9884\u6d4b\u7684\u65f6\u5019\uff0c\u5c31\u5f88\u7b80\u5355</p> </li> <li> <p>\u4e5f\u5c31\u662f\u8bf4 \u76f8\u6bd4\u4e8e\u8fde\u8d2f\u6027\u9884\u6d4b\uff0c\u4e3b\u9898\u9884\u6d4b\u975e\u5e38\u5bb9\u6613\u5b66\u4e60</p> </li> <li> <p>\u8fd9\u4e5f\u662f\u540e\u7eed\u5f88\u591a\u4efb\u52a1 \u9a8c\u8bc1 NSP\u4efb\u52a1 \u6ca1\u6709\u6548\u679c\u7684\u539f\u56e0\uff0c\u662f\u56e0\u4e3a \u5b58\u5728\u4e3b\u9898\u9884\u6d4b\u8fd9\u4e00\u4e2a\u5355\u4efb\u52a1\uff0c\u8ba9\u6574\u4e2a\u9884\u6d4b\u4efb\u52a1\u7b80\u5355\u4e86</p> </li> <li> <p>\u800c\u540e\u7eed\u7684\u6539\u8fdb\uff0c\u6bd4\u5982 ALBert\uff0c\u76f4\u63a5\u5c31\u629b\u5f03\u6389\u4e86 \u4e3b\u9898\u9884\u6d4b\uff0c\u800c\u662f\u53bb\u505a\u7c7b\u4f3c\u8fde\u8d2f\u6027\u9884\u6d4b\u7684\u4efb\u52a1\uff0c\u5c31\u662f\u9884\u6d4b \u53e5\u5b50\u987a\u5e8f</p> </li> <li> <p>\u5bf9\u4e8ealbert\u6765\u8bf4\uff0c\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\u90fd\u662f\u6765\u81ea\u4e8e\u540c\u4e00\u7bc7\u6587\u6863</p> </li> </ul> <ul> <li>\u6b63\u6837\u672c\u5c31\u662f \u540c\u4e00\u7bc7\u6587\u6863\u4e2d\uff0c\u4e24\u4e2a\u53e5\u5b50 \u987a\u5e8f\u7684\u53e5\u5b50</li> <li>\u8d1f\u6837\u672c \u5c31\u662f \u4e24\u4e2a\u53e5\u5b50 \u98a0\u5012\u8fc7\u6765</li> <li>\u4f46\u662f \u6b63\u6837\u672c \u548c \u8d1f\u6837\u672c \u90fd\u662f\u6765\u81ea\u540c\u4e00\u6587\u6863</li> </ul>"},{"location":"learning/5_Bert/#3-bertbert","title":"3  \u5982\u4f55\u5fae\u8c03Bert\uff0c\u63d0\u5347Bert\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6548\u679c","text":"<p>\u63a5\u4e0b\u6765\u770b\uff0c\u5982\u4f55\u5728\u4e0b\u6e38\u4efb\u52a1 \u5fae\u8c03bert</p> <p></p> <p>\u4e3b\u8981\u5206\u4e3a\u56db\u79cd\uff1a</p> <ol> <li>\uff08a\uff09\u6587\u672c\u5206\u7c7b\uff0c\u8868\u793a\u53e5\u5b50\u7684\u5206\u7c7b\u4efb\u52a1\uff0c\u662f\u53e5\u5b50\u5bf9\u7684\u5206\u7c7b\u4efb\u52a1</li> <li>\uff08b\uff09\u5355\u4e2a\u53e5\u5b50\u7684\u5206\u7c7b\u4efb\u52a1</li> <li>\uff08c\uff09\u95ee\u7b54</li> <li>\uff08d\uff09\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1</li> </ol> <p>\u6700\u5e38\u7528\u7684\uff1a\u6587\u672c\u5206\u7c7b\u3001\u5e8f\u5217\u6807\u6ce8\u3001\u6587\u672c\u5339\u914d</p> <ul> <li>\u4ee5 \u5e8f\u5217\u6807\u6ce8 \u4e3a\u4f8b\uff1a\u628a\u6240\u6709\u7684 token \u8f93\u51fa \u8fdb\u884c\u4e00\u4e2asoftmax\uff0c\u5224\u8bfb \u5c5e\u4e8e \u5b9e\u4f53 \u4e2d\u7684\u54ea\u4e00\u4e2a</li> <li>\u5bf9\u4e8e\u5355\u4e2a\u6837\u672c\u7684 \u6587\u672c\u5206\u7c7b \u5c31\u662f \u4f7f\u7528 [CLS] \u7684\u8f93\u51fa\uff0c\u505a\u4e00\u4e2a\u5fae\u8c03\uff0c\u505a\u4e00\u4e2a\u4e8c\u5206\u7c7b \u6216\u8005 \u591a\u5206\u7c7b\uff0c\u672c\u8d28\u5c5e\u4e8e \u6587\u672c\u5339\u914d\u7684\u4efb\u52a1</li> <li>\u6587\u672c\u5339\u914d \u5c31\u662f\u628a\u4e24\u4e2a\u53e5\u5b50\u62fc\u63a5\u8d77\u6765\uff0c\u5224\u65ad\u53e5\u5b50\u662f\u5426\u76f8\u4f3c\uff0c\u7528[CLS]\u8f93\u51fa\uff0c\"0\"\u8868\u793a\u4e0d\u76f8\u4f3c\uff0c\"1\"\u8868\u793a\u76f8\u4f3c</li> </ul> <p>\u73b0\u5728\u8ba8\u8bba \uff1a</p> <p></p> <p>\u56e0\u4e3a \u5728\u5b9e\u9645\u5e94\u7528\u4e2d \u5f88\u5c11\u81ea\u5df1\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u4e00\u4e2abert\uff0c\u66f4\u591a\u7684\u662f\uff0c\u5229\u7528\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684bert\uff0c\u7136\u540e\u5728\u81ea\u5df1\u7684\u4efb\u52a1\u4e2d\u5fae\u8c03</p> <p></p> <p>\u73b0\u5728\u66f4\u4e00\u822c\u7684\u505a\u6cd5\u662f\uff1a</p> <ul> <li>\u5148\u83b7\u53d6 \u8c37\u6b4c\u4e2d\u6587 \u6216\u8005 \u5176\u4ed6\u516c\u53f8\u7684 bert</li> <li>\u7136\u540e\u57fa\u4e8e\u81ea\u5df1\u7684\u4efb\u52a1\u6570\u636e \u8fdb\u884c\u5fae\u8c03</li> </ul> <p>\u8981\u8ffd\u6c42\u66f4\u597d\u7684\u6027\u80fd\uff0c\u6709\u5f88\u591a\u7684trick\u53ef\u4ee5\u505a\uff0c\ud83d\udc47\ud83c\udffb</p>"},{"location":"learning/5_Bert/#trick","title":"\u7b2c\u4e00\u4e2atrick","text":"<p>\u628a \u4e24\u4e2a\u6b65\u9aa4 \u5206\u4e3a 4\u4e2a\u6b65\u9aa4\uff0c\u6bd4\u5982\u73b0\u5728\u505a \u5fae\u535a\u60c5\u611f\u5206\u6790</p> <ul> <li>\u9996\u5148\u5728\u5927\u91cf\u901a\u7528\u8bed\u6599\u505a\u4e00\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u8fd9\u4e00\u6b65\u4e0d\u7528\u81ea\u5df1\u505a\uff0c\u901a\u5e38\u7528\u4e00\u4e2a\u4e2d\u6587\u8c37\u6b4c\u7684bert\u5c31\u53ef\u4ee5</li> <li>\u7b2c\u4e8c\u90e8\u5206\uff0c\u5c31\u662f\u5728\u76f8\u540c\u9886\u57df\u7684\u6587\u672c\u4e0a\uff0c\u7ee7\u7eed\u8bad\u7ec3language model\uff0c\u4e5f\u53eb\u505a \u9886\u57df\u7684\u81ea\u9002\u5e94 \u6216\u8005\u8bf4 \u9886\u57df\u8fc1\u79fb\uff0c\u4e5f\u5c31\u662f\u5728\u5927\u91cf\u7684\u5fae\u535a\u6587\u672c\u4e0a\u7ee7\u7eed\u8bad\u7ec3\u8fd9\u4e2abert</li> <li>\u7b2c\u4e09\u4e2a\u5c31\u662f\u5728\u4efb\u52a1\u76f8\u5173\u7684\u5c0f\u6570\u636e\u4e0a\u7ee7\u7eed\u8bad\u7ec3language model\uff0c\u5c31\u662f\u7b2c\u4e8c\u6b65\u4e2d\u5927\u91cf\u7684\u5fae\u535a\u6587\u672c\u4e2d\uff0c\u6709\u5f88\u591a\u4e0d\u5c5e\u4e8e \u5fae\u535a\u60c5\u611f\u5206\u6790\u7684\u6570\u636e\uff0c\u4f7f\u5f97\u6587\u672c\u66f4\u805a\u7126\u4e8e \u4e0e\u5fae\u535a\u60c5\u611f\u5206\u6790\u66f4\u76f8\u5173\u7684\u6570\u636e\uff0c\u7ee7\u7eed\u8bad\u7ec3language model</li> <li>\u7b2c\u56db\u4e2a\u6b65\u9aa4\uff0c\u5728\u5177\u4f53\u7684\u5fae\u535a\u60c5\u611f\u5206\u6790\u4efb\u52a1\uff0c\u6bd4\u5982\u6bd4\u8d5b\u7ed9\u7684\u6570\u636e\u96c6\u8fdb\u884c fine tune</li> <li>\u4e00\u822c\u7684\u7ecf\u9a8c\u5c31\u662f\u5148\u505a\u9886\u57df\u7684\uff0c\u7136\u540e\u518d\u505a\u4efb\u52a1\u7684\uff0c\u6700\u540e\u5fae\u8c03\u6027\u80fd\u662f\u6700\u597d\u7684</li> <li>\u76f8\u5f53\u4e8e\u628a\u4e0a\u9762\u7684\u4e24\u4e2a\u6b65\u9aa4\uff0c\u6269\u5c55\u62104\u4e2a\u6b65\u9aa4\uff0c\u6548\u679c\u4e00\u822c\u53ef\u4ee5\u63d0\u5230 3-4\u4e2a\u70b9\u5de6\u53f3</li> </ul>"},{"location":"learning/5_Bert/#32-trick","title":"3.2 \u7b2c\u4e8c\u4e2atrick","text":"<p>\u7b2c\u4e8c\u4e2a\u90e8\u5206</p> <p></p> <p>\u5728\u5927\u91cf\u7684\u5fae\u535a\u6587\u672c\u4e0a\u8bad\u7ec3bert\uff0c\u4e5f\u76f8\u5f53\u4e8e\u8bad\u7ec3bert</p> <p>\u4e5f\u6709trick\uff0c\u4e24\u4e2a\u5173\u4e8emask\u7684\ud83d\udc47\ud83c\udffb</p> <p></p> <ul> <li>\u7b2c\u4e00\u4e2a\uff0c\u52a8\u6001mask\uff0cbert\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u4f7f\u7528\u7684\u662f\u56fa\u5b9a\u7684mask\uff0c\u5c31\u662f\u628a\u6587\u672cmask\u4e4b\u540e\uff0c\u5b58\u5728\u672c\u5730\uff0c\u7136\u540e\u6bcf\u6b21\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u90fd\u662f\u4f7f\u7528\u540c\u4e00\u4e2a\u6587\u4ef6\uff0c\u5c31\u662f\u6bcf\u6b21\u8bad\u7ec3\u7684\u65f6\u5019\u4f7f\u7528\u7684\u90fd\u662f\u540c\u4e00\u4e2amask\u6807\u8bb0\uff0c\u4ee5 \"\u6211\u7231\u5403\u996d\" \u4e3e\u4f8b\uff0c\u6bcf\u6b21\u8bad\u7ec3\u90fd\u662fmask\u6389 \"\u5403\"\uff0c\u8fd9\u662f\u4e0d\u592a\u597d\u7684\uff1b\u6240\u4ee5\u52a8\u6001mask\u5c31\u662f \u6bcf\u6b21epoch\u8bad\u7ec3\u4e4b\u524d\uff0c\u7136\u540e\u518d\u5bf9\u6570\u636e\u8fdb\u884cmask\uff0c\u76f8\u5bf9\u4e8e\u6bcf\u4e2aepoch\u6765\u8bf4\uff0cmask\u7684\u5355\u8bcd\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u800c\u4e0d\u662f\u4e00\u76f4\u4f7f\u7528\u540c\u4e00\u4e2a\u6587\u4ef6</li> <li>\u7b2c\u4e8c\u4e2a n-gram mask</li> </ul>"},{"location":"learning/5_Bert/#33trick","title":"3.3\u7b2c\u4e09\u4e2atrick","text":"<p>\u53c2\u6570\u7684\u8bbe\u8ba1</p> <p></p>"},{"location":"learning/5_Bert/#4-bert","title":"4 Bert\u4ee3\u7801\u5b9e\u6218","text":"<p>\u6765\u81ea\uff1a</p> <p>\u6570\u5b66\u5bb6\u662f\u6211\u7406\u60f3</p>"},{"location":"learning/5_Bert/#5-bert","title":"5 bert\u539f\u7406","text":""},{"location":"learning/5_Bert/#51","title":"5.1 \u6587\u5b57\u63cf\u8ff0","text":"<p>\u9996\u5148\uff0cbert\u7528\u7684\u662f\u7684Transformer Encoder\u7684\u90e8\u5206</p> <p>\u63a5\u6536\u7684\u8f93\u5165\u662f <code>the cat sat on the mat</code></p> <p></p> <p>\u8f93\u5165\u5230\u7f51\u7edc\u4e2d\uff0c\u9996\u5148\u505a\u4e00\u4e2aembedding</p> <p>embedding\u5728Transformer\u4e2d\u63a5\u6536\u4e24\u4e2a\u4e1c\u897f= word embedding+Position embedding\uff08encoding\uff09</p> <p>\u901a\u8fc7embedding\u4e4b\u540e\uff0c\u5f97\u5230\u6bcf\u4e2a\u8bcd\u5bf9\u5e94\u7684\u8f93\u51fa</p> <p>\u63a5\u7740\u628a\u6bcf\u4e2a\u8bcd\u7684\u8f93\u51fa\uff0c\u9001\u5165\u5230Transformer Encoder\u4e2d\uff1a</p> <p></p> <p>Encoder\u4e2d\u5305\u542b\u4e00\u4e2a\u6b8b\u5dee\u8fde\u63a5\u3001\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3001LayerNorm\uff0c\u518d\u7ecf\u8fc7FFN \u524d\u9988\u5168\u8fde\u63a5\u7f51\u7edc</p> <p>\u63a5\u7740\u5806\u53e0\u8fd9\u4e2aEncoderLayer\u7684\u7ed3\u6784\uff08\u7ee7\u7eed\u6b8b\u5dee\u8fde\u63a5....\uff09\u5806\u53e06\u5c42</p> <p>Bert\uff0c\u9996\u5148\u968f\u673a\u63a9\u76d6\u4e00\u4e9b\u8bcd\uff1a</p> <p></p> <p>\u6bd4\u5982 \u7b2c\u4e8c\u4e2a\u8bcd mask\u6389</p> <p></p> <p>\u7f51\u7edc\u8f93\u51fa \u9884\u6d4b\u7684\u6982\u7387\uff0c\u4f7f\u5f97\u9884\u6d4b\u7684\u6982\u7387\u65e0\u9650\u63a5\u8fd1 cat\u7684\u72ec\u70ed\u7f16\u7801\u5411\u91cf</p> <p></p> <p></p> <p>\u4ee5\u4e0a\u662fbert\u53ef\u4ee5\u89e3\u51b3\u7684\u7b2c\u4e00\u4e2a\u4efb\u52a1</p> <p>\u7b2c\u4e8c\u4e2a\u4efb\u52a1\uff1a\u9884\u6d4b\u4e0b\u4e00\u4e2a\u53e5\u5b50</p> <p></p> <p>\u9884\u6d4b\u4e24\u4e2a\u53e5\u5b50\u662f\u5426\u662f\u8fde\u7eed\u53e5\u5b50</p> <p></p> <p>\u6216\u8005\u5224\u65ad\"it was developed by newton and leibniz\"\u662f\u4e0d\u662f \"calculus is a branch of math\"\u7684\u4e0b\u4e00\u4e2a\u53e5\u5b50</p> <p>\u8f93\u51fa\u5e94\u8be5\u662f true\u6216\u8005\u662ffalse</p> <p></p> <p>\u90a3\u5177\u4f53\u600e\u4e48\u505a\u5462\uff1f</p> <p>\u9996\u5148\u5728\u53e5\u5b50\u7684\u5f00\u5934\u52a0\u5165 [CLS] token\uff0c\u5728\u4e24\u4e2a\u53e5\u5b50\u7684\u4e2d\u95f4\u52a0\u5165 [SEP]</p> <p></p> <p>\u7136\u540e\u7ecf\u8fc7 \u4e24\u4e2a Encoder \u5f97\u5230\u4e24\u4e2a\u8f93\u51fa</p> <p>\u7136\u540e\u6211\u4eec\u628a [CLS] token\u7684 \u5bf9\u5e94\u7684 C\u8fdb\u884c\u4e00\u4e2a \u4e8c\u5206\u7c7b \u4efb\u52a1</p> <p></p> <p>\u901a\u8fc7nn.Linear\u6620\u5c04\u4e3a\u4e00\u4e2a\u4e24\u7ef4\u7684?\u5411\u91cf\uff0c\u6bd4\u59820\u6216\u80051</p> <p>\u95ee\u9898\uff1a\u4e3a\u4ec0\u4e48\u4e0d\u7528 first sentence\u7684\u7b2c\u4e00\u4e2a\u8bcd \u6bd4\u5982 calculus \u5bf9\u5e94\u7684 \\(u_1\\) \u8fdb\u884c\u4e8c\u5206\u7c7b\u5462\uff1f\u6216\u8005 \\(u_2\\) \u5462\uff1f</p> <p>\u56de\u7b54</p> <p></p> <p>\u81ea\u6ce8\u610f\u529b\u673a\u5236 \u81ea\u5df1\u5bf9\u81ea\u5df1\u7684\u5173\u6ce8\u6700\u5927\uff0c\u5982\u679c\u6a21\u578b\u66f4\u5173\u6ce8\u6709\u610f\u4e49\u7684\u8bcd\u4f1a\u5f71\u54cd\u6a21\u578b\u7684\u7ed3\u679c\uff0c\u6240\u4ee5[CLS]\u76f8\u5f53\u4e8e\u5360\u4f4d\u7b26\uff0c\u5305\u542b\u6240\u6709\u4fe1\u606f</p> <p>\u63a5\u4e0b\u6765\u8ba1\u7b97 loss\uff0c\u7136\u540ebackward\u5373\u53ef</p> <p></p>"},{"location":"learning/5_Bert/#52-bert","title":"5.2 bert\u7684\u5177\u4f53\u65b9\u6cd5\u7ed3\u5408\u4e24\u79cd\u4efb\u52a1","text":"<p>\u6bd4\u5982\u8bf4 \u6709\u4e24\u53e5\u8bdd\uff1a</p> <p></p> <ul> <li>\u5728\u6bcf\u4e00\u53e5\u8bdd\u5f53\u4e2d\uff0c\u8fdb\u884cmask\uff0c\u7136\u540e\u628a\u4e24\u53e5\u8bdd\u62fc\u8d77\u6765</li> <li>\u662f\u4e00\u4e2a\u591a\u4efb\u52a1\u7684\u5b66\u4e60\u65b9\u6cd5</li> <li>\u9996\u5148\u5224\u65ad\u662f\u5426\u4e3a\u8fde\u7eed\u7684\u4e24\u53e5\u8bdd\uff0c<code>true or false</code></li> <li>\u5e76\u4e14\u8ba1\u7b97 mask\u7684\u4f4d\u7f6e\u662f\u4ec0\u4e48\u8bcd</li> <li>\u6240\u4ee5bert\u6a21\u578b\u6709\u5f88\u591aloss\uff0c\u6bd4\u5982\u5206\u7c7b\u662f\u4e0d\u662f\u8fde\u7eed\u7684\u4e24\u53e5\u8bdd \u662f\u4e00\u4e2aloss\uff0c\u6709\u591a\u4e2amask\u5c31\u6709\u591a\u4e2aloss\uff0c\u628a\u6240\u6709\u7684loss\uff0c\u5168\u90e8\u52a0\u8d77\u6765\uff0c\u6c42\u548c</li> </ul> <p></p> <ul> <li>\u6c42\u548c\u4e4b\u540e\uff0c\u5728\u8fdb\u884cbackward\uff0c\u5c31\u662f <code>sum of the three loss functions</code></li> </ul> <p>\u4ee5\u4e0a\u662fbert\u7684\u6574\u4e2a\u8fc7\u7a0b</p>"},{"location":"learning/5_Bert/#53-mlm","title":"5.3 MLM\u5b9e\u9645\u4f8b\u5b50","text":"<p>\u63a5\u4e0b\u6765\u7ec6\u8282\uff1a</p> <p>\u9996\u5148\u9884\u6d4b\u54ea\u4e2a\u8bcd\uff1f</p> <p></p> <p>\u5047\u5982\u6709100\u4e2a\u8bcd\uff0c\u6211\u4eec\u9009\u51fa15\u4e2a\u8bcd</p> <p>\u5728\u8fd915\u4e2a\u8bcd\u5f53\u4e2d\uff1a</p> <ol> <li>\u6bcf\u4e2a\u8bcd\u670980%\u7684\u6982\u7387 \u4f1a\u88ab\u6539\u4e3a mask\uff0c\u6bd4\u5982  \"my dog is hairy\" \u6539\u6210 \"my dog is [MASK]\"</li> <li>\u6bcf\u4e2a\u8bcd \u8fd8\u670910%\u7684\u6982\u7387\uff0c\u4f1a\u88ab\u66ff\u6362\u6210\u4efb\u610f\u4e00\u4e2a\u5176\u4ed6\u7684 token\uff0c\u6bd4\u5982 \"my dog is hairy\"\u6539\u6210 \"my dog is apple\"\uff08\u601d\u8003\u4e3a\u4ec0\u4e48\u8fd9\u6837\u505a\uff1f\u540e\u9762\u4f1a\u8bf4\uff09</li> <li>\u6bcf\u4e2a\u8bcd \u8fd8\u6709 10%\u7684\u6982\u7387 \u539f\u5c01\u4e0d\u52a8\uff0c\"my dog is hairy\" \u8fd8\u662f \"my dog is hairy\"</li> </ol> <p>\u7b2c1\u70b9\u548c\u7b2c2\u70b9\u5f88\u597d\u7406\u89e3\uff0c\u90a3\u4e3a\u4ec0\u4e48\u63d0\u51fa\u7b2c3\u70b9\u5462\uff1f</p> <p>\u8fd9\u662f\u5f88\u5de7\u5999\u7684\u5730\u65b9\uff0c\u5e0c\u671b\u6a21\u578b \u8f93\u51fa\u7684 hairy  \u8fd8\u662f hairy\uff0c\u8fd9\u6837\u505a\u7684\u597d\u5904\u5728\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u8ba9\u6a21\u578b\u771f\u6b63\u7406\u89e3\u8fd9\u4e2a\u53e5\u5b50\uff0c\u56e0\u4e3a\"my dog is hairy \"\u53ef\u80fd\u4f1a\u9884\u6d4b\u51fa\u522b\u7684\u8f93\u51fa\uff0c\u6bd4\u5982\"my dog is jack\"\u3001\"my dog is merry\"\uff0c\u5c31\u4e0d\u662f \"hairy\" \u7684\u610f\u601d \uff0c\u4e22\u5931\u539f\u59cb\u7684\u8bed\u4e49</p> <p>\u5173\u4e8e\u7b2c2\u70b9\uff1a</p> <p></p> <p>\u4e00\u53e5\u8bdd\uff1a\u4e3a\u4e86\u9632\u6b62\u6a21\u578b\u8fc7\u4e8e\u76f8\u4fe1 \u5f53\u524d\u7684\u8bcd\uff0c\u800c\u662f\u5e0c\u671b\u6a21\u578b\u53bb\u89c2\u5bdf\u4e0a\u4e0b\u6587</p> <p>\u4ee5\u4e0a\u662fbert\u7684\u7b2c\u4e00\u4e2a\u4efb\u52a1 MLM\uff1a\u63a9\u76d6\u4e00\u4e9b\u8bcd\uff0c\u8fdb\u884c\u9884\u6d4b</p> <p></p>"},{"location":"learning/5_Bert/#531-nsp","title":"5.3.1 NSP\u5b9e\u9645\u4f8b\u5b50","text":"<p>\u9996\u5148\u5bf9\u8f93\u5165\u53e5\u5b50</p> <ol> <li>\u52a0\u5165 \u7279\u6b8a\u5b57\u7b26[SEP]\uff08seperate\uff09[CLS]\uff08class\uff09</li> <li>bert\u6709 \u4e09\u4e2aembedding\u3001Transformer\u67092\u4e2aembedding\uff081\u4e2aembedding+1\u4e2aencoding\uff09\uff0c\u6709\u4e24\u70b9\u4e0d\u540c</li> </ol> <p>\uff081\uff09bert\u591a\u4e86\u4e00\u4e2a segment embedding\uff0c\u4f5c\u7528\u662f \u5224\u65ad\u53e5\u5b50\u5c5e\u4e8e\u7b2c\u4e00\u53e5\u8fd8\u662f\u7b2c\u4e8c\u53e5\uff0c\u5c31\u662f\u5f88\u7b80\u5355\u7684\uff0c\u6bd4\u5982\\(E_A\\)\u5168\u662f\u7b2c\u4e00\u53e5\u7684\uff0c\u90a3\u5c31\u5168\u90e8\u5199\u6210 0\uff0c\\(E_B\\) \u662f\u7b2c\u4e8c\u53e5\uff0c\u90a3\u5c31\u5168\u90e8\u5199\u62101</p> <p></p> <p>\uff082\uff09\u7b2c\u4e8c\u70b9\u4e0d\u540c\uff0cpositional embedding\u5728bert\u4e2d\u662f\u53ef\u8bad\u7ec3\u7684\uff0c\u7c7b\u4f3c <code>nn.embedding</code> \uff0c\u5728Transformer\u4e2d\u662f\u4e09\u89d2\u51fd\u6570\u8868\u793a\u7684\u5e38\u6570\u4f4d\u7f6e\u7f16\u7801</p> <p>\u6700\u540e\u5c06\u4e09\u4e2aembedding\u76f8\u52a0\uff0c\u5f97\u5230embedding layer\u7684\u8f93\u51fa</p> <p></p> <p></p>"},{"location":"learning/5_Bert/#532-multi-task-learning","title":"5.3.2 Multi-Task Learning","text":""},{"location":"learning/5_Bert/#533","title":"5.3.3 \u5fae\u8c03\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1","text":"<p>\u5982\u4f55\u4f7f\u7528 bert fine tune\u5e94\u7528\u5230\u522b\u7684\u4efb\u52a1\u4e0a</p>"},{"location":"learning/5_Bert/#_1","title":"\u7b2c\u4e00\u79cd\u4efb\u52a1\uff1a\u5206\u7c7b\u95ee\u9898","text":"<p>\u60c5\u611f\u5206\u6790\u3001\u6587\u672c\u5206\u7c7b</p> <p>\u9996\u5148[CLS]\u6807\u5fd7\uff0c\u63a5\u7740\u628a\u53e5\u5b50\u6216\u8005\u6587\u7ae0\u653e\u5230\u540e\u9762 \\(w_1\u3001w_2\u3001w_3\\)</p> <p>bert\u8fd9\u91cc\u7684\u53c2\u6570\u53ef\u4ee5\u662ffrozen\u51bb\u4f4f\u7684\uff0c\u6216\u8005fine_tune \u5fae\u8c03\u7684</p> <p>[CLS] \u7684\u8f93\u51fa \u7ecf\u8fc7 \u4e00\u4e2a\u7ebf\u6027\u5206\u7c7b\u5668\uff0c\u7ebf\u6027\u5206\u7c7b\u5668 \u662f\u4ece\u5934\u5f00\u59cb\u5b66\u4e60\u7684\uff0c\u5f97\u5230\u4e00\u4e2aclass\u8f93\u51fa</p>"},{"location":"learning/5_Bert/#slot-filling","title":"\u7b2c\u4e8c\u79cd\u4efb\u52a1:slot filling","text":"<p>slot filling?</p> <p>\u6bd4\u5982\u6709\u4e00\u4e2a\u53e5\u5b50 \"arrive Taipei on November 2nd\" \uff0c\u6807\u6ce8\uff1a\"Taipei\" \u662f\" \u5730\u70b9\"\u3001\"November\" \u662f\" \u65f6\u95f4\" </p> <p>\u5c31\u662f\u628a\u53e5\u5b50\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8bcd \u8fdb\u884c\u4e00\u4e2a\u5206\u7c7b\uff0c\u6bd4\u5982 \"on\" \u662f \"other\" \u7c7b\u522b\uff0c\"Taipei\" \u662f\" \u5730\u70b9\"\u7c7b\u522b</p> <p>\u6bcf\u4e2a\u8bcd \u90fd\u8fdb\u884c\u4e00\u4e2a\u7ebf\u6027\u5206\u7c7b\u5668\uff0c\u5f97\u5230\u4e00\u4e2a\u8f93\u51fa</p>"},{"location":"learning/5_Bert/#_2","title":"\u7b2c\u4e09\u79cd\u4efb\u52a1\uff1a\u81ea\u7136\u8bed\u8a00\u63a8\u7406","text":"<p>\u81ea\u7136\u8bed\u8a00\u63a8\u7406</p> <p>\u5c31\u662f\u7ed9\u5b9a\u4e00\u4e2a\u524d\u63d0\uff0c\u7ed9\u5b9a\u4e00\u4e2a\u5047\u8bbe</p> <p>\u5e0c\u671bbert\u63a8\u7406\u51fa true\u3001false\u3001unknown\uff08\u4e0d\u77e5\u9053\uff09</p> <p>\u4f8b\u5b50\uff1a</p> <p>\u7ed9\u51fa\u524d\u63d0\uff1a\u5730\u7403\u56f4\u7ed5\u592a\u9633\u8f6c</p> <p>\u5047\u8bbe\uff1a\u660e\u5929\u6211\u4eec\u8981\u8003\u8bd5</p> <p>\u4e24\u8005\u4e4b\u95f4\u6ca1\u6709\u4efb\u4f55\u5173\u7cfb\uff0c\u50cf\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5c31\u8981\u5224\u522b\u5047\u8bbe\u662f\u5bf9\u7684\u5417\uff1f\u5176\u5b9e\u662f\u4e0d\u77e5\u9053\uff0c\u6240\u4ee5\u8f93\u51fa unknown</p> <p>\u56e0\u6b64\u8fd9\u4e2a\u5c5e\u4e8e\u4e09\u5206\u7c7b\u7684\u95ee\u9898</p> <p></p> <ul> <li>\u524d\u63d0 \u548c \u5047\u8bbe \u901a\u8fc7 [SEP]\u5206\u9694\u5f00</li> <li>[CLS]  token \u62ff\u51fa\u6765 \u901a\u8fc7\u7ebf\u6027\u5206\u7c7b\u5668 \u9884\u6d4b\uff0c\u5f97\u5230\u8f93\u51fa true\u3001false\u3001unknown</li> </ul>"},{"location":"learning/5_Bert/#_3","title":"\u7b2c\u56db\u79cd\u4efb\u52a1\uff1a\u95ee\u7b54","text":"<p>\u95ee\u7b54</p> <p>\u6bd4\u5982 \u73b0\u5728\u6709\u4e00\u7bc7\u6587\u7ae0\uff0c\u73b0\u5728\u6709\u4e00\u4e2a\u95ee\u9898\uff0c\u8981\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898</p> <p>\u9996\u5148\uff0c\u5047\u8bbe \u95ee\u9898\u7684\u7b54\u6848\u4e00\u5b9a\u662f\u539f\u6587\u4e2d\u51fa\u73b0\u7684\u8bcd \u6216\u8005 \u8fde\u7eed\u7684\u53e5\u5b50</p> <p></p> <p>\u6bd4\u5982\u8fd9\u4e2a\u95ee\u9898\u7684\u7b54\u6848\uff0c\u662f\u539f\u6587\u7684\u7b2c17\u4e2a\u8bcd\u5230\u7b2c17\u4e2a\u8bcd\uff08s\u8868\u793a\u5f00\u59cb\uff0ce\u8868\u793a\u7ed3\u675f\uff09</p> <p>\u5177\u4f53\u6765\u8bf4\uff1a</p> <p></p> <p>\u5148\u628aquestion\u8fd9\u4e2a\u53e5\u5b50 \u653e\u5230\u524d\u9762\uff0c[SEP]\u5206\u9694\u4e24\u4e2a\u53e5\u5b50\uff0cdocument\u653e\u5230\u540e\u9762</p> <p>\u6700\u524d\u9762 \u52a0\u5165 [CLS]</p> <p>\u901a\u8fc7bert\uff0c\u5bf9document\u4e2d \u6bcf\u4e2a\u8bcd\u7684\u8f93\u51fa \u9ec4\u8272\u7684\u5411\u91cf \u4e58\u4ee5\u4e00\u4e2a \u6a59\u8272\u7684\u5411\u91cf\uff0c\u6a59\u8272\u7684\u5411\u91cf \u5c31\u662f nn.Linear\uff0c\u8fdb\u884c\u4e00\u4e2adot product\uff0c\u7136\u540e\u7ecf\u8fc7\u4e00\u4e2asoftmax \uff0c\u5f97\u5230\u6982\u7387\u503c\uff0c\u5176\u4e2d\u6700\u5927\u503c\u6982\u7387\u4e3a0.5\uff0c\u5bf9\u5e94 \u7b2c\u4e8c\u4e2a\u8bcd\uff0c\u4e5f\u5c31\u662f\u8bf4 \u95ee\u9898\u7684\u7b54\u6848\u4ece\u6587\u7ae0\u7684\u7b2c\u4e8c\u4e2a\u8bcd\u4f5c\u4e3a\u5f00\u59cb\uff0c\u90a3\u7ed3\u675f\u5462\uff1f</p> <p></p> <p>\u7ed3\u675f\u5c31\u662f \u84dd\u8272\u7684\u5411\u91cf \u4e58\u4ee5 \u9ec4\u8272\u7684\u5411\u91cf \u8fdb\u884c dot product\uff0c\u7136\u540e\u901a\u8fc7softmax\uff0c\u5f97\u5230\u6982\u7387\u6700\u5927\u503c=0.7\uff0c\u5bf9\u5e94\u7b2c\u4e09\u4e2a\u8bcd\uff0c\u5c31\u8ba4\u4e3ae = d\u7b2c\u4e09\u4e2a\u8bcd</p> <p>\u4e5f\u5c31\u662f\u8bf4\u7b54\u6848 \u4ece \u7b2c\u4e8c\u4e2a\u8bcd \u5230 \u7b2c\u4e09\u4e2a\u8bcd</p> <p>\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\uff1as&gt;e?</p> <p></p> <p>\u4e3e\u4e2a\u4f8b\u5b50\uff1a\u6587\u6863\u662f \u5b5f\u5b50\u5b54\u5b50\u4e2d\u56fd\u5386\u53f2\uff0c\u95ee\u9898\uff1a\u795e\u5dde\u4e94\u53f7\u4ec0\u4e48\u65f6\u5019\u53d1\u5c04\u3002\u8fd9\u65f6\u5c31\u662f\u6ca1\u6709\u7b54\u6848\u7684\u3002</p>"},{"location":"learning/5_Bert/#54","title":"5.4 \u4ee3\u7801\u5b9e\u6218","text":"<p>Rereference1</p> <p>Reference2</p>"},{"location":"learning/6_Diffusion/","title":"DDPM","text":""},{"location":"learning/6_Diffusion/#ddpm","title":"DDPM","text":"2024-12-03 09:54:572025-09-28 12:54:04 <p> \u7ea6 7451 \u4e2a\u5b57  24 \u884c\u4ee3\u7801  89 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 38 \u5206\u949f</p> <p>Probabilistic Diffusion Model</p> <p>What are Diffusion Models?</p> <p>Probabilistic Diffusion Model\u6982\u7387\u6269\u6563\u6a21\u578b\u7406\u8bba\u4e0e\u5b8c\u6574PyTorch\u4ee3\u7801\u8be6\u7ec6\u89e3\u8bfb</p> <p>\u600e\u4e48\u7406\u89e3\u4eca\u5e74 CV \u6bd4\u8f83\u706b\u7684\u6269\u6563\u6a21\u578b\uff08DDPM\uff09\uff1f</p> <p>Diffusion Model\u5b66\u4e60\u7b14\u8bb0(1)\u2014\u2014DDPM</p> <p>\u53c2\u8003\u6587\u732e\uff1a</p> <p>\uff081\uff092015\u5e74 \uff1a \u57fa\u4e8e\u975e\u5e73\u8861\u70ed\u529b\u5b66\u8fdb\u884c\u6df1\u5ea6\u65e0\u76d1\u7763\u5b66\u4e60</p> TeX<pre><code>@inproceedings{10.5555/3045118.3045358,\nauthor = {Sohl-Dickstein, Jascha and Weiss, Eric A. and Maheswaranathan, Niru and Ganguli, Surya},\ntitle = {Deep unsupervised learning using nonequilibrium thermodynamics},\nyear = {2015},\npublisher = {JMLR.org},\nbooktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},\npages = {2256\u20132265},\nnumpages = {10},\nlocation = {Lille, France},\nseries = {ICML'15}\n}\n</code></pre> <p>\u6df1\u5ea6\u65e0\u76d1\u7763\u5b66\u4e60\u5c31\u662f\u751f\u6210\u7167\u7247</p> <p></p> <p>\uff082\uff092020\u5e74\uff1a\u53bb\u566a\u6982\u7387\u6a21\u578b</p> <p></p> TeX<pre><code>@inproceedings{10.5555/3495724.3496298,\nauthor = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},\ntitle = {Denoising diffusion probabilistic models},\nyear = {2020},\nisbn = {9781713829546},\npublisher = {Curran Associates Inc.},\naddress = {Red Hook, NY, USA},\nbooktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},\narticleno = {574},\nnumpages = {12},\nlocation = {Vancouver, BC, Canada},\nseries = {NIPS '20}\n}\n</code></pre> <ul> <li>\u6269\u6563\u6a21\u578b\u5f00\u59cb\u6d41\u884c\u5b9e\u884c2020\u5e74\u7684\u8fd9\u7bc7\u8bba\u6587\uff0c2021\u5e74\u30012022\u5e74\u5f00\u59cb\u6709\u5927\u91cf\u8bba\u6587\u51fa\u73b0</li> <li> <p>\u76ee\u524d\uff1aDDPM 2020\u5e74\u8fd9\u7bc7\u8bba\u6587\u7684\u5f15\u7528\u91cf\u5df2\u7ecf220\u4e07\uff0c2015\u5e74\u8bba\u6587\u7684\u5f15\u7528\u91cf\u4e5f\u6709200\u591a\u4e07</p> </li> <li> <p>\u6269\u6563\u6a21\u578b\u662f\u4e00\u79cd\u751f\u6210\u5f0f\u6a21\u578b\uff1aGAN\u7684\u4efb\u52a1\u3001VAE\u7684\u4efb\u52a1\u3001FLOW\u7684\u4efb\u52a1\u90fd\u53ef\u4ee5\u7528Diffusion Model</p> </li> </ul>"},{"location":"learning/6_Diffusion/#1","title":"1 \u6c47\u603b\u751f\u6210\u6a21\u578b","text":"<p>\uff081\uff09\u7b2c\u4e00\u7c7b\u751f\u6210\u6a21\u578b\uff1aSeq2Seq\u6a21\u578b\uff0c\u81ea\u56de\u5f52\u7684\u89e3\u7801\u6a21\u578b</p> <p>\uff082\uff09\u7b2c\u4e8c\u7c7b\u751f\u6210\u6a21\u578b\uff1a\u57fa\u4e8eGAN\u7684\u6a21\u578b\uff0c\u6ca1\u6709\u663e\u5f0f\u7684\u5bf9\u76ee\u6807\u5206\u5e03\u8fdb\u884c\u5efa\u6a21\uff0c\u53ea\u662f\u5c06\u751f\u6210\u7684\u6570\u636e\u653e\u5230\u4e0b\u6e38\u7684\u5224\u522b\u5668\u4e2d\uff0c\u4ee5\u5bf9\u6297\u7684\u65b9\u5f0f\u4f7f\u5f97\u751f\u6210\u5668\u8fbe\u5230\u7406\u60f3\u7684\u76ee\u6807\u5206\u5e03</p> <p>\uff083\uff09\u7b2c\u4e09\u7c7b\u751f\u6210\u6a21\u578b\uff1aFLOW\u6a21\u578b\uff1aFLOW\u6a21\u578b\u7684\u6570\u5b66\u539f\u7406\u6bd4\u8f83\u4e25\u8c28\uff0c\u662f\u4e00\u4e2a\u5b8c\u5168\u53ef\u9006\u7684\u8fc7\u7a0b\uff0c\u4e3a\u4e86\u8ba9FLOW\u6a21\u578b\u53d8\u5f97\u53ef\u89e3\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u4e9b\u5de7\u5999\u7ed3\u6784\uff0c\u4f7f\u5f97\u5bf9\u6570\u4f3c\u7136\u5b8c\u5168\u53ef\u89e3\uff0c\u4e5f\u662f\u56e0\u4e3a\u8bbe\u8ba1\u7684\u5de7\u5999\u7684\u7ed3\u6784\uff0c\u9650\u5236\u4e86FLOW\u7684\u6027\u80fd</p> <p>\uff084\uff09\u7b2c\u56db\u7c7b\u751f\u6210\u6a21\u578b\uff1aVAE</p> <p>\uff085\uff09\u7b2c\u4e94\u7c7b\u751f\u6210\u6a21\u578b\uff1aDiffusion\uff1a\u5176\u4e2dVAE\u548cDiffusion\u6a21\u578b\u5176\u5b9e\u6709\u70b9\u50cf</p> <p></p>"},{"location":"learning/6_Diffusion/#2","title":"2 \u524d\u7f6e\u6570\u5b66\u77e5\u8bc6","text":""},{"location":"learning/6_Diffusion/#kl","title":"\u4e00\u3001\u6761\u4ef6\u6982\u7387\u516c\u5f0f\u4e0e\u9ad8\u65af\u5206\u5e03\u7684KL\u6563\u5ea6","text":"<p>1\u3001\u6761\u4ef6\u6982\u7387\u7684\u4e00\u822c\u516c\u5f0f</p> <ul> <li> <p> \uff081\uff09P(A,B,C)=P(A)P(B|A)P(C|A,B)</p> </li> <li> <p> \uff082\uff09P(B,C|A) = P(B|A)P(C|A,B)</p> </li> </ul> <p>2\u3001\u57fa\u4e8e\u9a6c\u5c14\u79d1\u592b\u5047\u8bbe\u7684\u6761\u4ef6\u6982\u7387</p> <p>\u4ec0\u4e48\u53eb \u9a6c\u5c14\u79d1\u592b\u5047\u8bbe\uff1f</p> <p>\u5f53\u524d\u65f6\u523b\u7684\u8f93\u51fa \u53ea\u4e0e \u4e0a\u4e00\u65f6\u523b\u6709\u5173\uff0c\u8ddf\u8fc7\u53bb\u4ee5\u53ca\u66f4\u8fdc\u7684\u65e0\u5173</p> <p>\u5982\u6211\u4eec\u73b0\u5728\u6709\u9a6c\u5c14\u79d1\u592b\u94fe\uff1aA\u2192B\u2192C\uff0c\u5219\u4e0a\u9762\u7684\uff081\uff09\u3001\uff082\uff09\u53ef\u4ee5\u8fdb\u884c\u7b80\u5316\uff1a</p> <p>P(A,B,C)\u53ef\u4ee5\u5199\u6210\uff1aP(A,B)P(C|A,B) \u7ee7\u7eed\u5199\u6210\uff1aP(A)P(B|A)P(C|A,B)</p> <p>\u56e0\u4e3a A\u662fB\u7684\u4e0a\u4e00\u65f6\u523b\uff0c\u6240\u4ee5\u4fdd\u7559 P(B|A)</p> <p>\u56e0\u4e3aA\u8ddd\u79bbC\u6bd4\u8f83\u8fdc\uff0c\u4e0d\u518d\u662fC\u7684\u4e0a\u4e00\u65f6\u523b\uff0c\u6240\u4ee5 P(C|A,B)\u5199\u6210P(C|B)</p> <p>\u6240\u4ee5\u5728\u6ee1\u8db3\u9a6c\u5c14\u79d1\u592b\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\uff0c\u6761\u4ef6\u6982\u7387\u5199\u6210\uff1a</p> <ul> <li> \uff083\uff09P(A,B,C)=P(A)P(B|A)P(C|B)</li> </ul> <p>\u540c\u7406\u7b80\u5316P(B,C|A)\uff0c\u5f97\u5230\uff1a</p> <ul> <li> \uff084\uff09P(B,C|A) = P(B|A)P(C|B)</li> </ul> <p>3\u3001\u4e24\u4e2a\u9ad8\u65af\u5206\u5e03\u7684KL\u6563\u5ea6\u516c\u5f0f </p> <p>\u660e\u767dVAE\u7684\u8bdd\uff0cKL\u6563\u5ea6\u516c\u5f0f\u4f1a\u5f88\u6e05\u695a</p> <p></p> <p>\u5bf9\u4e8e\u4e24\u4e2a\u5355\u4e00\u53d8\u91cf\u7684\u9ad8\u65af\u5206\u5e03p\u548cq\u6765\u8bf4\uff0c\u5747\u503c\u662f \\(\\mu_1\\) \u548c \\(\\mu_2\\) \uff0c\u65b9\u5dee\u662f \\(\\sigma_1^2\\)\u3001\\(\\sigma_2^2\\)</p> <p>\u5219\u5b83\u4eec\u7684KL\u6563\u5ea6\u516c\u5f0f\uff1a</p> <p>\\(KL(p,q)=log\\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma^2+(\\mu_1-\\mu_2)^2}{2\\sigma^2_2}-\\frac{1}{2}\\)</p> <p>4\u3001\u53c2\u6570\u91cd\u6574\u5316\u7684\u6280\u5de7</p> <p>\u4ec0\u4e48\u662f\u53c2\u6570\u91cd\u6574\u5316\uff1f</p> <p>\u5047\u8bbe\u5e0c\u671b\u4ece \u5747\u503c\u4e3a \\(\\mu\\)\u3001\u65b9\u5dee\u4e3a \\(\\sigma^2\\) \u7684\u9ad8\u65af\u5206\u5e03 \\(N(\\mu,\\sigma^2)\\) \u4e2d\u91c7\u6837\uff0c\u5982\u679c\u76f4\u63a5\u91c7\u6837\u7684\u8bdd\uff0c\u4f1a\u9020\u6210\u4ec0\u4e48\u95ee\u9898\u5462\uff1f</p> <p>\u5982\u679c \\(\\mu\\) \u548c  \\(\\sigma\\) \u662f\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u51fa\u6765\u7684\u8bdd\uff0c\u76f4\u63a5\u53bb\u91c7\u6837\\(N(\\mu,\\sigma)\\)\uff0c\u5c31\u4f1a\u5bfc\u81f4\u4e0e \\(\\mu\\) \u548c\\(\\sigma\\) \u53c2\u6570\u65ad\u5f00\u4e86\uff0c\u68af\u5ea6\u65e0\u6cd5\u4f20\u56de\u53bb\u4e86\uff0c\u56e0\u4e3a\u91c7\u6837\u7684\u8fc7\u7a0b\u662f\u4e0d\u53ef\u5bfc\u7684\uff1b\u6240\u4ee5\u4e3a\u4e86\u8ba9\u91c7\u6837\u51fa\u6765\u7684\u6837\u672c\u8ddf \\(\\mu\\) \u548c \\(\\sigma\\) \u4e4b\u95f4\uff0c\u4ecd\u7136\u53ef\u4ee5\u68af\u5ea6\u53ef\u4f20\u64ad\u7684\uff0c\u4ecd\u7136\u662f\u53ef\u5bfc\u7684\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u628a\u8fd9\u4e2a\u91c7\u6837\u8fc7\u7a0b \u7b49\u4ef7\u4e8e \u9996\u5148\u4ece \\(N(0,1)\\) \u7684\u6807\u51c6\u5206\u5e03\u4e2d\uff0c\u91c7\u6837\u51fa z\uff0c\u628a z \u5f53\u6210\u662f\u4e00\u4e2a\u5e38\u6570\uff0c\u518d\u628az\u4e58\u4ee5\u539f\u6765\u5206\u5e03\u7684 \\(\\sigma\\) \u548c \\(\\mu\\) \uff0c\u4fdd\u8bc1\u4e86\u68af\u5ea6\u53ef\u4ee5\u56de\u4f20</p> <p>\u8fd9\u6837\u505a\u7684\u597d\u5904\u662f\uff0c\u8fd9\u6837\u7684\u91c7\u6837\u8fc7\u7a0b\u8f6c\u79fb\u5230\u4e86 z\u4e0a\uff0c   z\u53ef\u4ee5\u770b\u505a\u662f \u7f51\u7edc\u7684\u8f93\u5165    \uff0c\u6216\u8005\u5f53\u6210\u4e00\u4e2a\u5e38\u6570\uff0c\u91c7\u6837\u503c \\(y=\\sigma z+\\mu\\)\uff0c\\(y\\)\u4e0e \\(\\sigma\\) \u548c \\(y\\)\u4e0e \\(\\mu\\) \u4e4b\u95f4\u662f\u5b8c\u5168\u53ef\u5bfc\u7684</p> <p>\u5982\u679c\u4e0d\u8fd9\u6837\u505a\u7684\u8bdd\uff0c\\(y\\)\u5bf9\\(\\mu\\) \u548c \\(y\\)\u5bf9 \\(\\sigma\\) \u7684\u5bfc\u6570\u662f\u7b97\u4e0d\u51fa\u6765\u7684</p> <p>\u4ee5\u4e0a\u79f0\u4e3a\u53c2\u6570\u91cd\u6574\u5316</p> <p></p> <p>\u76ee\u7684\u5c31\u662f\u5e0c\u671b \u91c7\u6837\u51fa\u6765\u7684\u503c\uff0c\u8ddf \\(\\mu\\) \u548c \\(\\sigma\\) \u4e4b\u95f4 \u68af\u5ea6\u662f\u53ef\u5bfc\u7684</p> <p>\u8fd9\u5c31\u662f\u53c2\u6570\u91cd\u6574\u5316\u7684\u6280\u5de7\uff0c\u8fd9\u4e2a\u6280\u5de7\u5728VAE\u548cDiffusion\u4e2d\u5927\u91cf\u4f7f\u7528</p> <p>\u4ee5\u4e0a\u662f\u56de\u987e\uff0c\u63a5\u4e0b\u6765\u8bb2\u89e3\u4ec0\u4e48\u662fVAE\u4ee5\u53ca\u591a\u5c42VAE</p>"},{"location":"learning/6_Diffusion/#vaevae","title":"\u4e8c\u3001VAE\u4e0e\u591a\u5c42VAE\u56de\u987e","text":""},{"location":"learning/6_Diffusion/#1-vae","title":"1 \u5355\u5c42VAE&amp;\u7f6e\u4fe1\u4e0b\u754c","text":"<p>VAE\u7684\u539f\u7406\uff1a</p> <p>\u9996\u5148\u5355\u5c42VAE</p> <p>VAE\u8ba4\u4e3ax\u7531\u67d0\u4e00\u4e2a\u9690\u53d8\u91cfz\u751f\u6210</p> <p></p> <p>\u9690\u53d8\u91cfz\u5982\u4f55\u5f97\u5230\u5462\uff1f</p> <p>\u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u901a\u8fc7\\(q_{\\phi}(z|x)\\) \u4ecex\u4e2d\u751f\u6210z\uff0c\u5728\u63a8\u7406\u7684\u65f6\u5019\uff0c\u4ecez\u9884\u6d4bx</p> <p>\u8865\u5145\uff1a\u4ece z \u5230 x \u662f\u751f\u6210\u8fc7\u7a0b\uff0c\u7f51\u7edc\u8bad\u7ec3\u597d\u4e86\u4ee5\u540e\u53ea\u9700\u8981\u751f\u6210\u5c31\u884c\uff0c\u800c\u4e0d\u9700\u8981\u4ece x \u5230 z \u7684\u7f16\u7801\u8fc7\u7a0b\u4e86</p> <p>\u7b49\u4ef7\u4e8e  \u8bad\u7ec3\u65f6\u8bad\u7ec3\u4e24\u4e2a\u7f51\u7edc\uff0c\u63a8\u7406\u65f6\u53ea\u7528\u5230 z \u5230 x \u7684\u7f51\u7edc</p> <p>\u4ee5\u4e0a\u5c31\u662f\u5355\u5c42VAE</p> <p>\u516c\u5f0f\uff1a</p> <p></p> <p>\u7528\u516c\u5f0f \u6982\u62ec\u76ee\u6807\u6570\u636e\u5206\u5e03\uff1a</p> <p>\uff081\uff09p(x)\u53ef\u4ee5\u5199\u6210\u8054\u5408\u6982\u7387\u5206\u5e03\uff0c\u5bf9z\u8fd9\u4e2a\u53d8\u91cf\u8fdb\u884c\u79ef\u5206\uff0c\u5f97\u5230\u8fb9\u7f18\u5206\u5e03\uff1a</p> <p>\\(p(x) = \\int_zp_{\\theta}(x|z)p(z)\\)</p> <p>\u5199\u6210\u4e00\u4e2a \\(\u6761\u4ef6\u6982\u7387\\) \u548c \\(p(z)\\) \u76f8\u4e58\u7684\u5f62\u5f0f</p> <p>\uff082\uff09\u5bf9\uff081\uff09\u4e58\u4ee5\u540e\u9a8c\u6982\u7387\u5206\u5e03\u7684\u5f62\u5f0f\uff0c\u540e\u9a8c\u662f\u5e0c\u671b\u4ecex\u53bb\u9884\u6d4bz\u8fd9\u4e2a\u9690\u53d8\u91cf\uff0c\u4e0a\u4e0b\u5206\u522b\u4e58\u4ee5 $q_{\\phi} $  z  given  x \u5c31\u662f\\(q_{\\phi}(z|x)\\) \uff1a</p> <p>\\(p(x)= \\int q_{\\phi}(z|x) \\frac{p_{\\theta}(x|z)p(z)}{q_{\\phi}(z|x)}\\)</p> <p>\u8fd9\u4e2a\u5f0f\u5b50\u76f8\u5f53\u4e8e  \\(\\frac{p_{\\theta}(x|z)p(z)}{q_{\\phi}(z|x)}\\)  \u5728 \\(q_{\\phi}\\) \u5206\u5e03\u4e0b\u7684\u671f\u671b</p> <p>\uff083\uff09\u5bf9\uff082\uff09\u5de6\u53f3\u4e24\u8fb9\u540c\u65f6\u53d6\\(log\\)\uff0c\u5f97\u5230\\(logp(x)\\)</p> <p>\u53f3\u8fb9\u5199\u6210\u671f\u671b\u7684\u5f62\u5f0f\uff1a</p> <p>\\(logp(x)\\)  \u5c31\u662f\u4e00\u4e2a\u5bf9\u6570\u4f3c\u7136</p> <p>\\(logp(x) = log \\mathbb{E}_{z \\sim q_{\\phi}(z|x)}[\\frac{p_{\\theta}(x|z)p(z)}{q_{\\phi(z|x)}}]\\)</p> <p>\uff084\uff09\u6839\u636e\u8a79\u68ee\u4e0d\u7b49\u5f0f\uff0clog\u79fb\u5230\u671f\u671b\u91cc\u9762\uff0c\u5f97\u5230\uff1a</p> <p>\\(logp(x)  \\ge  \\mathbb{E}_{z \\sim q_{\\phi}(z|x)}[log \\frac{p_{\\theta}(x|z)p(z)}{q_{\\phi(z|x)}}]\\) </p> <p>\u7ecf\u8fc7\u4ee5\u4e0a\u7684\u63a8\u5bfc\uff0c\u5f97\u5230\u76ee\u6807\u6570\u636e\u5206\u5e03\u7684\u4e0b\u754c\uff0c\u8bad\u7ec3\u7f51\u7edc\u7684\u76ee\u7684\u662f\u6700\u5927\u5316 \\(logp(x)\\)\uff0c\u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136\uff0c\u6700\u5927\u5316 \\(logp(x)\\) \u4e0d\u597d\u6c42\uff0c\u5c31\u53ef\u4ee5 \u6700\u5927\u5316  \\(\\mathbb{E}_{z \\sim q_{\\phi}(z|x)}[log \\frac{p_{\\theta}(x|z)p(z)}{q_{\\phi(z|x)}}]\\) </p> <p>\u56e0\u4e3a    \\(logp(x)  \\ge  \\mathbb{E}_{z \\sim q_{\\phi}(z|x)}[log \\frac{p_{\\theta}(x|z)p(z)}{q_{\\phi(z|x)}}]\\)    \u8fd9\u4e2a\u4e0d\u7b49\u5f0f\u6c38\u8fdc\u6210\u7acb</p> <p>\u63a5\u4e0b\u6765\uff0c\u601d\u8003\uff0c\u600e\u4e48\u6700\u5927\u5316 \\(\\mathbb{E}_{z \\sim q_{\\phi}(z|x)}[log \\frac{p_{\\theta}(x|z)p(z)}{q_{\\phi(z|x)}}]\\) \uff1f</p> <p>\u770b\u6210\u4e24\u90e8\u5206</p> <p>\u7b2c\u4e00\u90e8\u5206\uff1a\\(log p_{\\theta}(x|z)\\)</p> <p>\u770b\u6210\u662f\u9884\u6d4b\u7f51\u7edc\uff0c\u57fa\u4e8e\u9884\u6d4b\u51fa\u6765\u7684\u9690\u53d8\u91cfz\u9884\u6d4bx\uff0c\u8fd9\u4e00\u90e8\u5206\u597d\u6c42\uff0c\u4e0e\u76ee\u6807\u6570\u636e\u7684\u5206\u5e03\u4f5c\u5dee\u5373\u53ef</p> <p>\u7b2c\u4e8c\u90e8\u5206\uff1a\\(log\\frac{p(z)}{q_{\\phi}(z|x)}\\)</p> <p>\u8fd9\u90e8\u5206\u5206\u5b50\u3001\u5206\u6bcd\u6c42\u5012\u6570\uff0c\u53d8\u6210\\(-log\\frac{q_{\\phi}(z|x)}{p(z)}\\)</p> <p>\u53c8 \u56e0\u4e3a\u5728 \\(q_{\\phi}\\) \u5206\u5e03\u4e0b\u7684\u671f\u671b \\(\\mathbb{E}_{z \\sim q_{\\phi}(z|x)}\\) \uff0c\u6240\u4ee5\u8fd9\u4e2a\u5f0f\u5b50\u53d8\u6210 \\(q_{\\phi}\\) \u4e0e \\(p_z\\) \u4e4b\u95f4\u7684KL\u6563\u5ea6</p> <p>\u4e8e\u662f\u4e0b\u754c\u53d8\u6210\uff1a</p> <p>\\(\\mathbb{E}_{z \\sim q_{\\phi}(z|x)}[log \\frac{p_{\\theta}(x|z)p(z)}{q_{\\phi(z|x)}}]\\)</p> <p>\\(= log p_{\\theta}(x|z) - KL\u6563\u5ea6(q_{\\phi} \u4e0e p)\\)</p> <p>\\(p\\) \u4e00\u822c\u60c5\u51b5\u4e0b\u53ef\u4ee5\u5047\u8bbe\u670d\u4ece\u9ad8\u65af\u5206\u5e03</p> <p>\u56e0\u6b64\uff0c\\(q_{\\phi}\\)  \u53ef\u4ee5\u9884\u6d4b\u9ad8\u65af\u5206\u5e03</p> <p>\u7531\u4e8e\u4e24\u4e2a\u9ad8\u65af\u5206\u5e03\u4e4b\u95f4\u7684KL\u6563\u5ea6\u662f\u53ef\u89e3\u7684\uff0c\u6240\u4ee5\u6574\u4e2aVAE\u7684\u76ee\u6807\u51fd\u6570\uff0c\u4e5f\u662f\u53ef\u4ee5\u5199\u51fa\u6765\u7684\uff0c\u4ee5\u4e0a\u662f\u5355\u5c42VAE\u7684\u539f\u7406</p> <p>\u63a5\u4e0b\u6765\uff0c\u591a\u5c42VAE</p>"},{"location":"learning/6_Diffusion/#2-vae","title":"2 \u591a\u5c42VAE\u53ca\u7f6e\u4fe1\u4e0b\u754c","text":"<p>\u591a\u5c42VAE</p> <p>\u5047\u8bbe\u8fd9\u91cc\u7684x \u4e0d\u662f\u7531\u4e00\u4e2a\u9690\u53d8\u91cf \u751f\u6210\u7684\uff0c\u800c\u662f\u7531 2\u4e2a\u751f\u6210</p> <p></p> <p>\u4e00\u5f00\u59cb\u7684\u9690\u53d8\u91cf\u79f0\u4e3a \\(z_2\\) \uff0c\u901a\u8fc7 \\(z_2\\) \u751f\u6210 \\(z_1\\)\uff0c\u518d\u901a\u8fc7 \\(z_1\\)  \u751f\u6210 \\(x\\)</p> <p>\u8fd9\u6837\u7684\u751f\u6210\u8fc7\u7a0b\u53eb\u505a\u591a\u5c42VAE</p> <p>(1)\u6b64\u65f6\u7684\u76ee\u6807\u5206\u5e03 \\(p(x)\\) \uff0c\u53ef\u4ee5\u5199\u6210\u4e00\u4e2a\u8054\u5408\u6982\u7387\u5206\u5e03\uff0c\u7136\u540e\u628a \\(z_1\\) \u3001\\(z_2\\)  \u79ef\u6389\uff0c\u5f97\u5230 \\(p(x)\\)\uff1a</p> <p>\\(p(x) = \\int_{z_1}\\int_{z_2}p_{\\theta}(x,z_1,z_2)dz_1dz_2\\)</p> <p>(2)\u5206\u5b50\u5206\u6bcd \u540c\u65f6\u4e58\u4ee5 \u540e\u9a8c\u5206\u5e03\uff1a</p> <p>\\(p(x) = \\int_{z_1}\\int_{z_2}q_{\\phi}(z_1,z_2|x)\\frac{p_{\\theta}(x,z_1,z_2)}{q_{\\phi}(z_1,z_2|x)}dz_1dz_2\\)</p> <p>(3)\u7ee7\u7eed\u5c06(2)\u5199\u6210\u671f\u671b\u7684\u5f62\u5f0f\uff1a\\(p(x) = \\mathbb{E}_{z_1,z_2\\sim q_{\\phi}(z_1,z_2|x)}[\\frac{p_{\\theta}(x,z_1,z_2)}{q_{\\phi}(z_1,z_2|x)}]\\)</p> <p>(4) \u540c\u6837\u5bf9(3)\u4e24\u8fb9\u53d6\u4e00\u4e2a\u5bf9\u6570\uff0c\u5229\u7528\u8a79\u68ee\u4e0d\u7b49\u5f0f\uff0c\u5f97\u5230\\(log(p(x))\\) \u7684\u4e0b\u754c\uff1a</p> <p></p> <p>(5)\u5bf9(4)\uff0c\u501f\u52a9\u4e4b\u524d\u8bf4\u8fc7\u7684\u516c\u5f0f\uff0c\u5728\u9a6c\u5c14\u79d1\u592b\u5047\u8bbe\u7684\u6761\u4ef6\u4e0b\uff0c\u53ef\u4ee5\u5199\u6210\uff1a</p> <p></p> <p>(6)\u5c06(5)\u4ee3\u5165(4)\uff0c\u5f97\u5230</p> <p></p> <p>\u4ee5\u4e0a\u662f\u591a\u5c42VAE\u7684\u76ee\u6807\u51fd\u6570</p> <p></p> <p>\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6709\u4e24\u6b21 \u9996\u5148\u4ece \\(x\\)\u4e2d\u63a8\u7406\u51fa\\(z\\)\uff0c\u7136\u540e\u4ece\\(z\\)\u4e2d\uff0c\u63a8\u7406\u51fa\\(x\\)</p> <p>\u8fd9\u4e2a\u8fc7\u7a0b\u8ddfDiffusion\u5f88\u50cf</p>"},{"location":"learning/6_Diffusion/#diffusion","title":"\u4e09\u3001Diffusion\u56fe\u793a","text":"<p>\uff081\uff09</p> <p></p> <p>\uff082\uff09\u8bb2\u89e3\u4e86Diffusion\u662f\u600e\u4e48\u4e00\u56de\u4e8b</p> <p></p> <p>Diffusion\u4ece\u76ee\u6807\u5206\u5e03 \\(x_0\\) \u4e2d\u52a0\u566a\uff0c\u53bb\u751f\u6210\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u4e00\u4e2a\u5206\u5e03 \\(x_T\\) \uff0c\u7528\u7684\u65f6\u5019\u4ece\u6700\u7ec8\u5206\u5e03 \\(x_T\\) \uff0c\u9010\u6b65\u9010\u6b65\u7684\u5f97\u5230\u76ee\u6807\u5206\u5e03  \\(x_0\\)</p> <p>\u6240\u4ee5Diffusion\u7684\u76ee\u6807\u51fd\u6570\u8ddf\u591a\u5c42VAE\u7684\u76ee\u6807\u51fd\u6570\u662f\u5f88\u50cf\u7684</p> <p>\u601d\u8003\uff0c\u591a\u5c42VAE &amp; Diffusion\u4e4b\u95f4\u6709\u4ec0\u4e48\u5173\u8054\uff1f</p> <p>Diffusion\u5206\u4e3a\u4e24\u4e2a\u8fc7\u7a0b</p> <p>\u7b26\u53f7\u8bf4\u660e\uff1a\u76ee\u6807\u5206\u5e03\uff08\u8bb0\u4e3a \\(x_0\\)\uff09\uff0c\u566a\u58f0\u5206\u5e03 \\(x_T\\)</p> <p>\u7b2c\u4e00\u4e2a\u8fc7\u7a0b\uff1a\u6269\u6563\u8fc7\u7a0b</p> <p></p> <ul> <li>\u4ece \\(x_0\\)  \u5230 \\(x_T\\) \u71b5\u589e\u8fc7\u7a0b\uff0c\u4ece\u6709\u5e8f\u5230\u65e0\u5e8f</li> <li>\u60f3\u8c61 \u628a\u4e00\u4e2a\u6c34\u6ef4 \u5012\u5165\u5230 \u4e00\u4e2a\u6c60\u5858\u6216\u8005\u6cb3\u6d41\u4e4b\u4e2d\uff0c\u6162\u6162\u7684\u6269\u6563\uff0c\u6700\u540e\u6ca1\u6709\u4e86\u539f\u6765\u7684\u5206\u5e03</li> <li>\u6269\u6563\u8fc7\u7a0b \u5c31\u662f\u539f\u59cb\u7684\u8fc7\u7a0b\u4e2d \u4e0d\u65ad\u7684\u52a0\u566a\uff0c\u76f4\u5230\u6700\u540e\u53d8\u6210\u4e86 \u5404\u9879\u72ec\u7acb\u7684\u9ad8\u65af\u5206\u5e03</li> </ul> <p>\u751f\u6210\u7684\u65f6\u5019\uff0c\u662f\u5e0c\u671b\u4ece\u4e00\u4e2a\u566a\u58f0\u5206\u5e03\u4e2d\uff0c\u9010\u6b65\u9884\u6d4b\u51fa\u76ee\u6807\u5206\u5e03\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u53eb\u505a \u9006\u6269\u6563\u8fc7\u7a0b reverse </p> <p>\u7b2c\u4e8c\u4e2a\u8fc7\u7a0b\uff1a\u9006\u6269\u6563\u8fc7\u7a0b</p> <p></p> <p>\u9006\u6269\u6563\u8fc7\u7a0b\uff0c\u5c31\u662f\u57fa\u4e8e\u4e00\u4e2a\u566a\u58f0\uff0c\u80fd\u591f\u628a\u76ee\u6807\u5206\u5e03\u63a8\u5bfc\u51fa\u6765\uff0c\u4ece\u76ee\u6807\u5206\u5e03\u4e2d\uff0c\u91c7\u6837\u65b0\u7684\u6837\u672c\uff0c\u751f\u6210\u65b0\u7684\u56fe\u50cf</p> <p>DIffusion\u8981\u505a\u7684\u5c31\u662f\uff0c\u6709\u4e00\u5806\u76ee\u6807\u5206\u5e03\uff08\u6bd4\u5982\u6709\u4e00\u5806\u8fd9\u4e2a\u4eba\u7684\u7167\u7247\uff09\uff0c\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u628a\u9006\u6269\u6563\u8fc7\u7a0b\uff0c\u4e5f\u5c31\u662f\u4ece\\(x_T\\) \u5230 \\(x_0\\) \u7684\u539f\u7406\u641e\u51fa\u6765\uff0c\u6216\u8005\u8bf4\u516c\u5f0f\u9884\u6d4b\u51fa\u6765\uff0c\u7136\u540e\u968f\u673a\u7684\u751f\u6210\u566a\u58f0\u5206\u5e03\uff0c\u4ece\u800c\u80fd\u591f\u9884\u6d4b\u51fa\u65b0\u7684\u8fd9\u4e2a\u4eba\u7684\u7167\u7247\uff0c\u4ee5\u4e0a\u5c31\u662fDiffusion Model\u505a\u7684\u4e8b\u60c5</p> <p>\u8865\u5145\u4e24\u4e2a\u6761\u4ef6\u6982\u7387\u5206\u5e03\uff1a</p> <p></p> <ul> <li>\\(p_{\\theta}(x_{t-1}|x_t)\\) \uff1a \u8868\u793a\u9006\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u6761\u4ef6\u6982\u7387\u5206\u5e03</li> <li>\\(q(x_t|x_{t-1})\\) \uff1a\u8868\u793a\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u6761\u4ef6\u6982\u7387\u5206\u5e03</li> </ul> <p>\u800c\u6211\u4eec\u5728\u8fdb\u884c\u63a8\u7406\u7684\u65f6\u5019\uff0c\u53ea\u7528\u5230\u9006\u6269\u6563\u8fc7\u7a0b</p> <p>\u63a5\u4e0b\u6765\u7528\u56fe\u8868\u793a\u8fd9\u4e2a\u8fc7\u7a0b\uff1a</p> <p>\uff083\uff09</p> <p></p> <p>t=0\u65f6\uff0c\u5c31\u662f\u6807\u51c6\u7684\u76ee\u6807\u5206\u5e03\uff0c\u5c31\u662f\u89c4\u5219\u7684\u56fe\u5f62\uff0c\u63a5\u7740\u6211\u4eec\u9010\u6b65\u7684\u52a0\u566a\uff0c\u52a0\u5230\u4e00\u534a\u7684\u65f6\u5019\uff0c\u53d1\u73b0\u56fe\u5f62\u53d8\u5f97\u5f88\u6a21\u7cca\uff0c\u52a0\u5230\u6700\u7ec8\u7684\u65f6\u5019\uff0c\u5206\u5e03\u5df2\u7ecf\u5b8c\u5168\u5931\u53bb\u4e86\u539f\u8c8c\uff0c\u57fa\u672c\u5df2\u7ecf\u53d8\u6210\u4e86\u5404\u9879\u72ec\u7acb\u7684\u9ad8\u65af\u5206\u5e03\uff1a</p> <p></p> <p>\u9006\u6269\u6563\u7684\u8fc7\u7a0b\u4e5f\u662f\u540c\u6837\uff0c\u4e00\u5f00\u59cb\u7684\u65f6\u5019\uff0c\u751f\u6210\u4e00\u5806\u9ad8\u65af\u5206\u5e03\u7684\u566a\u58f0\uff0c\u7136\u540e\u57fa\u4e8e\u6a21\u578b\u4e0d\u65ad\u7684\u8fed\u4ee3\uff0c\u8fed\u4ee3\u5230t=0\u7684\u65f6\u5019\uff0c\u4e5f\u5c31\u662f T\u65f6\u523b\u7684\u8fed\u4ee3\uff0c\u751f\u6210\u65b0\u7684\u6837\u672c\uff0c\u65b0\u7684\u6837\u672c\u7684\u5206\u5e03\u8ddf\u539f\u6765\u6570\u636e\u662f\u4e00\u6837\u7684\uff0c\u4ece\u540c\u4e00\u4e2a\u5206\u5e03\u4e2d\uff0c\u91c7\u6837\u51fa\u6765\u7684\u65b0\u7684\u6837\u672c\uff0c\u4ee5\u4e0a\u662f\u9006\u6269\u6563\u8fc7\u7a0b\uff1a</p> <p></p> <p>\u6269\u6563\u8fc7\u7a0b\u548c\u9006\u6269\u6563\u8fc7\u7a0b\u7684\u5dee\u79f0\u4e3a\u6f02\u79fb\u91cf\uff1a</p> <p></p> <p>\u4ee5\u4e0a\u662f\u6269\u6563\u6a21\u578b\u7684\u5927\u81f4\u8fc7\u7a0b</p> <p>\u4ee5\u4e0a\u662f\u56fe\u793a\uff0c\u4e0b\u9762\u662f\u6b63\u5f0f\u7684\u63a8\u5bfc\u8fc7\u7a0b</p>"},{"location":"learning/6_Diffusion/#_1","title":"\u56db\u3001\u6269\u6563\u8fc7\u7a0b","text":"<p>\u9996\u5148\u660e\u767d\uff0c\u6269\u6563\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u8fc7\u7a0b\uff1a</p> <p>(1)\u6b63\u5411\u7684\u6269\u6563\u8fc7\u7a0b\uff0c\u4ece \\(x_0\\) \u5230 \\(x_T\\)</p> <p>(2)\u53cd\u5411\u7684\u9006\u6269\u6563\u8fc7\u7a0b\uff0c\u4ece \\(x_T\\) \u5230 \\(x_0\\)\uff08\u4e5f\u53ef\u4ee5\u53eb\u91cd\u5efa\u8fc7\u7a0b\uff09 \u4ece\u566a\u58f0\u4e2d \u91cd\u5efa\u76ee\u6807\u5206\u5e03</p> <p></p> <p>1\u3001\u9996\u5148\u770b\u6269\u6563\u8fc7\u7a0b\uff1a\u7ed9\u5b9a\u521d\u59cb\u6570\u636e\u5206\u5e03\uff0c\u901a\u4fd7\u4e00\u70b9\u5c31\u662f\u8bad\u7ec3\u96c6\u670d\u4ece\u5206\u5e03 \\(x_0 \\sim q(x)\\)\uff0c\u63a5\u7740\u4e0d\u65ad\u7684\u5411\u5206\u5e03\u4e2d\u6dfb\u52a0\u566a\u58f0\uff0c\u8fd9\u91cc\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\u90fd\u662f\u4e0d\u542b\u53c2\u6570\u7684\uff0c\u518d\u6b21\u5f3a\u8c03\uff0c\u6269\u6563\u8fc7\u7a0b\u7684\u6b63\u5411\u8fc7\u7a0b\u662f\u4e0d\u542b\u53c2\u6570\u7684\uff0c\u5c31\u662f\u5f80 \\(x_0\\) \u4e2d \u6dfb\u52a0\u9ad8\u65af\u566a\u58f0\u7684\u65f6\u5019\uff0c\u6bcf\u4e00\u6b65\u7684\u5747\u503c\u7684\u65b9\u5dee\u90fd\u662f\u786e\u5b9a\u7684\uff0c\u5c31\u6bd4\u5982\u5b66\u4e60\u7387\uff0c\u867d\u7136\u6bcf\u4e00\u6b65\u90fd\u5728\u53d8\u5316\uff0c\u4f46\u662f\u662f\u786e\u5b9a\u7684\uff0c\u800c\u4e0d\u662f\u7f51\u7edc\u9884\u6d4b\u7684\uff0c\u5e76\u4e14\u8fd9\u4e2a\u8fc7\u7a0b\u4e5f\u662f\u9a6c\u5c14\u79d1\u592b\u94fe\u7684\u8fc7\u7a0b\uff0c\u5373\u5f53\u524d\u65f6\u523b\u53ea\u4e0e\u4e0a\u4e00\u65f6\u523b\u76f8\u5173\uff0c\u4e0e\u8fc7\u53bb\u66f4\u8fdc\u7684\u65f6\u523b\u65e0\u5173\uff0c\u8fd9\u5c31\u662f\u7b2c\u4e00\u70b9\uff0c\u4e0d\u65ad\u7684\u5f80\u539f\u59cb\u5206\u5e03\u4e2d\uff0c\u53bb\u6dfb\u52a0\u9ad8\u65af\u566a\u58f0\uff0c\u4f46\u8fd9\u4e2a\u6dfb\u52a0\u4e0d\u662f\u7b80\u5355\u7684\u52a0\u6cd5\uff0c\u800c\u662f\u4eff\u5c04\u53d8\u6362\u7684\u8fc7\u7a0b\uff0c\u7b49\u4e0b\u4f1a\u57fa\u4e8e\u53c2\u6570\u91cd\u6574\u5316\u751f\u6210\u6bcf\u4e00\u65f6\u523b\u65b0\u7684\u6570\u636e\u5206\u5e03</p> <p></p> <p>2\u3001\u7b2c\u4e8c\u70b9\uff0c\u968f\u7740 t\u7684\u4e0d\u65ad\u589e\u5927\uff0c\u6211\u4eec\u6700\u7ec8\u7684\u6570\u636e\u5206\u5e03\u4f1a\u53d8\u6210 \u5404\u9879\u72ec\u7acb\u7684\u9ad8\u65af\u5206\u5e03\uff0c\u4e3a\u4ec0\u4e48\u4f1a\u8fd9\u6837\uff1f\u4e0b\u9762\u5f00\u59cb\u63a8\u5bfc\uff1a</p> <p>\u5728\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u6709\u5b9a\u4e49 \\(q(x_t|x_{t-1})\\)\uff1a\u4ece \\(x_0\\) \u53bb\u9884\u6d4b \\(x_1\\) \uff0c\u6216\u8005\u8bf4 \\(x_1\\) \u9884\u6d4b \\(x_2\\) \u7684\u8bdd\uff0c\u662f\u4e00\u4e2a\u6761\u4ef6\u6982\u7387\u5206\u5e03\uff0c\u5e76\u4e14\u8fd9\u4e2a\u6761\u4ef6\u6982\u7387\u5206\u5e03\u662f\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03\uff0c\u8fd9\u4e2a\u9ad8\u65af\u5206\u5e03\u7684\u5747\u503c\u662f \\(\\sqrt{1-\\beta_t}x_{t-1}\\)\uff0c\u65b9\u5dee\u662f \\(\\beta_tI\\) \uff0c\u4e5f\u5c31\u662f\u8bf4 \u6bcf\u6b21\u52a0\u566a\u7684\u9ad8\u65af\u5206\u5e03\uff0c\u53ea\u7531\u5f53\u524d\u65f6\u523b\u7684 \\(x\\) \u548c\u4e00\u4e2a\u786e\u5b9a\u503c \\(\\beta_t\\) \u6709\u5173\uff0c\u662f\u5b8c\u5168\u4e0d\u542b\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\uff0c\u4ee5\u4e0a\u5c31\u662f\u6269\u6563\u8fc7\u7a0b\uff0c\u662f\u4e0d\u542b\u53c2\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4 \u6309\u7167\u516c\u5f0f\uff1a</p> <p></p> <p>\u8fed\u4ee3\u7684\u8bdd\uff0c\u53ef\u4ee5\u8ba1\u7b97 t=\u4efb\u610f\u65f6\u523b\u7684\uff0c\\(x_t\\) \u7684\u5206\u5e03\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u91c7\u6837\u51fa\u503c</p> <p>\u8fd8\u6709\u4e00\u4e2a\u8fed\u4ee3\u5f0f\uff0c\u7ed9\u5b9a \\(x_0\\) \u6c42\u51fa \\(x_{1:T}\\) \u7684\u8054\u5408\u5206\u5e03\uff0c\u5c31\u662f\u591a\u4e2a\u6761\u4ef6\u6982\u7387\u76f8\u4e58\u7684\u7ed3\u679c\uff0c\u662f\u4e00\u4e2a \u9a6c\u5c14\u79d1\u592b\u8fc7\u7a0b\uff0c\u4ee5\u4e0a\u662f\u4e00\u4e2a\u8054\u5408\u5206\u5e03</p> <p>\u95ee\u9898\uff1a\u600e\u4e48\u7b97\u51fa \\(x_t\\) \u5462\uff1f</p> <p>\u7b54\uff1a\u7528\u4e4b\u524d\u53c2\u6570\u91cd\u6574\u5316\u7684\u6280\u5de7\uff0c\u56e0\u4e3a\\(x_t\\)\u670d\u4ece\u7684\u5206\u5e03\u6709\uff1a\\(x_t|x_{t-1} \\sim \\mathcal{N}(\\sqrt{1-\\beta_t}x_{t-1},\\beta_tI)\\)\uff0c\u53ef\u4ee5\u4ece\u4e00\u4e2a\u6b63\u6001\u5206\u5e03\u4e2d \u751f\u6210\u4e00\u4e2a z\uff0c\u7136\u540e\u628a z\u4e58\u4ee5 \u6839\u53f7\u4e0b \\(\\beta_t\\)\uff0c\u518d\u52a0\u4e0a \\(\\sqrt{1-\\beta_t}x_{t-1}\\)\uff1a</p> <p>\\(\\sigma z + \\mu = \\sqrt{\\beta_t}z+\\sqrt{1-\\beta_t}x_{t-1}\\)\uff0c</p> <p>\u8fd9\u5c31\u662f \\(x_t\\) \u7684\u4e00\u4e2a\u91c7\u6837\u503c\uff0c\u7ecf\u8fc7\u4e0d\u65ad\u7684\u8fed\u4ee3\uff0c\u5f97\u5230 \\(x_{t+1}\\) \u7684\u91c7\u6837\u503c\uff0c\u6700\u7ec8\u5f97\u5230 \\(x_T\\) \u7684\u91c7\u6837\u503c</p> <p>\u95ee\u9898\uff1a\u5927T\u662f\u600e\u6837\u786e\u5b9a\u7684\uff0c\u4ee5\u53ca \\(\\beta_t\\) \u600e\u4e48\u8bbe\u7f6e\uff1f</p> <p>\u7b54\uff1a \\(\\beta_t\\) \u5728\u539f\u8bba\u6587\u4e2d\u662f \u51fa\u4e8e \\(0\\sim 1\\)\u4e4b\u95f4\u7684\u5c0f\u6570\uff0c\u5e76\u4e14\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\\(\\beta_t\\) \u662f\u8d8a\u6765\u8d8a\u5927\u7684</p> <p>\u4e5f\u5c31\u662f \\(\\beta_1 &lt; \\beta_2&lt;...&lt;\\beta_T\\)   \u628a  \\(\\beta_t\\) \u8bbe\u7f6e\u6210\u5c31\u50cf\u5b66\u4e60\u7387\u4e00\u6837\u8bbe\u7f6e\u6210\u4e0d\u65ad\u53d8\u5316\u7684\uff0c\u4e0d\u8fc7\u5b66\u4e60\u7387\u662f\u4e0d\u65ad\u964d\u4f4e\u7684\uff0c\u8fd9\u91cc\u7684 \\(\\beta_t\\) \u662f\u5728\u4e0d\u65ad\u53d8\u5927\u7684</p> <p>\u4ee5\u4e0a\u901a\u8fc7\u8fed\u4ee3\u7684\u65b9\u6cd5\u8ba1\u7b97 \\(x_t\\) \u7684\u91c7\u6837\u503c</p> <p>\u63a5\u4e0b\u6765 \u8bf4\u660e \u5f53 \\(T=\u4ec0\u4e48\\) \u7684\u65f6\u5019\uff0c\\(x_T\\) \u63a5\u8fd1\u4e8e\u4e00\u4e2a\u5404\u9879\u72ec\u7acb\u7684\u9ad8\u65af\u5206\u5e03</p> <p></p> <p>\u4efb\u610f\u65f6\u523b\u7684 \\(q(x_t)\\) \uff0c\u53ef\u4ee5\u4e0d\u7528 \u5b8c\u5168\u4e00\u6837\u7684 \u57fa\u4e8e\u4e0a\u9762\u7684\u516c\u5f0f\uff0c\u6bcf\u4e00\u6b65\u7684\u91c7\u6837\u8fed\u4ee3\u51fa\u6765\uff1a</p> <p></p> <p>\u800c\u662f\u53ef\u4ee5\u5b8c\u5168\u7684\u57fa\u4e8e \\(x_0\\)  \u548c \\(\\beta_t\\) \u8ba1\u7b97\u51fa\u6765\uff0c\u4e5f\u5c31\u662f\u7ed9\u51fa \\(x_0\\) \u521d\u59cb\u7684\u6570\u636e\u5206\u5e03\u548c \\(\\beta_t\\) \u4e00\u4e2a\u53d8\u6362\u503c\uff0c\u5c31\u53ef\u4ee5\u7b97\u51fa\u4efb\u610f\u65f6\u523b\u7684 \\(q(x_t)\\) \uff0c\u5c31\u4e0d\u7528\u4e00\u6b65\u6b65\u8fed\u4ee3\u4e86</p> <p>\u5177\u4f53\u7684\u8ba1\u7b97\u6b65\u9aa4\uff1a</p> <p></p> <p>\uff081\uff09 \\(x_t = \\sqrt{\\alpha_t}x_{t-1}+\\sqrt{1-\\alpha_t}z_{t-1}\\)</p> <p>\u9996\u5148\uff0c\\(x_t\\)  \u7528\u53c2\u6570\u91cd\u6574\u5316\u7684\u6280\u5de7 \u5199\u6210 \\(\\sqrt{\\alpha_t}x_{t-1}+\u6807\u51c6\u5dee\\)</p> <p>\\(\\sigma z + \\mu = \\sqrt{\\beta_t}z+\\sqrt{1-\\beta_t}x_{t-1}\\) </p> <p>\u8fd9\u91cc\u7684 \\(\\alpha_t = 1-\\beta_t\\)</p> <p>\u53ef\u4ee5\u770b\u5230\u539f\u6587\u90fd\u5199\u4e86</p> <p>\u4e5f\u5c31\u662f \\(x_t = \\sqrt{\\alpha_t}x_{t-1}+\\sqrt{1-\\alpha_t}z_{t-1}\\)</p> <p><code>\u5747\u503c + \u6807\u51c6\u5dee \u00d7 \u968f\u673a\u751f\u6210\u7684\u6b63\u6001\u5206\u5e03\u7684\u91cf</code></p> <p>\u4ee5\u4e0a\u5c31\u662f \u53c2\u6570\u91cd\u6574\u5316\u6280\u5de7</p> <p>\\(z_t\\) \u662f\u4ece \\(N(0,1)\\) \u4e2d\u91c7\u6837\u51fa\u6765\u7684 \u968f\u673a\u503c</p> <p>\uff082\uff09</p> <p></p> <p>\\(x_t = \\sqrt{\\alpha_t}x_{t-1}+\\sqrt{1-\\alpha_t}z_{t-1}\\)</p> <p>$=\\sqrt{\\alpha_t}(\\sqrt{\\alpha_{t-1}}x_{t-2}+\\sqrt{1-\\alpha_{t-1}}z_{t-2})+\\sqrt{1-\\alpha_t}z_{t-1} $</p> <p>$=\\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2}+\\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}z_{t-2}+\\sqrt{1-\\alpha_t}z_{t-1} $</p> <p>\\(\\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}z_{t-2}+\\sqrt{1-\\alpha_t}z_{t-1}\\)</p> <p>\u53ef\u4ee5\u53c2\u6570\u91cd\u6574\u5316\u4e3a \u53ea\u5305\u542b\u4e00\u4e2a \u968f\u673a\u53d8\u91cfz\u7684\u5f62\u5f0f\uff0c\u7406\u7531\uff1a</p> <p></p> <p>\u82e5\u7ed9\u51fa \\(X \\sim N(\\mu_1,\\sigma_1)\\) \\(Y\\sim N(\\mu_2,\\sigma_2)\\)</p> <p>\u5219 \\(aX+bY \\sim N(a\\mu_1+b\\mu_2,a^2\\sigma_1^2+b^2\\sigma_2^2)\\)</p> <p>\u6240\u4ee5 </p> <p>\\(\\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}z_{t-2}+\\sqrt{1-\\alpha_t}z_{t-1} \\sim N(0,\\alpha_t-\\alpha_t\\alpha_{t-1}+1-\\alpha_t)=N(0,1-\\alpha_{t-1}\\alpha_t)\\)</p> <p>\uff08\\(z_{t-1}\u3001z_{t-2} \\sim N(0,1)\\)\uff09</p> <p>\u6240\u4ee5 </p> <p>\\(\\sqrt{\\alpha_t}\\sqrt{1-\\alpha_{t-1}}z_{t-2}+\\sqrt{1-\\alpha_t}z_{t-1}\\) \u53ef\u4ee5\u91cd\u6574\u5316\u4e3a \\(\\sqrt{1-\\alpha_t\\alpha_{t-1}}\\bar z_{t-2}\\)</p> <p>\u4ee5\u4e0a\u63a8\u51fa  \u7b2c\u4e8c\u6b65</p> <p>\uff083\uff09</p> <p>\u4e00\u6b21\u7c7b\u63a8\uff0c\u5f97\u5230</p> <p></p> <ul> <li>z\u4ecd\u7136\u662f N(0,1) \u4e2d\u91c7\u6837\u51fa\u6765\u7684</li> <li>\\(x_t = \\sqrt{\\bar{\\alpha_t}}x_0 + \\sqrt{1-\\bar\\alpha_t}z\\)</li> <li>\\(\\bar \\alpha_t\\) \u8868\u793a\u8fde\u4e58</li> <li>\\(\\bar{z_{t-2}}\\) \u8868\u793a \u878d\u5408\u4e24\u4e2a\u9ad8\u65af\u5206\u5e03</li> </ul> <p></p> <p>\uff084\uff09</p> <p></p> <p>\u7531\u516c\u5f0f\u53ef\u77e5\uff0c\u5f53\u7ed9\u5b9a \\(x_0\\) \u7684\u65f6\u5019\uff0c\\(q(x_t|x_0)\\) \u7684\u5206\u5e03\u5176\u5b9e\u5c31\u662f \u4ee5 \\(\\sqrt {\\bar\\alpha_t} x_0\\) \u4e3a\u5747\u503c\uff0c\u4ee5 \\(\\sqrt{1-\\bar \\alpha_t }\\)\u4e3a\u65b9\u5dee\u7684\u9ad8\u65af\u5206\u5e03\uff0c\u8fd9\u4e5f\u5c31\u662f\u8bf4 \u5728\u7ed9\u5b9a \\(x_0\\) \u548c \\(\\beta_t\\) \u7684\u6761\u4ef6\u4e0b\uff0c\u53ef\u4ee5\u6c42\u51fa \\(q(x_t|x_0)\\)</p> <p>\uff08\u524d\u9762\u6211\u4eec\u5047\u8bbe\u4e86 \\(\\alpha_t = 1-\\beta_t\\)\uff0c\u6240\u4ee5 \\(\\beta_t\\) \u5df2\u7ecf \u5c31\u76f8\u5f53\u4e8e \\(\\alpha_t\\)\u5df2\u77e5\uff0c\u81ea\u7136\u7684 \\(\\bar \\alpha_t\\) \u5df2\u77e5\uff09</p> <p>\\(q(x_t|x_0)=\\mathcal{N}(x_t;\\sqrt{\\bar \\alpha_t}x_0,(1-\\bar \\alpha_t)I)\\)</p> <p>\u4e5f\u5c31\u662f \u53ef\u4ee5\u4ee5  \\(\\mathcal{N}(x_t;\\sqrt{\\bar \\alpha_t}x_0,(1-\\bar \\alpha_t)I)\\) \u8fd9\u4e2a\u9ad8\u65af\u5206\u5e03\u8fdb\u884c\u91c7\u6837\uff0c\u800c\u4e0d\u9700\u8981\u9010\u6b65\u8fed\u4ee3</p> <p>\u2705</p> <p></p> <p>\u2705</p> <p></p> <p>\u4e24\u79cd \u91c7\u6837\u65b9\u6cd5</p> <p>\u4ee5\u4e0a\u5c31\u53ef\u4ee5\u786e\u5b9a\uff0cT\uff0c\u4e5f\u5c31\u662f\u5f53\u52a0\u591a\u5c11\u6b65\u566a\u58f0\u7684\u65f6\u5019\uff0c\u6211\u4eec\u7684 \\(q(x_t|x_0)\\) \u771f\u7684\u53d8\u6210\u4e00\u4e2a\u5404\u9879 \u540c\u6027 \u7684 \u9ad8\u65af\u5206\u5e03\u4e86\uff08\u7b49\u4ef7\u4e8e \u5404\u9879\u72ec\u7acb\uff09\uff0c\u56e0\u4e3a \\(\\alpha_t\\) \u662f\u5df2\u77e5\u7684\uff0c\u662f\u6211\u4eec\u81ea\u5df1\u8bbe\u7f6e\u7684 \u7c7b\u4f3c \u5b66\u4e60\u7387\u7684\u5e38\u6570\uff0c\u56e0\u6b64\u5c31\u80fd\u7b97\u51fa\u6765 \u5f53 \\(t=\u591a\u5c11\\)\u7684\u65f6\u5019\uff0c \\(\\sqrt{\\bar \\alpha_t}\\) \u63a5\u8fd1\u4e8e0\uff0c\\((1-\\bar \\alpha_t)\\) \u63a5\u8fd1\u4e8e1\uff0c\u6b64\u65f6 \\(q(x_t|x_0)\\) \u5c31\u63a5\u8fd1\u4e8e \u6807\u51c6\u6b63\u6001\u5206\u5e03\u3002\u4ee5\u4e0a\u8bf4\u660e\u4e86\u5982\u4f55\u786e\u5b9a t\u5728\u4ec0\u4e48\u65f6\u5019\uff0c\u80fd\u591f\u4f7f\u5f97 \\(q(x_t|x_0)\\) \u63a5\u8fd1\u4e8e \\(N(0,1)\\)</p> <p>\u5c0f\u5c0f\u7684\u603b\u7ed3\u4e00\u4e0b\uff1a</p> <p>(1) \u6269\u6563\u8fc7\u7a0b\u662f\u4e00\u4e2a\u5b8c\u5168\u4e0d\u542b\u53c2\u7684\u6269\u6563\u8fc7\u7a0b</p> <p>(2) \u8fed\u4ee3\u6b21\u6570 \u4ee5\u53ca \\(q(x_t)\\) \u7684\u8ba1\u7b97</p> <p>\u53ea\u8981\u7ed9\u5b9a\u521d\u59cb\u5206\u5e03\uff0c\u4efb\u610f\u65f6\u523b\u7684 \\(q(x_t)\\) \u90fd\u53ef\u4ee5\u628a\u91c7\u6837\u503c \u7b97\u51fa\u6765</p> <p>\u5176\u4e2d \u8ba1\u7b97 \\(q(x_t)\\) \u4e0d\u4e00\u5b9a\u662f \u901a\u8fc7\u8fed\u4ee3\uff1a</p> <p></p> <p>\u4e5f\u53ef\u4ee5\u901a\u8fc7\u76f4\u63a5\u7684\u8ba1\u7b97\u51fa\u6765\uff1a</p> <p></p> <p>\u8fd9\u4e2a\u5f0f\u5b50\u4f7f\u7528\u7684\u65f6\u5019\u9700\u8981 \u9884\u5148\u7684\u77e5\u9053 \\(\\alpha_t\\) \u4e5f\u5c31\u662f \\(\\beta_t\\)</p> <p>(3)\u4e0eVAE\u7684\u533a\u522b\uff1a</p> <p>\u7b2c\u4e00\u70b9\uff1a</p> <p>VAE\u4ece\\(x\\)\u5230\\(z\\)\uff0c\u9996\u5148 \u4e0d\u662f\u4e00\u4e2a \u65e0\u53c2\u6570\u7684 \u8fc7\u7a0b\uff0c\u800c\u662f \u901a\u8fc7 \u540e\u9a8c\u7f51\u7edc \u9884\u6d4b\u51fa\u6765\u7684\uff0c\u5176\u6b21 VAE\u7684\\(z\\)\u5e76\u4e0d\u662f\u5b8c\u5168\u7684\u8ddf\\(x\\)\u65e0\u5173\uff0cDiffusion \u7ecf\u8fc7\u6269\u6563\u4ee5\u540e\u7684 \\(x_t\\) \u662f\u4e00\u4e2a\u57fa\u672c\u5404\u9879\u72ec\u7acb\u7684 \u9ad8\u65af\u5206\u5e03\uff0c\u57fa\u672c\u4e0e \u539f\u59cb\u7684 \\(x_0\\) \u65e0\u5173\u4e86</p> <p></p> <p>\u7b2c\u4e8c\u70b9\uff1a</p> <p>\\(VAE\\)\u4e2d\uff0c\\(x\\)\u8ddf\\(z\\)\u7684\u7ef4\u5ea6\u4e0d\u4e00\u5b9a\u662f\u4e00\u6837\u7684\uff0c\u4f46\u662f\u5728\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u4ece \\(x_0\\) \u5230 \\(x_1\\) \u5230....\u5230 \\(x_t\\) \u7ef4\u5ea6\u59cb\u7ec8\u662f\u4e00\u6837\u7684\uff0c\u4e5f\u5c31\u662f\u6700\u540e\u7684 \\(x_T\\) \u7684\u7ef4\u5ea6 \u548c \\(x_0\\) \u7684\u7ef4\u5ea6\u662f\u4e00\u6837\u7684\uff0c\u662f\u6ca1\u6709\u53d8\u5316\u7684</p> <p>(4)</p> <p>\\(\\beta_t\\) \u600e\u4e48\u6837\u8bbe\u7f6e\uff1f</p> <p></p> <p>\u539f\u6587\uff1b\u5f53\u5206\u5e03\u8d8a\u6765\u8d8a\u63a5\u8fd1\u566a\u58f0\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u8ba9 \\(\\beta_t\\) \u66f4\u5927\u4e00\u70b9\uff0c\u5c31\u662f\u4e00\u5f00\u59cb\u7684\u65f6\u5019\uff0c\u4e0d\u8981\u52a0\u7684\u592a\u5927\uff0c\u4e00\u5f00\u59cb\u7684\u65f6\u5019  \\(\\beta_t\\) \u52a0\u7684\u7684\u5c0f\u4e00\u70b9\uff08\\(\\beta_t\\) \u662f\u63a7\u5236\u4ec0\u4e48\u7684\uff1f\uff09\uff0c\u5230\u540e\u9762\u53ef\u4ee5\u8d8a\u6765\u8d8a\u5927</p> <p>\u53cd\u8fc7\u6765\uff0c\u4ece \\(x_T\\) \u751f\u6210 \\(x_0\\) \uff0c\u5728\u4e00\u5f00\u59cb\u7684\u9636\u6bb5\u53d8\u5316\u5e76\u4e0d\u660e\u663e\uff0c\u59cb\u7ec8\u662f\u6df7\u4e71\u7684\u4e00\u56e2\uff0c\u4f46\u662f\u5728\u6700\u540e\u51e0\u6b65\u7684\u65f6\u5019\uff0c\u53d8\u5316\u7279\u522b\u660e\u663e\uff0c\u6700\u540e\u51e0\u6b65\u53ef\u4ee5\u5f88\u5feb\u7684\u663e\u793a\u539f\u59cb\u6570\u636e\u5206\u5e03</p> <p>\u63a5\u4e0b\u6765\uff0c\u9006\u8fc7\u7a0b\uff0c\u4e5f\u53eb \u9006\u6269\u6563\u8fc7\u7a0b \u6216\u8005 \u91cd\u5efa\u8fc7\u7a0b\uff1areverse process</p>"},{"location":"learning/6_Diffusion/#_2","title":"\u4e94\u3001\u9006\u6269\u6563\u8fc7\u7a0b","text":"<ul> <li>\u6269\u6563\u8fc7\u7a0b\u662f\u5bf9\u539f\u59cb\u6570\u636e\u4e00\u6b65\u6b65\u52a0\u566a\uff0c\u4f7f\u5176\u5f7b\u5e95\u53d8\u6210\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03</li> <li>\u9006\u6269\u6563\u8fc7\u7a0b\uff1a\u4ece\u9ad8\u65af\u5206\u5e03\u4e2d\uff0c\u6062\u590d\u539f\u59cb\u6570\u636e\uff08\u8fd9\u4e5f\u662f DIffusion model\u7684\u76ee\u7684\uff1a\u7ed9\u6211\u4eec\u4e00\u5806\u8bad\u7ec3\u96c6\uff0c\u5e0c\u671b\u6a21\u578b\u80fd\u591f\u4ece\u566a\u58f0\u9884\u6d4b\u51fa\u8bad\u7ec3\u96c6\u7684\u5206\u5e03\uff0c\u8fdb\u800c\u751f\u6210\u65b0\u7684\u6837\u672c\uff09</li> <li>\u5728 \u52a0\u566a\u7684\u8fc7\u7a0b\u4e2d\uff0c \\(\\beta_t\\) \u662f\u6bd4\u8f83\u5c0f\u7684\uff0c\u59cb\u7ec8\u662f 0~1 \u4e4b\u95f4 \u5f88\u5c0f\u7684\u6570\uff0c\u6bcf\u6b21\u52a0\u7684\u9ad8\u65af\u566a\u58f0\u5f88\u5c0f\uff0c\u65e2\u7136\u6bcf\u6b21\u52a0\u7684\u9ad8\u65af\u566a\u58f0\u5f88\u5c0f\uff0c\u53ef\u4ee5\u6709\u7406\u7531\u5047\u8bbe \u9006\u8fc7\u7a0b\uff08\u4ece  \\(x_T\\) \u9010\u6b65\u6062\u590d \\(x_0\\) \u7684\u8fc7\u7a0b \uff09\uff0c\u4e5f\u53ef\u4ee5\u5047\u8bbe\u662f\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03\uff0c\u5373 \\(p_{\\theta}(x_{t-1}|x_t)\\) \u4e5f\u662f\u670d\u4ece\u9ad8\u65af\u5206\u5e03</li> <li>\u4f46\u662f\uff0c\u6211\u4eec\u65e0\u6cd5\u76f4\u63a5\u62df\u5408  \\(p_{\\theta}(x_{t-1}|x_t)\\) \u8fd9\u4e2a\u9ad8\u65af\u5206\u5e03\uff0c\u5982\u679c\u6211\u4eec\u8981\u9010\u6b65\u62df\u5408 \\(p_{\\theta}(x_{t-1}|x_t)\\) \uff0c\u9996\u5148\u9700\u8981\u751f\u6210\u4e00\u5806 \\(x_t\\) \uff0c\u7136\u540e\u9010\u6b65\u505a GMM \u7684\u62df\u5408\uff0c\u62df\u5408\u51fa \\(x_{t-1}\\) \u4e4b\u540e\uff0c\u8fd8\u8981\u62df\u5408 \\(x_{t-2}\\) \u7b49\u7b49\uff0c\u9700\u8981\u904d\u5386\u6574\u4e2a\u6570\u636e\u96c6 \u6bd4\u8f83\u9ebb\u70e6\uff0c\u73b0\u5728\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u7f51\u7edc\uff0c\u6765\u8fdb\u884c\u8fd9\u4e2a\u4f30\u8ba1</li> <li>\u5f3a\u8c03\uff1a\u9006\u6269\u6563\u8fc7\u7a0b\u4ecd\u7136\u662f\u4e00\u4e2a\u9a6c\u5c14\u79d1\u592b\u94fe\u8fc7\u7a0b\uff1a</li> </ul> <p>\u73b0\u5047\u8bbe \u6709\u7f51\u7edc\\(\\theta\\)\uff0c\u53ef\u4ee5\u6784\u5efa\u51fa\u6761\u4ef6\u6982\u7387 \\(p_{\\theta}(x_{t-1}|x_t)\\) \uff0c\u5047\u8bbe\u8be5\u6761\u4ef6\u6982\u7387\u5747\u503c\u4e3a \\(\\mu_{\\theta}\\)  \u8fd9\u4e2a\u5747\u503c\u4e0e \\(x_t\\)  \u548c \\(t\\) \u6709\u5173\u7684\uff0c\u4e5f\u5c31\u662f\u8fd9\u4e2a\u7f51\u7edc\uff0c\u4ee5 \\(x_t\\) \u548c \\(t\\) \u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd9\u4e2a\u6761\u4ef6\u6982\u7387\u7684\u65b9\u5dee \u4e5f\u662f\u542b\u53c2\u7684 \\(\\sum_{\\theta}\\) \uff0c\u4e5f\u662f\u7531 \\(x_t\\) \u548c \\(t\\) \u5171\u540c\u4f5c\u4e3a\u8f93\u5165\u7684\uff0c\u540c\u6837\u4e5f\u53ef\u4ee5\u628a\u6574\u4e2a\u8054\u5408\u6982\u7387\u5206\u5e03 \u5199\u6210 \\(p(x_T)\\) \u00d7 \u4e00\u8fde\u4e32\u7684 \u6761\u4ef6\u6982\u7387\u76f8\u4e58</p> <ul> <li>\u4ee5\u4e0a\u662f \u9006\u6269\u6563\u8fc7\u7a0b\uff0c\u5c31\u662f\u4ece \\(x_T\\) \u9010\u6e10\u6062\u590d \\(x_0\\)</li> <li>\u90a3 \\(\\mu_{\\theta}\\)\u548c \\(\\sum_{\\theta}\\) \u5e94\u8be5\u6062\u590d\u6210\u591a\u5c11\u5462\uff1f\uff08\u540e\u9762\u4f1a\u8ba8\u8bba\uff09</li> </ul>"},{"location":"learning/6_Diffusion/#_3","title":"\u516d\u3001\u6269\u6563\u4e2d\u7684\u540e\u9a8c\u6761\u4ef6\u6982\u7387","text":"<p>\u8be5\u90e8\u5206\u6559\u6848\uff1a</p> <p></p> <p></p> <p>\u8be5\u90e8\u5206\u8bb2\u89e3\uff1a</p> <p>\u8fd9\u662f\u4e00\u4e2a\u65b0\u6027\u8d28\uff0c\u6269\u6563\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u5199\u51fa\u540e\u9a8c\u6269\u6563\u6761\u4ef6\u6982\u7387</p> <p>q \u662f\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u6761\u4ef6\u6982\u7387\u5206\u5e03</p> <p>\u5982\u679c\u8981\u5199 \\(q(x_{t-1}|x_t,x_0)\\) \u7684\u8bdd\uff0c\u8fd9\u4e2a\u5f0f\u5b50\u53ef\u4ee5\u7528\u4e00\u4e2a\u516c\u5f0f\u8fdb\u884c\u8868\u8fbe</p> <p>\u8fd9\u4e2a\u5c31\u662f\u6269\u6563\u8fc7\u7a0b\u4e2d\u540e\u9a8c\u7684\u6761\u4ef6\u6982\u7387\uff1a\u4e5f\u5c31\u662f\u7ed9\u5b9a \\(x_0\\) \u548c \\(x_t\\)\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa \\(x_{t-1}\\)</p> <p></p> <p>\u5f3a\u8c03\uff1a\u8fd9\u91cc\u662f\u9700\u8981\u7ed9\u5b9a \\(x_0\\)  \u7684\uff0c\u800c\u4e0d\u80fd\u5728\u7ed9\u5b9a \\(x_{t}\\) \u5c31\u80fd\u8ba1\u7b97\u51fa \\(x_{t-1}\\) \u5982\u679c\u8fd9\u6837\u7684\u8bdd\uff0c\u4e5f\u5c31\u4e0d\u9700\u8981\u8fd9\u4e2a\u6269\u6563\u7f51\u7edc\u4e86\uff0c\u6240\u4ee5\u4e00\u5b9a\u662f\u540e\u9a8c\u7684\uff0c\u7ed9\u5b9a \\(x_0\\)  \u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u7b97\u51fa \\(x_{t-1}\\)  \u7684\uff0c\u7ed9\u5b9a \\(x_t\\)  \u548c \\(x_0\\)  \u7684\u60c5\u51b5\u4e0b\uff0c\u8ba1\u7b97\u51fa \\(x_{t-1}\\)  \u7684\uff0c\u5177\u4f53\u5730\u8ba1\u7b97\u65b9\u6cd5\u5c31\u662f\u57fa\u4e8e \u6761\u4ef6\u6982\u7387 \\(q\\) \uff0c\u516c\u5f0f\uff1a\\(q(x_{t-1}|x_t,x_0)\\)</p> <p></p> <p>\u73b0\u5728\u5047\u8bbe\u5728 \\(x_t\\) \\(x_0\\) \u7ed9\u5b9a\u7684\u6761\u4ef6\u4e0b\uff0c \\(x_{t-1}\\) \u670d\u4ece \u9ad8\u65af\u5206\u5e03\uff0c\u5747\u503c\u4e3a \\(\\tilde{\\mu}\\)  \uff0c\u65b9\u5dee\u4e3a \\(\\tilde{\\beta_t}\\)</p> <p>\u57fa\u4e8e\u8d1d\u53f6\u65af\u516c\u5f0f\uff1a</p> <p></p> <p>\uff081\uff09\u63a8\u5bfc\u7b2c\u4e00\u4e2a\u7b49\u53f7</p> <p>\\(q(x_{t-1}|x_t,x_0) = q(x_t|x_{t-1,x_0})\\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)}\\)</p> <p>\u2460</p> <p>\\(=\\frac{q(x_{t-1},x_t|x_0)}{q(x_t|x_0)}\\)</p> <p>\\(=\\frac{q(x_{t-1}|x_0)q(x_t|x_{t-1},x_0)}{q(x_t|x_0)}\\)</p> <p>\u2461</p> <p>\\(=\\frac{q(x_{t-1},x_t,x_0)}{q(x_t,x_0)}\\)</p> <p>\\(=\\frac{q(x_0)q(x_{t-1}|x_0)q(x_t|x_{t-1},x_0)}{q(x_t,x_0)}\\)</p> <p>\\(=\\frac{q(x_{t-1}|x_0)q(x_t|x_{t-1},x_0)}{\\frac{q(x_t,x_0)}{q(x_0)}}\\)</p> <p>\\(=\\frac{q(x_{t-1}|x_0)q(x_t|x_{t-1},x_0)}{q(x_t|x_0)}\\)</p> <p>\u8bc1\u6bd5</p> <p>\uff082\uff09\u63a8\u5bfc\u7b2c\u4e00\u4e2a\u6b63\u6bd4\u4e8e</p> <p>\\(q(x_t|x_{t-1},x_0)\\)  \u7531\u9a6c\u5c14\u79d1\u592b\u5047\u8bbe\uff0c\\(x_t\\)  \u4e0e \\(x_0\\)  \u65e0\u5173</p> <p>\u2234  \\(q(x_t|x_{t-1},x_0) = q(x_t|x_{t-1})\\)</p> <p>\u7531\uff1a</p> <p></p> <p>\u6240\u4ee5\uff1a\\(q(x_t|x_{t-1}) = \\mathcal{N}(x_t;\\sqrt{1-\\beta_t}x_{t-1},\\beta_tI)\\)  \u5747\u503c= \\(\\sqrt{1-\\beta_t}x_{t-1}\\) </p> <p>\\(\u65b9\u5dee = \\beta_tI\\)</p> <p>\u8bb0 \\(1-\\beta_t=\\alpha_t\\)</p> <p>\u5219</p> <p>\\(q(x_t|x_{t-1})\\propto \\exp(-\\frac{(x_t-\\sqrt{\\alpha_t}x_{t-1})^2}{2\\beta_t})\\) </p> <p>\u8bc1\u6bd5</p> <p>\uff083\uff09\u63a8\u5bfc\u7b2c\u4e8c\u4e2a\u6b63\u6bd4\u4e8e\u53f7</p> <p>\u7531\uff1a</p> <p></p> <p>\u6240\u4ee5 \\(\\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)}\\)</p> <p>\\(q(x_{t-1}|x_0) \\sim \\mathcal{N}(x_{t-1};\\sqrt{\\bar{\\alpha}_{t-1}}x_0,(1-\\bar{\\alpha}_{t-1})I)\\)</p> <p>\\(q(x_{t}|x_0) \\sim \\mathcal{N}(x_{t};\\sqrt{\\bar{\\alpha}_{t}}x_0,(1-\\bar{\\alpha_{t}})I)\\)</p> <p>\u6240\u4ee5\uff1a</p> <p>\\(\\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} \\propto \\exp(-\\frac{1}{2}(\\frac{(x_{t-1}-\\sqrt{\\bar{\\alpha}_{t-1}}x_0)^2}{1-\\bar{\\alpha}_{t-1}}-\\frac{(x_t-\\sqrt{\\bar{\\alpha}_{t}}x_0)^2}{1-\\bar{\\alpha_{t}}}))\\)</p> <p>\uff084\uff09\u5408\u5e76\u6b63\u6bd4\u53f7</p> <p>\\(q(x_t|x_{t-1})\\propto \\exp(-\\frac{(x_t-\\sqrt{\\alpha_t}x_{t-1})^2}{2\\beta_t})\\)</p> <p>\\(\\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} \\propto \\exp(-\\frac{1}{2}(\\frac{(x_{t-1}-\\sqrt{\\bar{\\alpha}_{t-1}}x_0)^2}{1-\\bar{\\alpha}_{t-1}}-\\frac{(x_t-\\sqrt{\\bar{\\alpha}_{t}}x_0)^2}{1-\\bar{\\alpha_{t}}}))\\)</p> <p>\\(q(x_{t-1}|x_t,x_0) = \\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)}\\)</p> <p>\\(\\propto \\exp(-\\frac{1}{2}(\\frac{(x_t-\\sqrt{\\alpha_t}x_{t-1})^2}{\\beta_t}+\\frac{(x_{t-1}-\\sqrt{\\bar{\\alpha}_{t-1}}x_0)^2}{1-\\bar{\\alpha}_{t-1}}-\\frac{(x_t-\\sqrt{\\bar{\\alpha}_{t}}x_0)^2}{1-\\bar{\\alpha_{t}}}))\\)</p> <p>(\u5ffd\u7565\u7cfb\u6570\u3001\u53ea\u4fdd\u7559\u6307\u6570\u90e8\u5206)</p> <p>\u5316\u7b80\uff0c\u4ee5 \\(x_{t-1}\\)  \u4e3a\u57fa\u51c6\u8fdb\u884c\u5408\u5e76\uff0c\u53ea\u6458\u51fa \\(x_{t-1}^2\\)  \u548c \\(x_{t-1}\\) \uff0c\u5176\u4f59\u7684 \\(x_t\\)  \u548c \\(x_0\\) \u5168\u90e8\u5f52\u5230 \\(C(x_t,x_0)\\) \uff1a</p> <p></p> <p>\u6700\u540e\u5b8c\u6210\u5168\u90e8\u7684\u63a8\u5bfc  </p> <p>\u89e3\u91ca \\(C(x_t,x_0)\\) \uff1a</p> <p></p> <p>\uff085\uff09\u6839\u636e\u9ad8\u65af\u5206\u5e03\u7684\u6807\u51c6\u5f62\u5f0f\uff0c\u5f97\u5230\u5747\u503c\u548c\u65b9\u5dee\uff1a</p> <p></p> <p></p> <p>\u7531 \\(ax^2+bx=a(x+\\frac{b}{2a})^2+C\\)</p> <p>\u53ef\u4ee5\u77e5\u9053 \\(\u5747\u503c = -\\frac{b}{2a}\\)</p> <p>\\(\u65b9\u5dee = \\frac{1}{a}\\)</p> <p>\u6240\u4ee5</p> <p></p> <p>\u5747\u503c \\(\\tilde{\\mu}\\)  \u548c \u65b9\u5dee  \\(\\tilde\\beta_t\\)    \u53ef\u6c42</p> <p>\u7ecf\u8fc7\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u5b8c\u6210\u5168\u90e8\u8fd9\u4e00\u90e8\u5206\u7684\u63a8\u5bfc\uff1a</p> <p></p> <p>\u63a5\u4e0b\u6765\uff0c\u7ee7\u7eed\uff1a</p> <p></p> <p>\uff081\uff09\u7531\u53c2\u6570\u91cd\u6574\u5316\uff1a</p> <p></p> <p>\u79fb\u9879 \u53ef\u5bfc \\(x_0\\) \u548c \\(x_t\\)</p> <p>\\(x_0 = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}}(x_t-\\sqrt{1-\\bar{\\alpha}_t} z_t)\\)</p> <p>(2)</p> <p></p> <p>\u6700\u5f00\u59cb\u7684\u5747\u503c\u8868\u8fbe\u5f0f\uff1a</p> <p></p> <p>\u628a \\(x_0\\) \u4ee3\u5165</p> <p>\u6700\u7ec8\u5f97\u5230 \\(\\tilde{\\mu}_t = \\frac{1}{\\alpha_t}(x_t-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}z_t)\\)</p> <p>\u53ea\u4e0e \\(x_t\\) \u548c \\(z_t\\) \u6709\u5173\uff0c\\(z_t\\) \u8868\u793a  \\(t\\)\u65f6\u523b \u4ece \u6b63\u6001\u5206\u5e03\u4e2d \u7684\u91c7\u6837\u503c</p> <p>\uff083\uff09</p> <p>\u7ecf\u8fc7\u4ee5\u4e0a\uff0c\u5199\u51fa\u4e86\u6269\u6563\u8fc7\u7a0b\u4e2d\uff0c\u540e\u9a8c\u7684\u6761\u4ef6\u6982\u7387\u5206\u5e03\u7684\u5747\u503c\u548c\u65b9\u5dee\u90fd\u5199\u51fa\u6765\u4e86</p> <p>\u65b9\u5dee\uff1a</p> <p></p> <p>\u53ea\u4e0e \\(\\alpha\\)  \u548c \\(\\beta\\) \u6709\u5173</p> <p>\u5747\u503c\uff1a</p> <p></p> <p>\u4e0e \\(x_t\\)  \u548c \\(z_t\\)  \u6709\u5173</p> <p>\u7b2c\u4e03\u90e8\u5206 \uff0c\u63a8\u5bfc\u6269\u6563\u6a21\u578b\uff0c\u76ee\u6807\u6570\u636e\u7684\u4f3c\u7136\u51fd\u6570\uff0c\u63a8\u5bfc\u51fa\u4f3c\u7136\u51fd\u6570\uff0c\u5c31\u53ef\u4ee5\u4f18\u5316\u7f51\u7edc</p>"},{"location":"learning/6_Diffusion/#_4","title":"\u4e03\u3001\u5bf9\u6570\u4f3c\u7136\u4e0b\u754c\u63a8\u5bfc","text":"<p>\u5185\u5bb9\uff1a</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>\u8bb2\u89e3\uff1a</p> <p>\uff081\uff09</p> <p></p> <p>\\(-logp_{\\theta}(x_0) \\leq  -logp_{\\theta}(x_0) + KL\u6563\u5ea6\\)</p> <p>\\(KL\u6563\u5ea6 \\geq 0\\)</p> <p>\u6240\u4ee5\u6709 </p> <p></p> <p>\\(-logp_{\\theta}(x_0) + DL_{KL}\\) \u662f\u5b83 \\(-logp_{\\theta}(x_0)\\) \u7684\u4e0a\u754c</p> <p>\u6240\u4ee5 \u4f18\u5316 \\(-logp_{\\theta}(x_0) + DL_{KL}\\)  \u76f8\u5f53\u4e8e \u4f18\u5316 \\(-logp_{\\theta}(x_0)\\) </p> <p>\u4e5f\u5c31\u662f  \\(-logp_{\\theta}(x_0) + DL_{KL}\\) \u8fbe\u5230\u6700\u5c0f\uff0c\u5c31\u662f \\(-logp_{\\theta}(x_0)\\)  \u8fbe\u5230\u6700\u5c0f</p> <p>\u79f0\u4e3a \u8d1f\u5bf9\u6570\u4f3c\u7136 \\(-logp_{\\theta}(x_0)\\)</p> <p>\u5148\u9a8c\u77e5\u8bc6\uff1a</p> <p>KL\u6563\u5ea6\u516c\u5f0f\uff1a</p> <p>\\(D(p||q) = H(p,q)-H(p) = \\sum p_i\\log\\frac{1}{q_i}-p_i\\log\\frac{1}{p_i}=\\sum p_i\\log\\frac{p_i}{q_i} = \\mathbb{E}_{x \\sim p}(log\\frac{p}{q})\\)</p> <p> </p> <p>\u7ee7\u7eed\u63a8\u516c\u5f0f\uff1a</p> <p></p> <p>\u7b2c\uff081\uff09\u4e2a \u5c0f\u4e8e\u7b49\u4e8e\u53f7\uff1a</p> <p>K1\uff1a\u4e3a \u4e00\u4e2a \u8d1f\u7684 \u5bf9\u6570\u4f3c\u7136 \u51d1\u9879</p> <p>K2\uff1aKL\u6563\u5ea6 \u5927\u4e8e\u7b49\u4e8e 0 \u6052\u6210\u7acb</p> <p>\u7b2c\uff082\uff09\u4e2a\u7b49\u4e8e\u53f7\uff1a</p> <p>K1\uff1a</p> <p>\\(KL\u6563\u5ea6= D(p||q) = H(p,q)-H(p) = \\sum p_i\\log\\frac{1}{q_i}-p_i\\log\\frac{1}{p_i}=\\sum p_i\\log\\frac{p_i}{q_i} = \\mathbb{E}_{x \\sim p}(log\\frac{p}{q})\\)</p> <p>K2\uff1a</p> <p>\\(-logp_{\\theta}(x_0) \\leq -logp_{\\theta}(x_0) + D_{KL}(q(x_{1:T}|x_0)||p_{\\theta}(x_{1:T}|x_0))\\)</p> <p>\uff081\uff09\u62c6\u51faKL\u6563\u5ea6\uff1a\\(D_{KL}(q(x_{1:T}|x_0)||p_{\\theta}(x_{1:T}|x_0))\\)</p> <p>\\(= \\mathbb{E}_{x_{1:T} \\sim q(x_{1:T}|x_0)}[\\log \\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{1:T}|x_0)}]\\)</p> <p>\uff082\uff09</p> <p>\u62c6\u51fa\u6761\u4ef6\u6982\u7387\uff1a\\(p_{\\theta}(x_{1:T}|x_0)\\)</p> <p>\\(=\\frac{p_{\\theta}(x_{0:T})}{p_{\\theta}(x_0)}\\)</p> <p></p> <p>\u7b2c\u4e8c\u4e2a \u7b49\u4e8e\u53f7\u4e5f \u8bc1\u660e\u51fa\u6765\u4e86</p> <p></p> <ul> <li>\u540e\u9762\u7684\u7b49\u4e8e\u53f7 \u5c31\u6bd4\u8f83\u597d\u8bf4\u4e86\uff0c\u987a\u7740\u5199</li> <li>\u5173\u4e8e \u7b2c\uff083\uff09\u4e2a\u7b49\u4e8e\u53f7\uff0c\u6709\u4e00\u4e2a\u7ec6\u8282\uff0c\u56e0\u4e3a \\(\\mathbb{E}_q logp_{\\theta}(x_0)\\) \u4e2d \\(p_{\\theta}(x_0)\\) \u4e0e \\(q\\) \u65e0\u5173\uff0c\u6240\u4ee5\u53ef\u4ee5\u76f4\u63a5\u62ff\u51fa\u6765\uff0c\u5e76\u4e14\u4e0e\u524d\u9762 \u6d88\u9879</li> </ul> <p></p> <p>\u7ee7\u7eed\u770b</p> <p>\u5728 \u63a8\u5bfc\u51fa </p> <p>\\(-logp_{\\theta}(x_0) \\leq \\mathbb{E}_{{x_{1:T} \\sim q(x_{1:T}|x_0)}}[log\\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{0:T})}]\\)</p> <p>\u4ee5\u540e\uff0c\u5de6\u53f3\u4e24\u8fb9 \u5bf9\u4e8e\\(q(x)\\) \u6c42\u671f\u671b\u65f6\uff0c\u4ece \\(x_0\\) \u5f00\u59cb\uff1a</p> <p>\u6362\u53e5\u8bdd\u8bf4\uff1a\u5bf9\\(q(x_0)\\) \u6c42\u671f\u671b</p> <p>\\(-logp_{\\theta}(x_0) \\leq \\mathbb{E}_{{x_{1:T} \\sim q(x_{1:T}|x_0)}}[log\\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{0:T})}]\\) \\(\\iff\\) \\(-logp_{\\theta}(x_0) \\leq \\mathbb{E}_{ q(x_{1:T})}[log\\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{0:T})}]\\)</p> <p>(\u5728\u4e8e \u4e0b\u6807\u7684\u53d8\u5316)</p> <p>\u2234 \\(-\\mathbb{E}_{q(x_0)}logp_{\\theta}(x_0) \\leq \\mathbb{E}_{{q(x_{0:T})}}[log\\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{0:T})}]\\)</p> <p>\u53cd\u8fc7\u6765 \u5c31\u662f \u8bb2\u4e49\u4e0a\u5199\u7684\u4e86</p> <p>\\(\\mathbb{E}_{{q(x_{0:T})}}[log\\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{0:T})}]  \\geq -\\mathbb{E}_{q(x_0)}logp_{\\theta}(x_0)\\)</p> <p>\u6ce8\u610f\u5230   \\(-\\mathbb{E}_{q(x_0)}logp_{\\theta}(x_0)\\)  \u8fd9\u4e2a\u4e1c\u897f\u662f\u4ea4\u53c9\u71b5</p> <p>\u6240\u4ee5\u73b0\u5728\u6211\u4eec\u6700\u5c0f\u5316  \u4ea4\u53c9\u71b5 \\(-\\mathbb{E}_{q(x_0)}logp_{\\theta}(x_0)\\) \u5c31\u662f\u6700\u5c0f\u5316 \u4ea4\u53c9\u71b5\u7684\u4e0a\u754c\uff1a\\(\\mathbb{E}_{{q(x_{0:T})}}[log\\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{0:T})}]\\) </p> <p>\u603b\u4e4b\uff1a\\(\\mathbb{E}_{{q(x_{0:T})}}[log\\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{0:T})}]\\)  \u8fd9\u4e2a\u5f0f\u5b50 \u5c31\u662fLoss\u7684\u4e0a\u754c\uff0c\u6700\u5c0f\u5316\u4e86\u8fd9\u4e2a\u4e0a\u754c\uff0c\u5c31\u662f\u6700\u5c0f\u5316\u4e86Loss\uff0c\u63a5\u4e0b\u6765\u8fdb\u4e00\u6b65\u5316\u7b80\u4e0a\u754c\uff1a\\(\\mathbb{E}_{{q(x_{0:T})}}[log\\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{0:T})}]\\)</p> <p>\u4e0a\u754c\u8bb0\u4e3a VLB\uff08why\uff1f\uff09</p> <p></p> <p>\u9996\u5148\uff1a</p> <p>\\(L_{VLB} = \\mathbb{E}_{{q(x_{0:T})}}[log\\frac{q(x_{1:T}|x_0)}{p_{\\theta}(x_{0:T})}]\\)</p> <p>\u63a5\u7740\uff0c\u628a\u5206\u5b50\u5206\u6bcd\u5199\u6210\u5f88\u591a\u6761\u4ef6\u6982\u7387\u76f8\u4e58\u7684\u5f62\u5f0f</p> <p>\\(=\\mathbb{E}\\frac{\\prod q}{\\prod p}\\)</p> <p>\u63a5\u4e0b\u6765\uff0c\u8fd9\u4e00\u5927\u4e32\uff1a</p> <p></p> <p>\u8fd9\u91cc\u7684\u63a8\u5bfc\u5f3a\u8c03\u4e00\u4e0b\uff1a </p> <p>\uff081\uff09</p> <p>\u4ed4\u7ec6\u770b\u4e00\u4e0b\uff0c\u53d8\u4e0e\u4e0d\u53d8 \\(p_{\\theta}(x_{t-1}|x_t)\\) \u662f\u6ca1\u6709\u53d8\u5f97\uff0c\u53ea\u662f \\(q(x_t|x_{t-1})\\) \u53d8\u4e86\uff0c\u63a5\u7740\u518d\u7528\u8d1d\u53f6\u65af\u516c\u5f0f\u5316\u7b80\u5373\u53ef</p> <p></p> <p>\\(q(x_t|x_{t-1})\\)</p> <p>= \\(\\frac{q(x_{t-1}|x_{t})q(x_t)}{q(x_{t-1})}\\)</p> <p>(\u9a6c\u5c14\u79d1\u592b\u6027\u8d28\uff0c\u6240\u4ee5\u53ef\u4ee5\u52a0\u6761\u4ef6 \\(x_0\\))= \\(\\frac{q(x_{t-1}|x_{t},x_0)q(x_t,x_0)}{q(x_{t-1},x_0)}\\)</p> <p>\uff082\uff09</p> <p></p> <p></p> <p>\uff083\uff09</p> <p></p> <p>\uff084\uff09</p> <p>\u4ee5\u4e0b\u4e24\u5f20\u56fe\u7247\uff0c\u8868\u793a\u4e00\u4e2a\u610f\u601d\u3002</p> <p>\u2460 \u4e0a\u9762\u7684\u56fe\uff1a\u6709\u70b9\u5c0f\u95ee\u9898</p> <p>\u6539\u6210\uff1a\\(=D_{KL}(q(x_T|x_0)||p_{\\theta}(x_T)) + \\sum_{t=2}^T D_{KL}(q(x_{t-1}|x_t,x_0)||p_{\\theta}(x_{t-1}|x_t))-\\mathbb{E}_q \\log p_{\\theta}(x_0|x_1)\\)</p> <p>\u8fd9\u6837\uff0c\u4e0a\u56fe\u548c\u4e0b\u56fe\u662f\u4e00\u6837\u7684</p> <p>\u2461 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c</p> <p>KL \u6563\u5ea6\u516c\u5f0f</p> <p></p> <p>\u4e2d\u95f4\u8fd8\u6709\u5220\u6389\u65e0\u5173\u53d8\u91cf\u7684\u6b65\u9aa4\uff1a</p> <p></p>"},{"location":"learning/6_Diffusion/#diffusion-probabilistic-model","title":"\u516b\u3001DIffusion Probabilistic Model \u7b97\u6cd5\u4ee3\u7801","text":"<p>\u6269\u6563\u4e0e\u9006\u6269\u6563\u8fc7\u7a0b\u4f2a\u4ee3\u7801</p> <p></p> <p>pytorch\u5b9e\u73b0\u65e0\u76d1\u7763\u56fe\u50cf\u751f\u6210</p>"},{"location":"learning/6_Diffusion1/","title":"VDM","text":""},{"location":"learning/6_Diffusion1/#vdm","title":"VDM","text":"2024-12-19 22:26:512025-09-28 12:54:04 <p> \u7ea6 7545 \u4e2a\u5b57  69 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 38 \u5206\u949f</p> <p>ref\uff1a\u3010\u516c\u5f0f\u63a8\u5bfc\u3011\u8fd8\u5728\u5934\u75bcDiffusion\u6a21\u578b\u516c\u5f0f\u5417\uff1fDiffusion\u7406\u8bba\u516c\u5f0f\u5582\u996d\u5f0f\u8d85\u8be6\u7ec6\u9010\u6b65\u63a8\u5bfc\u6765\u4e86\uff01</p> <p>\u300aUnderstanding Diffusion Models: A Unified Perspective\u300b\uff1ahttps://arxiv.org/abs/2208.11970 </p> <p>\u300aDenoising Diffusion Probabilistic Models\u300b:https://arxiv.org/abs/2006.11239</p> <p></p> <p></p>"},{"location":"learning/6_Diffusion1/#1-vae","title":"1 VAE","text":""},{"location":"learning/6_Diffusion1/#11","title":"1.1 \u6781\u5927\u4f3c\u7136\u6a21\u578b","text":"<p>\u76ee\u7684\u662f\u4f7f\u5f97\u6a21\u578b\u5b66\u5f97\u6570\u636e\u96c6\u7684\u5206\u5e03</p> <p>\u7ed9\u5b9a\u6570\u636e\u96c6 \\(x_D\\)\uff0c\u901a\u8fc7\u6a21\u578b\u5b66\u5f97 \\(\\phi\\)\u53c2\u6570\uff0c\u5f97\u5230\u6a21\u578b \\(p_{\\phi}(x_D)\\)\uff0c\u8bad\u7ec3\u6a21\u578b\u6700\u5927\u5316 \\(p_{\\phi}(x_D)\\)\uff0c\u4f7f\u5f97 \\(p_{\\phi}(x_D)\\) \u80fd\u591f\u62df\u5408\u6837\u672c \\(x'\\)</p> <p>\u5f97\u5230\u6a21\u578b \\(p_{\\phi}(x_D)\\) \u4ee5\u540e\uff0c\u8fd8\u80fd\u591f\u8fdb\u884c\u91c7\u6837\uff0c\u91c7\u6837\u51fa\u6765\u7684\u6837\u672c\u53ef\u80fd\u4e0d\u5728\u6570\u636e\u96c6\u91cc\u9762\uff0c\u4f46\u662f\u91c7\u6837\u51fa\u6765\u7684\u6837\u672c\u662f\u7b26\u5408\u6982\u7387\u5206\u5e03\u7684\u503c</p>"},{"location":"learning/6_Diffusion1/#12-vae","title":"1.2 VAE","text":"<ul> <li> \u91cd\u70b9\u5728\u4e8e\u7406\u89e3\uff1aVAE\u5c31\u662f\u5efa\u7acb \u771f\u5b9e\u56fe\u7247 \\(x\\) \u4e0e \u9690\u53d8\u91cf\u9ad8\u65af\u5206\u5e03\\(z\\) \u4e4b\u95f4\u7684\u8f6c\u6362\uff0c\u5de5\u5177\u662f Encoder\u548cdecoder</li> </ul> <p>\u9996\u5148\uff0c\u751f\u6210\u6a21\u578b\u5fc5\u987b\u8981\u6709\u80fd\u591f\u91c7\u6837\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u80fd\u53ea\u80fd\u56fa\u5b9a\u751f\u6210\u4e00\u4e9b\u6837\u672c</p> <p>\u6240\u4ee5\uff0c\u9996\u5148\u8981\u6709\u4e00\u4e2a\u5206\u5e03\u4f9b\u6211\u91c7\u6837\uff0c\u6709\u4e86\u5206\u5e03\u624d\u80fd\u91c7\u6837\uff0cVAE\u5c31\u501f\u52a9\u4e86\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684\u5206\u5e03\uff0c\u5c31\u662f\u6807\u51c6\u9ad8\u65af\u5206\u5e03\uff0c\u7528\u516c\u5f0f\u8868\u8fbe\uff1a\u4ee50\u4e3a\u5747\u503c\uff0c\\(I\\) \u4e3a\u65b9\u5dee\u7684\u4e00\u4e2a\u5206\u5e03\uff0c\u6ce8\u610f\u662f\u591a\u7ef4\u7684  \\(N \\sim N(z;\\mathrm{0},\\mathrm{I})\\)</p> <p>VAE\u7684\u7ed3\u6784\u9996\u5148\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff1aEncoder+decoder</p> <p>\u6587\u5b57\u8868\u8fbe\uff1a</p> <p>**Encoder\uff1a **\u628a\u4e00\u4e9b\u56fe\u50cf\u901a\u8fc7Encoder\u53d8\u6210\u4e00\u4e9bembedding\uff0c\u4e00\u822c\u662f\u7ef4\u5ea6\u6bd4\u8f83\u4f4e\u7684embedding</p> <p>**decoder\uff1a **decoder\u88ab\u7ef4\u5ea6\u6bd4\u8f83\u4f4e\u7684embedding\u751f\u6210\u4e00\u4e9b\u7ef4\u5ea6\u6bd4\u8f83\u9ad8\u7684\u56fe\u7247</p> <p>\u6570\u5b66\u8868\u8fbe\uff1a</p> <p>Encoder\uff1a\\(q(z|x)\\) \u7ed9\u5b9a\u56fe\u7247 \\(x\\) \u80fd\u591f\u62ff\u5230 \\(z\\)\uff0c\\(z\\)\u8868\u793a\u6807\u51c6\u9ad8\u65af\u5206\u5e03\u7684\u4e00\u4e2a\u6837\u672c</p> <p>Decoder\uff1a\\(p(x|z)\\) \u7ed9\u5b9a\u6807\u51c6\u9ad8\u65af\u5206\u5e03\u7684\u4e00\u4e2a\u503c\uff0c\u901a\u8fc7decoder\u751f\u6210\u4e00\u5f20\u56fe\u7247\\(x\\)</p> <p>VAE\u7684Encoder\u548cdecoder\u5c31\u662f\u5728 \\(x\\)\u548c\\(z\\)\u4e4b\u95f4\u5efa\u7acb\u8d77\u8054\u7cfb</p> <p>\u4e3a\u4ec0\u4e48\u8fd9\u4e48\u505a\u7684\u539f\u56e0\uff1a</p> <p>\u56e0\u4e3a\u8ba9\u6a21\u578b\u76f4\u63a5\u5b66\u4e60 \\(x\\)\u7684\u5206\u5e03\u6bd4\u8f83\u96be\uff0c\\(x\\)\u53ef\u80fd\u5e76\u4e0d\u662f\u5e38\u89c1\u7684\u5206\u5e03\uff0c\u6240\u4ee5\u6ca1\u6709\u529e\u6cd5\u91c7\u6837\uff0c\u4f46\u5982\u679c\u628a\\(x\\)\u4e0e\u4e00\u4e2a\u6807\u51c6\u9ad8\u65af\u5206\u5e03\u8054\u7cfb\u8d77\u6765\uff0c\u90a3\u4e48\u6bcf\u5728\u6807\u51c6\u9ad8\u65af\u5206\u5e03\u4e0a\u91c7\u6837\u4e00\u4e2a\u503c\uff0c\u63a5\u7740\u901a\u8fc7decoder\u5c31\u80fd\u6620\u5c04\u6210\u5728\\(x\\)\u4e5f\u5c31\u662fpixel\u8fd9\u4e2a\u50cf\u7d20\u7a7a\u95f4\u4e0a\uff0c\u751f\u6210\u4e00\u5f20\u56fe\u7247\uff0c\u8fd9\u6837\u5c31\u4f1a\u6709\u5f88\u591a\u6837\u672c\u4ea7\u751f\uff0c\u56e0\u4e3a\u6807\u51c6\u9ad8\u65af\u5206\u5e03\u53ef\u4ee5\u91c7\u6837\u51fa\u65e0\u7a77\u65e0\u5c3d\u4e2a\u6837\u672c</p> <p>\u4e5f\u5c31\u662f\u8fd9\u53e5\u8bdd\uff1a</p> <p></p> <p>z \u8868\u793a\u9690\u53d8\u91cf\uff0c\u4e00\u822c\u91c7\u7528\u9ad8\u65af\u5206\u5e03\uff0c\u4e14\u4e00\u822c\u662f\u591a\u7ef4\u7684\uff0c\u7406\u8bba\u4e0a\u8bb2\u53ef\u4ee5\u662f\u4efb\u610f\u4e00\u4e2a\u80fd\u591f\u8fdb\u884c\u65b9\u4fbf\u91c7\u6837\u7684\u5206\u5e03\uff0c\u53ea\u662f\u56e0\u4e3a\u9ad8\u65af\u90e8\u5206\u6bd4\u8f83\u7b80\u6d01\uff0c\u63a8\u5bfc\u4e5f\u6bd4\u8f83\u7b80\u5355\uff0c\u6240\u4ee5\u4e00\u822c\u91c7\u7528\u9ad8\u65af\u5206\u5e03\u4f5c\u4e3a\u9690\u53d8\u91cf\u3002</p> <p>\u4e00\u53e5\u8bdd\uff0cVAE\u5c31\u662f\u5efa\u7acb \u771f\u5b9e\u56fe\u7247 \\(x\\) \u4e0e \u9690\u53d8\u91cf\u9ad8\u65af\u5206\u5e03\\(z\\) \u4e4b\u95f4\u7684\u8f6c\u6362</p>"},{"location":"learning/6_Diffusion1/#13-vae","title":"1.3 VAE\u7684\u6570\u5b66\u539f\u7406","text":"<p>\u9996\u5148\uff0cVAE\u7684\u4f18\u5316\u76ee\u6807\uff0c\u5b66\u4e60\u5230\u7684\u5206\u5e03 \\(p_{\\phi}(x)\\) \u8d8b\u8fd1\u4e8e \u771f\u5b9e\u5206\u5e03 \\(p(x)\\)</p> <p>\u9996\u5148\u660e\u786e\u4f18\u5316\u76ee\u6807\uff1a  \\(p_{\\phi}(x) \\rightarrow p(x)\\)</p> <p>\u90a3\u5177\u4f53\u600e\u4e48\u5b9e\u73b0\u76ee\u6807\u5462\uff1f\u601d\u60f3\u5c31\u7c7b\u4f3c\u4e8e\u8f85\u52a9\u7ebf &amp; \u4e2d\u95f4\u53d8\u91cf\uff0c\u8fd9\u91cc\u501f\u52a9\u7684\u4e2d\u95f4\u53d8\u91cf\u5c31\u662f \\(z\\)</p> <p>\u9996\u5148\uff0c\u771f\u5b9e\u5206\u5e03 \\(p(x)\\) \u4e00\u822c\u7528\u5bf9\u6570\u4f30\u8ba1\uff0c\u8868\u793a\u6210 \\(logp(x)\\) \uff0c\u4e14\u6709\u4e0b\u754c \\(\\mathbb{E}_{q_{\\phi}(z|x)}[log \\frac{p(x,z)}{q_{\\phi}(z|x)}]\\)</p> <p>\u4ee5\u4e0a\u6b65\u9aa4\u90fd\u5f88\u7b80\u5355\uff0c\u6ca1\u5565\u597d\u8bf4\u7684\uff0c\u503c\u5f97\u6ce8\u610f\u7684\u662f\u7434\u751f\u4e0d\u7b49\u5f0f\uff0c\u4e5f\u5c31\u662f\u628alog\u5185\u79fb</p> <p>\u7406\u89e3\u7434\u751f\u4e0d\u7b49\u5f0f\uff1a</p> <p></p> <p>\u6587\u5b57\u63cf\u8ff0\uff1a\u4efb\u610f\u4e24\u70b9\u7684\u671f\u671b \uff1e \u671f\u671b\u7684\u51fd\u6570\u503c</p> <p>\u56fe\u793a\uff1a\u4efb\u610f\u4e24\u70b9\u7684\u8fde\u7ebf\uff0c\u6c38\u8fdc\u5728\u66f2\u7ebf\u4e0a\u65b9</p> <p>\u51fd\u6570\u503c\u7684\u671f\u671b \uff1e \u671f\u671b\u7684\u51fd\u6570\u503c\uff08\u5bf9\u4e8e\u51f8\u51fd\u6570\u6765\u8bf4\uff1a\u671f\u671b&gt;\u51fd\u6570\u503c\uff09</p> <p>\u800clog\u51fd\u6570\u662f\u4e2a\u51f9\u51fd\u6570\uff0c\u53cd\u8fc7\u6765\u7684\uff0c\u4e5f\u5c31\u662f \u5f26 \u5728 \u66f2\u7ebf\u7684 \u4e0b\u65b9\uff08\u4e5f\u5c31\u662f \u51fd\u6570\u503c &gt; \u671f\u671b\uff09\u501f\u52a9\u8111\u888b\u4e2d\u7684\u56fe\u50cf\u7406\u89e3</p> <p>\u4e0d\u7528\u6b7b\u8bb0\u786c\u80cc\uff0c\u53bb\u60f3\u56fe\u50cf\uff0c\u753b\u4e2a\u56fe\u5373\u53ef\uff0c\u4e5f\u5c31\u662f\u770b\u660e\u767d\u4e86\u516c\u5f0f\uff0c\u8fd9\u4e2a\u516c\u5f0f\u8bc1\u660e\u51fa\u6765\u6709\u4ec0\u4e48\u7528\uff1f</p>"},{"location":"learning/6_Diffusion1/#14-vaeelbo","title":"1.4 \u4e3a\u4ec0\u4e48\u8bf4 \u4f18\u5316VAE\u300a==\u300b\u6700\u5927\u5316ELBO\uff1f","text":"<p>\\(ELBO= \\mathbb{E}_{q_{\\phi}(z|x)}[log \\frac{p(x,z)}{q_{\\phi}(z|x)}]\\)</p> <p>\u518d\u89e3\u91ca\u4e00\u4e0b\uff1a\u7ed9\u5b9a\u6570\u636e\u96c6 \\(x\\)\uff0c\u90a3\u4e48\\(p(x)\\)\u786e\u5b9a\uff0c\u4e5f\u5c31\u662f\\(logp(x)\\)\u786e\u5b9a</p> <p>Encoder\u7684\u4f18\u5316\u76ee\u6807 \\(q_{\\phi}(z|x)=p(z|x)\\)  \u300a====\u300b KL\u6563\u5ea6=0</p> <p>\u90a3\u548c\u53c8\u662f\u56fa\u5b9a\u7684\uff0c\u6240\u4ee5\u62df\u5408\u672a\u77e5\u4f46\u662f\u786e\u5b9a\u7684p(x)\uff0c\u53d8\u6210\u4e86\u6700\u5927\u5316 ELBO</p> <p>VAE\u7684\u76ee\u7684\u5c31\u662f\u5b66\u5230\u771f\u5b9e\\(x\\)\u7684\u5206\u5e03\\(p(x)\\)\uff0c\u4f46\u662f\u53c8\u4e0d\u597d\u76f4\u63a5\u5b66\u5230\uff0c\u6240\u4ee5\u501f\u52a9\u8f85\u52a9\u53d8\u91cfz\uff0c\u901a\u8fc7Encoder\u548cdecoder\u95f4\u63a5\u5b66\u5230\\(x\\)\u7684\u5206\u5e03\uff0c\u53c8\u63a8\u51fa\u4e86\u4e0b\u754c\uff0c\u4e0b\u754c\u5c31\u662f\\(ELBO\\)\uff0c\u4f46\u662f\\(logP(x)=ELBO+KL\u6563\u5ea6\\)\uff0c\\(KL\u6563\u5ea6\\)\u662fEncoder\u7684\u76ee\u6807\uff0c\u7b49\u4e8e\\(0\\)\u6700\u597d\u5c31\u662f \\(q(z|x)\\)\u65e0\u9650\u63a5\u8fd1\\(p(z|x)\\)</p>"},{"location":"learning/6_Diffusion1/#15-elbo","title":"1.5 \u62c6\u89e3ELBO","text":"<p>\u4f7f\u7528\u94fe\u5f0f\u6cd5\u5219\u7684\u539f\u56e0\u662f\u56e0\u4e3a\uff0c\u6211\u4eec\u7528\u7684\u662f\u4e2d\u95f4\u53d8\u91cf\\(z\\)</p> <p></p> <p>\u5c06 ELBO\u62c6\u6210\u4e86 <code>ELBO=\u91cd\u5efa\u9879-\u5148\u9a8c\u5339\u914d\u9879</code></p> <p>\\(=\\mathbb{E}_{q_{\\phi}}(z|x)[logp_{\\theta}(x|z)]-D_{KL}(q_{\\phi}(z|x)||p(z))\\)</p> <ul> <li> \u9996\u5148\uff0c\u4e3a\u4ec0\u4e48\u53eb\u91cd\u5efa\u9879\uff1f</li> </ul> <p>\\(p(x|z)\\) \u4e5f\u5c31\u662f\u5df2\u77e5\\(z\\)\u5b66\u4e60\\(x\\)\uff0c\u5c31\u662f\\(decoder\\)</p> <p>decoder\u7684\u76ee\u7684\u5c31\u662f\u91cd\u5efa\u56fe\u50cf\\(x\\)\uff0c\u6240\u4ee5\u53eb\u91cd\u5efa\u9879</p> <ul> <li> \u4e3a\u4ec0\u4e48\u53eb\u5148\u9a8c\u5339\u914d\u9879\uff1f  \\(D_{KL}(q_{\\phi}(z|x)||p(z))\\)</li> </ul> <p>\\(q_{\\phi}(z|x)\\) \\(x\\)\u5230\\(z\\)\u7684\u5206\u5e03\uff0c\u5c31\u662f\\(Encoder\\)</p> <p>\u4e5f\u5c31\u662f\u8ba9Encoder\u5b66\u5230\u7684\u5206\u5e03\u63a5\u8fd1\u4e8e\\(z\\)\uff0c\\(z\\) \u662f\u4ec0\u4e48\uff1f\\(z\\)\u5c31\u662f\u6211\u4eec\u91c7\u6837\u7684\u9ad8\u65af\u5206\u5e03\uff0c\u4e5f\u5c31\u662f\\(p(z)\\)</p> <p>\u6211\u4eec\u8981\u8ba9 \u6211\u4eec\u7684Encoder\u7f16\u7801\uff0c\u628a\\(x\\)\u6620\u5c04\u5230\\(z\\)\u7a7a\u95f4\u4e0a\uff0c\\(z\\)\u80fd\u6ee1\u8db3\u6307\u5b9a\u7684\u5206\u5e03\uff0c\u4e5f\u5c31\u662fprior matching</p> <p>\\(z\\)\u5c31\u662fprior\uff0c\u4e5f\u5c31\u662fEncoder\u4ee5\u540e\u7684\\(z\\)\uff0c\\(z\\)\u6ee1\u8db3\u6211\u4eec\u81ea\u5df1\u9009\u7684\u9ad8\u65af\u5206\u5e03\uff0c\u4e5f\u5c31\u662f\u628a \u6211\u4eec\u7684 \\(x\\)\u6620\u5c04\u5230\\(z\\)\uff0c\\(z\\)\u6ee1\u8db3\u6211\u4eec\u81ea\u5df1\u9009\u7684\u9ad8\u65af\u5206\u5e03\uff0c\u771f\u662f\u56e0\u4e3a\u6211\u4eec\u7f16\u7801\u540e\u7684\\(z\\)\u6ee1\u8db3\u9ad8\u65af\u5206\u5e03\uff0c\u540e\u7eed\u6211\u4eec\u624d\u53ef\u4ee5\u629b\u5f00Encoder\uff0c\u540e\u7eed\u76f4\u63a5\u5728decoder\u4e0a\u8fdb\u884c\u91c7\u6837\u5f97\u5230\u9ad8\u65af\u5206\u5e03\u503c\uff0c\u7136\u540e\u901a\u8fc7decoder\u5f97\u5230\\(x\\)</p> <p>\u4e00\u53e5\u975e\u5e38\u91cd\u8981\u7684\u8bdd\uff1a</p> <p>Encoder\u628ax\u6620\u5c04\u6210z\uff0c\u5e76\u4e14\u8fd9\u4e2az\u65e0\u9650\u63a5\u8fd1\u9ad8\u65af\u5206\u5e03</p> <p>\u6240\u4ee5\u540e\u9700\u624d\u53ef\u4ee5\u76f4\u63a5\u4e22\u6389Encoder\uff0c\u76f4\u63a5\u91c7\u6837x\u6620\u5c04\u7684\u9ad8\u65af\u5206\u5e03z\uff0c\u76f4\u63a5\u91c7\u6837\uff0c\u7136\u540e\u91cd\u5efax</p> <p>\u4e5f\u5c31\u662f\u4fdd\u8bc1VAE\u80fd\u505a\u751f\u6210\u4efb\u52a1\u7684\u524d\u63d0\uff1a<code>\u628a\u771f\u5b9e\u5206\u5e03\u6620\u5c04\u5230 \u9ad8\u65af\u5206\u5e03\u4e0a</code></p> <ul> <li> \u4f18\u5316VAE\uff0c\u5c31\u662f\u4f18\u5316ELBO\uff0cELBO\u6709\u4e24\u9879\uff1a\u91cd\u5efa\u9879+KL\u6563\u5ea6\u9879</li> </ul> <p>\u6240\u4ee5\uff0c\u6700\u5927\u5316ELBO\uff0c\u5c31\u662f\u6700\u5927\u5316\u91cd\u5efa\u9879\uff0c\u4e5f\u5c31\u662f\u6700\u5c0f\u5316\u5148\u9a8c\u5339\u914d\u9879</p> <p>\u63a5\u4e0b\u6765\u89e3\u91ca\uff0c\u6700\u5927\u5316\u91cd\u5efa\u9879\u662f\u4ec0\u4e48\u610f\u601d\uff1f\u6700\u5c0f\u5316\u5148\u9a8c\u5339\u914d\u9879\u53c8\u662f\u4ec0\u4e48\u610f\u601d\uff1f</p> <ul> <li> \u6700\u5927\u5316\u91cd\u5efa\u9879\u600e\u4e48\u7406\u89e3\uff1a  \\(\\mathbb{E}_{q_{\\phi}}(z|x)[logp_{\\theta}(x|z)]\\)</li> </ul> <p>\u6700\u5927\u5316\u91cd\u5efa\u9879\u4e5f\u662f\u6a21\u578bdecoder\u51fa\u6765\u7684\\(x\\)\uff0c\u548c\u771f\u5b9e\u7684\\(x\\) \u8d8a\u76f8\u8fd1\u8d8a\u597d\uff0c\u4e5f\u5c31\u662f\u91cd\u5efa\u8bef\u5dee\u8d8a\u5c0f\u8d8a\u597d\uff0c\u4e5f\u5c31\u662f\u91cd\u5efa\u51fa\u6765\u7684\u6982\u7387\u8d8a\u5927\u8d8a\u597d\uff0c\u4e5f\u5c31\u662f \\(p_{\\theta}(x|z) \\rightarrow 1\\) \uff0c\u4e5f\u5c31\u662f  \\(logp_{\\theta}(x|z) \\rightarrow 0\\)</p> <ul> <li> \u6700\u5c0f\u5316 \u5148\u9a8c\u5339\u914d\u9879 \\(D_{KL}(q_{\\phi}(z|x)||p(z))\\)</li> </ul> <p>\\(q_{\\phi}(z|x)\\)  \u901a\u8fc7Encoder\u6620\u5c04\u5230\u9690\u7a7a\u95f4\u4e4b\u540e\uff0c\u5c3d\u91cf\u6ee1\u8db3\u5206\u5e03\uff0c\u8d8a\u63a5\u8fd1\u8d8a\u597d\uff0c\u4e5f\u5c31\u662f<code>\u6700\u5c0f\u5316KL\u6563\u5ea6\u21920</code></p> <p>\u8fd9\u9879KL\u6563\u5ea6\uff0c\u76f8\u5f53\u4e8e\u8bad\u7ec3Encoder\u7684loss\uff0c\u8fd9\u9879loss\u964d\u5230\u6700\u5c0f\uff0c\u4e5f\u5c31\u662fEncoder\u5b66\u5230\u6700\u597d</p> <p>\u5982\u679c<code>\u8fd9\u4e00\u9879\uff1d0</code>\uff0c\u4e5f\u5c31\u662f\u5b8c\u5168\u628a\u771f\u5b9e\u4e16\u754c\u7684\\(x\\)\u6620\u5c04\u5230\u4e86\u6807\u51c6\u7684\u6b63\u6001\u5206\u5e03\uff0c\u6b64\u65f6Encoder\u662f\u5b66\u4e60\u7684\u975e\u5e38\u5b8c\u7f8e\u7684</p> <p>\u4e5f\u5c31\u662f<code>KL=0</code></p> <ul> <li> ADD\uff1a\u5982\u679c\u628a\u540e\u9762\u9879\u53bb\u6389\uff0c\u5c31\u662f\u53ea\u7559\u4e0b \u91cd\u5efa\u9879\uff0c\u5c31\u53d8\u6210\u7684AE\uff08AutoEncoder\uff09\u6a21\u578b\uff0cAutoEncoder\u6ca1\u6709\u751f\u6210\u80fd\u529b\uff0c\u56e0\u4e3a\u6ca1\u6709\u628a\u539f\u59cb\u6570\u636e\u6620\u5c04\u5230\u9ad8\u65af\u5206\u5e03\u4e0a\uff0c\u4e5f\u5c31\u662f\u5728\u751f\u6210\u7684\u65f6\u5019\uff0c\u6ca1\u6709\u529e\u6cd5\u8fdb\u884c\u91c7\u6837\uff0c\u4e5f\u5c31\u662f\u6ca1\u6709\u529e\u6cd5\u901a\u8fc7decoder\u5f97\u5230\u56fe\u50cf\uff0c\uff08\u6ca1\u6709\u4e86\u91c7\u6837\uff0c\u5c31\u6ca1\u6709\u4e86\u751f\u6210\uff09</li> </ul> <p>AE\u6a21\u578b\u6ca1\u6709\u4e86\u91c7\u6837\u80fd\u529b\uff0cdecoder\u51fa\u6765\u7684\u4e1c\u897f\u4e5f\u5c31\u4e0d\u662f\u591a\u6837\u7684\uff0c\u4e0d\u662f\u4e00\u4e2a\u5168\u65b0\u7684\uff0c\u6b64\u65f6\\(z\\)\u7684\u5206\u5e03\uff0c\u5c31\u662fAutoEncoder\u7684z\u5206\u5e03\u662f\u672a\u77e5\u7684\uff0c\u56e0\u4e3a\u6211\u4eec\u6ca1\u6709\u628a\\(x\\)\u5f3a\u5236\u7684\u5f52\u4e8e\u67d0\u4e2a\u5206\u5e03\uff0c\u4e5f\u5c31\u662f\\(z\\)\u662f\u672a\u77e5\u7684\uff0c\u6b64\u65f6\u662f\u6ca1\u6709\u529e\u6cd5\u8fdb\u884c\u6709\u6548\u91c7\u6837\u7684\uff0c\u4e5f\u5c31\u6ca1\u6709\u529e\u6cd5\u751f\u6210\u66f4\u591a\u7684\u56fe\u7247</p>"},{"location":"learning/6_Diffusion1/#16-vae","title":"1.6 VAE\u7684\u7ed3\u6784","text":"<ul> <li> \u63cf\u8ff0\u56fe\u7247</li> </ul> <p>\u9996\u5148\u6709\u4e00\u5f20\u8bad\u7ec3\u96c6\u56fe\u7247x\uff0c\u901a\u8fc7Encoder\uff0cEncoder\u5c31\u662f\u4f1a\u628a\u8bad\u7ec3\u7684x\u6620\u5c04\u5230z\u4e0a\u9762\uff0cz\u6240\u5728\u7684\u662f\u4e00\u4e2a\u9690\u7a7a\u95f4\uff0c\u9690\u7a7a\u95f4\u600e\u4e48\u8868\u8fbe\u5462\uff1f\u56e0\u4e3a\u6211\u4eec\u5c31\u662f\u8981\u628ax\u6620\u5c04\u5230\u6b63\u6001\u5206\u5e03\u7a7a\u95f4\u4e0a\uff0c\u6b63\u6001\u5206\u5e03\u662f\u901a\u8fc7\u5747\u503c\u548c\u65b9\u5dee\u63cf\u8ff0\u7684\uff0c\u4e5f\u5c31\u662f\u4f1a\u5f97\u5230\u4e00\u4e2a\u5747\u503c\u5411\u91cf \\(\\mu_{\\phi}(x)\\) \u548c\u4e00\u4e2a\u65b9\u5dee\u5411\u91cf  \\(\\sigma^2_{\\phi}(x)\\) \uff0c\u56e0\u4e3a\u6211\u4eec\u4f7f\u7528\u7684\u662f\u6807\u51c6\u9ad8\u65af\u5206\u5e03\uff0c\u6240\u4ee5\u6211\u4eec\u4f18\u5316\u7684\u76ee\u6807\u5c31\u662f \\(\\mu_{\\phi}(x) \u2192 0\\) \u548c \\(\\sigma^2_{\\phi}(x) \u2192 \\mathrm{1}\\) <code>\u51680\u5411\u91cf</code> \u548c <code>\u51681\u5411\u91cf</code></p> <p></p> <p>\u4e0a\u9762\u63cf\u8ff0\u7684\u8fc7\u7a0b \u4e5f\u5c31\u662f \u516c\u5f0f\u4e2d\u7684 \u5148\u9a8c\u5339\u914d\u9879\uff0c\u4e5f\u5c31\u662f\u7b2c\u4e8c\u9879</p> <p>\u63a5\u4e0b\u6765\uff1a</p> <p></p> <p>\u6211\u4eec\u5f97\u5230\u4e86\u5c3d\u53ef\u80fd\u5f97<code>\u51680\u5411\u91cf</code> \\(\\mu_{\\phi}(x)\\)  \u3001<code>\u51681\u5411\u91cf</code> \\(\\sigma^2_{\\phi}(x)\\) \uff0c</p> <p>\\(z'\\)\u662f\u6839\u636eEncoder\u5f97\u5230\u7684 \\(\\mu\\) \u548c\\(\\sigma\\) \u91cd\u53c2\u6570\u5316\u5f97\u5230\u7684 \\(z'\\)</p> <p>\u6b63\u5f0f\u91c7\u6837\u7684\u65f6\u5019\uff0c\u4e0d\u9700\u8981Encoder\uff0c\u800c\u662f\u76f4\u63a5\u4ece \"\u6807\u51c6\"\u6b63\u6001\u5206\u5e03\\(z'\\)\u91c7\u6837\u51fa\u6765\u7684\uff0c\u7136\u540e\u901a\u8fc7decoder\u5f97\u5230\u4e00\u5f20\u65b0\u7684\u56fe\u7247</p> <p>\u6ce8\u610f\uff1a</p> <p>Encoder\u51fa\u6765\u7684\\(z\\)\uff0c\u5c31\u662f\\(z'\\)\u662f\u5e0c\u671b\u5c3d\u53ef\u80fd\u4e3a\u6807\u51c6\u6b63\u6001\u5206\u5e03\u7684</p>"},{"location":"learning/6_Diffusion1/#17","title":"1.7 \u53c2\u6570\u91cd\u6574\u5316","text":"<ul> <li> \u4e3a\u4ec0\u4e48\uff1f\u91cd\u53c2\u6570\u5316\u6280\u5de7</li> </ul> <p>\u5982\u679c\u4e0d\u8fdb\u884c\u53c2\u6570\u91cd\u6574\u5316\u7684\u8bdd\uff0c\\(z'\\)\u662f\u6839\u636e\u5747\u503c\u548c\u65b9\u5dee\u91c7\u6837\u51fa\u6765\u7684\uff0c\u4f46\u662f\u6211\u4eec\u7684\u5747\u503c \\(\\mu_{\\phi}(x)\\) \u548c\u65b9\u5dee \\(\\sigma^2_{\\phi}(x)\\) \u91cc\u9762\u90fd\u662f\u5305\u542b\u53c2\u6570\u7684<code>\u300a====\u300b</code>\u4e5f\u5c31\u662f\u6211\u4eec\u91c7\u6837\u7684\u968f\u673a\u566a\u58f0\u91cc\u9762\u662f\u5305\u542b\u53c2\u6570\u7684<code>\u300a=====\u300b</code> \u968f\u673a\u8fc7\u7a0b\u4e2d\u5305\u542b\u4e86\u5f85\u4f18\u5316\u7684\u53c2\u6570 \\(\\phi\\) \u6b64\u65f6\uff0c\u5bf9\u53c2\u6570\u7684 \\(\\phi\\) \u662f\u4e0d\u53ef\u5bfc\u7684<code>\u300a=====\u300b</code> \u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u968f\u673a\u8fc7\u7a0b\uff0c\u968f\u673a\u8fc7\u7a0b\u4e2d\u5305\u542b\u53c2\u6570\uff0c\u600e\u4e48\u6c42\u8fd9\u4e2a\u53c2\u6570\u7684\u5bfc\u6570\u5462\uff1f<code>\u300a=====\u300b</code>\u9274\u4e8e\u6b64\uff0c\u5f15\u5165\u4e86\u91cd\u53c2\u6570\u5316\u6280\u5de7\u3002\u8ba9\u8fd9\u4e2a\u8fc7\u7a0b\u53d8\u5f97\u53ef\u5bfc</p> <ul> <li> \u4ec0\u4e48\u662f\uff1f\u91cd\u53c2\u6570\u5316\u6280\u5de7</li> </ul> <p>\u9996\u5148\uff0c\u91cd\u53c2\u6570\u5316\u6280\u5de7\u662f\u5728\u4e00\u4e2a\u6807\u51c6\u6b63\u6001\u5206\u5e03\u91cc\u9762\uff0c\u5148\u968f\u673a\u53d6\u4e00\u4e2a\u503c\uff0c\u4e5f\u5c31\u662f \\(\\epsilon \\sim N(\\epsilon;0,I)\\)</p> <p>\u4e5f\u5c31\u662f\u91c7\u6837\u51fa\u6765\u7684 <code>\u5355\u4f4d\u566a\u58f0 \u00d7 \u65b9\u5dee + \u5747\u503c</code>  \u7b49\u4ef7\u4e8e \u4ece  \\(\\mu_{\\phi}(x)\\)  \u548c \\(\\sigma^2_{\\phi}(x)\\) \u4e2d\u76f4\u63a5\u91c7\u6837</p> <p>\u4e5f\u5c31\u662f\u8bf4\u8fd9\u6837\u91c7\u6837\u51fa\u6765\u7684\u53c2\u6570\uff0c\u5747\u503c\u4e5f\u7b49\u4e8e \\(\\mu_{\\phi}(x)\\) \uff0c\u65b9\u5dee\u4e5f\u7b49\u4e8e \\(\\sigma^2_{\\phi}(x)\\)</p> <ul> <li> <code>\u5355\u4f4d\u566a\u58f0 \u00d7 \u65b9\u5dee + \u5747\u503c</code>  \u7b49\u4ef7\u4e8e \u4ece  \\(\\mu_{\\phi}(x)\\)  \u548c \\(\\sigma^2_{\\phi}(x)\\) \u4e2d\u76f4\u63a5\u91c7\u6837 ||\u597d\u5904\u662f\u662f\u4ec0\u4e48\uff1f</li> </ul> <p>\u9996\u5148\uff0c\u6211\u4eec\u7684\u968f\u673a\u8fc7\u7a0b\u662f\u5728\u4e00\u4e2a\u6ca1\u6709\u53c2\u6570\u7684\u566a\u58f0\u4e2d\u91c7\u6837\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\u8fd9\u4e2a\u968f\u673a\u8fc7\u7a0b\u662f\u4e0d\u5305\u542b\u53c2\u6570\u7684\uff0c\u90a3\u540e\u9762\u5bf9\u53c2\u6570 \\(\\phi\\) \u4f18\u5316\u7684\u65f6\u5019\uff0c\u5c31\u53ef\u4ee5\u76f4\u63a5\u6c42\u5bfc\u4e86\uff0c\u56e0\u4e3a\u8fd9\u4e2a\u53c2\u6570\u662f \u5265\u79bb\u51fa\u8fd9\u4e2a\u968f\u673a\u8fc7\u7a0b\u7684\uff0c\u4ee5\u4e0a\u5c31\u662f\u91cd\u53c2\u6570\u5316\u7684\u8fc7\u7a0b\uff1b</p> <p>\u603b\u4e4b\u91cd\u53c2\u6570\u5316\u8fc7\u7a0b \u4fdd\u8bc1\u4e86 \u91c7\u6837\u7684\u5206\u5e03\u6ca1\u6709\u53d8\uff0c\u7136\u540e\u53c8\u8ba9\u6240\u6709\u53c2\u6570\u662f\u53ef\u5bfc\u7684\uff0c\u800c\u6ca1\u6709\u5728\u4e00\u4e2a\u968f\u673a\u7684\u8fc7\u7a0b\u4e2d\uff0c\u8fd9\u6837\u6a21\u578b\u624d\u80fd\u8bad\u7ec3\uff0c\u4e5f\u5c31\u662f\u91cd\u53c2\u6570\u5316\u6280\u5de7\u7684\u597d\u5904</p>"},{"location":"learning/6_Diffusion1/#18-vae","title":"1.8 VAE\u6a21\u578b\u5c0f\u7ed3","text":"<p>\u9996\u5148\u662f \u6a21\u578b\u7684\u6574\u4f53\u67b6\u6784\uff0c\u5e76\u5305\u542b\u4e86 \u91cd\u53c2\u6570\u5316\u6280\u5de7</p> <p>\u7b2c\u4e8c\u70b9\uff0c\u4f18\u5316VAE \u7b49\u4ef7\u4e8e \u4f18\u5316 ELBO\uff0c\u66f4\u5177\u4f53\u6765\u8bf4\u5c31\u662f \u6700\u5927\u5316 ELBO</p> <p>\u7b2c\u4e09\u70b9\uff0c\u7ee7\u7eed\u62c6\u89e3ELBO\uff0cELBO\u5305\u542b\u4e24\u90e8\u5206\uff081\uff09\u91cd\u5efa\u9879\uff082\uff09\u5148\u9a8c\u5339\u914d\u9879</p> <p>\uff081\uff09\u91cd\u5efa\u9879\uff1a\u53cd\u6620\u7684\u662fdecoder\u4ece\u9690\u53d8\u91cf\u91cd\u5efa\u56fe\u7247\u7684\u80fd\u529b</p> <p>\uff082\uff09\u5148\u9a8c\u5339\u914d\u9879\uff1a\u53cd\u6620\u7684\u662fEncoder\u5c06\u56fe\u7247\u6620\u5c04\u5230\u6307\u5b9a\u9690\u53d8\u91cf\u5206\u5e03\u7684\u80fd\u529b\uff0c\u4e5f\u5c31\u662f\u628a\u56fe\u7247\u6620\u5c04\u5230\u6807\u51c6\u6b63\u6001\u5206\u5e03\u7684\u80fd\u529b</p> <p>\u7b2c\u56db\u70b9\uff0c\u91cd\u53c2\u6570\u5316\u6280\u5de7\u7684\u597d\u5904</p> <p>\u7b2c\u4e94\u70b9\uff0c\u751f\u6210\u7684\u65f6\u5019\u5c31\u4e0d\u9700\u8981Encoder\u4e86\uff0c\u6bcf\u6b21\u53ea\u9700\u8981\u5728Encoder\u51fa\u6765\u7684\u53d8\u91cf\u91c7\u6837\u4e00\u4e2az\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u901a\u8fc7decoder\u751f\u6210\u4e00\u5f20\u65b0\u7684\u56fe\u7247\u4e86\uff0c\u4ee5\u4e0a\u662f\u4e00\u4e2aVAE\u7684\u8fc7\u7a0b</p>"},{"location":"learning/6_Diffusion1/#2-mhvae","title":"2 MHVAE\u7684\u63a8\u5bfc","text":"<p>\u4e2d\u6587\uff1a\u9a6c\u5c14\u79d1\u592b\u94fe\u7684\u7ea7\u8054\u7684VAE\uff08\u7ea7\u8054\u9a6c\u5c14\u79d1\u592b\u94feVAE\uff09</p> <p></p> <ul> <li>\u5b9e\u9645\u4e0a\u5c31\u662f\u628a\u5f88\u591aVAE\u5806\u53e0\u8d77\u6765\uff0c\u800c\u4e14\u6bcf\u4e00\u4e2a\u72b6\u6001\u503c\u4f9d\u8d56\u524d\u4e00\u4e2a\u548c\u5b83\u76f8\u90bb\u7684\u524d\u4e00\u4e2a\u72b6\u6001\uff0c\u800c\u4e0e\u4e4b\u524d\u7684\u66f4\u957f\u66f4\u8fdc\u7684\u72b6\u6001\u662f\u65e0\u5173\u7684\uff0c\u4e5f\u5c31\u662f\u9a6c\u5c14\u79d1\u592b\u94fe</li> <li>\u516c\u5f0f\u63a8\u5bfc\u7684\u53d8\u5316\uff1a</li> </ul> <p>\uff081\uff09\u516c\u5f0f\u63a8\u5bfc\u7684\u539f\u7406\u662f\u4e00\u6a21\u4e00\u6837\u7684</p> <p>\uff082\uff09\u533a\u522b\u5728\u4e8e\uff0c\u4e4b\u524d\u5355\u4e2aVAE\u53ea\u9700\u8981\u4e00\u4e2a\u8f85\u52a9\u53d8\u91cf\\(z\\)\uff0c\u73b0\u5728\u7ea7\u8054\u9a6c\u5c14\u79d1\u592bVAE\uff0c\u6709\u591a\u4e2a\u8f85\u52a9\u53d8\u91cf\\(z\\)\uff0c\u6240\u4ee5\u4ece\\(z\u2192z_{1:T}\\)</p>"},{"location":"learning/6_Diffusion1/#3-vdm","title":"3 VDM\u7406\u8bba\u63a8\u5bfc","text":"<p>\u4e2d\u6587\u7ffb\u8bd1\uff1aVariational Diffusion Models \u53d8\u5206\u6269\u6563\u6a21\u578b</p> <p>\u533a\u5206\uff1a\uff08 Denoising Diffusion Probabilistic Models\uff0cDDPM\uff09\u53bb\u566a\u6982\u7387\u6269\u6563\u6a21\u578b</p> <p></p> <p>\u4ece \u7ea7\u8054\u9a6c\u5c14\u79d1\u592bVAE \\(MHVAE\\)  \u2192  \\(VDM\\)</p> <p>MHVAE+3\u4e2a\u9650\u5236\u6761\u4ef6 \u5c31\u4f1a\u53d8\u6210 VDM</p> <p>\u9650\u52361\uff1a\u6570\u636e\\(x\\)\u548c\u6240\u6709\u7684\u9690\u53d8\u91cf\\(z_t\\)\u7ef4\u5ea6\u76f8\u540c</p> <p>\u4e4b\u524d\u7684VAE\uff0c\\(x\\)\u548c\\(z\\)\u7684\u7ef4\u5ea6\u53ef\u4ee5\u662f\u4e0d\u540c\uff0c\u4e14\u4e00\u822c\u4e5f\u662f\u4e0d\u540c\u7684</p> <p>\u4f46\u5982\u679c\u662f \\(VDM\\)\u7684\u8bdd\uff0c\u6620\u5c04\u7684\u7ef4\u5ea6\u5c31\u662f\u76f8\u540c\u7684\uff0c\u4e5f\u5c31\u662f\\(x\\)\u548c\u6240\u6709\u7684\u9690\u53d8\u91cf\\(z\\)\u7684\u7ef4\u5ea6\u90fd\u662f\u76f8\u540c\u7684</p> <p>\u9650\u52362\uff1a\u6240\u4ee5Encoder\u7684\u8fc7\u7a0b\u662f\u4e0d\u9700\u8981\u5b66\u4e60\u7684</p> <p>\u4e5f\u5c31\u662f\u4ece \\(z_1 \u2192 z_2\\) \u3001\u4ece \\(z_2\\) \u5230 \\(z_3\\) \u3001\u4ece \\(z_3\\)\u5230\\(z_4\\) \u3001\u4ece\\(z_{t-1}\\)\u5230\\(z_t\\) \u662f\u4e0d\u9700\u8981\u5b66\u4e60\u7684\uff0c\u662f\u4eba\u4e3a\u9884\u5b9a\u4e49\u597d\u7684\uff0c\u662f\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4 \u6bcf\u4e0b\u4e00\u4e2a\u72b6\u6001 \u90fd\u662f\u4ee5 \u4e0a\u4e00\u4e2a\u72b6\u6001\u4e3a\u5747\u503c\u7684\u9ad8\u65af\u5206\u5e03  \\(q(z_t|z_{t-1})\\)\uff0c\u8fd9\u4e2a\u5747\u503c\u548c\u65b9\u5dee\u90fd\u53ef\u4ee5\u5b9a\u4e49\u597d\uff0c\u5f53\u7136\u4e5f\u53ef\u4ee5\u8bbe\u7f6e\u4e3a\u9700\u8981\u5b66\u4e60\u7684\uff0c\u4f46\u662f\u8bba\u6587\u4e2d\u8bbe\u7f6e\u7684\u662f\u5148\u9884\u5b9a\u4e49\u597d\u7684</p> <p>\u9650\u52363\uff1a\u6700\u540e\u7684 \\(z_t\\)\u662f\u6ee1\u8db3\u6807\u51c6\u7684\u9ad8\u65af\u5206\u5e03\u7684</p> <p>\u7c7b\u6bd4VAE\u6700\u540e\u4e5f\u662f\u8981\u62df\u5408\u4e00\u4e2a\u6807\u51c6 \u9ad8\u65af\u5206\u5e03</p> <p>\u4f46 VAE\u4e2d\u7684Encoder\u8fc7\u7a0b\u662f\u5b66\u4e60\u5230\u7684\uff0c\u5b66\u4e60\u76ee\u6807\u5c31\u662f\u5c06\u539f\u59cb\u56fe\u50cf \\(x\\) \u53d8\u6210\u4e00\u4e2a\u6807\u51c6\u9ad8\u65af\u5206\u5e03 \\(z\\)</p> <p>\u4f46\u73b0\u5728\u662f\u4eba\u5de5\u5b9a\u4e49\u7684Encoder\u7684\u8fc7\u7a0b\uff0c\u8fd9\u5c31\u8981\u6c42\u6211\u4eec\u81ea\u5df1\u5b9a\u4e49\u7684\u8fd9\u4e2a\u8fc7\u7a0b \u6ee1\u8db3 \\(z_t\\) \u4e3a\u6807\u51c6\u9ad8\u65af\u5206\u5e03</p> <p>\u4e5f\u5c31\u662fEncoder\u6620\u5c04\\(x\\)\u5230\\(z_t\\)\u7684\u8fc7\u7a0b\u672c\u6765\u662f\u901a\u8fc7\u5b66\u4e60\u4f7f\u5176\u80fd\u591f\u6620\u5c04\u5230\u4e00\u4e2a\u6807\u51c6\u9ad8\u65af\u5206\u5e03\uff0c\u800c\u73b0\u5728\u662f\u901a\u8fc7\u8ba4\u4e3a\u5b9a\u4e49\u8ba9\u5b83\u53bb\u6620\u5c04\u5230\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03\uff0c\u6240\u4ee5\u8981\u6c42\uff0c\u6211\u4eec\u5b9a\u4e49\u7684\u9ad8\u65af\u5206\u5e03\\(q\\)\uff0c\u4e00\u5b9a\u8981\u4f7f\u5f97\u6700\u540e\u7684 \\(z_t\\) \u662f\u6807\u51c6\u9ad8\u65af\u5206\u5e03\uff0c\u4e5f\u5c31\u6ee1\u8db3\u4e86\u4e4b\u524dVAE\u63a8\u5bfc\u7684\u8fc7\u7a0b</p> <p><code>\u603b\u7ed3\uff1aMHVAE+3\u4e2a\u9650\u5236=VDM</code></p>"},{"location":"learning/6_Diffusion1/#31","title":"3.1 \u9650\u5236\u662f\u600e\u4e48\u52a0\u7684\uff1f","text":"<ul> <li>\u9650\u52361\u548c\u9650\u52362\uff0c\u8981\u6c42\u7ef4\u5ea6\u76f8\u540c\uff0c\u5b9e\u9645\u4e0a\u4e3b\u8981\u5728\u9650\u52362\uff0c\u9650\u52361\u8981\u6c42\u7ef4\u5ea6\u76f8\u540c\uff0c\u9650\u52361\u662f\u9650\u52362\u7684\u524d\u63d0\uff0c\u56e0\u4e3a\u5982\u679c\u9650\u52361\u90fd\u4e0d\u6ee1\u8db3\uff0c\u4e5f\u5c31\u662f\u7ef4\u5ea6\u90fd\u4e0d\u76f8\u540c\u7684\u8bdd\uff0c\u90a3\u4e48\u662f\u6ca1\u6709\u529e\u6cd5\u76f4\u63a5\u4ee5\u524d\u4e00\u72b6\u6001\uff08\u4e58\u4ee5\u67d0\u4e2a\u7cfb\u6570\uff09\u4e3a\u5747\u503c\u7684\uff0c\u56e0\u4e3a\u7ef4\u5ea6\u90fd\u4e0d\u76f8\u540c\uff0c\u662f\u4e0d\u53ef\u4ee5\u76f4\u63a5\u4ee5\u524d\u4e00\u72b6\u6001\u4e3a\u5747\u503c\u7684\uff0c\u56e0\u6b64\uff0c\u9996\u5148\u7b2c\u4e00\u70b9\uff0c\u9650\u52361\u548c\u9650\u52362\u8981\u4e00\u8d77\u770b</li> <li>\u56e0\u6b64\uff0c\u5177\u4f53\u5730\u505a\u6cd5\u662f\uff1a\u4eba\u4e3a\u7684\u5b9a\u4e49\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03\uff0c\u505aEncoder\uff0c\u5728\u6587\u7ae0\u4e2d\u7684\u5b9a\u4e49\u662f\uff1a</li> </ul> <p>\\(q(x_{t}|x_{t-1}) \\sim N(x_t;\\sqrt{\\alpha_t}x_{t-1},(1-\\alpha_t)t)\\)</p> <p>\u8bfb\uff1a\u5df2\u77e5 \\(x_{t-1}\\)  \u7684\u524d\u63d0\u4e0b\uff0c\\(x_t\\) \u670d\u4ece \u5747\u503c\u4e3a  \\(\\sqrt{\\alpha_t}x_{t-1}\\) \u65b9\u5dee\u4e3a \\((1-\\alpha_t)t\\)  \u7684\u9ad8\u65af\u5206\u5e03</p> <p>\u4e3a\u4ec0\u4e48\u662f\u8fd9\u6837\u5b9a\u4e49\u7684\u5462\uff1f\u600e\u4e48\u7406\u89e3\uff1f</p> <ul> <li>\u9996\u5148\uff0c\\(\\sqrt{\\alpha_t}x_{t-1} \u2192 0\u3001(1-\\alpha_t)t \u2192 1\\)  \u4e5f\u5c31\u662f\u8bf4 \\(\\alpha_t \u2192 0\\)</li> <li>\u5176\u6b21\uff0c\u8981\u77e5\u9053 \u539f\u59cb\u56fe\u7247\u968f\u7740t\u7684\u589e\u5927\uff0c\u6240\u542b\u7684\u4fe1\u606f\u6d53\u5ea6\u5c31\u4f1a\u964d\u4f4e\uff0c\u56e0\u4e3a\u4e00\u76f4\u5728\u00d7  \\(\\sqrt{\\alpha_t}\\) \uff0c\u5e76\u4e14  \\(\\alpha_t \uff1c 1\\) </li> <li>\u6240\u4ee5\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5982\u679c\u521d\u59cb\u503c\u662f \\(x_0\\) \u7684\u8bdd\uff0c \u968f\u7740 \\(t\\) \u8d8a\u5927\uff0c\\(x_t\\) \u6240\u5305\u542b\u7684\u4fe1\u606f\u5c31\u4f1a\u8d8a\u5c11\uff0c\u566a\u58f0\u5c31\u4f1a\u8d8a\u591a\uff0c\u56e0\u4e3aEncoder\u5c31\u662f\u5728\u6bcf\u4e00\u6b65\u90fd\u4f1a\u52a0\u4e00\u4e9b\u566a\u58f0\uff0c\u6240\u4ee5\u566a\u58f0\u4f1a\u8d8a\u6765\u8d8a\u5927\uff0c\u6700\u540e\u52a0\u4e86\u5f88\u591a\u6b65\uff0c\u76f4\u5230 \\(x_t\\)\uff0c\u57fa\u672c\u4e0a\u8fd1\u4f3c\u8d8b\u8fd1\u4e8e \u4e00\u4e2a \u9ad8\u65af\u5206\u5e03\u3002\u5f53\u7136 \u4e0d\u53ef\u80fd \u5b8c\u5168 \u7b49\u4e8e \u4e00\u4e2a \u9ad8\u65af\u5206\u5e03\uff0c\u53ea\u9700\u8981\u8fd1\u4f3c\u63a5\u8fd1\u5373\u53ef \u9ad8\u65af\u5206\u5e03\u5373\u53ef</li> </ul> <p>\u8fd9\u91cc\u7684\u4fe1\u606f\u6307\u7684\u662f\u786e\u5b9a\u6027\u4fe1\u606f\uff0c\u968f\u7740t\u53d8\u5927\uff0c\u786e\u5b9a\u6027\u4fe1\u606f\u8d8a\u5c11</p> <ul> <li>\\(\\alpha\\)\u662f\u4ec0\u4e48\u5462\uff1f \\(\\alpha\\)  \u662f\u4e00\u4e2a\u8d85\u53c2\u6570\uff0c\u662f\u4eba\u4e3a\u5b9a\u4e49\u7684\uff0c\u7c7b\u4f3c\u4e8e\u5b66\u4e60\u7387\uff0c\u53ef\u4ee5\u4eba\u4e3a\u5b9a\u4e49\u4e00\u4e2a\u516c\u5f0f\uff0c\u4e0et\u6709\u5173\u7684\u516c\u5f0f\uff0c\u6216\u8005\u901a\u8fc7\u5b66\u4e60\u5f97\u5230\uff0c\u603b\u4e4b\u5b9a\u4e49\u51fa\u6765\u7684 \\(\\alpha_t\\)\u8981\u6ee1\u8db3 \\(x_t\\)  \u65e0\u9650\u63a5\u8fd1\u4e8e \u9ad8\u65af\u5206\u5e03\uff0c\u4e00\u822c\u662f\u8ba4\u4e3a\u5b9a\u4e49\u516c\u5f0f\uff0c\u5f53\u4e00\u4e2a\u8d85\u53c2\u6570</li> <li>\u9650\u52363\uff0c\u6700\u540e\u4e00\u4e2a\u65f6\u523b \\(x_t\\)\u8981\u6ee1\u8db3\u9ad8\u65af\u5206\u5e03\uff0c\u6570\u5b66\u8868\u8fbe\u5c31\u662f \\(p(x_t)\\sim N(x_T;\\mathrm{0,I})\\)</li> </ul> <p></p> <ul> <li>\u4ee5\u4e0a\u662fVDM\u7684\u56fe\u793a</li> <li>\u5982\u679c\u53ea\u662fMHVAE\u7684\u8bdd\uff0c\u6bcf\u4e00\u4e2ap\u548cq\u90fd\u662f\u8981\u5b66\u4e60\u7684\uff0c\u73b0\u5728VDM\u7684\u8bdd\uff0c\u53ea\u6709p\u662f\u8981\u5b66\u4e60\u7684\uff0c\u901a\u8fc7 \\(\\theta\\) \u6765\u62df\u5408\uff0c\u4f46\u662f \\(q\\) \uff08q\u8868\u793a\u4ece\u4e0a\u4e00\u4e2a\u72b6\u6001\u5230\u4e0b\u4e00\u4e2a\u72b6\u6001\uff09\u6bcf\u4e00\u4e2a\u72b6\u6001\u90fd\u662f\u5df2\u77e5\u7684\uff08\u9012\u63a8\u5df2\u77e5\uff09\uff0c\u90fd\u662f\u4eba\u4e3a\u5b9a\u4e49\u7684\uff0c\u5305\u62ec \\(z_t\\)  \u4e5f\u662f\u5df2\u77e5\u7684\uff0c\u5e76\u4e14\u6ee1\u8db3 \u6807\u51c6\u9ad8\u65af\u5206\u5e03\uff0c\u56e0\u6b64 VDM\u8981\u5b66\u4e60\u7684\u53ea\u662f \u4e0a\u9762\u4e00\u90e8\u5206 p \u8fc7\u7a0b\uff0c\u964d\u4f4e\u6a21\u578b\u5b66\u4e60\u96be\u5ea6</li> </ul>"},{"location":"learning/6_Diffusion1/#32-vdmelbo","title":"3.2 VDM\u7684ELBO\u63a8\u5bfc","text":"<ul> <li> <p>VAE \u2192 MHVAE \u2192 VDM \u63a8\u5bfc\u90fd\u662f\u5f88\u7c7b\u4f3c\u7684\uff0c\u533a\u522b\u5c31\u662f\u4e00\u4e9b\u7b26\u53f7\u7684\u7ec6\u8282</p> </li> <li> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u4e4b\u524d\u7528x \u8868\u793a\u7b2c\u4e00\u4e2a\u72b6\u6001\uff0c\u73b0\u5728\u7528 \\(x_0\\) \u8868\u793a\u7b2c\u4e00\u4e2a\u72b6\u6001</p> </li> <li>\u4e4b\u524d\u7528 \\(z_{1:T}\\) \u8868\u793a\u4e00\u4e9b\u9690\u53d8\u91cf\uff0c\u73b0\u5728VDM\u4e2d\u7ef4\u5ea6\u90fd\u4e00\u6837\uff0c\u6240\u4ee5\u76f4\u63a5\u4f5c\u7528 \\(x_{1:T}\\) \u6765\u8868\u793a \\(z_{1:T}\\) </li> <li>\u4e5f\u5c31\u662f \u7ea2\u5b57\u6807\u51fa\u7684 \\(x\\) \u66ff\u6362\u6210 \\(x_0\\)\uff0c\\(z_t\\) \u6362\u6210 \\(x_t\\)</li> <li>\u7ecf\u8fc7\u4ee5\u4e0a\u7b26\u53f7\u7684\u66ff\u6362\uff0c\u53ef\u4ee5\u770b\u5230 \\(VDM\\) \u4e2d\uff0c\u662f\u6ca1\u6709 \\(z\\) \u8fd9\u4e2a\u53d8\u91cf\u4e86\uff0c\u5168\u662f \\(x_0\\) \u5230 \\(x_T\\)\u4e86\uff0c\u63a8\u5bfc\u5c31\u662f\u4e00\u6a21\u4e00\u6837\u7684\uff0c\u5c31\u662f\u628a\u7b26\u53f7\u53d8\u4e00\u4e0b</li> <li>\u6700\u540e\u53ef\u4ee5\u8bc1\u660e\u51fa\u6765 \\(ELBO\\)</li> </ul>"},{"location":"learning/6_Diffusion1/#33-elbo","title":"3.3  ELBO\u7684\u62c6\u89e3","text":"<p>\u7ee7\u7eed\u6cbf\u7528\u4e4b\u524d\u7684\u7814\u7a76\u6b65\u9aa4\uff0c\u62c6\u89e3VDM\u7684ELBO\uff0c\u89c2\u5bdf\u4e0eVAE\u7684\u62c6\u89e3\u6709\u4ec0\u4e48\u4e0d\u540c</p> <p>\\(VAE\u7684ELBO\u62c6\u89e3=\u91cd\u5efa\u9879-KL\u6563\u5ea6\uff08\u5148\u9a8c\u5339\u914d\u9879\uff09\\)</p> <p></p> <ul> <li>\u9a6c\u5c14\u79d1\u592b\u6027\u8d28\uff1a\u53ea \u4e0e\u524d\u4e00\u4e2a\u72b6\u6001\u6709\u5173</li> <li>p\u8fc7\u7a0b\u662f\u540e\u5411 decoder\u8fc7\u7a0b\uff0c\u6240\u4ee5\u662f\u4ee5 \\(x_t\\) \u4e3a\u6761\u4ef6</li> <li>q\u8fc7\u7a0b\u662f\u524d\u5411 Encoder\u8fc7\u7a0b\uff0c\u6240\u4ee5\u662f\u4ee5 \\(x_{t-1}\\) \u4e3a\u6761\u4ef6</li> </ul> <p>\u7ee7\u7eed\u63a8\u5bfc\uff1a</p> <p></p> <p></p> <ul> <li>\u7740\u91cd\u7406\u89e3 \u4ec0\u4e48\u53eb \u5220\u6389\u65e0\u5173\u53d8\u91cf</li> </ul> <p>\u5c31\u770b\u7eff\u6846\u90e8\u5206 <code>\u5220\u6389\u65e0\u5173\u53d8\u91cf</code> \u8fd9\u4e00\u884c</p> <p>\u5bf9\u4ec0\u4e48\u6c42\u671f\u671b\uff1f\u5bf9 \\(x_t\\)\u6c42\u671f\u671b\uff0c\u540c\u65f6\u4e5f\u9700\u8981\u77e5\u9053 \\(x_{t+1}\\) \u548c \\(x_{t-1}\\) \u7684\u72b6\u6001\u4e0b\uff0c\u5bf9 \\(x_t\\) \u6c42\u671f\u671b\uff0c\u6240\u6d89\u53ca\u7684\u53d8\u91cf \u5c31\u662f \\(x_{t-1}\\) \u3001\\(x_{t+1}\\)</p> <p>\u800c\u524d\u9762\u7684\u5206\u5e03\u662f \\(q(x_{1:T}|x_0)\\) \u6709\u5f88\u591a\u65e0\u5173\u53d8\u91cf\uff0c\u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u5212\u6389\uff0c\u53ea\u4fdd\u7559 \u4e0e \\(x_{t}\u3001x_{t-1}\u3001x_{t+1}\\)\u6709\u5173\u7684\u90e8\u5206</p> <p>\u56e0\u4e3a\u6211\u4eec\u53ea\u5173\u5fc3 \u8981\u6c42\u671f\u671b\u91cc\u9762 \u6709\u5173 \u53d8\u91cf\u7684 \u5206\u5e03\u5373\u53ef\uff0c\u4e0e  \u90a3\u4e9b\u65e0\u5173 \u53d8\u91cf\u7684\u5206\u5e03\u662f \u6ca1\u6709\u5173\u7cfb\u7684</p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u8981\u505a\u7684\u5c31\u662f\u628a \u62ec\u53f7\u91cc\u9762 \u65e0\u5173\u7684\u53d8\u91cf\u5220\u6389\uff0c\u5b9e\u9645\u4e0a\u5c31\u662f\u4ec0\u4e48\u5206\u5e03\u6c42\u671f\u671b\uff0c\u4e0e\u4ec0\u4e48\u53d8\u91cf\u6709\u5173\uff0c\u5c31\u4fdd\u7559\u5206\u5e03\u4e2d\u7684\u53d8\u91cf\u5373\u53ef</p> <p>\u84dd\u8272\u6846\u540c\u7406</p> <p>\u671f\u671b\u91cc\u9762\u53ea\u4e0e \\(x_T\\) \u548c \\(x_{T-1}\\)\u6709\u5173\uff0c\u671f\u671b\u4e0b\u6807\u5c31\u53ea\u4fdd\u7559 \\(x_{T}\\) \u548c \\(x_{T-1}\\) \u6709\u5173\u7684\u5206\u5e03\u5373\u53ef\uff0c\u5220\u6389\u65e0\u5173\u53d8\u91cf\u5373\u65e0\u5173\u7684\u5206\u5e03</p> <p>\u6700\u540e\u4e00\u6b65\u7684\u63a8\u5bfc\uff0c\u5148\u770b\u84dd\u8272\u6846\u90e8\u5206\uff1a</p> <p></p> <ul> <li>\u9996\u5148\u6c42\u671f\u671b\uff0c\u5e76\u4e14\u662f\u5bf9\u4e24\u4e2a\u53d8\u91cf\u6c42\u671f\u671b\uff0c\u6240\u4ee5\u7528\u591a\u5143\u51fd\u6570\u671f\u671b\u7684\u5b9a\u4e49</li> <li>\u7531\u9a6c\u5c14\u79d1\u592b\u6027\u8d28\uff1a\\(q(x_T|x_{T-1},x_0)\\)  \u53ef\u4ee5\u5212\u6389 \\(x_0\\) \u53d8\u6210 \\(q(x_T|x_{T-1})\\) \uff0c\u4f46\u662f \\(q(x_{T-1}|x_0)\\)\u5212\u4e0d\u6389</li> <li>\u62fd\u51fa \\(x_T\\)\uff0c\\(dx_{T}\\) \u79ef\u5206\u53f7\uff0c\u8981\u79ef\u5206\u7684\u5206\u5e03\uff0c\u548c\u8981\u79ef\u5206\u7684\u51fd\u6570\uff0c\u6784\u6210\u4e00\u4e2a\u671f\u671b</li> </ul> <p></p> <ul> <li>\u63a5\u7740 \u5c31\u53d8\u6210\u4e86\u4e00\u4e2a KL\u6563\u5ea6 \\(KL(A||B)=\\int P(A)\\log\\frac{P(A)}{P(B)}?\\)\u8fd9\u516c\u5f0f\u771f\u8bb0\u4e0d\u4f4f</li> </ul> <p>Okay,\u84dd\u8272\u6846\u63a8\u5bfc\u5b8c\u4e86</p> <p></p> <p>\u63a8\u5bfc\u7eff\u8272\u6846</p> <p></p> <ul> <li>\u4e00\u4e2a\u79ef\u5206\u53d8\u91cf+\u4e00\u4e2a\u79ef\u5206\u53f7 \u2192 1\u5143\u671f\u671b</li> <li>2\u4e2a\u79ef\u5206\u53d8\u91cf+2\u4e2a\u79ef\u5206\u53f7 \u2192 2\u5143\u671f\u671b</li> <li> <p>\u6709\u4e00\u6b65\uff1a\u7531\u9a6c\u5c14\u79d1\u592b\u6027\u8d28 \\(q(x_t|x_{t-1},x_{t+1},x_0)\\) \u53ea\u7559\u4e0b \\(q(x_t|x_{t-1})\\)</p> </li> <li> <p>\\(dx\\) \u8bfb\u6210\u79ef\u5206\u7b26\u53f7</p> </li> </ul> <p>ELBO\u62c6\u89e3\u7684\u8bc1\u660e\uff0c\u73b0\u5728\u770b\u6bcf\u4e00\u9879\u5177\u4f53\u5730\u542b\u4e49</p>"},{"location":"learning/6_Diffusion1/#34-elbo","title":"3.4 ELBO\u62c6\u89e3\u51fa\u6765\u7684\u542b\u4e49","text":"<p>\u9996\u5148\uff0c\u7b2c\u4e00\u9879\uff1a\\(\\mathbb{E}_{q(x_1|x_0)}[\\log p_{\\theta}(x_0|x_1)]\\)</p> <p>\u91cd\u5efa\u9879</p> <ul> <li>\u628a\\(x_0\\)\u770b\u505a\u4e4b\u524d VAE\u7684\\(x\\) </li> <li>\\(x_1\\) \u770b\u505a\u4e4b\u524d\u7684 \\(z\\)</li> </ul> <p>\u5c31\u662f\u4e4b\u524d\u7684decoderye\u4e5f\u5c31\u662f\uff08\u91cd\u5efa\u9879\uff0creconstruction term\uff09</p> <p>\u63a5\u7740\uff0c\u7b2c\u4e8c\u9879\uff1a\\(\\mathbb{E}_{q(x_{T-1}|x_0)}[D_{KL}(q(x_T|x_{T-1})||p(x_T))]\\)</p> <ul> <li>\\(x_{T-1}\\) \u770b\u6210 \\(x\\)</li> <li>\\(x_T\\) \u770b\u6210\u4e4b\u524d\u7684 \\(z\\)</li> </ul> <p>\u4e5f\u5c31\u662f\u5148\u9a8c\u5339\u914d\u9879\uff0cEncoder\uff0c\uff08prior matching term\uff09</p> <p>\u8fd9\u4e24\u9879\u4e0eVAE\u4e2d\u4e00\u6a21\u4e00\u6837\uff0c\u591a\u4e86\u6700\u540e\u4e00\u9879\uff1a</p> <p>\u6700\u540e\uff0c\u7b2c\u4e09\u9879 \\(\\sum_{t=1}^{T-1} \\mathbb{E}_{q(x_{t-1},x_{t+1 }|x_0)}[D_{KL}(q(x_t|x_{t-1})||p_{\\theta}(x_t|x_{t+1}))]\\)</p> <ul> <li>\u53eb\u505a consistency term</li> <li>\u7b2c\u4e09\u9879\u524d\u9762\u662f\u6709\u4e00\u4e2a \u6c42\u548c\u7b26\u53f7\u7684\uff0c\u800c\u524d\u9762\u4e24\u9879\u662f\u6ca1\u6709\u6c42\u548c\u7b26\u53f7\u7684\uff0c\u524d\u9762\u4e24\u9879\u90fd\u662f\u53ea\u6709\u4e00\u9879\uff0c\u8fd9\u91cc\u6709\u6c42\u548c\u53f7\uff0c\u5e76\u4e14\u6709 \\(T-1\\) \u9879</li> <li>\u56e0\u4e3a\u6709\u8fd9\u4e2a\u6c42\u548c\u9879\uff0c\u6240\u4ee5\u7b2c\u4e09\u9879\u5728\u6574\u4e2a loss function \u91cc\u9762\uff0c\u5360\u5f97\u6743\u91cd\u662f\u6bd4\u8f83\u5927\u7684</li> <li>\u6240\u4ee5\u5728\u4f18\u5316 Diffusion \u65f6\uff0c\u7b2c\u4e09\u9879\uff0cconsistency term \u662f\u5360\u4e3b\u5bfc\u7684\u9879</li> </ul>"},{"location":"learning/6_Diffusion1/#35-elbo","title":"3.5 ELBO \u62c6\u89e3\u9879\u56fe\u793a","text":"<ul> <li>\u501f\u7528 MHVAE \u7684\u56fe\uff0c\u6765\u53ef\u89c6\u5316</li> <li>\u9996\u5148\uff0creconstruction term \u8868\u793a\u4ece x1 \u5230 x0 \u7684\u5206\u5e03\uff0c\u5728\u56fe\u4e0a\u5c31\u662f\uff1a</li> </ul> <ul> <li>\u5176\u6b21\uff0cprior matching term\uff0c\u7bad\u5934\u6765\u8bf4\u5c31\u662f\u6700\u540e\u4e00\u9879\uff0c\u8868\u793a \\(x_{T-1}\\) \u5230 \\(x_T\\)\u7684\u5206\u5e03\uff1a</li> </ul> <ul> <li>\u800c\u6700\u540e\u7684 consistency term \u5c31\u662f\u5269\u4e0b\u7684\u6240\u6709\u7bad\u5934</li> </ul> <p>\u5177\u4f53\u6765\u8bf4\uff0c</p> <ul> <li>\\(q(x_t|x_{t-1})\\) \u5c31\u662f\u7c89\u7ea2\u8272\u7684\u7bad\u5934</li> <li>\u5bf9 \\(p_{\\theta}(x_t|x_{t+1})\\) \u7684 KL \u6563\u5ea6</li> <li>\u800c\uff0c\\(p_{\\theta}(x_t|x_{t+1})\\) \u5c31\u662f\u7eff\u8272\u7684\u7bad\u5934</li> <li>\u8868\u793a\u7684\u662f \u4e24\u4e2a\u7bad\u5934\u5f97\u5230\u7684 \\(x_t\\) \u4e4b\u95f4\u7684 <code>KL \u6563\u5ea6</code></li> <li>\u7136\u540e\uff0c\u8fd9\u4e24\u7ec4\u7bad\u5934\u770b\u505a\u4e00\u4e2a\u6574\u4f53\uff0c\u5411\u53f3\u6216\u8005\u5411\u5de6\u79fb\uff0c\u56e0\u4e3a\u4e00\u5171\u6709\u5927 T \u4e2a\u72b6\u6001\uff0c\u6240\u4ee5\u6574\u4f53\u4e0a\u5c31\u662f \\(T-1\\) \u4e2a\u6c42\u548c</li> </ul> <p>\u4ee5\u4e0a\u662f\u4e09\u4e2a loss \u5728 MHVAE \u4e2d\u76f4\u89c2\u5730\u8868\u8fbe</p>"},{"location":"learning/6_Diffusion1/#36-consistency-term","title":"3.6 consistency term\uff1a\u53bb\u566a\u65b9\u5411\u9884\u4f30","text":"<p>\u8bf4\u660e\u7b2c\u4e09\u9879  </p> <p></p> <p>\\(consistency\\_term  = \\sum_{t=1}^{T-1} \\mathbb{E}_{q(x_{t-1},x_{t+1}|x_0)}[D_{KL}(q(x_t|x_{t-1})||p_{\\theta}(x_t|x_{t+1}))]\\)</p> <p>\u8fd9\u4e2a\u8868\u8fbe\u662f\u6709\u95ee\u9898\u7684\u3002</p> <p>\u8fd9\u4e2a consistency term \u662f\u4e00\u4e2a\u6c42\u548c\u9879\uff0c\u6709\u5f88\u591a\u9879</p> <p>\u4e14\u5728\u6a21\u578b\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5360\u4e3b\u5bfc</p> <p>\u4f46\u662f\u8fd9\u4e00\u9879\u91cc\u9762\u6709\u95ee\u9898\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u8fd9\u4e00\u9879\u662f\u901a\u8fc7\u4e24\u4e2a\u968f\u673a\u53d8\u91cf\u5f97\u5230\u7684</p> <p>\u4e5f\u5c31\u662f\u8bf4 \\(x_t\\) \u662f\u901a\u8fc7\u4e24\u4e2a\u968f\u673a\u53d8\u91cf \\(x_{t-1}\\) \u548c \\(x_{t+1}\\) \u6765\u9884\u4f30</p> <p>\\(\\mathbb{E}_{q(x_{t-1},x_{t+1}|x_0)}\\) \u6c42\u671f\u671b\u662f\u5bf9\u4e24\u4e2a\u53d8\u91cf \\(x_{t-1}\\)\u548c \\(x_{t+1}\\)\uff0c\u5bf9\u4e24\u4e2a\u591a\u5143\u53d8\u91cf\u5bf9\u5e94\u7684\u591a\u5143\u5206\u5e03\u6c42\u5f97\u671f\u671b</p> <p>\u53c8\u56e0\u4e3a\uff0c\u8981\u901a\u8fc7 \\(x_{t-1}\\) \u548c \\(x_{t+1}\\) \u6765\u9884\u4f30 \\(x_t\\)</p> <p>\u800c\u5728\u5b9e\u9645\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5e76\u4e0d\u662f\u76f4\u63a5\u6c42\u5f97\u671f\u671b\u7684\uff0c\u800c\u662f\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u7684\u65b9\u6cd5\uff0c\u8499\u7279\u5361\u6d1b\u5c31\u662f\u7528\u5f88\u591a\u6837\u4f8b\u7684\u5e73\u5747\u7b49\u4e8e\u671f\u671b\uff0c\u5728\u8ba1\u7b97\u8fd9\u9879\u671f\u671b\u7684\u65f6\u5019\uff0c\u56e0\u4e3a\u6709\u4e24\u4e2a\u968f\u673a\u53d8\u91cf\u4f30\u8ba1 \\(x_t\\)\uff0c\u6b64\u65f6\u5f97\u5230\u7684 \\(x_t\\) \u7684\u65b9\u5dee\u662f\u6bd4\u8f83\u5927\u7684</p> <p>\u56e0\u4e3a\u4e24\u4e2a\u53d8\u91cf\u672c\u8eab\u662f\u6709\u65b9\u5dee\u7684\uff0c\u7528\u4e24\u4e2a\u5177\u6709\u65b9\u5dee\u7684\u53d8\u91cf\u53bb\u9884\u4f30\u53e6\u4e00\u4e2a\u53d8\u91cf\uff0c\u65b9\u5dee\u662f\u4f1a\u7d2f\u79ef\u7684\uff0c\u5c31\u4f1a\u5bfc\u81f4\u8fd9\u4e2a loss\uff08\u7b2c\u4e09\u9879\uff0cconsistency term\uff09\u4e0d\u592a\u51c6\u4e86</p> <ul> <li> \u63a5\u4e0b\u6765\uff0c\u8ba8\u8bba\u80fd\u4e0d\u80fd\u964d\u4f4e\u8fd9\u4e2a\u65b9\u5dee</li> </ul> <p></p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u5c31\u662f\u628a 2 \u4e2a\u968f\u673a\u53d8\u91cf\u53d8\u6210 1 \u4e2a</p> <p>\u5206\u6790\u601d\u8def\uff1a\u65e2\u7136\u90fd\u662f\u8981\u6c42 \\(x_t\\) \uff0c\u601d\u8003\u628a \\(x_{t-1}\\) \u5230 \\(x_t\\) \u53d8\u6210 \\(x_{t+1}\\) \u5230 \\(x_t\\)\uff0c\u8bb0\u4f4f\u8d1d\u53f6\u65af\u516c\u5f0f</p> <p>\u4ed4\u7ec6\u770b ppt \u4e0a\u7684\u8d1d\u53f6\u65af\u516c\u5f0f\uff0c\u5728\u4e0d\u770b \\(x_0\\)\u7684\u60c5\u51b5\u4e0b\uff0c\u4f59\u4e0b\u7684\u90e8\u5206\u5c31\u662f\u6807\u51c6\u7684\u8d1d\u53f6\u65af\u516c\u5f0f</p> <p></p> <ul> <li> \u63a5\u4e0b\u6765\u8ba8\u8bba\uff0c\u5982\u4f55\u901a\u8fc7\u8d1d\u53f6\u65af\u516c\u5f0f\uff0c\u628a\u7b2c\u4e09\u9879\u53d8\u6210\u53ea\u6709\u4e00\u4e2a\u968f\u673a\u53d8\u91cf\uff0c\u6765\u9884\u4f30 \\(x_t\\)</li> </ul> <p></p> <p></p> <p>\uff081\uff09\u770b\u7b2c\u4e00\u4e2a\u5212\u6389\u7684\uff0c\u62ff\u51fa\u6765\uff1a</p> <p>\\(\\log \\prod_{t=2}^T\\frac{1}{\\frac{q(x_t|x_0)}{q(x_{t-1}|x_0)}}\\)</p> <p>\\(=\\log \\prod_{t=2}^{T}\\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)}\\)</p> <p>\\(=\\sum_{t=2}^T (\\log q(x_{t-1}|x_0) - \\log q(x_t|x_0))\\)</p> <p>\\(=\\sum_{t=2}^T \\log q(x_{t-1}|x_0) - \\sum_{t=2}^T \\log q(x_t|x_0)\\)</p> <p>\\(=\\sum_{t=1}^{T-1} \\log q(x_{t}|x_0) - \\sum_{t=2}^T \\log q(x_t|x_0)\\)</p> <p>\\(=\\log q(x_1|x_0) - \\log q(x_T|x_0)\\)</p> <p>\\(=\\log \\frac{q(x_1|x_0)}{q(x_T|x_0)}\\)</p> <p>\uff082\uff09<code>denoising matching term</code> \u7684\u63a8\u5bfc</p> <p></p> <ul> <li>\u8fd9\u4e2a\u8fc7\u7a0b\u548c\u524d\u9762 prior matching term \u7684\u63a8\u5bfc\u662f\u4e00\u6837\u7684</li> <li>\u5177\u4f53\u6765\u8bf4\uff1a\u8981\u6c42\u671f\u671b\uff0c\u7528\u5b9a\u4e49\u5c55\u5f00\uff0c\u53d8\u6210\u79ef\u5206\u7684\u5f62\u5f0f</li> <li>\u56e0\u4e3a\u662f\u5bf9\u4e24\u4e2a\u53d8\u91cf\u7684\u5206\u5e03\u6c42\u671f\u671b\uff0c\u6240\u4ee5\u662f\u4e24\u4e2a\u79ef\u5206\u7b26\u53f7 \\(dx_t\\) \u548c \\(dx_{t-1}\\)\uff0c\u8868\u793a\u5bf9\u4e24\u4e2a\u53d8\u91cf\u6c42\u79ef\u5206</li> <li>\u63a5\u7740\u94fe\u5f0f\u6cd5\u5219\uff0c\u62c6 \\(q(x_t,x_{t-1}|x_0)\\) \u62c6\u6210 \\(=q(x_t|x_0)q(x_{t-1}|x_t,x_0)\\)</li> <li>\u94fe\u63a5\u6cd5\u5219\u4ee5\u540e\uff0c\u5408\u5e76\uff0c\u51fa\u73b0\u4e00\u4e2a\u671f\u671b\uff1a</li> </ul> <p></p> <p>\u4e5f\u5c31\u662f KL \u6563\u5ea6\uff08\u6ce8\u610f\u662f\u8d1f\u7684\uff09</p> <p></p> <ul> <li>\u6700\u540e\u5c31\u662f\u5bf9 KL \u6563\u5ea6\u6c42\u671f\u671b\uff0c\u5f97\u5230\u6700\u540e\uff1a</li> </ul> <p></p> <p><code>\u5206\u5e03\u3001\u51fd\u6570\u3001\u79ef\u5206\u53f7\u3001\u79ef\u5206\u7b26\u53f7\u90fd\u6709 \u2192 \u671f\u671b</code></p> <ul> <li> KL \u6563\u5ea6\u7684\u6587\u5b57\u63cf\u8ff0\uff1a</li> </ul> <p>\u4e00\u4e2a\u5206\u5e03\u9664\u4ee5\u53e6\u4e00\u4e2a\u5206\u5e03\u7684 log\uff0c\u7136\u540e\u5bf9\u5206\u5b50\u7684\u5206\u5e03\u6c42\u4e00\u4e2a\u671f\u671b</p> <ul> <li> \u671f\u671b\u7684\u63cf\u8ff0</li> </ul> <p>\u6709\u4e00\u4e2a \\(dx_t\\)\uff0c\u53c8\u6709 \\(x_t\\)\u7684\u5206\u5e03\uff0c\u53c8\u6709\u79ef\u5206\u53f7 \\(\\int\\)\uff0c\u8fd9\u4e09\u9879\u63d0\u51fa\u6765\u5c31\u662f\u5bf9 \\(q(x_t)\\) \u6c42\u671f\u671b\uff0c\u5269\u4e0b\u7684\u90e8\u5206\u7167\u6284</p>"},{"location":"learning/6_Diffusion1/#37-vdm-e-lbo-2","title":"3.7 VDM \u7684E LBO \u62c6\u89e32","text":"<p>\u6700\u540e\u5f97\u5230\u7684\u8868\u8fbe\u5f0f\uff1a</p> <p></p> <ul> <li>\u89c2\u5bdf\u7b2c\u4e09\u9879\uff0c\u6b64\u65f6\u5bf9\u4e8e \\(x_{t-1}\\)\u4e0d\u9700\u8981\u65e2\u77e5\u9053\u524d\u4e00\u4e2a\u72b6\u6001\u53c8\u77e5\u9053\u540e\u4e00\u4e2a\u72b6\u6001\uff0c\u5982\u679c\u8981\u9884\u4f30 \\(x_{t-1}\\)\uff0c\u53ea\u9700\u8981\u77e5\u9053 \\(x_t\\) \u5373\u53ef</li> <li>\u8fd9\u6837\u5c31\u628a\u4e4b\u524d\u9700\u8981\u4e24\u4e2a\u53d8\u91cf\u9884\u4f30\u7b2c\u4e09\u9879\uff08denosing matching term\uff09\u8868\u8fbe\u5f0f \u53d8\u6210\u4e86 \u4e00\u4e2a\u53d8\u91cf \u5c31\u662f \u7531 \\(x_t\\) \u5f97\u5230 \\(x_{t-1}\\) \uff0c\u56e0\u6b64\u51cf\u5c0f\u4e86\u8fd9\u9879\u8bef\u5dee</li> <li>\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u4e4b\u524d\u7b2c\u4e09\u9879\u53eb\u505a <code>consistency term</code>\uff0c\u7406\u89e3\u5c31\u662f\u4e00\u81f4\u6027\uff0c\u524d\u5411\u8fc7\u7a0b\u548c\u540e\u5411\u8fc7\u7a0b\u5f97\u5230 \\(x_t\\) \uff0c\u4e5f\u5c31\u662f \u524d\u5411\u548c\u540e\u5411\u7684\u4e00\u81f4\u6027\uff0c\u6240\u4ee5\u53eb\u505a <code>consistency term</code></li> <li>\u800c\u73b0\u5728\uff0c\u662f\u4e00\u4e2a\u65b9\u5411\u7684\uff0c\u5c31\u662f\u53bb\u566a\u7684\u65b9\u5411\uff0c\u4e5f\u5c31\u662f\u4ece \\(x_t\\) \u5230 \\(x_0\\)\u7684\u65b9\u5411\uff0c\u6240\u4ee5\u628a\u8fd9\u9879\u547d\u540d\u6210 <code>denoising matching term</code></li> <li>\u5176\u5b9e\u662f\u4e00\u4e2a\u4e1c\u897f\uff0c\u53ea\u662f\u901a\u8fc7\u63a8\u5bfc\uff0c\u4f7f\u7528\u4e00\u4e2a\u65b9\u5411\u7684\u9884\u4f30\uff0c\u53ef\u4ee5\u4f7f\u5f97 \u65b9\u5dee\u53d8\u5c0f\uff0c\u9884\u4f30\u66f4\u51c6\u786e</li> </ul>"},{"location":"learning/6_Diffusion1/#38-vdm-elbo-vae-elbo","title":"3.8 VDM \u7684 ELBO \u62c6\u89e3&amp;VAE \u7684ELBO \u62c6\u89e3","text":"<p>\u5bf9\u6bd4 VAE \u7684 ELBO \u62c6\u89e3</p> <p>\uff081\uff09VAE \u7684 ELBO \u62c6\u89e3</p> <p>\uff082\uff09VDM \u7684 ELBO \u62c6\u89e3</p> <p>\u2460 \u53ef\u4ee5\u770b\u5230\u524d\u4e24\u9879\u662f\u4e00\u6837\u7684\uff0c\u90fd\u6709 reconstruction term \u548c prior matching term</p> <p>\u2461 \u76f8\u6bd4\u4e8e VAE\uff0cVDM \u591a\u4e86\u6700\u540e\u4e24\u9879\uff0cdenoising matching term\uff0c\u800c\u4e14\u5bf9\u4e8e\u8fd9\u4e2a\u6c42\u548c\u9879\uff0c\u5982\u679c \\(T=1\\) \u7684\u8bdd\uff0c\u8fd9\u9879\u5c31\u662f\u7b49\u4e8e \\(0\\) \u7684\uff0c\u56e0\u4e3a \\(t\\) \u662f\u4ece \\(2\\) \u5f00\u59cb\u7684\uff0c\u6240\u4ee5 \\(T=1\\)\uff0c\u8fd9\u9879\u5c31\u662f\u6ca1\u6709\u7684</p> <p></p> <p>\u6b64\u65f6 <code>VAE \u7684 ELBO \u62c6\u89e3=VDM \u7684 ELBO \u62c6\u89e3</code></p> <p>\u5f53\u7136\u5566\uff0c\u8981\u6ce8\u610f\u7b26\u53f7\u7684\u5bf9\u5e94\u5466~</p> <p></p> <p>\\(VDM \uff1ax_0 \u2192 VAE\uff1ax\\)</p> <p>\\(VDM \uff1ax_1 \u2192 VAE\uff1az\\)</p> <p>\u8fd9\u4e5f\u8bf4\u660e\u4e86\uff0cVAE \u548c VDM\uff08Diffusion model\uff09\u5e95\u5c42\u7684 loss \u8868\u8fbe\u662f\u4e00\u81f4\u7684\uff0c\u7406\u8bba\u57fa\u7840\u7684\u4e00\u8109\u76f8\u627f\u7684</p>"},{"location":"learning/6_Diffusion1/#39-vdm-elbo","title":"3.9 VDM \u7684 ELBO \u4f18\u5316","text":"<p>\uff081\uff09\u7b2c\u4e00\u9879\uff1areconstruction term  \\(\\mathbb{E}_{\\log p_{\\theta}(x_0|x_1)}[\\log p_{\\theta}(x_0|x_1)]\\)</p> <p>\u53ea\u6709 1 \u9879\uff0c\u5e76\u4e0d\u662f\u4f18\u5316\u7684\u91cd\u70b9</p> <p>\uff082\uff09\u7b2c\u4e8c\u9879\uff1aprior matching term  \\(D_{KL}(q(x_T|x_0)||p(x_T))\\)</p> <p>\\(q(x_T|x_0)\\)  \u56e0\u4e3a\u4ece \\(x_0\\) \u5230 \\(x_T\\) \u662f\u6211\u4eec\u4eba\u4e3a\u5b9a\u4e49\u7684\uff0c\u662f\u6ca1\u6709\u4efb\u4f55\u6a21\u578b\u53c2\u6570\u7684</p> <p>\\(p(x_T)\\) \u662f\u5b9a\u4e49\u7684\u4e00\u4e2a\u9ad8\u65af\u6b63\u6001\u5206\u5e03</p> <p>\u56e0\u6b64\uff0c\u8fd9\u4e2a KL \u6563\u5ea6\u662f\u5df2\u77e5\u7684\uff0c\u6ca1\u6709\u4efb\u4f55\u53c2\u6570\u53ef\u4ee5\u4f18\u5316\u7684</p> <p>\uff083\uff09\u91cd\u70b9\u4f18\u5316\u7b2c\u4e09\u9879\uff0c\u6709\u6c42\u548c\u53f7  \uff08\u53bb\u566a\u9879\uff09</p> <p>\\(\\sum_{t=2}^{T}\\mathbb{E}_{q(x_t|x_0)}[D_{KL}(q(x_{t-1}|x_t,x_0)||p_{\\theta}(x_{t-1}|x_t))]\\)</p> <ul> <li>\u9996\u5148\u9700\u8981\u77e5\u9053 \\(q(x_{t-1}|x_t,x_0)\\) \u7684\u5206\u5e03\u662f\u4ec0\u4e48\u6837\u7684\uff0c\u9700\u8981\u77e5\u9053\u5b83\u7684\u771f\u5b9e\u5206\u5e03\uff0c\u7136\u540e\u624d\u80fd\u53bb\u62df\u5408\uff0c\u901a\u8fc7 \\(x_t\\) \u9884\u6d4b \\(x_{t-1}\\)</li> <li>VDM \u8fd9\u4e2a\u6a21\u578b\u5c31\u662f\u8981\u6839\u636e \\(x_t\\) \u5f97\u5230 \\(x_{t-1}\\)</li> </ul> <p>\u5176\u5b9e q \u662f\u52a0\u566a\u8fc7\u7a0b\uff0cp \u662f\u4ece \\(x_0\\) \u5230 \\(x_T\\) \u7684\uff0c\u4f46\u662f\u7ecf\u8fc7\u8f6c\u6362\u8fd9\u91cc\u7684 q \u4ece \\(x_t\\) \u5230 \\(x_0\\)</p>"},{"location":"learning/6_Diffusion1/#310-qx_t-1x_tx_0-ground-truth","title":"3.10 \\(q(x_{t-1}|x_t,x_0)\\) \u7684 ground truth","text":"<p>\u601d\u8def\uff1a\u5df2\u77e5 \\(q(x_t|x_{t-1})\\) \u7684\u5206\u5e03\u662f\u5df2\u77e5\u7684\uff0c\u73b0\u5728\u8981\u6c42 \\(q(x_{t-1}|x_t)\\) \u7684\u5206\u5e03\uff0c\u65b9\u6cd5\u5c31\u662f\u501f\u52a9\u8d1d\u53f6\u65af\u516c\u5f0f</p> <ul> <li>ppt \u4e0a\u5199\u7684\uff0c\u53ef\u4ee5\u5148\u4e0d\u7528\u770b \\(x_0\\)\uff0c\u4f59\u4e0b\u7684\u90e8\u5206\u5c31\u662f\u6807\u51c6\u7684\u8d1d\u53f6\u65af\u516c\u5f0f</li> <li>\u91cd\u53c2\u6570\u5316\u6280\u5de7\uff1a\\(x_t = \u5747\u503c + \u6807\u51c6\u5dee\u00d7\u6807\u51c6\u9ad8\u65af\u5206\u5e03\\)</li> <li>\u89c2\u5bdf\u8d1d\u53f6\u65af\u516c\u5f0f\uff1a</li> </ul> <p>\\(q(x_{t-1}|x_t,x_0) = \\frac{q(x_t|x_{t-1},x_0)q(x_{t-1}|x_0)}{q(x_t|x_0}\\)</p> <ul> <li> <p>for  \\(q(x_t|x_{t-1},x_0)\\) \u662f\u6ee1\u8db3\u4e0e \\(x_{t-1}\\)\u6709\u5173\u7684\u9ad8\u65af\u5206\u5e03\uff0c\u4e5f\u5c31\u662f\u53ef\u4ee5\u901a\u8fc7 \\(x_{t-1}\\) \u53ef\u4ee5\u5f97\u5230 \\(x_t\\)</p> </li> <li> <p>\uff08for \\(q(x_t|x_0)\\)\uff09\u73b0\u5728\u8981\u901a\u8fc7 \\(x_0\\) \u5f97\u5230 \\(x_{t-1}\\) \u548c \\(x_t\\)\uff0c\u65b9\u6cd5\uff1a\u501f\u52a9\u91cd\u53c2\u6570\u5316\u516c\u5f0f\uff0c\u9012\u63a8\uff0c\u5177\u4f53\u7684\u6b65\u9aa4\uff1a</p> </li> </ul> <p></p> <p>\u8bf4\u660e</p> <p>\uff081\uff09\u4e0d\u7ba1\u662f \\(\\epsilon_{t-1}^*\\)\u3001\\(\\epsilon_{t-2}^*\\)\u3001\\(\\epsilon_{t-2}\\) \\(\\sim N(0,1)\\) \uff0c\u90fd\u662f\u6807\u51c6\u9ad8\u65af\u5206\u5e03\u7684\u968f\u673a\u566a\u58f0\uff0c\u53ea\u662f\u8868\u793a\u7b26\u53f7\u4e0d\u540c</p> <p>\uff082\uff09\u91cd\u70b9\u8bf4\u4e0b\uff1a</p> <p></p> <p>\u8fd9\u91cc\u7528\u7684\u77e5\u8bc6\u70b9\uff1a\u4e24\u4e2a\u9ad8\u65af\u5206\u5e03\u7684\u548c \u8fd8\u662f \u9ad8\u65af\u5206\u5e03\uff0c\u4e14\u5747\u503c\u548c\u65b9\u5dee\u7684\u516c\u5f0f\u6709</p> <p>\\(a\\epsilon_{t-2}^*+b\\epsilon_{t-1}^* \\sim N(0,a^2+b^2)\\)</p> <p>\u8fd8\u6709\uff0c\\(\u4efb\u610f\u6b63\u6001\u5206\u5e03 = \\sigma N(0,1) + \\mu\\)</p> <p>\u6240\u4ee5\u6709\u4e0a\u56fe</p> <p>(3)\u6700\u540e\u9012\u63a8\u5f97\u5230\uff1a\\(x_t = \\sqrt{\\bar \\alpha_t}x_0 + \\sqrt{1-\\bar \\alpha_t} \\epsilon_0\\)</p> <p>\u5176\u4e2d\uff0c\\(x_0\\)\u4e3a\u5df2\u77e5\uff0c\\(\\epsilon_0 \\sim N(0,1)\\)</p> <p>\u4ee5\u4e0a\u5f97\u5230\u4e86 \\(q(x_t|x_0)\\)  \u4e5f\u5c31\u662f\u5df2\u77e5 \\(x_0\\)  \u5f97\u5230 \\(x_t\\)</p> <ul> <li>for \\(q(x_{t-1}|x_0)\\)  \u53ea\u9700\u8981\u628a \u4e0a\u9762\u5f97\u5230 \\(q(x_t|x_0)\\)\u76f8\u5173\u7684\uff0ct \u90fd\u6362\u6210 \\(t-1\\) \u5373\u53ef</li> </ul> <p>\u5982\u56fe\uff1a</p> <p></p> <ul> <li>\u4ee5\u4e0a\uff0c\u5c31\u5f97\u5230\u4e86\u4e09\u9879\u7684\u8868\u8fbe\u5f0f</li> <li>\u63a5\u4e0b\u6765\uff0c\u628a\u5f97\u5230\u7684\u8868\u8fbe\u5f0f\uff0c\u4ee3\u5165\u5230\u516c\u5f0f\u4e2d\uff0c\u4e5f\u5c31\u662f\u4e24\u4e2a\u5206\u5e03\u76f8\u4e58 \u9664\u4ee5 \u53e6\u5916\u4e24\u4e2a\u5206\u5e03</li> <li>\u7701\u7565\u7cfb\u6570</li> <li>\u628a \\(x_{t-1}\\)\u89c6\u4e3a\u672a\u77e5\u6570\uff0c\u5408\u5e76\u540c\u7c7b\u9879\uff0c\u56e0\u4e3a\u8981\u6c42\u7684\u5c31\u662f \\(x_{t-1}\\)\u7684\u5206\u5e03\u3002\u522b\u5fd8\u4e86\u662f\u5728\u5229\u7528\u8d1d\u53f6\u65af\u516c\u5f0f \u6c42 \\(q(x_{t-1}|x_t)\\)</li> </ul> <p></p> <p>\u5408\u5e76 x_{t-1} \u7684\u5e73\u65b9\u9879\u3001\u4e00\u6b21\u9879\u3001\u5e38\u6570\u9879\uff0c\u5f97\u5230\u6700\u540e\u7684\u8868\u8fbe\u5f0f</p> <ul> <li>\u5ffd\u7565\u5e38\u6570\u9879 \u6216\u8005 \u7cfb\u6570 \u90fd\u662f\u52a0\u4e86 <code>\u6b63\u6bd4</code> \u7b26\u53f7</li> </ul> <p></p> <p>\u6ce8\u610f\u770b\u7bad\u5934\u6307\u5411&amp;\u5bf9\u5e94\u5173\u7cfb\uff1a</p> <p></p> <p>\u5f97\u5230\u4e86 \u4ee5\u7ea2\u6846\u4e3a\u65b9\u5dee\uff0c\u9ec4\u6846\u4e3a\u5747\u503c\u7684 \u9ad8\u65af\u5206\u5e03\uff0c\u4e5f\u5c31\u662f\u63a8\u51fa\u4e86 \\(q(x_t|x_{t-1})\\)</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>\u7528\u7684\u57fa\u7840\u77e5\u8bc6\uff1a</p> <ul> <li>\u671f\u671b\u7684\u5b9a\u4e49</li> <li>KL \u6563\u5ea6\u7684\u516c\u5f0f</li> <li>\u8d1d\u53f6\u65af\u516c\u5f0f</li> </ul> <p></p>"},{"location":"learning/8_WeightNorm/","title":"WeightNorm","text":""},{"location":"learning/8_WeightNorm/#weightnorm","title":"WeightNorm","text":"2024-12-08 16:39:362025-09-28 12:54:04 <p> \u7ea6 2939 \u4e2a\u5b57  254 \u884c\u4ee3\u7801  7 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 18 \u5206\u949f</p> <p>\u5feb\u901f\u590d\u73b0PyTorch\u7684Weight Normalization</p>"},{"location":"learning/8_WeightNorm/#1-api","title":"1 \u5b98\u65b9api\u89e3\u8bfb","text":"<p>\u6743\u91cd\u5f52\u4e00\u5316\u7684api</p> <p>\u751f\u6210\u5f0f\u7f51\u7edc\u6bd4\u5982GAN\uff0c\u4f7f\u7528\u6743\u91cd\u5f52\u4e00\u5316\u4f7f\u5f97\u7f51\u7edc\u8bad\u7ec3\u66f4\u52a0\u7a33\u5b9a</p> <p>\u6743\u91cd\u5f52\u4e00\u5316\u7684api\u5728<code>torch.nn.utils</code>\u4e0b\u7684\u4e00\u4e2a\u51fd\u6570\uff0c\u4e0d\u662fclass</p> <p>\u8fd9\u4e2a\u51fd\u6570\u7684\u4f20\u5165\u53c2\u6570\uff1a</p> <ul> <li>module\uff1apytorch\u4e2d\u5f88\u591aclass\u90fd\u662fnn.module\u7684\u5b50\u7c7b\uff0c\u6240\u4ee5\u53ea\u9700\u8981\u4f20\u5165module\u7684\u5bf9\u8c61\u5373\u53ef\uff0c\u5982\uff1ann.Linear\u3001nn.ReLu\u3001nn.Conv\u3001nn.RNN</li> <li>name\uff1a\u4e00\u822c\u4e0d\u4f1a\u6539</li> <li>dim\uff1a\u4e5f\u4e00\u822c\u662f\u9ed8\u8ba4\u7684</li> </ul> <p>\u6743\u91cd\u5f52\u4e00\u5316\u7684\u8bba\u6587\uff1a</p> <p></p> <p>\u6807\u9898\uff1a\u6743\u91cd\u5f52\u4e00\u5316\uff1a\u7b80\u5355\u7684\u53c2\u6570\u91cd\u6574\u5316\u65b9\u6cd5\uff1a\u52a0\u901f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3</p> <p>\u4eca\u5929\u8bb2\u89e3\uff1a\u6743\u91cd\u5f52\u4e00\u5316\u4e3b\u8981\u505a\u4e86\u4ec0\u4e48\u4e8b</p> <p>WeightNorm\u5bf9module\u8fdb\u884c\u4e00\u5c42\u5305\u88f9</p> <p>\u4f8b\u5982 \u628a\u4e00\u4e2ann.Linear\u653e\u5165WeightNorm\u4e2d\uff0cWeightNorm\u4ecd\u7136\u8fd4\u56de\u7684\u662f\u4e00\u4e2amodule\uff0c\u8fd9\u4e2a\u8fd4\u56de\u7684module\u5305\u542b\u4e24\u4e2a\u53c2\u6570\uff1aWeight_g \u548c Weight_v</p> <p>\u672c\u6765\u7684Linear\u5c42\uff0c\u53ea\u6709\u4e00\u4e2a\u53c2\u6570w\uff0c\u5ffd\u7565bias\uff0c\u653e\u5165WeightNorm\u4e2d\u5904\u7406\uff0c\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684module\uff0c\u65b0\u7684module\u6709\u4e24\u4e2a\u53c2\u6570\uff1aWeight_g \u548c Weight_v</p> <p>Weight_g \u548c Weight_v\u5c31\u662fWeightNorm\u516c\u5f0f\u4e2d\u7684g\u548cv</p> <p>\\(w = g\\frac{v}{||v||}\\)</p> <p></p> <p>\u770b\u516c\u5f0f</p> <p>\u76f8\u5f53\u4e8e\u628a\u539f\u6765\u7684module\u4e2d\u7684 \u6743\u91cdw \u5206\u89e3\u4e86\uff0c\u6240\u4ee5\u4e0e\u5176\u53eb\u6743\u91cd\u5f52\u4e00\u5316\uff0c\u4e5f\u53ef\u4ee5\u53eb\u6743\u91cd\u5206\u89e3</p> <p>\u76f8\u5f53\u4e8e\u628a\u539f\u6765module\u4e2d\u7684w\u5206\u89e3\u6210\u4e24\u9879\uff1a</p> <ul> <li>g\uff1ag\u8868\u793aw\u7684\u5e45\u5ea6\uff0c\u76f8\u5f53\u4e8ew\u6bcf\u9636\u5411\u91cf\u7684\u4e8c\u9636\u6a21\u3001\u8303\u6570</li> <li>\\(\\frac{v}{||v||}\\)\uff1a\u5355\u4f4d\u5411\u91cf\uff0c\u65b9\u5411\u9664\u4ee5\u6a21\u957f\u5f97\u5230\u65b9\u5411\u5411\u91cf</li> </ul> <p>\u4e5f\u5c31\u662f\u8bf4\u672c\u6765 module\u53ea\u6709\u4e00\u4e2a\u53c2\u6570 w\uff0c\u73b0\u5728\u53d8\u6210\u4e24\u4e2a\u53c2\u6570\uff0c\u5206\u522b\u662f g \u548c v \uff0c\u4e5f\u5c31\u662f\u6b64\u65f6\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u66f4\u65b0\u53c2\u6570\u65f6\uff0c\u4e0d\u662f\u5bf9 w \u8fdb\u884c\u66f4\u65b0\u4e86\uff0c\u800c\u662f\u5bf9 g \u548c v \u8fdb\u884c\u66f4\u65b0\uff08\u597d\u5904\u81ea\u5df1\u53bb\u770b\u8bba\u6587\uff09</p>"},{"location":"learning/8_WeightNorm/#2","title":"2 \u4ee3\u7801\u5b9e\u73b0","text":""},{"location":"learning/8_WeightNorm/#21","title":"2.1 \u4e24\u4e2a\u5b9e\u4f8b\u6f14\u793a","text":"<ol> <li>Linear\u5c42</li> <li>\u4e00\u7ef4Conv\u7684\u4f8b\u5b50</li> </ol> <p>\u4ee5\u4e0a \u4e24\u4e2a\u4f8b\u5b50 \u89e3\u91ca WeightNorm\u5b98\u65b9api\u505a\u4e86\u4ec0\u4e48\u4e8b</p> Python<pre><code>import torch\nimport torch.nn as nn\n\n# \u5173\u4e8e\u6743\u91cd\u5f52\u4e00\u5316\u7684\u518d\u6b21\u8bf4\u660e\n# WeightNorm W = Magnitude * UnitDirection = Magnitude * (W/Norm(W))\n\n# step1:define constant\nbatch_size = 2\nfeat_dim = 3\nhid_dim = 4\ninputx = torch.randn(batch_size,feat_dim)\nlinear = nn.Linear(feat_dim,hid_dim,bias=False)\nwn_linear = torch.nn.utils.weight_norm(linear)\n\n# step2:Linear Layer:calculate g and v\nweight_magnitude = torch.tensor([linear.weight[i:,].norm() for i in torch.arange(linear.weight.shape[0])],dtype =torch.float32).unsqueeze(-1)\nweight_direction = linear.weight / weight_magnitude\n\nprint(\"linear.weight:\",linear.weight)\nprint(\"weight_magnitude:\",weight_magnitude)\nprint(\"weight_direction:\",weight_direction)\nprint(\"magnitude of weight_direction:\",(weight_direction**2).sum(dim=-1))\n\n\n'''\nlinear.weight: tensor([[-0.2701, -0.0754,  0.3812],\n        [-0.1806,  0.1814,  0.4922],\n        [-0.2900, -0.5321, -0.4400],\n        [-0.5492,  0.0195, -0.5189]], grad_fn=&lt;WeightNormInterfaceBackward0&gt;)\nweight_magnitude: tensor([[1.2899],\n        [1.2000],\n        [1.0640],\n        [0.7558]])\nweight_direction: tensor([[-0.2094, -0.0584,  0.2956],\n        [-0.1505,  0.1512,  0.4102],\n        [-0.2726, -0.5001, -0.4135],\n        [-0.7267,  0.0259, -0.6865]], grad_fn=&lt;DivBackward0&gt;)\nmagnitude of weight_direction: tensor([0.1346, 0.2138, 0.4954, 1.0000], grad_fn=&lt;SumBackward1&gt;)\n'''\n</code></pre>"},{"location":"learning/8_WeightNorm/#22","title":"2.2 \u6ce8\u91ca","text":"Python<pre><code>import torch\nimport torch.nn as nn\n\n# \u5173\u4e8e\u6743\u91cd\u5f52\u4e00\u5316\u7684\u518d\u6b21\u8bf4\u660e\n# WeightNorm W = Magnitude * UnitDirection = Magnitude * (W/Norm(W))\n\n# step1:define constant\nbatch_size = 2\nfeat_dim = 3\nhid_dim = 4\ninputx = torch.randn(batch_size,feat_dim) # 2\u00d73\nlinear = nn.Linear(feat_dim,hid_dim,bias=False) # linear.weight=4\u00d73\nwn_linear = torch.nn.utils.weight_norm(linear)\n\n# step2:Linear Layer:calculate g and v\nweight_magnitude = torch.tensor([linear.weight[i:,].norm() \n                                 for i in torch.arange(linear.weight.shape[0])],\n                                dtype =torch.float32).unsqueeze(-1)\n# weight_magnitude\uff1a4\u00d71\nweight_direction = linear.weight / weight_magnitude\n# weight_direction\uff1a4\u00d73\nprint(\"linear.weight:\",linear.weight) # linear.weight=4\u00d73\nprint(\"weight_magnitude:\",weight_magnitude) # weight_magnitude\uff1a4\u00d71\nprint(\"weight_direction:\",weight_direction) # weight_direction\uff1a4\u00d73\nprint(\"magnitude of weight_direction:\",(weight_direction**2).sum(dim=-1))\n\n\n'''\nlinear.weight: tensor([[-0.2701, -0.0754,  0.3812],\n        [-0.1806,  0.1814,  0.4922],\n        [-0.2900, -0.5321, -0.4400],\n        [-0.5492,  0.0195, -0.5189]], grad_fn=&lt;WeightNormInterfaceBackward0&gt;)\nweight_magnitude: tensor([[1.2899],\n        [1.2000],\n        [1.0640],\n        [0.7558]])\nweight_direction: tensor([[-0.2094, -0.0584,  0.2956],\n        [-0.1505,  0.1512,  0.4102],\n        [-0.2726, -0.5001, -0.4135],\n        [-0.7267,  0.0259, -0.6865]], grad_fn=&lt;DivBackward0&gt;)\nmagnitude of weight_direction: tensor([0.1346, 0.2138, 0.4954, 1.0000], grad_fn=&lt;SumBackward1&gt;)\n'''\n</code></pre>"},{"location":"learning/8_WeightNorm/#23","title":"2.3 \u8be6\u89e3","text":""},{"location":"learning/8_WeightNorm/#1","title":"\uff081\uff09\u5b9a\u4e49\u5e38\u91cf","text":"Python<pre><code>import torch\nimport torch.nn as nn\n\n# \u5173\u4e8e\u6743\u91cd\u5f52\u4e00\u5316\u7684\u518d\u6b21\u8bf4\u660e\n# WeightNorm W = Magnitude * UnitDirection = Magnitude * (W/Norm(W))\n\nbatch_size = 2\nfeat_dim = 3\nhid_dim = 4\ninputx = torch.randn(batch_size,feat_dim)\nlinear = nn.Linear(feat_dim,hid_dim,bias=False)\nwn_linear = torch.nn.utils.weight_norm(linear)\n</code></pre> <ul> <li> feat_dim\uff1a\u6570\u636e\u7ef4\u5ea6</li> <li> hid_dim\uff1a\u9690\u542b\u5c42\u7ef4\u5ea6\uff0c\u6307\u7684\u662f\u7ebf\u6027\u5c42\u7684\u7ef4\u5ea6\uff0c\u7ebf\u6027\u5c42\u7684\u9690\u542b\u5c42\u6216\u8005Conv\u7684\u8f93\u51fa\u901a\u9053\u6570</li> <li> <code>inputx = torch.randn(batch_size,feat_dim)</code></li> </ul> <p>torch.randn\u521d\u59cb\u5316inputx\uff0c\u662f\u4e00\u4e2a\u4e8c\u7ef4\u5f20\u91cf\uff0c\u7b2c\u4e00\u7ef4\u5ea6\u662f batch_size \uff0c\u7b2c\u4e8c\u7ef4\u5ea6\u662f \u8f93\u5165\u6570\u636e\u7684\u7279\u5f81\u7ef4\u5ea6</p> <ul> <li> <code>linear = nn.Linear(feat_dim,hid_dim,bias=False)</code></li> </ul> <p>\u5b9e\u4f8b\u5316\u4e00\u4e2alinear\u5c42\uff0clinear\u5c42\u7684api\uff1a</p> <ul> <li>\u7b2c\u4e00\u4e2a\u53c2\u6570 \u8f93\u5165\u6570\u636e\u7684\u7279\u5f81\u7ef4\u5ea6</li> <li>\u7b2c\u4e8c\u4e2a\u53c2\u6570 \u9690\u542b\u5c42\u7684\u7279\u5f81\u7ef4\u5ea6</li> <li> <p>bias\u8bbe\u7f6eFalse\uff0c\u7ed9\u5173\u6389</p> </li> <li> <p> <code>wn_linear = torch.nn.utils.weight_norm(linear)</code></p> </li> </ul> <p>\u63a5\u4e0b\u6765\uff0c\u628alinear\u4f5c\u4e3a\u4e00\u4e2a\u53c2\u6570\uff0c\u4f20\u5165 torch \u7684 weight norm\u51fd\u6570\u4e2d\uff0c\u5f97\u5230\u65b0\u7684\u6a21\u5757 weightnorm linear\uff1a<code>wn_linear</code>\uff0c\u4ecd\u7136\u662f\u4e00\u4e2amodule</p>"},{"location":"learning/8_WeightNorm/#2-linear-wn_linear-modulegv","title":"\uff082\uff09\u63a2\u8ba8 <code>linear</code> \u548c <code>wn_linear</code> \u4e24\u4e2amodule\u7684\u5173\u7cfb\uff08\u8ba1\u7b97g&amp;v\uff09","text":"<p>\u6839\u636e\u516c\u5f0f\uff0c\u53ef\u4ee5\u7b97\u51fa g \u548c \\(\\frac{v}{||v||}\\)\uff0c\u63a5\u4e0b\u6765\u7814\u7a76\u600e\u4e48\u7b97\u8fd9\u4e24\u4e2a\u5411\u91cf\uff1a</p> Python<pre><code>weight_magnitude = torch.tensor([linear.weight[i:,].norm() \n                                 for i in torch.arange(linear.weight.shape[0])],\n                                dtype =torch.float32).unsqueeze(-1)\n\nweight_direction = linear.weight / weight_magnitude\n\nprint(\"linear.weight:\",linear.weight)\nprint(\"weight_magnitude:\",weight_magnitude)\nprint(\"weight_direction:\",weight_direction)\nprint(\"magnitude of weight_direction:\",(weight_direction**2).sum(dim=-1))\n</code></pre> <ul> <li>\u9996\u5148 \u8ba1\u7b97 g\uff0cg\u8868\u793a\u5e45\u5ea6</li> </ul> Python<pre><code>weight_magnitude = torch.tensor([linear.weight[i:,].norm() \n                                 for i in torch.arange(linear.weight.shape[0])],\n                                dtype =torch.float32).unsqueeze(-1)\n</code></pre> <p>\u5e45\u5ea6\u6307\u7684\u662f \u8ddf\u8f93\u5165\u7684\u6bcf\u4e00\u4e2asample \u8fdb\u884c\u5185\u79ef\u7684\u5411\u91cf\u7684\u5e45\u5ea6</p> <p>\u9996\u5148\u62ff\u51falinear\u5c42\u7684\u6743\u91cd\u77e9\u9635\uff0c<code>linear.weight</code></p> <p>\u7136\u540e \u627e\u5230\u6bcf\u4e00\u4e2a \u8ddfsample\u8fdb\u884c\u5185\u79ef\u7684 \u5411\u91cf\uff0c\u4e5f\u5c31\u662f weight\u7684\u6bcf\u4e00\u884c <code>linear.weight[i:,]</code></p> <p>\u5bf9 <code>linear.weight[i:,]</code> \u7684\u6bcf\u4e00\u884c\u8fdb\u884c\u904d\u5386\uff0c\u8ba1\u7b97norm\uff1a<code>linear.weight[i:,].norm()</code></p> <p><code>.norm()</code> \u662f torch\u4e2d\u7684\u51fd\u6570\uff0c\u8ba1\u7b97L2\u8303\u6570\uff0c\u8c03\u7528norm() \u51fd\u6570\u4ee5\u540e\uff0c\u5f97\u5230\u6bcf\u4e00\u884c\u7684\u8303\u6570</p> <p><code>.unsqueeze(-1)</code> \u6269\u4e00\u7ef4</p> <p>\u8ba1\u7b97\u51fa linear\u5c42\uff0c\u539f\u6765\u6743\u91cd\u77e9\u9635\u7684 \u5e45\u5ea6\u503c</p> Python<pre><code>weight_magnitude: tensor([[1.2899],\n        [1.2000],\n        [1.0640],\n        [0.7558]])\n</code></pre> <p>\u6743\u91cd\u77e9\u9635\u662f 4\u884c\u7684\uff0c\u6bcf\u4e00\u884c\u90fd\u80fd\u8ba1\u7b97\u5e45\u5ea6\u503c</p> inputx = 2\u00d73\uff0c\u4e3a\u4ec0\u4e48 linear.weight=4\u00d73? <ul> <li>\u8ba1\u7b97\u5355\u4f4d\u5411\u91cf</li> </ul> Python<pre><code>weight_direction = linear.weight / weight_magnitude\n</code></pre> <ul> <li>\u5355\u4f4d\u5411\u91cf \u5c31\u662f v \u9664\u4ee5 v\u7684\u6a21</li> <li>v\u5176\u5b9e\u5c31\u662fw\uff0c\u6240\u4ee5\u5728\u8ba1\u7b97w\u7684\u65f6\u5019\uff0c\u5c31\u662f\u628a\u539f\u6765\u7684\u6743\u91cd\u77e9\u9635 <code>linear.weight</code> \u9664\u4ee5 \u6211\u4eec\u521a\u521a\u7b97\u51fa\u6765\u7684 \u5e45\u5ea6\u503c <code>weight_magnitude</code></li> <li> <p>\u6bcf\u4e00\u4e2a\u6743\u91cd\u5411\u91cf \u9664\u4ee5 \u5411\u91cf\u7684\u6a21\uff0c\u5f97\u5230 <code>weight_direction</code></p> </li> <li> <p><code>weight_direction</code> \u8ddf weight \u77e9\u9635\u7684\u5f62\u72b6\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u4e2a\u77e9\u9635\u53eb\u505a\u5355\u4f4d\u5411\u91cf\u77e9\u9635\uff0c\u6bcf\u4e00\u884c\u90fd\u662f\u5355\u4f4d\u5411\u91cf</p> </li> <li>\u90a3\u4e3a\u4ec0\u4e48 \u662f \u5355\u4f4d\u5411\u91cf\u77e9\u9635\u5462\uff1f\u9a8c\u8bc1\uff1a</li> </ul> Python<pre><code>print(\"magnitude of weight_direction:\",(weight_direction**2).sum(dim=-1))\n</code></pre> <ul> <li>\u628a <code>weight_direction</code> \u9996\u5148\uff0c\u6bcf\u4e2a\u5143\u7d20\u53d6\u5e73\u65b9\uff0c\u7136\u540e\u518d\u5bf9\u6bcf\u4e00\u884c\u6c42\u548c</li> </ul> <p>\u8fd9\u91cc\u6709\u95ee\u9898\uff1aup\u4e3b\u7ed3\u679c\u4e3a1\uff0c\u6211\u7684\u7ed3\u679c\u4e0d\u4f1a\u662f1\uff0c\u4f46\u7ed3\u679c\u5e94\u8be5\u662f1</p> <p></p> <p>\u4e5f\u4e0d\u77e5\u9053\u54ea\u91cc\u51fa\u95ee\u9898\u4e86\uff0c\u603b\u4e4b\u6211\u7684\u6709\u95ee\u9898\uff0c\u6240\u4ee5\u79f0\u4e4b\u4e3a \u5355\u4f4d\u5411\u91cf</p> <ul> <li> <p>\u53eb\u505a \u5355\u4f4d\u5411\u91cf\u7684\u539f\u56e0\u662f weight\u6bcf\u4e00\u884c\u7684\u5e73\u65b9\u548c \u90fd\u662f1</p> </li> <li> <p>\u4e5f\u5c31\u662f\u8bf4 \u6bcf\u4e00\u884c\u5411\u91cf\u957f\u5ea6\u90fd\u662f 1\uff0c\u4e5f\u5c31\u662f\u5355\u4f4d\u5411\u91cf\uff0c\u53cd\u6620\u7684\u662f \u6bcf\u4e2a\u5411\u91cf\u7684\u65b9\u5411\u7684\uff0c\u5e76\u4e14\u7528 \u957f\u5ea6\u4e3a1 \u7684\u5411\u91cf \u53cd\u6620\u65b9\u5411</p> </li> <li> <p>\u4e0a\u9762\u5df2\u7ecf\u7b97\u51fa\u6765\u4e86 \u539f\u6765 linear\u5c42 \u7684\u6743\u91cd\u7684\u5e45\u5ea6\u548c\u65b9\u5411\uff1a</p> </li> </ul> Python<pre><code>weight_magnitude = torch.tensor([linear.weight[i:,].norm() for i in torch.arange(linear.weight.shape[0])],dtype =torch.float32).unsqueeze(-1)\nweight_direction = linear.weight / weight_magnitude\n</code></pre> <p>\u4e0b\u9762\u5c06\u65b9\u5411\u4e0e\u5e45\u5ea6\u76f8\u4e58\uff1a</p> Python<pre><code>print(\"weight_direction * weight_magnitude:\")\nprint(weight_direction * weight_magnitude)\n\nprint(\"inputx @ (weight_direction * weight_magnitude).T:\")\nprint(inputx @ (weight_direction * weight_magnitude).T)\n\nprint(\"linear(inputx):\")\nprint(linear(inputx))\n\nprint(\"wn_linear(inputx):\")\nprint(wn_linear(inputx))\n</code></pre> Text Only<pre><code>weight_direction * weight_magnitude:\ntensor([[ 0.0999, -0.1095,  0.0053],\n        [ 0.4107, -0.1039, -0.5627],\n        [-0.0347, -0.1121,  0.0211],\n        [ 0.1116,  0.0381, -0.0633]], grad_fn=&lt;MulBackward0&gt;)\ninputx @ (weight_direction * weight_magnitude).T:\ntensor([[-0.2544, -0.1274, -0.3263,  0.1558],\n        [-0.0517,  1.6473, -0.2235,  0.3099]], grad_fn=&lt;MmBackward0&gt;)\nlinear(inputx):\ntensor([[-0.2544, -0.1274, -0.3263,  0.1558],\n        [-0.0517,  1.6473, -0.2235,  0.3099]], grad_fn=&lt;MmBackward0&gt;)\nwn_linear(inputx):\ntensor([[-0.2544, -0.1274, -0.3263,  0.1558],\n        [-0.0517,  1.6473, -0.2235,  0.3099]], grad_fn=&lt;MmBackward0&gt;)\n</code></pre> <p>\uff081\uff09\u65b9\u5411\u4e0e\u5e45\u5ea6\u76f8\u4e58\uff0c\u5f97\u5230\uff1a</p> Python<pre><code>print(\"weight_direction * weight_magnitude:\")\nprint(weight_direction * weight_magnitude)\n</code></pre> Text Only<pre><code># weight_direction * weight_magnitude:\n# tensor([[ 0.4900, -0.5379,  0.5541],\n#         [-0.5104,  0.3061,  0.4884],\n#         [-0.0247, -0.0822,  0.2893],\n#         [-0.1487, -0.4578, -0.4388]], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>\u89c2\u5bdf\uff0clinear.weight\u7684\u7ed3\u679c\u548c \u65b9\u5411\u4e0e\u5e45\u5ea6\u76f8\u4e58 \u5f97\u5230\u7684\u4e58\u79ef  \u7ed3\u679c\u76f8\u540c</p> <p>\u53ef\u4ee5\u628a lienar.weight \u7684\u7ed3\u679c \u5206\u89e3\u4e3a \u5e45\u5ea6\u548c\u65b9\u5411\u7684\u4e58\u79ef</p> <p>\uff082\uff09\u628ainputx\u5206\u522b\u653e\u5165linear\u5c42\u548cweight_linear\u5c42\u3001inputx\u4e0eweight_direction \u65b9\u5411\u548c\u5e45\u5ea6 weight_magnitude\u505a\u77e9\u9635\u4e58\u6cd5\uff1a</p> Python<pre><code>print(\"inputx @ (weight_direction * weight_magnitude).T:\")\nprint(inputx @ (weight_direction * weight_magnitude).T)\nprint(\"linear(inputx):\")\nprint(linear(inputx))\nprint(\"wn_linear(inputx):\")\nprint(wn_linear(inputx))\n</code></pre> <p>\u6253\u5370\u7ed3\u679c\uff1a</p> Text Only<pre><code>inputx @ (weight_direction * weight_magnitude).T:\ntensor([[-0.2544, -0.1274, -0.3263,  0.1558],\n        [-0.0517,  1.6473, -0.2235,  0.3099]], grad_fn=&lt;MmBackward0&gt;)\nlinear(inputx):\ntensor([[-0.2544, -0.1274, -0.3263,  0.1558],\n        [-0.0517,  1.6473, -0.2235,  0.3099]], grad_fn=&lt;MmBackward0&gt;)\nwn_linear(inputx):\ntensor([[-0.2544, -0.1274, -0.3263,  0.1558],\n        [-0.0517,  1.6473, -0.2235,  0.3099]], grad_fn=&lt;MmBackward0&gt;)\n</code></pre> <p>\u53d1\u73b0 \u4e09\u4e2a\u7ed3\u679c\u90fd\u662f\u4e00\u6837\u7684</p> <ul> <li>wn_linear \u8fd9\u4e2a\u65b0\u751f\u6210\u7684\u5c42\u5e76\u4e0d\u4f1a\u6539\u53d8\u6a21\u5757\u7684\u8f93\u51fa\u503c\uff0c\u4e4b\u524dlinear\u7684\u8f93\u51fa\u662f\u4ec0\u4e48\uff0c\u52a0\u4e86WeightNorm\u8f93\u51fa\u4f9d\u65e7\u4e0d\u53d8</li> <li>\u533a\u522b\uff1a\uff081\uff09\u539f\u59cblinear\u5c42\u7684\u53c2\u6570\u53ea\u6709weight\uff082\uff09weightNorm\u4e4b\u540e\u7684\u5c42\u6709g\u548cv</li> </ul> <p>\u67e5\u770bwn_lienar\u7684\u53c2\u6570</p> Python<pre><code>print(\"paramter of wn_linear:\")\nfor n,p in wn_linear.named_parameters():\n    print(n,p)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>weight_g Parameter containing:\ntensor([[0.1483],\n        [0.7043],\n        [0.1192],\n        [0.1339]], requires_grad=True)\nweight_v Parameter containing:\ntensor([[ 0.0999, -0.1095,  0.0053],\n        [ 0.4107, -0.1039, -0.5627],\n        [-0.0347, -0.1121,  0.0211],\n        [ 0.1116,  0.0381, -0.0633]], requires_grad=True)\n</code></pre> <p>\u89e3\u91ca\u8f93\u51fa\u7ed3\u679c\uff1a</p> <p>wn_linear\u53ea\u6709\u4e24\u4e2a\u8f93\u51fa\u7ed3\u679c\uff1a</p> <ul> <li>weight g\uff1alinear\u6743\u91cd\u7684\u5e45\u5ea6</li> <li>weight v\uff1aweight\u7684\u65b9\u5411\u5f52\u4e00\u5316</li> </ul> Python<pre><code>print(\"paramter of wn_linear:\")\nfor n,p in wn_linear.named_parameters():\n    print(n,p)\n\nprint(\"lienar.weight\")\nprint(linear.weight)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>paramter of wn_linear:\nweight_g Parameter containing:\ntensor([[0.1483],\n        [0.7043],\n        [0.1192],\n        [0.1339]], requires_grad=True)\nweight_v Parameter containing:\ntensor([[ 0.0999, -0.1095,  0.0053],\n        [ 0.4107, -0.1039, -0.5627],\n        [-0.0347, -0.1121,  0.0211],\n        [ 0.1116,  0.0381, -0.0633]], requires_grad=True)\nlienar.weight\ntensor([[ 0.0999, -0.1095,  0.0053],\n        [ 0.4107, -0.1039, -0.5627],\n        [-0.0347, -0.1121,  0.0211],\n        [ 0.1116,  0.0381, -0.0633]], grad_fn=&lt;WeightNormInterfaceBackward0&gt;)\n</code></pre> <p>\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff1a</p> <p>weight_v \u548c lienar.weight\u7684\u7ed3\u679c\u662f\u76f8\u7b49\u7684\uff0c\u5176\u5b9eweight_v \u5c31\u662flinear.weight\u4f46\u662f\u516c\u5f0f\u4e2d \u5bf9 weight_v\u8fdb\u884c\u4e86\u5f52\u4e00\u5316 \u5e76\u4e58\u4ee5 \u5e45\u5ea6\uff0c\u6240\u4ee5 linear.weight\u53ef\u4ee5\u62c6\u6210\u5e45\u5ea6\u5411\u91cf\u548c\u65b9\u5411\u5411\u91cf\uff0c\u5982\u679c\u4e0d\u5bf9weight_v \u8fdb\u884c\u53d8\u6362\uff0c\u90a3\u7b49\u5f0f\u4e24\u8fb9\u5c31\u4e0d\u4f1a\u76f8\u7b49\u7684</p> \\[ w = g \\frac{v}{||v||}\\] <p>v\u5c31\u662fw\uff0c\u5bf9v\u505a\u53d8\u6362\uff0c\u4f7f\u5f97\u7b49\u5f0f\u4e24\u8fb9\u76f8\u7b49</p> Python<pre><code>print(\"construct weight of linear:\")\nprint(wn_linear.weight_g*(wn_linear.weight_v)/torch.tensor([wn_linear.weight_v[i,:].norm() for i in torch.arange(wn_linear.weight_v.shape[-1])]))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>construct weight of linear:\ntensor([[ 0.0999, -0.0231,  0.0066],\n        [ 1.9504, -0.1039, -3.3245],\n        [-0.0279, -0.0190,  0.0211],\n        [ 0.1008,  0.0072, -0.0711]], grad_fn=&lt;DivBackward0&gt;)\n</code></pre> <p>\u8fd9\u4e2a\u7ed3\u679c\u548c weight_v \u4ee5\u53calinear.weight\u7684\u7ed3\u679c\u90fd\u662f\u76f8\u7b49\u7684</p>"},{"location":"learning/8_WeightNorm/#24-linear","title":"2.4 linear\u5c42\u6f14\u793a\u4ee3\u7801","text":"<p>\u6240\u6709linear\u5c42\u7684\u4ee3\u7801\uff1a</p> Python<pre><code>import torch\nimport torch.nn as nn\n\n# \u5173\u4e8e\u6743\u91cd\u5f52\u4e00\u5316\u7684\u518d\u6b21\u8bf4\u660e\n# WeightNorm W = Magnitude * UnitDirection = Magnitude * (W/Norm(W))\n\n# step1:define constant\nbatch_size = 2\nfeat_dim = 3\nhid_dim = 4\ninputx = torch.randn(batch_size,feat_dim)\n\n# x\uff1a2\u00d73 3\u6620\u5c04\u52304\u7ef4 w^T 4\u00d73 w 3\u00d74 torch\u4e2d\u5b58\u7684\u5c31\u662f 4\u00d73\u7684 \u76f4\u63a5\u8fdb\u884c w\uff084 3\uff09\u53d8\u6210 2\u00d74\nlinear = nn.Linear(feat_dim,hid_dim,bias=False)\nwn_linear = torch.nn.utils.weight_norm(linear)\n</code></pre> <p></p>Python<pre><code># step2:Linear Layer:calculate g and v\nweight_magnitude = torch.tensor([linear.weight[i:,].norm() for i in torch.arange(linear.weight.shape[0])],dtype =torch.float32).unsqueeze(-1)\nweight_direction = linear.weight / weight_magnitude\nprint(weight_direction)\n# print(\"inputx:\",inputx.shape) # inputx: torch.Size([2, 3])\n# print(\"linear.weight:\",linear.weight.shape) # linear.weight: torch.Size([4, 3])\n# print(\"linear(inputx)\",linear(inputx).shape)  # linear(inputx) torch.Size([2, 4])\n\n# print(\"weight_magnitude:\",weight_magnitude.shape)  # torch.Size([4, 1])\n# print(\"weight_direction:\",weight_direction.shape)  # weight_direction: torch.Size([4, 3])\nprint(\"magnitude of weight_direction:\",(weight_direction**2).sum(dim=-1))\n</code></pre> \u552f\u4e00\u6709\u7684\u4e00\u4e2a\u95ee\u9898\uff1amagnitude of weight_direction\u7ed3\u679c\u4e0d\u662f1<p></p> Text Only<pre><code>tensor([[ 0.1347, -0.1476,  0.0071],\n        [ 0.5651, -0.1429, -0.7742],\n        [-0.1938, -0.6252,  0.1177],\n        [ 0.8338,  0.2848, -0.4729]], grad_fn=&lt;DivBackward0&gt;)\nmagnitude of weight_direction: tensor([0.0400, 0.9392, 0.4423, 1.0000], grad_fn=&lt;SumBackward1&gt;)\n</code></pre> Python<pre><code>print(\"weight_direction * weight_magnitude:\")\nprint(weight_direction * weight_magnitude)\n\nprint(\"inputx @ (weight_direction * weight_magnitude).T:\")\nprint(inputx @ (weight_direction * weight_magnitude).T)\n\nprint(\"linear(inputx):\")\nprint(linear(inputx))\n\nprint(\"wn_linear(inputx):\")\nprint(wn_linear(inputx))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>weight_direction * weight_magnitude:\ntensor([[ 0.0999, -0.1095,  0.0053],\n        [ 0.4107, -0.1039, -0.5627],\n        [-0.0347, -0.1121,  0.0211],\n        [ 0.1116,  0.0381, -0.0633]], grad_fn=&lt;MulBackward0&gt;)\ninputx @ (weight_direction * weight_magnitude).T:\ntensor([[-0.2544, -0.1274, -0.3263,  0.1558],\n        [-0.0517,  1.6473, -0.2235,  0.3099]], grad_fn=&lt;MmBackward0&gt;)\nlinear(inputx):\ntensor([[-0.2544, -0.1274, -0.3263,  0.1558],\n        [-0.0517,  1.6473, -0.2235,  0.3099]], grad_fn=&lt;MmBackward0&gt;)\nwn_linear(inputx):\ntensor([[-0.2544, -0.1274, -0.3263,  0.1558],\n        [-0.0517,  1.6473, -0.2235,  0.3099]], grad_fn=&lt;MmBackward0&gt;)\n</code></pre> Python<pre><code>print(\"paramter of wn_linear:\")\nfor n,p in wn_linear.named_parameters():\n    print(n,p)\n\nprint(\"lienar.weight\")\nprint(linear.weight)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>paramter of wn_linear:\nweight_g Parameter containing:\ntensor([[0.1483],\n        [0.7043],\n        [0.1192],\n        [0.1339]], requires_grad=True)\nweight_v Parameter containing:\ntensor([[ 0.0999, -0.1095,  0.0053],\n        [ 0.4107, -0.1039, -0.5627],\n        [-0.0347, -0.1121,  0.0211],\n        [ 0.1116,  0.0381, -0.0633]], requires_grad=True)\nlienar.weight\ntensor([[ 0.0999, -0.1095,  0.0053],\n        [ 0.4107, -0.1039, -0.5627],\n        [-0.0347, -0.1121,  0.0211],\n        [ 0.1116,  0.0381, -0.0633]], grad_fn=&lt;WeightNormInterfaceBackward0&gt;)\n</code></pre> Python<pre><code>print(\"construct weight of linear:\")\nprint(wn_linear.weight_g*(wn_linear.weight_v)/torch.tensor([wn_linear.weight_v[i,:].norm() for i in torch.arange(wn_linear.weight_v.shape[-1])]))\n</code></pre> Python<pre><code>construct weight of linear:\ntensor([[ 0.0999, -0.0231,  0.0066],\n        [ 1.9504, -0.1039, -3.3245],\n        [-0.0279, -0.0190,  0.0211],\n        [ 0.1008,  0.0072, -0.0711]], grad_fn=&lt;DivBackward0&gt;)\n</code></pre>"},{"location":"learning/8_WeightNorm/#25-conv","title":"2.5 conv\u5c42\u7684\u4ee3\u7801","text":"<p>(\u5168\u90e8\u4ee3\u7801)</p> Text Only<pre><code>conv1d = nn.Conv1d(feat_dim,hid_dim,kernel_size=1,bias=False) # input:[B,C,T],weight:[oc,ic,1]\nwn_conv1d = torch.nn.utils.weight_norm(conv1d)\n</code></pre> Python<pre><code>covn1d_weight_magnitude = torch.tensor([conv1d.weight[i,:,:].norm() \n                                        for i in torch.arange(conv1d.weight.shape[0])],dtype=torch.float32).reshape(\n                                            conv1d.weight.shape[0],1,1\n                                        ).tile(1,feat_dim,1)\n\ncovn1d_weight_direction = conv1d.weight / covn1d_weight_magnitude\n\nprint(\"parameters of wn_conv1d:\")\nfor n,p in wn_conv1d.named_parameters():\n    print(n,p,p.shape)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>parameters of wn_conv1d:\nweight_g Parameter containing:\ntensor([[[0.4729]],\n\n        [[0.7834]],\n\n        [[0.5456]],\n\n        [[0.5718]]], requires_grad=True) torch.Size([4, 1, 1])\nweight_v Parameter containing:\ntensor([[[ 0.0987],\n         [-0.1757],\n         [ 0.4279]],\n\n        [[ 0.4962],\n         [-0.4026],\n         [ 0.4533]],\n\n        [[ 0.4717],\n         [-0.1782],\n         [-0.2082]],\n\n\n        [[-0.5708],\n         [ 0.0271],\n         [-0.0208]]], requires_grad=True) torch.Size([4, 3, 1])         \n</code></pre> Python<pre><code>print(\"construct weight of conv1d:\")\nprint(wn_conv1d.weight_g * (wn_conv1d.weight_v / torch.tensor(\n    [wn_conv1d.weight_v[i,:,:].norm() \n     for i in torch.arange(wn_conv1d.weight_v.shape[0])],\n                            dtype=torch.float32).unsqueeze(-1).unsqueeze(-1)))\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>construct weight of conv1d:\ntensor([[[ 0.0987],\n         [-0.1757],\n         [ 0.4279]],\n\n        [[ 0.4962],\n         [-0.4026],\n         [ 0.4533]],\n\n        [[ 0.4717],\n         [-0.1782],\n         [-0.2082]],\n\n        [[-0.5708],\n         [ 0.0271],\n         [-0.0208]]], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> Python<pre><code>print(\"conv1d.weight:\")\nprint(conv1d.weight)\n\nprint(\"covn1d_weight_magnitude:\")\nprint(covn1d_weight_magnitude)\n\nprint(\"covn1d_weight_direction:\")\nprint(covn1d_weight_direction)\n</code></pre> <p>\u8f93\u51fa\uff1a</p> Text Only<pre><code>conv1d.weight:\ntensor([[[ 0.0987],\n         [-0.1757],\n         [ 0.4279]],\n\n        [[ 0.4962],\n         [-0.4026],\n         [ 0.4533]],\n\n        [[ 0.4717],\n         [-0.1782],\n         [-0.2082]],\n\n        [[-0.5708],\n         [ 0.0271],\n         [-0.0208]]], grad_fn=&lt;WeightNormInterfaceBackward0&gt;)\ncovn1d_weight_magnitude:\ntensor([[[0.4729],\n         [0.4729],\n         [0.4729]],\n\n        [[0.7834],\n         [0.7834],\n         [0.7834]],\n\n        [[0.5456],\n         [0.5456],\n         [0.5456]],\n        [[0.5718],\n         [0.5718],\n         [0.5718]]])\ncovn1d_weight_direction:\ntensor([[[ 0.2086],\n         [-0.3715],\n         [ 0.9047]],\n\n        [[ 0.6334],\n         [-0.5139],\n         [ 0.5785]],\n\n        [[ 0.8647],\n         [-0.3267],\n         [-0.3816]],\n\n        [[-0.9982],\n         [ 0.0475],\n         [-0.0364]]], grad_fn=&lt;DivBackward0&gt;)         \n</code></pre> <p>\u89e3\u8bfb\uff1a</p> <p>\uff081\uff09\u5b9e\u4f8b\u5316\u4e00\u4e2a 1\u00d71 \u7684\u5377\u79ef\u5c42</p> Python<pre><code>conv1d = nn.Conv1d(feat_dim,hid_dim,kernel_size=1,bias=False)\n# input:[B,C,T],weight:[oc,ic,1]\nwn_conv1d = torch.nn.utils.weight_norm(conv1d)\n</code></pre> <ul> <li>1\u00d71 \u7684\u5377\u79ef\u5c42 \u7c7b\u4f3c MLP</li> <li>\u8f93\u5165\u901a\u9053\u6570 \u8bbe\u7f6e\u4e3a feat_dim\uff0c\u8f93\u51fa\u901a\u9053\u6570\u662f  hid_dim\uff0ckernel_size\u8bbe\u4e3a1\uff0c\u4e0d\u8981bias</li> <li>1\u00d71\u7684\u5377\u79ef\u5c42\uff0c\u8f93\u5165\u7684\u6570\u636e\u683c\u5f0f\uff1abatchsize \u00d7 channel\u00d7length</li> <li>\u6743\u91cd\u7684\u7ef4\u5ea6\u662f output channel\u00d7input channel \u00d7kernel size\uff0c\u8fd9\u91cckernel size=1</li> <li>\u628a\u4e00\u7ef4\u5377\u79ef conv1d \u4f5c\u4e3a module\uff0c\u9001\u5165\u5230weight Norm\u51fd\u6570\u4e2d\uff0c\u5f97\u5230WeightNorm\u5305\u88f9\u540e\u7684convolution\uff1awn_conv1d\uff08\u5373\u52a0\u4e86\u6743\u91cd\u5f52\u4e00\u5316\u7684\u6a21\u5757\uff09</li> </ul> <p>\uff082\uff09\u8ba1\u7b97 covn1d_weight_magnitude</p> Python<pre><code>covn1d_weight_magnitude = torch.tensor([conv1d.weight[i,:,:].norm() \n                                        for i in torch.arange(conv1d.weight.shape[0])],dtype=torch.float32).reshape(\n                                            conv1d.weight.shape[0],1,1\n                                        ).tile(1,feat_dim,1)\n\ncovn1d_weight_direction = conv1d.weight / covn1d_weight_magnitude\n\nprint(\"parameters of wn_conv1d:\")\nfor n,p in wn_conv1d.named_parameters():\n    print(n,p,p.shape)\n</code></pre> <ul> <li>conv1d.weight\u62ff\u51fa\u5377\u79ef\u5c42\u7684\u6743\u91cd\uff0c\u8ba1\u7b97\u6743\u91cd\u77e9\u9635\u7684\u5e45\u5ea6\uff0c\u6743\u91cd\u662f\u4e00\u4e2a\u4e09\u7ef4\u77e9\u9635\uff0c\u683c\u5f0f\u662fweight:[oc,ic,1]\uff0c\u5bf9\u6bcf\u4e00\u884c\u8ba1\u7b97\u6a21\uff0c\u6bcf\u4e00\u884c\u662f\u4e00\u4e2a\u4e8c\u9636\u5f20\u91cf\uff0c\u6bcf\u4e00\u4e2a\u4e8c\u9636\u5f20\u91cf \u8ddf input \u8fdb\u884c\u4e58\u6cd5\u64cd\u4f5c\uff0c\u6240\u4ee5\u6211\u4eec\u5bf9\u6bcf\u4e00\u884c \u8ba1\u7b97\u8303\u6570\uff0c\u7136\u540e\u62fc\u8d77\u6765\uff0c\u7136\u540e\u8fdb\u884c\u6269\u7ef4\uff0c\u5f97\u5230\u5e45\u5ea6 covn1d_weight_magnitude</li> <li>\u5355\u4f4d\u5411\u91cf \u540c\u6837\u662f weight \u9664\u4ee5 \u5e45\u5ea6\uff0c\u5f97\u5230\u5355\u4f4d\u5411\u91cf\uff0c\u4e5f\u5c31\u662f\u65b9\u5411\u5411\u91cf</li> </ul> <p>\uff083\uff09\u6253\u5370\u5e45\u5ea6\u3001\u5355\u4f4d\u5411\u91cf\u3001\u539f\u6765\u7684\u6743\u91cd\uff0c\u4ee5\u53cawn_conv1d\u4e2d\u7684\u4e24\u4e2a\u53c2\u6570\uff1a</p> Python<pre><code>print(\"parameters of wn_conv1d:\")\nfor n,p in wn_conv1d.named_parameters():\n    print(n,p,p.shape)\n\n\nprint(\"construct weight of conv1d:\")\nprint(wn_conv1d.weight_g * (wn_conv1d.weight_v / torch.tensor(\n    [wn_conv1d.weight_v[i,:,:].norm() \n     for i in torch.arange(wn_conv1d.weight_v.shape[0])],\n                            dtype=torch.float32).unsqueeze(-1).unsqueeze(-1)))\n\nprint(\"conv1d.weight:\")\nprint(conv1d.weight)\n\nprint(\"covn1d_weight_magnitude:\")\nprint(covn1d_weight_magnitude)\n\nprint(\"covn1d_weight_direction:\")\nprint(covn1d_weight_direction)\n</code></pre> <p>\u2460 wn_conv1d\u4e2d\u7684\u4e24\u4e2a\u53c2\u6570\uff1a\u6709weight_g  \u548c weight_v</p> <p>weight_g  \u5377\u79ef\u7684\u6743\u91cd\u7684\u5e45\u5ea6</p> <p>weight_v  \u5c31\u662f\u5377\u79ef\u7684\u6743\u91cd</p> <p>\u533a\u5206\uff1a</p> <p>weight_v \u5c31\u662f\u6743\u91cd</p> <p>\u9664\u4ee5v\u7684\u8303\u6570 \u624d\u662f\u65b9\u5411</p> <p>\u9664\u4ee5v\u7684\u8303\u6570 \u518d\u4e58\u4ee5 \u5e45\u5ea6 \u8fd8\u662f\u6743\u91cd \u8fd8\u662f weight_v</p> <p>\u2461 </p> <p>\u628a \u5e45\u5ea6 \u4e0e\u5355\u4f4d\u5411\u91cf \u76f8\u4e58</p> <p>\u5e45\u5ea6\uff1awn_conv1d.weight_g</p> <p>\u5355\u4f4d\u5411\u91cf\uff1a</p> Text Only<pre><code>wn_conv1d.weight_v / torch.tensor(\n    [wn_conv1d.weight_v[i,:,:].norm() \n     for i in torch.arange(wn_conv1d.weight_v.shape[0])],\n                            dtype=torch.float32)\n</code></pre> <p>\u672c\u8d28\u662f weight\u5411\u91cf \u9664\u4ee5 weight \u5411\u91cf\u7684\u6a21\uff0c\u5f97\u5230\u5355\u4f4d\u65b9\u5411\u5411\u91cf\uff0c\u6216\u8005\u53eb \u5355\u4f4d\u957f\u5ea6\u7684\u65b9\u5411\u5411\u91cf</p> <p>\u5e45\u5ea6 \u00d7 \u5355\u4f4d\u957f\u5ea6\u7684\u65b9\u5411\u5411\u91cf \u5f97\u5230  <code>construct weight of conv1d</code></p> <p>\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff1a<code>construct weight of conv1d</code> \u4e0e <code>weight_v</code> \u4e0e <code>conv1d.weight</code> \u662f\u4e00\u6837\u7684\uff0c\u5c31\u662f\u5377\u79ef\u7684\u6743\u91cd</p> <p>\u2462 \u5bf9\u6bd4  <code>weight_v</code> <code>construct weight of conv1d</code> <code>conv1d.weight</code>  \u90fd\u662f\u4e00\u6837\u7684</p> <p>\u5728\u4e00\u7ef4\u5377\u79ef\u4e2d \u4e5f\u662f\u4e00\u6837\u7684\uff0c\u52a0\u4e86\u6743\u91cd\u5f52\u4e00\u5316\uff0c\u5c31\u662f\u628a\u5e45\u5ea6\u4e0e \u6743\u91cd\u7684\u5355\u4f4d\u957f\u5ea6\u7684\u65b9\u5411\u5411\u91cf \u89e3\u8026\u5f00\u6765\uff0c\u6253\u5370\u6743\u91cd\u7684\u5e45\u5ea6 \u548c \u6743\u91cd\u7684\u5355\u4f4d\u957f\u5ea6\u7684\u65b9\u5411\u5411\u91cf</p> Python<pre><code>print(\"covn1d_weight_magnitude:\")\nprint(covn1d_weight_magnitude)\n\nprint(\"covn1d_weight_direction:\")\nprint(covn1d_weight_direction)\n</code></pre> <p>\u4ee5\u4e0a\u7684WeightNorm\u7684\u539f\u7406\uff0c\u6700\u91cd\u8981\u7684\u5c31\u662f \u516c\u5f0f\uff1a</p> <p></p> <p>\uff081\uff09\u5982\u679c\u4e0d\u52a0 WeightNorm\uff0c\u53ea\u9700\u8981\u4f18\u5316\u4e00\u4e2a\u53c2\u6570\uff0c\u52a0\u4e86WeightNorm\u4e4b\u540e\uff0c\u9700\u8981\u4f18\u5316\u4e24\u4e2a\u53c2\u6570\uff0c\u628aloss\u540c\u65f6\u5bf9g\u6c42\u68af\u5ea6\uff0c\u5bf9v\u6c42\u4e00\u4e2a\u68af\u5ea6</p> <p>\uff082\uff09\u5e76\u4e14WeightNorm\u5e76\u6ca1\u6709\u5e26\u6765\u989d\u5916\u7684\u53c2\u6570\uff0c\u5e76\u6ca1\u6709\u5e26\u6765\u5b9e\u8d28\u610f\u4e49\u4e0a\u7684\u989d\u5916\u53c2\u6570\uff0c\u5bf9\u6bd4BatchNorm\u4f1a\u9700\u8981\u8ba1\u7b97\u989d\u5916\u7684\u7edf\u8ba1\u91cf\uff0c\u800cWeightNorm\u5e76\u6ca1\u6709\u589e\u52a0\u989d\u5916\u7684\u53c2\u6570</p> <p>\uff083\uff09\u7ecf\u8fc7\u4ee5\u4e0a\u7684\u5b9e\u9a8c\uff0c\u53ef\u4ee5\u770b\u5230\u505a\u4e86WeightNorm\u4e4b\u540e\uff0c\u8f93\u51fa\u503c\u662f\u6ca1\u6709\u53d8\u5316\u7684\uff0c\u6bd4\u5982\uff1a</p> <p></p> <p>\u5c55\u793a\u4e86\u4e09\u79cd\u8ba1\u7b97\uff0c</p> <p>\u2460 inputx\u8ddf\u65b9\u5411\u5411\u91cf\u76f8\u4e58</p> <p>\u2461inputx\u653e\u5165linear\u5c42</p> <p>\u2462inputx\u653e\u5165WeightNorm linear\u5c42</p> <p>\u8f93\u51fa\u503c\u90fd\u662f\u4e00\u6837\u7684\uff0c\u6743\u91cd\u5f52\u4e00\u5316\u4e0d\u4f1a\u6539\u53d8\u6a21\u5757\u7684\u8f93\u51fa\u503c\uff0c\u53ea\u662f\u6539\u53d8\u4e86\u53c2\u6570\u5185\u90e8\u7684\u4e58\u6cd5\u64cd\u4f5c\u7684\u6a21\u5f0f\uff0c\u76f8\u5f53\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u8fc7\u7a0b</p> <p>\u6240\u4ee5\u6743\u91cd\u5f52\u4e00\u5316 \u4e5f\u53ef\u4ee5 \u7406\u89e3\u4e3a\u6743\u91cd\u5206\u89e3</p> <p>\u628a\u6743\u91cd\u7684\u5e45\u5ea6 \u8ddf \u5355\u4f4d\u957f\u5ea6\u7684 \u65b9\u5411\u5411\u91cf \u89e3\u8026\u5f00\u6765\uff0c\u5728pytorch\u4e2d\u901a\u8fc7torch.nn.utils.weight_norm\u7684\u51fd\u6570\uff0c\u628a\u4e00\u4e2amodule\u5305\u88f9\u8d77\u6765\uff0c\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684module\uff0c\u65b0\u7684module\u53c2\u6570\u662f\u4e24\u4e2a\uff0c\u4e00\u4e2a\u662fweight_g \u4e00\u4e2a\u662f weight_v</p> <p>weight_g \u662f\u539f\u6765\u6743\u91cd\u7684\u5e45\u5ea6\uff0cweight_v \u5c31\u662f\u539f\u6765\u7684\u6743\u91cd</p> <p>\u95ee\u9898\uff1a\u4e3a\u4ec0\u4e48\u8981\u9664\u4ee5 v\u7684\u6a21\uff1f</p> <p>\u7b54\uff1a\u56e0\u4e3a\u9664\u4ee5 v\u7684\u6a21\uff0c\u5f97\u5230\u5355\u4f4d\u957f\u5ea6\u7684\u65b9\u5411\u5411\u91cf\uff0c\u518d\u8ddf\u5e45\u5ea6\u76f8\u4e58\uff0c\u5f97\u5230\u539f\u6765\u7684\u6743\u91cd\uff0c\u5982\u679c\u4e0d\u9664\u4ee5\u6a21\u7684\u8bdd\uff0c\u6240\u6709\u4e24\u8fb9\u662f\u4e0d\u4f1a\u76f8\u7b49\u7684</p> <p></p>"},{"location":"learning/9_cGAN/","title":"GAN \u53d8\u4f53","text":""},{"location":"learning/9_cGAN/#gan","title":"GAN \u53d8\u4f53","text":"2024-12-08 22:35:212025-09-28 12:54:04 <p> \u7ea6 6782 \u4e2a\u5b57  370 \u884c\u4ee3\u7801  41 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 39 \u5206\u949f</p> <p>cGAN\u53caLSGAN\u7684\u539f\u7406\u4e0ePyTorch\u624b\u5199\u9010\u884c\u8bb2\u89e3</p> <p></p> <p></p> <ul> <li>\u6761\u4ef6GAN</li> <li>\u6700\u5c0f\u5e73\u65b9GAN or  \u6700\u5c0f\u4e8c\u4e58GAN</li> </ul> <p>topic\uff1a\u539f\u7406 &amp; \u4ee3\u7801\u5b9e\u73b0</p> <p>minist\u6570\u636e\u96c6\uff1a6w\u5f20\u624b\u5199\u6570\u5b57\u56fe\u7247</p> <p>GAN\u57fa\u4e8eminist\u6570\u636e\u96c6\u8fdb\u884c\u65e0\u76d1\u7763\u7684\u56fe\u7247\u751f\u6210\u4efb\u52a1</p>"},{"location":"learning/9_cGAN/#1-recall","title":"1 Recall","text":"<p>GAN\u7684\u4ee3\u7801\u5b9e\u73b0\u903b\u8f91\uff0c\u9996\u5148\u6784\u5efaGenerator\uff0cGenerator\u4ee5\u4e00\u4e2a\u9690\u53d8\u91cf\uff0c\u4ece\u9ad8\u65af\u5206\u5e03\u751f\u6210\u7684\u968f\u673a\u9690\u53d8\u91cfz\uff0c\u4f5c\u4e3a\u8f93\u5165\uff0c\u7136\u540e\u628az\u653e\u5165\u5230\u5f88\u591a\u5c42DNN\u4e2d\uff0cDNN\u6700\u540e\u751f\u6210\u56fe\u7247\u5927\u5c0f\u7684\u751f\u6210\u56fe\u7247\uff0c\u7136\u540e\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\u7ea6\u675f\u5230\u4e00\u5b9a\u7684\u503c\u57df\u5185\uff0c\u901a\u8fc7nn.Sigmoid() \u6216\u8005 nn.tanh()\u90fd\u53ef\u4ee5\uff1a</p> <p></p> <p></p> <p>\u7ecf\u8fc7 \u751f\u6210\u5668\uff0c\u751f\u6210\u4e00\u5f20\u56fe\u7247</p> <p>\u57fa\u4e8e \u968f\u673a\u9ad8\u65af\u53d8\u91cfz\uff0c\u751f\u6210\u4e00\u5f20\u7167\u7247\uff0cz\u7684\u7ef4\u5ea6\u53ef\u4ee5\u8bbe\u7f6e\u4e00\u4e2alatent_dim\uff0c\u6bd4\u598296\uff0c\u5e76\u4e14\u4ee4batchsize=64\uff0c\u6b64\u65f6\u6bcf\u4e00\u6b21\u8bad\u7ec3\u7684\u5927\u5c0f \u5c31\u662f 64\u00d796\u7684\u4e8c\u7ef4\u5f20\u91cf</p> <p>\u4ee5\u4e0a\u662f\u751f\u6210\u5668\uff0c\u63a5\u4e0b\u6765\u770b\u5224\u522b\u5668\uff1a</p> <p></p> <p>\u5224\u522b\u5668\u7684\u4f5c\u7528\uff1a</p> <p>\uff081\uff09\u51c6\u786e\u7684\u533a\u5206\u51fa \u4ec0\u4e48\u662f\u771f\u5b9e\u6837\u672c \u4ec0\u4e48\u662f \u9884\u6d4b\u6837\u672c</p> <p>\uff082\uff09\u7ed9\u51fa\u4fe1\u53f7\uff0c\u4f7f\u5f97\u751f\u6210\u5668 \u66f4\u597d\u7684\u751f\u6210 \u66f4\u52a0\u903c\u8fd1\u771f\u5b9e\u7684\u6837\u672c</p> <p>\u5224\u522b\u5668\u4ee5 \u56fe\u7247\u4f5c\u4e3a\u8f93\u5165\uff0c\u63a5\u7740\u7531 \u4e00\u7cfb\u5217\u7684  nn\u5c42\uff0c\u8c31\u5f52\u4e00\u5316 \u662f\u540e\u9762\u52a0\u7684\uff0c\u6700\u540e\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u503c\uff0c\u6807\u91cf\u503c \u901a\u8fc7nn.Sigmoid() \u8f93\u51fa\u7684\uff0c\u539f\u59cb\u7684GAN\u4f7f\u7528\u7684\u662f \u4e8c\u5206\u7c7b \u4ea4\u53c9\u71b5 \u7684\u635f\u5931\u51fd\u6570\uff0c\u6240\u4ee5\u4f7f\u7528\u7684\u662fnn.Sigmoid</p> <p></p> <p>\u6784\u5efa dataset\uff0cdataloader</p> <p>dataset\u4f7f\u7528\u7684torchvision\u7684\u5e93\uff0c\u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u4e0b\u8f7d</p> <p>\u89e3\u91ca torchvision.transforms.Compose\u4e2d   torchvision.transformsNormalize \u4e3a\u4ec0\u4e48\u4f7f\u7528\u7684 \u5747\u503c=0.5\uff0c\u65b9\u5dee=0.5\uff0c\u5982\u679c\u6211\u4eec\u53bb\u8ba1\u7b97minist\u6570\u636e\u96c6\u5747\u503c\u548c\u65b9\u5dee \u7684\u8bdd\uff0c\u5747\u503c \u5927\u6982\u7b49\u4e8e 0.1\uff0c\u6807\u51c6\u5dee\u7ea6\u7b49\u4e8e0.3\uff0c\u800c\u8fd9\u91cc\u4f7f\u7528\u7684\u5747\u503c\u548c\u65b9\u5dee\u4e3a0.5\uff0c\u662f\u56e0\u4e3a\u672c\u6765\u662f\u4f7f\u7528ToTensor\u7684\u8bed\u53e5\uff0c\u5df2\u7ecf\u628a\u56fe\u7247\u7684\u503c\u57df\u7ea6\u675f\u5230\u4e860~1\u4e4b\u95f4\uff0c0~1\u4e4b\u95f4 \u51cf\u53bb 0.5\uff0c\u53d8\u6210-0.5\u52300.5\u4e4b\u95f4\uff0c-0.5\u52300.5\u518d\u9664\u4ee50.5\uff0c\u53d8\u6210-1\u52301\u4e4b\u95f4\uff0c\u6240\u4ee5\u8fd9\u884c\u7684\u8bed\u53e5\u5e76\u4e0d\u662f\u5f52\u4e00\u5230\u6b63\u6001\u5206\u5e03\uff0c\u800c\u662f\u628a\u503c\u57df\u4ece0~1\u53d8\u5316\u5230-1~1\u4e4b\u95f4\uff0c\u8fd9\u662f\u5199\u4ee3\u7801\u7684\u5c0f\u6280\u5de7\uff1a\u5728transforms\u4e2d\u7684\u7ec4\u5408\u91cc\u9762\uff0c\u600e\u4e48\u628a\u4e0a\u4e00\u6b65\u76840~1\u7684\u6d6e\u70b9\u6570\u600e\u4e48\u53d8\u6210-1~1\u4e4b\u95f4\u7684\u503c\u57df\uff0c\u53ef\u4ee5\u901a\u8fc7\u5747\u503c\u548c\u6807\u51c6\u5dee\u5f52\u4e00\u5316\u5b9e\u73b0\uff0c\u6b64\u65f6\u6211\u4eec\u8bbe\u7f6e\u5747\u503c=0.5\uff0c\u6807\u51c6\u5dee=0.5\uff0c\u4ece\u539f\u6765\u76840~1\u8303\u56f4\u5185\uff0c\u53d8\u6210-1~1\u8303\u56f4\u5185\uff0c\u53d8\u6362\u5230-1~1\u8303\u56f4\u5185\u3002\u53d8\u6210-1~1\u8303\u56f4\u5185\uff0c\u5c31\u53ef\u4ee5\u5728Generator\u4e2d\uff0c\u4f7f\u7528tanh\u51fd\u6570\u9884\u6d4b\u6700\u7ec8\u7684\u50cf\u7d20\u503c</p> <p>\u6700\u7ec8tanh\u51fd\u6570\u867d\u7136\u8f93\u51fa\u7684\u662f-1~1\uff0c\u4f46\u662f\u6211\u4eec\u5728\u4fdd\u5b58\u7167\u7247\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u901a\u8fc7\u589e\u52a0\u4e00\u4e2aNormalize=True\uff0c\u5c31\u53ef\u4ee5\u4f7f\u5f97\u56fe\u7247\u4ece-1~1\uff0c\u518d\u6b21\u53d8\u62100 ~1\u4e4b\u95f4</p> <p>\u5728\u8bad\u7ec3\u65f6\uff0c</p> <p></p> <p>\u8ba1\u7b97g\u7684\u65f6\u5019\uff0c\u628a\u9884\u6d4b\u7684\u7167\u7247 \u9001\u5165\u5230\u5224\u522b\u5668\u4e2d\uff0c\u628a\u51681\u7684\u6807\u7b7e\uff0c\u4f5c\u4e3a\u5f53\u524d\u7684\u6807\u7b7e\uff0c\u6765\u5f97\u5230loss\u503c\uff0c\u6765\u66f4\u65b0Generator</p> <p>\u5bf9\u4e8e\u5224\u522b\u5668\u800c\u8a00\uff0c\u6709\u4e24\u4e2aloss\uff0c</p> <p></p> <p><code>real_loss</code> \u548c <code>fake_loss</code> </p> <p><code>real_loss</code> \u628a\u771f\u5b9e\u7684\u7167\u7247\u9001\u5165\u5230\u5224\u522b\u5668\u4e2d\uff0c\u6807\u7b7e\u662f\u51681 \u7684</p> <p><code>fake_loss</code>  \u628a\u9884\u6d4b\u7684\u7167\u7247 \u9001\u5165\u5230\u5224\u522b\u5668\u4e2d\uff0c\u6807\u7b7e\u662f\u51680 \u7684</p> <p>\u6211\u4eec\u5e0c\u671b\u5224\u522b\u5668\u662f\u80fd\u591f\u533a\u5206\u771f\u5b9e\u7167\u7247\u548c\u9884\u6d4b\u7167\u7247\u7684</p> <p></p> <p>\u4e4b\u540e\uff0c\u4f9d\u6b21\u66f4\u65b0 \u751f\u6210\u5668\u548c\u5224\u522b\u5668\u5373\u53ef</p> <p>\u4ee5\u4e0a\u662f\u539f\u59cbGAN\uff0c\u901a\u8fc7\u4e8c\u5206\u7c7b\u7684\u3001\u4ea4\u53c9\u71b5loss\u6765\u4f5c\u4e3a\u5224\u522b\u5668\u7684loss function</p>"},{"location":"learning/9_cGAN/#2-gan","title":"2 \u6761\u4ef6GAN","text":"<ul> <li>\u6761\u4ef6GAN</li> <li>\u5e94\u7528\u5f88\u5e7f\u6cdb</li> <li>\u5f15\u7528\u6b21\u6570 4k \u591a\u6b21</li> </ul>"},{"location":"learning/9_cGAN/#21-cgan","title":"2.1 cGAN\u7684\u521b\u65b0\u70b9","text":"<ul> <li>\u4e3a\u4ec0\u4e48\u4f1a\u6709 \u6761\u4ef6GAN\uff1f</li> </ul> <p>\u9996\u5148\u8ba8\u8bba\u539f\u59cbGAN\u7684\u751f\u6210\u6709\u4ec0\u4e48\u95ee\u9898\uff1f</p> <p></p> <p>\u539f\u59cbGAN\u7684\u56fe\u7247\u751f\u6210\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u770b\u539f\u6587\u7684\u7b97\u6cd51</p> <p>\uff081\uff09\u770b\u5224\u522b\u5668\u7684\u8f93\u5165\uff0c\u65e0\u8bba\u662f\u771f\u5b9e\u7684\u6837\u672c\uff0c\u8fd8\u662f\u9884\u6d4b\u7684\u6837\u672c\uff0c\u8f93\u5165\u90fd\u53ea\u6709\u4e00\u4e2a\uff0c\\(x^{(i)}\\) \u6216\u8005 \\(G(z{(i)})\\)\uff0c\u53ea\u662f\u628a\u7167\u7247\u9001\u5165\u5230\u5224\u522b\u5668\u4e4b\u4e2d</p> <p></p> <p>\uff0c\u4f46\u662f\u5728minist\u6570\u636e\u5e93\u4e2d\uff0c\u7167\u7247\u670910\u4e2a\u7c7b\u522b\uff0c0~9\uff0c10\u4e2a\u624b\u5199\u5b57\u8bc6\u522b\uff0c10\u7c7b\u7684\u65f6\u5019\uff0c\u4ec5\u4ec5\u8f93\u5165\u4e00\u4e2a\u968f\u673a\u7684\u9ad8\u65af\u53d8\u91cfz\u7684\u8bdd\uff0c\u6ca1\u6709\u8f93\u5165\u4efb\u4f55\u5176\u4ed6\u7684\u4fe1\u606f\uff0c\u5e76\u4e14\u5e0c\u671b\u751f\u6210\u5668\u80fd\u591f\u751f\u6210\u5f53\u524d\u6837\u672c\uff0c\u5f53\u524d\u4eceminibatch\u4e2d\uff0c\u53d6\u5f97\u7684\u662f0\uff0c\u5e0c\u671b\u5728z\u7684\u6307\u5bfc\u4e0b\uff0c\u751f\u62100\u7684\u7167\u7247\uff0c\u5982\u679c\u5f53\u524d\u771f\u5b9e\u7167\u7247\u62ff\u5230\u7684\u662f1\uff0c\u6211\u4eec\u6307\u671b\u968f\u673a\u53d8\u91cfz\uff0c\u751f\u6210\u4e3a1\u7684\u7167\u7247\uff0c\u8fd9\u6837\u4e5f\u662f\u53ef\u4ee5\u7684\uff0c\u4f46\u662f\u6709\u70b9\u96be\uff0c\u5c31\u662f\u7ed9\u7684\u4fe1\u606f\u91cf\u592a\u5c11\u4e86\uff0cz\u5c31\u662f\u4e00\u4e2a\u968f\u673a\u7684\u9ad8\u65af\u53d8\u91cf\uff0c\u4e0d\u786e\u5b9a\u6027\u5f88\u5927\uff0c\u56e0\u6b64\u6709\u52a9\u4e8e\u6211\u4eec\u9884\u6d4b\u76ee\u6807\u7167\u7247\u7684\u4fe1\u606f\u5c31\u5f88\u5c11\uff0c\u8fd9\u65f6\uff0c\u601d\u8003\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u63d0\u4f9b\u4ec0\u4e48\u91cf\u5462\uff1f\u6211\u4eec\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2ac\uff0c\u4e00\u4e2acondition\uff0c\u4e5f\u5c31\u662f\u8bf4\u5f53\u6211\u4eec\u7684G\u7684\u8f93\u5165\uff0c\u63a5\u6536\u7684\u8f93\u5165\u4e0d\u4ec5\u4ec5\u662fz\uff0c\u800c\u662f\u4ee5\u968f\u673a\u9ad8\u65af\u53d8\u91cfz\u548c\u6761\u4ef6c\u4e00\u8d77\u4f5c\u4e3a\u8f93\u5165\u7684\u65f6\u5019\uff0cc\u5c31\u662fcondition\u6761\u4ef6\uff0c\u53ef\u4ee5\u662f\u6807\u7b7e\uff0c\u6bd4\u5982\u6211\u4eec\u5f53\u524d\u9884\u6d4b\u624b\u5199\u5b571\u7684\u7167\u7247\uff0c\u5c31\u53ef\u4ee5\u5c061 \u7684 class\u4fe1\u606f\u4f20\u5165\u5230G\u4e4b\u4e2d\uff0c\u8fd9\u65f6\u5019G\u7684\u8f93\u5165\u4e0d\u4ec5\u662fz\u8fd8\u6709\u7c7b\u522b\u6807\u7b7e1\uff0c\u5f53\u505a\u6761\u4ef6c\uff0c\u8fd9\u65f6\u751f\u6210\u5668\u80fd\u66f4\u597d\u7684\u77e5\u9053 \u8981\u751f\u6210\u7684 \u56fe\u7247\u662f 1\uff0c\u4e0d\u662f2\u4e5f\u4e0d\u662f3\uff0c\u53ef\u4ee5\u4f7f\u5f97\u751f\u6210\u5668\u6709\u76ee\u6807\u7684\u751f\u6210\uff0c\u4ee5\u4e0a\u5c31\u662fcGAN\u7684\u70b9</p> <p>\u539f\u59cbGAN\u516c\u5f0f\uff1a</p> <p></p> <p>\u4ee5 \\(x\\) \u6216\u8005 \\(G(z)\\) \u4f5c\u4e3a\u8f93\u5165\uff0c\u4e5f\u5c31\u662f\u539f\u59cbGAN\u4e2d\u4ee5\u7167\u7247\u4f5c\u4e3a\u8f93\u5165</p> <p>\u73b0\u5728\u5f15\u5165\\(y\\)</p> <p></p> <p>\\(y\\)\u8868\u793a \u6761\u4ef6\u4fe1\u606f</p> <p>\u6bd4\u5982\u5728MNIST\u6570\u636e\u96c6\u4e2d\uff0c\\(y\\)\u53ef\u4ee5\u8868\u793a\u6bcf\u5f20\u7167\u7247\u7684\u6807\u7b7e\u4fe1\u606f\uff0c\u6bd4\u5982\u5f53\u524d\u624b\u5199\u6570\u5b57\u7167\u7247\u662f1\u7684\u8bdd\uff0c\u90a3\u8fd9\u4e2a\u6807\u7b7e\u5c31\u7b97\u662f1\uff0c\u5982\u679c\u5f53\u524d\u751f\u6210\u624b\u5199\u6570\u5b57\u7167\u7247\u662f2\u7684\u8bdd\uff0c\u90a3\u4e48\u8fd9\u4e2a\u6807\u7b7e\u5c31\u662f2\uff0c\u4e5f\u5c31\u662f\u628a\\(y\\)\u7684\u4fe1\u606f\uff0c\u4e5f\u4f5c\u4e3a\u751f\u6210\u5668\u7684\u8f93\u5165\uff0c\u6b64\u65f6\u53ef\u4ee5\u66f4\u597d\u5730\u5b66\u4e60\u76ee\u6807\u7167\u7247\u7684\u751f\u6210\uff0c\u56e0\u4e3a\u6211\u4eec\u6307\u5b9a\u5f53\u524d\u751f\u6210\u5668\u751f\u6210\"1\"\u7684\u7167\u7247\uff0c\u4e8e\u662f\u6211\u4eec\u63d0\u4f9b\u6807\u7b7e\u7b49\u4e8e1\uff0c\u8fd9\u4e2a\u4fe1\u606f\uff1b\u5982\u679c\u5f53\u524d\u6307\u5b9a\u751f\u6210\"2\"\u7684\u7167\u7247\uff0c\u6211\u4eec\u5c31\u4f20\u5165 \"y=2\" \u7684\u4fe1\u606f \u4f20\u5165\u7f51\u7edc\uff0c\u4ee5\u4e0a\u5c31\u662fcGAN\u7684\u8bba\u6587 \u63d0\u51fa\u7684\u6539\u8fdb\u70b9\uff0c\u521b\u65b0\u601d\u60f3\u6bd4\u8f83\u7b80\u5355\uff0c\u4f46\u662f\u5e94\u7528\u5374\u5f88\u5e7f\u6cdb</p> <p>\u540e\u9762\u7684\u5e94\u7528\u4e2d\uff0c\u57fa\u672c\u4e0a\u90fd\u662f\u6761\u4ef6GAN\u7684\uff0c\u800c\u4e0d\u662f\u5b8c\u5168\u7684\u4e00\u4e2a\u9ad8\u65af\u53d8\u91cf\u4f5c\u4e3a\u751f\u6210\u5668\u7684\u8f93\u5165\u4fe1\u53f7</p>"},{"location":"learning/9_cGAN/#22","title":"2.2 \u7f51\u7edc\u7ed3\u6784","text":"<p>\u56fe\uff1a</p> <ul> <li>\u4e0a\uff1a\u751f\u6210\u5668</li> <li>\u4e0b\uff1a\u5224\u522b\u5668</li> </ul> <p>\uff081\uff09\u751f\u6210\u5668</p> <p>\u751f\u6210\u5668\u7684\u8f93\u5165\u9664\u6807\u51c6\u7684z\u4ee5\u5916\uff0c\u8fd8\u6709\u7eff\u8272\u90e8\u5206\uff0c\u7eff\u8272\u90e8\u5206\u5c31\u662f\u6761\u4ef6\u4fe1\u606f</p> <p>\u6761\u4ef6\u4fe1\u606f\u53ef\u4ee5\u662f\u8fde\u7eed\u7684\u53d8\u91cf\uff0c\u4e5f\u53ef\u4ee5\u662f\u79bb\u6563\u7684\u53d8\u91cf</p> <p>\u6bd4\u5982\u8bf4 \u624b\u5199\u5b57\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u63d0\u4f9b\u7684\u6761\u4ef6\u4fe1\u606f\u5c31\u662f \u6bcf\u4e00\u6b21 \u624b\u5199\u5b57\u7684\u7167\u7247\uff0c\u91cc\u9762\u6570\u5b57\u7684\u7c7b\u522b\uff0c\u63d0\u4f9b\u7684\u4e00\u4e2aclass\u4fe1\u606f\uff0c\u4e14\u8fd9\u4e2aclass\u4fe1\u606f\u662f\u4e00\u4e2aone hot\u7684\u53d8\u91cf\uff0c\u5982\u679c\u628aone hot\u53d8\u91cf\u76f4\u63a5\u4f20\u5165\u8fdb\u53bb\uff0c\u4f1a\u6bd4\u8f83\u7a00\u758f\uff0c\u6700\u6807\u51c6\u7684\u505a\u6cd5\uff0c\u5c31\u662f\u6309\u7167\u4e4b\u524d\u7684word embedding\u4e00\u6837\uff0c\u628aclass\u4fe1\u606f\u8f6c\u5316\u6210\u4e00\u4e2a class embedding\uff0c\u7136\u540e\u518d\u8ddfz\u62fc\u8d77\u6765\uff0c\u7136\u540e\u518d\u8f93\u5165\u5230\u7f51\u7edc\u4e4b\u4e2d\uff0c\u8fd9\u662f\u6807\u51c6\u7684\u4f5c\u6cd5\u3002\uff08class \\(\\rightarrow\\) class embedding\uff09</p> <p>\uff082\uff09\u5224\u522b\u5668</p> <p>\u7c7b\u4f3c\u7684\uff0c\u5728\u5224\u522b\u5668\u4e4b\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u52a0\u5165\u6761\u4ef6\u4fe1\u606f\uff0c\u600e\u4e48\u7406\u89e3\uff1f</p> <p>\u5224\u522b\u5668\u6bcf\u6b21\u63a5\u6536\u7684\u7167\u7247\uff0c\u7c7b\u522b\u4e0d\u592a\u4e00\u6837\uff0c\u6bd4\u5982\u4e0a\u6b21\u63a5\u6536\u7167\u7247\u7684\u662f\"1\"\uff0c\u5224\u522b\u5668\u6839\u636e\u81ea\u5df1\u7684\u5224\u65ad\uff0c\u5224\u65ad1\u662f\u771f\u7684\u8fd8\u662f\u5047\u7684\uff0c\u7b2c\u4e8c\u6b21\u7ed9\u5224\u522b\u5668\u4e00\u5f20\"2\"\u7684\u7167\u7247\uff0c\u53c8\u53bb\u5224\u65ad2\u662f\u771f\u7684\u8fd8\u662f\u5047\u7684\uff0c\u5982\u679c\u4e0d\u544a\u8bc9\u5224\u522b\u5668\u8fd9\u5f20 \"1\" \u7684\u7167\u7247 \u662f 1\uff0c\"2\" \u7684\u7167\u7247\u662f2\uff0c\u4e24\u5f20\u7167\u7247\u5c5e\u4e8e\u4e0d\u540c\u7c7b\u522b\u7684\u8bdd\uff0c\u5224\u522b\u5668\u53ef\u80fd\u5f88\u96be\u53bb\u5224\u65ad\u3002\u4f46\u662f\u5982\u679c\u544a\u8bc9\u4e86\u5224\u522b\u5668\u4e24\u5f20\u7167\u7247\u662f\u4e0d\u540c\u7c7b\u522b\u7684\u8bdd\uff0c\u544a\u8bc9\u5224\u522b\u5668\u5f53\u524d \u7167\u7247 \u5c5e\u4e8e 1 \u8fd9\u4e2a\u7c7b\u522b\uff0c\u5224\u522b\u5668\u5224\u65ad\u5f53\u524d\u7167\u7247\u662f\u4e0d\u662f\u771f\u7684\u662f1\uff0c\u7b2c\u4e8c\u6b21\u7ed9\u5224\u522b\u5668 2 \u8fd9\u5f20\u7167\u7247\uff0c\u7136\u540e\u5224\u65ad\u5f53\u524d\u7167\u7247\u662f\u4e0d\u662f\u771f\u7684\u662f2\uff0c\u6240\u4ee5\u5728\u5224\u522b\u5668\u5f53\u4e2d \u4e5f\u53ef\u4ee5\u5f15\u5165class\u4fe1\u606f\uff0c\u5f15\u5165\u6761\u4ef6\uff0c\u5728minist\u624b\u5199\u5b57\u4f53\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u5224\u522b\u5668\u7684\u8f93\u5165\u53ef\u4ee5\u901a\u8fc7 one hot\u7684class label\u8f6c\u6362\u6210 class embedding\uff0c\u7136\u540e\u8ddf\u56fe\u50cf\u62fc\u8d77\u6765\uff0c\u6216\u8005\u628aclass embedding\u7ecf\u8fc7\u51e0\u5c42DNN\u518d\u62fc\u8d77\u6765</p> <p>\u4ee5\u4e0a\u662fcGAN\u6838\u5fc3\u7684\u70b9</p>"},{"location":"learning/9_cGAN/#3-gan","title":"3 \u6761\u4ef6GAN \u4ee3\u7801\u5b9e\u73b0","text":"Python<pre><code>import  torch\nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport os\n\nimage_size = [1,28,28]\nlatent_dim = 96\nlabel_emb_dim = 32\nbatch_size = 64\nuse_gpu = torch.cuda.is_available()\nsave_dir = \"cgan_images\"\nos.makedirs(save_dir,exist_ok=True)\n\nclass Generator(nn.Moudle):\n    def __init__(self):\n        super(Generator,self).__init__()\n\n        self.embedding = nn.Embedding(10,label_emb_dim)\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim+label_emb_dim,128),\n            torch.nn.BatchNorm1d(128),\n            torch.nn.GELU(),\n\n            nn.Linear(128,256),\n            torch.nn.BatchNorm1d(256),\n            torch.nn.GELU(),\n            nn.Linear(256,512),\n            torch.nn.BatchNorm1d(512),\n            torch.nn.GELU(),\n            nn.Linear(512,1024),\n            torch.nn.BatchNorm1d(1024),\n            torch.nn.GELU(),\n            nn.Linear(1024,np.prod(image_size,dtype=np.int32)),\n            nn.Sigmoid(),\n        )\n    def forward(self,z,labels):\n        # shape of z:[batchszie,latent_dim]\n        label_embedding = self.embedding(labels)\n        z = torch.cat([z,label_embedding],axis=-1)\n\n        output = self.model(z)\n        image = output.reshape(z.shape[0],*image_size)\n\n        return image\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator,self).__init__()\n\n        self.embedding = nn.Embedding(10,label_emb_dim)\n        self.model = nn.Sequential(\n            nn.Linear(np.prod(image_size,dtype=np.int32)+label_emb_dim,512),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(512,256)),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(256,128)),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(128,64)),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(64,32)),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(32,1)),\n            nn.Sigmoid(),\n        )\n    def forward(self,image,labels):\n        # shape of image:[batchsize,1,28,28]\n\n        label_embedding = self.embedding(labels)\n        prob = self.model(torch.cat([image.reshape(image.shape[0],-1),label_embedding],axis=-1))\n        return prob\n\n\n# Training\ndataset = torchvision.datasets.MNIST(\"mnist_data\", train=True, download=True,\n                                     transform=torchvision.transforms.Compose(\n                                         [\n                                             torchvision.transforms.Resize(28),\n                                             torchvision.transforms.ToTensor(),\n                                             #  torchvision.transforms.Normalize([0.5], [0.5]),\n                                         ]\n                                                                             )\n                                     )\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n\ngenerator = Generator()\ndiscriminator = Discriminator()\n\n\ng_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)\nd_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)\n\nloss_fn = nn.BCELoss()\nlabels_one = torch.ones(batch_size, 1)\nlabels_zero = torch.zeros(batch_size, 1)\n\nif use_gpu:\n    print(\"use gpu for training\")\n    generator = generator.cuda()\n    discriminator = discriminator.cuda()\n    loss_fn = loss_fn.cuda()\n    labels_one = labels_one.to(\"cuda\")\n    labels_zero = labels_zero.to(\"cuda\")\n\nnum_epoch = 200\nfor epoch in range(num_epoch):\n    for i, mini_batch in enumerate(dataloader):\n        gt_images, labels = mini_batch\n\n\n        z = torch.randn(batch_size, latent_dim)\n\n        if use_gpu:\n            gt_images = gt_images.to(\"cuda\")\n            z = z.to(\"cuda\")\n\n        pred_images = generator(z,labels)\n        g_optimizer.zero_grad()\n\n        recons_loss = torch.abs(pred_images-gt_images).mean()\n\n        g_loss = recons_loss*0.05 + loss_fn(discriminator(pred_images,labels), labels_one)\n\n        g_loss.backward()\n        g_optimizer.step()\n\n        d_optimizer.zero_grad()\n\n        real_loss = loss_fn(discriminator(gt_images,labels), labels_one)\n        fake_loss = loss_fn(discriminator(pred_images.detach(),labels), labels_zero)\n        d_loss = (real_loss + fake_loss)\n\n        # \u89c2\u5bdfreal_loss\u4e0efake_loss\uff0c\u540c\u65f6\u4e0b\u964d\u540c\u65f6\u8fbe\u5230\u6700\u5c0f\u503c\uff0c\u5e76\u4e14\u5dee\u4e0d\u591a\u5927\uff0c\u8bf4\u660eD\u5df2\u7ecf\u7a33\u5b9a\u4e86\n\n        d_loss.backward()\n        d_optimizer.step()\n\n        if i % 50 == 0:\n            print(f\"step:{len(dataloader)*epoch+i}, recons_loss:{recons_loss.item()}, g_loss:{g_loss.item()}, d_loss:{d_loss.item()}, real_loss:{real_loss.item()}, fake_loss:{fake_loss.item()}\")\n\n        if i % 800 == 0:\n            image = pred_images[:16].data\n            torchvision.utils.save_image(image, f\"{save_dir}/image_{len(dataloader)*epoch+i}.png\", nrow=4)\n</code></pre>"},{"location":"learning/9_cGAN/#31","title":"3.1 \u751f\u6210\u5668\u4ee3\u7801\u89e3\u8bfb","text":"Python<pre><code>class Generator(nn.Moudle):\n    def __init__(self):\n        super(Generator,self).__init__()\n\n        self.embedding = nn.Embedding(10,label_emb_dim)\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim+label_emb_dim,128),\n            torch.nn.BatchNorm1d(128),\n            torch.nn.GELU(),\n\n            nn.Linear(128,256),\n            torch.nn.BatchNorm1d(256),\n            torch.nn.GELU(),\n            nn.Linear(256,512),\n            torch.nn.BatchNorm1d(512),\n            torch.nn.GELU(),\n            nn.Linear(512,1024),\n            torch.nn.BatchNorm1d(1024),\n            torch.nn.GELU(),\n            nn.Linear(1024,np.prod(image_size,dtype=np.int32)),\n            nn.Sigmoid(),\n        )\n    def forward(self,z,labels):\n        # shape of z:[batchszie,latent_dim]\n        label_embedding = self.embedding(labels)\n        z = torch.cat([z,label_embedding],axis=-1)\n\n        output = self.model(z)\n        image = output.reshape(z.shape[0],*image_size)\n\n        return image\n</code></pre> <p>cGAN\u8fdb\u884c\u624b\u5199\u5b57\u751f\u6210\u4efb\u52a1</p> <ul> <li>\u751f\u6210\u5668\u7684forward\u51fd\u6570\u4e2d\uff0c\u52a0\u5165labels\u4fe1\u606f</li> <li>labels\u8868\u793a\u5e0c\u671b\u751f\u6210\u5668\u8981\u751f\u6210\u6307\u5b9a\u7684\u76ee\u6807\uff0c\u800c\u4e0d\u662f\u968f\u4fbf\u751f\u6210\u7684\uff0c\u6bd4\u5982\u670910\u4e2a\u7c7b\u522b\uff0c0~9\u4e2a\u4e0d\u540c\u7c7b\u522b\u7684\u7167\u7247\uff0c\u901a\u8fc7\u6307\u5b9alabel\uff0c\u6bd4\u5982\u6307\u5b9a1\u5c31\u751f\u62101\u7684\u56fe\u50cf\uff0c\u6307\u5b9a2\u5c31\u751f\u62102\u7684\u7167\u7247\uff0c\u8fd9\u5c31\u662f\u6761\u4ef6\u4fe1\u606f\uff0c\u901a\u8fc7labels\u4f20\u5165\uff0clabels\u5c31\u662f\u79bb\u6563\u7684\u6807\u7b7e\u53d8\u91cf\uff0c\u65e2\u7136\u662f\u79bb\u6563\u7684</li> </ul> Python<pre><code>    def forward(self,z,labels):\n        # shape of z:[batchszie,latent_dim]\n        label_embedding = self.embedding(labels)\n        z = torch.cat([z,label_embedding],axis=-1)\n\n        output = self.model(z)\n        image = output.reshape(z.shape[0],*image_size)\n\n        return image\n</code></pre> <p>\uff081\uff09\u7b2c\u4e00\u6b65\uff0c\u901a\u8fc7embedding table\u628alabel\u4f20\u5165\u5230embedding table\u53bb\u627e\u5230\u5bf9\u5e94\u7684embedding vector\uff0c\u5f97\u5230label embedding\uff0c\u8fd9\u662f\u7b2c\u4e00\u6b65\uff0c\u628a\u79bb\u6563\u7684label \u7c7b\u522b\u4fe1\u606f \u8f6c\u5316\u6210\u8fde\u7eed\u7684 \u6d6e\u70b9\u5411\u91cf\uff0c</p> <p>\uff082\uff09\u7b2c\u4e8c\u6b65\uff0c\u5f97\u5230embedding\u5411\u91cf\u4e4b\u540e\uff0c\u628a\u8fd9\u4e2a\u5411\u91cf\u6700\u7b80\u5355\u7684\u662f\uff0c\u8ddfz\u62fc\u8d77\u6765\uff0c\u5f53\u7136\u8fd9\u4e2a\u6548\u679c\u4e0d\u4e00\u5b9a\u6700\u597d\uff0c\u53ef\u4ee5\u5e38\u8bc6\u4e0d\u540c\u7684\u7279\u5f81\u6784\u9020\u65b9\u6cd5</p> <p>\u4ee5\u4e0a\u6b65\u9aa4\u5f97\u5230\u4e86\u65b0\u7684z\uff0c\u8fd9\u4e2az\u5305\u542b\u4e86\u6761\u4ef6\u4fe1\u606f\u7684\u91cf\uff0c\u8fd9\u65f6\u628az\u7ee7\u7eed\u9001\u5165\u5230\u4e4b\u524d\u7684\u751f\u6210\u5668\u4e3b\u5e72\u7f51\u7edc\u4e2d\uff0c\u7531DNN\u548c\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u6784\u6210\u7684\u4e3b\u5e72\u7f51\u7edc\u4e4b\u4e2d\uff0c\u7684\u90fd\u6700\u540e\u7684image</p> <p>\u4ee5\u4e0a\u5728\u751f\u6210\u5668\u4e4b\u4e2d\uff0c\u5f15\u5165\u4e86 \u6761\u4ef6\u4fe1\u606f\uff0c\u8fd9\u91cc\u7684\u6539\u53d8\uff1a</p> <ul> <li><code>self.embedding = nn.Embedding(10,label_emb_dim)</code>  init\u4e2d \u6dfb\u52a0\u4e86embedding\u7684\u91cf\uff0c\u5b9e\u4f8b\u5316\u662f10\u884c\uff0c\u56e0\u4e3a\u670910\u7c7b\u624b\u5199\u6570\u5b57\uff0c\u7b2c\u4e8c\u7ef4 <code>label_emb_dim</code> \u4e5f\u5c31\u662f <code>label_embedding</code> \u7684\u7ef4\u5ea6\uff0c\u8bbe\u7f6e\u4e3a32\uff0c\u5728forward\u51fd\u6570\u4e2d\uff0c\u9700\u8981\u628a labels \u4f5c\u4e3a\u53c2\u6570\uff0c\u4f5c\u4e3a\u4e00\u90e8\u5206\u8f93\u5165\u4f20\u5165  <code>self.model</code></li> </ul>"},{"location":"learning/9_cGAN/#32","title":"3.2 \u5224\u522b\u5668\u4ee3\u7801\u89e3\u8bfb","text":"Python<pre><code>class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator,self).__init__()\n\n        self.embedding = nn.Embedding(10,label_emb_dim)\n        self.model = nn.Sequential(\n            nn.Linear(np.prod(image_size,dtype=np.int32)+label_emb_dim,512),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(512,256)),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(256,128)),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(128,64)),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(64,32)),\n            torch.nn.GELU(),\n            torch.nn.utils.spectral_norm(nn.Linear(32,1)),\n            nn.Sigmoid(),\n        )\n    def forward(self,image,labels):\n        # shape of image:[batchsize,1,28,28]\n\n        label_embedding = self.embedding(labels)\n        prob = self.model(torch.cat([image.reshape(image.shape[0],-1),label_embedding],axis=-1))\n        return prob\n</code></pre> <ul> <li>\u5224\u522b\u5668\u7684 <code>forward</code> \u51fd\u6570\u4e2d\uff0c\u4e5f\u9700\u8981\u4f20\u5165labels\u544a\u8bc9\u5224\u522b\u5668\u5f53\u524d\u7c7b\u522b\u662f \u7c7b\u522b1 \u8fd8\u662f\u7c7b\u522b2 \uff0c\u5e2e\u52a9\u5224\u522b\u5668\u66f4\u597d\u7684\u505a\u51fa\u5224\u65ad</li> <li>\u4fee\u65391\uff1a\u9996\u5148 <code>def forward(self,image,labels)</code>  forward\u51fd\u6570\u4e2d\u52a0\u5165 labels</li> <li>\u4fee\u65392\uff1a <code>label_embedding = self.embedding(labels)</code> \u79bb\u6563\u53d8\u91cf\u8f6c\u5316\u6210\u8fde\u7eed\u53d8\u91cf\uff0c\u901a\u8fc7embedding table\u5f97\u5230<code>label embedding</code>\u7684\u5411\u91cf</li> <li>\u4fee\u65393\uff1a\u63a5\u7740\u628a <code>label embedding</code>\u7684\u5411\u91cf \uff0c\u8ddf image \u8fdb\u884c\u62fc\u63a5 \uff1a</li> </ul> <p><code>torch.cat([image.reshape(image.shape[0],-1),label_embedding],axis=-1)</code></p> <p>\u8fd9\u662f\u6700\u7b80\u5355\u7684\u5904\u7406\uff0c\u5982\u679c\u6548\u679c\u4e0d\u597d\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u66f4\u6539\uff0c\u501f\u9274\u5176\u4ed6\u7684\u7f51\u7edc\u7684\u505a\u6cd5 \u628a <code>label embedding</code> \u5f15\u5165\u7f51\u7edc\uff0c \u4f5c\u4e3a\u4e3b\u5e72\u7f51\u7edc\u7684\u8f93\u5165\uff0c\u6700\u540e\u5f97\u5230 0~1\u4e4b\u95f4\u7684\u6982\u7387\u503c\uff1a<code>nn.Sigmoid()</code></p>"},{"location":"learning/9_cGAN/#33-train","title":"3.3 train\u51fd\u6570\u7684\u4fee\u6539","text":"<p>\uff081\uff09<code>pred_images = generator(z,labels)</code></p> <p>\u5728\u8bad\u7ec3\u7f51\u7edc\u7684\u65f6\u5019\u9700\u8981\u628a <code>labels</code>\u4e5f\u4f20\u5165\u7f51\u7edc</p> <p><code>labels</code>\u600e\u4e48\u6765\u7684\u5462\uff1f <code>gt_images, labels = mini_batch</code> \u5bf9<code>mini_batch</code>\u89e3\u6790\u51fa\u6765\u7684</p> <p>\uff082\uff09<code>g_loss = recons_loss*0.05 + loss_fn(discriminator(pred_images,labels), labels_one)</code></p> <p>\u628a\u9884\u6d4b\u7684\u7167\u7247\u4f20\u5165\u5230  discriminator \u4e2d\uff0c\u540c\u6837\u4e5f\u9700\u8981\u5e26\u4e0a \u6761\u4ef6\u4fe1\u606flabels</p> <p>\u4e5f\u5c31\u662f\u8bf4\u9700\u8981\u5bf9\u751f\u6210\u5668\u548c\u5224\u522b\u5668\u90fd\u9700\u8981\u52a0\u5165condition\u4fe1\u606f</p> <p>\uff083\uff09\u5728\u8ba1\u7b97 real loss\u548cfake loss\u65f6\uff0c\u90fd\u9700\u8981\u628alabels\u4f20\u5165discriminator\u4e4b\u4e2d</p> Python<pre><code>        real_loss = loss_fn(discriminator(gt_images,labels), labels_one)\n        fake_loss = loss_fn(discriminator(pred_images.detach(),labels), labels_zero)\n</code></pre> <p>\u4ee5\u4e0a\uff0c\u6240\u6709\u6761\u4ef6GAN\u7684\u4ee3\u7801\u5b9e\u73b0</p>"},{"location":"learning/9_cGAN/#4-gan","title":"4 \u6700\u5c0f\u5e73\u65b9GAN","text":"<ul> <li>\u6700\u5c0f\u5e73\u65b9GAN or \u6700\u5c0f\u4e8c\u4e58GAN or LSGAN</li> <li>cGAN\uff1a\u6761\u4ef6GAN</li> <li>LSGAN\uff1a\u6700\u5c0f\u5e73\u65b9GAN</li> <li>\u5f15\u7528\u91cf\uff1a3k\u5de6\u53f3\uff0c\u5f88\u9ad8</li> <li>\u73b0\u5728\u7528\u7684GAN\u5df2\u7ecf\u5f88\u5c11\u662f\u539f\u59cbGAN\uff0c\u4e0d\u7528\u4e8c\u5206\u7c7b\u4ea4\u53c9\u71b5\u7684\u635f\u5931\u51fd\u6570\uff0c\u73b0\u5728\u5f88\u591a\u635f\u5931\u51fd\u6570\u90fd\u662f\u7528\u7684LSGAN\u7684\u635f\u5931\u51fd\u6570\uff0c\u7c7b\u4f3c\u56de\u5f52\u4efb\u52a1\u800c\u4e0d\u662f\u5206\u7c7b\u4efb\u52a1</li> </ul>"},{"location":"learning/9_cGAN/#41","title":"4.1 \u6458\u8981","text":"<ul> <li>\u57fa\u4e8eGAN\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u5927\u83b7\u6210\u529f</li> <li>\u6807\u51c6\u7684GAN\u628a\u5224\u522b\u5668\u5f53\u6210\u5206\u7c7b\u5668\uff0c\u91c7\u7528sigmoid\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u4f46\u662fsigmoid\u635f\u5931\u51fd\u6570\u4f1a\u5bfc\u81f4\u68af\u5ea6\u6d88\u5931\u7684\u95ee\u9898</li> <li>\u4e3a\u4e86\u514b\u670d\u68af\u5ea6\u6d88\u5931\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faLSGAN</li> <li>LSGAN\u91c7\u7528\u6700\u5c0f\u5e73\u65b9\u8bef\u5dee\u51fd\u6570\uff0c\u5bf9\u4e8e\u5224\u522b\u5668\u800c\u8a00\u91c7\u7528\u6700\u5c0f\u5e73\u65b9\u8bef\u5dee\u51fd\u6570</li> <li>\u5f53\u91c7\u7528 \u6700\u5c0f\u5e73\u65b9\u8bef\u5dee\u635f\u5931\u51fd\u6570\u65f6\uff0c\u76f8\u5f53\u4e8e\u4f18\u5316 <code>\u76ae\u5c14\u900a\u5f00\u65b9\u6563\u5ea6</code>  \uff1a $\\mathrm{Pearson    \\mathcal{X}^2   divergence} $ </li> <li>\u5728GAN\u7684\u8bba\u6587\u4e2d\uff0c\u540c\u6837\u4e5f\u662f\u5728\u4f18\u5316\u4e00\u4e2a\u6563\u5ea6\uff1a</li> </ul> <p>\u2460 KL\u6563\u5ea6</p> <p>\u2461 \u8a79\u68ee-\u9999\u519c \u6563\u5ea6</p> <ul> <li>LSGAN\u76f8\u6bd4\u539f\u59cbGAN\u7684\u4e24\u4e2a\u4f18\u70b9\uff1a</li> </ul> <p>\uff081\uff09LSGAN\u53ef\u4ee5\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u56fe\u7247</p> <p>\uff082\uff09LSGAN\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u66f4\u52a0\u7a33\u5b9a</p>"},{"location":"learning/9_cGAN/#42","title":"4.2 \u672c\u6587\u7684\u8d21\u732e","text":"<p>\u672c\u6587\u7684\u4e09\u4e2a\u8d21\u732e\u70b9\uff08\u539f\u6587Intro\u6700\u540e\u4e00\u6bb5\uff09</p> <p>\uff081\uff09</p> <ul> <li> <p>\u63d0\u51fa\u4e86LSGAN\uff0c\u91c7\u7528\u6700\u5c0f\u5e73\u65b9\u7684\u8bef\u5dee\u51fd\u6570\uff0c\u5728\u539f\u59cbGAN\u4e2d\u91c7\u7528\u7684\u4e8c\u5206\u7c7b\u4ea4\u53c9\u71b5\u8bef\u5dee\u51fd\u6570\uff08BCE\u3001\u57fa\u4e8eSigmoid\u3001\u4e8c\u5206\u7c7b\u4ea7\u751f0  ~1\u7684\u6982\u7387\uff09 </p> </li> <li> <p>\u5728\u6700\u5c0f\u5316 LSGAN\u76ee\u6807\u51fd\u6570\u7684\u65f6\u5019\uff0c\u76f8\u5f53\u4e8e\u5728\u6700\u5c0f\u5316 \u76ae\u5c14\u900a\u5f00\u65b9\u6563\u5ea6\uff08\u6709\u63a8\u5bfc\uff09</p> </li> </ul> <p>\uff082\uff09</p> <p>\u7ecf\u8fc7\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u5bf9\u6bd4\uff0cLSGAN\u80fd\u4ea7\u751f\u66f4\u52a0\u903c\u771f\u7684\u7167\u7247</p> <p>\uff083\uff09</p> <p>\u5c06LSGAN\u5e94\u7528\u5230\u4e2d\u6587\u7684\u624b\u5199\u5b57\u751f\u6210\u4e0a\uff0c\u53d1\u73b0LSGAN\u4e5f\u80fd\u4ea7\u751f\u53ef\u61c2\u7684\u4e2d\u6587\u6c49\u5b57</p>"},{"location":"learning/9_cGAN/#43-3-method","title":"4.3 \u539f\u65873 Method","text":"<ul> <li>\u56de\u987eGAN\u7684\u516c\u5f0f</li> <li>\u5c55\u793aLSGAN\u7684\u516c\u5f0f</li> <li>\u4ecb\u7ecd\u4e24\u4e2aLSGAN\u7684\u6a21\u578b</li> </ul>"},{"location":"learning/9_cGAN/#31-gan","title":"3.1 GAN\u7684\u5b66\u4e60\u8fc7\u7a0b","text":"<p>GAN\u7684\u5b66\u4e60\u8fc7\u7a0b\u5b66\u4e60\u4e00\u4e2a \u5224\u522b\u5668\\(D\\)\u548c\u4e00\u4e2a\u751f\u6210\u5668\\(G\\)\uff0c\u8fd9\u4e24\u4e2a\u662f\u540c\u65f6\u8bad\u7ec3\u7684\uff1b</p> <p>\u751f\u6210\u5668G</p> <p>\\(G\\)\u7684\u76ee\u6807\u662f\u5b66\u5230\u6570\u636e\\(x\\)\u7684\u5206\u5e03\\(p_g\\)</p> <p>\\(G\\)\u4ece\u4e00\u4e2a\u5747\u5300\u5206\u5e03 \u6216\u8005 \u9ad8\u65af\u5206\u5e03\u4e2d\uff0c\u91c7\u6837\u4e00\u4e2a\u8f93\u5165\u53d8\u91cf \\(z\\)\uff0c\u88ab\u91c7\u6837\u7684\u5206\u5e03\u8bb0\u4e3a \\(p_z(z)\\)</p> <p>\u901a\u8fc7\u751f\u6210\u5668\\(G\\)\uff0c\u5c06\u8f93\u5165\u53d8\u91cf\\(z\\)\uff0c\u901a\u8fc7\u53ef\u5fae\uff08differentiable netwark\uff09\u7684\u7f51\u7edc \u6620\u5c04\u5230\u4e00\u4e2a\u65b0\u7684\u7a7a\u95f4\u4e0a\uff0c\u8bb0\u4f5c \\(G(z;\\theta_g)\\) \uff0c\u4e5f\u5c31\u662f\u8bf4 \u901a\u8fc7 \\(\u751f\u6210\u5668\u751f\u6210\u7684\u6570\u636e \\sim p_G\\)</p> <p>\u5224\u522b\u5668D</p> <p>\u5224\u522b\u5668D\u662f\u4e00\u4e2a\u5206\u7c7b\u5668</p> <p>\u5224\u522b\u5668D\u7684\u76ee\u6807\u662f\u51c6\u786e\u7684\u8bc6\u522b\u51fa\u4e00\u5f20\u7167\u7247\u662f\u6765\u81ea\u8bad\u7ec3\u96c6\u8fd8\u662f\u6765\u81ea\u751f\u6210\u5668\u6240\u751f\u6210\u7684\u6570\u636e</p> <p>\u6807\u51c6GAN\u7684\u76ee\u6807\u51fd\u6570</p> <p></p> <ul> <li>\u662f\u4e00\u4e2a minmax\u7684\u516c\u5f0f</li> <li>GAN\u9700\u8981\u540c\u65f6\u4f18\u5316\u4e24\u4e2a\u7f51\u7edc\uff1aG&amp;D</li> </ul> <p>\uff081\uff09\u5f53\u4f18\u5316\\(D\\)\u7684\u65f6\u5019\uff0c\u5e0c\u671b\\(V\\)\u8fbe\u5230\u6700\u5927 \\(\\mathrm{max_d}\\)</p> <p>\u7b49\u4ef7\u4e8e\u5f53\\(x\\)\u670d\u4ece\\(p_{data}\\)\u5206\u5e03\u7684\u65f6\u5019\uff0c\\(logD(x)\\)\u8fbe\u5230\u6700\u5927\uff0c\u540c\u65f6\u5f53\\(z\\)\u670d\u4ece\\(p_z\\)\u5206\u5e03\u7684\u65f6\u5019\uff0c\u5e0c\u671b\\(log1-D(G(z))\\)\u4e5f\u8fbe\u5230\u6700\u5927\uff0c\u8fd9\u662f\u5f53\u4f18\u5316\\(D\\)\u7684\u65f6\u5019</p> <p>\uff082\uff09\u5f53\u4f18\u5316\\(G\\)\u7684\u65f6\u5019\uff0c\u662f\u4e00\u4e2a\\(\\mathrm{min_G}\\)\u51fd\u6570\uff0c\u5e0c\u671b\u8fd9\u4e2a\u51fd\u6570\u8fbe\u5230\u6700\u5c0f</p> <p>\u5f53\u4f18\u5316\\(G\\)\u7684\u65f6\u5019\uff0c\u5e0c\u671b\\(V\\)\u8fbe\u5230\u6700\u5c0f\uff0c\u9996\u5148\u5ffd\u7565\u7b2c\u4e00\u9879\uff0c\u56e0\u4e3a\u7b2c\u4e00\u9879\u4e0d\u5305\u542b\\(G\\)\uff0c\u53ea\u770b\u7b2c\u4e8c\u9879\uff0c\u5f53\u4f18\u5316G\u7684\u65f6\u5019\uff0c\u5f53\\(z\\)\u670d\u4ece\\(p_z\\)\u5206\u5e03\u7684\u65f6\u5019\uff0c\u5e0c\u671b \\(log(1-D(G(z)))\\) \u8fbe\u5230\u6700\u5c0f</p> <p>\u4ee5\u4e0a\u662f\u6807\u51c6GAN\uff0cminmax</p> <p>\\(\\mathbb{E}\\) \u8868\u793a\u671f\u671b\u503c\uff0c\u671f\u671b\u503c\u7684\u610f\u601d\u662f\u9700\u8981\u8003\u8651\u5230\u6574\u4e2a\u5206\u5e03\uff0c\u901a\u8fc7\u5c0f\u6279\u6b21\u8bad\u7ec3\u4e0d\u65ad\u903c\u8fd1\u671f\u671b\u503c</p>"},{"location":"learning/9_cGAN/#32-lsgan","title":"3.2 LSGAN","text":"<p>\u68af\u5ea6\u6d88\u5931\u95ee\u9898</p> <ul> <li>\u5f53\u628a\u5224\u522b\u5668\u5f53\u505a\u5206\u7c7b\u5668\u7684\u65f6\u5019\uff0c\u6807\u51c6\u7684GAN\u91c7\u7528\u57fa\u4e8eSigmoid\u7684\u4ea4\u53c9\u71b5\u8bef\u5dee\u51fd\u6570</li> <li>\u5f53\u66f4\u65b0\u751f\u6210\u5668\u7684\u65f6\u5019\uff0c\u6807\u51c6\u7684GAN\u4f1a\u5bfc\u81f4\u68af\u5ea6\u6d88\u5931\u7684\u95ee\u9898\uff0c\u4e3a\u4e86\u5f25\u8865\u8fd9\u4e2a\u95ee\u9898\uff0c\u63d0\u51faLSGAN</li> </ul> <p>\u53ef\u89c6\u5316 \u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff1a</p> <p></p> <p>(a)sigmoid\u7684\u4ea4\u53c9\u71b5\u8bef\u5dee\u51fd\u6570\u56fe\uff0c\u4eceloss\u66f2\u7ebf\u53ef\u4ee5\u770b\u5230\uff0c\u5f53x&gt;2\u65f6\uff0closs\u7684\u659c\u7387\u5f00\u59cb\u63a5\u8fd1\u4e8e0\uff0c\u800c\u4e14\u4e0d\u600e\u4e48\u53d8\u5316\uff0c\u4e5f\u5c31\u662f\u8bf4\u5f53x\u9010\u6e10\u53d8\u5927\u65f6\uff0closs\u63a5\u8fd1\u4e8e\u9971\u548c\uff0c\u68af\u5ea6\u4e00\u76f4\u5904\u57280\u7684\u4f4d\u7f6e\u4e0a\uff0c\u8fd9\u5e76\u4e0d\u5229\u4e8e\u53c2\u6570\u7684\u66f4\u65b0</p> <p>\u6f14\u793a\u8fd9\u4e2a\u56fe\u50cf\u662f\u600e\u4e48\u6765\u7684\uff1a</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nlogits = torch.linspace(-10,10,2000)\nloss = []\nloss_fn = nn.BCELoss()\nfor lgs in logits:\n    loss.append(loss_fn(torch.sigmoid(lgs),torch.ones_like(lgs)))\n\nplt.plot(logits,loss)\nplt.show()\n</code></pre> <p></p> <ul> <li>\u523b\u5ea6\u4e0d\u4e00\u6837\uff0c\u5f62\u72b6\u548c\u539f\u6587\u662f\u4e00\u6837\u7684</li> <li>sigmoid ce\u7684\u56fe\u50cf\uff1a\u8868\u793asigmoid\u4ea4\u53c9\u71b5\u7684\u56fe\u50cf</li> <li>logits\u4ece-10\u53d8\u5316\u523010\uff0closs\u4ece10\u53d8\u5316\u52300\uff0c\u4f46\u662f0\u662f\u5927\u6982\u52302\u7684\u65f6\u5019\uff0c\u5c31\u5df2\u7ecf\u52300\u4e86\uff0c\u5f53logits\u4ece2\u523010\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u8ba4\u4e3a logits\u5c31\u662f\u4e0d\u53d8\u4e86\uff0c\u68af\u5ea6\u5c31\u6d88\u5931\u4e86</li> <li>x\u8f74\u662f \u9884\u6d4b\u6982\u7387 logits\uff0cy\u8f74\u662f\u5bf9\u5e94\u7684loss\uff0c\u628a\u771f\u5b9e\u6807\u7b7e\u8bbe\u7f6e\u4e3a1 \u7684loss</li> </ul> <p>\u2460 <code>logits = torch.linspace(-10,10,2000)</code></p> <p>\u9996\u5148\u968f\u673a\u751f\u6210logits\uff0c\u8fdb\u5165\u5224\u522b\u5668\u4e4b\u524d\uff0c\u751f\u6210\u5668\u9884\u6d4b\u7684\u503c</p> <p>linspace\u751f\u6210-10\u523010\u4e4b\u95f4\uff0c2000\u4e2a\u70b9\u7684logits</p> <p>\u2461 </p> Python<pre><code>loss = []\nloss_fn = nn.BCELoss()\nfor lgs in logits:\n    loss.append(loss_fn(torch.sigmoid(lgs),torch.ones_like(lgs)))\n</code></pre> <p>\u751f\u6210loss\u51fd\u6570\uff0c\u5b9e\u4f8b\u5316loss function\uff0cnn.BCELoss()</p> <p>\u8ba1\u7b97\u6bcf\u4e00\u4e2alogits\uff0c\u5bf9\u5e94\u7684BCELoss\u662f\u4ec0\u4e48</p> <p>\u5bf9logits\u8fdb\u884c\u904d\u5386\u5f97\u5230lgs\uff0c\u628algs\u4f20\u5165\u5230sigmoid\u4e4b\u4e2d\uff0c\u5f97\u5230\u9884\u6d4b\u6982\u7387\u503c</p> <p>\u63a5\u4e0b\u6765\u5c06 \u9884\u6d4b\u6982\u7387\u503c <code>torch.sigmoid(lgs)</code> \u548c\u771f\u5b9e\u503c <code>torch.ones_like(lgs)</code> \u4f20\u5165\u5230 BCELoss\u5b9e\u4f8b\u5316\u7684 <code>loss_fn</code> \u5f97\u5230loss\uff0c\u5c06loss\u6dfb\u52a0\u5230\u5217\u8868\u4e2d\uff0c\u5f97\u5230\u6bcf\u4e00\u4e2algs\u5bf9\u5e94\u7684loss</p> <p>\u2462</p> <p>\u53ef\u89c6\u5316</p> <p>\u4ee5logits\u4f5c\u4e3ax\u8f74\uff0closs\u4f5c\u4e3ay\u8f74 plt.plot(logits,loss)</p> <p>plt.show() \u53ef\u89c6\u5316</p> <p>\u4ee5\u4e0a\u901a\u8fc7\u56fe\u50cf\uff0c\u76f4\u89c2\u5730\u7ed9\u51fa\u4e86\u539f\u59cbGAN\u9047\u5230\u7684\u68af\u5ea6\u6d88\u5931\u7684\u95ee\u9898</p> <p>LSGAN</p> <p></p> <ul> <li>\u4e3a\u4e86\u5f25\u8865\u68af\u5ea6\u6d88\u5931\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86LSGAN</li> <li>\u5047\u8bbe\u7528\u5224\u522b\u5668 a,b\u7684\u7f16\u7801\u65b9\u6848\uff0c\u6765\u4f5c\u4e3a\u771f\u5b9e\u6807\u7b7e\u548c\u865a\u5047\u6807\u7b7e\uff0c\u4e5f\u5c31\u662f\u662f\u8bf4\u628afake data\u7684\u6807\u7b7e\u5b9a\u4e49\u4e3aa\uff0creal data\u7684\u6807\u7b7e\u5b9a\u4e49\u4e3ab\uff0c\u6b64\u65f6\u5f97\u5230LSGAN\u7684\u76ee\u6807\u51fd\u6570\uff1a</li> </ul> <p>\\(\\mathrm{min}_DV_{LSGAN}(D) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}}}[(D(x)-b)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-a)^2]\\)</p> <p>\\(\\min_GV_{LSGAN}(G) = \\frac{1}{2}\\mathbb{E}_{z\\sim{p_z(z)}}[(D(G(z))-c)^2]\\)</p> <p>\uff081\uff09\u4f18\u5316D\uff0c\u5206\u4e3a\u4e24\u6b65\uff0creal loss\uff08\u771f\u5b9e\u6570\u636e\u5bf9\u5e94\u7684loss\uff09\u548cfake loss\uff08\u751f\u6210\u5668\u751f\u6210\u7684\u865a\u5047\u6570\u636e\u5bf9\u5e94\u7684loss\uff09</p> <ul> <li>real loss\u8f93\u5165\u7684\u662fx\uff08\u771f\u5b9e\u6570\u636e\uff09\uff0c\u5e0c\u671b\u6a21\u578b\u9884\u6d4b\u51fa\u6765\u7684\u6807\u7b7e\u662fb</li> </ul> <p>\uff08\u5148\u8bbe\u7f6ea\u3001b\u3001c\u7684\u7b26\u53f7\u8868\u793a\uff0c\u5173\u4e8eabc\u5177\u4f53\u5730\u8bbe\u7f6e\uff0c\u7b49\u4e0b\u4f1a\u8bf4\uff09</p> <ul> <li>\u628a\u751f\u6210\u5668\u7684\u8f93\u51fa G(z) \u8f93\u5165\u5230\u5224\u522b\u5668\u4e2d\uff0c\u5e0c\u671b\u9884\u6d4b\u7684\u6807\u7b7e\u662fa</li> </ul> <p>\u4ee5\u4e0a\u662f\u4f18\u5316\u5224\u522b\u5668</p> <p>\uff082\uff09\u4f18\u5316\u751f\u6210\u5668G\uff0c\u7528\u7684\u6807\u7b7e\u662fc</p> <p>\uff083\uff09</p> <p>\u8fd9\u91cc\u6ca1\u6709log\u51fd\u6570\uff0c\u7528\u7684\u662f\u4ea4\u53c9\u71b5\u51fd\u6570</p> <p>\u628a\u5224\u522b\u5668\u7528\u56de\u5f52\u7684\u503c\u8868\u793a\uff0c\u4f18\u5316\u7684\u662f\u5224\u522b\u5668\u4e0e\u6807\u7b7e\u503c\uff0c\u6240\u4ee5\u53eb\u6700\u5c0f\u5e73\u65b9GAN</p> <p>\u4ece\u6807\u51c6GAN\u8fc7\u6e21\u5230\u6700\u5c0f\u5e73\u65b9GAN\uff0c\u5c31\u662f\u5c06\u539f\u6765\u7684\u4e8c\u5206\u7c7b\u5206\u7c7b\u4efb\u52a1\u8f6c\u5316\u6210\u4e00\u4e2a\u56de\u5f52\u4efb\u52a1\uff0c\u5e76\u4e14\u5224\u522b\u5668\u662f\u8bbe\u7f6e\u7684\u4e0d\u540c\u7684\u56de\u5f52\u6807\u7b7e\uff0c\u4f18\u5316\u7684\u662f\u6700\u5c0f\u5e73\u65b9\u5dee\uff0c\u53eb\u505a\u6700\u5c0f\u5e73\u65b9GAN</p> <p>\u524d\u9762\u6709\u4e00\u4e2a \\(\\frac{1}{2}\\) \u662f\u4e3a\u4e86\u6c42\u5bfc\u4ee5\u540e\uff0c2\u00d7 \\(\\frac{1}{2}\\) \u7ea6\u6389</p> <p>\uff084\uff09\u518d\u6b21\u5f3a\u8c03 LSGAN\u7684\u76ee\u6807\u51fd\u6570</p> <p>\u5728LSGAN\u4e2d\uff0c\u4f18\u5316D\u7684\u76ee\u6807\u51fd\u6570\u662f </p> <p>\\(\\mathrm{min}_DV_{LSGAN}(D) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}}}[(D(x)-b)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-a)^2]\\)</p> <p>\\(\\frac{1}{2}\\) \u7684 \u5f53 \\(x\\)\u670d\u4ece \\(p_{data}\\) \u7684\u5206\u5e03\u7684\u65f6\u5019\uff0c\\(D(x)-b \u7684\u5e73\u65b9\\) \u7684\u671f\u671b \u52a0\u4e0a \\(\\frac{1}{2}\\) \u7684 \u5f53z \u670d\u4ece \\(p_z\\) \u7684\u65f6\u5019\uff0c\\(D(G(z))-a\u7684\u5e73\u65b9\\) \u7684\u671f\u671b </p> <p>\u4f18\u5316\u751f\u6210\u5668G\u7684\u65f6\u5019</p> <p>\\(\\min_GV_{LSGAN}(G) = \\frac{1}{2}\\mathbb{E}_{z\\sim{p_z(z)}}[(D(G(z))-c)^2]\\)</p> <p>\u4f18\u5316\u7684\u662f \\(\\frac{1}{2}\\) \u7684 \u5f53z\u670d\u4ece \\(p_{z(z)}\\) \u5206\u5e03\u7684\u65f6\u5019\uff0c\\(D(G(z)) - c \u5e73\u65b9\\)\u7684\u671f\u671b</p> <p>\u901a\u8fc7 \u4f18\u5316\u4e24\u4e2a\u671f\u671b\uff0c\u6765\u4f18\u5316\u5224\u522b\u5668\u548c\u751f\u6210\u5668</p> <p>\u4ee5\u4e0a\u662fLSGAN\u7684\u5b9a\u4e49</p>"},{"location":"learning/9_cGAN/#33-lsgan","title":"3.3 LSGAN \u7684\u63a8\u5bfc","text":"<p>\u4f18\u5316 LSGAN \u7b49\u4ef7\u4e8e \u4f18\u5316 \u76ae\u5c14\u900a\u5f00\u65b9\u6563\u5ea6</p> <p></p> <ul> <li>\u5728\u539f\u59cbGAN\u4e2d\uff0c\u4f18\u5316 \u4ef7\u503c\u51fd\u6570 \u7b49\u4ef7\u4e8e \u4f18\u5316 \u8a79\u68ee-\u9999\u519c\u6563\u5ea6</li> </ul> <p>LSGAN\uff1a</p> <p></p> <p>\uff081\uff09\u9996\u5148 \u5bf9\u4e8e \\(\\min_G\\)  \u52a0\u4e0a\u4e00\u4e2a   \\(\\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}}}[(D(x)-c)^2]\\)</p> <p>\u5f97\u5230\uff1a</p> <p>\\(\\mathrm{min}_GV_{LSGAN}(G) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}}}[(D(x)-c)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-c)^2]\\)</p> <p>\u56e0\u6b64\u751f\u6210\u5668\u548c\u5224\u522b\u5668\u90fd\u5199\u6210\u4e86\u4e24\u90e8\u5206\uff1a</p> <p>\\(\\mathrm{min}_DV_{LSGAN}(D) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}(x)}}[(D(x)-b)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-a)^2]\\)</p> <p>\\(\\mathrm{min}_GV_{LSGAN}(G) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}(x)}}[(D(x)-c)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-c)^2]\\)</p> <p>\u7b2c\u4e00\u90e8\u5206\uff1a\u5f53 \\(x\\sim p_{data}(x)\\) \u5206\u5e03\uff08real\u771f\u5b9e\u5206\u5e03\uff09\u7684\u65f6\u5019\uff0c\\(D(x)\\)\u8ddf\u6807\u7b7eb\u6216\u8005\u6807\u7b7ec\u7684\u5e73\u65b9\u5dee</p> <p>\u7b2c\u4e8c\u90e8\u5206\uff1a\u5f53 \\(x\\sim p_z(z)\\) \u5206\u5e03\uff08fake\u751f\u6210\u5206\u5e03\uff09\u7684\u65f6\u5019\uff0c\\(D(G(x))\\)\u8ddf\u6807\u7b7ea\u6216\u8005\u6807\u7b7ec\u7684\u5e73\u65b9\u5dee</p> <p>\u539f\u6587\uff1a</p> <p></p> <p>\u4e5f\u63d0\u5230\u4e86\uff0c\u5bf9\u4e8e \\(V_{LSGAN}(G)\\) \u4e2d\u6dfb\u52a0\u4e00\u9879 \\(\\mathbb{E}_{x \\sim p_{data}(x)}[(D(x)-c)^2]\\) \u5e76\u4e0d\u6539\u53d8\u6700\u4f18\u503c\uff0c\u56e0\u4e3a\u6dfb\u52a0\u7684\u4e00\u9879\u5e76\u4e0d\u5305\u542b \u53c2\u6570G</p> <p>\u4f46\u662f\u6dfb\u52a0\u4e00\u9879\uff0c\u4f1a\u65b9\u4fbf\u63a8\u5bfc</p> <p>\u518d\u6b21\u516c\u5f0f\uff1a</p> <p>\\(\\mathrm{min}_DV_{LSGAN}(D) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}(x)}}[(D(x)-b)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-a)^2]\\)</p> <p>\\(\\mathrm{min}_GV_{LSGAN}(G) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}(x)}}[(D(x)-c)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-c)^2]\\)</p> <p></p> <p>\u5f53\u5bf9\u4e8e\u56fa\u5b9a\u7684G\uff0c\u63a8\u5bfc\u51fa\u6700\u4f18\u5224\u522b\u5668D\uff0c\u5177\u4f53\u7684\u63a8\u5bfc\u8fc7\u7a0b\uff0c\u6362\u5143 \u4ee4 \\(x = G(z)\\) \uff1a</p> <p>\\(z \\sim p_{z}(z))  \\rightarrow  x \\sim p_{g}\\)</p> <p>\u56e0\u6b64</p> <p>\\(\\mathrm{min}_DV_{LSGAN}(D) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}(x)}}[(D(x)-b)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-a)^2]\\)</p> <p>\u63a8\u5bfc\u51fa\uff1a</p> <p>\u671f\u671b\u5199\u6210\u79ef\u5206</p> <p>$\\min_DV_{LSGAN}(D) $</p> <p>\\(= \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}(x)}}[(D(x)-b)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-a)^2]\\)</p> <p>$= \\int_x p_{data}(x)(D(x)-b)^2dx + \\int_z p_z(z)(D(G(z))-a)^2dz $</p> <p>$= \\int_x p_{data}(x)(D(x)-b)^2dx +  p_g(x)(D(x)-a)^2dx $</p> <p>\u79ef\u5206\u53f7\u91cc\u9762\uff0c\u5c55\u5f00\uff0c\u662f\u4e00\u4e2a\u4e8c\u6b21\u65b9\u9879\uff0c\u5173\u4e8e\\(D(x)\\)\u7684\u4e00\u5143\u4e8c\u6b21\u65b9\u7a0b\uff1a</p> <p>\\(p_{data} (D^2(x)-2bD(x)+b^2) + p_g((D^2(x)-2aD(x)+a^2))\\)</p> <p>\\(= (p_{data}+p_g)D^2(x)-2(ap_g+bp_{data})D(x)+(b^2p_{data}+a^2p_g)\\)</p> <p>\u6700\u5c0f\u503c \\(D^*(x)=-\\frac{b}{2a}=-\\frac{-2(ap_g+bp_{data})}{2(p_{data}+p_g)}=\\frac{ap_g+bp_{data}}{p_{data}+p_g}=\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}\\) </p> <p>\u4e5f\u5c31\u662f \u56fa\u5b9a\u751f\u6210\u5668\uff0c\u5f97\u5230\u6700\u4f18\u7684\u5224\u522b\u5668\uff1a</p> <p>\\(D^*(x)= \\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}\\)</p> <p>\uff08\u4ee5\u4e0a\u63a8\u5bfc \u6a21\u4eff\u539f\u59cbGAN\uff1a</p> <p></p> <p>\uff09</p> <p>\u63a5\u4e0b\u6765\uff0c</p> <p></p> <p>\u7528 \\(p_d\\) \u8868\u793a \\(p_{data}\\)</p> <p>\u7136\u540e\u628a \u516c\u5f0f4 \u7684 \\(V_{LSGAN}(G)\\) \u5199\u6210\uff1a</p> <p></p> <p>\u4e0a\u9762 \u6211\u4eec\u4f18\u5316\u5b8c\u4e86 \u5224\u522b\u5668\uff0c\u5904\u7406\u7684\u662f\u7b2c\u4e00\u4e2a\u5f0f\u5b50\uff1a</p> <p>\\(\\mathrm{min}_DV_{LSGAN}(D) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}(x)}}[(D(x)-b)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-a)^2]\\)</p> <p>\u63a5\u4e0b\u6765 \u4f18\u5316\u751f\u6210\u5668\uff0c\u7b2c\u4e8c\u4e2a\u5f0f\u5b50\uff1a</p> <p>\\(\\mathrm{min}_GV_{LSGAN}(G) = \\frac{1}{2}\\mathbb{E}_{x\\sim {p_{data}(x)}}[(D(x)-c)^2] + \\frac{1}{2}\\mathbb{E}_{z\\sim {p_z(z)}}[(D(G(z))-c)^2]\\)</p> <p>\uff081\uff09\u9996\u5148\uff0c\u6309\u7167\u8bba\u6587\u6240\u8bf4\uff0c\\(p_{data}\\) \u5199\u6210 \\(p_d\\)</p> <p>\u8fd8\u6709\u51e0\u70b9\u6ce8\u610f\uff1a</p> <ul> <li>\\(V_{LSGAN}\\) \u6539\u5199\u6210 \\(C(G)\\)  \u8868\u793a \u4ee3\u4ef7 \u662f\u4e00\u4e2a\u610f\u601d</li> <li>\u7b49\u5f0f\u5de6\u53f3\u4e24\u8fb9\u540c\u65f6\\(\u00d72\\)</li> <li>\\(D(x)\\) \u5168\u90e8\u66ff\u6362\u4e3a \\(D^*(x)\\)</li> </ul> <p>\\(\u2234\\)</p> <p>\\(2C(G) = \\mathbb{E}_{x \\sim p_d}[(D^*(x)-c)^2]+\\mathbb{E}_{x \\sim p_z}(D^*(G(z))-c)^2\\)</p> <p>\\(z\\)\u6362\u5143\u6210 \\(G(z)\\)</p> <p>\\(x\u670d\u4ecep_z\\) \u6362\u5143\u6210 \\(x\u670d\u4ecep_g\\) </p> <p>\\(= \\mathbb{E}_{x \\sim p_d}[(D^*(x)-c)^2]+\\mathbb{E}_{x \\sim p_g}(D^*(x)-c)^2\\)</p> <p>\u63a5\u4e0b\u6765 \u4ee3\u5165 \\(D^*(x)=\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}\\)</p> <p>\\(= \\mathbb{E}_{x \\sim p_d}[(\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}-c)^2]+\\mathbb{E}_{x \\sim p_g}(\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}-c)^2\\)</p> <p>\u63a5\u4e0b\u6765 \u5c06 \u671f\u671b\u6539\u5199\u6210\u79ef\u5206\u7684\u5f62\u5f0f\uff1a</p> <p>\\(= \\int_x(\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}-c)^2 p_d(x)dx+\\int_x(\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}-c)^2p_g(x)dx\\)</p> <p>c\u901a\u9879 \u5408\u5e76  \u4ee5 \\(p_g\\) \\(p_{data}\\) \u4e3a\u57fa\u51c6(\\(p_{data}\\)\u548c\\(p_d\\) \u662f\u4e00\u4e2a\u4e1c\u897f\uff0c\u4e0d\u540c\u8bb0\u53f7\uff0c\u540e\u9762\u5c31\u7edf\u4e00)</p> <p>\\(= \\int_x(\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}-c)^2 p_d(x)dx+\\int_x(\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}-c)^2p_g(x)dx\\)</p> <p>\\(= \\int_x(\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}-c\\frac{p_g(x)+p_{data}(x)}{p_{data}(x)+p_g(x)})^2 p_d(x)+(\\frac{ap_g(x)+bp_{data}(x)}{p_{data}(x)+p_g(x)}-c\\frac{p_g(x)+p_{data}(x)}{p_{data}(x)+p_g(x)})^2p_g(x)dx\\)</p> <p>\\(= \\int_x p_d (\\frac{(a-c)p_g+(b-c)p_d}{p_{d}+p_g})^2+p_g(\\frac{(a-c)p_g+(b-c)p_d}{p_d+p_g})^2dx\\)</p> <p>\u5e73\u65b9\u9879 \u76f8\u7b49\uff0c\u5408\u5e76 \uff0c\u540c\u65f6\u548c\u5206\u6bcd\u6d88\u53bb\u4e00\u4e2a \\((p_d + p_g)\\)</p> <p>\\(=\\int_x  \\frac{((a-c)p_g + (b-c)p_d)^2}{p_d+p_g} dx\\)</p> <p>\u5206\u6bcd\u662f\u4e00\u6b21\u9879\uff0c\u5206\u5b50\u662f\u4e8c\u6b21\u9879\uff0c\u5bf9\u5206\u5b50\u5e73\u65b9\u91cc\u9762\u505a\u53d8\u6362\uff0c\u5bf9\\(p_g\\) \u505a \\(-b+b\\) \u7684\u64cd\u4f5c\uff1a</p> <p>\\(=\\int_x  \\frac{((a-b+b-c)p_g + (b-c)p_d)^2}{p_d+p_g} dx\\)</p> <p>\\(=\\int_x  \\frac{((b-c)(p_d+p_g)-(b-a)p_g)^2}{p_d+p_g} dx\\)</p> <p>\u5199\u6210 \u8fd9\u4e2a\u5f62\u5f0f\u4ee5\u540e\uff0c\u4ee4 \\(b-c=1\uff0cb-a=2\\)\uff0c\u521a\u597d\u662f\u76ae\u5c14\u900a\u5f00\u65b9\u6563\u5ea6\u7684\u516c\u5f0f\uff1a</p> <p>\\(2C(G) = \\int_x \\frac{((p_d+p_g)-2p_g)^2}{p_d+p_g}dx\\)</p> <p>\u5e73\u65b9\u91cc\u9762\uff0c\u6539\u53d8 \u9879\u7684\u6b21\u5e8f\uff1a</p> <p>\\(2C(G) = \\int_x \\frac{(2p_g-(p_d+p_g))^2}{p_d+p_g}dx\\)</p> <p>\\(=\\mathcal{X}^2_{Pearson}(p_d+p_g||2p_g)\\)</p> <p></p> <p>\u8868\u793a \\(2p_g\\) \u4e0e \\(p_d + p_g\\) \u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684 \u76ae\u5c14\u900a\u5f00\u65b9\u6563\u5ea6\u516c\u5f0f\uff0c\u4e5f\u5c31\u662f\u8bf4 \u5f53\u6211\u4eec\u5728\u4f18\u5316 \u516c\u5f0f</p> <p></p> <p>\u5f53\u6211\u4eec\u5728\u4f18\u5316\u516c\u5f0f(4)\u7684\u65f6\u5019\uff0c\u76f8\u5f53\u4e8e\u5728\u4f18\u5316\u516c\u5f0f(7)\uff1a\\(2p_g\\) \u548c \\(p_d + p_g\\)\u4e24\u4e2a\u5206\u5e03\u7684 \u76ae\u5c14\u900a\u5f00\u65b9\u6563\u5ea6</p> <p>\u9700\u8981\u6ee1\u8db3\u7684\u6761\u4ef6</p> <p></p> <ul> <li>b-c=1\uff08\u6807\u7b7eb \u51cf\u53bb \u6807\u7b7ec \u7684\u503c=1\uff09</li> <li>b-a=1\uff08\u6807\u7b7eb \u51cf\u53bb \u6807\u7b7ea\u7684\u503c=2\uff09</li> </ul> <p>\u6563\u5ea6 \u4e00\u822c \u5927\u4e8e\u7b49\u4e8e 0\uff0c\u4e5f\u5c31\u662f \\(p_g + p_d =2p_g\\) \u6563\u5ea6\u8fbe\u5230\u6700\u5c0f\uff0c\u7b49\u4ef7\u4e8e \\(p_g = p_d\\) \uff0c\u4e5f\u5c31\u662f\\(\u751f\u6210\u5668\u7684\u6570\u636e\u5206\u5e03=\u8bad\u7ec3\u96c6\u771f\u5b9e\u7684\u6570\u636e\u5206\u5e03\\)\uff0c\u4e5f\u5c31\u662f\u6b64\u65f6 \u751f\u6210\u5668G \u8fbe\u5230\u6700\u4f18</p>"},{"location":"learning/9_cGAN/#34","title":"3.4 \u5b9e\u9645\u7684\u53c2\u6570\u8bbe\u7f6e","text":"<ul> <li>\u786e\u5b9a \u65b9\u7a0b2 \u4e2da\u3001b\u3001c\u4e09\u4e2a\u503c\uff0c\u9700\u8981\u6ee1\u8db3\u6761\u4ef6 \\(b-c=1\\)\uff0c\u5e76\u4e14 \\(b-a=2\\) \uff0c\u6b64\u65f6 \u76f8\u5f53\u4e8e\u4f18\u5316 \\(2p_g\\) \u548c \\(p_d+p_g\\)  \u4e24\u4e2a\u5206\u5e03 \u7684\u76ae\u5c14\u900a\u5f00\u65b9\u6563\u5ea6</li> </ul> <ul> <li>\u6bd4\u5982\u8bbe\u7f6e \\(a=-1\u3001b=1\u3001c=0\\)\uff0c\u6b64\u65f6\u76ee\u6807\u51fd\u6570 \u5199\u6210 \u516c\u5f0f8\u7684\u5f62\u5f0f</li> </ul> <p>\u6b64\u65f6 \u76f8\u5f53\u4e8e\u4f18\u5316\u76ae\u5c14\u900a\u5f00\u65b9\u6563\u5ea6</p> <ul> <li>\u53e6\u5916\u4e00\u79cd\u65b9\u5f0f</li> </ul> <p></p> <p>\u8ba9\u751f\u6210\u5668\u5c3d\u53ef\u80fd\u8ddf\u771f\u5b9e\u6837\u672c\u4e00\u6837\uff0c\u4e5f\u5c31\u662f\u4ee4\\(c=b\\)</p> <p>\u5982\u516c\u5f0f9\u6240\u793a\uff0c\u91c7\u752801\u7f16\u7801\uff1a</p> <p>\uff081\uff09\u4f18\u5316\u751f\u6210\u5668\u7684\u65f6\u5019\uff0c\u4ee4\\(\u771f\u5b9e\u503c=1\\) \u7b49\u4ef7\u4e8e D(x)=1\uff0c\u628aD(G(z))\u4e5f\u5c3d\u53ef\u80fd\u63a5\u8fd1\u771f\u5b9e\u6837\u672c\uff0c\u6240\u4ee5\u6807\u7b7e\u4e5f\u7b49\u4e8e1\uff1b</p> <p>\uff082\uff09\u540c\u65f6\u5728 \u4f18\u5316\u5224\u522b\u5668\u7684\u65f6\u5019\uff0c\u4ee4\\(D(G(Z))=0\u3001D(x)=1\\)</p> <p>\u4ee5\u4e0a \u516c\u5f0f\uff088 \uff09\u548c\u516c\u5f0f\uff089\uff09\uff0c\u90fd\u662fLSGAN\u76ee\u6807\u51fd\u6570\u7684\u5199\u6cd5\uff1a</p> <p></p> <p>\u867d\u7136\u516c\u5f0f\uff088\uff09\u548c\u516c\u5f0f\uff089\uff09\u5b9e\u9a8c\u6548\u679c\u662f\u76f8\u4f3c\u7684\uff0c\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u516c\u5f0f\uff089\uff09\u7684\u5199\u6cd5\u66f4\u5e38\u89c1\uff0c\u5728\u539f\u672c\u7684\u5b9e\u9a8c\u4e2d\uff0c\u4e5f\u662f\u4f7f\u7528\u7684\u516c\u5f0f\uff089\uff09\u8bad\u7ec3\u6a21\u578b</p> <p>\u4ee5\u4e0a\u662fLSGAN\u7684\u539f\u7406</p>"},{"location":"learning/9_cGAN/#5-gan","title":"5 \u6700\u5c0f\u5e73\u65b9GAN\u4ee3\u7801\u5b9e\u73b0","text":"<p>\u4ee3\u7801\u4fee\u6539\uff1a</p> <p>\u539f\u59cbGAN\u7528\u7684BCELoss\uff0cLSGAN\u628aBCELoss\u6539\u4e86\uff0c\u7528MSELoss\uff0c\u5177\u4f53\u5230\u516c\u5f0f\uff089\uff09\uff0c\u5c31\u662f\u9047\u5230\u771f\u5b9e\u6837\u672c\u7528\u6807\u7b7e1\uff0c\u9047\u5230\u751f\u6210\u5668\u751f\u6210\u7684\u6837\u672c\uff0c\u5224\u522b\u5668\u4f18\u5316\\(D(G(z))\\)\u7684\u76ee\u6807\u662f0</p> <p>ls_cgan_minist.py</p> <p>\u5728cgan\u7684\u57fa\u7840\u4e0a\u8fdb\u884c\u4fee\u6539\uff0c\u53ea\u9700\u8981\u4fee\u6539\u635f\u5931\u51fd\u6570\u5373\u53ef</p> Python<pre><code>\"\"\" \u57fa\u4e8eMNIST \u5b9e\u73b0\u5bf9\u6297\u751f\u6210\u7f51\u7edc (GAN) \"\"\"\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport numpy as np\n\nimage_size = [1, 28, 28]\nlatent_dim = 96\nbatch_size = 64\nuse_gpu = torch.cuda.is_available()\n\nclass Generator(nn.Module):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, 128),\n            torch.nn.BatchNorm1d(128),\n            torch.nn.GELU(),\n\n            nn.Linear(128, 256),\n            torch.nn.BatchNorm1d(256),\n            torch.nn.GELU(),\n            nn.Linear(256, 512),\n            torch.nn.BatchNorm1d(512),\n            torch.nn.GELU(),\n            nn.Linear(512, 1024),\n            torch.nn.BatchNorm1d(1024),\n            torch.nn.GELU(),\n            nn.Linear(1024, np.prod(image_size, dtype=np.int32)),\n            #  nn.Tanh(),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, z):\n        # shape of z: [batchsize, latent_dim]\n\n        output = self.model(z)\n        image = output.reshape(z.shape[0], *image_size)\n\n        return image\n\n\nclass Discriminator(nn.Module):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.model = nn.Sequential(\n            nn.Linear(np.prod(image_size, dtype=np.int32), 512),\n            torch.nn.GELU(),\n            nn.Linear(512, 256),\n            torch.nn.GELU(),\n            nn.Linear(256, 128),\n            torch.nn.GELU(),\n            nn.Linear(128, 64),\n            torch.nn.GELU(),\n            nn.Linear(64, 32),\n            torch.nn.GELU(),\n            nn.Linear(32, 1),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, image):\n        # shape of image: [batchsize, 1, 28, 28]\n\n        prob = self.model(image.reshape(image.shape[0], -1))\n\n        return prob\n\n# Training\ndataset = torchvision.datasets.MNIST(\"mnist_data\", train=True, download=True,\n                                     transform=torchvision.transforms.Compose(\n                                         [\n                                             torchvision.transforms.Resize(28),\n                                             torchvision.transforms.ToTensor(),\n                                             #  torchvision.transforms.Normalize([0.5], [0.5]),\n                                         ]\n                                                                             )\n                                     )\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n\ngenerator = Generator()\ndiscriminator = Discriminator()\n\n\ng_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)\nd_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)\n\n# loss_fn = nn.BCELoss()\nloss_fn = nn.MSELoss()\n\nlabels_one = torch.ones(batch_size, 1)\nlabels_zero = torch.zeros(batch_size, 1)\n\nif use_gpu:\n    print(\"use gpu for training\")\n    generator = generator.cuda()\n    discriminator = discriminator.cuda()\n    loss_fn = loss_fn.cuda()\n    labels_one = labels_one.to(\"cuda\")\n    labels_zero = labels_zero.to(\"cuda\")\n\nnum_epoch = 200\nfor epoch in range(num_epoch):\n    for i, mini_batch in enumerate(dataloader):\n        gt_images, _ = mini_batch\n\n\n        z = torch.randn(batch_size, latent_dim)\n\n        if use_gpu:\n            gt_images = gt_images.to(\"cuda\")\n            z = z.to(\"cuda\")\n\n        pred_images = generator(z)\n        g_optimizer.zero_grad()\n\n        recons_loss = torch.abs(pred_images-gt_images).mean()\n\n        g_loss = recons_loss*0.05 + loss_fn(discriminator(pred_images), labels_one)\n\n        g_loss.backward()\n        g_optimizer.step()\n\n        d_optimizer.zero_grad()\n\n        real_loss = loss_fn(discriminator(gt_images), labels_one)\n        fake_loss = loss_fn(discriminator(pred_images.detach()), labels_zero)\n        d_loss = (real_loss + fake_loss)\n\n        # \u89c2\u5bdfreal_loss\u4e0efake_loss\uff0c\u540c\u65f6\u4e0b\u964d\u540c\u65f6\u8fbe\u5230\u6700\u5c0f\u503c\uff0c\u5e76\u4e14\u5dee\u4e0d\u591a\u5927\uff0c\u8bf4\u660eD\u5df2\u7ecf\u7a33\u5b9a\u4e86\n\n        d_loss.backward()\n        d_optimizer.step()\n\n        if i % 50 == 0:\n            print(f\"step:{len(dataloader)*epoch+i}, recons_loss:{recons_loss.item()}, g_loss:{g_loss.item()}, d_loss:{d_loss.item()}, real_loss:{real_loss.item()}, fake_loss:{fake_loss.item()}\")\n\n        if i % 400 == 0:\n            image = pred_images[:16].data\n            torchvision.utils.save_image(image, f\"image_{len(dataloader)*epoch+i}.png\", nrow=4)\n</code></pre> <p>\u76f4\u63a5\u770bloss function\uff0c\u7531BCELoss\u6362\u6210MSELoss()</p> <p></p> <ul> <li>loss function\u4eceBCELoss\u4fee\u6539\u6210MSELoss</li> <li>\u5177\u4f53\u5230\u4f18\u5316\u751f\u6210\u5668\u7684\u65f6\u5019\uff0c\u4f20\u5165\u7684\u4e5f\u662f labels_one</li> </ul> <p></p> <p>\u53ea\u4e0d\u8fc7\u662f\u628a\u4ece\u524d\u7684\u5206\u7c7b\u4efb\u52a1\u53d8\u6210\u4e86\u56de\u5f52\u4efb\u52a1</p> <ul> <li>\u540c\u6837\u5728\u8ba1\u7b97\u5224\u522b\u5668\u7684 real loss\u548cfake loss\u7684\u65f6\u5019\uff0c</li> </ul> <p></p> <p>\u5728\u8ba1\u7b97 real loss\u7684\u65f6\u5019\uff0c\u4e5f\u662f\u4f20\u5165\u51681 \u7684 \u6d6e\u70b9\u578b</p> <p>\u5728\u8ba1\u7b97fake loss\u7684\u65f6\u5019\uff0c\u4f20\u5165\u7684\u662f\u51680\u7684\u6d6e\u70b9\u578b</p> <p>\u4e5f\u5c31\u662f\u628a\u4ece\u524d\u7684\u4e24\u4e2a\u5206\u7c7bloss BCELoss\uff0c\u6539\u6210\u4e24\u4e2a \u5e73\u65b9\u5dee\u7684 \u56de\u5f52loss</p>"},{"location":"learning/convs/","title":"\u5377\u79ef","text":""},{"location":"learning/convs/#_1","title":"\u5377\u79ef","text":"2024-11-25 22:33:462025-09-28 12:54:04 <p> \u7ea6 7091 \u4e2a\u5b57  579 \u884c\u4ee3\u7801  22 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 43 \u5206\u949f</p> <ul> <li> \u8f6c\u7f6e\u5377\u79ef\u3001\u53cd\u5377\u79ef</li> <li> \u5206\u7ec4\u5377\u79ef\u3001\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef</li> <li> 1\u00d71\u5377\u79ef\u3001\u9010\u70b9\u5377\u79ef</li> <li> \u81a8\u80c0\u5377\u79ef\u3001\u7a7a\u6d1e\u5377\u79ef\u5377\u79ef</li> <li> \u53ef\u53d8\u5f62\u5377\u79ef</li> <li> \u5927\u6838\u5377\u79ef</li> <li> 1D \u5377\u79ef</li> </ul> <p></p>"},{"location":"learning/convs/#1","title":"1 \u5e93\u51fd\u6570\u5b9e\u73b0\u5377\u79ef","text":"<ul> <li>\u7c7b\uff1a<code>torch.nn.Conv2d</code></li> <li>\u51fd\u6570\uff1a<code>F.conv2d</code>  or <code>torch.nn.functional.conv2d</code></li> </ul> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nin_channels = 1\nout_channels = 1\nkernel_size = 3\nbatch_size = 1\nbias = False\n\ninput_size = [batch_size,in_channels,4,4]\n\n# \u7b2c\u4e00\u79cd\u5b9e\u73b0\nconv_layer = torch.nn.Conv2d(in_channels,out_channels,kernel_size,bias=bias)\n\ninput_feature_map = torch.randn(input_size)\nout_feature_map = conv_layer(input_feature_map)\n# print(input_feature_map)\n# print(conv_layer.weight)  # 1*1*3*3=out_channels*in_channels*height*width\n\nprint(out_feature_map)\n\nout_feature_map1 = F.conv2d(input_feature_map,conv_layer.weight)\n\nprint(out_feature_map1)\n</code></pre>"},{"location":"learning/convs/#api","title":"\u9996\u5148\u770b\u4e00\u4e0b \u4e8c\u7ef4\u5377\u79ef\u7684api","text":"<p>\u8c37\u6b4c\u641c\u7d22 pytorch conv2d\uff0c\u51fa\u73b0\u4e24\u4e2aapi \uff1a</p> <ul> <li>\u4e00\u4e2a\u662f\u5927\u5199\u7684\u4e8c\u7ef4\u5377\u79ef\u3001 class</li> <li>\u4e00\u4e2a\u662f torch.nn.functional.conv2d\u5c0f\u5199\u7684\u4e8c\u7ef4\u5377\u79ef\u3001\u51fd\u6570</li> </ul> <p>\u533a\u522b\uff1a</p> <ul> <li> <p>\uff08\u7b2c\u4e00\u4e2a\u533a\u522b\uff09</p> </li> <li> <p>\u7b2c\u4e00\u4e2a\u5927\u5199\u7684\u662f\u4e00\u4e2aclass\uff0c\u5982\u679c\u6211\u4eec\u8981\u7528\u7b2c\u4e00\u4e2a\u7684\u8bdd\uff0c\u6211\u4eec\u9996\u5148\u9700\u8981\u5bf9\u8fd9\u4e2aclass\u8fdb\u884c\u4e00\u4e2a\u5b9e\u4f8b\u5316\uff0c\u7136\u540e\u5bf9\u5b9e\u4f8b\u5316\u7684\u5bf9\u8c61\uff0c\u518d\u5bf9\u8f93\u5165\u7279\u5f81\u56fe\u8fdb\u884c\u4e00\u4e2a\u5377\u79ef \u64cd\u4f5c\uff1b  </p> </li> <li> <p>\u7b2c\u4e8c\u4e2a\u662f\u4e00\u4e2a\u51fd\u6570\uff0c\u4e0d\u9700\u8981\u5b9e\u4f8b\u5316\uff0c\u5c31\u76f4\u63a5\u63a5\u6536\u4e00\u4e2a\u8f93\u5165\u7279\u5f81\u56fe\uff0c\u76f4\u63a5\u8fdb\u884c\u4e00\u4e2a\u5377\u79ef\u64cd\u4f5c\uff1b\u4ee5\u4e0a\u662f\u7b2c\u4e00\u4e2a\u533a\u522b\uff1b </p> </li> <li> <p>\uff08\u7b2c\u4e8c\u4e2a\u533a\u522b\uff09</p> </li> <li>class\u53ef\u4ee5\u81ea\u5df1\u53bb\u521b\u5efa\u64cd\u4f5c\uff0c\u5305\u62ecweight\u548cbias\uff0c\u53ef\u4ee5\u81ea\u52a8\u53bb\u521b\u5efa\uff0c\u5c31\u4e0d\u9700\u8981\u624b\u52a8\u521b\u5efa\uff1b</li> <li>\u5bf9\u4e8e\u51fd\u6570\u6765\u8bf4\uff0c \u9700\u8981\u624b\u52a8\u7684\u4f20\u5165weight\u548cbias\uff1b</li> </ul>"},{"location":"learning/convs/#conv2d","title":"CONV2D","text":"<ul> <li>\u8c03\u7528\uff1atorch.nn.Conv2d</li> <li>\u9700\u8981\u4f20\u5165\u7684\u53c2\u6570\uff1a</li> <li>\u8f93\u5165\u901a\u9053</li> <li>\u8f93\u51fa\u901a\u9053</li> <li>kernel\u7684\u5927\u5c0f</li> <li>\u6b65\u957f</li> <li>padding\u586b\u5145</li> <li>\u81a8\u80c0dilation</li> <li> <p>group</p> </li> <li> <p>\u533a\u5206 \u5377\u79ef &amp; \u5168\u8fde\u63a5\uff1a</p> </li> </ul> <p>\u795e\u7ecf\u7f51\u7edc\u6700\u6838\u5fc3\u7684\u4e00\u4e2a\u64cd\u4f5c\uff1a\u4eff\u5c04\u53d8\u6362\uff1a\u5c06\u4e00\u4e2a\u77e9\u9635 \u4e58\u4ee5 \u8f93\u5165\u5411\u91cf \u5f97\u5230 \u53e6\u5916\u4e00\u4e2a\u5411\u91cf\u3002\u8fd9\u662f\u5168\u8fde\u63a5\u7f51\u7edc\u7684\u4e00\u4e2a\u505a\u6cd5\uff0c \u6240\u4ee5\u6211\u4eec\u4e00\u822c\u4f1a\u5bf9\u4e00\u4e2a\u5411\u91cf \u505a\u5168\u8fde\u63a5\u7684\u7f51\u7edc \u7684\u8f93\u5165\uff1b\u6bd4\u65b9\u8bf4\uff1a\u4e00\u4e2aword embedding\u5411\u91cf\uff1b\u6bd4\u65b9\u8bf4 \u8981\u9884\u6d4b\u623f\u4ef7\uff0c\u57ce\u5e02\u7684\u4eba\u53e3\u8fd8\u6709\u7269\u4ef7\u7b49\uff0c\u4e0d\u540c\u7684\u6d6e\u70b9\u6570 \u7ec4\u6210\u7684\u5411\u91cf\uff0c\u8fd9\u4e9b\u90fd\u53ef\u4ee5\u9001\u5165 \u5168\u8fde\u63a5\u7f51\u7edc\u3002</p> <p>\u6240\u4ee5\u5168\u8fde\u63a5\u7f51\u7edc \u662f\u628a \u8f93\u5165\u5f53\u6210\u4e00\u4e2a\u5411\u91cf\uff0c\u7136\u540e\u7edf\u4e00\u7684\u53bb\u4e58 \u4e00\u4e2a\u77e9\u9635\uff0c\u8fdb\u884c\u64cd\u4f5c\u3002\u4f46\u662f\uff0c\u8fd8\u6709\u5f88\u591a\u5176\u4ed6\u4e1c\u897f\uff0c\u4e0d\u80fd\u4ec5\u4ec5\u4f7f\u7528\u4e00\u4e2a\u5411\u91cf\u6765\u8fdb\u884c\u523b\u753b\uff0c\u6bd4\u5982\u56fe\u50cf\u6709\u957f\u5ea6\u548c\u5bbd\u5ea6\uff0c\u662f\u4e00\u4e2a\u4e8c\u7ef4\u7684\uff0c\u8fd8\u6709RGB\u4e09\u4e2a\u901a\u9053\uff0c\u8fd9\u4e9b \u6211\u4eec\u4e0d\u80fd\u4ec5\u4ec5\u53ea\u662f\u628a\u56fe\u7247\u62c9\u76f4\u5904\u7406\uff0c\u8fd9\u6837\u7834\u574f\u4e86\u56fe\u7247\u7684\u7a7a\u95f4\u7ed3\u6784\uff1b</p> <p>\u7c7b\u4f3c\u7684\u8fd8\u6709\u8bed\u97f3\uff0c\u8bed\u8a00\u6709\u65f6\u95f4\u7ef4\u8fd8\u6709\u9891\u7387\u7ef4\uff0c\u6211\u4eec\u6bcf\u4e2a\u65f6\u523b\u53d1\u51fa\u7684\u58f0\u97f3\uff0c \u662f\u7531\u4e0d\u540c\u7684\u9891\u7387\u7ec4\u5408\u7684\uff0c\u540c\u6837\u5bf9\u4e8e\u8bed\u97f3\u8fd9\u79cd\u4fe1\u53f7\uff0c\u6211\u4eec\u4e5f\u4e0d\u80fd\u4ec5\u4ec5\u662f \u5f53\u6210 \u4e00\u7ef4\u4fe1\u53f7\u5904\u7406\uff0c\u751a\u81f3\u66f4\u590d\u6742\u7684\u662f \u56fe\u50cf\u548c\u8bed\u97f3\u4fe1\u53f7\u7684\u7ed3\u5408\uff0c\u6bd4\u5982\u89c6\u9891\u3002\u6240\u4ee5\u5bf9\u4e8e\u8fd9\u4e9b\u6211\u4eec\u4e0d\u80fd\u4ec5\u4ec5\u53ea\u662f\u5f53\u6210\u4e00\u4e2a\u5411\u91cf\u5904\u7406\uff0c\u8fd9\u6837\u7684\u8bdd\uff0c\u5168\u8fde\u63a5\u7f51\u7edc\u4e5f\u5c31\u65e0\u6cd5\u523b\u753b\u5b83\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u5377\u79ef\u7f51\u7edc\u523b\u753b\uff0c\u5bf9\u4e8e\u5377\u79ef\u7f51\u7edc \u548c \u54ea\u4e9b\u64cd\u4f5c \u6bd4\u8f83\u76f8\u5173\u5462\uff1f\u5c31\u662f\u4e92\u76f8\u5173\uff0c\u5982\u679c\u5b66\u8fc7\u4fe1\u53f7\u4e0e\u7cfb\u7edf\u7684\u8bdd\uff0c\u4e92\u76f8\u5173\u5c31\u662f \u5bf9\u4e8e\u4e24\u4e2a\u4e00\u7ef4\u5411\u91cf\uff0c\u6211\u4eec\u628a\u4e00\u4e2a\u4e00\u7ef4\u4fe1\u53f7 \u6cbf\u7740 \u53e6\u5916\u4e00\u4e2a\u4e00\u7ef4\u4fe1\u53f7\uff0c\u4e0d\u65ad\u5730\u8fdb\u884c \u6ed1\u52a8\u76f8\u4e58\u7684\u64cd\u4f5c\uff0c\u7136\u540e\u8ba1\u7b97 \u4e00\u4e2a\u76f8\u5173\u7cfb\u6570\u3002\u5377\u79ef\u4e5f\u662f\u7c7b\u4f3c\u7684\uff0c\u5bf9\u4e8e\u4e00\u5f20\u56fe\u7247\uff0c\u5982\u679c\u6211\u4eec\u6709\u4e00\u4e2a\u5377\u79ef\u6838\u7684\u8bdd\uff0c\u53eb\u505akernel\uff0c\u6211\u4eec\u4f1a\u628a kernel \u6cbf\u7740 \u56fe\u7247\u7684\u4e0d\u540c\u533a\u57df \u8fdb\u884c\u4e00\u4e2a\u6ed1\u52a8\u76f8\u4e58\uff0c\u6765\u5f97\u5230\u4e00\u4e2a\u7279\u5f81\u7684\u8868\u793a</p> <ul> <li>\u6570\u5b66\u4f8b\u5b50\uff1a</li> </ul> <p></p> <ul> <li>\u5047\u8bbe\u6211\u4eec\u7684input feature map=4\u00d74\uff0ckernel=3\u00d73\uff0c\u5377\u79ef\u64cd\u4f5c\u5c31\u662f\u5c06kernel\u5728\u56fe\u7247\u4e0a \u4e0d\u540c\u4f4d\u7f6e\u5143\u7d20\u76f8\u4e58 element-wise\uff0c\u4e0d\u540c\u4f4d\u7f6e\u5143\u7d20\u76f8\u4e58\u518d\u76f8\u52a0\uff0c\u5f97\u5230\u8f93\u51fa\uff1b</li> <li>k=3\uff0cp=0\uff0cs=1</li> <li>kernel\u7684\u79fb\u52a8\u8f68\u8ff9\u662fZ\u5b57\u578b\u7684\uff0c\u4ece\u5de6\u5230\u53f3\uff0c\u4ece\u4e0a\u5230\u4e0b</li> <li>\u8f93\u5165input future map\u7684\u5927\u5c0f\u662f4\u00d74\u7684\uff0c\u800c\u4e14 channel=1\uff0c\u518d\u7528\u4e00\u4e2a3\u00d73\u7684kernel\uff0c\u4e0e\u8f93\u5165\u7279\u5f81\u56fe \u8fdb\u884c\u5377\u79ef\u64cd\u4f5c\uff0c\u5f97\u5230output\uff0c\u5e76\u4e14output\u5927\u5c0f 2\u00d72\uff0cchannel=1\uff0c\u540c\u65f6\u8fd9\u91cc\u6211\u4eec\u8bbe\u7f6e\u7684bias=False\uff0c\u4e0d\u52a0 bias\uff1b</li> <li>\u5982\u679c\u6211\u4eec\u52a0\u5165 bias\u5462\uff1f</li> <li>\u5982\u679c channel=1\uff0c\u90a3\u4e48 bias\u5c31\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u76f4\u63a5\u76f8\u52a0\u5c31\u597d\u4e86\uff0c\u8fd9\u5c31\u662f\u4e00\u4e2a bias\u7684\u64cd\u4f5c</li> <li>\u5982\u679c \u8f93\u5165\u7684\u901a\u9053\u6570\u4e0d\u6b62\u662f1\u5462\uff1f\u6bd4\u5982\u4e24\u4e2a\u901a\u9053\uff0c\u8fd9\u4e2a\u65f6\u5019 \u5c31\u4f1a\u6709\u4e24\u4e2akernel\uff0c\u7b2c\u4e00\u4e2akernel\u5f97\u5230y1 y2 y3 y4\uff1b\u7b2c\u4e8c\u4e2akernel\u53c8\u4f1a\u5f97\u5230\u4e00\u4e2ay1\uff0cy2,y3,y4,\u7136\u540e\u6211\u4eec\u518d\u628a\u4e24\u4e2akernel\u5f97\u5230\u7684\u8f93\u51fa \u518d\u8fdb\u884c\u4e00\u4e2a\u70b9\u5bf9\u70b9\u7684\u8f93\u51fa\uff0c\u8fd9\u6837\u5f97\u5230 \u6700\u7ec8\u7684output\uff0c\u8fd9\u662f\u5bf9\u8f93\u5165\u7279\u5f81\u56fe\u6709\u591a\u4e2a\u901a\u9053\u7684\u60c5\u51b5\u3002\uff08\u6362\u4e00\u79cd\u8bf4\u6cd5\uff1a\u8f93\u5165\u901a\u9053\u7684channel\u6709\u51e0\u4e2a\uff0ckernel\u7684channel\u5c31\u6709\u51e0\u4e2a\uff09</li> <li>\u90a3\u5982\u679c\u6211\u4eec \u8f93\u51fa \u7279\u5f81\u56fe \u4e5f\u6709\u591a\u4e2a\u901a\u9053\u7684\u60c5\u51b5 \u4f1a\u600e\u4e48\u5904\u7406\u5462\uff1f \u521a\u521a \u6211\u4eec\u5f97\u5230\u4e86\u7b2c\u4e00\u4e2a\u901a\u9053\uff0c\u5bf9\u4e8e\u7b2c\u4e8c\u4e2a\u901a\u9053\uff0c\u6211\u4eec\u540c\u6837 \u5728\u53e6\u5916\u521b\u9020 \u4e0d\u540c\u7684kernel\uff0c\u5bf9\u8f93\u5165\u8fdb\u884c\u4e00\u4e2a\u5377\u79ef\u64cd\u4f5c\uff0c\u6700\u540e\u628a \u8f93\u5165\u7684\u901a\u9053 \u52a0\u8d77\u6765\uff0c\u53d8\u6210 \u8f93\u51fa \u901a\u9053\u7684\u7b2c\u4e8c\u4e2a\u8f93\u51fa\uff08\u8fd8\u662f\u7406\u89e3\u4e3a\uff1a\u6709\u51e0\u4e2akernel\u5c31\u6709\u51e0\u4e2a\u8f93\u51fa\uff1bkernel\u7684\u901a\u9053\u6570\u7531\u8f93\u5165\u7684\u901a\u9053\u6570\u51b3\u5b9a\uff09</li> </ul> <p>\u4ee5\u4e0a\u662f\u6240\u6709 \u5377\u79ef\u7684\u8fc7\u7a0b\uff1a</p> <ul> <li>\u6709\u51e0\u4e2a\u5377\u79ef\u6838 \u5c31\u6709\u51e0\u4e2a \u8f93\u51fa\u901a\u9053\uff1b</li> <li> <p>\u5355\u4e2a\u5377\u79ef\u6838\u7684\u901a\u9053\u6570 \u53d6\u51b3\u4e8e \u8f93\u5165\u7279\u5f81\u56fe\u7684\u901a\u9053\u6570</p> </li> <li> <p>\u6211\u4eec\u5c06 3\u00d73\u7684kernel\uff0c\u5728\u8f93\u5165\u7684\u7279\u5f81\u56fe\u4e0a \u8fdb\u884c\u4e00\u4e2aZ\u5b57\u578b\u7684\u6ed1\u52a8\u76f8\u4e58\u7684\u64cd\u4f5c</p> </li> <li>==\uff08\u62c9\u76f4\u6ed1\u52a8\u8f93\u5165\u533a\u57df\uff09==\u5176\u5b9e\u8fd9\u91cc\u7684\u6ed1\u52a8\u76f8\u4e58 \u53ef\u4ee5\u7406\u89e3\u4e3a \u5982\u679c\u628a\u8f93\u5165\u7684\u7279\u5f81\u56fe\uff08\u88ab\u5377\u79ef\u6838\u8986\u76d6\u7684\u533a\u57df\uff093\u00d73\u7684\u533a\u57df \u62c9\u6210\u4e00\u4e2a\u5411\u91cf\u7684\u8bdd \u7136\u540e\u6211\u4eec\u628akernel\u4e5f\u62c9\u6210\u4e00\u4e2a\u5411\u91cf\uff0c\u5176\u5b9e\u5c31\u662f\u8ba1\u7b97 \u4e24\u4e2a\u5411\u91cf\u7684 \u4e00\u4e2a\u5185\u79ef\u3002\u5185\u79ef\u8d8a\u5927 \u4e24\u4e2a\u5411\u91cf \u8d8a\u76f8\u4f3c\u3002</li> <li>\u6240\u4ee5\u5377\u79ef\u7f51\u7edc \u5b66\u4e60\u7684\u662f\u4ec0\u4e48\u5462\uff1f\u5377\u79ef\u7f51\u7edc \u4f1a \u4e0d\u65ad\u7684\u66f4\u65b0 kernel\u548c bias\u3002\u5c31\u662f\u4e3a\u4e86\u5b66\u5230\uff1a</li> <li>\u6bd4\u65b9\u8bf4 \u4eba\u8138\u8bc6\u522b\uff0c\u5c31\u5e0c\u671bkernel\u80fd\u591f\u5b66\u5230 \u80fd\u591f\u53cd\u6620\u4eba\u8138\u7684 \u7279\u5f81\uff0c\u7136\u540e\u628akernel\u5bf9\u56fe\u7247\u7684\u4e0d\u540c\u533a\u57df\uff0c\u8fdb\u884c\u6bd4\u5bf9\uff0c\u5982\u679c\u521a\u597d\u53d1\u73b0\uff0c\u56fe\u7247\u7684\u67d0\u4e00\u4e2a\u533a\u57df\u521a\u597d\u4e0e\u4eba\u8138\u7684kernel\u5f88\u76f8\u4f3c\u7684\u8bdd\uff0c\u90a3\u5c31\u8bf4\u660e\u4f60\u7ed9\u6211\u4eec\u5df2\u7ecf\u627e\u5230\u4eba\u8138\u4e86\uff0c\u603b\u4e4b\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u662f \u7ed9\u5b9a\u4e00\u4e2a\u76ee\u6807 \u4e0d\u65ad\u7684\u5b66\u4e60kernel\uff0c\u6700\u7ec8\u5e0c\u671bkernel\uff0c\u80fd\u591f\u8ddf\u56fe\u7247\u7684\u67d0\u4e00\u4e2a\u533a\u57df\uff0c\u76f8\u4f3c\u5ea6\u8fbe\u5230\u4e00\u4e2a\u6bd4\u8f83\u9ad8\u7684\u503c\uff0c\u5f97\u5230\u4e00\u4e2a\u6bd4\u8f83\u597d\u7684\u7279\u5f81\uff0c\u7136\u540e\u518d\u4e0d\u65ad\u7684\u5f80 \u6df1\u5c42\u53bb\u4f20</li> </ul> <p>\u4f7f\u7528api\u7684\u65f6\u5019\uff0c\u9700\u8981\u6ce8\u610f\ud83d\udce2</p> <ul> <li> <p>Conv2d\u9ed8\u8ba4\u8f93\u5165\u662f4\u7ef4\u7684\uff0c\u7b2c\u4e00\u7ef4\u662fbatch size\u7ef4\uff0c\u6211\u4eec\u8bbe\u7f6ebatch size=1\uff0c\u5e76\u6dfb\u52a0\u5230input_size\u5373\u53ef;</p> </li> <li> <p>input feature map\u7684\u5f62\u72b6\uff1abatch size \u00d7 \u901a\u9053\u6570 \u00d7 \u9ad8 \u00d7 \u5bbd \u53ef\u4ee5\u67e5\u770b\u5b98\u7f51 \u627e\u5230\u9700\u8981\u7684\u8f93\u5165\u5f62\u72b6</p> </li> </ul> <p></p> <ul> <li>\u5e76\u4e14\u6253\u5370 \u5377\u79ef\u5c42\u7684 weight\uff0c\u4e5f\u5c31\u662fkernel\uff0c\u8fd8\u53ef\u4ee5\u6253\u5370\u8f93\u5165\u548c\u8f93\u51fa</li> </ul> <p></p> <ul> <li> <p>\u8f93\u51fa\u4e09\u4e2a\u5f20\u91cf \u7b2c\u4e00\u4e2a\u662f \u8f93\u5165\u7279\u5f81\u56fe\u3001\u7b2c\u4e8c\u4e2a\u662f\u5377\u79ef\u7684weight\u3001\u6216\u8005kernel\uff0c\u7b2c\u4e09\u4e2a\u662f \u5377\u79ef\u7684\u8f93\u51fa</p> </li> <li> <p>\u8f93\u51fa\u7684\u5927\u5c0f\u662f 1\u00d71\u00d74\u7684\uff1b</p> </li> <li> <p>kernel\u662f1\u00d71\u00d73\u00d73 \u6743\u91cd\u5c31\u662fout channel\u00d7 input channel\u00d7height\u00d7width</p> </li> </ul> <p>\u4e5f\u5c31\u662f\u8bf4 \u5bf9\u4e8e \u4e8c\u7ef4\u5377\u79ef\uff0cweight\u662f4\u7ef4\u7684\uff0c\u90a3\u4e48\u603b\u7684\u6570\u76ee \u7b49\u4e8e \u8f93\u51fa\u901a\u9053\u6570\u00d7\u8f93\u5165\u901a\u9053\u6570\u00d7\u5377\u79ef\u6838\u7684\u9ad8\u5ea6\u00d7\u5377\u79ef\u6838\u7684\u5bbd\u5ea6\uff0c\u5982\u679c\u6211\u4eec\u8ba4\u4e3a \u5377\u79ef\u6838\u662f\u4e00\u4e2a\u4e8c\u7ef4\u7684\u56fe\u7247\u7684\u8bdd\uff0c\u90a3\u4e48\u4e00\u5171\u6709 \u8f93\u5165\u901a\u9053\u6570 \u00d7 \u8f93\u51fa\u901a\u9053\u6570 \u8fd9\u4e48\u591a\u4e2a  \u5377\u79ef\u6838\u56fe\u7247</p> <ul> <li> <p>torch.nn.Conv2d(class \u7684api)</p> </li> <li> <p>functional\u7684api(\u51fd\u6570\u7684api)</p> </li> </ul> <p></p> <p>\u5bf9\u4e8e\u8fd9\u4e2aapi \u6211\u4eec\u9700\u8981\u624b\u52a8\u7684\u6307\u5b9a weight \u548c bias\uff0c\u4e3a\u4e86\u9a8c\u8bc1\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u628a\u521a\u521a\u7684weight\u4f20\u5165\uff0c\u53ef\u4ee5\u770b\u5230 \u7ed3\u679c\u662f\u4e00\u6837\u7684:</p> Python<pre><code>output_feature_map1 = F.conv2d(input_feature_map,conv_layer.weight)\n</code></pre> <ul> <li>kernel\u5c31\u662f\u5728\u8bad\u7ec3\u4e2d\uff0c\u4e0d\u65ad\u66f4\u65b0\u7684</li> </ul>"},{"location":"learning/convs/#2","title":"2 \u624b\u6495\u666e\u901a\u5377\u79ef","text":"<p>\u4ece\u4e24\u79cd\u89d2\u5ea6\u770b\u5377\u79ef\uff1a</p> <ul> <li>\u628a\u5377\u79ef\u770b\u6210\u662f \u9996\u5148\u5bf9\u8f93\u5165\u7279\u5f81\u56fe\u8fdb\u884c\u5c55\u5f00\uff0c\u7136\u540e\u518d\u8fdb\u884c\u77e9\u9635\u7684\u76f8\u4e58\uff1b</li> <li>\u5bf9kernel\u6216\u8005filter\u8fdb\u884c\u5c55\u5f00\uff0c\u7136\u540e\u518d\u8fdb\u884c\u77e9\u9635\u76f8\u4e58\uff1b</li> </ul> <ul> <li>\u6709\u4e86\u8fd9\u79cd\u65b9\u6cd5 \u53ef\u4ee5\u987a\u5176\u81ea\u7136\u7684\u5f15\u51fa \u8f6c\u7f6e\u5377\u79ef\uff1b\u4e4b\u540e\u4f1a\u8bb2 \u8f6c\u7f6e\u5377\u79ef \u4e5f\u79f0\u4e3a\u53cd\u5377\u79ef\uff0c\u4f46\u662f\u53cd\u5377\u79ef\u7684\u8bf4\u6cd5\u4e0d\u592a\u51c6\u786e\uff0c\u56e0\u4e3a \u8f6c\u7f6e\u5377\u79ef\u867d\u7136\u8bf4\u662f\u4e0a\u91c7\u6837\uff0c\u4f46\u662f\u4e0d\u80fd\u4eceoutput\u53bb\u6062\u590dinput\uff0c\u8f6c\u7f6e\u5377\u79ef \u6062\u590d\u7684\u53ea\u662f input\u7684\u5f62\u72b6\uff0c\u4e0d\u662finput\u7684\u5143\u7d20\u503c</li> <li>\u66f4\u51c6\u786e\u7684\u5b9a\u4e49 \u5c31\u662f\u8f6c\u7f6e\u5377\u79ef\uff1b\u4e3a\u4ec0\u4e48\u53eb\u8f6c\u7f6e\u5377\u79ef\u5462\uff1f\u518d\u8bf4\u5b8c \u5bf9kernel \u8fdb\u884c\u5c55\u5f00\uff0c\u518d\u8fdb\u884c\u77e9\u9635\u76f8\u4e58 \u5c31\u660e\u767d\u4e86</li> <li>\u5f53\u6211\u4eec\u628a\u5e38\u89c4\u7684\u5377\u79ef \u770b\u6210\u662f\u5bf9kernel\u7684\u5c55\u5f00\uff0c\u7136\u540e\u518d\u77e9\u9635\u76f8\u4e58\u7684\u8bdd\uff0c\u90a3\u4e48\u8f6c\u7f6e\u5377\u79ef\u53ef\u4ee5\u770b\u6210 \u5c06kernel\u8fdb\u884c\u4e00\u4e2a \u8f6c\u7f6e\u64cd\u4f5c\uff0c\u7136\u540e\u518d\u8fdb\u884c\u77e9\u9635\u76f8\u4e58\uff0c\u5c31\u80fd\u5f97\u5230\u8f6c\u7f6e\u5377\u79ef\u7684\u8f93\u51fa</li> </ul> Python<pre><code>input = torch.randn(5,5) # \u5377\u79ef \u8f93\u5165\u7279\u5f81\u56fe\nkernel = torch.randn(3,3) # \u5377\u79ef\u6838\nbias = torch.randn(1) # \u5377\u79ef\u504f\u7f6e\uff0c\u9ed8\u8ba4\u8f93\u51fa\u901a\u9053\u6570\u76ee\u7b49\u4e8e1\n\n# step1 \u7528\u539f\u59cb\u7684\u77e9\u9635\u8fd0\u7b97\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5148\u4e0d\u8003\u8651 batch size\u7ef4\u5ea6 \u548c channel\u7ef4\u5ea6\ndef matrix_multiplication_for_conv2d(input,kernel,bias=0,stride=1,padding=0):\n\n  if padding &gt;0:\n    input = F.pad(input,(padding,padding,padding,padding))\n\n\n  input_h,input_w = input.shape\n  kernel_h,kernel_w = kernel.shape\n\n  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u9ad8\u5ea6\n  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u5bbd\u5ea6 \n  output = torch.zeros(output_h,output_w) # \u521d\u59cb\u5316 \u8f93\u51fa\u77e9\u9635\n\n  for i in range(0,input_h - kernel_h + 1,stride): # \u5bf9\u9ad8\u5ea6\u8fdb\u884c\u904d\u5386\n    for j in range(0,input_w - kernel_w +1,stride):  # \u5bf9\u5bbd\u5ea6\u7ef4\u8fdb\u884c\u904d\u5386\n      region = input[i:i+kernel_h, j:j+kernel_w]  # \u53d6\u51fa\u88ab\u6838\u6ed1\u52a8\u5230\u7684\u533a\u57df\n      output[int(i/stride),int(j/stride)] = torch.sum(region * kernel) + bias # \u70b9\u4e58 \u5e76\u8d4b\u503c\u7ed9\u8f93\u51fa\u4f4d\u7f6e\u7684\u5143\u7d20 \n\n  return output\n\n\n# step2 \u7528\u539f\u59cb\u7684\u77e9\u9635\u8fd0\u7b97\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5148\u4e0d\u8003\u8651 batch size\u7ef4\u5ea6 \u548c channel\u7ef4\u5ea6\uff0cflatten\u7248\u672c\ndef matrix_multiplication_for_conv2d_flatten(input,kernel,bias=0,stride=1,padding=0):\n\n  if padding &gt;0:\n    input = F.pad(input,(padding,padding,padding,padding))\n\n\n  input_h,input_w = input.shape\n  kernel_h,kernel_w = kernel.shape\n\n  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u9ad8\u5ea6\n  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u5bbd\u5ea6 \n  output = torch.zeros(output_h,output_w) # \u521d\u59cb\u5316 \u8f93\u51fa\u77e9\u9635\n\n  region_matrix = torch.zeros(output.numel(),kernel.numel()) #\u5b58\u50a8\u7740\u6240\u6709\u62c9\u5e73\u540e\u7279\u5f81\u533a\u57df\n  kernel_matrix = kernel.reshape(kernel.numel(),1) # \u5b58\u50a8\u7740kernel\u7684 \u5217\u5411\u91cf\uff08\u77e9\u9635\uff09\u5f62\u5f0f\n  row_index = 0\n\n  for i in range(0,input_h - kernel_h + 1,stride): # \u5bf9\u9ad8\u5ea6\u8fdb\u884c\u904d\u5386\n    for j in range(0,input_w - kernel_w +1,stride):  # \u5bf9\u5bbd\u5ea6\u7ef4\u8fdb\u884c\u904d\u5386\n      region = input[i:i+kernel_h, j:j+kernel_w]  # \u53d6\u51fa\u88ab\u6838\u6ed1\u52a8\u5230\u7684\u533a\u57df\n      region_vector = torch.flatten(region)\n      region_matrix[row_index] = region_vector\n      row_index +=1\n\n  output_matrix = region_matrix @ kernel_matrix\n  output = output_matrix.reshape((output_h,output_w))+bias\n\n  return output\n\n\n# \u77e9\u9635\u8fd0\u7b97\u5b9e\u73b0\u5377\u79ef\u7684\u7ed3\u679c\nmat_mul_conv_output = matrix_multiplication_for_conv2d(input,kernel,bias = bias,stride=2,padding=1)\n# print(mat_mul_conv_output)\n\n# \u8c03\u7528pytorch api\u5377\u79ef\u7684\u7ed3\u679c\npytorch_api_conv_output = F.conv2d(input.reshape((1,1,input.shape[0],input.shape[1])),\n                                   kernel.reshape((1,1,kernel.shape[0],kernel.shape[1])),\n                                   padding=1,bias=bias,stride=2).squeeze(0).squeeze(0)\n\n# \u77e9\u9635\u8fd0\u7b97\u5b9e\u73b0\u5377\u79ef\u7684\u7ed3\u679c flatten input\u7248\u672c\nmat_mul_conv_output_flatten = matrix_multiplication_for_conv2d_flatten(input,kernel,bias = bias,stride=2,padding=1)\n# \u9a8c\u8bc1\u4e86 flatten\u7248\u672c\u5377\u79ef \u4e0e pytorch \u5b98\u65b9\u5377\u79ef\u7684\u7ed3\u679c\uff0c\u6b63\u786e\nflag1 = torch.allclose(mat_mul_conv_output,pytorch_api_conv_output)\nflag2 = torch.allclose(mat_mul_conv_output_flatten,pytorch_api_conv_output)\nprint(flag1)\nprint(flag2)\n</code></pre> Python<pre><code># step3 \u7528\u539f\u59cb\u7684\u77e9\u9635\u8fd0\u7b97\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u8003\u8651 batch size\u7ef4\u5ea6 \u548c channel\u7ef4\u5ea6\ndef matrix_multiplication_for_conv2d_full(input,kernel,bias=0,stride=1,padding=0):\n\n  # input kernel \u90fd\u662f4\u7ef4\u5f20\u91cf\n  if padding &gt;0:\n    input = F.pad(input,(padding,padding,padding,padding,0,0,0,0))\n\n  bs,in_channel,input_h,input_w = input.shape\n  out_channel,in_channel,kernel_h,kernel_w = kernel.shape\n\n  if bias is None:\n    bias = torch.zeros(out_channel)\n\n\n  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u9ad8\u5ea6\n  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u5bbd\u5ea6 \n  output = torch.zeros(bs,out_channel,output_h,output_w) # \u521d\u59cb\u5316 \u8f93\u51fa\u77e9\u9635\n\n\n  for ind in range(bs):\n    for oc in range(out_channel):\n      for ic in range(in_channel):\n        for i in range(0,input_h - kernel_h + 1,stride): # \u5bf9\u9ad8\u5ea6\u8fdb\u884c\u904d\u5386\n          for j in range(0,input_w - kernel_w +1,stride):  # \u5bf9\u5bbd\u5ea6\u7ef4\u8fdb\u884c\u904d\u5386\n            region = input[ind,ic,i:i+kernel_h, j:j+kernel_w]  # \u53d6\u51fa\u88ab\u6838\u6ed1\u52a8\u5230\u7684\u533a\u57df\n            output[ind,oc,int(i/stride),int(j/stride)] += torch.sum(region * kernel[oc,ic]) # \u70b9\u4e58 \u5e76\u8d4b\u503c\u7ed9\u8f93\u51fa\u4f4d\u7f6e\u7684\u5143\u7d20 \n      output[ind,oc] += bias[oc]\n  return output\n\ninput = torch.randn(2,2,5,5)  # bs*in_channel*in_h*in_w\nkernel = torch.randn(3,2,3,3) # out_channel*in_channel*kernel_h*kernel_w\nbias = torch.randn(3)\n\n# \u9a8c\u8bc1matrxi_multiplication_for_conv2d_full\u4e0e\u5b98\u65b9API\u7ed3\u679c\u662f\u5426\u4e00\u81f4\npytorch_api_conv_output = F.conv2d(input,kernel,bias=bias,padding=1,stride=2)\nmm_conv2d_full_output = matrix_multiplication_for_conv2d_full(input,kernel,bias=bias,padding=1,stride=2)\nflag = torch.allclose(pytorch_api_conv_output,mm_conv2d_full_output)\nprint(\"all close:\",flag)\n</code></pre>"},{"location":"learning/convs/#3","title":"3 \u8f6c\u7f6e\u5377\u79ef","text":"<p>\u4ee3\u7801\u5b9e\u73b0\uff1a</p> Python<pre><code># step4 \u901a\u8fc7\u5bf9kernel\u8fdb\u884c\u5c55\u5f00\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5e76\u63a8\u5bfc\u51fa\u8f6c\u7f6e\u5377\u79ef\uff0c\u4e0d\u8003\u8651batch\u3001channel\u5927\u5c0f\uff0c\u4e0d\u8003\u8651padding\uff0c\u5047\u8bbestride=1\ndef get_kernel_matrix(kernel,input_size):\n    # \u57fa\u4e8ekernel\u548c\u8f93\u5165\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u6765\u5f97\u5230\u586b\u5145\u62c9\u76f4\u540e\u7684kernel\u5806\u53e0\u540e\u7684\u77e9\u9635\n    kernel_h,kernel_w = kernel.shape\n    input_h,input_w = input.shape\n    num_out_fea_map = (input_h-kernel_h+1)*(input_w-kernel_w+1)  # \u5377\u79ef\u516c\u5f0f\n    result = torch.zeros((num_out_fea_map,input_h*input_w)) #\u521d\u59cb\u5316\u7ed3\u679c\u77e9\u9635\uff0c\u8f93\u51fa\u7279\u5f81\u56fe\u5143\u7d20\u4e2a\u6570*\u8f93\u5165\u7279\u5f81\u56fe\u5143\u7d20\u4e2a\u6570\n    count = 0\n    for i in range(0,input_h-kernel_h+1,1):\n        for j in range(0,input_w - kernel_w +1,1):\n            # \u586b\u5145\u6210 \u8ddf \u8f93\u5165\u7279\u5f81\u56fe\u4e00\u6837\u5927\u5c0f\n            # padded_kernel = F.pad(kernel,(i,input_h-kernel_h-i,j,input_w-kernel_w-j))\n            padded_kernel = F.pad(kernel,(j,input_h-kernel_h-j,i,input_w-kernel_w-i))\n            result[count] = padded_kernel.flatten()\n            count +=1\n    return result  \n\n\n\n# \u6d4b\u8bd51\uff1a\u9a8c\u8bc1 \u4e8c\u7ef4\u5377\u79ef\nkernel = torch.randn(3,3)\ninput = torch.randn(4,4)\nkernel_matrix = get_kernel_matrix(kernel,input.shape)  # 4*16\n\n# \u901a\u8fc7\u77e9\u9635\u76f8\u4e58\u6765\u8ba1\u7b97\u5377\u79ef\nmm_conv2d_output = kernel_matrix @ input.reshape((-1,1))  \n\n# pytorch conv2d API\npytorch_conv2d_output = F.conv2d(input.unsqueeze(0).unsqueeze(0),kernel.unsqueeze(0).unsqueeze(0))\n# print(kernel)\n# print(kernel_matrix)\n# print(mm_conv2d_output)\n# print(pytorch_conv2d_output)\n\n# \u6d4b\u8bd52  \u901a\u8fc7\u77e9\u9635\u4e58\u79ef\u6765\u8ba1\u7b97\u8f6c\u7f6e\u5377\u79ef || \u9a8c\u8bc1\u4e8c\u7ef4\u8f6c\u7f6e\u5377\u79ef\nmm_transposed_conv2d_output = kernel_matrix.transpose(-1,-2) @ mm_conv2d_output\npytorch_transposed_conv2d_conv2d = F.conv_transpose2d(pytorch_conv2d_output,kernel.unsqueeze(0).unsqueeze(0))  #API\nprint(mm_transposed_conv2d_output.reshape(4,4))\nprint(pytorch_transposed_conv2d_conv2d)\n</code></pre> Python<pre><code>tensor([[ 0.9213, -4.1975, -2.0054,  1.9133],\n        [ 1.1103,  6.4068, -3.9560, -1.6305],\n        [-3.2193,  3.4451,  0.5374, -2.8065],\n        [ 0.5796, -3.2003,  3.8138,  0.9070]])\ntensor([[[[ 0.9213, -4.1975, -2.0054,  1.9133],\n          [ 1.1103,  6.4068, -3.9560, -1.6305],\n          [-3.2193,  3.4451,  0.5374, -2.8065],\n          [ 0.5796, -3.2003,  3.8138,  0.9070]]]])\n</code></pre>"},{"location":"learning/convs/#torchunfold-api","title":"torch.unfold api","text":"<p>\u67e5\u5b98\u7f51\uff0c\u770b\u5177\u4f53\u7528\u6cd5\uff1a</p> <p></p>"},{"location":"learning/convs/#_2","title":"\u5b9e\u4f8b\u8bb2\u89e3","text":"<p>\u9010\u884c\u89e3\u91ca\uff1a</p> <ul> <li>\u7b2c\u4e00\u884c\uff0c\u5b9e\u4f8b\u5316 Unfold\u64cd\u4f5c\uff0c\u8fd9\u91cc\u8c03\u7528\u7684\u662fnn.Unfold\uff0c\u7136\u540e\u4f20\u5165 kernel size\uff0ckernel size\u662f2\u00d73\u7684</li> <li>\u7b2c\u4e8c\u884c\uff0c\u7136\u540e\u5b9a\u4e49input\uff0c\u4f20\u5165 2\u00d75\u00d73\u00d74\u7684\u5f20\u91cf</li> <li>\u518d\u628ainput\u4f5c\u4e3aunfold\u7684\u8f93\u5165\uff0c\u4f20\u8fdb\u53bb\u5f97\u5230output</li> <li>\u5f97\u5230output\u7684\u5f62\u72b6\uff1a2\u00d730\u00d74</li> </ul> <p>\u89e3\u91caoutput\u7684\u5f62\u72b6\uff1a</p> <ul> <li> <p>\u6bcf\u4e2apatch\u5305\u542b\u4e8630\u4e2a\u6570\u503c\uff0c\u4e3a\u4ec0\u4e48\u662f30\u4e2a\u6570\u503c\uff1f\u5c31\u662f\u56e0\u4e3a\u8fd9\u91ccinput\u7684\u5f62\u72b62\u00d75\u00d73\u00d74</p> </li> <li> <p>2\u662fbatch size</p> </li> <li> <p>5\u662f input channel</p> </li> <li> <p>3\u548c4\u5206\u522b\u662f input\u7684\u9ad8\u5ea6\u548c\u5bbd\u5ea6</p> </li> <li> <p>\u5982\u679c\u6211\u4eec\u5bf9input \u628a\u6bcf\u4e00\u6b21 \u5377\u79ef\u7684\u5757 \u62ff\u51fa\u6765\u7684\u7684\u8bdd\uff0c\u90a3\u4e48\u4e00\u5171\u662f 2\u00d73\u00d75 \u8fd9\u4e48\u591a\u4e2a\u503c</p> <p>\u4e3a\u4ec0\u4e48\u662f\u8fd9\u4e48\u591a\u4e2a\u503c\u5462\uff1f\u9996\u51482\u00d73\u662fkernel size\u7684\u9762\u79ef\uff0c\u7136\u540e\u7531\u4e8e input\u67095\u4e2achannel\uff0c\u5176\u5b9e\u8fd9\u4e2a\u662f\u628achannel\u4e00\u8d77\u8003\u8651\u8fdb\u6765\u4e86\uff0c\u90a3\u6bcf\u4e2apatch\u5c31\u670930\u4e2a\u503c\uff1b</p> </li> <li> <p>\u7136\u540e\u6211\u4eec\u8fd9\u91cc \u8f93\u5165\u5927\u5c0f\u662f 3\u00d74\uff0c\u800ckernel size\u662f2\u00d73\u7684\uff0c\u90a3\u4e48\u8fd9\u6837\u7684\u8bdd\uff0c\u5982\u679c\u9ed8\u8ba4stride=1\uff0cpadding=0\u7684\u8bdd\uff0c\u5c31\u4e00\u5171\u67094\u4e2ablocks\uff0c\u5c31\u662f2\u00d72\u7684\u4e00\u4e2a\u8f93\u51fa \\([3-2+1=2]\\)  \u00d7  \\([ 4-3 +1 =2]\\) </p> </li> </ul> <p>\u4e00\u53e5\u8bdd\u603b\u7ed3 torch.unfold api\u5377\u79ef\u6838\u6ed1\u52a8input\uff0c\u5f97\u5230\u5bf9\u5e94\u7684region\uff0c\u8ddf\u5377\u79ef\u6838\u4e00\u6837\u5927\uff0c\u62c9\u6210\u884c\u5411\u91cf\uff0c\u5f62\u72b6\u662f </p> <p>\uff08\u5bf9\u4e8e\u5355\u4e2a\u5377\u79ef\u6838\uff09</p> <p><code>batch size\u00d7input region\u7684\u5143\u7d20\u6570\uff08=kernel\u7684\u5143\u7d20\u6570 \u901a\u9053\u6570*h*w\uff09\u00d7\u6ed1\u52a8\u4e86\u51e0\u4e2a\u533a\u57df\uff08=\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u9ad8 \u00d7 \u5bbd\uff09</code></p> <p>\uff08\u5bf9\u4e8e \u591a\u4e2a\u5377\u79ef\u6838 torch.unfold\u8f93\u51fa\u7684\u5f62\u72b6\u662f\u4ec0\u4e48\uff1f\uff09</p>"},{"location":"learning/convs/#_3","title":"\u4ec0\u4e48\u662f\u8f6c\u7f6e\u5377\u79ef\uff1f","text":"<p>\u5377\u79ef\u7684\u4e24\u79cd\u89d2\u5ea6\uff1a</p> <ul> <li>flatten input feature map region</li> </ul> <ol> <li> <p>\u6211\u4eec\u5c06input\u8fdb\u884c\u5c55\u5f00\uff0c\u4e5f\u5c31\u662f\u8bf4 \u6211\u4eec\u662f\u628a\uff0c\u6bcf\u4e00\u4e2ainput\u533a\u57df\u62c9\u76f4\uff0c\u62c9\u6210\u4e00\u4e2a\u5411\u91cf \uff0c\u7136\u540e\u628a\u6240\u6709\u7684\u533a\u57df\u7ec4\u5408\u6210\u4e00\u4e2a\u77e9\u9635\uff0c\u7136\u540e\u518d\u8ddf kernel\uff0c\u4e5f\u628akernel\u62c9\u6210\u4e00\u4e2a\u5411\u91cf\uff0c\u7136\u540e\u628a\u4e24\u4e2a\u77e9\u9635 \u8fdb\u884c\u51e0\u4e2a\u76f8\u4e58\u3002\u8fd9\u6837\u5f97\u5230\u6700\u7ec8\u7684\u5377\u79ef\u7ed3\u679c\uff1b </p> </li> <li> <p>flatten input feature map region\u62c9\u6210\u884c\u5411\u91cf\uff0ckernel\u62c9\u6210\u5217\u5411\u91cf</p> </li> <li>\u628a\u6bcf\u6b21\u6ed1\u52a8\u76f8\u4e58 \u8fd9\u4e2ainput region\u62c9\u76f4\uff0c\u62c9\u6210\u4e00\u4e2a\u5411\u91cf\uff0c\u628a9\u4e2a\u5411\u91cf \u62fc\u6210\u4e00\u4e2a\u77e9\u9635\uff0c\u518d\u8ddfkernel\uff0c\u628akernel \u4e5f\u62c9\u6210\u4e00\u4e2a\u5217\u5411\u91cf\uff0c\u8fdb\u884c\u4e24\u4e2a\u77e9\u9635\u7684\u76f8\u4e58\uff1b</li> </ol> <ul> <li>pad &amp; flatten kernel</li> </ul> <ol> <li>\u9996\u5148\u662f\u628a\u6574\u4e2ainput\uff0cinput\u662f5\u00d75\uff0c\u628a\u6574\u4e2ainput\u62c9\u6210\u4e00\u4e2a25\u00d71\u7684\u5411\u91cf\uff0c\u518d\u628a\u6bcf\u4e00\u6b65\u7684kernel\uff0c\u4e5f\u628a\u5b83\u53d8\u6210\u4e00\u4e2a\u957f\u5ea6\u4e3a25\u7684\u5411\u91cf\uff0c\u65b9\u6cd5\u662f\u628a\u6bcf\u4e00\u6b65\u7684kernel\u586b\u5145\u62105\u00d75\u7684\u5927\u5c0f</li> </ol> <p></p> <ol> <li> <p>9\u4e2akernel \u8ddf \u540c\u4e00\u4e2a input \u8fdb\u884c\u5185\u79ef\u64cd\u4f5c</p> </li> <li> <p>\u628a9\u4e2akernel \u62fc\u6210\u4e00\u4e2a\u77e9\u9635\u7684\u8bdd\uff0c\u76f8\u5f53\u4e8e\u662f\u4e00\u4e2a 9\u00d725\u7684 kernel\u77e9\u9635\uff0c\u8ddf25\u00d71\u7684input feature map\u8fdb\u884c\u77e9\u9635\u76f8\u4e58\uff0c\u6700\u7ec8\u5f97\u5230 9\u00d71\uff0c\u6211\u4eec\u518d\u628a 9\u00d71\u7684\u8f93\u51fa reshape\u4e00\u4e0b\uff0c\u53d8\u6210 3\u00d73\uff1b</p> </li> <li> <p>kernel \u62c9\u6210\u884c\u5411\u91cf\uff0cinput\u62c9\u6210\u5217\u5411\u91cf</p> </li> <li> <p>again\uff1a\u628a\u5377\u79ef\u770b\u6210 \u6bcf\u4e00\u6b65 \u90fd\u662f 5\u00d75 \u7684kernel \u8ddf 5\u00d75 \u7684input \u8fdb\u884c\u5185\u79ef\uff0c\u7136\u540e\u6c42\u548c\u7684\u64cd\u4f5c\uff1b\u4e3a\u4ec0\u4e48\u662f5\u00d75\uff0c\u56e0\u4e3a\u6211\u4eec\u628a\u6bcf\u4e00\u6b65 kernel\u586b\u5145\u6210 5\u00d75\u7684\uff0c\u5177\u4f53\u600e\u4e48 \u586b\u5145  \u770bkernel\u7684\u4f4d\u7f6e\uff0c\u6309\u7167 input\u7684\u5f62\u72b6 \u8fdb\u884c\u586b</p> </li> </ol>"},{"location":"learning/convs/#kernel-flatten-convolution","title":"\u4ece kernel flatten convolution \u5f00\u59cb","text":"Python<pre><code># step4 \u901a\u8fc7\u5bf9kernel\u8fdb\u884c\u5c55\u5f00\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5e76\u63a8\u5bfc\u51fa\u8f6c\u7f6e\u5377\u79ef\uff0c\u4e0d\u8003\u8651batch\u3001channel\u5927\u5c0f\uff0c\u4e0d\u8003\u8651padding\uff0c\u5047\u8bbestride=1\ndef get_kernel_matrix(kernel,input_size):\n    # \u57fa\u4e8ekernel\u548c\u8f93\u5165\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u6765\u5f97\u5230\u586b\u5145\u62c9\u76f4\u540e\u7684kernel\u5806\u53e0\u540e\u7684\u77e9\u9635\n    kernel_h,kernel_w = kernel.shape\n    input_h,input_w = input.shape\n    num_out_fea_map = (input_h-kernel_h+1)*(input_w-kernel_w+1)  # \u5377\u79ef\u516c\u5f0f\n    result = torch.zeros((num_out_fea_map,input_h*input_w)) #\u521d\u59cb\u5316\u7ed3\u679c\u77e9\u9635\uff0c\u8f93\u51fa\u7279\u5f81\u56fe\u5143\u7d20\u4e2a\u6570*\u8f93\u5165\u7279\u5f81\u56fe\u5143\u7d20\u4e2a\u6570\n    count = 0\n    for i in range(0,input_h-kernel_h+1,1):\n        for j in range(0,input_w - kernel_w +1,1):\n            # \u586b\u5145\u6210 \u8ddf \u8f93\u5165\u7279\u5f81\u56fe\u4e00\u6837\u5927\u5c0f\n            # padded_kernel = F.pad(kernel,(i,input_h-kernel_h-i,j,input_w-kernel_w-j))\n            padded_kernel = F.pad(kernel,(j,input_h-kernel_h-j,i,input_w-kernel_w-i))\n            result[count] = padded_kernel.flatten()\n            count +=1\n    return result  \n\n\n\n# \u6d4b\u8bd51\uff1a\u9a8c\u8bc1 \u4e8c\u7ef4\u5377\u79ef\nkernel = torch.randn(3,3)\ninput = torch.randn(4,4)\nkernel_matrix = get_kernel_matrix(kernel,input.shape)  # 4*16\n\n# \u901a\u8fc7\u77e9\u9635\u76f8\u4e58\u6765\u8ba1\u7b97\u5377\u79ef\nmm_conv2d_output = kernel_matrix @ input.reshape((-1,1))  \n\n# pytorch conv2d API\npytorch_conv2d_output = F.conv2d(input.unsqueeze(0).unsqueeze(0),kernel.unsqueeze(0).unsqueeze(0))\nprint(kernel)\nprint(kernel_matrix)\nprint(mm_conv2d_output)\nprint(pytorch_conv2d_output)\n</code></pre> Python<pre><code>kernel\ntensor([[ 0.3170,  2.4005, -1.2991],\n        [ 1.1566, -0.3610, -0.7246],\n        [-0.5764, -0.7988,  1.5611]])\nkernel_matrix\ntensor([[ 0.3170,  2.4005, -1.2991,  0.0000,  1.1566, -0.3610, -0.7246,  0.0000,\n         -0.5764, -0.7988,  1.5611,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.3170,  2.4005, -1.2991,  0.0000,  1.1566, -0.3610, -0.7246,\n          0.0000, -0.5764, -0.7988,  1.5611,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.3170,  2.4005, -1.2991,  0.0000,\n          1.1566, -0.3610, -0.7246,  0.0000, -0.5764, -0.7988,  1.5611,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3170,  2.4005, -1.2991,\n          0.0000,  1.1566, -0.3610, -0.7246,  0.0000, -0.5764, -0.7988,  1.5611]])\nmm_conv2d_output\ntensor([[ 5.3770],\n        [-2.0131],\n        [-5.9471],\n        [-2.7944]])\npytorch_conv2d_output\ntensor([[[[ 5.3770, -2.0131],\n          [-5.9471, -2.7944]]]])\n</code></pre>"},{"location":"learning/convs/#_4","title":"\u8f6c\u7f6e\u5377\u79ef","text":"<ul> <li>\u8f93\u5165\uff1a4\u00d74\uff0ckernel\uff1a3\u00d73\uff0coutput\uff1a2\u00d72   <ul> <li>flatten input feature map region\uff1a4\u00d79  @ 9\u00d71 = 4\u00d71</li> <li>padding &amp; flatten kernel \uff1a4\u00d716 @ 16\u00d71 = 4\u00d71</li> </ul> </li> <li>\u8f6c\u7f6e\u5377\u79ef\uff1a   <ul> <li>16\u00d74 @ 4\u00d71 = 16\u00d71  $ reshape \\rightarrow $ 4 \u00d7 4 </li> </ul> </li> </ul> <p>\u8f6c\u7f6e\u5377\u79ef\u662f\u600e\u4e48\u505a\u7684\u5462\uff1f</p> <p>\u5176\u5b9e\u505a\u6cd5\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u628akernel matrix \u9996\u5148\u8f6c\u7f6e\u4e00\u4e0b\uff1b\u6bd4\u65b9\u8bf4\u672c\u6765\u662f4\u00d716\u7684 \u77e9\u9635\uff1b\u6211\u4eec\u8f6c\u7f6e\u4e00\u4e0b\uff1b\u8f6c\u7f6e\u621016\u00d74\u7684\u77e9\u9635\uff1b</p> <p>\u7136\u540e\u6211\u4eec\u4e5f\u8bb2\u4e86output\u662f\u4e00\u4e2a2\u00d72\u7684 \u77e9\u9635\uff0c\u6211\u4eec\u4e5f\u628a\u5b83\u62c9\u76f4\u4e00\u4e0b\uff0c\u53d8\u62104\u00d71\u7684\u77e9\u9635\uff1b\u4e8e\u662f16\u00d74\u7684\u77e9\u9635\uff0c\u8ddf4\u00d71\u7684\u77e9\u9635\uff0c\u76f8\u4e58\uff0c\u5c31\u53d8\u6210\u4e86\u4e00\u4e2a16\u00d71\u7684\u77e9\u9635\uff0c\u6211\u4eec\u5728reshape\u4e00\u4e0b\uff0c\u5c31\u53d8\u6210\u4e864\u00d74\uff0c\u8fd9\u6837\u6211\u4eec\u5c31\u628a\u4e00\u4e2a 2\u00d72\u7684\u7279\u5f81\u56fe\uff0c\u53d8\u6210\u4e86\u4e00\u4e2a4\u00d74\u7684\u7279\u5f81\u56fe\uff1b\u8fd9\u662f\u4ece\u539f\u7406\u4e0a\u7684\u89e3\u91ca</p> <p>\u53e6\u5916\u8fd8\u6709\u4e00\u79cd\uff0c\u6211\u4eec\u8fd9\u91cc\u5b9e\u73b0\u4e86\u4e8c\u7ef4\u5377\u79ef\uff0c\u5c31\u7c7b\u4f3c\u4e8e y=wx(w\u4e58\u4ee5x\u8fd9\u6837\u7684\u4e00\u4e2a\u8fc7\u7a0b)\uff1b</p> <p>w\u8ddfx\u4e4b\u95f4 \u662f\u4e00\u4e2a\u77e9\u9635\u4e58\u6cd5\uff1b\u7136\u540e\u6211\u4eec\u6c42\u540e\u5411\u68af\u5ea6\u7684\u65f6\u5019\uff0c\u504fy\uff0c\u504fx\uff0c\u521a\u597d\u5c31\u662fw\u7684\u4e00\u4e2a\u8f6c\u7f6e\uff0c\u6240\u4ee5\u8bf4\u5728pytorch\u4e2d\uff0c\u5b9e\u73b0\u8f6c\u7f6e\u5377\u79ef \u6216\u8005\u53eb deconvolution \u6216\u8005\u53ebtranspose convolution\uff0c\u90fd\u662f\u57fa\u4e8e\u540e\u5411\u4f20\u64ad \u6765\u5b9e\u73b0\u7684\uff1b</p> <p>y=wx</p> <p>dy dx\u5c31\u7b49\u4e8ew\u7684\u8f6c\u7f6e</p> <p>\u8fd9\u4e2a\u5c31\u662f\u8f6c\u7f6e\u5377\u79ef\u7684\u539f\u7406\u90e8\u5206</p> <ul> <li>\u4e09\u70b9\u9700\u8981\u7279\u522b\u6ce8\u610f\uff1a</li> </ul> <p>\u7b2c\u4e00\u70b9</p> <p>\u8f6c\u7f6e\u5377\u79ef\u4e00\u822c\u7528\u5728\u4e0a\u91c7\u6837\u7684\u8fc7\u7a0b\uff1b\u56e0\u4e3a\u666e\u901a\u7684\u5377\u79ef\u4f1a\u7528\u5728\u4e0b\u91c7\u6837\uff0c\u6bd4\u65b9\u8bf4\u8fd9\u91cc\u7684\u4f8b\u5b50\uff0c\u628a4\u00d74\u7684\u7279\u5f81\u56fe\uff0c\u901a\u8fc7\u5377\u79ef\u53d8\u6210\u4e86\u4e00\u4e2a2\u00d72\u7684\uff0c\u8fd9\u662f\u5e38\u89c4\u7684\u64cd\u4f5c\uff0c\u8fd9\u662f\u4e0b\u91c7\u6837</p> <p>\u90a3\u6709\u65f6\u5019\uff0c\u5728\u751f\u6210\u7684\u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u53ef\u80fd\u9700\u8981\uff0c\u8f93\u5165\u662f2\u00d72\u7684\uff0c\u8f93\u51fa\u53d8\u62104\u00d74\u7684\uff0c\u8fd9\u4e2a\u65f6\u5019\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u8f6c\u7f6e\u5377\u79ef\u5b9e\u73b0\uff0c\u8fd9\u662f\u7b2c\u4e00\u70b9\uff1b </p> <p>\u7b2c\u4e8c\u70b9</p> <p>\u8f6c\u7f6e\u5377\u79ef \u6216\u8005 \u540e\u5411 \u5377\u79ef \u68af\u5ea6\uff1b\u610f\u601d\u5c31\u662f\u8bf4 \u6211\u4eec\u901a\u8fc7\u540e\u5411\u4f20\u64ad \u6765\u5b9e\u73b0\u8f6c\u7f6e\u5377\u79ef\u7684</p> <p>\u7b2c\u4e09\u70b9</p> <p>\u8f6c\u7f6e\u5377\u79ef\u4e5f\u53ef\u4ee5\u901a\u8fc7 \u586b\u5145\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\uff0c\u4ec0\u4e48\u610f\u601d\u5462\uff1f\u5c31\u662f\u53ef\u4ee5\u628a2\u00d72\u7684\u8f93\u5165 \u586b\u5145\u52306\u00d76\u7684\u5927\u5c0f\uff1b\u7136\u540e\u518d\u53bb\u75283\u00d73\u7684kernel \u8fdb\u884c\u4e00\u4e2a\u5377\u79ef\uff1b\u4e5f\u80fd\u5b9e\u73b0\u4e00\u4e2a\u4e0a\u91c7\u6837\u7684\u6548\u679c\uff1b\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5e76\u4e0d\u662f\u6846\u67b6\u4e2d\u4f7f\u7528\u7684\u65b9\u6cd5\uff1b\u6846\u67b6\u4e2d\u7684\u5b9e\u73b0 \u662f\u901a\u8fc7 \u540e\u5411\u4f20\u64ad\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0 \u8f6c\u7f6e\u5377\u79ef\u7684\uff1b</p> <p>\u4ee3\u7801\u5b9e\u73b0\uff1a</p> <p>\u9996\u5148\u5bf9kernel matrix\u8fdb\u884c\u4e00\u4e2a\u8f6c\u7f6e\uff0ctranspose\uff0c-1\u7ef4\uff0c-2\u7ef4\u8f6c\u7f6e\u4e00\u4e0b</p> <p>kernel_matrix.transpose(-1,-2)\uff0c\u8fd9\u6837\u5f97\u5230w\u7684\u4e00\u4e2a\u8f6c\u7f6e\uff0c\u6211\u4eec\u518d\u628a\u8fd9\u4e2a\u8f6c\u7f6e\u8ddf\u4e0a\u9762\u8fd9\u4e2aoutput <code>mm_conv2d_output</code> \u8fdb\u884c\u4e00\u4e2a\u77e9\u9635\u76f8\u4e58\u64cd\u4f5c</p> Python<pre><code>kernel_matrix.transpose(-1,-2) @ mm_conv2d_output\n</code></pre> <ul> <li> <p>mm_conv2d_output \u662f\u4e00\u4e2a 4\u00d71 \u7684\u77e9\u9635\uff0c\u524d\u9762\u8f6c\u7f6e\u540e\u662f\u4e00\u4e2a 16\u00d74\u7684\uff0c\u5f97\u5230\u4e00\u4e2a 16\u00d71\u7684\u7ed3\u679c </p> </li> <li> <p>\u5b9a\u4e49\u4e3a mm_transposed_conv2d_output  </p> </li> <li> <p>\u8fd9\u4e2a\u5c31\u662f\u901a\u8fc7\u77e9\u9635\u76f8\u4e58 \u5f97\u5230\u7684\u8f6c\u7f6e\u5377\u79ef\uff0c\u4e5f\u53eb\u505a\u53cd\u5377\u79ef\uff1b </p> </li> <li> <p>\u8fd9\u4e2a\u53cd\u5377\u79ef \u6216\u8005\u53eb \u8f6c\u7f6e\u5377\u79ef\uff0c\u5e76\u4e0d\u662f\u4e00\u4e2a\u53ef\u9006\u7684\uff0c\u4e0d\u662f\u4e00\u4e2a\u9006\u8ba1\u7b97\uff0c\u8fd9\u91cc\u7684output\u5e76\u4e0d\u662f\u5f53\u521d\u7684input\uff0c\u53ea\u662f\u5f62\u72b6\u8ddfinput\u4e00\u6837\u800c\u5df2</p> </li> </ul> Python<pre><code>mm_transposed_conv2d_output = kernel_matrix.transpose(-1,-2) @ mm_conv2d_output\n</code></pre> <p>\u4ee5\u4e0a\u662f\u77e9\u9635\u4e58\u79ef\u5f97\u5230\u8f6c\u7f6e\u5377\u79ef\u7684\uff1b</p> <p>\u4e3a\u4e86\u9a8c\u8bc1\uff0c\u6211\u4eec\u53ef\u4ee5\u8c03\u7528pytorch\u8f6c\u7f6e\u5377\u79ef\u7684api</p> <p></p> <ol> <li>\u7c7b\u5f62\u5f0f</li> <li>\u51fd\u6570\u5f62\u5f0f</li> </ol> <p></p> <ul> <li>\u5b9e\u4f8b\u5316class\uff0c\u8c03\u7528\u7684\u8fd8\u662f\u51fd\u6570\u5f62\u5f0f\uff1b\u73b0\u5728\u6211\u4eec\u6765\u8c03\u7528\u4e00\u4e0b\u8fd9\u4e2a\u51fd\u6570</li> <li>\u5c31\u662fF.conv_transpose2d()\u4e00\u6837\u7684\uff0c\u9996\u5148\u4f20\u5165\u4e0a\u9762\u7684output\uff0c\u5c31\u662f\u628a\u4e0a\u9762\u7684pytorch_conv2d_output\u4f5c\u4e3a\u8f93\u5165\uff0ckernel\u4e5f\u8981\u4f20\u8fdb\u53bb\uff0ckernel\u5c31\u662f\u4e4b\u524d\u5199\u7684kernel\uff0c\u540c\u6837\u4e5f\u8981\u5bf9\u5b83\u8fdb\u884c\u4e24\u6b21\u7684unsqueeze\u64cd\u4f5c\uff08batch size \u00d7 channel \u00d7 height \u00d7 width\uff09\uff0c\u8fd9\u6837\u5f97\u5230pytorch_transposed_conv2d_output API</li> </ul> Python<pre><code># \u6d4b\u8bd52  \u901a\u8fc7\u77e9\u9635\u6210\u7ee9\u6765\u8ba1\u7b97\u8f6c\u7f6e\u5377\u79ef\nmm_transposed_conv2d_output = kernel_matrix.transpose(-1,-2) @ mm_conv2d_output\npytorch_transposed_conv2d_conv2d = F.conv_transpose2d(pytorch_conv2d_output,kernel.unsqueeze(0).unsqueeze(0))  #API\nprint(mm_transposed_conv2d_output.reshape(4,4))\nprint(pytorch_transposed_conv2d_conv2d)\n</code></pre> <p>\u5173\u4e8e\u8f6c\u7f6e\u5377\u79ef\u8981\u8bf4\u660e\u7684\uff1a</p> <ul> <li>\u6211\u4eec\u628a\u5377\u79ef\u770b\u6210\u662f \u586b\u5145\u540e\u7684kernel\u8ddfinput\uff0c\u5f97\u5230 kernel_matrix\u4e4b\u540e\uff0c\u518d\u628akernel matrix\u8f6c\u7f6e\u4e00\u4e0b\uff0c\u8ddfconvolution output\u8fdb\u884c\u77e9\u9635\u76f8\u4e58\uff0c\u8fd9\u6837\u5f97\u5230\u4e86\u4e00\u4e2a\u65b0\u7684output\uff0c\u521a\u597doutput\u7684\u5927\u5c0f\u548cinput\u7684\u5927\u5c0f\u662f\u4e00\u6837\u7684\uff1b\u6210\u529f\u5b9e\u73b0\u4e86\u4e0a\u91c7\u6837\uff0c\u56e0\u4e3amm conv2d output\u662f 2\u00d72\u7684\uff0c\u5de6\u8fb9mm transposed conv2d output\u662f 4\u00d74\u7684\uff0c\u6211\u4eec\u5c31\u5b9e\u73b0\u4e86\u4e0a\u91c7\u6837\uff1b</li> <li>F.conv_transposed2d()\u7684\u8f93\u5165\uff0c\u5c31\u662f\u666e\u901a\u5377\u79ef\u7684\u8f93\u51fa\uff0ckernel\u8fd8\u662f\u90a3\u4e2akernel\uff0c\u628a\u5b83\u6269\u5145\u4e00\u4e0b</li> </ul> <p>\u5173\u4e8e\u4e0a\u91c7\u6837\u7684\u4e24\u4e2a\u89d2\u5ea6\uff1a </p> <ul> <li>\uff08\u7b2c\u4e00\u79cd\u5b9e\u73b0\uff1a\u628akernel\u8f6c\u7f6e 16 \u00d7 4  $ \\rightarrow $ 4\u00d716 \uff09  \u9996\u5148\u8981\u628a\u666e\u901a\u5377\u79ef\u7684kernel matrix\u5199\u51fa\u6765\uff0c\u7136\u540e\u518d\u628amatrix\u8f6c\u7f6e\u4e00\u4e0b\uff0c\u518d\u8ddf\u666e\u901a\u5377\u79ef\u7684\u8f93\u51fa \u76f8\u4e58\u4e00\u4e0b\uff1b\u5c31\u5b9e\u73b0\u4e86</li> <li>\uff08\u7b2c\u4e8c\u79cd\u5b9e\u73b0\uff1a\u628ainput\u53d8\u5927\uff09   \u76f4\u63a5\u628ainput\u8fdb\u884c\u586b\u5145\uff1b\u6bd4\u5982\u73b0\u5728input\u662f2\u00d72\uff0c\u6211\u4eec\u4e3a\u4e86\u5b9e\u73b04\u00d74\uff0c\u4e3a\u4e86\u7528\u666e\u901a\u7684\u5377\u79ef\uff0c\u6211\u4eec\u53ef\u4ee5\u628a2\u00d72\u7684\u586b\u5145\u62105\u00d75 \u6216\u8005 6\u00d76\u7684\uff1b\u5047\u5982\u8bf4\u662f6\u00d76\u7684\uff0c\u6211\u4eec\u5c31\u628a\u4e0a\u4e0b\u5de6\u53f3 \u586b\u5145\u4e24\u884c0\u5c31\u597d\u4e86\uff0c\u518d\u7528\u666e\u901a\u5377\u79ef\u5b9e\u73b0 \u4e5f\u662f\u53ef\u4ee5\u7684\uff1b\u56e0\u4e3a\u53cd\u6b63\u53c2\u6570\u90fd\u662f\u8981\u5b66\u4e60\u7684\uff0c\u6211\u4eec\u7684\u76ee\u7684\u5c31\u662f\u505a\u4e0a\u91c7\u6837\uff1b\u65e0\u8bba\u662f\u4ece\u540e\u5411\u4f20\u64ad\u7684\u89d2\u5ea6\uff0c\u8fd8\u662f\u76f4\u63a5\u5bf9input\u8fdb\u884c\u586b\u5145\uff0c\u628ainput\u53d8\u5927\uff0c\u90fd\u80fd\u5b9e\u73b0 \u4e0a\u91c7\u6837\uff0c\u4e0d\u8fc7\u6570\u503c\u662f\u4e0d\u4e00\u6837\u7684\uff0c\u4e0d\u8fc7\u6ca1\u5173\u7cfb\uff0c\u53cd\u6b63\u90fd\u662f\u8981\u5b66\u4e60\u7684</li> </ul> <p>\u8f6c\u7f6e\u5377\u79ef \u53cd\u5377\u79ef=transpose conv2d</p>"},{"location":"learning/convs/#4","title":"4 \u81a8\u80c0\u5377\u79ef &amp; \u7a7a\u6d1e\u5377\u79ef","text":"<p>intro\uff0c\u5b98\u65b9api\uff1a</p> <p></p> <p>\u5728\u9ed8\u8ba4\u7684api\u4e2d dilation\u7684\u503c\u7b49\u4e8e1\uff0cgroups\u7684\u503c \u4e5f\u662f\u7b49\u4e8e1 \u7684\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u5e38\u7528\u7684\u5377\u79ef\u90fd\u6ca1\u6709\u6307\u5b9a\uff0c\u5e38\u7528\u7684\u503c\u90fd\u4e3a1</p> <p>\u4ec0\u4e48\u662fdilation\uff1f</p> <p>dilation\u7684\u610f\u601d\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u666e\u901a\u7684\u5377\u79ef\uff0c\u6bd4\u5982\u8bf43\u00d73\u7684\u5377\u79ef\u6838\uff0c\u5728\u4e00\u4e2a\u8f93\u5165\u7279\u5f81\u56fe\u4e0a \u8fdb\u884c \u5377\u79ef\u7684\u8bdd\uff0c\u6211\u4eec\u6bcf\u6b21\uff0c\u4ece\u8f93\u5165\u7279\u5f81\u56fe\u4e0a\u53d6\u4e00\u5757 3\u00d73\u7684 \u9762\u79ef\uff0c\u53d69\u4e2a\u5143\u7d20\uff0c\u5e76\u4e14\u8fd99\u4e2a\u5143\u7d20\uff0c\u90fd\u662f\u7d27\u6328\u7740\u5f7c\u6b64\u7684\uff0c\u5c31\u662f3\u00d73\u7684\u533a\u57df\uff0c\u4e00\u4e2a\u65b9\u5f62\u533a\u57df\uff0c\u8fd9\u79cd\u60c5\u51b5\uff0c\u6211\u4eec\u6210\u4e3adilation=1\uff0c\u4e5f\u5c31\u662f\u8bf4\u5f7c\u6b64\u4e4b\u95f4\u95f4\u9694\u4e3a1\uff0c\u53ef\u4ee5\u8fd9\u4e48\u7406\u89e3\uff0c\u5f7c\u6b64\u7684\u7d22\u5f15\uff0c\u5dee\u8ddd\u4e3a1\uff0c\u6bd4\u65b9\u8bf4\u7b2c\u4e00\u4e2a\u5143\u7d20 \u7d22\u5f15\u4e3a1\uff0c\u7b2c\u4e8c\u4e2a\u5143\u7d20 \u7d22\u5f15 \u5c31\u662f2\uff0c\u90a3\u5982\u679cdilation\u4e0d\u662f\u7b49\u4e8e1\uff0c\u800c\u662f2\u7684\u8bdd\u5462\uff0c\u8bf4\u660e\u7b2c\u4e00\u4e2a\u5143\u7d20\u548c\u7b2c\u4e8c\u4e2a\u5143\u7d20 \u7d22\u5f15\u76f8\u5dee\u4e862\uff0c\u90a3\u5c31\u8bf4\u660e \u4e2d\u95f4\u8fd8\u591a\u4e86\u4e00\u4e2a\u5143\u7d20\uff1b</p> <p>\u4e5f\u5c31\u662f\u8bf4 dilation \u662f\u63a7\u5236\u7740\u6211\u4eec\u8f93\u5165 \u7279\u5f81\u56fe \u8981\u53d6\u5f97\u90a3\u90e8\u5206\u9762\u79ef \u662f\u5426\u662f\u7d27\u51d1\u7684\uff0c\u5982\u679c\u5b83\u7684\u503c\u5927\u4e8e1\u7684\u8bdd\uff0c\u5b83\u5c31\u4e0d\u662f\u7d27\u51d1\u7684\uff0c\u5b83\u4e2d\u95f4\u662f\u6709\u4e00\u4e9b\uff0c\u8df3\u8fc7\u7684\u5143\u7d20\u7684\uff1b</p> Python<pre><code>a = torch.randn(7,7)\n</code></pre> <p></p> <ul> <li>dilation=2  a[0:5:2,0:5:2] \u7d22\u5f150\u5230\u7d22\u5f155\uff0c\u8df3\u8fc7\u4e00\u4e2a\u53d6\u4e00\u4e2a\uff0c\u6700\u540e\u4e00\u4e2a\u53d6\u4e0d\u5230</li> <li>dilation=3 \u7528\u7d22\u5f15\u8868\u793a\u7684\u8bdd \u5c31\u662f 0\u52307\uff0c\u7136\u540e\u95f4\u9694\u662f3\uff1ba[0:7:3,0:7:3] # dilation=3 \u540c\u6837\u5217\u6570\u4e5f\u662f\u4e00\u6837\u7684 0\u52307 \u95f4\u9694\u662f3\uff1b\u7d22\u5f15\u95f4\u9694\u4e3a3</li> </ul> <p></p> <p>\u4e00\u53e5\u8bdd\u8bf4\u6e05dilation\u662f\u4ec0\u4e48\uff1f\u5377\u79ef\u7684\u8986\u76d6\u533a\u57df \u7d22\u5f15\u95f4\u9694\u591a\u5c11</p> <p>\u5982\u679c input size=7\u00d77 kernel size=3\u00d73\uff0cdilation=3\uff0c\u6211\u4eec\u53ea\u9700\u8981 \u53d6\u4e00\u6b21\u5c31\u597d\u4e86\uff1b</p> <p>\u53d6\u4e00\u6b21 \u5c31\u521a\u597d \u5df2\u7ecf\u5230 \u8fb9\u754c\u4e86</p> <p>\u6240\u4ee57\u00d77\u7684input \u8ddf 3\u00d73\u7684kernel \u8fdb\u884c \u5377\u79ef\u7684\u8bdd\uff0c\u6211\u4eec\u4e0d\u505apadding stride=1\u7684\u8bdd\uff0c\u90a3\u4e48\u8f93\u51fa\u5c31\u662f\u4e00\u4e2a\u6570\uff0c\u5c31\u662f\u4e00\u4e2a\u6807\u91cf\uff1b\u8fd9\u5c31\u662fdilation \u53d6 \u4e0d\u540c\u503c \u5177\u4f53\u7684\u8fd0\u7b97\u89c4\u5219</p> <p>\u90a3\u4e3a\u4ec0\u4e48\u8981\u7528dilation\u5927\u4e8e1\u7684\u8fd9\u4e9b\u60c5\u51b5\u5462\uff1f\u5c31\u662f\u56e0\u4e3a\u6211\u4eec \u589e\u5927dilation \u4f46\u662f\u5e76\u6ca1\u6709\u589e\u5927\u8fd0\u7b97\u91cf\uff1b\u6211\u4eec\u8fd8\u662f3\u00d73\u7684\u77e9\u9635\uff0c\u8ddf3\u00d73\u7684\u77e9\u9635 \u8fdb\u884c\u5143\u7d20\u76f8\u4e58\uff1b\u5e76\u6ca1\u6709\u56e0\u4e3a \u611f\u53d7\u91ce\u53d8\u5927 \u8ba1\u7b97\u91cf \u53d8\u5927\uff1b\u6240\u4ee5\u4e00\u822c \u589e\u5927 dilation\u7684\u76ee\u7684 \u5c31\u662f\u6211\u4eec\u5728 \u4fdd\u6301\u8fd0\u7b97\u91cf\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\uff0c\u5e0c\u671b \u589e\u5927 \u611f\u53d7\u91ce\u7684\u9762\u79ef\uff1b\u8fd9\u5c31\u662fdilation</p> <p>\u4e00\u53e5\u8bdd\u4e3a\u4ec0\u4e48dilation\uff1a\u5728\u4e0d\u589e\u52a0\u8fd0\u7b97\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u589e\u5927\u611f\u53d7\u91ce</p>"},{"location":"learning/convs/#5","title":"5 \u5206\u7ec4\u5377\u79ef &amp; \u7fa4\u5377\u79ef","text":""},{"location":"learning/convs/#_5","title":"\u4ec0\u4e48\u662f\u5206\u7ec4\u5377\u79ef\uff1f","text":"<p>\u5206\u7ec4\u5377\u79ef group convolution\uff1b\u662f\u5bf9\u8f93\u5165\u901a\u9053\u8fdb\u884c\u5206\u7ec4\uff1b\u8f93\u51fa\u901a\u9053\u5e76\u4e0d\u662f\u7531\u6240\u6709\u7684\u8f93\u5165\u901a\u9053\u5171\u540c\u4f5c\u7528\u7684\uff1b\u4f1a\u6709\u4e00\u79cd\u60c5\u51b5\uff0c\u6bd4\u5982\u8f93\u5165\u901a\u9053\u662f4\uff0c\u8f93\u51fa\u901a\u9053\u662f2\uff0c\u8f93\u51fa\u901a\u9053\u7684\u7b2c\u4e00\u4e2a\u901a\u9053\u53ea\u8ddf\u8f93\u5165\u901a\u9053\u7684\u7b2c1\u30013\u4e2a\u901a\u9053\u6709\u5173\uff1b\u8f93\u51fa\u901a\u9053\u7684\u7b2c\u4e8c\u4e2a\u901a\u9053\u53ea\u8ddf\u8f93\u5165\u901a\u9053\u7684\u7b2c2\u30014\u4e2a\u901a\u9053\u6709\u5173\uff1b\u5982\u679c\u8f93\u5165\u901a\u9053\u6709\u8fd9\u6837\u7684\u5173\u7cfb\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u91c7\u7528\u5206\u7ec4\u5377\u79ef\uff0c\u8bbe\u7f6e\u7ec4\u6570group=2\uff0c\u8fd9\u65f6\u6709\u51e0\u4e2a\u7ec4\u5c31\u4f1a\u6709\u51e0\u4e2a\u8f93\u51fa\u901a\u9053\uff1b\u8fd9\u79cd\u60c5\u51b5\u662f\u6211\u4eec\u5bf9\u6bcf\u4e2a\u7ec4\u8fdb\u884c\u4e00\u6b21\u5377\u79ef\uff0c\u5982\u679c\u6211\u4eec\u5bf9\u6bcf\u4e2a\u7ec4\u8fdb\u884c\u591a\u6b21\u5377\u79ef\uff0c\u90a3\u4e48\u5377\u79ef\u6838\u7684\u4e2a\u6570\u5c31\u4f1a\u589e\u52a0\u4e86\uff1b\u8fd9\u6837\u4e5f\u6709\u4e00\u4e2a\u95ee\u9898\uff0c\u5c31\u662f\u8f93\u5165\u7279\u5f81\u56fe\u7684\u901a\u9053\u4e4b\u95f4\u6ca1\u6709\u4ea4\u4e92\uff0c\u6240\u4ee5\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5728\u540e\u9762\u7684\u5377\u79ef\u8fc7\u7a0b\u4e2d\uff0c\u4f1a\u6709\u901a\u9053\u4e4b\u95f4\u7684\u968f\u673a\u6df7\u5408\u6216\u8005\u75281\u00d71\u7684\u5377\u79ef\uff1bpoinwise convolution\uff1b</p>"},{"location":"learning/convs/#depthwise-pointwise","title":"\u8865\u5145\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef depthwise &amp; pointwise\uff1a","text":"<p>\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\uff0c\u662f\u7279\u6b8a\u7684\u5206\u7ec4\u5377\u79ef\uff0c\u6709\u51e0\u4e2a\u8f93\u5165\u901a\u9053\uff0c\u5c31\u5206\u6210\u51e0\u4e2a\u7ec4\uff0c\u8f93\u5165\u901a\u9053\u4e4b\u95f4\u5b8c\u5168\u76f8\u4e92\u72ec\u7acb\uff0cdeepwise convolution\uff1b\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u540e\u9762\u901a\u5e38\u4f1a\u8ddf\u7740 pointwise  convolution\uff1b</p> <p>\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef &amp; 1\u00d71\u5377\u79ef</p> <p>\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684Separable Convolution</p> <p>\u4e00\u5f20\u56fe\u770b\u61c2\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\uff1a</p> <p></p> <p>Depthwise Convolution\u5b8c\u6210\u540e\u7684Feature map\u6570\u91cf\u4e0e\u8f93\u5165\u5c42\u7684depth\u76f8\u540c\uff0c\u4f46\u662f\u8fd9\u79cd\u8fd0\u7b97\u5bf9\u8f93\u5165\u5c42\u7684\u6bcf\u4e2achannel\u72ec\u7acb\u8fdb\u884c\u5377\u79ef\u8fd0\u7b97\u540e\u5c31\u7ed3\u675f\u4e86\uff0c\u6ca1\u6709\u6709\u6548\u7684\u5229\u7528\u4e0d\u540cmap\u5728\u76f8\u540c\u7a7a\u95f4\u4f4d\u7f6e\u4e0a\u7684\u4fe1\u606f\u3002\u56e0\u6b64\u9700\u8981\u589e\u52a0\u53e6\u5916\u4e00\u6b65\u64cd\u4f5c\u6765\u5c06\u8fd9\u4e9bmap\u8fdb\u884c\u7ec4\u5408\u751f\u6210\u65b0\u7684Feature map\uff0c\u5373\u63a5\u4e0b\u6765\u7684Pointwise Convolution\u3002\uff08\u6458\u81ea\uff09</p> <p>\u4e00\u5f20\u56fe\u770b\u61c21\u00d71\u5377\u79ef\uff1a</p> <p></p> <p>Pointwise Convolution\u7684\u8fd0\u7b97\u4e0e\u5e38\u89c4\u5377\u79ef\u8fd0\u7b97\u975e\u5e38\u76f8\u4f3c\uff0c\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\u5377\u79ef\u6838\u7684\u5c3a\u5bf8\u4e3a 1\u00d71\u00d7M\uff0cM\u4e3a\u4e0a\u4e00\u5c42\u7684depth\u3002\u6240\u4ee5\u8fd9\u91cc\u7684\u5377\u79ef\u8fd0\u7b97\u4f1a\u5c06\u4e0a\u4e00\u6b65\u7684map\u5728\u6df1\u5ea6\u65b9\u5411\u4e0a\u8fdb\u884c\u52a0\u6743\u7ec4\u5408\uff0c\u751f\u6210\u65b0\u7684Feature map\u3002\u6709\u51e0\u4e2aFilter\u5c31\u6709\u51e0\u4e2aFeature map\u3002\uff08\u6458\u81ea\uff09</p> <p>\u8865\u5145\u666e\u901a\u5377\u79ef\uff1a</p> <p></p>"},{"location":"learning/convs/#_6","title":"\u4e3a\u4ec0\u4e48\u9700\u8981\u5206\u7ec4\u5377\u79ef\uff1f","text":"<p>\u5f52\u7eb3\u504f\u7f6e\uff1a</p> <p>\u6bcf\u4e00\u4e2a\u6a21\u578b \u90fd\u6709\u81ea\u5df1\u7684\u5047\u8bbe\uff0c\u6216\u8005\u53eb \u5f52\u7eb3\u504f\u7f6e inductive bias\uff1b</p> <ul> <li>CNN\u7684\u5f52\u7eb3\u504f\u7f6e\u5c31\u662f \u5c40\u90e8\u5efa\u6a21\u6027 \u548c \u5e73\u79fb\u4e0d\u53d8\u6027</li> <li>RNN\u5c31\u662f\u524d\u540e\u5173\u8054\u6027</li> <li>Transformer\u6ca1\u6709\u4ec0\u4e48\u5047\u8bbe\uff0c\u53ea\u662f\u5f15\u5165\u4e86\u4e00\u4e2aposition embedding\u800c\u5df2</li> </ul> <p>\u5728\u6211\u4eec\u8fd9\u91cc\u5f15\u5165\u7684 group&gt;1\u7684\u8bdd\uff0c\u5f15\u5165\u7684\u5047\u8bbe\u662f\u4ec0\u4e48\u5462\uff1f</p> <p>\u6211\u4eec\u53ea\u9700\u8981\u4e00\u5c0f\u90e8\u5206\uff0c\u53ea\u9700\u8981\u505a\u4e00\u5c0f\u90e8\u5206 \u901a\u9053\u4e4b\u95f4\u7684\u5efa\u6a21\u5c31\u597d\u4e86\uff0c\u4e0d\u9700\u8981\u8003\u8651 \u6bcf\u4e2a\u901a\u9053 \u8ddf\u6240\u6709\u901a\u9053\u7684 \u5173\u7cfb\uff1b\u5176\u5b9e\u672c\u8d28\u4e0a group=1\u7684\u8bdd\uff0c\u5c31\u662f\u8bf4 in channel\uff0c\u6bcf\u4e2a\u901a\u9053 \u90fd\u9700\u8981 \u8ddf \u5176\u4ed6 \u901a\u9053 \u8fdb\u884c\u4e00\u4e2a\u6df7\u5408\uff1b\u4f46\u662f\u5f53\u6211\u4eec\u628a groups\uff0c\u8bbe\u7f6e\u6210&gt;1\u7684\u8bdd\uff0c\u5c31\u662f\u628a\u5b83\u4eec\u5206\u7ec4\u6765\u8003\u8651\uff0c\u5c31\u662f\u6bcf\u6b21\u5462\uff0c\u53ea\u5728\u51e0\u4e2a\u901a\u9053\u505a\u4e00\u4e0b\u5377\u79ef\uff1b\u7136\u540e\u4e0b\u6b21 \u518d\u53e6\u5916\u7684\u901a\u9053 \u505a\u5377\u79ef\uff1b\u7136\u540e\u628a\u7ed3\u679c\u62fc\u8d77\u6765 \u5c31\u597d\u4e86\uff1b\u4e5f\u5c31\u662f\u8bf4 \u901a\u9053\u878d\u5408 \u5e76\u4e0d\u5145\u5206\uff1b\u7b80\u5355\u8bf4 \u5c31\u662f \u8fd9\u6837\u7684</p> <p>\u518d\u91cd\u590d\uff1agroups&gt;1\uff0c\u5c31\u662f\u8bf4 \u901a\u9053\u878d\u5408 \u4e0d\u9700\u8981 \u5b8c\u5168 \u5145\u5206\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5728\u4e00\u4e2a\u4e2agroup\u5185\u8fdb\u884c\u878d\u5408\uff0c\u6700\u540e\u62fc\u63a5\uff0c\u8fd9\u5c31\u662fgroup convolution \u5f15\u5165\u7684\u4e00\u4e2a\u504f\u7f6e</p> <p>\u5176\u5b9e\u8fd9\u4e2a\u504f\u7f6e\u4e5f\u5f88\u597d\u89e3\u51b3\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5728group convolution\u540e\u9762\uff0c\u518d\u52a0\u4e0a\u4e00\u4e2a 1\u00d71 point wise\u5377\u79ef\u5c31\u597d\u4e86 </p> <p>\u5c31\u662f\u8bf4 1\u00d71\u7684\u9010\u70b9\u5377\u79ef\uff0c\u867d\u7136\u6ca1\u6709\u8003\u8651 \u5c40\u90e8\u5efa\u6a21\uff0c\u4f46\u662f\u5b83\u80fd\u5bf9\u901a\u9053\u4e4b\u95f4 \u8fdb\u884c\u878d\u5408\uff1b\u6240\u4ee5\u6700\u540e \u6211\u4eec\u8fd8\u662f\u80fd\u591f\u628a \u901a\u9053\u4e4b\u95f4 \u8fdb\u884c\u878d\u5408\u7684</p> <p>\u5206\u7ec4\u5377\u79ef &amp; \u9010\u70b9\u5377\u79ef</p> <p>add \u5404\u79cdwise </p> <ul> <li>\u6211\u4eec\u518d\u8bf4\u4e00\u4e0b \u8fd9\u91cc\u7684wise\uff0c\u4e00\u65e6\u770b\u5230\u5404\u79cd wise\uff0c\u5c31\u662f\u8bf4 \u6211\u4eec\u53ea\u8003\u8651wise\u524d\u9762\u8fd9\u4e2a\u4e1c\u897f\uff1b</li> <li>\u6bd4\u65b9\u8bf4\uff1bpoint wise\u5c31\u662f\u8bf4 \u6211\u4eec\u53ea\u5bf9 \u4e00\u4e2a\u70b9 \u53bb\u7b97 \u76f8\u4e58\uff0c\u800c\u4e0d\u662f\u8bf4 \u50cf \u666e\u901a\u7684\u5377\u79ef\u4e00\u6837\uff0c\u53d6\u4e00\u4e2a3\u00d73\u7684\u533a\u57df\uff1b\u90a3\u5c31\u4e0d\u662f\u4e00\u4e2a\u70b9\uff1b</li> <li>\u8fd8\u6bd4\u5982\u8bf4 channel wise\uff0c\u6211\u4eec\u53ea\u5bf9\u4e00\u4e2a\u901a\u9053\uff1b\uff08\u6709\u70b9\u50cf \u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\uff09</li> <li>\u6bd4\u5982\u8bf4layer wise\uff0c\u6211\u4eec\u53ea\u5bf9\u4e00\u5c42\u8003\u8651\u7b49\u7b49\uff1b</li> <li>\u5404\u79cd wise\uff0c\u6bd4\u5982element wise \u53ea\u5bf9\u5143\u7d20\u8ddf\u5143\u7d20\u4e4b\u95f4\uff1b\u76f8\u540c\u4f4d\u7f6e\u7684\u5143\u7d20\u8fdb\u884c\u8003\u8651\uff1b</li> </ul>"},{"location":"learning/convs/#_7","title":"\u5206\u7ec4\u5377\u79ef\u4e2d\u7684\u53d8\u4e0e\u4e0d\u53d8","text":"<p>\u9898\u8bbe\uff1a in channel\u548cout channel\u5206\u522b\u7b49\u4e8e2\u548c4\uff0c\u5206\u6790group=1\u548cgroup=2</p> <p>case1 \uff1agroup=1\uff0c\u4e00\u5171\u662f8\u5f20kernel map\uff0c\uff084\u4e2a\u5377\u79ef\u6838\uff0c\u6bcf\u4e2akernel\u901a\u9053\u6570\u7b49\u4e8e2\uff09 </p> <p>\u9996\u5148\u6211\u4eec\u62ff\u51fa\u4e24\u5f20kernel map \u5206\u522b\u4e0einput\u8fdb\u884c\u5377\u79ef\uff0c\u7136\u540e\u52a0\u8d77\u6765\uff0c\u52a0\u8d77\u6765\u7684\u7ed3\u679c\u8d4b\u7ed9\u7b2c\u4e00\u4e2a\u901a\u9053\uff1b\u518d\u62ff\u4e24\u4e2a\u5377\u79ef\u6838\uff0c\u540c\u6837\u8ddf\u8f93\u5165\u7684\u4e24\u4e2a\u901a\u9053\u8fdb\u884c\u5377\u79ef\uff0c\u7136\u540e\u52a0\u8d77\u6765\uff0c\u8d4b\u503c\u7ed9\u7b2c\u4e8c\u4e2a\u901a\u9053\uff0c\u4ee5\u6b64\u7c7b\u63a8\uff0c\u76f4\u5230\u6211\u4eec\u62ff\u51fa\u6700\u540e\u7684\u4e24\u4e2a\u5377\u79ef\u6838 \u8ddf \u8f93\u5165\u4e24\u4e2a\u7279\u5f81\u56fe \u8fdb\u884c\u5377\u79ef\uff0c\u7136\u540e\u518d\u6c42\u548c \u8d4b\u503c\u7ed9 \u6700\u540e\u4e00\u4e2a\u901a\u9053\uff1b\u6240\u4ee5\u4e00\u5171\u662f8\u5f20kernel map</p> <p>case2 \uff1agroups=2\uff0c\u4e00\u5171\u662f4\u5f20kernel map\uff0c\uff084\u4e2a\u5377\u79ef\u6838\uff0c\u6bcf\u4e2akernel\u7684\u901a\u9053\u6570=1\uff09 </p> <p>\uff1ain channels=2\uff0cgroups=2\uff0c\u5982\u679c\u8fd8\u8ba9output channel=4\uff0c\u90a3\u4e48kernel map\u6709\u51e0\u5f20\uff1f\u5377\u79ef\u6838\u6709\u51e0\u4e2a\uff1f</p> <p>\u9996\u5148\uff0c<code>#\u5377\u79ef\u6838</code>   $ \\stackrel{\u51b3\u5b9a}{\\rightarrow} $ <code>#\u8f93\u51fa\u901a\u9053\u6570</code>  \u3001<code>#\u8f93\u5165\u901a\u9053\u6570</code>   $ \\stackrel{\u51b3\u5b9a}{\\rightarrow} $  <code>#\u5355\u4e2a\u5377\u79ef\u6838\u901a\u9053\u6570</code></p> <p>\u2234 \u67094\u4e2a\u5377\u79ef\u6838\uff0c\u6bcf\u4e2a\u5377\u79ef\u6838\u7684channels=1\uff0c\uff08\u2235\u628a\u8f93\u5165\u901a\u9053\u6570\u5206\u62102\u7ec4\uff0c\u6240\u4ee5\u8f93\u5165\u901a\u9053\u6570\u53d8\u6210 2\u00f72=1 \uff09</p> <p>\u2234\u67094\u5f20kernel map </p> <p>\u7efc\u4e0a\uff1a </p> <ol> <li>kernel map\u51cf\u5c11\u4e00\u534a || \u5728\u6bcf\u4e00\u7ec4\u4e2d\uff0c\u5176\u5b9e\u6709\u4e24\u4e2a\u5377\u79ef\u6838\uff0c\u6240\u4ee5\u4e24\u7ec4 \u4e00\u5171\u662f 4\u4e2a kernel map\uff0c\u76f8\u6bd4\u4e0a\u9762 8\u4e2akernel map \u5c31\u5c11\u4e86\u4e00\u534a\uff08kernel map\u3001\u53c2\u6570\u91cf\u3001\u8fd0\u7b97\u91cf\u51cf\u534a\uff09</li> <li>\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u9ad8\u5ea6 &amp; \u5bbd\u5ea6 \u4e0d\u53d8\uff0cbatch size\u4e0d\u53d8</li> </ol>"},{"location":"learning/convs/#dilationgroups","title":"\u4ee3\u7801\u5b9e\u73b0 dilation&amp;groups \u624b\u6495 &amp; \u5e93\u51fd\u6570","text":"Python<pre><code>def matrix_multiplication_for_conv2d_finall(input,kernel,bias=None,stride=1,padding=0,dilation=1,groups=1):\n    if padding&gt;0:\n        input = F.pad(input,(padding,padding,padding,padding,0,0,0,0))\n\n    bs,in_channel,input_h,input_w = input.shape\n    out_channel,_,kernel_h,kernel_w = kernel.shape\n\n    assert out_channel % groups == 0 and in_channel % groups==0,\"groups\u5fc5\u987b\u8981\u540c\u65f6\u88ab\u8f93\u5165\u901a\u9053\u548c\u8f93\u51fa\u901a\u9053\u6570\u6574\u9664\uff01\"\n    input = input.reshape((bs,groups,in_channel//groups,input_h,input_w))\n    kernel = kernel.reshape((groups,out_channel//groups,in_channel//groups,kernel_h,kernel_w))\n\n    kernel_h = (kernel_h-1)*(dilation-1)+kernel_h\n    kernel_w = (kernel_w-1)*(dilation-1)+kernel_w\n\n    output_h = math.floor((input_h-kernel_h)/stride)+1\n    output_w = math.floor((input_w-kernel_w)/stride)+1\n\n    output_shape = (bs,groups,out_channel//groups,output_h,output_w)\n    output = torch.zeros(output_shape)\n\n    if bias is None:\n        bias = torch.zeros(out_channel)\n\n    for ind in range(bs): # \u5bf9batch size\u8fdb\u884c\u904d\u5386\n        for g in range(groups): # \u5bf9\u7fa4\u7ec4\u8fdb\u884c\u904d\u5386\n            for oc in range(out_channel//groups): # \u5bf9\u5206\u7ec4\u540e\u7684\u8f93\u51fa\u901a\u9053\u8fdb\u884c\u904d\u5386\n                for ic in range(in_channel//groups): # \u5bf9\u5206\u7ec4\u540e\u7684\u8f93\u5165\u901a\u9053\u8fdb\u884c\u904d\u5386\n                    for i in range(0,input_h-kernel_h+1,stride): #\u5bf9\u9ad8\u5ea6\u904d\u5386\n                        for j in range(0,input_w-kernel_w+1,stride): # \u5bf9\u5bbd\u5ea6\u904d\u5386\n                            region = input[ind,g,ic,i:i+kernel_h:dilation,j:j+kernel_w:dilation] #\u7279\u5f81\u533a\u57df\n                            output[ind,g,oc,int(i/stride),int(j/stride)] += torch.sum(region*kernel[g,oc,ic])\n\n                output[ind,g,oc] += bias[g*(out_channel//groups)+oc]  # \u8003\u8651\u504f\u7f6e\u9879\n    output = output.reshape((bs,out_channel,output_h,output_w))  # \u8fd8\u539f\u6210\u56db\u7ef4\u5f20\u91cf\n    return output\n\n# \u9a8c\u8bc1\u6d4b\u8bd5\u7684\u4ee3\u7801\nkernel_size=3\nbs,in_channel,input_h,input_w = 2,2,5,5\nout_channel=4\ngroups,dilation,stride,padding=2,2,2,1\n\ninput = torch.randn(bs,in_channel,input_h,input_w)\nkernel = torch.randn(out_channel,in_channel//groups,kernel_size,kernel_size)\nbias = torch.randn(out_channel)\n\n# pytorch API\u7684\u7ed3\u679c\npytorch_conv2d_api_output = F.conv2d(input,kernel,bias=bias,padding=padding,\n                                     stride=stride,dilation=dilation,groups=groups)\nmm_conv2d_finall_output = matrix_multiplication_for_conv2d_finall(input,kernel,bias=bias,padding=padding,\n                                                                  stride=stride,dilation=dilation,groups=groups)\n\nflag = torch.allclose(pytorch_conv2d_api_output,mm_conv2d_finall_output)\nprint(flag)\n</code></pre>"},{"location":"learning/convs/#6","title":"6 \u6c47\u603b\u4ee3\u7801","text":"<p>\u5e93\u51fd\u6570\u5b9e\u73b0\u5377\u79ef</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nin_channels = 1\nout_channels = 1\nkernel_size = 3\nbatch_size = 1\nbias = False\n\ninput_size = [batch_size,in_channels,4,4]\n\n# \u7b2c\u4e00\u79cd\u5b9e\u73b0\nconv_layer = torch.nn.Conv2d(in_channels,out_channels,kernel_size,bias=bias)\n\ninput_feature_map = torch.randn(input_size)\nout_feature_map = conv_layer(input_feature_map)\n# print(input_feature_map)\n# print(conv_layer.weight)  # 1*1*3*3=out_channels*in_channels*height*width\n\nprint(out_feature_map)\n\nout_feature_map1 = F.conv2d(input_feature_map,conv_layer.weight)\n\nprint(out_feature_map1)\n</code></pre> <p>step1 \u7528\u539f\u59cb\u7684\u77e9\u9635\u8fd0\u7b97\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5148\u4e0d\u8003\u8651 batch size\u7ef4\u5ea6 \u548c channel\u7ef4\u5ea6</p> <p>step2 \u7528\u539f\u59cb\u7684\u77e9\u9635\u8fd0\u7b97\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5148\u4e0d\u8003\u8651 batch size\u7ef4\u5ea6 \u548c channel\u7ef4\u5ea6\uff0cflatten\u7248\u672c</p> Python<pre><code>input = torch.randn(5,5) # \u5377\u79ef \u8f93\u5165\u7279\u5f81\u56fe\nkernel = torch.randn(3,3) # \u5377\u79ef\u6838\nbias = torch.randn(1) # \u5377\u79ef\u504f\u7f6e\uff0c\u9ed8\u8ba4\u8f93\u51fa\u901a\u9053\u6570\u76ee\u7b49\u4e8e1\n\n# step1 \u7528\u539f\u59cb\u7684\u77e9\u9635\u8fd0\u7b97\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5148\u4e0d\u8003\u8651 batch size\u7ef4\u5ea6 \u548c channel\u7ef4\u5ea6\ndef matrix_multiplication_for_conv2d(input,kernel,bias=0,stride=1,padding=0):\n\n  if padding &gt;0:\n    input = F.pad(input,(padding,padding,padding,padding))\n\n\n  input_h,input_w = input.shape\n  kernel_h,kernel_w = kernel.shape\n\n  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u9ad8\u5ea6\n  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u5bbd\u5ea6 \n  output = torch.zeros(output_h,output_w) # \u521d\u59cb\u5316 \u8f93\u51fa\u77e9\u9635\n\n  for i in range(0,input_h - kernel_h + 1,stride): # \u5bf9\u9ad8\u5ea6\u8fdb\u884c\u904d\u5386\n    for j in range(0,input_w - kernel_w +1,stride):  # \u5bf9\u5bbd\u5ea6\u7ef4\u8fdb\u884c\u904d\u5386\n      region = input[i:i+kernel_h, j:j+kernel_w]  # \u53d6\u51fa\u88ab\u6838\u6ed1\u52a8\u5230\u7684\u533a\u57df\n      output[int(i/stride),int(j/stride)] = torch.sum(region * kernel) + bias # \u70b9\u4e58 \u5e76\u8d4b\u503c\u7ed9\u8f93\u51fa\u4f4d\u7f6e\u7684\u5143\u7d20 \n\n  return output\n\n\n# step2 \u7528\u539f\u59cb\u7684\u77e9\u9635\u8fd0\u7b97\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5148\u4e0d\u8003\u8651 batch size\u7ef4\u5ea6 \u548c channel\u7ef4\u5ea6\uff0cflatten\u7248\u672c\ndef matrix_multiplication_for_conv2d_flatten(input,kernel,bias=0,stride=1,padding=0):\n\n  if padding &gt;0:\n    input = F.pad(input,(padding,padding,padding,padding))\n\n\n  input_h,input_w = input.shape\n  kernel_h,kernel_w = kernel.shape\n\n  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u9ad8\u5ea6\n  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u5bbd\u5ea6 \n  output = torch.zeros(output_h,output_w) # \u521d\u59cb\u5316 \u8f93\u51fa\u77e9\u9635\n\n  region_matrix = torch.zeros(output.numel(),kernel.numel()) #\u5b58\u50a8\u7740\u6240\u6709\u62c9\u5e73\u540e\u7279\u5f81\u533a\u57df\n  kernel_matrix = kernel.reshape(kernel.numel(),1) # \u5b58\u50a8\u7740kernel\u7684 \u5217\u5411\u91cf\uff08\u77e9\u9635\uff09\u5f62\u5f0f\n  row_index = 0\n\n  for i in range(0,input_h - kernel_h + 1,stride): # \u5bf9\u9ad8\u5ea6\u8fdb\u884c\u904d\u5386\n    for j in range(0,input_w - kernel_w +1,stride):  # \u5bf9\u5bbd\u5ea6\u7ef4\u8fdb\u884c\u904d\u5386\n      region = input[i:i+kernel_h, j:j+kernel_w]  # \u53d6\u51fa\u88ab\u6838\u6ed1\u52a8\u5230\u7684\u533a\u57df\n      region_vector = torch.flatten(region)\n      region_matrix[row_index] = region_vector\n      row_index +=1\n\n  output_matrix = region_matrix @ kernel_matrix\n  output = output_matrix.reshape((output_h,output_w))+bias\n\n  return output\n\n\n# \u77e9\u9635\u8fd0\u7b97\u5b9e\u73b0\u5377\u79ef\u7684\u7ed3\u679c\nmat_mul_conv_output = matrix_multiplication_for_conv2d(input,kernel,bias = bias,stride=2,padding=1)\n# print(mat_mul_conv_output)\n\n# \u8c03\u7528pytorch api\u5377\u79ef\u7684\u7ed3\u679c\npytorch_api_conv_output = F.conv2d(input.reshape((1,1,input.shape[0],input.shape[1])),\n                                   kernel.reshape((1,1,kernel.shape[0],kernel.shape[1])),\n                                   padding=1,bias=bias,stride=2).squeeze(0).squeeze(0)\n\n# \u77e9\u9635\u8fd0\u7b97\u5b9e\u73b0\u5377\u79ef\u7684\u7ed3\u679c flatten input\u7248\u672c\nmat_mul_conv_output_flatten = matrix_multiplication_for_conv2d_flatten(input,kernel,bias = bias,stride=2,padding=1)\n# \u9a8c\u8bc1\u4e86 flatten\u7248\u672c\u5377\u79ef \u4e0e pytorch \u5b98\u65b9\u5377\u79ef\u7684\u7ed3\u679c\uff0c\u6b63\u786e\nflag1 = torch.allclose(mat_mul_conv_output,pytorch_api_conv_output)\nflag2 = torch.allclose(mat_mul_conv_output_flatten,pytorch_api_conv_output)\nprint(flag1)\nprint(flag2)\n</code></pre> <p>step3 \u7528\u539f\u59cb\u7684\u77e9\u9635\u8fd0\u7b97\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u8003\u8651 batch size\u7ef4\u5ea6 \u548c channel\u7ef4\u5ea6</p> Python<pre><code># step3 \u7528\u539f\u59cb\u7684\u77e9\u9635\u8fd0\u7b97\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u8003\u8651 batch size\u7ef4\u5ea6 \u548c channel\u7ef4\u5ea6\ndef matrix_multiplication_for_conv2d_full(input,kernel,bias=0,stride=1,padding=0):\n\n  # input kernel \u90fd\u662f4\u7ef4\u5f20\u91cf\n  if padding &gt;0:\n    input = F.pad(input,(padding,padding,padding,padding,0,0,0,0))\n\n  bs,in_channel,input_h,input_w = input.shape\n  out_channel,in_channel,kernel_h,kernel_w = kernel.shape\n\n  if bias is None:\n    bias = torch.zeros(out_channel)\n\n\n  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u9ad8\u5ea6\n  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # \u5377\u79ef\u8f93\u51fa\u7684\u5bbd\u5ea6 \n  output = torch.zeros(bs,out_channel,output_h,output_w) # \u521d\u59cb\u5316 \u8f93\u51fa\u77e9\u9635\n\n\n  for ind in range(bs):\n    for oc in range(out_channel):\n      for ic in range(in_channel):\n        for i in range(0,input_h - kernel_h + 1,stride): # \u5bf9\u9ad8\u5ea6\u8fdb\u884c\u904d\u5386\n          for j in range(0,input_w - kernel_w +1,stride):  # \u5bf9\u5bbd\u5ea6\u7ef4\u8fdb\u884c\u904d\u5386\n            region = input[ind,ic,i:i+kernel_h, j:j+kernel_w]  # \u53d6\u51fa\u88ab\u6838\u6ed1\u52a8\u5230\u7684\u533a\u57df\n            output[ind,oc,int(i/stride),int(j/stride)] += torch.sum(region * kernel[oc,ic]) # \u70b9\u4e58 \u5e76\u8d4b\u503c\u7ed9\u8f93\u51fa\u4f4d\u7f6e\u7684\u5143\u7d20 \n      output[ind,oc] += bias[oc]\n  return output\n\ninput = torch.randn(2,2,5,5)  # bs*in_channel*in_h*in_w\nkernel = torch.randn(3,2,3,3) # out_channel*in_channel*kernel_h*kernel_w\nbias = torch.randn(3)\n\n# \u9a8c\u8bc1matrxi_multiplication_for_conv2d_full\u4e0e\u5b98\u65b9API\u7ed3\u679c\u662f\u5426\u4e00\u81f4\npytorch_api_conv_output = F.conv2d(input,kernel,bias=bias,padding=1,stride=2)\nmm_conv2d_full_output = matrix_multiplication_for_conv2d_full(input,kernel,bias=bias,padding=1,stride=2)\nflag = torch.allclose(pytorch_api_conv_output,mm_conv2d_full_output)\nprint(\"all close:\",flag)\n</code></pre> <p>step4 \u901a\u8fc7\u5bf9kernel\u8fdb\u884c\u5c55\u5f00\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5e76\u63a8\u5bfc\u51fa\u8f6c\u7f6e\u5377\u79ef\uff0c\u4e0d\u8003\u8651batch\u3001channel\u5927\u5c0f\uff0c\u4e0d\u8003\u8651padding\uff0c\u5047\u8bbestride=1</p> Python<pre><code># step4 \u901a\u8fc7\u5bf9kernel\u8fdb\u884c\u5c55\u5f00\u6765\u5b9e\u73b0\u4e8c\u7ef4\u5377\u79ef\uff0c\u5e76\u63a8\u5bfc\u51fa\u8f6c\u7f6e\u5377\u79ef\uff0c\u4e0d\u8003\u8651batch\u3001channel\u5927\u5c0f\uff0c\u4e0d\u8003\u8651padding\uff0c\u5047\u8bbestride=1\ndef get_kernel_matrix(kernel,input_size):\n    # \u57fa\u4e8ekernel\u548c\u8f93\u5165\u7279\u5f81\u56fe\u7684\u5927\u5c0f\u6765\u5f97\u5230\u586b\u5145\u62c9\u76f4\u540e\u7684kernel\u5806\u53e0\u540e\u7684\u77e9\u9635\n    kernel_h,kernel_w = kernel.shape\n    input_h,input_w = input.shape\n    num_out_fea_map = (input_h-kernel_h+1)*(input_w-kernel_w+1)  # \u5377\u79ef\u516c\u5f0f\n    result = torch.zeros((num_out_fea_map,input_h*input_w)) #\u521d\u59cb\u5316\u7ed3\u679c\u77e9\u9635\uff0c\u8f93\u51fa\u7279\u5f81\u56fe\u5143\u7d20\u4e2a\u6570*\u8f93\u5165\u7279\u5f81\u56fe\u5143\u7d20\u4e2a\u6570\n    count = 0\n    for i in range(0,input_h-kernel_h+1,1):\n        for j in range(0,input_w - kernel_w +1,1):\n            # \u586b\u5145\u6210 \u8ddf \u8f93\u5165\u7279\u5f81\u56fe\u4e00\u6837\u5927\u5c0f\n            # padded_kernel = F.pad(kernel,(i,input_h-kernel_h-i,j,input_w-kernel_w-j))\n            padded_kernel = F.pad(kernel,(j,input_h-kernel_h-j,i,input_w-kernel_w-i))\n            result[count] = padded_kernel.flatten()\n            count +=1\n    return result  \n\n\n\n# \u6d4b\u8bd51\uff1a\u9a8c\u8bc1 \u4e8c\u7ef4\u5377\u79ef\nkernel = torch.randn(3,3)\ninput = torch.randn(4,4)\nkernel_matrix = get_kernel_matrix(kernel,input.shape)  # 4*16\n\n# \u901a\u8fc7\u77e9\u9635\u76f8\u4e58\u6765\u8ba1\u7b97\u5377\u79ef\nmm_conv2d_output = kernel_matrix @ input.reshape((-1,1))  \n\n# pytorch conv2d API\npytorch_conv2d_output = F.conv2d(input.unsqueeze(0).unsqueeze(0),kernel.unsqueeze(0).unsqueeze(0))\n# print(kernel)\n# print(kernel_matrix)\n# print(mm_conv2d_output)\n# print(pytorch_conv2d_output)\n\n# \u6d4b\u8bd52  \u901a\u8fc7\u77e9\u9635\u4e58\u79ef\u6765\u8ba1\u7b97\u8f6c\u7f6e\u5377\u79ef || \u9a8c\u8bc1\u4e8c\u7ef4\u8f6c\u7f6e\u5377\u79ef\nmm_transposed_conv2d_output = kernel_matrix.transpose(-1,-2) @ mm_conv2d_output\npytorch_transposed_conv2d_conv2d = F.conv_transpose2d(pytorch_conv2d_output,kernel.unsqueeze(0).unsqueeze(0))  #API\nprint(mm_transposed_conv2d_output.reshape(4,4))\nprint(pytorch_transposed_conv2d_conv2d)\n</code></pre> <p>\u5206\u7ec4\u5377\u79ef&amp;\u81a8\u80c0\u5377\u79ef</p> Python<pre><code>def matrix_multiplication_for_conv2d_finall(input,kernel,bias=None,stride=1,\n                                            padding=0,dilation=1,groups=1):\n    if padding&gt;0:\n        input = F.pad(input,(padding,padding,padding,padding,0,0,0,0))\n\n    bs,in_channel,input_h,input_w = input.shape\n    out_channel,_,kernel_h,kernel_w = kernel.shape\n\n    assert out_channel % groups == 0 and in_channel % groups==0,\"groups\u5fc5\u987b\u8981\u540c\u65f6\u88ab\u8f93\u5165\u901a\u9053\u548c\u8f93\u51fa\u901a\u9053\u6570\u6574\u9664\uff01\"\n    input = input.reshape((bs,groups,in_channel//groups,input_h,input_w))\n    kernel = kernel.reshape((groups,out_channel//groups,in_channel//groups,kernel_h,kernel_w))\n\n    kernel_h = (kernel_h-1)*(dilation-1)+kernel_h\n    kernel_w = (kernel_w-1)*(dilation-1)+kernel_w\n\n    output_h = math.floor((input_h-kernel_h)/stride)+1\n    output_w = math.floor((input_w-kernel_w)/stride)+1\n\n    output_shape = (bs,groups,out_channel//groups,output_h,output_w)\n    output = torch.zeros(output_shape)\n\n    if bias is None:\n        bias = torch.zeros(out_channel)\n\n    for ind in range(bs): # \u5bf9batch size\u8fdb\u884c\u904d\u5386\n        for g in range(groups): # \u5bf9\u7fa4\u7ec4\u8fdb\u884c\u904d\u5386\n            for oc in range(out_channel//groups): # \u5bf9\u5206\u7ec4\u540e\u7684\u8f93\u51fa\u901a\u9053\u8fdb\u884c\u904d\u5386\n                for ic in range(in_channel//groups): # \u5bf9\u5206\u7ec4\u540e\u7684\u8f93\u5165\u901a\u9053\u8fdb\u884c\u904d\u5386\n                    for i in range(0,input_h-kernel_h+1,stride): #\u5bf9\u9ad8\u5ea6\u904d\u5386\n                        for j in range(0,input_w-kernel_w+1,stride): # \u5bf9\u5bbd\u5ea6\u904d\u5386\n                            region = input[ind,g,ic,i:i+kernel_h:dilation,j:j+kernel_w:dilation] #\u7279\u5f81\u533a\u57df\n                            output[ind,g,oc,int(i/stride),int(j/stride)] += torch.sum(region*kernel[g,oc,ic])\n\n                output[ind,g,oc] += bias[g*(out_channel//groups)+oc]  # \u8003\u8651\u504f\u7f6e\u9879\n    output = output.reshape((bs,out_channel,output_h,output_w))  # \u8fd8\u539f\u6210\u56db\u7ef4\u5f20\u91cf\n    return output\n\n# \u9a8c\u8bc1\u6d4b\u8bd5\u7684\u4ee3\u7801\nkernel_size=3\nbs,in_channel,input_h,input_w = 2,2,5,5\nout_channel=4\ngroups,dilation,stride,padding=2,2,2,1\n\ninput = torch.randn(bs,in_channel,input_h,input_w)\nkernel = torch.randn(out_channel,in_channel//groups,kernel_size,kernel_size)\nbias = torch.randn(out_channel)\n\n# pytorch API\u7684\u7ed3\u679c\npytorch_conv2d_api_output = F.conv2d(input,kernel,bias=bias,padding=padding,\n                                     stride=stride,dilation=dilation,groups=groups)\nmm_conv2d_finall_output = matrix_multiplication_for_conv2d_finall(input,kernel,bias=bias,padding=padding,\n                                                                  stride=stride,dilation=dilation,groups=groups)\n\nflag = torch.allclose(pytorch_conv2d_api_output,mm_conv2d_finall_output)\nprint(flag)\n</code></pre>"},{"location":"learning/convs/#7-1d","title":"7 1D \u5377\u79ef","text":""},{"location":"learning/convs/#8","title":"8 \u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef","text":"<p>2025.2.20</p> <p>\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\uff08Depthwise Separable Convolution\uff09\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5377\u79ef\u64cd\u4f5c\uff0c\u5b83\u5c06\u6807\u51c6\u5377\u79ef\u5206\u89e3\u4e3a\u4e24\u4e2a\u66f4\u7b80\u5355\u7684\u64cd\u4f5c\uff1a\u6df1\u5ea6\u5377\u79ef\uff08Depthwise Convolution\uff09\u548c\u9010\u70b9\u5377\u79ef\uff08Pointwise Convolution\uff09\u3002</p> <p>\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u7684\u5b9a\u4e49</p> <p>\u6df1\u5ea6\u5377\u79ef\uff08Depthwise Convolution\uff09\uff1a</p> <ul> <li>\u5bf9\u6bcf\u4e2a\u8f93\u5165\u901a\u9053\u5206\u522b\u8fdb\u884c\u5377\u79ef\u64cd\u4f5c\uff0c\u800c\u4e0d\u662f\u5bf9\u6240\u6709\u901a\u9053\u8fdb\u884c\u5377\u79ef\u3002</li> <li>\u8fd9\u610f\u5473\u7740\u6bcf\u4e2a\u5377\u79ef\u6838\u53ea\u4f5c\u7528\u4e8e\u4e00\u4e2a\u8f93\u5165\u901a\u9053\uff0c\u8f93\u51fa\u7684\u901a\u9053\u6570\u4e0e\u8f93\u5165\u7684\u901a\u9053\u6570\u76f8\u540c\u3002</li> </ul> <p>\u9010\u70b9\u5377\u79ef\uff08Pointwise Convolution\uff09\uff1a</p> <ul> <li>\u4f7f\u7528 <code>1x1</code> \u5377\u79ef\u6838\u5bf9\u6df1\u5ea6\u5377\u79ef\u7684\u8f93\u51fa\u8fdb\u884c\u5377\u79ef\u64cd\u4f5c\u3002</li> <li>\u9010\u70b9\u5377\u79ef\u7528\u4e8e\u5c06\u4e0d\u540c\u901a\u9053\u7684\u4fe1\u606f\u8fdb\u884c\u7ebf\u6027\u7ec4\u5408\uff0c\u4ece\u800c\u751f\u6210\u65b0\u7684\u8f93\u51fa\u901a\u9053\u3002</li> </ul> Python<pre><code>import torch\nimport torch.nn as nn\n\nclass DepthwiseSeparableConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n        super(DepthwiseSeparableConv, self).__init__()\n        # \u6df1\u5ea6\u5377\u79ef\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n                                   stride=stride, padding=padding, groups=in_channels)\n        # \u9010\u70b9\u5377\u79ef\n        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        return x\n\n# \u793a\u4f8b\u8f93\u5165\nx = torch.randn(1, 64, 32, 32)  # (batch_size, in_channels, height, width)\n\n# \u5b9e\u4f8b\u5316\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\nmodel = DepthwiseSeparableConv(in_channels=64, out_channels=128)\n\n# \u524d\u5411\u4f20\u64ad\noutput = model(x)\nprint(output.shape)  # \u8f93\u51fa\u5f62\u72b6\u5e94\u4e3a (1, 128, 32, 32)\n</code></pre> <p>\u6df1\u5ea6\u5377\u79ef\uff1a</p> Python<pre><code>self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n                           stride=stride, padding=padding, groups=in_channels)\n</code></pre> <ul> <li>groups=in_channels\u8868\u793a\u6bcf\u4e2a\u8f93\u5165\u901a\u9053\u90fd\u6709\u4e00\u4e2a\u72ec\u7acb\u7684\u5377\u79ef\u6838\u3002</li> <li>\u8fd9\u4e00\u6b65\u7684\u8f93\u51fa\u901a\u9053\u6570\u4e0e\u8f93\u5165\u901a\u9053\u6570\u76f8\u540c\u3002</li> </ul> <p>\u9010\u70b9\u5377\u79ef\uff1a</p> Python<pre><code>self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n</code></pre> <p>\u4f7f\u7528 <code>1x1</code> \u5377\u79ef\u6838\u5c06\u6df1\u5ea6\u5377\u79ef\u7684\u8f93\u51fa\u901a\u9053\u6570\u8f6c\u6362\u4e3a\u6240\u9700\u7684\u8f93\u51fa\u901a\u9053\u6570\u3002</p> <p>\u524d\u5411\u4f20\u64ad\uff1a</p> Python<pre><code>def forward(self, x):\n    x = self.depthwise(x)\n    x = self.pointwise(x)\n    return x\n</code></pre> <p>\u5148\u8fdb\u884c\u6df1\u5ea6\u5377\u79ef\uff0c\u518d\u8fdb\u884c\u9010\u70b9\u5377\u79ef\u3002</p> <p>\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\uff0c\u5982 MobileNet \u548c Xception\uff0c\u7528\u4e8e\u51cf\u5c11\u8ba1\u7b97\u91cf\u548c\u53c2\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u597d\u7684\u6027\u80fd\u3002</p> <p></p>"},{"location":"learning/convs/#_8","title":"\u5377\u79ef\u8fc7\u540e\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5927\u5c0f","text":"<p>\u5206\u7ec4\u5176\u5b9e\u4e0d\u5f71\u54cd\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5927\u5c0f\uff0c\u4f1a\u5f71\u54cd\u5377\u79ef\u6838\u7684\u901a\u9053\u6570\uff0c\u4e5f\u4e0d\u5f71\u54cd\u5377\u79ef\u6838\u7684\u4e2a\u6570\uff0c\u4f1a\u5f71\u54cd\u5377\u79ef\u7684\u53c2\u6570\u91cf\uff0c\u56e0\u4e3a\u901a\u9053\u53d8\u5c11\u4e86</p> <p>\u6b63\u5e38\u5377\u79ef\uff1a</p> <p>\\(output_h = \\frac{h-k+2p+s}{s}\\)</p> Python<pre><code>import torch\nimport torch.nn as nn\n\n# \u5b9a\u4e49\u5206\u7ec4\u5377\u79ef\nconv = nn.Conv2d(64, 64, kernel_size=5, stride=2, padding=5//2, groups=64, bias=False)\n\n# \u793a\u4f8b\u8f93\u5165\nx = torch.randn(1, 64, 7, 7)\n\n# \u524d\u5411\u4f20\u64ad\noutput = conv(x)\n\n# \u6253\u5370\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5927\u5c0f\nprint(output.shape)  # \u8f93\u51fa\u5f62\u72b6\u5e94\u4e3a (1, 64, 4, 4)\n</code></pre> <p>\\(output_h = \\frac{input_h-k+s+2p}{s} =\\frac{7-5+2+2*p}{2}=\\frac{7-5+2+2*2}{2}=4\\) </p> <p>\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662f $ p = 5//2 = 2$</p> <p>\u6240\u4ee5\u5f53 \\(stride = 1\\) \u65f6\uff0c\\(padding = kernel\\_size //2\\) \u65f6\uff0c\u662f\u4e0d\u53d8\u5377\u79ef\uff08\u8f93\u5165\u7279\u5f81\u56fe\u5c3a\u5bf8 \u548c \u8f93\u51fa\u7279\u5f81\u56fe\u5c3a\u5bf8\u76f8\u540c\uff09</p> <p>\u5206\u7ec4\u53ea\u662f\u5377\u79ef\u6838\u7684\u53c2\u6570\u53d8\u5c11\u4e86\u3002</p> <ul> <li> \u81a8\u80c0\u5377\u79ef\u4e0e\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\uff1f</li> </ul> \\[ \\text{Output Size} = \\left\\lfloor \\frac{\\text{Input Size} + 2 \\times \\text{Padding} - \\text{Kernel Size}}{\\text{Stride}} \\right\\rfloor + 1 \\] <p>\u5bf9\u4e8e\u8f93\u5165\u7279\u5f81\u56fe\u5c3a\u5bf8\u4e3a 80x80\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a 3x3\uff0c\u6b65\u5e45\u4e3a 2\uff0c\u586b\u5145\u4e3a 1 \u7684\u60c5\u51b5</p> \\[ \\text{Output Size} = \\left\\lfloor \\frac{80 + 2 \\times 1 - 3}{2} \\right\\rfloor + 1 \\] <ul> <li>\u8ba1\u7b97\u62ec\u53f7\u5185\u7684\u503c:  \\(80 + 2 \\times 1 - 3 = 80 + 2 - 3 = 79\\) </li> <li>\u9664\u4ee5\u6b65\u5e45: \\(\\frac{79}{2}\\) = 39.5 </li> <li>\u53d6\u6574:  \\(\\left\\lfloor 39.5 \\right\\rfloor = 39\\) </li> <li>\u52a0 1:  \\(39 + 1 = 40\\) </li> </ul> <p>\u56e0\u6b64\uff0c\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u5c3a\u5bf8\u4e3a \\(40\u00d740\\)</p>"},{"location":"learning/pe/","title":"4\u79cd\u4f4d\u7f6e\u7f16\u7801","text":""},{"location":"learning/pe/#4","title":"4\u79cd\u4f4d\u7f6e\u7f16\u7801","text":"2024-11-25 22:33:462025-09-28 12:54:06 <p> \u7ea6 531 \u4e2a\u5b57  87 \u884c\u4ee3\u7801  9 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p> <ul> <li> \u4e00\u7ef4\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801</li> <li> \u4e00\u7ef4\u53ef\u5b66\u4e60\u4f4d\u7f6e\u7f16\u7801</li> <li> \u4e8c\u7ef4\u76f8\u5bf9\u504f\u7f6e\u4f4d\u7f6e\u7f16\u7801</li> <li> \u4e8c\u7ef4\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801</li> <li> \u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801</li> </ul>"},{"location":"learning/pe/#_1","title":"\u4f4d\u7f6e\u7f16\u7801\u4e3a\u4ec0\u4e48\u662f\u4e09\u89d2\u51fd\u6570\u5f62\u5f0f\u7684\uff1f","text":"<ol> <li>\u6700\u76f4\u89c2\u7684\u7f16\u7801\u65b9\u5f0f\u662f\u4ece0\u5230sequence length\uff0c\u4f46\u662f\u65e0\u754c</li> <li>\u7528 \\(\\frac{1}{sequence\\_length}\\) \u6539\u53d8\u4e86\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u76f8\u5bf9\u4f4d\u7f6e</li> <li>\u4e8c\u8fdb\u5236\u7f16\u7801\uff0cd model\u901a\u5e38\u8bbe\u7f6e\u4e3a512,2\u7684512\u6b21\u65b9\u80fd\u7f16\u7801\u5b8c max sequence length\u4e2a\u4f4d\u7f6e\uff0c\u4f46\u662f\u662f\u79bb\u6563\u7684</li> <li>\u8fde\u7eed\uff0c\u5e26\u6709\u5468\u671f\u6027\u7684\u4e09\u89d2\u51fd\u6570\u4f4d\u7f6e\u7f16\u7801\uff0c\u7c7b\u4f3c\u4e8c\u8fdb\u5236\uff0c\u4f4e\u4f4d\u53d8\u5316\u5feb\uff0c\u9ad8\u4f4d\u53d8\u5316\u6162</li> </ol> <p>\u301046\u3001\u56db\u79cdPosition Embedding\u7684\u539f\u7406\u4e0ePyTorch\u624b\u5199\u9010\u884c\u5b9e\u73b0\uff08Transformer/ViT/Swin-T/MAE\uff09-\u54d4\u54e9\u54d4\u54e9\u3011</p> <p></p>"},{"location":"learning/pe/#transformer","title":"\u539f\u59cbTransformer\u7684\u4f4d\u7f6e\u7f16\u7801 \uff1a\u4e00\u7ef4\u7edd\u5bf9\u3001\u5e38\u6570\u4f4d\u7f6e\u7f16\u7801","text":"<p>pos\uff1a\u53e5\u5b50\u4e2d\u8bcd\u7684\u4f4d\u7f6e\uff080-max sequence length\uff09</p> <p>i\uff1a\u8bcd\u5d4c\u5165\u4f4d\u7f6e\uff080\u2014255\uff09</p> <p>1D\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u5e38\u6570\u4e0d\u9700\u8981\u8bad\u7ec3</p> <p>\u4ee3\u7801\u5b9e\u73b0\uff1a</p> <p>(\u7c7b\u5199\u6cd5)</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SinCosPositionEmbedding(nn.Module):\n    def __init__(self, max_sequence_length,model_dim):\n        super().__init__()\n        self.max_sequence_length = max_sequence_length\n        self.model_dim = model_dim\n    def forward(self):\n        pe = torch.zeros(self.max_sequence_length,self.model_dim)\n        pos_mat = torch.arange(self.max_sequence_length).reshape(-1,1)\n        i_mat = torch.pow(10000,\n                          torch.arange(0,self.model_dim,2).reshape(1,-1)/self.model_dim\n                          )\n\n        pe[:,0::2] = torch.sin(pos_mat/i_mat)\n        pe[:,1::2] = torch.cos(pos_mat/i_mat)\n\n        return pe\nprint(SinCosPositionEmbedding(max_sequence_length=8,model_dim=4).forward())\n</code></pre> <p>\uff08\u51fd\u6570\u5199\u6cd5\uff09</p> Python<pre><code>def position_sincos_embedding(max_sequence_length,model_dim):\n    assert model_dim%2 == 0,\"wrong dimension\"\n    pe_table = torch.zeros(max_sequence_length,model_dim)\n    pos_mat = torch.arange(max_sequence_length).reshape(-1,1)\n    i_mat = torch.pow(\n        10000,\n        torch.arange(0,model_dim,2)/model_dim\n    )\n    pe_table[:,0::2]=torch.sin(pos_mat/i_mat)\n    pe_table[:,1::2]=torch.cos(pos_mat/i_mat)\n    return pe_table\n\n# Transformer\u8bba\u6587 \u4e00\u7ef4\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\nif __name__==\"__main__\":\n    max_sequence_length = 8\n    model_dim = 4\n    pe_table = position_sincos_embedding(max_sequence_length,model_dim)\n    print(pe_table)\n</code></pre>"},{"location":"learning/pe/#vit-1","title":"ViT  1\u7ef4\u7edd\u5bf9\u7684\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801","text":"<p>\u6807\u51c6\u7684\u3001\u53ef\u5b66\u4e60\u7684\u4e00\u7ef4\u4f4d\u7f6e\u7f16\u7801\uff1b\u4e8c\u7ef4\u7684\u4f4d\u7f6e\u7f16\u7801\u5e76\u6ca1\u6709\u5e26\u6765\u66f4\u597d\u7684\u6548\u679c</p> Python<pre><code>def create_1d_absolute_trainable_embeddings(max_sequence_length,model_dim):\n    pe = nn.Embedding(max_sequence_length,model_dim)\n    nn.init.constant_(pe.weight,0.)\n\n    return pe\n</code></pre>"},{"location":"learning/pe/#swintransformer-2","title":"SwinTransformer 2\u7ef4\u7684\u3001\u76f8\u5bf9\u7684\u3001\u57fa\u4e8e\u4f4d\u7f6e\u504f\u5dee\u53ef\u8bad\u7ec3\u7684\u4f4d\u7f6e\u7f16\u7801","text":"<ul> <li>\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u3001\u53ef\u5b66\u4e60\u7684\u3001\u76f8\u5bf9\u4f4d\u7f6e\u504f\u5dee\u52a0\u5230\u6bcf\u4e00\u4e2a\u5934\u4e0a</li> <li>\\(QK^T\\) \u7684\u7ef4\u5ea6\u662f \\(\u5e8f\u5217\u957f\u5ea6 \u00d7 \u5e8f\u5217\u957f\u5ea6\\)\uff0c\u6240\u4ee5B\u7684\u5f62\u72b6\u4e5f\u662f  \\(\u5e8f\u5217\u957f\u5ea6 \u00d7 \u5e8f\u5217\u957f\u5ea6\\)</li> <li>\u8003\u8651head\uff0c\u90a3\u4e48\u5f62\u72b6\u662f \\(num\\_head \\times L \\times L\\)</li> <li>\u7531\u4e8e\u662f\u53ef\u5b66\u4e60\u7684\uff0c\u8981\u8ba1\u7b97\u4e24\u4e24Patch\u7684\u504f\u5dee\uff0c\\(Position\\_bias\\)\uff0c\u628a\\(bias\\)\u5f53\u6210\u7d22\u5f15\uff0c\u4ece\\(bias\\_matrix\\)\u91cc\u67e5\u627e\u5230\\(learnable \\_ vector\\)\uff0c\u5373\u53ef\u5b66\u4e60\u7684\u5411\u91cf</li> <li>\u53ef\u4ee5\u770b\u5230 \u504f\u5dee\u77e9\u9635\u662f \\(\\hat{B} \\in \\mathbb{R}^{(2M-1) \\times (2M-1)}\\)</li> </ul> <p>\u4ee3\u7801\uff1a</p> <ul> <li> <p>\u9996\u5148\uff0c\u7531\u4e8e\u662f\u4e8c\u7ef4\u7684\uff0c\u6240\u4ee5\u65e2\u8981\u8003\u8651\u6a2a\u8f74\uff0c\u53c8\u8981\u8003\u8651\u7eb5\u8f74 </p> </li> <li> <p>\u4e8c\u7ef4\u3001\u76f8\u5bf9\u7684\u3001\u57fa\u4e8ebias\u7684\u3001\u53ef\u8bad\u7ec3\u7684\u4f4d\u7f6e\u7f16\u7801 <code>create_2d_relative_bias_trainable_embeddings</code></p> </li> </ul> Python<pre><code>def create_2d_relative_bias_trainable_embeddings(n_head,height,width,dim):\n    # width:5,[0,1,2,3,4],bias=[-width+1,width-1],2*width-1\n    # height:5,[0,1,2,3,4],bias=[-height+1,height-1],2*height-1\n\n    position_embedding = nn.Embedding((2*width-1)*(2*height-1),n_head)\n    nn.init.constant_(position_embedding.weight,0.)\n\n    def get_relative_position_index(height,width):\n        m1,m2 = torch.meshgrid(torch.arange(height),torch.arange(width))\n        coords = torch.stack(m1,m2) #[2,height,width]\n        coords_flatten = torch.flatten(coords,1) #[2,height*width]\n\n        # \u628a\u504f\u5dee\u53d8\u6210\u6b63\u6570\uff0c\u7136\u540e\u4eceposition_embedding\u4e2d\u6309\u7d22\u5f15\u53d6\u503c\n        relative_coords_bias = coords_flatten[:,:,None]-coords_flatten[:,None,:] # [2,height*width,height*width]\n\n        relative_coords_bias[0,:,:] += height-1\n        relative_coords_bias[1,:,:] += width-1\n\n        # A:2d,B:1d,B[[i*cols+j] = A[i,j]\n        relative_coords_bias[0,:,:] *= relative_coords_bias[1,:,:].max()+1\n\n        return relative_coords_bias.sum(0) # [height*width,height*width]\n    relative_position_bias = get_relative_position_index(height,width)\n    bias_embedding = position_embedding(torch.flatten(relative_position_bias)).reshape(height*width,height*width,n_head) #[height*width,height*width,n_head]\n\n    bias_embedding = position_embedding.permute(2,0,1).unsqueeze(0) # [1,n_head,height*width,height*width]\n\n    return bias_embedding\n</code></pre>"},{"location":"learning/pe/#mae","title":"MAE\u4e2d\u7684\u4f4d\u7f6e\u7f16\u7801","text":"<p>\u9644\u5f55\u90e8\u5206</p> <p></p> <ul> <li>sin\u3001cos\u4f4d\u7f6e\u7f16\u7801</li> <li>\u6ca1\u6709\u76f8\u5bf9\u4f4d\u7f6e\u6216\u8005Layer scaling</li> <li>\u4e8c\u7ef4\u7684\u3001\u7edd\u5bf9\u7684 sin cos embedding</li> </ul> Python<pre><code># 4.2d absolute constant sincos embedding\n# Masked AutoEncoder \u8bba\u6587\ndef create_2d_absolute_sincos_embeddings(height,width,dim):\n    assert dim%4 ==0,\"wrong dimension!\"\n    position_embedding = torch.zeros(height*width,dim)\n    m1,m2 = torch.meshgrid(torch.arrange(height,dtype=torch.float),torch.arrange(width,dtype=torch.float))\n    coords = torch.stack(m1,m2)  # [2,height*width]\n\n    height_embedding = create_1d_absolute_sincos_embeddings(torch.flatten(coords[0]),dim//2)  # [height*width,dim//2]\n    width_embedding = create_1d_absolute_sincos_embeddings(torch.flatten(coords[1]),dim//2)  # [height*width,dim//2]\n\n    position_embedding[:,:dim//2] = height_embedding\n    position_embedding[:,:dim//2] = width_embedding\n\n    return position_embedding\n</code></pre> <p>\u5168\u90e8\u4ee3\u7801</p> <p></p> <p></p> <p></p> <p></p> <ul> <li> \u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801</li> </ul>"},{"location":"learning/vit/","title":"vision Transformer\u7684\u539f\u7406\u4e0e\u96be\u70b9\u6e90\u7801\u5b9e\u73b0","text":""},{"location":"learning/vit/#vision-transformer","title":"vision Transformer\u7684\u539f\u7406\u4e0e\u96be\u70b9\u6e90\u7801\u5b9e\u73b0","text":"2024-11-15 20:00:582025-09-28 12:54:06 <p> \u7ea6 8101 \u4e2a\u5b57  419 \u884c\u4ee3\u7801  42 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 46 \u5206\u949f</p> <ul> <li> \u9739\u96f3\u5427\u5566z</li> </ul> <p>\u301028\u3001Vision Transformer(ViT)\u6a21\u578b\u539f\u7406\u53caPyTorch\u9010\u884c\u5b9e\u73b0-\u54d4\u54e9\u54d4\u54e9\u3011</p>"},{"location":"learning/vit/#1-transformer","title":"1 \u600e\u4e48\u4eceTransformer\u5e94\u7528\u5230\u56fe\u50cf\u8bc6\u522b","text":""},{"location":"learning/vit/#11-encoder","title":"1.1 encoder","text":"<p>\u9996\u5148\u4eceTransformer\u5f00\u59cb\uff0c\u9996\u5148Transformer\u662f\u4e00\u4e2asequence to sequence \u7684\u6846\u67b6\uff0c\u5b83\u5305\u542b encoder\u548cdecoder\u4e24\u4e2a\u90e8\u5206\uff0c\u65e0\u8bba\u662fencoder \u8fd8\u662f decoder\uff0c\u6838\u5fc3\u7684\u5efa\u6a21\u6a21\u5757 \u662f\u7531multihead self Attention\u548cfeed forward Neural network \u8fd9\u4e24\u4e2a\u90e8\u5206 \u6784\u6210\u7684\u3002</p> <p></p>"},{"location":"learning/vit/#111-mhsa-fnn","title":"1.1.1 MHSA\u505a\u7684\u662f \u7a7a\u95f4\u878d\u5408\uff1bFNN \u505a\u7684\u662f \u901a\u9053\u878d\u5408","text":"<p>\u90a3\u5177\u4f53\u6765\u770b\uff0cencoder \u90e8\u5206 \u5c31\u662f\u5c06\u6211\u4eec\u7684\u6e90\u5e8f\u5217\u9001\u5165\u5230 multihead self Attention\u548cFNN \u8fd9\u4e24\u4e2a\u6a21\u5757\u91cc\uff0c\u8fd9\u4e24\u4e2a\u6a21\u5757\u6784\u6210\u4e00\u5c42\uff0c\u90a3\u4e48encoder\u5462\uff0c\u4e00\u822c\u67096\u5c42\uff0c\u8fd9\u6837\u76846\u5c42 \u5806\u53e0\u8d77\u6765\uff0c\u90a3\u6211\u4eec\u9700\u8981\u6ce8\u610f\u4e00\u4e0b \u8fd9\u4e24\u4e2a\u6a21\u5757\u7684\u4f5c\u7528\u662f\u4e0d\u4e00\u6837\u7684[\u91cd\u70b9]\uff0c**\u90a3\u9996\u5148 multihead self Attention\u505a\u7684\u4e8b \u662f\u5bf9\u5404\u4e2a\u4f4d\u7f6e\u4e0a\u7684 embedding \u8fdb\u884c\u4e00\u4e2a\u878d\u5408\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\u4e3a \u5b83\u505a\u7684\u662f \u7a7a\u95f4\u878d\u5408\u90e8\u5206\uff0c\u800cFNN\u5462\uff0c\u662fposition-wise\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4 \u5bf9\u6bcf\u4e2a\u4f4d\u7f6e\u4e0a\u5355\u72ec\u8fdb\u884c \u4eff\u5c04\u53d8\u6362\uff0c\u90a3\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\u4e3aFNN \u505a\u7684\u662f \u901a\u9053\u878d\u5408\uff0c**\u6240\u4ee5FNN\u548cMHA \u5e72\u7684\u662f \u4e24\u4e2a \u4e0d\u540c\u7684\u89d2\u5ea6\uff1b</p> <p>MHSA\u505a\u7684\u662f \u7a7a\u95f4\u878d\u5408\uff1bFNN \u505a\u7684\u662f \u901a\u9053\u878d\u5408\uff1b\u4e24\u4e2a\u7684\u4f5c\u7528\u662f\u4e0d\u4e00\u6837\u7684\uff1b</p>"},{"location":"learning/vit/#12-decoder","title":"1.2 decoder","text":"<p>\u7136\u540edecoder\u90e8\u5206 \u4e5f\u662f\u4e00\u4e2a\u7c7b\u4f3c\u7684\u7ed3\u6784\uff0c\u5e76\u4e14 encoder\u548cdecoder \u662f\u901a\u8fc7 cross-Attention \u8fdb\u884c\u4e00\u4e2a\u4ea4\u4e92\uff0c\u6765\u76f8\u4e92\u4f20\u9012\u4fe1\u606f\u7684</p>"},{"location":"learning/vit/#13","title":"1.3 \u5f52\u7eb3\u504f\u7f6e","text":"<p>\u8fd9\u6837\u7684\u7ed3\u6784 \u5c31\u6784\u6210\u4e86\u4e00\u4e2aTransformer\uff0c\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684CNN RNN\u7684\u533a\u522b\u5728\u4e8e\uff0cTransformer \u6ca1\u6709\u5c40\u90e8\u5efa\u6a21\u7684\u5047\u8bbe\uff0c\u4e5f\u6ca1\u6709\u65f6\u95f4\u4f9d\u8d56\u6027\u7684\u5047\u8bbe\uff0c\u662f\u4e00\u79cd\u5168\u5c40\u7684\u5047\u8bbe\uff0c\u5bf9\u5e8f\u5217\u8ba1\u7b97\u4e00\u4e2a\u8868\u5f81\uff0c\u4f46\u662f\u5b83\u5f15\u5165\u4e86 \u4e00\u4e2a\u5f52\u7eb3\u504f\u7f6e\uff1aposition embedding\uff0c\u5c31\u662f\u8bf4 \u8fd8\u662f\u6ce8\u5165\u4e86\u4f4d\u7f6e\u4fe1\u606f\uff1b</p>"},{"location":"learning/vit/#131-transformernlpcnn-rnn","title":"1.3.1 Transformer\u5728nlp\u4e2d\uff0c\u4e3a\u4ec0\u4e48\u4f1a\u6bd4CNN RNN\u6548\u679c\u8981\u597d\u5462","text":"<p>\u6362\u4e2a\u89d2\u5ea6\u6765\u8bf4\uff0cTransformer\u5728nlp\u4e2d\uff0c\u4e3a\u4ec0\u4e48\u4f1a\u6bd4CNN RNN\u6548\u679c\u8981\u597d\u5462\uff1f\u5c31\u662f\u56e0\u4e3aTransformer\uff0c\u6240\u5f15\u5165\u7684\u5f52\u7eb3\u504f\u7f6e \u662f\u6bd4\u8f83\u5c11\u7684\uff0c\u5982\u679c\u771f\u7684\u8981\u7b97\u5f52\u7eb3\u504f\u7f6e\u7684\u8bdd\uff0c\u90a3\u4e48\u5c31\u662f\u5f15\u5165\u4e86 position embedding\uff0c\u800c\u5176\u5b83\u4f4d\u7f6e\u5c31\u53ef\u4ee5\u8bf4 \u6ca1\u6709\u5f15\u5165 \u5148\u9a8c\u5047\u8bbe\u548c \u5f52\u7eb3\u504f\u7f6e\u7684\uff1b</p> <p>\u5bf9\u4e8e\u8fd9\u6837\u4e00\u4e2a\u6a21\u578b\uff0c\u5b83\u5b66\u4e60\u4e0a\u754c \u662f\u6bd4\u8f83\u597d\u7684\uff1b\u4e5f\u5c31\u662f\u8bf4 \u5b83\u7684performance\u662f\u6bd4\u8f83\u9ad8\u7684\uff0c\u552f\u4e00\u7684\u7f3a\u9677\u5c31\u8bf4 \u6570\u636e\u91cf\u7684\u8981\u6c42\u548c\u5f15\u5165\u7684\u5f52\u7eb3\u504f\u7f6e \u662f\u6210 \u53cd\u6bd4\u7684\uff0c\u6362\u53e5\u8bdd\u8bf4 \u5c31\u662f\u6211\u4eec\u5f15\u5165\u4e86\u8d8a\u591a\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u4e5f\u5c31\u662f\u8bf4 \u6211\u4eec\u4eba\u4e3a\u5730\u6ce8\u5165\u4e86 \u4eba\u7c7b\u7684\u7ecf\u9a8c\u6027 \u77e5\u8bc6 \u5c31\u53ef\u4ee5\u5e2e\u52a9\u8fd9\u4e2a\u6a21\u578b \u66f4\u597d\u7684\u53bb\u5b66\u4e60\uff1b</p> <p>\u4e00\u65e6\u5f52\u7eb3\u504f\u7f6e \u5f15\u5165\u7684\u6bd4\u8f83\u5c11\uff0c\u6211\u4eec\u5c31\u671f\u671b\u8fd9\u4e2a\u6a21\u578b\u4ece\u5927\u91cf\u7684\u6570\u636e\u4e2d\uff0c\u5f52\u7eb3\u51fa \u6a21\u578b\u81ea\u5df1\u7684 \u7ecf\u9a8c\u6765\u505a \u8fd9\u4e2a\u4efb\u52a1\u3002\u6240\u4ee5Transformer\u7684\u4f18\u70b9\u662f\uff0c\u4e0a\u9650\u5f88\u9ad8\uff0c\u7f3a\u70b9\u5c31\u662f \u5bf9\u6570\u636e\u91cf\u7684\u8981\u6c42\u6bd4\u8f83\u9ad8\uff1b</p> <p>\u518d\u6b21 \u5f3a\u8c03 \u5f52\u7eb3\u504f\u7f6e\u3002\u5f52\u7eb3\u504f\u7f6e\u5c31\u662f \u6211\u4eec\u4eba\u7c7b \u7528\u5f52\u7eb3\u6cd5 \u6240\u603b\u7ed3\u51fa\u7684\u7ecf\u9a8c\uff0c\u7136\u540e\u6211\u4eec\u628a\u7ecf\u9a8c \u4ee3\u5165\u5230 \u6a21\u578b\u7684\u6784\u5efa\u4e4b\u4e2d\uff0c\u90a3\u4ec0\u4e48\u662f\u5f52\u7eb3\uff1f\u5c31\u662f \u53d1\u73b0 \u5f88\u591a\u4e8b\u7269 \u4e4b\u95f4\u7684 \u5171\u6027\u3002</p> <p>\u4e3e\u4f8b\u5b50\uff0c\u732b\u4f1a\u53eb\u3001\u72d7\u4f1a\u53eb\u3001\u9e2d\u4f1a\u53eb\u3001\u9e21\u4f1a\u53eb\uff0c\u90a3\u6211\u4eec \u603b\u7ed3\u51fa \u52a8\u7269\u90fd\u4f1a\u53eb\uff0c\u8fd9\u4e2a\u5c31\u662f\u4e00\u4e2a \u5f52\u7eb3\u6cd5\uff1b</p> <p>\u76f8\u5bf9\u7684 \u8fd8\u6709\u4e00\u4e2a\u65b9\u6cd5 \u662f \u6f14\u7ece\u6cd5\uff1b\u6f14\u7ece\u6cd5 \u6bd4\u65b9\u8bf4\uff0c\u4e0b\u96e8\u5929\u8981\u5e26\u4f1e\uff0c\u660e\u5929\u8981\u4e0b\u96e8\uff0c\u6240\u4ee5\u660e\u5929\u9700\u8981\u5e26\u4f1e\u3002\u8fd9\u4e2a\u5c31\u662f\u6f14\u7ece\u6cd5\u3002\u8fd9\u662f\u5f52\u7eb3\u548c\u6f14\u7ece\u7684\u533a\u522b\u3002</p> <p>\u8fd9\u91cc\u6240\u8bf4\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u5c31\u662f\u5c06\u4eba\u7c7b\u6240\u603b\u7ed3\u7684\u7ecf\u9a8c\uff0c\u4ee3\u5165\u5230 \u6211\u4eec\u8bbe\u8ba1\u7684\u6a21\u578b\u7684 \u8fc7\u7a0b\u4e4b\u4e2d\u3002</p> <p>\u4e0a\u9762\u662f\u8bb2\u7684Transformer\u6a21\u578b\u7684\u7ed3\u6784 \u4ee5\u53ca \u4f18\u7f3a\u70b9\u3002\u56de\u7b54\u4e86 \u5982\u4f55\u8bc4\u4ef7Transformer\u7684\u95ee\u9898</p> <p>\u4ee5\u4e0a\uff1a</p> <ul> <li>\u5f52\u7eb3\u504f\u7f6e  &amp; \u6570\u636e\u91cf</li> <li>MHSA &amp; FFN</li> </ul>"},{"location":"learning/vit/#14-transformer","title":"1.4 Transformer\u7684\u4f7f\u7528\u7c7b\u578b","text":"<p>Transformer\u7684\u53d8\u4f53\u6709\uff0c\u53ea\u4f7f\u7528Transformer\u7684encoder\uff0c\u6bd4\u5982\u8bf4\u6211\u4eec\u5e38\u8bf4\u7684bert\uff0cbert\u4e3a\u4ec0\u4e48\u53eb \u53cc\u5411\u7684\u5462\uff1f\u5c31\u662f\u5728bert\u4e2d \u9884\u8bad\u7ec3 \u662f\u91c7\u7528\u7684\u4e24\u4e2aloss \u4e00\u4e2a\u662fMLM\uff0c\u8fd8\u6709\u4e00\u4e2a\u662fNSP\uff0c\u5c31\u662f\u5b83\u662f\u53bb\u9884\u6d4b\u7684\u88ab\u63a9\u7801\u7684\u4f4d\u7f6e\u4e0a\u7684\uff0c\u6ca1\u6709\u548cGPT\u4e00\u6837\uff0c\u7528\u7684\u81ea\u56de\u5f52\u7684\u65b9\u5f0f \u8fdb\u884c\u8bed\u8a00\u5efa\u6a21\uff0c\u662f\u53ea\u4f7f\u7528encoder\u7684\u65b9\u5f0f\u3002</p> <p>\u597d\u5904\u662f\u901f\u5ea6\u5f88\u5feb\uff0c\u4e0d\u9700\u8981\u505a \u81ea\u56de\u5f52\u7684 \u9012\u63a8\u3002\u53e6\u5916\u4e00\u79cd \u4f7f\u7528 \u573a\u666f\u662f decoder only\uff0c\u6bd4\u5982GPT\u7cfb\u5217\uff0c\u4f20\u7edf\u7684\u81ea\u56de\u5f52\u7684 \u8bed\u8a00\u5efa\u6a21\uff0c\u5305\u62ec\u81ea\u56de\u5f52\u751f\u6210 \u4ee5\u53ca\u4e00\u4e9b \u6d41\u5f0f\u7684\u4efb\u52a1\uff0c\u4e00\u822c \u6211\u4eec\u53ea\u4f1a\u7528\u5230 Transformer decoder\u7684\u90e8\u5206\uff0c\u8fd9\u662f\u7b2c\u4e8c\u79cd\u573a\u666f\uff1b</p> <p>\u90a3\u7b2c\u4e09\u79cd\u573a\u666f\u5462\uff0c\u5c31\u662fTransformer\u539f\u59cb\u8bba\u6587\u7684\u573a\u666f\uff0c\u5c31\u662f\u50cf\u673a\u5668\u7ffb\u8bd1\u3001\u8bed\u8a00\u8bc6\u522b\u7b49\uff0c\u5c31\u662f\u4ece\u4e00\u4e2a\u5e8f\u5217\u7a7a\u95f4 \u5230 \u53e6\u5916\u4e00\u4e2a\u5e8f\u5217\u7a7a\u95f4\u7684\u8f6c\u6362\uff0c\u6211\u4eec\u5c31\u4f1a\u7528\u5230\u5b8c\u6574\u7684Transformer\u7684encoder\u548cdecoder\u8fd9\u6837\u4e00\u4e2a\u7ed3\u6784\uff1b\u8fd9\u4e09\u79cd\u4f7f\u7528\u573a\u666f \u90fd\u5f88\u5e38\u7528\u3002\u5e76\u4e14\u5462 \u5404\u81ea\u6709\u5404\u81ea\u7684\u7279\u70b9\u3002\u60f3\u5b66\u81ea\u5df1\u770b\u8bba\u6587\u3002</p> <p>\u4eca\u5929\u8bb2\u7684vision Transformer\u662fencoder only\u7684\u7ed3\u6784\uff0c\u518d\u6b21\u5f3a\u8c03ViT\u53ea\u7528\u5230\u4e86 encoder only\u7684\u90e8\u5206\uff0c\u4e8e\u662f\u6211\u4eec\u5c31\u4e0d\u7528\u8003\u8651\u81ea\u56de\u5f52\u3001\u4e0b\u4e09\u89d2\u7684\u63a9\u7801\u77e9\u9635\u7b49\u7b49\uff1b</p>"},{"location":"learning/vit/#2-vit","title":"2 vit \u6846\u67b6","text":"<p>\u5e76\u4e14vit\u53c8\u662f\u4e00\u4e2a\u5206\u7c7b\u4efb\u52a1\uff0c\u66f4\u7b80\u5355\u4e86\uff0c\u6700\u540e\u53ea\u9700\u8981\u9884\u6d4b\u4e00\u4e2a\u6982\u7387\uff0c\u5c31\u53ef\u4ee5\u4e86\u3002\u76f8\u6bd4\u4e8e\u751f\u6210\u4efb\u52a1 \u662f\u8981\u7b80\u5355\u5f88\u591a\u7684\u3002</p> <p>\u9996\u5148 vit\u7684\u6846\u67b6\uff1a</p> <p></p> <p>vit\u7684\u601d\u60f3 \u5c31\u662f\u60f3\u628a Transformer\u6a21\u578b\u5e94\u7528\u5230 \u56fe\u50cf\u8bc6\u522b\u4efb\u52a1\u4e0a\uff0c\u4f46\u662f\u76f4\u63a5\u5c06Transformer \u5e94\u7528\u5230\u56fe\u50cf\u8bc6\u522b\u4efb\u52a1\u4e0a\uff0c\u9762\u4e34\u7684\u56f0\u96be\u5c31\u662f\uff1aTransformer\u5728nlp\u5f53\u4e2d \u662f\u4ee5\u5b57\u4e3a\u5355\u4f4d\uff0c\u5c31\u662f\u4e00\u53e5\u8bdd\u4e2d word\u7684\u6570\u91cf\u8fd8\u662f\u6bd4\u8f83\u5c11\u7684\uff1b\u4f46\u662f\u5982\u679c\u6211\u4eec \u76f4\u63a5\u5c06Transformer \u5e94\u7528\u5230\u4e00\u5f20\u56fe\u7247\u4e0a\u7684\u8bdd\uff0c\u90a3\u56fe\u7247\u7684\u57fa\u672c\u5355\u4f4d \u5c31\u662f\u4e00\u4e2a\u4e2a\u50cf\u7d20\u70b9\uff0c\u7136\u540e\u6bcf\u4e2a\u56fe\u50cf\u7684\u50cf\u7d20\u70b9 \u662f\u975e\u5e38\u975e\u5e38\u591a\u7684\uff0c\u5c11\u5219\u51e0\u767e\uff0c\u5927\u5219 \u51e0\u5343 \u51e0\u4e07 \u90fd\u6709\u3002\u6240\u4ee5\u6211\u4eec\u628aTransformer \u76f4\u63a5\u5e94\u7528\u5230\u56fe\u50cf\u70b9\u4e0a\u7684\u8bdd\uff0c\u7b2c\u4e00\u4e2a\u5c31\u662f\u8bf4 \u8ba1\u7b97\u91cf \u975e\u5e38\u5927\uff0c\u7b2c\u4e8c\u4e2a \u5c31\u662f\u5bf9\u56fe\u50cf\u800c\u8a00\uff0c\u5b83\u7684\u5355\u4e2a\u50cf\u7d20\u70b9\u4e0d\u50cf\u5728\u4e00\u4e2a\u53e5\u5b50\u4e2d  \u5355\u4e2a\u5b57\u6240\u5305\u542b\u7684\u4fe1\u606f\u91cf\u3002\u5728\u4e00\u53e5\u8bdd\u4e2d\uff0c\u5355\u4e2a\u5b57 \u6240\u5305\u542b\u7684\u4fe1\u606f\u91cf \u8fd8\u662f \u975e\u5e38\u4e30\u5bcc\u7684\u3002</p> <p>\u4f46\u662f\u5bf9\u4e00\u5f20\u56fe\u50cf\u5f53\u4e2d\u7684 \u67d0\u4e2a\u50cf\u7d20\u70b9 \u5e76\u4e0d\u5305\u542b \u4ec0\u4e48\u4fe1\u606f\u91cf\uff1b\u5bf9\u4e8e\u56fe\u50cf\u6765\u8bf4 \u4fe1\u606f\u91cf\u8fd8\u662f\u4e3b\u8981\u805a\u7126\u5728 \u4e00\u5c0f\u5757\u533a\u57df\u4e2d\uff1b\u5c31\u662f\u8bf4 \u5f88\u591a\u4e2a\u50cf\u7d20\u70b9 \u6240\u6784\u6210\u7684\u533a\u57df \u6784\u6210\u7684\u4fe1\u606f\u91cf \u624d\u4f1a\u6bd4\u8f83\u4e30\u5bcc\uff1b</p> <p>\u5982\u679c\u5355\u72ec\u770b\u4e00\u4e2a\u50cf\u7d20\u70b9\u7684\u8bdd \u53ef\u80fd\u6ca1\u6709\u4ec0\u4e48\u4fe1\u606f\u91cf\uff1b</p> <p>\u4ee5\u4e0a\u662f \u56fe\u50cf \u76f8\u6bd4\u4e8e \u6587\u672c\u53e5\u5b50\u7684\u533a\u522b\uff0c</p> <p>\u6240\u4ee5\u4e3a\u4e86\u5c06Transformer\u5e94\u7528\u5230 \u56fe\u50cf\u9886\u57df\u4e2d \u4ece\u8fd9\u4e24\u4e2a\u89d2\u5ea6\u51fa\u53d1 \u5c31\u4e0d\u80fd\u628a Transformer \u4ece\u50cf\u7d20\u70b9\u5c42\u9762 \u4e00\u4e2a\u4e2a\u4e2a\u53bb\u7b97 \u81ea\u6ce8\u610f\u529b\u3002\u90a3\u4e48\u4e00\u4e2a\u5f88\u7b80\u5355 \u5f88\u76f4\u63a5\u7684\u60f3\u6cd5 \u5c31\u662f\u628a \u5f88\u591a\u4e2a\u50cf\u7d20\u70b9 \u7ec4\u6210\u4e00\u4e2a\u5757\uff0c\u7136\u540e\u628a\u56fe\u50cf\u5206\u6210\u5f88\u591a\u4e2a\u5757\uff0c\u7136\u540e\u5462 \u628a\u4e00\u4e2a\u4e2a\u56fe\u50cf\u5757 \u53bb\u5f53\u505a\u4e00\u4e2atoken\uff0c\u7136\u540e\u9001\u5165\u5230Transformer\u4e2d\uff0c\u8fd9\u662f\u4e00\u4e2a\u5f88\u76f4\u63a5\u7684\u60f3\u6cd5\u3002\u8fd9\u4e2a\u662f\u8f93\u5165\u7279\u5f81\u90e8\u5206\u3002</p>"},{"location":"learning/vit/#21-patch","title":"2.1 patch\u7684\u6784\u5efa","text":"<p>\u5bf9\u4e8e\u8fd9\u4e2a\u5757 \u6709\u4e24\u79cd\u89d2\u5ea6 \u7406\u89e3\u3002</p> <p></p> <p>\u7b2c\u4e00\u79cd\u89d2\u5ea6\uff0c\u901a\u8fc7DNN\u7684\u89d2\u5ea6\u7406\u89e3\uff0c\u4e5f\u5c31\u662f\u8bf4 \u9996\u5148\u628a \u56fe\u7247 \u5207\u5272\u6210 \u5f88\u591a\u4e2a\u5757\uff0c\u4e5f\u5c31\u662fimage to patch\u7684\u8fc7\u7a0b\u3002\u7136\u540e \u6211\u4eec\u518d\u5bf9 \u5f88\u591a\u4e2apatch \u7ecf\u8fc7\u4e00\u4e2a\u4eff\u5c04\u53d8\u6362\uff0c\u5f97\u5230\u4e00\u4e2a\u65b0\u7684\u5411\u91cf\uff0c\u53eb\u505aembedding\uff0c\u4e5f\u5c31\u662f patch to embedding\uff0c\u8fd9\u662f\u4eceDNN\u7684\u89d2\u5ea6\u7406\u89e3</p> <p></p> <p>\u90a3\u53e6\u5916\u4e00\u4e2a\u89d2\u5ea6\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u7406\u89e3\u4e3a \u6211\u4eec\u628a \u56fe\u7247 \u5f97\u5230 embedding\u7684\u8fc7\u7a0b \uff0c\u4e5f\u53ef\u4ee5\u7406\u89e3\u4e3a\u5377\u79ef\u7f51\u7edc\uff0c\u4e5f\u5c31\u662f\u8bf4 \u6211\u4eec\u4f1a\u7528\u4e00\u4e2a\u4e8c\u7ef4\u7684\u5377\u79ef \u5728\u56fe\u50cf\u4e0a \u5e94\u7528\u4e00\u4e2a\u5377\u79ef\uff0c\u5e76\u4e14\u8bf4\u5377\u79ef kernel size\u7b49\u4e8estride\u7684\uff0c\u7136\u540e\u6211\u4eec\u518d\u628a\u5f97\u5230\u7684\u5377\u79ef\u56fe\u62c9\u76f4\u4e00\u4e0b\uff0c\u5c31\u5f97\u5230\u6211\u4eec\u4e00\u4e2a\u4e2a\u7684token embedding</p> <p>\u8fd9\u662f\u6211\u4eec\u4ece \u4e24\u79cd\u89d2\u5ea6 \u53bb\u770b image to embedding\u7684\u8fc7\u7a0b</p>"},{"location":"learning/vit/#22-cls-token","title":"2.2  CLS token","text":"<p>\u63a5\u4e0b\u6765 \u4e3a\u4e86\u53bb\u505a\u5206\u7c7b\u4efb\u52a1\uff0cvit\u662f\u501f\u9274\u4e86bert\u4e2d\u7684\u4e00\u4e2a class token\u7684\u5360\u4f4d\u7b26\uff0c\u5173\u4e8e\u8fd9\u4e2aclass token\uff0c\u5927\u5bb6\u4e5f\u6709\u4e0d\u540c\u7684\u4e89\u8bae\uff0c\u6bd4\u5982\u4e3a\u4ec0\u4e48\u8981\u6709\u4e00\u4e2a class token\uff0c\u4ee5\u53caclass token \u65e2\u7136 \u5145\u5f53\u4e86 query\u7684\u4f5c\u7528\uff0c\u90a3\u4e3a\u4ec0\u4e48 \u5176\u4ed6 \u4f4d\u7f6e\u4e0a\u7684 \u91cf \u53c8\u53ef\u4ee5\u5bf9\u5b83\u53bb\u8ba1\u7b97\u4e00\u4e2a \u6ce8\u610f\u529b\u7684\u6743\u91cd\uff0c\u603b\u4e4b \u8fd9\u91cc\u6709\u5f88\u591a\u4e89\u8bae\u3002\u4f46\u662fbert\u8bba\u6587\u4e2d \u4e5f\u505a\u4e86\u5bf9\u6bd4\uff0c\u7528\u4e86class token\u7684\u6548\u679c \u662f\u6bd4 \u76f4\u63a5Pooling\u7684\u6548\u679c \u8981\u597d\u7684\u3002</p>"},{"location":"learning/vit/#23-position-embedding","title":"2.3 Position embedding","text":"<p>\u53e6\u5916 \u5728vit\u4e2d \u540c\u6837\u5f15\u5165\u4e86 position embedding\uff0c\u8fd9\u91cc\u5bf9\u6bd4\u4e86\u597d\u51e0\u79cd embedding\uff0c\u6700\u540e\u4f7f\u7528\u4e86 \u53ef\u8bad\u7ec3\u7684\u4e00\u7ef4embedding\uff0c\u6548\u679c\u4f1a\u6bd4\u8f83\u597d\u4e00\u70b9</p>"},{"location":"learning/vit/#24-transformer-encoder","title":"2.4 Transformer encoder","text":"<p>\u53e6\u5916\uff0cvit\u662f\u4e3b\u8981\u7528\u4e86Transformer encoder\u7684\u4e00\u4e2a\u6a21\u5757\uff0c \u5e76\u6ca1\u6709\u4f7f\u7528\u5230 decoder\uff0c\u662f\u6bd4\u8f83\u7b80\u5355\u7684\u3002</p>"},{"location":"learning/vit/#25-classification-head","title":"2.5 classification head","text":"<p>\u6700\u540e \u6211\u4eec\u901a\u8fc7class token\u8fd9\u4e2a\u4f4d\u7f6e\u4e0a\u7684  \u72b6\u6001\u91cf \u62ff\u51fa\u6765\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u53bb\u505a \u5206\u7c7b\u4efb\u52a1\u3002\u8fd9\u5c31\u662fvit\u7684\u4e00\u4e2a\u5168\u5c40\u7684\u7ed3\u6784\u3002\u63a5\u4e0b\u6765 \u6211\u4eec\u6765\u770b \u5177\u4f53\u8bba\u6587</p>"},{"location":"learning/vit/#3","title":"3 \u539f\u8bba\u6587","text":"<p>\u8bba\u6587\u7684\u6807\u9898\uff1a\u4e00\u56fe\u80dc16\u00d716\u7684\u5b57\uff0c\u6539\u7f16\u81ea \u4e00\u56fe\u80dc\u5343\u8a00\uff1b</p> <p>AN IMAGE IS WORTH 16\u00d716 WORDS</p> <p>\u6807\u9898\u7684\u610f\u601d\u5c31\u662f\u8bf4 \u5982\u679c\u628a \u4e00\u4e2a\u56fe\u50cf\u7684\u6bcf\u4e2a\u50cf\u7d20\u70b9\u770b\u6210 \u4e00\u4e2a\u5355\u8bcd\u7684\u8bdd \u5176\u5b9e\u6211\u4eec\u53ef\u4ee5\u628a16\u00d716 \u50cf\u7d20\u70b9 \u5f53\u6210\u4e00\u5f20\u56fe \u5c31\u591f\u4e86 \u3002\u6211\u4eec\u4e0d\u9700\u8981\u628a16\u00d716\u4e2a\u50cf\u7d20\u70b9 \u62ff\u51fa\u6765 \u5355\u72ec\u8fdb\u884c\u5efa\u6a21\uff1b\u800c\u662f\u53ef\u4ee5\u628a\u5b83\u4eec \u76f4\u63a5\u770b\u6210\u4e00\u4e2a\u6574\u4f53\u3002\u518d\u53d8\u6210\u4e00\u4e2aembedding \u8fdb\u884c\u5efa\u6a21\uff0c\u8fd9\u6837\u7684\u6548\u679c\u4f1a\u66f4\u597d\u3002</p> <p>TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</p> <p>\u4e0b\u9762\u4e00\u884c \u5c31\u662f\u8bf4 Transformer \u5e94\u7528\u5230 \u56fe\u50cf\u8bc6\u522b\uff0c\u6240\u4ee5\u5728\u672c\u6587\u4e2d \u4e3b\u8981\u662f\u628atransformer\u5e94\u7528\u5230 \u56fe\u50cf\u8bc6\u522b\uff0ccv\u9886\u57df \u603b\u5171 \u6709\u4e09\u5927\u4efb\u52a1\uff1a\u8bc6\u522b\u3001\u68c0\u6d4b\u3001\u5206\u5272\uff1b\u672c\u6587\u4e2d \u53ea\u8bb2\u5230\u4e86 \u8bc6\u522b\u3002\u540e\u9762\u8fd8\u6709\u8bba\u6587\u628atransformer\u7528\u5230cv\uff0c\u4e0d\u4ec5\u4f1a\u8bb2\u5230image recognition\u8fd8\u4f1a\u8bb2\u5230 \u68c0\u6d4b\u548c\u5206\u5272</p>"},{"location":"learning/vit/#31","title":"3.1 \u6458\u8981","text":"<p>\u9996\u5148 \u6458\u8981\u90e8\u5206\uff1a</p> <p></p> <p>\u5c3d\u7ba1transformer\u5df2\u7ecf\u6210\u4e3anlp\u4efb\u52a1\u7684\u6807\u914d\uff1b\u4f46\u662f\u5b83\u5728cv\u8fd9\u4e2a\u9886\u57df\u7684\u6f5c\u529b\u8fd8\u6ca1\u6709\u88ab\u6316\u6398</p> <p>\u90a3\u4e48\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\uff0c\u6ce8\u610f\u529b\u673a\u5236\u8981\u4e48\u5e94\u7528\u5230\u5377\u79ef\u7f51\u7edc\u4e2d\uff0c\u8981\u4e48\u76f4\u63a5\u66ff\u4ee3\u5377\u79ef\u7f51\u7edc\u7684\u67d0\u4e00\u90e8\u5206\uff1b</p> <p>\u5728\u672c\u6587\u4e2d\uff0c\u4f5c\u8005\u5c55\u793a\u4e86CNN\u4e0d\u662f\u5fc5\u987b\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u7b80\u5355\u7684transformer\u6a21\u578b\u76f4\u63a5\u5e94\u7528\u5230\u56fe\u50cf\u5757\u4e0a\uff0c\u5c31\u53ef\u4ee5\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a \u8868\u73b0\u5f97\u5f88\u597d\uff1b\u4f46\u662f\u8fd9\u4e2a\u5f88\u597d\u662f\u6709\u6210\u672c\u7684\uff1b\u5f53\u6211\u4eec\u9996\u5148\u5c06\u8fd9\u4e2avit\u6a21\u578b\u5728\u5927\u91cf\u7684\u6570\u636e\u4e0a \u505a\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u518d\u628a\u5b83\u8fc1\u79fb\u5230 \u4e2d\u7b49\u5927\u5c0f \u6216\u8005 \u5c0f\u7684\u6570\u636e\u96c6\u4e0a\uff0cvit\u5c31\u53ef\u4ee5\u53d6\u5f97 \u76f8\u6bd4\u4e8e\u5377\u79ef\u7f51\u7edc \u4e00\u6837 \u751a\u81f3 \u66f4\u597d\u7684\u6548\u679c\u3002</p> <p>\u8ddf\u4e4b\u524d\u8bb2\u7684transformer\u6709\u5f02\u66f2\u540c\u5de5\u4e4b\u5999\uff0c\u56e0\u4e3atransformer\u7684\u5f52\u7eb3\u504f\u7f6e \u662f\u6bd4\u8f83\u5c11\u7684\u3002\u5c31\u662f\u8bf4\u5e76\u6ca1\u6709\u628a\u6211\u4eec\u4eba\u7c7b\u603b\u7ed3\u7684\u4e00\u4e9b\u7ecf\u9a8c \u6ce8\u5165\u5230transformer\u6a21\u578b\u4e4b\u4e2d\uff0c\u6240\u4ee5\u5355\u7eaf\u8ba9transformer\u4f9d\u8d56\u6570\u636e\u53bb\u5b66\u4e60\u5230\u8fd9\u4e9b\u7ecf\u9a8c \u662f\u4e00\u4e2a\u6bd4\u8f83\u6f2b\u957f\u7684\u8fc7\u7a0b\uff0c\u6240\u4ee5\u6211\u4eec\u5fc5\u987b\u9700\u8981\u5927\u91cf\u7684\u6570\u636e\u91cf \u5927\u91cf\u7684\u6570\u636e\u96c6 \u624d\u53ef\u4ee5\u8ba9transformer vit\u53d6\u5f97\u6bd4\u8f83\u597d\u7684\u6548\u679c\uff0c\u5b8c\u5168\u662f \u6570\u636e\u9a71\u52a8\u7684\uff1b</p>"},{"location":"learning/vit/#32","title":"3.2 \u6a21\u578b\u56fe","text":"<p>introduction\u76f4\u63a5\u8df3\u8fc7\uff0c\u76f4\u63a5\u770b\u6a21\u578b\u56fe\uff1a</p> <p></p> <p>vit\u7684\u7ed3\u6784\u5c31\u662f \u56fe1\u6240\u793a\uff1b\u9996\u5148\u770bdecription\uff1b</p> <p>\u9996\u5148\u628a\u56fe\u7247\u5206\u6210\u5f88\u591a\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684 \u5757\u3002\u7136\u540e\u5728\u7528\u7ebf\u6027\u7f51\u7edc \u5c06\u8fd9\u4e9b\u5757 \u5f62\u6210\u4e00\u4e2a\u5d4c\u5165\u8868\u5f81\uff0c\u7136\u540e\u518d\u5728\u8868\u5f81\u4e0a \u52a0\u5165\u4f4d\u7f6e\u7f16\u7801\uff1b\u7136\u540e\u518d\u628a\u8fd9\u4e00\u7cfb\u5217\u7684\u5411\u91cf \u9001\u5165\u5230\u6807\u51c6\u7684transformer encoder\u4e4b\u4e2d\uff0c\u6a21\u578b\u5c31\u7528\u8fd9\u4e48\u4e00\u53e5\u8bdd \u63cf\u8ff0\u5b8c\u4e86\u3002\u7136\u540e\u4e3a\u4e86\u53bb\u505a \u5206\u7c7b\u4efb\u52a1\uff0c\u5c31\u662f\u50cfbert\u4e2d\u4e00\u6837\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a \u989d\u5916\u7684classification token\u4f4d\u7f6e\uff0c\u5c31\u662f\u5bf9\u5e8f\u5217 \u65b0\u589e\u4e86\u4e00\u4e2a\u4f4d\u7f6e\uff1b</p> <p>\u53ef\u4ee5\u7406\u89e3\u4e3a \u8fd9\u4e2a\u4f4d\u7f6e \u5c31\u662f\u8d77\u4e00\u4e2a query\u7684\u4f5c\u7528\u3002\u5c31\u662f\u5b83\u4f1a\u53bb\u6536\u96c6 \u4f7f\u5f97\u8fd9\u4e2a\u6a21\u578b \u80fd\u505a\u597d \u5206\u7c7b\u4efb\u52a1\u7684\u4fe1\u606f\u3002\u6700\u540e\u5462 \u6211\u4eec\u5c06\u6700\u540e\u4e00\u5c42\u7684 \u4f4d\u7f6e\u4fe1\u606f \u62ff\u51fa\u6765 \u505a\u4e00\u4e2a\u7ebf\u6027\u6620\u5c04\uff0c\u6620\u5c04\u5230 \u7c7b\u522b\u7684\u6982\u7387\u5206\u5e03\u4e0a\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u4e86\u3002\u8fd9\u4e2a\u6a21\u578b\u662f\u6bd4\u8f83\u7b80\u5355\u7684 \u5982\u679c\u975e\u5e38\u4e86\u89e3transformer\u6a21\u578b\u7684\u8bdd\u3002vit\u662f\u6ca1\u6709\u96be\u5ea6\u7684\uff08\u4ee3\u7801 \u6f14\u793a\u5b9e\u4f8b\uff09</p> <p>\u63a5\u4e0b\u6765 \u770b\u5de6\u56fe\uff0c\u53f3\u56fe\u770b\u8fc7 \u5f88\u591a\u904d\u4e86</p> <p></p> <ul> <li> <p>\u9996\u5148\u5c06\u4e00\u526f\u56fe\u7247 \u5206\u6210\u5f88\u591a\u4e2a \u5757\uff1b\u9700\u8981\u6ce8\u610f\u7684\u662f \u6bcf\u4e2a\u5757\u7684\u5927\u5c0f\u662f\u4e0d\u53d8\u7684\uff1b\u56fe\u50cf\u7684\u5927\u5c0f \u53ef\u80fd\u4f1a\u53d8\u5316 \u4f46\u662f \u6bcf\u4e2a\u5757\u7684\u5927\u5c0f \u662f\u4e0d\u4f1a \u53d1\u751f\u53d8\u5316\u7684</p> </li> <li> <p>\u5728\u540c\u4e00\u4e2a\u6a21\u578b\u4e2d \u5757\u7684\u5927\u5c0f \u4e0d\u4f1a\u53d1\u751f\u53d8\u5316\uff1b</p> </li> <li> <p>\u6362\u53e5\u8bdd\u8bf4\uff0c\u5982\u679c\u56fe\u7247\u5927\u4e00\u70b9\uff0c\u90a3\u53cd\u5e94\u5728 \u5e8f\u5217\u957f\u5ea6\u4e0a \u957f\u4e00\u70b9\uff1b</p> </li> <li>\u5c06\u4e00\u4e2a\u56fe\u7247\u5206\u6210\u5f88\u591a\u5757\uff0c\u50cf\u5377\u79ef\u4e2d \u5e73\u79fb\u7684\u987a\u5e8f\u4e00\u6837\uff0c\u5148\u5de6\u5230\u53f3\uff0c\u628a\u56fe\u7247\u62c9\u76f4\uff0c\u62c9\u6210\u4e00\u4e2a\u5e8f\u5217\u7684\u5f62\u72b6\uff1b</li> <li>\u7136\u540e\u518d\u628a \u6bcf\u4e2a\u5757\u7684\u50cf\u7d20\uff0c\u50cf\u7d20\u70b9\u7684\u503c \u5f52\u4e00\u5316\uff1b\u5c31\u662f\u8bf4\u4e4b\u524d\u5c31\u5df2\u7ecf \u505a\u597d \u5f52\u4e00\u5316\u4e86 \u5f52\u4e00\u5316\u52300-1\u4e4b\u95f4\u3002</li> <li>\u7136\u540e\u518d\u628a\u5757\u91cc\u7684 \u503c \u901a\u8fc7\u7ebf\u6027\u53d8\u6362 \u6620\u5c04\u5230 \u6a21\u578b\u7684\u7ef4\u5ea6\uff0c\u6216\u8005\u8bf4 \u6211\u4eec\u5f97\u5230\u4e86patch embedding\uff1b</li> <li>\u6709\u4e86patch embedding\u4ee5\u540e\uff0c\u4e3a\u4e86\u505a\u5206\u7c7b\u4efb\u52a1\uff0c\u9700\u8981\u5728\u5e8f\u5217\u7684\u5f00\u5934 \u589e\u52a0\u4e00\u4e2a \u53ef\u8bad\u7ec3\u7684embedding\uff0c\u8fd9\u4e2aembedding\u662f\u968f\u673a\u521d\u59cb\u5316\u7684 embedding\u3002\u90a3\u8fd9\u6837 \u5c31\u6784\u6210\u4e86 \u4e00\u4e2a\u957f\u5ea6+1\u7684\u5e8f\u5217\u3002</li> <li>\u7136\u540e\u6211\u4eec\u518d\u589e\u52a0position embedding\uff0c\u5c31\u662f\u4f4d\u7f6e\u7f16\u7801\uff0c\u90a3\u8fd9\u6837 \u52a0\u5b8c \u540e\u7684 \u5e8f\u5217\u8868\u5f81 \u5c31\u53ef\u4ee5\u76f4\u63a5 \u9001\u5165\u5230 transformer encoder\u4e2d\uff0c\u7136\u540e\u6211\u4eec\u5728encoder \u6700\u540e\u4e00\u5c42\u4e2d\uff0c\u53d6\u51fa \u65b0\u52a0\u7684 \u4e5f\u5c31\u662f\u591a\u4f59\u4f4d\u7f6e\u4e0a\u7684 \u8f93\u51fa\u72b6\u6001 \u7ecf\u8fc7\u4e00\u4e2aMLP\uff0c\u5f97\u5230\u7c7b\u522b\u7684\u6982\u7387\u5206\u5e03\uff0c\u5c31\u53ef\u4ee5\u7528\u4ea4\u53c9\u71b5 \u53bb\u7b97\u51fa \u5206\u7c7bloss\uff0c\u5c31\u5b8c\u6210\u4e86 \u4e00\u4e2avit\u6a21\u578b\u7684\u642d\u5efa\uff1b</li> </ul>"},{"location":"learning/vit/#4","title":"4 \u4ee3\u7801\u5b9e\u73b0","text":"<p>\u63a5\u4e0b\u6765 \u4ee3\u7801 \u5b9e\u73b0\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u7684\u91cd\u70b9\uff1a</p>"},{"location":"learning/vit/#41-patch","title":"4.1 \u5207\u5206 patch","text":"<ul> <li>Image2embedding</li> </ul> <p>\u4e5f\u5c31\u662f\u8bf4 \u5b9e\u73b0\u7684\u91cd\u70b9 \u5728transformer\u4e4b\u524d\u7684\u90e8\u5206\uff1b\u56e0\u4e3atransformer encoder\u7684\u4ee3\u7801 pytorch \u5df2\u7ecf\u5305\u88c5\u8d77\u6765\u4e86\u3002\u800c\u4e14 \u4e4b\u524d \u4e5f\u5df2\u7ecf\u8be6\u7ec6\u8bb2\u8fc7</p> <p>\u6240\u6709\u7684\u6240\u6709 \u90fd\u662f\u4e3a\u4e86 \u4ee3\u7801 \u55ef \u522b\u5fd8\u4e86 \u5f00\u59cb\u7684\u76ee\u7684</p> <p>\u7279\u70b9\uff1a\u5b9e\u73b0 \u529f\u80fd\u4e3a\u4e3b \uff0c\u4e0d\u662f\u8dd1\u6a21\u578b\uff1b\u56f4\u7ed5\u4f8b\u5b50 \u5b9e\u73b0 \u8fc7\u7a0b\uff1b</p> <p>\u9996\u5148 \u5bfc\u5165\u5e93\uff1a</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n</code></pre> <p>,\u6765\u770b\u4e00\u4e0b\uff0c\u9996\u5148\u7b2c\u4e00\u90e8\u5206 \u8981\u505a\u4ec0\u4e48\uff0c\u6211\u4eec\u9700\u8981\u5c06 \u4e00\u5e45 \u56fe\u7247\u53d8\u6210embedding\uff0c\u7b2c\u4e00\u6b65\u6211\u4eec\u8981\u505a\u8fd9\u4e2a\u4e8b\u60c5\uff0c\u6211\u4eec\u53ef\u4ee5\u9996\u5148 \u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570</p> Python<pre><code>def image2emb():\n  pass\n</code></pre> <p></p> <p>\u4e4b\u524d\u5728 \u601d\u7ef4\u5bfc\u56fe\u91cc \u8bb2\u4e86 \u8fd9\u4e2a image2emb\u8fd9\u4e2a\u8fc7\u7a0b \u53ef\u4ee5\u4ece\u4e24\u4e2a\u89d2\u5ea6 \u53bb\u7406\u89e3\uff0c\u4e00\u4e2a\u89d2\u5ea6 \u662fDNN\u7684\u89d2\u5ea6\uff0c\u6211\u4eec\u628aimage\u624b\u52a8 \u5207\u6210 \u4e00\u4e2a\u4e2a\u5757\uff0c\u518d\u628a\u6bcf\u4e2a\u5757 \u53d8\u6210 embedding</p> <p>\u7b2c\u4e8c\u4e2a\u89d2\u5ea6\u5c31\u662f\u8bf4 \u76f4\u63a5\u4ece \u4e8c\u7ef4\u5377\u79ef\u7684 \u89d2\u5ea6\u53bb\u7406\u89e3\uff0c\u5c31\u662f \u76f4\u63a5\u5bf9\u56fe\u7247\u505a \u4e8c\u7ef4\u5377\u79ef \uff0c\u7136\u540e\u628a\u5377\u79ef\u540e\u7684\u7ed3\u679c \u62c9\u76f4\u4e00\u4e0b\uff0c\u6784\u6210embedding</p> <p>\u6240\u4ee5vit\u7ed3\u6784 \u7b2c\u4e00\u5c42 \u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u5377\u79ef\uff1b\u90a3 \u5199\u4e24\u4e2a\u51fd\u6570 \u5b9e\u73b0\u5b83</p> <p>\u7b2c\u4e00\u4e2a\u51fd\u6570 \u53ebnavie,\u5f88\u76f4\u63a5\u7684\u5b9e\u73b0\uff1b</p> <p>\u7b2c\u4e8c\u4e2a\u51fd\u6570\u53d6\u540d\u4e3aconv\uff0c\u6211\u4eec\u4ee5\u5377\u79ef\u7684\u89d2\u5ea6\uff0c\u6765\u5b9e\u73b0</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie():\n    pass\n\ndef image2emb_conv():\n    pass\n</code></pre>"},{"location":"learning/vit/#411-naivetorchunfold","title":"4.1.1 naive\u7248\u672c\uff1atorch.unfold()","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    patch_embedding = patch @ weight\n    return patch_embedding\ndef image2emb_conv():\n    pass\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim)\n\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)\nprint(patch_embedding_naive.shape)\n</code></pre> <p>\u6ce8\u91ca\uff1a</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width = 1,3,8,8\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    # patchshape = torch.Size([1, 48, 4])   patch_size = 4\n    # 1\uff1abatchsize\n    # 48 = 3*4*4\uff08\u5377\u79ef\u8986\u76d6\u7684input region\uff09\n    # 4\uff1a1,3,8,8\u7684\u8f93\u5165\u56fe\u7247\u7528 1344\u7684\u5377\u79ef\u6838\u5377\u79ef\uff0c\u5f97\u52304\u4e2ainput region\n    # transpose(-1,-2) \u2192 1,4,48  \n    patch_embedding = patch @ weight\n    # 1,4,48 @ 48,8 = 4 \u00d7 8\n    return patch_embedding\ndef image2emb_conv():\n    pass\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim)\n\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)\nprint(patch_embedding_naive.shape)\n</code></pre> <p>\u4ee5\u4e0b\u662f\u4ee3\u7801\u7684\u600e\u4e48\u5199\u51fa\u6765\u7684\u8be6\u89e3\uff0c\u53ef\u8df3\uff1a</p> <p>\u9996\u5148 \u6211\u4eec\u6765\u5b9e\u73b0 navie\u7684\u7248\u672c</p> <p>\u90a3\u4e48\u65e2\u7136\u662f image2embedding\uff0c\u6211\u4eec\u9700\u8981\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570 \u5c31\u662fimage\u7684\u5f20\u91cf\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570 \u5c31\u662f \u5757\u7684\u5927\u5c0f\uff0c\u9996\u5148\u5c06image\u5206\u6210\u5f88\u591a\u5f88\u591a\u7684\u5757\uff0c\u6bcf\u4e2a\u5757 \u80af\u5b9a\u662f \u65b9\u5f62\u7684 \u8fb9\u957f\u662f\u591a\u5c11\uff0c\u90a3\u6211\u4eec \u4f20\u5165\u7684\u662f\u5c31\u662f <code>patch_size</code> \u4e5f\u5c31\u662f \u5757\u7684\u8fb9\u957f\uff0c\u90a3\u8fd8\u6709\u5c31\u662f \u6211\u4eec\u65e2\u7136\u8981\u5f97\u5230embedding\uff0c\u9996\u5148\u5f97\u5230\u5757\uff0c\u5757\u91cc\u9762\u7684\u6240\u6709\u50cf\u7d20\u70b9\uff0c\u6211\u4eec\u4f1a\u5bf9\u5b83\u505a\u4e00\u4e2a \u7ebf\u6027\u53d8\u6362\uff0c\u7ebf\u6027\u53d8\u6362\u7684\u8bdd \u9700\u8981\u4e00\u4e2aweight\uff0c\u8fd9\u4e2a \u53d8\u6362\u7684\u6743\u91cd\u77e9\u9635</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,wieght):\n    pass\n\ndef image2emb_conv():\n    pass\n</code></pre> <p>\u8fd9\u91cc\u7684image size\u4e00\u822c\u662f\u8ddf \u5377\u79ef\u4e2d\u7c7b\u4f3c\uff0c\u5b83\u7684\u683c\u5f0f \u5c31\u662f batch size\u00d7channel\u00d7height\u00d7width\uff0c\u8fd9\u4e2a\u662fimage\u7684shape\uff0c\u5728\u4e8c\u7ef4\u5377\u79ef\u4e2d \u4e5f\u662f\u8fd9\u6837\u683c\u5f0f</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    pass\ndef image2emb_navie():\n    pass\n</code></pre> <p>\u9996\u5148\u7b2c\u4e00\u6b65 \u6211\u4eec\u8981\u5bf9 \u56fe\u50cf\u5206\u5757\uff0c\u90a3\u8fd9\u4e2a\u56fe\u7247\u5206\u5757 \u5176\u5b9e\u5c31\u662f \u7c7b\u4f3c\u4e4b\u524d\u5377\u79ef\u8bb2\u8fc7\u7684</p> <p></p> <p>\u6211\u4eec\u6709\u4e24\u79cd\u89d2\u5ea6 \u7406\u89e3\u5377\u79ef\uff0c\u7b2c\u4e00\u79cd \u89d2\u5ea6 \u662f\u628a\u6bcf\u6b21 \u6ed1\u52a8\u76f8\u4e58\u7684\u533a\u57df \u62ce\u51fa\u6765\uff0c\u5176\u5b9e\u5c31\u662fimage2patch\uff0c\u53ea\u662f \u8fd9\u91cc\u7684stride \u521a\u597d \u7b49\u4e8e kernel size</p> <p>\u53e6\u5916\u4e00\u79cd\u89d2\u5ea6 \u5c31\u662f\u6211\u4eec\u5bf9kernel \u8fdb\u884c \u586b\u5145\uff0c\u628akernel \u586b\u5145\u6210 \u8ddf input feature map\u4e00\u6837\u5927\u5c0f\u7684\uff0c\u7136\u540e \u63a8\u51fa\u4e86 \u8f6c\u7f6e\u5377\u79ef</p> <p>\u6240\u4ee5\u8fd9\u91cc \u5c31\u662f \u7b2c\u4e00\u79cd\u89d2\u5ea6\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7image2patch\uff0c\u5c06\u6bcf\u4e00\u6b65 \u5377\u79ef\u7684\u533a\u57df \u62ff\u51fa\u6765 \u6784\u6210\u4e00\u4e2a\u4e2apatch\uff0c\u90a3\u8fd9\u91cc \u4e0d\u5199for \u5faa\u73af \u62ffpatch</p> <p>\u4e4b\u524d \u4e5f\u8bb2\u8fc7 \u5728pytorch \u4e2d\uff0c\u6709\u4e00\u4e2aapi\u53eb\u505a<code>pytorch nn functional unfold</code>\u8fd9\u4e2aapi</p> <p></p> <p>\u8fd9\u4e2aapi\u505a\u7684\u4e8b\u60c5\uff0c\u5c31\u662f\u62ff\u51fa\u5377\u79ef\u7684\u533a\u57df</p> <p></p> <p>\uff0c\u7b80\u5355\u6765\u8bb2 \u5c31\u662f \u62ff\u51fa \u5377\u79ef\u7684\u533a\u57df\uff0c\u4f60\u770b\u5b83\u9700\u8981\u7684\u53c2\u6570 \u4e5f\u975e\u5e38\u7684\u5377\u79ef</p> <p></p> <p>\u6709input\u3001kernel size\u3001dilation\uff0cpadding\u3001stride</p> <p>\u5176\u5b9e\u5c31\u662f\u8bf4 \u6839\u636einput \u5377\u79ef\u7684\u53c2\u6570 \u5c31\u80fd\u5c06 \u6bcf\u4e00\u6b21 \u6ed1\u52a8\u7684 \u533a\u57df\u7684\u8f93\u5165 \u5355\u72ec\u7684 \u62ff\u51fa\u6765</p> <p>\u8fd9\u91cc \u5c31\u662f image2patch\u7684\u8fc7\u7a0b</p> <p>\u8fd9\u91cc \u6211\u4eec\u76f4\u63a5\u53bb\u8c03\u7528</p> <p>\u90a3\u4e5f\u5c31\u662f\u8bf4 \u521a\u597d\u6709\u8fd9\u4e9b\u53c2\u6570\uff0c\u5c31\u53ef\u4ee5\u76f4\u63a5\u53bb\u8c03\u7528</p> <p>\u6211\u4eec\u5df2\u7ecf import \u7b80\u5199\u6210F\u4e86\uff0c\u6240\u4ee5\u5c31\u5199F.unfold,input\u5176\u5b9e\u5c31\u662f image\uff0c\u521a\u597d\u662f\u6ee1\u8db3\u8fd9\u4e2a\u683c\u5f0f\u7684\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570 \u5c31\u662fkernel size\u53c2\u6570\uff0ckernel size \u5176\u5b9e\u5c31\u662f patch size\uff0c\u7b2c\u4e09\u4e2a\u5462 \u5176\u5b9e\u5c31\u662fdilation\uff0cdilation\u8fd9\u91cc\u6211\u4eec\u4e0d\u9700\u8981\u8003\u8651\uff0c\u56e0\u4e3a \u6211\u4eec\u5e76\u6ca1\u6709 \u7a7a\u6d1e\uff0cpadding\u4e5f\u4e0d\u7528\u8003\u8651\uff0c\u4e5f\u6ca1\u6709\u505a\u586b\u5145\uff0c\u6700\u540e\u4e00\u4e2astride\u6211\u4eec\u9700\u8981\u8003\u8651\uff0c\u6211\u4eec\u7684stride\u5e76\u4e0d\u662f1\uff0c\u56e0\u4e3a \u6211\u4eec\u8fd9\u91cc\u7684\u56fe\u50cf\u5206\u5757 \u662f\u6ca1\u6709\u4ea4\u53e0\u7684\uff0c\u7ed3\u6784\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230 \uff0c\u6bcf\u4e2a\u5757\u4e0e\u5757\u4e4b\u95f4 \u662f\u6ca1\u6709\u4ea4\u53e0\u7684\uff0c\u8fd9\u5c31\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u5377\u79ef stride=kernel size\uff0c\u901a\u8fc7F.unfold\u51fd\u6570 \u5c31\u80fd\u628a \u56fe\u50cf\u5206\u5757\uff0c\u7ed3\u679c\u5b9a\u4e49\u4e3apatch</p> Python<pre><code>    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size)\n</code></pre> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size)\n    pass\ndef image2emb_navie():\n    pass\n</code></pre> <p>\u8fd9\u4e2a \u5c31\u662f \u8c03\u7528pytorch F.unfold\u8fd9\u4e2a\u51fd\u6570 \u5c06\u56fe\u7247 \u8fdb\u884c\u5206\u5757\uff0c\u539f\u7406\u5c31\u662f \u5c06\u56fe\u7247\u770b\u6210 kernel size=stride\u7684\u5377\u79ef\u5c31\u597d\u4e86\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u628a\u6bcf\u4e00\u6b21 \u6bcf\u4e00\u6b65 \u8f93\u5165\u7684\u533a\u57df \u5355\u72ec\u62ff\u51fa\u6765\uff0c\u653e\u5230patch\u4e2d</p> <p>\u5f53\u7136 \u8fd9\u4e2apatch\u662f\u4ec0\u4e48\u5f62\u72b6\u5462\uff1f\u6211\u4eec\u53ef\u4ee5\u5148\u6765 \u6d4b\u8bd5\u4e00\u4e0b\uff0c\u9700\u8981\u5148 \u6d4b\u8bd5\u4e00\u4e0b \u8fd9\u4e2a\u51fd\u6570 \u6765\u770b\u4e00\u4e0b patch\u7684\u5f62\u72b6\u3002</p> <p>\u4e3a\u4e86 \u6d4b\u8bd5 \u6211\u4eec\u9700\u8981 \u5148 \u5b9a\u4e49\u4e00\u4e9b\u5e38\u91cf\uff0c\u6bd4\u5982\u8bf4 \u6211\u4eec\u9700\u8981\u5b9a\u4e49 batch size\u3001input channel\u3001\u56fe\u7247\u7684\u9ad8\u5ea6 \u4ee5\u53ca \u56fe\u7247\u7684\u5bbd\u5ea6</p> <p>\u5047\u8bbe \u6211\u4eec\u8bbe\u7f6ebatch size=1\uff0cchannel=3\uff0c\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u5199\u4e2a8\u548c8</p> <p>\u540c\u65f6\u6211\u4eec\u8fd8\u9700\u8981 \u5b9a\u4e49 patch size\uff0c\u8fd9\u91cc \u6211\u4eec\u53ef\u4ee5\u5b9a\u4e494\uff0c\u4e5f\u5c31\u662f\u8bf4 \u6211\u4eec\u662f4\u00d74\u4e3a\u4e00\u4e2a patch</p> <p>\u90a3\u8fd8\u6709 \u6211\u4eec\u9700\u8981\u5f97\u5230 \u4e00\u4e2a embedding\uff0c\u6240\u4ee5\u6211\u4eec\u8fd8\u9700\u8981\u6709\u4e00\u4e2a patch embedding dim\uff0c\u5176\u5b9e\u5c31\u662ftransformer\u4e2d\u7684 model dim\uff0c\u6211\u4eec\u53ef\u4ee5 \u5b9a\u4e49\u4e3a8</p> Python<pre><code># test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n</code></pre> <p>\u5728\u5b9a\u4e49\u597d\u4e86\u8fd9\u4e9b\u91cf\u4ee5\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u6765\u6d4b\u8bd5\u8fd9\u4e9b\u51fd\u6570\u4e86</p> <p>\u9996\u5148 \u6211\u4eec\u9700\u8981\u751f\u6210 \u56fe\u7247</p> Python<pre><code>image = torch.randn(bs,ic,image_h,image_w)\n</code></pre> <p>\u8fd8\u9700\u8981 weight\uff0cweight\u600e\u4e48\u6837\u5b9a\u4e49\u5462\uff1f</p> <p>weight \u5176\u5b9e\u5c31\u662f patch2embedding\u8fc7\u7a0b\u7684\u4e58\u6cd5\u77e9\u9635\uff0c\u4e5f\u5c31\u662f\u8bf4 \u6211\u4eec\u5c06patch\u7684\u5927\u5c0f \u6620\u5c04\u6210model dim\u8fd9\u4e2a\u5927\u5c0f\uff0c\u6240\u4ee5weight \u662f\u4e00\u4e2a \u4e8c\u7ef4\u7684\u5f20\u91cf</p> <p>\u5f20\u91cf\u7684\u7b2c\u4e00\u4e2a\u5f62\u72b6\uff0c\u5148\u6682\u65f6\u8bbe\u4e3aNone\uff0c\u7b2c\u4e8c\u4e2a\u5f62\u72b6 \u5176\u5b9e \u5c31\u662f model dim\uff0c\u662f\u4e00\u4e2a \u8fd9\u6837\u7684 \u4e58\u6cd5\u77e9\u9635 </p> Python<pre><code>weight = torch.randn(None,model_dim)\n</code></pre> <p>\u90a3\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u5462\uff1f\u7b2c\u4e00\u4e2a\u7ef4\u5ea6 \u5176\u5b9e\u5c31\u662f patch\u7684\u5927\u5c0f\uff0c\u6309\u7167\u8bba\u6587\u7684\u610f\u601d patch\u7684\u5927\u5c0f \u662f\u4ec0\u4e48\u5462\uff1fpatch\u7684\u5927\u5c0f \u5176\u5b9e\u5c31\u662fpatch\u7684\u8fb9\u957f\uff0c\u8fb9\u957f\u7684\u5e73\u65b9\u521a\u597d\u662f \u9762\u79ef\uff0c\u7136\u540e\u518d\u4e58\u4ee5 \u901a\u9053\u6570\u76ee\uff0c\u4e5f\u5c31\u662f\u8bf4 \u5982\u679c\u56fe\u7247 \u6709 \u4e09\u4e2a\u901a\u9053\u7684\u8bdd\uff0c\u6bcf\u4e2apatch \u5176\u5b9e\u662f \u5305\u542b \u4e09\u4e2a \u901a\u9053\u7684\uff0c\u6240\u4ee5\u8fd9\u91cc \u6211\u4eec\u9700\u8981\u7b97\u51fa\u4e00\u4e2a\u91cf</p> <p>patch_depth \u4e5f\u5c31\u662f patch\u7684\u6df1\u5ea6\uff0c\u5b83\u5e94\u8be5\u5c31\u662f patch size\u518d\u4e58\u4ee5 patch size\u518d\u4e58\u4ee5 ic \u8f93\u5165\u7684\u901a\u9053\u6570\u76ee\uff0c\u90a3\u8fd9\u91cc \u6211\u4eec\u5c31\u53ef\u4ee5\u628a weight\u7684\u77e9\u9635 \u7ed9\u5199\u51fa\u6765\uff0c\u4e5f\u5c31\u662f patch_depth</p> Python<pre><code>patch_depth = patch_size * patch_size * ic\nweight = torch.randn(patch_depth,model_dim)\n</code></pre> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size)\n    pass\ndef image2emb_navie():\n    pass\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim)\n</code></pre> <p>\u8fd9\u5c31\u662f weight \u77e9\u9635\uff0c\u6709\u4e86weight \u6709\u4e86image\uff0cpatch_size \u6211\u4eec\u5c31\u53ef\u4ee5 \u8c03\u7528\u8fd9\u4e2a\u51fd\u6570image2emb_navie</p> <p>\u7136\u540e \u6211\u4eec\u9996\u5148\u6253\u5370\u4e00\u4e0b \u91cc\u9762\u7684patch\u7684\u5f62\u72b6</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size)\n    print(patch.shape)\ndef image2emb_conv():\n    pass\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim)\n\nimage2emb_navie(image,patch_size,weight)\n</code></pre> <p>\u8f93\u51fa\uff1atorch.Size([1, 48, 4])</p> <p>\u7ed3\u679c\u89e3\u8bfb\uff1apatch\u7684\u5f62\u72b6\u662f1\u00d748\u00d74 \u77e5\u9053\u4e3a\u4ec0\u4e48 \u662f \u8fd93\u4e2a\u6570\u5b57\u5417</p> <p>\u9996\u5148 4\u5f88\u597d\u7406\u89e3 \u56e0\u4e3a \u56fe\u50cf\u662f 8\u00d78\u7684 \u8fd9\u6837\u4e00\u4e2a \u9762\u79ef\uff0c\u7136\u540e patch size\u662f4\u00d74\uff0c\u90a3\u4e00\u4e2a8\u00d78\u7684\u56fe\u7247\uff0c\u4ee54\u00d74\u4e3a\u4e00\u4e2a\u5757\u7684\u8bdd\uff0c\u521a\u597d\u662f 4\u5757\uff1b\u5c31\u6784\u6210\u4e864\u5757\uff1b</p> <p>\u8fd9\u91cc\u76844 \u5176\u5b9e\u5c31\u662f \u5757\u7684\u6570\u76ee\uff0c\u5c31\u662f \u56fe\u7247 \u5206\u5757\u4ee5\u540e \u5757\u7684\u6570\u76ee</p> <p>\u7136\u540e 48\u600e\u4e48\u6765\u7684\u5462\uff1f48\u5176\u5b9e\u5c31\u662f  patch size\u00d7patch size \u00d7input channel \u5c31\u662f 4\u00d74\u00d73=48,\u628a\u6bcf\u4e2a\u5377\u79ef\u90fd\u62c9\u76f4\u4e86\uff0c\u4e3a\u4e86\u66f4\u4fbf\u4e8e\u7406\u89e3 \u6211\u4eec\u53ef\u4ee5\u589e\u52a0\u4e00\u4e2atranspose\uff0c\u5c31\u662f\u628a\u6700\u540e\u4e00\u7ef4\u548c\u5012\u6570\u7b2c\u4e8c\u7ef4 \u4ea4\u6362\u4e00\u4e0b\uff0c\u518d\u8fd0\u884c</p> <p></p> <p>1\u662fbatch size\uff1b4\u662fpatch\u7684\u6570\u76ee\uff1b48\u662f\u6bcf\u4e2apatch\u6240\u5305\u542b\u7684\u50cf\u7d20\u70b9\u7684\u6570\u76ee</p> <p>\u5f97\u5230patch\u4ee5\u540e\uff0c\u6253\u5370weight\u5f62\u72b6</p> <p></p> <p>weight\u5f62\u72b6 \u521a\u597d\u662f48\u00d78\uff0c\u6240\u4ee5\u6211\u4eec\u628apatch\u8ddfweight \u8fdb\u884c\u4e00\u4e2a\u77e9\u9635\u76f8\u4e58\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230patch embedding\uff0c\u7528@\u7b26\u53f7\uff0c\u7136\u540e\u8fd4\u56depatch embedding\uff0c\u7136\u540e\u628a\u5f97\u5230patch embedding naive\uff0c\u7136\u540e\u6253\u5370patch embedding naive\u7684\u5f62\u72b6</p> <p></p> <p>\u8fd9\u6837 \u5c31\u5b8c\u6210\u4e86 \u7b2c\u4e00\u4e2a\u51fd\u6570\u7684\u6d4b\u8bd5 \u628a\u8fd9\u4e2a3\u00d78\u00d78\u7684\u56fe\u7247\uff0c\u53d8\u6210\u4e86 embedding\u7684\u5f62\u5f0f\uff0cembedding\u7684\u5927\u5c0f\u662f4\u00d78\uff1b\u4e5f\u5c31\u662f\u4e00\u5f20\u56fe\u7247\u88ab\u5206\u6210\u4e864\u5757 \u5e76\u4e14\u6bcf\u4e00\u5757 \u53d8\u6210\u4e86\u957f\u5ea6\u4e3a8\u7684\u5411\u91cf\uff0c\u6765\u8868\u793a\u8fd9\u4e2a\u5757</p> <p>\u4ee5\u4e0a\u662f\u6240\u6709naive\u7684\u5b9e\u73b0\u6b65\u9aa4</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    patch_embedding = patch @ weight\n    return patch_embedding\ndef image2emb_conv():\n    pass\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim)\n\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)\nprint(patch_embedding_naive.shape)\n</code></pre>"},{"location":"learning/vit/#412-convflatten-output","title":"4.1.2 conv\u7248\u672c\uff1aflatten output","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# step1 convert image to embedding vector sequence\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    patch_embedding = patch @ weight\n    return patch_embedding\ndef image2emb_conv(image,kernel,stride):\n    conv_output = F.conv2d(image,kernel,stride=stride) # bs*oc*oh*ow\n    bs,oc,oh,ow = conv_output.shape\n    patch_embedding = conv_output.reshape((bs,oc,oh*ow)).transpose(-1,-2)\n\n    return patch_embedding\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim) # model_dim\u662f\u8f93\u51fa\u901a\u9053\u6570\u76ee\uff0cpatch depth\u662f\u5377\u79ef\u6838\u7684\u9762\u79ef\u4e58\u4ee5\u8f93\u5165\u901a\u9053\u6570\n\n# \u5206\u5757\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)\nkernel = weight.transpose(0,1).reshape((-1,ic,patch_size,patch_size))\n\n# \u4e8c\u7ef4\u5377\u79ef\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_conv = image2emb_conv(image,kernel,patch_size)\n\nprint(patch_embedding_naive)\nprint(patch_embedding_conv)\n</code></pre> <p>\u6ce8\u91ca\uff1a</p> Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# step1 convert image to embedding vector sequence\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width = 1,3,8,8\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    # patchshape = torch.Size([1, 48, 4])   patch_size = 4\n    # 1\uff1abatchsize\n    # 48 = 3*4*4\uff08\u5377\u79ef\u8986\u76d6\u7684input region\uff09\n    # 4\uff1a1,3,8,8\u7684\u8f93\u5165\u56fe\u7247\u7528 1344\u7684\u5377\u79ef\u6838\u5377\u79ef\uff0c\u5f97\u52304\u4e2ainput region\n    # transpose(-1,-2) \u2192 1,4,48  \n    patch_embedding = patch @ weight\n    # 1,4,48 @ 48,8 = 1\u00d7 4 \u00d7 8\n    return patch_embedding\n\ndef image2emb_conv(image,kernel,stride):\n    # image = bs,ic,image_h,image_w = 1,3,8,8 \n    # kernel = 8 \u00d7 3 \u00d7 4 \u00d7 4\n    # stride = patch_size = 4 \n    conv_output = F.conv2d(image,kernel,stride=stride) # bs*oc*oh*ow\n    # (h-k+2p+s)/s = (8-4+4)/4  = 2\n    # conv_output = 8 \u00d7 1 \u00d7 2 \u00d7 2\n    bs,oc,oh,ow = conv_output.shape\n    patch_embedding = conv_output.reshape((bs,oc,oh*ow)).transpose(-1,-2)\n    # conv_output = 1 \u00d7 8 \u00d7 2 \u00d7 2\n    # reshape \uff1a 1 \u00d7 8 \u00d7 4\n    # transpose(-1,-2)  1 \u00d7 4 \u00d7 8\n    #\uff08\u8f93\u5165\u56fe\u7247 \u5212\u5206\u6210 4\u4e2apatch\uff0c\u6bcf\u4e2apatch\u7531\u539f\u6765\u7684 48\u4e2a\u50cf\u7d20\u8868\u793a\uff0c\u964d\u7ef4\u62108\u7ef4\u8868\u793a\uff09\n    return patch_embedding\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim) # model_dim\u662f\u8f93\u51fa\u901a\u9053\u6570\u76ee\uff0cpatch depth\u662f\u5377\u79ef\u6838\u7684\u9762\u79ef\u4e58\u4ee5\u8f93\u5165\u901a\u9053\u6570\n\n# \u5206\u5757\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)\n\n# conv\u7248\u672c\uff1a\nkernel = weight.transpose(0,1).reshape((-1,ic,patch_size,patch_size))\n# weight = 48 \u00d7 8\n# transpose(0,1) : 8 \u00d7 48\n# reshape :8 \u00d7 3 \u00d7 4 \u00d7 4\n\n# \u4e8c\u7ef4\u5377\u79ef\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_conv = image2emb_conv(image,kernel,patch_size)\n# image = bs,ic,image_h,image_w = 1,3,8,8 \n# kernel = 8 \u00d7 3 \u00d7 4 \u00d7 4\n# patch_size = 4\n\nprint(patch_embedding_naive)\nprint(patch_embedding_conv)\n</code></pre> <p>\u4ee3\u7801\u8be6\u89e3\uff1a</p> <p>\u63a5\u4e0b\u6765 \u7528\u5377\u79ef\u5b9e\u73b0 conv\u7684\u7248\u672c</p> <p>\u65e2\u7136\u662f\u5377\u79ef \u5c31\u9700\u8981\u5bf9\u4f20\u5165\u7684\u53c2\u6570\u6539\u4e00\u4e0b\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570 \u8fd8\u662f image\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662fkernel\uff0c\u7b2c\u4e09\u4e2a\u53c2\u6570 \u9700\u8981 stride\uff0c\u8fd9\u6837\u6211\u4eec\u5b9a\u4e49\u597d\u4e86 \u5377\u79ef\u7684\u4e09\u8981\u7d20 </p> <p>\u9996\u5148\u5b9a\u4e49F.conv2d\u7b2c\u4e00\u4e2a\u53c2\u6570 image\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570 kernel\uff0cstride\u6b65\u957f\u8bbe\u7f6e\u4e3astride\uff0c\u8fd9\u6837\u5f97\u5230\u4e86conv_output,\u8fd9\u6837\u505a\u4e86\u4e00\u4e2a\u5377\u79ef\uff0c\u7b49\u4e0b \u4f1a\u8bb2\u89e3 \u8fd9\u4e2a\u5f97\u5230\u7684\u548c\u662f\u4ec0\u4e48</p> Python<pre><code>def image2emb_conv(image,kernel,stride):\n    conv_output = F.conv2d(image,kernel,stride=stride)\n    pass\n</code></pre> <p>\u8fd9\u6837\u64cd\u4f5c\u7684\u8bdd  \u5377\u79ef\u8f93\u51fa\u7684\u5927\u5c0f\u662f\u4ec0\u4e48\u5462\uff1f</p> <p>\u5377\u79ef\u8f93\u51fa\u7684\u5927\u5c0f\u662f batch_size\u00d7output channel\u00d7output height\u00d7output width  </p> <p>\u6700\u7ec8 \u6211\u4eec\u8981\u5f97\u5230 patch embedding\uff0c\u5176\u5b9e\u6211\u4eec\u5377\u79ef\u540e\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c\u6211\u4eec\u4f1a\u628a\u5b83\u62c9\u6210\u4e00\u4e2a\u5e8f\u5217\uff0c\u770b\u6846\u67b6\u56fe\uff1a</p> <p></p> <p>\u5c31\u662f\u8bf4 \u5c06 output feature map\u62c9\u76f4\uff0c\u62c9\u76f4\u7684\u5c31\u662foutput height\u00d7output width\u7684\u90e8\u5206\uff0c\u4e5f\u5c31\u662f\u8bf4 \u53ef\u4ee5\u5bf9conv output\u8fdb\u884c\u4e00\u4e2areshape\uff0creshape\u6210bs\u00d7oc\u00d7\uff08oh\u00d7ow\uff09\u518dtranspose\u4e00\u4e0b\uff0c\u628a\u5e8f\u5217\u957f\u5ea6\u8fd9\u4e00\u7ef4 \u653e\u5230\u4e2d\u95f4\uff0c\u8fd9\u6837\u5f97\u5230 patch embedding\uff0c\u6700\u540e \u8fd4\u56de patch embedding</p> <p>\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u9996\u5148\u5c06 image2embedding\u7684\u8fc7\u7a0b \u9996\u5148\u770b\u51fa\u4e8c\u7ef4\u5377\u79ef\uff0c\u5377\u79ef\u7684\u7ed3\u679c\u662f\u4e00\u4e2abatch size\u00d7\u901a\u9053\u6570\u518d\u2716\ufe0f\u9ad8\u5ea6\u2716\ufe0f\u5bbd\u5ea6\uff0c\u56e0\u4e3a\u6211\u4eec\u8fd9\u91cc\u6a21\u4effnlp\u4e2d \u628a\u56fe\u7247\u53d8\u6210\u5e8f\u5217\uff0c\u4e8e\u662f\u6211\u4eec\u53ef\u4ee5\u628a\u7279\u5f81\u56fe \u9ad8\u5ea6\u548c\u5bbd\u5ea6\u6d53\u7f29\u6210\u4e00\u8d77\uff0c\u5c31\u662f\u62c9\u76f4\u7684\u610f\u601d\uff0c\u7136\u540e\u518d\u628a\u901a\u9053\u6570\u548c\u5d4c\u5165\u4f4d\u7f6e \u4ea4\u6362\u4e00\u4e0b\u7ef4\u5ea6\uff0c\u901a\u9053\u6570 \u5c31\u662f patch size\uff0coh\u00d7ow\u5c31\u662fsequence\u7684\u957f\u5ea6</p> Python<pre><code>def image2emb_conv(image,kernel,stride):\n    conv_output = F.conv2d(image,kernel,stride=stride) # bs*oc*oh*ow\n    bs,oc,oh,ow = conv_output.shape\n    patch_embedding = conv_output.reshape((bs,oc,oh*ow)).transpose(-1,-2)\n\n    return patch_embedding\n</code></pre> <p>\u63a5\u4e0b\u6765\u6700\u5173\u952e\u7684\u5c31\u662f \u5b9a\u4e49\u597dkernel\uff0c\u90a3kernel\u600e\u4e48\u5b9a\u4e49\u5462\uff1fkernel\u5c31\u662fweight\uff0c\u53ea\u4e0d\u8fc7\u8981\u628a\u5f62\u72b6\u53d8\u4e00\u53d8\u3002</p> <p></p> <p>\u9996\u5148 \u4e0a\u9762\u8fd9\u4e2aweight\u7684\u5f62\u72b6\u662f patch depth\u00d7model dim\uff0c\u5176\u5b9e\u53ef\u4ee5\u600e\u4e48\u7406\u89e3\u5462\uff1fmodel dim\u5c31\u53d8\u6210\u4e86oc\uff0c\u6240\u4ee5model dim\u5c31\u662f\u8f93\u51fa\u901a\u9053\u6570\u76ee </p> <p>patch depth\u5c31\u662f\u5377\u79ef\u6838\u7684\u9762\u79ef\u00d7\u8f93\u5165\u901a\u9053\u6570</p> <p>kernel\u7684\u5f62\u72b6\u6309\u7167\u4e8c\u7ef4\u5377\u79ef\u7684\u5f62\u5f0f\uff0coc\u00d7ic\u00d7kh\u00d7kw \u8f93\u51fa\u901a\u9053\u6570\u3001\u8f93\u5165\u901a\u9053\u6570\u3001kernel\u5377\u79ef\u6838\u7684\u9ad8\u5ea6\u548c\u5bbd\u5ea6\uff0c\u6240\u4ee5\u628akernel  reshape\u6210oc\u00d7ic\u00d7kh\u00d7kw \u8fd9\u79cd\u5f62\u72b6\uff1b</p> <p>\u9996\u5148\u5c06kernel\u8f6c\u7f6e\u4e00\u4e0b\uff0c\u901a\u9053\u6570\u653e\u5230\u6700\u524d<code>kernel.transpose(0,1)</code></p> <p>\u7136\u540e\u518dreshape\u4e00\u4e0b\uff0c\u90a3reshape\u6210\u4ec0\u4e48\u5f62\u72b6\u5462\uff1f\u6309\u7167<code>oc\u00d7ic\u00d7kh\u00d7kw</code>\u7684\u6570\u636e\u683c\u5f0f\uff0c</p> <p></p> <p>oc\u4e0d\u77e5\u9053\u5927\u5c0f\uff0c\u7528-1\u8868\u793a\uff0cic\u524d\u9762\u5b9a\u4e49\u4e86\uff0c\u63a5\u4e0b\u6765kh\u00d7kw\uff0ckh\u3001kw\u5c31\u662fpatch size\uff0c\u8fd9\u91cc\u6709\u4e2a\u7b14\u8bef</p> <p></p> <p>kernel=weight.transpose</p> <p>weight\u7684\u5f62\u72b6\uff1a<code>patch_depth \u00d7 model_dim</code>\u3001<code>patch depth=patch size\u00d7patch size\u00d7ic</code>\u3001<code>model dim=oc</code></p> <p>\u6240\u4ee5\u6211\u4eec\u7684\u505a\u6cd5 \u9996\u5148\u4ea4\u63620\u30011\u7ef4\u5ea6 \u628a\u8f93\u51fa\u901a\u9053\u6570\u653e\u5230\u524d\u9762\uff0c\u7136\u540e\u505areshape\u64cd\u4f5c\uff0c\u7136\u540e\u628akernel\u4ee3\u5165\u51fd\u6570\u5f53\u4e2d\uff0c\u505aimage2emb\uff0c\u9996\u5148\u4f20\u5165\u7684\u662fimage\uff0c\u7136\u540e\u662fkernel\uff0c\u7136\u540e\u8fd9\u91cc\u7684stride\u5c31\u662fpatch size\uff0c\u7ed3\u679c\u4f20\u7ed9<code>patch embedding conv</code></p> <p></p> <p>\u5176\u4e2d\uff0cpatch embedding naive\u662f\u5206\u5757\u65b9\u6cd5\u5f97\u5230patch embedding</p> <p>patch embedding conv\u662f\u4e8c\u7ef4\u5377\u79ef\u7684\u65b9\u6cd5\u5f97\u5230patch embedding</p>"},{"location":"learning/vit/#413","title":"4.1.3 \u9a8c\u8bc1\u7ed3\u679c\u4e00\u6837","text":"<p>\u6253\u5370\u67e5\u770b\u7ed3\u679c \u7ed3\u679c\u57fa\u672c\u4e0a\u662f\u4e00\u6837\u7684</p> <p></p>"},{"location":"learning/vit/#414-patch","title":"4.1.4 patch \u6784\u5efa\u7684\u5168\u90e8\u4ee3\u7801","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# step1 convert image to embedding vector sequence\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    patch_embedding = patch @ weight\n    return patch_embedding\ndef image2emb_conv(image,kernel,stride):\n    conv_output = F.conv2d(image,kernel,stride=stride) # bs*oc*oh*ow\n    bs,oc,oh,ow = conv_output.shape\n    patch_embedding = conv_output.reshape((bs,oc,oh*ow)).transpose(-1,-2)\n\n    return patch_embedding\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim) # model_dim\u662f\u8f93\u51fa\u901a\u9053\u6570\u76ee\uff0cpatch depth\u662f\u5377\u79ef\u6838\u7684\u9762\u79ef\u4e58\u4ee5\u8f93\u5165\u901a\u9053\u6570\n\n# \u5206\u5757\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)\nkernel = weight.transpose(0,1).reshape((-1,ic,patch_size,patch_size))\n\n# \u4e8c\u7ef4\u5377\u79ef\u65b9\u6cd5\u5f97\u5230embedding\npatch_embedding_conv = image2emb_conv(image,kernel,patch_size)\n\n\nprint(patch_embedding_naive)\nprint(patch_embedding_conv)\n</code></pre> <p>\u603b\u7ed3\uff1a\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5176\u5b9e\u662f\u4e00\u79cd\u65b9\u6cd5\uff0c\u5982\u679c\u6309\u7167\u539f\u6587\u7684\u610f\u601d\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u539f\u6587\u9996\u5148\u662f\u5206\u6210\u5757\uff0c\u7528\u4e00\u4e2a\u77e9\u9635\u8fdb\u884c\u76f8\u4e58\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u8fd9\u4e2a\u8fc7\u7a0b\u770b\u6210\u4e8c\u7ef4\u5377\u79ef\u7684\u8fc7\u7a0b\uff1b\u5c31\u662f\u8bf4\u628a\u77e9\u9635\u8f6c\u7f6e\u6210kernel\u7684\u5f62\u72b6\uff0c\u7136\u540e\u4ee5kernel size\u7b49\u4e8estride\u7684\u5377\u79ef \u6765\u5bf9\u4e8c\u7ef4\u56fe\u5f62\u8fdb\u884c\u5377\u79ef\uff0c\u5377\u79ef\u8fc7\u540e\uff0c\u628a\u5377\u79ef\u8f93\u51fa\u7684\u7279\u5f81\u56fe\uff0c\u901a\u9053\u770b\u6210embedding\u7684\u5927\u5c0f\uff0c\u5377\u79ef\u7279\u5f81\u56fe\u7684\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u7684\u4e8c\u7ef4\u5f62\u5f0f\u62c9\u76f4\uff0c\u62c9\u6210\u4e00\u7ef4\u5e8f\u5217\u957f\u5ea6\uff0c\u5370\u8bc1\u4e86\u6211\u4eec\u7684\u89d2\u5ea6\uff0c\u4eceCNN\u7684\u89d2\u5ea6\u7406\u89e3\uff0c\u505a\u4e00\u4e2a\u4e8c\u7ef4\u5377\u79ef\uff0c\u518d\u628a\u8f93\u51fa\u7684\u7279\u5f81\u56fe\u62c9\u76f4\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u4e00\u7ef4\u7684embedding\u5e8f\u5217</p> <p></p> <p>\u4ee5\u4e0a\u662f\u7b2c\u4e00\u6b65 \u7531\u56fe\u7247\u5f97\u5230embedding\uff1aconvert image to embedding vector sequence</p>"},{"location":"learning/vit/#42-cls-token","title":"4.2 CLS token","text":"Python<pre><code># step2 prepend CLS token embedding\n# patch_embedding_conv = 1 \u00d7 4 \u00d7 8\n# cls_token_embedding = 1 \u00d7 1 \u00d7 8\n\ncls_token_embedding = torch.randn(bs,1,model_dim,requires_grad=True)\n# token_embedding\n# \u7b2c\u4e00\u4e2a\u4f4d\u7f6e \u662f cls token\uff0ccls token\u7684\u5d4c\u5165\u7ef4\u5ea6\u662f 8\n# \u6240\u4ee5 dim = 1\ntoken_embedding = torch.cat([cls_token_embedding,patch_embedding_conv],dim=1)\n</code></pre> <p>\u7b2c\u4e8c\u6b65\u52a0\u4e0a\u4e2a cls  token\uff1bclassification token\uff0c\u8fd9\u662f\u6a21\u4effbert\u6a21\u578b\u4e2d\uff0c</p> <p></p> <p>\u9700\u8981\u5728\u5e8f\u5217\u5f00\u59cb \u52a0\u5165\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684 embedding\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a query\uff0cup\u4e3b\u4e5f\u6709\u7591\u95ee\uff0c\u65e2\u7136\u662fquery \u4e3a\u4ec0\u4e48\u8981\u52a0\u53ef\u5b66\u4e60\u7684embedding\u4e3a\u4ec0\u4e48\u4e5f\u53ef\u4ee5\u52a0position embedding\uff0c\u4e3a\u4ec0\u4e48\u5176\u4ed6\u4f4d\u7f6e\u4e5f\u53ef\u4ee5\u5bf9\u5b83\u8ba1\u7b97\u6ce8\u610f\u529b\u673a\u5236  \uff1b\u603b\u4e4b\u8fd9\u91cc\u9762\u8fd8\u6709\u5f88\u591a\u96be\u4ee5\u89e3\u51b3\u7684\u95ee\u9898</p> <p>\u6839\u636e\u539f\u6587\u7684\u610f\u601d\uff0cCLS\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u4e00\u4e2a\u968f\u673a\u521d\u59cb\u5316\u7684\u5f20\u91cf\uff1a<code>cls_token_embeddding torch.randn()</code>\u5f62\u72b6\u662f batch size\uff0c\u957f\u5ea6\u663e\u7136\u662f1\uff0c\u5927\u5c0f\u662fmodel dim\uff0c\u9700\u8981\u589e\u52a0\u4e00\u4e2a\u53c2\u6570<code>requires_grad=True</code>\u56e0\u4e3a\u662f\u53ef\u8bad\u7ec3\u7684</p> <p></p> <p>\u4ee5\u4e0a\u589e\u52a0\u4e86cls_token_embedding</p> <p></p> <p>\u63a5\u4e0b\u6765\u5c06 naive\u6216\u8005conv\u7ed9\u62fc\u8d77\u6765\uff0c\u8c03\u7528torch.cat\u51fd\u6570\u8fdb\u884c\u62fc\u63a5\uff0c\u628acls embedding\u653e\u5728\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\uff0cpatch embedding\u653e\u5728\u7b2c\u4e8c\u4e2a\u4f4d\u7f6e\u4e0a\uff0c\u63a5\u4e0b\u6765\u8003\u8651\u5728\u54ea\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u62fc\u63a5 \uff0c\u8fd9\u4e2adim\u4f200\u8fd8\u662f1\u8fd8\u662f2\uff0c\u56e0\u4e3a\u6709\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u56e0\u4e3a\u6211\u4eec\u5728\u4f4d\u7f6e\u4e0a\u62fc\u63a5\uff0c\u4e0d\u662fbatch size\u4e0d\u662f\u901a\u9053\uff0c\u800c\u662f\u5728\u4f4d\u7f6e\u4e0a\u62fc\u63a5\uff0c\u6240\u4ee5dimension\u4f20\u51651\uff0c\u4e5f\u5c31\u662f\u4e2d\u95f4\u7684\u7ef4\u5ea6\uff0c\u8fd9\u6837\u6211\u4eec\u5f97\u5230\u4e86token embedding</p> <p>token embedding=patch embedding+cls token\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u589e\u52a0\u7684\u5206\u7c7b\u5b57\u7b26</p> <p></p>"},{"location":"learning/vit/#43-position-embedding","title":"4.3 Position embedding","text":"Python<pre><code># step3 add position embedding\npositon_embedding_table = torch.randn(max_num_token,model_dim,requires_grad=True)\nseq_len = token_embedding.shape[1]\npositon_embedding = torch.tile(positon_embedding_table[:seq_len],[token_embedding.shape[0],1,1])\ntoken_embedding += positon_embedding\n</code></pre> <p>\u6ce8\u91ca\uff1a</p> Python<pre><code># step3 add position embedding\n# max_num_token = 16\n# model_dim = 8\n# positon_embedding_table = 16,8\npositon_embedding_table = torch.randn(max_num_token,model_dim,requires_grad=True)\n\n# token_embedding = 1,5,8 (bs,5\u4e2a\u4f4d\u7f6e(1\u4e2acls token\u30014\u4e2a\u5355\u8bcd),model_dim = 8)\n# seq_len = 5\nseq_len = token_embedding.shape[1]\n\npositon_embedding = torch.tile(positon_embedding_table[:seq_len],[token_embedding.shape[0],1,1])\n# positon_embedding_table[:seq_len] = positon_embedding_table[:5] \u53d6\u524d5\u4e2a8\u7ef4\n# [:5] \u8868\u793a \u5bf9 \u7b2c\u4e00\u7ef4 \u7d22\u5f15\n# positon_embedding_table[:seq_len] = 5,8\n# [token_embedding.shape[0],1,1] = [1,1,1]\n# positon_embedding = 1,5,8\ntoken_embedding += positon_embedding\n# token_embedding = 1,5,8\n</code></pre> <p>\u63a5\u4e0b\u6765 \u6211\u4eec\u8fd8\u9700\u8981\u589e\u52a0position embedding</p> <p>\u6587\u7ae0\u4e2d \u4f5c\u8005\u5bf9\u6bd4\u4e86\u5f88\u591a\u79cdposition emebedding\uff0c\u6548\u679c\u90fd\u5dee\u4e0d\u591a\uff0c\u6700\u7ec8\u91c7\u7528\u7684\u662f\u4e00\u4e2a \u968f\u673a\u7684 \u53ef\u5b66\u4e60\u7684 emebedding</p> <p>\u9996\u5148 \u5b9a\u4e49\u4e00\u4e2a embedding table\uff0c\u5173\u4e8e embedding table\uff0c\u4e4b\u524d\u8bb2\u8fc7\u5f88\u591a\u6b21\uff0c\u9996\u5148table\u7684\u5f62\u72b6\uff0c\u662f\u5355\u8bcd\u7684\u6570\u76ee\u00d7\u5d4c\u5165\u7684\u7ef4\u5ea6\uff1b\u4f4d\u7f6e\u7684\u6570\u76ee\u00d7\u6a21\u578b\u7ef4\u5ea6\uff0c\u6240\u4ee5\u6211\u4eec\u8fd8\u9700\u8981\u5b9a\u4e49\u4e00\u4e2a\u91cf max_num_token,\u5c31\u662ftoken\u7684\u6700\u5927\u6570\u76ee max_num_token=16,\u540c\u6837\u8bbe\u7f6e requires grad=True \u662f\u4e00\u4e2a\u53ef\u8bad\u7ec3\u7684</p> <p></p> <p>\u5728\u8bbe\u7f6e\u597d\u4e86 position embedding table\u4ee5\u540e\uff0c\u53ef\u4ee5\u5c06table\u53d6\u51fa\u6765\uff0ctable\u53d6\u51fa\u6765\uff0c\u5c31\u53ef\u4ee5\u4f9d\u8d56\u4e8e\u5e8f\u5217\u7684\u957f\u5ea6\uff0c\u6240\u4ee5\u9996\u5148 \u6211\u4eec\u5f97\u5230sequence length,\u5e94\u8be5\u5c31\u662f\u5f97\u5230token embedding</p> Python<pre><code>seq_len = token_embedding.shape[1]\n</code></pre> <p>\u5176\u5b9e\u5728\u56fe\u50cf\u4e2d\uff0c\u540c\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u56fe\u50cf\u5927\u5c0f\u4e00\u822c\u662f\u56fa\u5b9a\u7684\uff0c\u5c31\u662f\u8bf4\u4e00\u822c\u662f\u76f8\u540c\u7684\uff0c\u5c31\u8bf4\u5728\u56fe\u50cf\u4e2d\uff0c\u6240\u4ee5\u5bf9\u4e8emask\u6bd4nlp\u4e2d \u5c31\u4f1a\u5c11\u4e00\u70b9\uff1b\u4f46\u4eca\u5929\u8fd8\u662f\u4e0d\u8bb2mask\u4e86\uff0c\u4eca\u5929\u5ffd\u7565mask\u3002</p> <p>\u9996\u5148\u5f97\u5230sequence length\uff0c\u5c31\u53ef\u4ee5\u6839\u636esequence length\uff0c\u4eceposition embedding table\u4e2d\u53d6\u51fa\u4f4d\u7f6e\u7f16\u7801\uff0c\u53d6\u51fa\u524dsequence length\u4e2a\uff0c\u53d6\u51fa\u6765\u4ee5\u540e \u8fd8\u662f\u4e00\u4e2a\u4e8c\u7ef4\u7684\u5f20\u91cf\uff0c\u6211\u4eec\u8fd8\u9700\u8981\u5bf9\u5176\u8fdb\u884c\u4e00\u4e2a\u590d\u5236\uff0c\u590d\u5236\u6210\u4e00\u4e2a\u4e09\u7ef4\u7684\uff0c\u4e3b\u8981\u8fd8\u662f\u590d\u5236\u6210 batch size\u8fd9\u4e2a\u6570\u76ee, \u5c31\u662ftoken_embedding.shape[0],\u590d\u5236\u8fd9\u4e48\u591a\u4efd\uff0c\u56e0\u4e3a\u8fd9\u91cc\u662fbatch\u8fd9\u4e2a\u683c\u5f0f\uff0c\u90a3\u540e\u9762\u8fd9\u4e2a\u4f4d\u7f6e \u6216\u8005\u8bf4\u901a\u9053 \u90fd\u4e0d\u7528\u590d\u5236\uff0c\u8fd9\u6837\u5f97\u5230 position embedding\uff0c</p> <p></p> <p>\u6700\u540eposition embedding \u518d\u548c token embedding\u76f8\u52a0\uff1b</p> <p></p> <p>\u8fd9\u6837\u5b9e\u73b0\u4e86position embedding\u52a0\u5165\u5230token embedding\u4e4b\u4e2d\uff0c\u5b8c\u6210\u4e86\u7b2c\u4e09\u6b65</p>"},{"location":"learning/vit/#44-transformer-encoder","title":"4.4  Transformer Encoder","text":"Python<pre><code># step4 Pass embedding to Transformer Encoder\n# d_model = model_dim = 8\nencoder_layer = nn.TransformerEncoderLayer(d_model=model_dim,nhead=8)\ntransformer_encoder = nn.TransformerEncoder(encoder_layer,num_layers=6)\n# token_embedding = 1,5,8(\u53ef\u4ee5\u7406\u89e3\u4e3a 5\u4e2a\u8bcd\uff0c\u6bcf\u4e2a\u8bcd \u5d4c\u5165 8\u4e2a\u7ef4\u5ea6)\nencoder_output = transformer_encoder(token_embedding)\n</code></pre> <p>\u63a5\u4e0b\u6765 \u7b2c\u56db\u6b65\uff0c\u6309\u7167\u8bba\u6587\u4e2d\u7684\u56fe\uff0c\u7b2c\u56db\u6b65\u6bd4\u8f83\u7b80\u5355\u4e86\uff0c\u76f4\u63a5\u5c06embedding\u9001\u5230transformer encoder\uff0c\u8fd9\u90e8\u5206\u6bd4\u8f83\u7b80\u5355</p> <p></p> <p>\u6211\u4eec\u9700\u8981\u6765\u770b\u4e00\u4e0b pytorch\u7684transformer encoder\u7684api</p> <p></p> <p>\uff0c\u800c\u4e0d\u53bb\u5199 \u4e00\u4e2a\u5177\u4f53\u7684\u4ee3\u7801</p> <p></p> <p>\u8fd9\u91ccpytorch\u5df2\u7ecf\u628atransformer \u5b8c\u6574\u7684\u5b9e\u73b0\u4e86\u5206\u4e3aencoder\u3001decoder\u3001encoderLayer\u3001decoderLayer\u4e4b\u7c7b\u7684\uff1b\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u4f8b\u5b50</p> <p></p> <p>\u9996\u5148 \u5b9e\u4f8b\u5316\u4e00\u4e2a encoderLayer,encoderLayer\u5b9e\u9645\u4e0a\u5c31\u662fMHA+FFN\u6784\u6210\u7684\uff1b\u7136\u540e\u518d\u628alayer\u8fd9\u4e2a\u5bf9\u8c61\uff0c\u9001\u5230 encoder\u4e2d\uff0c\u5e76\u4e14\u5b9a\u4e49\u597d num_layers,\u5f97\u5230encoder\u5bf9\u8c61\uff1b</p> <p>\u7b2c\u56db\u6b65 \u628a embedding\u9001\u5165\u5230 transformer\u4e2d\uff0c</p> <p>\u590d\u5236\u4f8b\u5b50\uff0c\u628ad_model=512\u6539\u6210 d_model=model_dim</p> Python<pre><code>encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim,n_head=8)\n</code></pre> <p>\u628a encoder layer\u9001\u5165\u5230 encoder\u4e2d\uff0c\u5b9e\u4f8b\u5316\u4e00\u4e2a nn.TransformerEncoder,\u90fd\u4eff\u7167\u4f8b\u5b50\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u662fencoder_layer,\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f num_layers,\u8fd9\u6837\u5c31\u5f97\u5230\u4e86 transformer_encoder</p> Python<pre><code>transformer_encoder = nn.TransformerEncoder(encoder_layer,num_layers=6)\n</code></pre> <p>transformer_encoder\u76f4\u63a5\u4ee5 token_embedding\u4f5c\u4e3a\u8f93\u5165\u5c31\u597d\u4e86,\u5ffd\u7565 mask,\u5f97\u5230 encoder output</p> Python<pre><code>encoder_output = transformer_encoder(token_embedding)\n</code></pre>"},{"location":"learning/vit/#45-classification-head","title":"4.5 classification head","text":"Python<pre><code># step5 do classification\ncls_token_output = encoder_output[:,0,:]\nlinear_layer = nn.Linear(model_dim,num_classes)\nlogits = linear_layer(cls_token_output)\nloss_fn = nn.CrossEntropyLoss()\nloss = loss_fn(logits,label)\nprint(loss)\n</code></pre> <p>\u7b2c\u4e94\u6b65\uff0c</p> <p></p> <p>\u53d6\u51fa class token\u8fd9\u4e2a\u4f4d\u7f6e\u4e0a\u7684 \u7279\u5f81\u8f93\u51fa\uff0c\u7136\u540e\u628a\u5b83\u6620\u5c04\u5230\u7c7b\u522b\u4e0a\u9762\uff0c\u5f97\u5230\u6982\u7387\u5206\u5e03\uff0c\u8ddf\u6807\u7b7e \u8ba1\u7b97 \u4ea4\u53c9\u71b5\uff0c\u8fdb\u884c\u6a21\u578b\u7684 \u8bad\u7ec3</p> Python<pre><code># step5 do classification\n</code></pre> <p>\u9996\u5148 \u5c06\u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u7684 \u72b6\u6001 \u53d6\u51fa\u6765\uff0c\u5b9a\u4e49 cls_token_output,\u56e0\u4e3a encoder output\u662f \u4e09\u7ef4\u7684\uff0c\u90a3\u4e48 \u7b2c\u4e00\u7ef4\u662fbatch size\u4e0d\u7528\u7ba1\uff1b\u7b2c\u4e8c\u7ef4\u662f\u4f4d\u7f6e \u5199\u4e2a0\uff0c\u8868\u793a\u7b2c\u4e00\u4e2a\uff1b\u7b2c\u4e09\u7ef4\u662f \u901a\u9053\u6570\u76ee \u4e5f\u4e0d\u7528\u7ba1</p> Python<pre><code>cls_token_output = encoder_output[:,0,:]\n</code></pre> <p>\u8fd9\u6837\u5f97\u5230\u4e86 \u7b2c\u4e00\u4e2a\u4f4d\u7f6e\u4e0a \u7684 encoder \u7684\u8f93\u51fa\uff1b\u6211\u4eec\u5c06\u5176 \u6620\u5c04\u5230\u7c7b\u522b\u4e0a\uff1b\u6240\u4ee5 \u6211\u4eec\u9700\u8981 \u518d\u5b9a\u4e49\u4e00\u4e2a \u5e38\u91cf \u53ebnum_classes\uff0c\u8fd9\u662f\u7c7b\u522b\u6570\u76ee</p> Python<pre><code>num_classes = 10\n</code></pre> <p>\u518d\u5b9e\u4f8b\u5316 \u4e00\u4e2ann.Linear()\u5c42\uff0c\u4e5f\u5c31\u662fpytorch\u4e2d\u7684nn.Linear()\u5c42\uff0c\u8f93\u5165\u7684\u901a\u9053\u6570 \u662f model_dim,\u56e0\u4e3a transformer\u7684\u8f93\u51fa\u5c31\u662f model_dim  \u5c31\u662f\u5927\u5c0f\uff0c\u8f93\u51fa\u7684\u7279\u5f81\u6570 \u5c31\u662f num_classes;\u8fd9\u662f\u4e3a\u4e86 \u5206\u7c7b\u4e4b\u524d \u5bf9 encoder output \u505a\u4e00\u4e2a \u6620\u5c04\uff0c\u5f97\u5230 linear_layer</p> Python<pre><code>linear_layer = nn.Linear(model_dim,num_classes)\n</code></pre> <p>\u7136\u540e\u8fd9\u4e2a linear_layer\u8fdb\u884c \u8c03\u7528\u4e00\u4e0b\uff0c\u4ee5class token output \u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd9\u6837\u5f97\u5230 logits\uff0c</p> Python<pre><code>logits = linear_layer(cls_token_output)\n</code></pre> <p>logits\u662f\u6ca1\u6709\u8fc7softmax\u7684\uff0c\u63a5\u4e0b\u6765 \u56e0\u4e3a \u5728 loss function\u4e2d\u662f\u4f1a\u8c03\u7528softmax\u7684</p> <p>\u73b0\u5728 \u6211\u4eec\u5b9e\u4f8b\u5316\u4e00\u4e2a loss function\uff0cnn.CrossEntropyLoss()\u8fd9\u4e2a\u51fd\u6570\u7528\u5f97\u6bd4\u8f83\u591a \u4e0d\u7528\u67e5\u4e86</p> Text Only<pre><code> loss_fn = nn.CrossEntropyLoss()\n</code></pre> <p>\u5f53\u7136 \u8fd9\u4e2a loss_fn\uff0c\u662f\u4ee5logits\u548cLabel\u4f5c\u4e3a \u8f93\u5165</p> Python<pre><code>loss_fn(logits,label)\n</code></pre> <p>\u5f97\u5230loss</p> Python<pre><code>loss = loss_fn(logits,label)\n</code></pre> <p>\u63a5\u4e0b\u6765 \u5b9a\u4e49  Label \u8fd9\u4e2a\u6807\u7b7e\uff0cLabel \u662f\u4e00\u4e2a\u6574\u578b\u7684\u6807\u7b7e\uff0ctorch.randint()\u751f\u62100\u2014\u201410\u4ee5\u5185\u7684\u5f20\u91cf\uff0c\u5927\u5c0f\u662f batch size\u8fd9\u4e2a\u7ef4\u5ea6\uff0c\u8fd9\u6837 \u6211\u4eec\u751f\u6210\u4e86Label</p> Python<pre><code>label = torch.randint(10,(bs,))\n</code></pre> <p>\u8fd9\u6837 \u6211\u4eec \u751f\u6210\u4e86 label\uff0c\u6211\u4eec\u628a label\uff0c\u4f20\u5165\u5230loss function\u4e2d\uff0c\u8ba1\u7b97 loss\uff0c\u6700\u540e\u6253\u5370loss\uff0c\u63a5\u4e0b\u6765 \u6d4b\u8bd5</p>"},{"location":"learning/vit/#_1","title":"\u603b\u7ed3","text":"Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef image2emb_navie(image,patch_size,weight):\n    # image shape:bs  \u00d7 channel \u00d7 height \u00d7 width\n    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n    patch_embedding = patch @ weight\n    return patch_embedding\ndef image2emb_conv(image,kernel,stride):\n    conv_output = F.conv2d(image,kernel,stride=stride) # bs*oc*oh*ow\n    bs,oc,oh,ow = conv_output.shape\n    patch_embedding = conv_output.reshape((bs,oc,oh*ow)).transpose(-1,-2)\n\n    return patch_embedding\n\n# test code for image2emb\nbs,ic,image_h,image_w = 1,3,8,8\npatch_size = 4\nmodel_dim = 8\nmax_num_token = 16\nnum_classes = 10\nlabel = torch.randint(10,(bs,))\n\npatch_depth = patch_size * patch_size * ic\nimage = torch.randn(bs,ic,image_h,image_w)\nweight = torch.randn(patch_depth,model_dim) # model_dim\u662f\u8f93\u51fa\u901a\u9053\u6570\u76ee\uff0cpatch depth\u662f\u5377\u79ef\u6838\u7684\u9762\u79ef\u4e58\u4ee5\u8f93\u5165\u901a\u9053\u6570\n\npatch_embedding_naive = image2emb_navie(image,patch_size,weight)  # \u5206\u5757\u65b9\u6cd5\u5f97\u5230embedding\nkernel = weight.transpose(0,1).reshape((-1,ic,patch_size,patch_size))   # oc*ic*kh*kw\n\npatch_embedding_conv = image2emb_conv(image,kernel,patch_size) # \u4e8c\u7ef4\u5377\u79ef\u65b9\u6cd5\u5f97\u5230embedding\n\n# print(patch_embedding_naive)\n# print(patch_embedding_conv)\n\n# step2 prepend CLS token embedding\ncls_token_embedding = torch.randn(bs,1,model_dim,requires_grad=True)\ntoken_embedding = torch.cat([cls_token_embedding,patch_embedding_conv],dim=1)\n\n# step3 add position embedding\npositon_embedding_table = torch.randn(max_num_token,model_dim,requires_grad=True)\nseq_len = token_embedding.shape[1]\npositon_embedding = torch.tile(positon_embedding_table[:seq_len],[token_embedding.shape[0],1,1])\ntoken_embedding += positon_embedding\n\n# step4 Pass embedding to Transformer Encoder\nencoder_layer = nn.TransformerEncoderLayer(d_model=model_dim,nhead=8)\ntransformer_encoder = nn.TransformerEncoder(encoder_layer,num_layers=6)\nencoder_output = transformer_encoder(token_embedding)\n\n# step5 do classification\ncls_token_output = encoder_output[:,0,:]\nlinear_layer = nn.Linear(model_dim,num_classes)\nlogits = linear_layer(cls_token_output)\nloss_fn = nn.CrossEntropyLoss()\nloss = loss_fn(logits,label)\nprint(loss)\n</code></pre> <p>\u4ee5\u4e0a\u5b9e\u73b0\u4e86 \u6574\u4e2a vit\uff0c\u4ece\u8f93\u5165 \u5230 loss\uff0c\u5168\u90e8\u5b9e\u73b0\u4e86\uff1b\u5176\u4e2dimage2embedding\u7684\u8fc7\u7a0b\u7528\u4e24\u79cd\u65b9\u5f0f\u5b9e\u73b0\u4e86</p> <p>\u8fd9\u4e24\u79cd\u65b9\u5f0f\uff0c\u662f\u5728 \u5f00\u59cb\u7684\u65f6\u5019 \u5c55\u5f00\uff0c\u8fd8\u662f\u5728 \u5377\u79ef\u8fc7\u540e \u518d\u5c55\u5f00\uff0c\u4e24\u4e2a\u4e0d\u540c\u7684\u89d2\u5ea6\uff1b</p> <p>\u7136\u540e\u9700\u8981\u5728\u5e8f\u5217\u4e4b\u524d \u52a0\u5165cls token\uff1b</p> <p>\u7b2c\u4e09\u6b65 \u5bf9token embedding \u52a0\u5165 position embedding\uff1b\u6309\u7167\u8bba\u6587\u7684\u610f\u601d\u5c31\u662f\u589e\u52a0\u4e00\u4e2a \u53ef\u8bad\u7ec3\u7684embedding</p> <p>\u7b2c\u56db\u6b65 \u5c06 embedding\u4f20\u5165\u5230encoder\u4e2d</p> <p>\u7b2c\u4e94\u6b65 \u5c31\u662fclass token \u90a3\u4e2a\u4f4d\u7f6e\u4e0a\u7684output\uff0c\u505a\u4e00\u4e2a\u53d8\u6362\uff0c\u5f97\u5230 \u8981\u5206\u7c7b\u7684\u6982\u7387\u5206\u5e03\uff0c\u6700\u540e\u901a\u8fc7 \u4ea4\u53c9\u71b5\uff0c\u6765\u7b97\u51fa \u5206\u7c7b loss\uff1b</p> <p>\u603b\u4f53\u4e0a\u5c31\u662f \u8fd9\u6837\u7684\u8fc7\u7a0b\uff1b\u6240\u4ee5vit\u6a21\u578b \u4e0d\u7ba1\u662f \u6a21\u578b\u4e0a \u8fd8\u662f \u4ee3\u7801\u5b9e\u73b0 \u4e0a \u90fd\u6bd4\u8f83\u7b80\u5355\uff1b\u60f3\u6cd5\u4e5f\u5f88\u7b80\u5355 \u4f46\u662f\uff0c\u8bad\u7ec3\u6210\u672c\u5f88\u9ad8\uff0c\u9700\u8981\u5f88\u591a \u56fe\u7247\u6570\u636e \u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u624d\u80fd\u53d6\u5f97 \u8ddfCNN\u4e00\u6837\u7684\u6548\u679c\uff1b\u4e4b\u540e\u4e5f\u6709\u5f88\u591a\u5de5\u4f5c \u5c06 transformer\u5e94\u7528\u5230 \u68c0\u6d4b\u3001\u5206\u5272\u9886\u57df \uff1b\u73b0\u5728 \u53ea\u662f \u8bb2\u4e86 \u8bc6\u522b\u7684\u9886\u57df\uff1bvit\u4f5c\u8005\u4e5f\u63d0\u5230\u4e86 \u76ee\u524d\u53ea\u662f\u7528\u5230\u4e86 \u8bc6\u522b\u9886\u57df\uff0c\u540e\u9762\u6bd4\u8f83\u706b\u7684 swintransformer\uff0c\u4e00\u65b9\u9762\u964d\u4f4evit\u6a21\u578b\u7684\u8ba1\u7b97\u91cf\uff0c\u53e6\u4e00\u65b9\u9762 vit\u66f4\u52a0\u6a21\u4eff\u4e86CNN\u7684\u7ed3\u6784\uff0c\u6765\u53bb \u4e0d\u65ad\u5bf9 patch \u8fd9\u4e2a\u7ef4\u5ea6 \u8fdb\u884c\u964d\u7ef4\uff0c\u7136\u540e\u4e5f\u4f1a\u5bf9patch \u7684 weight \u8fdb\u884c\u53d8\u52a8\uff0cswintransformer\u4e0d\u4ec5\u5728 \u56fe\u50cf\u8bc6\u522b\u4e0a\uff0c\u5728\u68c0\u6d4b\u4e0a \u5728 \u5206\u5272\u4e0a \u90fd\u53d6\u5f97\u4e86 \u6bd4\u8f83\u597d\u7684\u6548\u679c\u3002</p>"},{"location":"literature/","title":"\u6587\u732e\u9605\u8bfb","text":""},{"location":"literature/#_1","title":"\u6587\u732e\u9605\u8bfb","text":"2024-12-11 22:29:492025-09-28 12:54:06 <p> \u7ea6 32 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>Abstract</p> <p>\u4e00\u4e9b\u7cbe\u8bfb\u8fc7\u7684\u6587\u732e</p> <p>2024.08-2025.02: \u76ee\u6807\u8ba1\u6570</p> <p>\u4e2d\u9014\u6362\u65b9\u5411\u4e86\uff0c\u8dd1\u4e0d\u8d77\u6765\u4e00\u70b9</p> <p>2025.02-now TSP</p>"},{"location":"literature/ObejectCounting/","title":"\u7d22\u5f15\u9875","text":""},{"location":"literature/ObejectCounting/#_1","title":"\u7d22\u5f15\u9875","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 325 \u4e2a\u5b57  5 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p>"},{"location":"literature/ObejectCounting/#todo","title":"TODO","text":"<ul> <li> <p> \u6574\u7406\u8bfb\u8fc7\u7684\u6587\u732e</p> </li> <li> <p> DINO \u68c0\u6d4b&amp;\u8ba1\u6570</p> </li> </ul> <p></p>"},{"location":"literature/ObejectCounting/#_2","title":"\u4e92\u8054\u7f51\u8d44\u6e90","text":"<ul> <li>CCF\u671f\u520a\u5206\u533a\u67e5\u8be2</li> </ul> <ul> <li>Object Counting on FSC147 in paper with code</li> </ul> <ul> <li>\u90d1\u4e4b\u6770 \u76ee\u6807\u8ba1\u6570(Object Counting) </li> </ul> <p>Tips</p> <p>\u9605\u8bfb\u903b\u8f91\uff1a</p> <ol> <li>\u6458\u8981\u3001\u5f15\u8a00-\u8d21\u732e\u3001\u7ed3\u8bba\uff08\u6709\u4e9b\u4f1a\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\uff09  </li> <li>introdution\u76f8\u5f53\u4e8e \u7814\u7a76\u80cc\u666f\u53ca\u610f\u4e49 \u7ed9\u51fa motivation  </li> <li>related work \u4f1a\u7ed9\u51fa\u7814\u7a76\u73b0\u72b6  </li> <li>method \u90e8\u5206 \u5173\u6ce8\u5c0f\u6807\u9898  </li> <li>experiment \u90fd\u505a\u4e86\u4ec0\u4e48\u5b9e\u9a8c \uff1a\u6cdb\u5316\uff08\u6570\u636e\u96c6\u3001\u4efb\u52a1\uff09\u3001\u5bf9\u6bd4\uff08\u65b9\u6cd5\uff09\u3001\u6d88\u878d \uff08\u6a21\u5757\uff09</li> </ol> <p>\u4e00\u70b9\u6709\u8da3\u7684\u53d1\u73b0\uff1a</p> <p>GeCo\u4f5c\u8005\uff1a27 Sep 2024 \u00b7 Jer Pelhan, Alan Luke\u017ei\u010d, Vitjan Zavrtanik, Matej Kristan</p> <p>LOCA\u4f5c\u8005\uff1a ICCV 2023  \u00b7 Nikola Djukic, Alan Lukezic, Vitjan Zavrtanik, Matej Kristan </p> <p>DAVE\u4f5c\u8005\uff1a25 Apr 2024 \u00b7 Jer Pelhan, Alan Luke\u017ei\u010d, Vitjan Zavrtanik, Matej Kristan \uff08\u4ed3\u5e93\u7684\u5171\u540c\u4f5c\u8005\u4e4b\u4e00\uff1aCounTR\uff09\uff08Jer\uff1aDAVE &amp; GeCo\uff09</p> <p>CounTR\u4f5c\u8005\uff1a29 Aug 2022 \u00b7 Chang Liu, Yujie Zhong, Andrew Zisserman, Weidi Xie  SHJT</p> <p>semAug counTR\u4f5c\u8005\uff1a26 Oct 2023 \u00b7 Perla Doubinsky, Nicolas Audebert, Michel Crucianu, Herv\u00e9 Le Borgne \u00b7</p> <p>SemAug-SAFECount\uff1a26 Oct 2023 \u00b7 Perla Doubinsky, Nicolas Audebert, Michel Crucianu, Herv\u00e9 Le Borgne \u00b7</p> <p></p> <p>22 Jan 2022 \u00b7 Zhiyuan You, Kai Yang, Wenhan Luo, Xin Lu, Lei Cui, Xinyi Le \uff08Tsinghua\u3001SHJT\uff09</p>"},{"location":"literature/ObejectCounting/#1","title":"1","text":"<ul> <li>multi-scale feature fusion module</li> <li>Transformer \u2192ViT\u2192SwinTransformer</li> <li>GAN\u2192diffusion\uff08text to image\uff09</li> <li>multimodle\uff1aclip\uff08text and image\uff09\uff1buser interaction</li> <li>SPDCN \u4fee\u6539\u4e86 \u635f\u5931\u51fd\u6570 \uff1b\u6839\u636e\u793a\u4f8b\u5c3a\u5bf8\u7684\u4e0d\u540c \u8c03\u6574\u635f\u5931\u51fd\u6570\u7684\u5f62\u5f0f</li> </ul>"},{"location":"literature/ObejectCounting/#2","title":"2","text":"<ul> <li>\u8ba1\u6570\u65b9\u6cd5  rank8 CounTR</li> <li>\u7c7b\u65e0\u5173\u8ba1\u6570 rank8 CounTR</li> <li>\u6570\u636e\u751f\u6210 rank7 SemAug CounTR</li> </ul>"},{"location":"literature/ObejectCounting/#_3","title":"\u6587\u732e\u7efc\u8ff0","text":"<ol> <li> <p>FamNet</p> </li> <li> <p>SAFECount</p> </li> <li> <p>GMN</p> </li> <li> <p>BMNet</p> </li> <li> <p>CounTR</p> </li> <li> <p>CountGD</p> </li> </ol>"},{"location":"literature/ObejectCounting/rank1%20CountGD/","title":"rank1 CountGD","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 5789 \u4e2a\u5b57  16 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 29 \u5206\u949f</p>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#_1","title":"\u591a\u6a21\u6001\u7279\u5f81\u5f00\u653e\u4e16\u754c\u76ee\u6807\u8ba1\u6570","text":"<p>2024\u5e747\u67085\u65e5 \u53d1\u8868</p> <p>5 Jul 2024 \u00b7 Niki Amini-Naieni, Tengda Han, Andrew Zisserman \u00b7 </p> <p></p>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#countgd-multi-modal-open-world-counting","title":"CountGD: Multi-Modal Open-World Counting","text":"<p>\u539f\u6587\u94fe\u63a5</p> <p>\u4e3a\u4e86\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4ec0\u4e48\u6837\u7684\u89e3\u51b3\u65b9\u6cd5\u3002</p> <p>\u6587\u672c\u63cf\u8ff0\u548c\u89c6\u89c9\u4fe1\u53f7\uff0c\u4e00\u8d77\u8fdb\u884c\u8ba1\u6570\uff0c\u6587\u672c\u63cf\u8ff0\u6bd4\u5982\u4f1a\u8fc7\u6ee4\u989c\u8272\uff0c\u4f4d\u7f6e\u7b49\uff1b</p> <p>\u4e00\u53e5\u8bdd\u603b\u7ed3\u672c\u6587\uff1aHere, we describe COUNTGD, a single-stage model for open-world object counting that accepts either visual exemplars or text or both together as prompts to specify the object to count.</p> <p>\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u63cf\u8ff0\u4e86COUNTGD\uff0c\u4e00\u4e2a\u5f00\u653e\u4e16\u754c\u7269\u4f53\u8ba1\u6570\u7684\u5355\u9636\u6bb5\u6a21\u578b\uff0c\u5b83\u63a5\u53d7\u89c6\u89c9\u6837\u672c\u6216\u6587\u672c\u6216\u4e24\u8005\u5171\u540c\u4f5c\u4e3a\u63d0\u793a\u6765\u6307\u5b9a\u8981\u8ba1\u6570\u7684\u7269\u4f53\u3002</p> <p>Note</p> <p>COUNTGD\u7684\u51e0\u4e2a\u5173\u952e\u8bcd\uff0c\u5f00\u653e\u4e16\u754c\u7684\u7269\u4f53\u8ba1\u6570\uff0c\u5355\u9636\u6bb5\u6a21\u578b\uff0c\u89c6\u89c9\u4fe1\u53f7\u548c\u6587\u672c\u4fe1\u53f7</p> <p>\u6587\u672c\u7279\u5f81\u54ea\u91cc\u6765\u5462\uff1f</p> <ul> <li>\u5bf9\u4e8eFSC147\u6570\u636e\u96c6\uff0cFor text descriptions, we use the singular forms of the class names in <code>FSC-147-D [1]</code> with any prefixes such as \u201cthe\" removed. For example, we change \u201cthe donuts in the donut tray\" in FSC-147-D to \u201cdonut\" by removing the prefix \u201cthe,\" extracting the class name \u201cdonuts,\" and then singularizing it to \u201cdonut.\"  \u6258\u76d8\u4e2d\u7684\u751c\u751c\u5708 \\(\\rightarrow\\) \u751c\u751c\u5708</li> <li>CARPK\uff1aWe use the class name \u201ccar\" as the text description.</li> </ul>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#_2","title":"\u6458\u8981","text":"<p>The goal of this paper is to improve the generality and accuracy of open-vocabulary object counting in images. </p> <p>\u4e3a\u4e86\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6cdb\u5316\u6027\uff0c\u8ba1\u6570\u73b0\u5b9e\u8bcd\u8868\u4e2d\u7684\u4e00\u5207\u7269\u4f53</p> <p>To improve the generality, we repurpose an open vocabulary detection foundation model (GroundingDINO) for the counting task, and also extend its capabilities by introducing modules to enable specifying the target object to count by visual exemplars. </p> <p>\u4e3a\u4e86\u63d0\u9ad8\u6cdb\u5316\u6027\uff0c\u91cd\u65b0\u8bbe\u8ba1\u57fa\u4e8e\u5f00\u653e\u8bcd\u8868\u7684\u68c0\u6d4b\u6a21\u578b\uff1aGroundingDINO</p> <p>\u589e\u52a0\u6a21\u5757\uff0c\u901a\u8fc7\u6837\u4f8b\u6846\u6307\u5b9a\u8ba1\u6570\u76ee\u6807</p> <p>In turn, these new capabilities \u2013 being able to specify the target object by multi-modalites (text and exemplars) \u2013 lead to an improvement in counting accuracy. </p> <p>\u901a\u8fc7\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u6307\u5b9a\u8ba1\u6570\u76ee\u6807\uff0c\u63d0\u9ad8\u8ba1\u6570\u7684\u51c6\u786e\u6027</p> <p>we introduce the first open-world counting model, COUNTGD, where the prompt can be specified by a text description or visual exemplars or both; </p> <p>\u672c\u6587\u63d0\u51fa\u7684\u6a21\u578b\uff1aCOUNTGD\uff0c\u53ef\u4ee5\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\uff1a\u6587\u672c\u3001\u89c6\u89c9\u6837\u4f8b\u3001\u6216\u8005\u4e24\u4e2a\u90fd</p>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#-","title":"\u5f15\u8a00-\u8d21\u732e","text":"<p>In summary, we make the following three contributions: </p> <p>First, we introduce COUNTGD, the first openworld object counting model that accepts either text or visual exemplars or both simultaneously, in a single-stage architecture; </p> <p>\u5355\u4e00\u7ed3\u6784\uff0c\u540c\u65f6\u63a5\u6536\u6587\u672c\u4fe1\u53f7\u548c\u89c6\u89c9\u4fe1\u53f7\u8fdb\u884c\u8ba1\u6570</p> <p>Second, we evaluate the model on multiple standard counting benchmarks, including FSC-147 [39], CARPK [18] and CountBench [36], and show that COUNTGD significantly improves on the state-of-the-art performance by specifying the target object using both exemplars and text. It also meets or improves on the state-of-the-art for text-only approaches when trained and evaluated using text-only; </p> <p>\u672c\u6587\u6240\u7528\u6570\u636e\u96c6\uff1aFSC-147 [39], CARPK [18] and CountBench [36]</p> <p>Third, we investigate how the text can be used to refine the visual information provided by the exemplar, for example by filtering on color or relative position in the image, to specify a sub-set of the objects to count.</p> <p>\u6587\u672c\u662f\u5982\u4f55\u7ec6\u5316\u7531\u6837\u4f8b\u63d0\u4f9b\u7684\u89c6\u89c9\u4fe1\u606f\u7684\uff0c\u6bd4\u5982\uff1a\u901a\u8fc7\u5bf9\u56fe\u50cf\u4e2d\u7684\u989c\u8272\u6216\u76f8\u5bf9\u4f4d\u7f6e\u8fdb\u884c\u8fc7\u6ee4\uff0c\u6765\u6307\u5b9a\u8981\u8ba1\u6570\u7684\u5bf9\u8c61\u7684\u5b50\u96c6</p> <p>In addition we make two minor improvements to the inference stage: one that addresses the problem of double counting due to self-similarity, and the other to handle the problem of a very high count.</p> <p>\u63a8\u7406\u9636\u6bb5\u7684\u4e24\u4e2a\u6539\u8fdb\uff1a</p> <ul> <li>\u7531\u4e8e\u81ea\u76f8\u4f3c\u6027\u7684\u91cd\u590d\u8ba1\u6570\u95ee\u9898</li> <li>\u6781\u5ea6\u5bc6\u96c6\u573a\u666f\u7684\u8ba1\u6570\u95ee\u9898</li> </ul> <p>\u76ee\u6807\u8ba1\u6570\u7684\u4e24\u5927\u95ee\u9898\uff1a</p> <p>\u7269\u4f53\u5806\u53e0\u5bfc\u81f4\u7684\u91cd\u590d\u8ba1\u6570</p> <p>\u5bc6\u96c6\u573a\u666f\u7684\u8ba1\u6570\u95ee\u9898 </p> \u96be\u9053\u4e0d\u662f\u540c\u4e00\u4e2a\u95ee\u9898\uff1f"},{"location":"literature/ObejectCounting/rank1%20CountGD/#conclusion-future-work","title":"Conclusion &amp; Future Work","text":"<p>We have extended the generality of open-world counting by introducing a model that can accept visual exemplars or text descriptions or both as prompts to specify the target object to count. </p> <p>\u7b2c\u4e00\u70b9\u6211\u4eec\u8fdb\u884c\u4e86\u5f00\u653e\u4e16\u754c\u7684\u8bed\u4e49\u7269\u4f53\u8ba1\u6570\u95ee\u9898\uff0c\u63a5\u6536\u6587\u672c\u63cf\u8ff0\u548c\u793a\u4f8b\u6846\u4fe1\u606f\u6216\u8005\u5171\u540c</p> <p>me\uff1a\u5f00\u653e\u4e16\u754c\u7684\u8bed\u4e49\u7269\u4f53\u8ba1\u6570\u3001\u6587\u672c\u63cf\u8ff0\u548c\u89c6\u89c9\u793a\u4f8b\u6846</p> <p>\u6587\u672c\u63cf\u8ff0\u662f\u5bf9\u793a\u4f8b\u6846\u7269\u4f53\u7684\u9009\u62e9\u5f15\u5165\u989d\u5916\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u77ed\u8bed\u9650\u5236</p> <p>The complementarity of these prompts in turn leads to improved counting performance. </p> <p>\u672a\u6765\u7684\u4e09\u4e2a\u7814\u7a76\u65b9\u5411\uff1a</p> <p>There are three research directions that naturally follow on from this work: </p> <p>(i) the performance could probably be further improved by training on larger scale datasets, for example using synthetic data as demonstrated recently for counting [24]; </p> <p>\u7b2c\u4e00\u4e2a\u7814\u7a76\u65b9\u5411\uff1a\u6269\u5c55\u8f93\u5165\u6570\u636e\u7684\u4e30\u5bcc\u6027\uff0c\u6bd4\u5982\u5408\u6210\u6570\u636e\uff0c\u545c\u545c\u545c\u545c\uff0c\u8ddf\u6211\u60f3\u7684\u4e00\u6837 </p> <p>(ii) a larger training set would enable a thorough investigation of freezing more of the GroundingDINO model when adding our new visual exemplar modules; and finally, </p> <p>\u66f4\u5927\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5bf9GroundingDINO\u6a21\u578b\u8fdb\u884c\u66f4\u5f7b\u5e95\u7684\u5b9e\u9a8c</p> <p>(iii) the model does not currently predict the errors of its counting. We discuss this point in the Limitations in the Appendix.</p> <p>Note</p> <p>countGD\uff1b\u5f00\u653e\u4e16\u754c\u7684\u8bed\u4e49\u7269\u4f53\u8ba1\u6570\u95ee\u9898\uff1b\u6cdb\u5316\u6027\u51c6\u786e\u6027\uff1btext and exemplar</p>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#related-work","title":"Related Work","text":"<p>Prior work on object counting has developed along three axes: \u76ee\u6807\u8ba1\u6570\u7684\u4e09\u4e2a\u7814\u7a76\u7ef4\u5ea6</p> <p>(1) the density map versus detection axis, \u57fa\u4e8e\u56de\u5f52\u7684 &amp; \u57fa\u4e8e\u68c0\u6d4b\u7684</p> <p>(2) the class-specific versus open-world (also referred to as \u201cclass-agnostic\") axis, and \u7279\u5b9a\u7c7b\u522b\u8ba1\u6570 &amp; \u5f00\u653e\u4e16\u754c\u7269\u4f53\u8ba1\u6570\uff08\u7c7b\u522b\u4e0d\u654f\u611f\u8ba1\u6570\uff09</p> <p>(3) the visual exemplar versus text axis.  \u57fa\u4e8e\u89c6\u89c9\u4fe1\u53f7\u7684\u8ba1\u6570 \u548c \u57fa\u4e8e\u6587\u672c\u7684\u8ba1\u6570</p> <p>The pattern is that detection, open-world, and text-based methods tend to offer more capabilities and be more general than their analogues along each axis. </p> <p>\u57fa\u4e8e\u68c0\u6d4b\u3001\u5f00\u653e\u4e16\u754c\u3001\u6587\u672c\u7684\u65b9\u6cd5\uff0c\u6cdb\u5316\u6027\u66f4\u597d</p> <p>On the other hand, density map, class-specific, and visual exemplar-based methods tend to be more accurate at the counting tasks they apply to. </p> <p>\u57fa\u4e8e\u56de\u5f52\u5bc6\u5ea6\u56fe\u3001\u7279\u5b9a\u7c7b\u522b\u3001\u89c6\u89c9\u6837\u4f8b\u6846\u7684\u51c6\u786e\u6027\u66f4\u597d</p> <p>COUNTGD integrates the third axis \u2013 the visual exemplar versus text axis \u2013 to achieve more general and accurate counting overall. Below, we discuss where prior work falls along each axis and where COUNTGD stands.</p> <p>COUNTGD\u6574\u5408\u4e86\u7b2c\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u65e2\u7528\u6587\u672c\uff0c\u53c8\u7528\u793a\u4f8b\u6846</p> <p>Note</p> <p>\u6211\u4eec\u8fd9\u4e2acounGD\u6574\u5408\u4e86\u7b2c\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u65e2\u6709\u89c6\u89c9\u4fe1\u53f7\u53c8\u6709\u6587\u672c\u4fe1\u53f7\uff0c\u518d\u6b21\u5f3a\u8c03\uff0c\u6587\u672c\u4fe1\u53f7\u6cdb\u5316\u6027\u597d\u3001\u89c6\u89c9\u4fe1\u53f7\u51c6\u786e\u6027\u597d\uff0c\u56e0\u6b64\u65e2\u6709\u89c6\u89c9\u4fe1\u53f7\u53c8\u6709\u6587\u672c\u4fe1\u53f7\u7684\u6cdb\u5316\u6027\u548c\u51c6\u786e\u6027\u90fd\u5f88\u597d\u3002\u63a5\u4e0b\u6765\u8ba8\u8bba\u5148\u524d\u7684\u5de5\u4f5c\u5728\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u53d1\u5c55\u4ee5\u53caCOUNTGD</p>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#density-map-versus-detection-based-object-counting-axis-1","title":"Density Map versus Detection-based Object Counting (Axis 1).","text":"<p>\u7ef4\u5ea6\u4e00\uff1a\u57fa\u4e8e\u5bc6\u5ea6\u548c\u57fa\u4e8e\u68c0\u6d4b</p> <p>Density Map versus Detection-based Object Counting (Axis 1). </p> <p>In the past, counting techniques that regress and sum density maps [2, 3, 6, 25, 26, 33, 42], instead of detecting and enumerating bounding boxes [5, 8, 18, 35], have proven more accurate in cluttered and dense scenes. \u5728\u5148\u524d\u7684\u5de5\u4f5c\u4e2d\uff0c\u5df2\u7ecf\u8bc1\u660e\u4e86\uff0c\u57fa\u4e8e\u5bc6\u5ea6\u7684\u7269\u4f53\u8ba1\u6570\u65b9\u6cd5\u5728\u5bc6\u96c6\u573a\u666f\u4e0b\u7684\u8ba1\u6570\u9002\u7528\u6027</p> <p>For example, density map-based approaches like CounTX [1], LOCA [10], and CounTR [29] achieve lower counting errors than detection-based approaches such as Mask-RCNN [16] and RetinaNet [27] on standard counting benchmarks. </p> <p>\u4e3e\u4f8b\u8bf4\u660e\uff0c\u57fa\u4e8e\u5bc6\u5ea6\u6bd4\u57fa\u4e8e\u68c0\u6d4b\u7684\u53d1\u5c55\u4f18\u52bf\u3002</p> <p>Concurrent to our work, DAVE [37], integrates density map regression with object detection to construct a more accurate and explainable two-stage counting system. Like DAVE, COUNTGD outputs explicit object locations.</p> <p>\u4e0e\u6211\u4eec\u7684\u5de5\u4f5c\u76f8\u4e00\u81f4\uff0cDAVE [ 37 ]\u5c06\u5bc6\u5ea6\u56fe\u56de\u5f52\u4e0e\u76ee\u6807\u68c0\u6d4b\u7ed3\u5408\u8d77\u6765\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u66f4\u7cbe\u786e\u548c\u53ef\u89e3\u91ca\u7684\u4e24\u9636\u6bb5\u8ba1\u6570\u7cfb\u7edf\u3002\u4e0eDAVE\u4e00\u6837\uff0cCOUNTGD\u8f93\u51fa\u660e\u786e\u7684\u5bf9\u8c61\u4f4d\u7f6e\u3002</p> <p>Note</p> <p>DAVE\u5bc6\u5ea6\u56fe\u56de\u5f52\u548c\u7269\u4f53\u68c0\u6d4b\uff0c\u8f93\u51fa\u76ee\u6807\u7684\u4f4d\u7f6e \u4e24\u9636\u6bb5\uff0c\u51c6\u786e\u6027&amp;\u6cdb\u5316\u6027</p> <p>However, COUNTGD is a single-stage approach that achieves better counting accuracy than DAVE and other density map-based techniques.</p> <p>\u7136\u800c\uff0cCOUNTGD\u662f\u4e00\u79cd\u5355\u9636\u6bb5\u7684\u65b9\u6cd5\uff0c\u5176\u8ba1\u6570\u7cbe\u5ea6\u4f18\u4e8eDAVE\u548c\u5176\u4ed6\u57fa\u4e8e\u5bc6\u5ea6\u56fe\u7684\u6280\u672f\u3002</p> <p>Note</p> <p>\u55ef\uff0cDAVE\u4e24\u9636\u6bb5\uff0c\u6211\u4e00\u9636\u6bb5\uff0c\u800c\u4e14\u662f text&amp;exemplar</p> <p>Therefore,while density map-based approaches tend to be more accurate than detectors in highly populated scenes, recent detection-based techniques, including COUNTGD, are beginning to achieve better accuracy than density map-based alternatives.</p> <p>\u867d\u7136\u57fa\u4e8e\u5bc6\u5ea6\u56fe\u7684\u65b9\u6cd5\u5728\u4eba\u53e3\u7a20\u5bc6\u7684\u573a\u666f\u4e2d\u5f80\u5f80\u6bd4\u68c0\u6d4b\u5668\u66f4\u51c6\u786e\uff0c\u4f46\u6700\u8fd1\u7684\u57fa\u4e8e\u68c0\u6d4b\u7684\u6280\u672f\uff0c\u5305\u62ecCOUNTGD\uff0c\u5df2\u7ecf\u5f00\u59cb\u53d6\u5f97\u6bd4\u57fa\u4e8e\u5bc6\u5ea6\u56fe\u7684\u65b9\u6cd5\u66f4\u597d\u7684\u51c6\u786e\u6027\u3002</p> <p>Note</p> <p>\u867d\u7136\u57fa\u4e8e\u5bc6\u5ea6\u7684\u5f88\u597d\uff0c\u4f46\u6700\u8fd1\u57fa\u4e8e\u68c0\u6d4b\u7684\u53d1\u5c55\u4e0d\u7518\u793a\u5f31 COUNTGD \u5c31\u662f\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570</p> \u4e3a\u4ec0\u4e48\u53ebCountGD\uff1f"},{"location":"literature/ObejectCounting/rank1%20CountGD/#_3","title":"\u7ef4\u5ea6\u4e8c\uff1a\u7279\u5b9a\u7c7b\u522b \u5bf9\u6bd4 \u5f00\u653e\u4e16\u754c\u7269\u4f53\u8ba1\u6570","text":"<p>Class-specific versus Open-world Object Counting (Axis 2). </p> <p>Object counting methods first developed as class-specific techniques [3, 4, 34, 42], solving the counting problem for only one category of object, but recent methods have generalized these approaches to open-world settings, where counting arbitrary objects is possible. \u5c31\u662f\u8bf4\uff0c\u6700\u5f00\u59cb\u53d1\u5c55\u7684\u5bf9\u7279\u5b9a\u7c7b\u522b\u7684\u8ba1\u6570\uff0c\u540e\u6765\u6f14\u53d8\u6210\u5bf9\u4efb\u610f\u7269\u4f53\u7684\u8ba1\u6570\u95ee\u9898</p> <p>Class-specific methods have been developed to count cars [22], humans [4], and cells [13]. In contrast, open-world methods can count instances from all three categories [32]. </p> <p>\u4e3e\u4f8b\u5177\u4f53\u8bf4\u660e</p> <p>Because class-specific techniques are more specialized than open-world approaches, they tend to be more accurate at counting instances from the class they were designed for. </p> <p>\u5c31\u662f\u8bf4\uff0c\u9488\u5bf9\u7279\u5b9a\u7c7b\u522b\u7684\u7269\u4f53\u8ba1\u6570\u51c6\u786e\u6027\u786e\u5b9e\u5f88\u597d</p> <p>Recent advancements in Vision-Language Foundation Models (VLMs) such as CLIP [38] and GroundingDINO [30] trained on web-scale image-text pairs produce semantically rich visual and textual features. </p> <p>\u89c6\u89c9-\u8bed\u8a00\u57fa\u7840\u6a21\u578b( Vision-Language Foundation Models\uff0cVLMs )\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5982CLIP [ 38 ]\u548cGroundingDINO [ 30 ]\uff0c\u5728\u7f51\u7edc\u89c4\u6a21\u7684\u56fe\u50cf-\u6587\u672c\u5bf9\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ea7\u751f\u4e86\u8bed\u4e49\u4e30\u5bcc\u7684\u89c6\u89c9\u548c\u6587\u672c\u7279\u5f81\u3002</p> <p>Note</p> <p>emm\u5728\u8fd9\u4e48\u5927\u89c4\u6a21\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u6700\u540e\u5c31\u662f\u5f97\u5230\u4e30\u5bcc\u7684\u89c6\u89c9\u7279\u5f81\u548c\u6587\u672c\u7279\u5f81</p> <p>These features generalize to a wide range of open-world downstream tasks. Building on top of these pre-trained VLMs, recent open-world methods [1, 7, 10, 21, 29, 40, 45] have begun to surpass class-specific approaches in counting accuracy. COUNTGD, like these recent approaches, is an open-world object counter that achieves competitive performance in comparison to class-specific alternatives.</p> <p>\u8fd9\u4e9b\u7279\u5f81\u6cdb\u5316\u5230\u4e86\u5e7f\u6cdb\u7684\u5f00\u653e\u4e16\u754c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u3002\u5728\u8fd9\u4e9b\u9884\u8bad\u7ec3\u7684VLMs\u7684\u57fa\u7840\u4e0a\uff0c\u6700\u8fd1\u7684\u5f00\u653e\u4e16\u754c\u65b9\u6cd5[ 1\u30017\u300110\u300121\u300129\u300140\u300145]\u5df2\u7ecf\u5f00\u59cb\u8d85\u8d8a\u7279\u5b9a\u7c7b\u522b\u7684\u65b9\u6cd5\u5728\u8ba1\u6570\u7cbe\u5ea6\u4e0a\u3002\u4e0e\u8fd9\u4e9b\u6700\u8fd1\u7684\u65b9\u6cd5\u4e00\u6837\uff0cCOUNTGD\u662f\u4e00\u4e2a\u5f00\u653e\u4e16\u754c\u7684\u5bf9\u8c61\u8ba1\u6570\u5668\uff0c\u4e0e\u7279\u5b9a\u7c7b\u7684\u66ff\u4ee3\u54c1\u76f8\u6bd4\uff0c\u5b83\u5177\u6709\u7ade\u4e89\u6027\u7684\u6027\u80fd\u3002</p> <p>Note</p> <p>\u83b7\u5f97\u8bed\u4e49\u66f4\u52a0\u4e30\u5bcc\u7684\u7279\u5f81\uff0c\u53ef\u4ee5\u66f4\u597d\u7684\u6cdb\u5316\u5230\u4e0b\u6e38\u4efb\u52a1\u3002   </p>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#_4","title":"\u89d2\u5ea6\u4e09\uff1a\u89c6\u89c9\u7279\u5f81\u548c\u6587\u672c\u7279\u5f81","text":"<p>Counting with Visual Exemplars versus Counting with Text (Axis 3).</p> <p>Most open-world object counters approach the problem by using visual exemplars to select the objects in the input image [10, 14, 28, 29, 32, 35, 39, 40, 44, 45], but very recent work [1, 7, 19, 21, 43] has attempted to replace the visual exemplars with text, enabling new capabilities at the cost of reduced accuracy. The stateof-the-art text-based approaches, such as GroundingREC [7], CounTX [1], CLIP-Count [19], and VLCounter [21] are built on top of vision-language foundation models pretrained on large quantities of data to relate images to textual inputs and map them to a joint embedding space. </p> <p>\u5927\u591a\u6570\u5f00\u653e\u4e16\u754c\u5bf9\u8c61\u8ba1\u6570\u5668\u901a\u8fc7\u4f7f\u7528\u89c6\u89c9\u6837\u672c\u6765\u9009\u62e9\u8f93\u5165\u56fe\u50cf[ 10\u300114\u300128\u300129\u300132\u300135\u300139\u300140\u300144\u300145]\u4e2d\u7684\u5bf9\u8c61\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u4f46\u6700\u8fd1\u7684\u5de5\u4f5c[ 1\u30017\u300119\u300121\u300143]\u5c1d\u8bd5\u7528\u6587\u672c\u4ee3\u66ff\u89c6\u89c9\u6837\u672c\uff0c\u4ee5\u964d\u4f4e\u51c6\u786e\u6027\u4e3a\u4ee3\u4ef7\u6765\u5b9e\u73b0\u65b0\u7684\u529f\u80fd\u3002\u76ee\u524d\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u6587\u672c\u7684\u65b9\u6cd5\uff0c\u5982GroundingREC [ 7 ]\uff0cCounTX [ 1 ]\uff0cCLIP-Count [ 19 ]\u548cVLCounter [ 21 ]\uff0c\u90fd\u662f\u5efa\u7acb\u5728\u57fa\u4e8e\u5927\u91cf\u6570\u636e\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u8bed\u8a00\u57fa\u7840\u6a21\u578b\u4e4b\u4e0a\uff0c\u5c06\u56fe\u50cf\u4e0e\u6587\u672c\u8f93\u5165\u76f8\u5173\u8054\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230\u4e00\u4e2a\u8054\u5408\u5d4c\u5165\u7a7a\u95f4\u3002</p> <p>Note</p> <p>\u4e4b\u524d\u7684\u8ba1\u6570\u65b9\u6cd5\u90fd\u662f\u901a\u8fc7\u793a\u4f8b\u6846\u9009\u62e9\u8f93\u5165\u56fe\u50cf\u7684\u76ee\u6807\uff1b\u6700\u8fd1\u7684\u5de5\u4f5c\u5f00\u59cb\u4f7f\u7528\u6587\u672c\uff0c\u8fd8\u8bb0\u5f97\u5427\uff0c\u6587\u672c\u4fe1\u53f7\u6cdb\u5316\u6027\u597d\uff0c\u89c6\u89c9\u4fe1\u53f7\u51c6\u786e\u6027\u597d\uff0c\u56e0\u6b64\u5f53\u4f7f\u7528\u6587\u672c\u4fe1\u53f7\u65f6\uff0c\u662f\u727a\u7272\u4e86\u51c6\u786e\u6027\u3002\u7136\u540e\u5c31\u8bf4\uff0c\u57fa\u4e8e\u6587\u672c\u7684\u9884\u6d4b\u65b9\u6cd5</p> <p>This allows these foundation models to understand general concepts learned during extensive pretraining and provides a mechanism for users to specify extrinsic object properties through text. However, text-based approaches perform significantly worse than state-of-the-art visual exemplar-based approaches such as LOCA [10], CounTR [29], and few-shot DAVE [37]. For example, while both GroundingREC and COUNTGD use the pretrained GroundingDINO [30] vision-language foundation model, unlike GroundingREC, COUNTGD allows the user to input both visual exemplars and text instead of just text. This enables COUNTGD to achieve superior counting accuracy in comparison to GroundingREC.</p> <p>\u8fd9\u4f7f\u5f97\u8fd9\u4e9b\u57fa\u7840\u6a21\u578b\u80fd\u591f\u7406\u89e3\u5728\u5e7f\u6cdb\u7684\u9884\u8bad\u7ec3\u4e2d\u5b66\u4e60\u5230\u7684\u4e00\u822c\u6982\u5ff5\uff0c\u5e76\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u8fc7\u6587\u672c\u6307\u5b9a\u5916\u90e8\u5bf9\u8c61\u5c5e\u6027\u7684\u673a\u5236\u3002\u7136\u800c\uff0c\u57fa\u4e8e\u6587\u672c\u7684\u65b9\u6cd5\u7684\u6027\u80fd\u660e\u663e\u5dee\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u89c6\u89c9\u6837\u672c\u7684\u65b9\u6cd5\uff0c\u5982LOCA [ 10 ]\uff0cCounTR [ 29 ]\u548c\u5c0f\u6837\u672cDAVE [ 37 ]\u3002\u4f8b\u5982\uff0cGroundingREC\u548cCOUNTGD\u90fd\u4f7f\u7528\u4e86\u9884\u8bad\u7ec3\u7684GroundingDINO [ 30 ]\u89c6\u89c9\u8bed\u8a00\u57fa\u7840\u6a21\u578b\uff0c\u4f46\u4e0eGroundingREC\u4e0d\u540c\u7684\u662f\uff0cCOUNTGD\u5141\u8bb8\u7528\u6237\u540c\u65f6\u8f93\u5165\u89c6\u89c9\u793a\u4f8b\u548c\u6587\u672c\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6587\u672c\u3002\u8fd9\u4f7f\u5f97COUNTGD\u76f8\u6bd4GroundingREC\u5177\u6709\u66f4\u9ad8\u7684\u8ba1\u6570\u7cbe\u5ea6\u3002</p> <p>Note</p> <p>\u4f60\u77e5\u9053\u7684\u5427\uff0c\u5728\u89c6\u89c9\u6587\u672c\u6a21\u578b\u4e2d\uff0c\u53ef\u4ee5\u5b66\u5230\u4e00\u822c\u6982\u5ff5\uff0c\u6240\u4ee5\u6cdb\u5316\u6027\u66f4\u597d\u3002\u4f46\u8fd8\u662f\u90a3\u53e5\u8bdd\uff0c\u51c6\u786e\u6027\u4e0d\u591f\u3002\u8fd9\u91cc\u8fd8\u8bf4\u4e86\u4e0eCountGD\u5de5\u4f5c\u5f88\u76f8\u4f3c\u7684\u6a21\u578bGroundingREC\uff0c\u4f46\u662f\u8f93\u5165\u4fe1\u53f7\u4e0d\u4e00\u6837\uff0c\u76f8\u4f3c\u5728\u4e8e\u90fd\u662f\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684GroundingDINO\u3002\u4e0d\u76f8\u4f3c\u5728\u4e8e\u8f93\u5165\u4fe1\u53f7\u4e0d\u4e00\u6837\u7684</p> <p>Notably, DAVE [37] is a visual exemplar-based approach that also enables textual prompts, but differs from COUNTGD in three important ways:COUNTGD \u4e0eDAVE\u7684\u4e09\u4e2a\u663e\u8457\u4e0d\u540c</p> <p>(1) it does not address the case when both text and visual exemplars are available while COUNTGD does,\u89c6\u89c9\u4fe1\u53f7\u548c\u6587\u672c\u4fe1\u53f7\u90fd\u6765</p> <p>(2) its comparison between text features and image features is not learned as it is by COUNTGD with attention, and     COUNTGD\u6709\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u6587\u672c\u7279\u5f81\u548c\u56fe\u50cf\u7279\u5f81</p> <p>(3) it is a two-stage approach, while COUNTGD solves the problem in a single stage, without relying on another visual exemplar-based counting model. DAVE\u4e24\u9636\u6bb5\u68c0\u6d4b\u65b9\u6cd5</p> <p>\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cDAVE [ 37 ]\u662f\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u6837\u4f8b\u7684\u65b9\u6cd5\uff0c\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u6587\u672c\u63d0\u793a\uff0c\u4f46\u4e0eCOUNTGD\u67093\u4e2a\u91cd\u8981\u7684\u533a\u522b\uff1a( 1 )\u5b83\u6ca1\u6709\u89e3\u51b3COUNTGD\u540c\u65f6\u63d0\u4f9b\u6587\u672c\u548c\u89c6\u89c9\u6837\u4f8b\u7684\u60c5\u51b5\uff1b( 2 )\u5b83\u6ca1\u6709\u50cfCOUNTGD\u90a3\u6837\u5728\u6709\u6ce8\u610f\u529b\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u6587\u672c\u7279\u5f81\u548c\u56fe\u50cf\u7279\u5f81\u4e4b\u95f4\u7684\u6bd4\u8f83\uff1b( 3 )\u5b83\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u65b9\u6cd5\uff0c\u800cCOUNTGD\u5728\u4e00\u4e2a\u9636\u6bb5\u4e2d\u89e3\u51b3\u95ee\u9898\uff0c\u800c\u4e0d\u4f9d\u8d56\u4e8e\u53e6\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u6837\u4f8b\u7684\u8ba1\u6570\u6a21\u578b\u3002</p> <p>Note</p> <p>\u8fd9\u7bc7\u8bba\u6587\u7684\u6539\u8fdb\u8bba\u6587\u662fDAVE\uff0c\u76ee\u6807\u90fd\u662f\u4e00\u6837\u7684\uff0cmotivation\uff1a\u63d0\u9ad8\u51c6\u786e\u7387 &amp; \u53ec\u56de\u7387</p>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#relation-of-counting-to-other-areas","title":"Relation of Counting to other areas. \u4e0e\u5176\u5b83\u9886\u57df\u5de5\u4f5c\u7684\u5173\u7cfb","text":"<p>\u8ddf\u5f00\u5c71\u4e4b\u4f5c\u7684\u76f8\u5173\u5de5\u4f5c\u53d9\u8ff0\u6709\u70b9\u50cf</p> <p>Our work is related to few-shot image classification [41] and image detection [12, 20] methods.   \u5c0f\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u548c\u68c0\u6d4b</p> <p>These works require a few query images of novel objects, and then compare the test image with these image examples to determine its semantic content (for image classification), or to spatially localize instances (for object detection). </p> <p>\u6211\u4eec\u7684\u5de5\u4f5c\u4e0e\u5c0f\u6837\u672c\u56fe\u50cf\u5206\u7c7b[ 41 ]\u548c\u56fe\u50cf\u68c0\u6d4b[ 12\u300120]\u65b9\u6cd5\u76f8\u5173\u3002\u8fd9\u4e9b\u5de5\u4f5c\u9700\u8981\u4e00\u4e9b\u65b0\u9896\u5bf9\u8c61\u7684\u67e5\u8be2\u56fe\u50cf\uff0c\u7136\u540e\u5c06\u6d4b\u8bd5\u56fe\u50cf\u4e0e\u8fd9\u4e9b\u56fe\u50cf\u793a\u4f8b\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u786e\u5b9a\u5176\u8bed\u4e49\u5185\u5bb9(\u5bf9\u56fe\u50cf\u8fdb\u884c\u5206\u7c7b)\uff0c\u6216\u8005\u5bf9\u5b9e\u4f8b(\u9488\u5bf9\u76ee\u6807\u68c0\u6d4b)\u8fdb\u884c\u7a7a\u95f4\u5b9a\u4f4d\u3002</p> <p>Like these methods, COUNTGD enables us to specify the object to count with visual exemplars (i.e., \u201cquery images\") but also allows for textual inputs, and then compares the test image with the multi-modal specifications to get the final count. Furthermore, we focus on the counting problem, a challenging task for object detectors.</p> <p>\u4e0e\u8fd9\u4e9b\u65b9\u6cd5\u4e00\u6837\uff0cCOUNTGD\u5141\u8bb8\u6211\u4eec\u7528\u53ef\u89c6\u5316\u793a\u4f8b(\u5373\"\u67e5\u8be2\u56fe\u50cf\")\u6307\u5b9a\u8981\u8ba1\u6570\u7684\u5bf9\u8c61\uff0c\u4f46\u4e5f\u5141\u8bb8\u6587\u672c\u8f93\u5165\uff0c\u7136\u540e\u5c06\u6d4b\u8bd5\u56fe\u50cf\u4e0e\u591a\u6a21\u6001\u89c4\u8303\u8fdb\u884c\u6bd4\u8f83\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u8ba1\u6570\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5173\u6ce8\u8ba1\u6570\u95ee\u9898\uff0c\u8fd9\u662f\u76ee\u6807\u68c0\u6d4b\u5668\u7684\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002</p> <p>\u57fa\u4e8e\u68c0\u6d4b\u7684\u65b9\u6cd5\u3001\u5b8c\u6210\u8ba1\u6570\u4efb\u52a1\uff0c\u5176\u5b9e\u73b0\u5728\u7528\u57fa\u4e8e\u68c0\u6d4b\u7684\u7b97\u6cd5\u6765\u8fdb\u884c\u8ba1\u6570\u4efb\u52a1\u662f\u6bd4\u8f83\u5c11\u7684 </p>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#3-counting-with-visual-exemplars-text","title":"3 Counting with Visual Exemplars &amp; Text","text":"<p>Here, we describe COUNTGD, a single-stage model for open-world object counting that accepts either visual exemplars or text or both together as prompts to specify the object to count.</p> <ul> <li>a single-stage model</li> <li>\u63a5\u6536\u7684\u8f93\u5165\uff1avisual exemplars or text or both together</li> </ul>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#31-overview","title":"3.1 Overview","text":"<p>\u7b26\u53f7\u8bf4\u660e</p> <p></p> <p>\u63a5\u6536\u6307\u5b9a\u7269\u4f53\u7684\u4fe1\u53f7\uff1a</p> <ul> <li>\u89c6\u89c9\u4fe1\u53f7\uff1a\\(B=\\{b_1,......,b_N\\}\\)</li> <li>\u6587\u672c\u4fe1\u53f7\uff1a\\(t\\)</li> <li>both\uff1a\\(\\{B,t\\}\\)</li> </ul> <p>\u67e5\u8be2\u56fe\u7247\uff1a\\(X\\in \\mathbb{R}^{H\u00d7W\u00d73}\\)</p> <p>\\(\\hat{y}=f(X,B,t)\\)</p> <p>\u8ba1\u6570\u6a21\u578b\u8bb0\u4e3a\uff1af\uff0c\u8f93\u51fa\u8ba1\u6570\u6570\u91cf \\(\\hat{y}\\)</p> <p></p> <p></p> <p>\u56fe2\uff1a\u6a21\u578b\u7ed3\u6784\u56fe </p> <p>GD \u6307\u7684\u662f  GroundingDINO\u7684\u9996\u5b57\u6bcd\u7f29\u5199</p> <p>COUNTGD\uff1a\u662f\u57fa\u4e8eGroundingDINO\u7684</p> <p>GroundingDINO\uff1a\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u7684\u5f00\u653e\u8bcd\u8868\u5efa\u7acb\u7684\u76ee\u6807\u68c0\u6d4b\u5668</p> <p>\u4e0eGroundingDINO\u4e0d\u540c\u7684\u662f\uff1a</p> <ul> <li>GroundingDINO\u53ea\u63a5\u6536\u6587\u672c\u6307\u5b9a\u67e5\u8be2\u5bf9\u8c61\u3001COUNTGD\u4e5f\u53ef\u4ee5\u63a5\u53d7\u89c6\u89c9\u4fe1\u53f7</li> </ul> <p>\u9996\u5148 \u4ecb\u7ecdCOUNTGD\uff0c\u7136\u540e\u4ecb\u7ecdCOUNTGD\u4e0eGroundingDINO\u7684\u5173\u7cfb\uff0c\u7279\u522b\u662fGroundingDINO\u54ea\u91cc\u662f\u88ab\u51bb\u7ed3\u7684\uff0c\u54ea\u91cc\u662f\u88ab\u8bad\u7ec3\u7684\uff0c\u4ee5\u53ca\u54ea\u91cc\u662f\u88ab\u6dfb\u52a0\u5230GroundingDINO\u7684</p> <p></p> <p>\u7ec4\u4ef6\u8bf4\u660e\uff1a</p> <ul> <li>\u63a8\u7406\u9636\u6bb5\uff1aAt inference the object to be counted can be specified by visual exemplars or text prompts or both.\u6307\u5b9a\u8ba1\u6570\u7269\u4f53\u7684\u65b9\u6cd5</li> <li>\u8f93\u5165\u56fe\u50cf\u7684\u5904\u7406\uff1a\\(f_{\\theta_{SwinT}}\\) \u63d0\u53d6\u4e0d\u540c\u5c3a\u5ea6\u7684\u4fe1\u606f</li> <li>\\(RoIAlign\\)\u83b7\u5f97 visual exemplar token</li> <li>text token\u7684\u83b7\u5f97\uff1a\\(f_{\\theta_{TT}}\\)</li> <li>\u7279\u5f81\u589e\u5f3a\u6a21\u5757 \\(f_{\\phi}\\) \uff1a\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u63d0\u53d6 \u89c6\u89c9\u4fe1\u53f7\u548c\u6587\u672c\u4fe1\u53f7\uff0c\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u878d\u5408\u89c6\u89c9\u4fe1\u53f7\u548c\u6587\u672c\u4fe1\u53f7\uff0c\u4ea7\u751f\u7279\u5f81 \\(z_{v,t}\\) \u3001\u56fe\u50cf\u7279\u5f81 \\(z_I\\)</li> <li>\u4ea7\u751f\u8de8\u6a21\u6001\u7279\u5f81\uff1a \u4f59\u5f26\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684 \\(k\\) \u4e2a\u56fe\u50cf\u7279\u5f81 \\(z_I\\) \u548c \u89c6\u89c9\u4fe1\u53f7\u548c\u6587\u672c\u4fe1\u53f7\u7684 \u878d\u5408\u7279\u5f81 \\(z_{v,t}\\) \u4f20\u5165 \u8de8\u6a21\u6001\u89e3\u7801\u5668 \\(f_{\\psi}\\)</li> <li>\u8ba1\u7b97 \u8de8\u6a21\u6001\u89e3\u7801\u5668 $ f_{\\psi}$ \u7684\u8f93\u51fa \u548c \\(z_{v,t}\\)  \u5f97\u5230 \\(\\hat{Y}\\)</li> <li>\u6700\u7ec8\u7684\u68c0\u6d4b\u8f93\u51fa\uff1a \\(z_{v,t} \uff1e \\sigma\\) \u83b7\u5f97\u6700\u5927\u76f8\u4f3c\u5ea6\u7684\u8f93\u51fa</li> <li>\u6574\u4e2a\u7684\u6a21\u578b\u6846\u67b6 \u90fd\u662f\u5728 GroundingDINO \u6846\u67b6\u7684\u57fa\u7840\u4e0a\u4e0a\u6539\u8fdb\u7684\uff0c\u53e6\u5916\u6dfb\u52a0\u7684\u90e8\u5206 \u7528\u84dd\u8272\u8868\u793a</li> </ul> <p></p> <p></p> <p>\u56fe3\uff1a\u89c6\u89c9\u7279\u5f81\u63d0\u53d6\u6a21\u5757</p> <p>\uff08a\uff09\u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf\uff0c\u6807\u51c6\u7684SwinTransformer\u6a21\u578b\u63d0\u53d6\u89c6\u89c9\u7279\u5f81\u7684 \u591a\u7a7a\u95f4\u7279\u5f81</p> <p>\uff08b\uff09\u5bf9\u4e8e\u6709\u6837\u4f8b\u6846\u7684\u8f93\u5165\u7279\u5f81\u56fe\uff0c\u5c06\u591a\u4e2a\u89c6\u89c9\u7279\u5f81\u6837\u4f8b\u6846\u4e0a\u91c7\u6837\u5230\u8f93\u5165\u56fe\u50cf\u7684\u5927\u5c0f\uff0c\u62fc\u63a5\u8fd9\u4e9b\u7279\u5f81\u56fe\uff0c\u901a\u8fc71\u00d71\u5377\u79ef\uff0c\u6295\u5f71\u5230256\u4e2a\u901a\u9053\uff1b\u6700\u540e\u5e94\u7528 \u5e26\u6709\u8fb9\u754c\u6846\u5750\u6807\u7684  RoIAlign \u83b7\u5f97 \u6837\u4f8b\u6846\u7684\u89c6\u89c9\u7279\u5f81</p>"},{"location":"literature/ObejectCounting/rank1%20CountGD/#32-countgd-architecture-components","title":"3.2 COUNTGD Architecture Components","text":"<p>\u56fe\u50cf\u7f16\u7801\u5668 \\(f_{\\theta_{SwinT}}\\)</p> <ul> <li>\u5904\u7406\u4e24\u4e2a\u8f93\u5165\u4fe1\u53f7\uff1a\u8f93\u5165\u56fe\u50cf \\(X\\) \u548c \u89c6\u89c9\u6837\u4f8b\u6846 \\(B\\)</li> <li>\u4f7f\u7528\u7684SwinTransformer\u7684\u7248\u672c Swin-B</li> <li>\uff08\u8f93\u5165\u56fe\u50cfX\u7684\u5efa\u6a21\uff09\u5982\u56fe3(a) \u6240\u793a\uff0c\u5bf9\u4e8e\u8f93\u5165\u56fe\u50cf \\(X\\) \u63d0\u53d63\u4e2a\u4e0d\u540c\u7a7a\u95f4\u5c3a\u5ea6\u7684 \u7279\u5f81 <ul> <li>\u4e09\u4e0d\u540c\u5927\u5c0f\u7684\u7edf\u5efa\u7279\u5f81\u56fe \u901a\u8fc71\u00d71\u7684\u5377\u79ef\u6838 \u6295\u5f71\u5230256\u7ef4\uff0c\u4ea7\u751f\u56fe\u50cftoken</li> <li>\u4e0d\u540c\u5c3a\u5ea6\u7684\u56fe\u50cf\u5757\u5bf9\u5e94\u957f\u5ea6\u4e3a256\u7684\u7279\u5f81\u5411\u91cf\uff0c\u4f5c\u4e3a\u7279\u5f81\u589e\u5f3a\u6a21\u5757 \\(f_{\\phi}\\)\u7684\u8f93\u5165</li> </ul> </li> <li>\uff08\u6837\u4f8b\u6846 B\u7684\u5efa\u6a21\uff09\u5982\u56fe3(b)\uff0c\u5bf9\u4e8e\u89c6\u89c9\u6837\u4f8b\u6846 B\uff0c\u590d\u7528 \u8f93\u5165\u56fe\u50cf \\(X\\) \u7684 \u7a7a\u95f4\u7279\u5f81\u56fe \\(f_{\\theta_{SwinT}}(X)\\)</li> <li>\u4f7f\u7528 ROI pooling\uff08\u5bf9\u9f50\u7684\u611f\u5174\u8da3\u533a\u57df\u6c60\u5316?\uff09\uff0c\u4e0e\u89c6\u89c9\u793a\u4f8bB\u6307\u5b9a\u7684\u50cf\u7d20\u5750\u6807</li> <li>\u4ea7\u751f\u7684\u89c6\u89c9\u7279\u5f81 \u548c \u56fe\u50cf\u548c\u6587\u672ctoken \u4e00\u6837\u7684\u5927\u5c0f\uff1a256\u7ef4\u5ea6</li> </ul> <p></p> <p></p> <p>\u6587\u672c\u7f16\u7801\u5668</p> <ul> <li> <p>\u5bf9\u4e8e\u6587\u672c\u7f16\u7801\u5668 \\(f_{\\theta_{TT}}\\)\uff0c\u4f7f\u7528\u57fa\u4e8ebert\u7684\u6587\u672cTransformer</p> </li> <li> <p>\u9884\u8bad\u7ec3\u7684\u6570\u636e\u96c6\uff1a\u68c0\u6d4b\u548c\u77ed\u8bed\u5b9a\u4f4d\u6570\u636e\uff0c\u6709\u56fe\u50cf\u7f16\u7801\u5668 \\(f_{\\theta_{SwinT}}\\)</p> </li> <li> <p>\u6587\u672c\u7f16\u7801\u5668\u5c06\u8f93\u5165\u5bf9\u8c61\u63cf\u8ff0 \\(t\\) \u6295\u5f71\u5230\u6700\u591a256\u4e2a token</p> </li> <li> <p>\u7f16\u7801\u540e\u7684\u6587\u672c \u7279\u5f81\u5411\u91cf\u662f256\u7ef4\u7684\uff08256\u4e2atoken\uff09</p> </li> <li> <p>\u56fe\u50cf\u7f16\u7801\u5668 \\(f_{{\\theta}_{SwinT}}\\) \u4ece\u8f93\u5165\u56fe\u50cf\u4e2d \u63d0\u53d6 \\(n\\) \u4e2a \u56fe\u50cf\u5757 \u7279\u5f81</p> </li> </ul> <ul> <li>\u5f53\u6709 \\(p\\) \u4e2a \u89c6\u89c9\u793a\u4f8b \u53ef\u7528\u65f6\uff0c\u89c6\u89c9\u7f16\u7801\u5668\u4ea7\u751f p \u4e2a\u89c6\u89c9\u793a\u4f8b\u7279\u5f81</li> <li>\u5f53bert\u5206\u8bcd\u5668\u5728\u6587\u672ct\u4e2d\u6709q\u4e2atoken\uff0c\u6587\u672c\u7f16\u7801\u5668\u4ea7\u751fq \u4e2a\u6807\u8bb0</li> </ul> <ul> <li>\u6700\u540e\uff0c\u83b7\u5f97 \u7279\u5f81\u589e\u5f3a\u6a21\u5757\u7684 \u8f93\u5165 \\(f_{\\phi}\\) \u6709 \u2460 n\u4e2a\u56fe\u50cftoken   \u2461p\u4e2a\u89c6\u89c9\u6837\u4f8b\u6846token   \u2462q\u4e2a\u6587\u672ctoken</li> </ul> <p>\u4f7f\u7528\u6ce8\u610f\u529b\u6a21\u5757\u878d\u5408\u8fd9\u4e09\u4e2a\u6e90\u7684\u4fe1\u606f</p> <p>Note</p> <p>\u6587\u672c\u7279\u5f81\uff1a clip   bert</p> <p></p> <p>\u7279\u5f81\u589e\u5f3a\u6a21\u5757 \\(f_{\\phi}\\)</p> <ul> <li>\u75316\u4e2a\u5757\u7ec4\u6210</li> <li>\u81ea\u6ce8\u610f\u529b\u673a\u5236 \u878d\u5408 \u89c6\u89c9\u6837\u4f8b\u6846\u7279\u5f81\u548c \u6587\u672ctoken</li> <li>\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757 \u878d\u5408 \u5408\u5e76\u540e\u7684\u7279\u5f81\u548c \u56fe\u50cf\u5757\u6807\u8bb0</li> <li>\u6bcf\u4e2a\u6a21\u5757\u5305\u62ec \u89c6\u89c9\u793a\u4f8b \u548c \u6587\u672c\u6807\u8bb0 \u8fde\u63a5\u540e\u7684\u81ea\u6ce8\u610f\u529b\u3001\u56fe\u50cf\u5757 \u6807\u8bb0\u4e4b\u95f4\u7684\u53ef\u53d8\u5f62\u81ea\u6ce8\u610f\u529b\uff0c\u4ee5\u53ca\u878d\u5408\u540e\u7684 \u89c6\u89c9\u793a\u4f8b\u548c\u6587\u672c\u6807\u8bb0 \u4e0e\u56fe\u50cf\u5757\u6807\u8bb0\u4e4b\u95f4 \u7684\u56fe\u50cf\u5230\u6587\u672c\u7684\u4ea4\u53c9\u6ce8\u610f\u529b \u548c \u6587\u672c\u5230\u56fe\u50cf\u7684\u4ea4\u53c9\u6ce8\u610f\u529b</li> <li>\u8fd9\u4e9b\u6a21\u5757\u4f7f\u5f97COUNTGD\u80fd\u591f\u5b66\u4e60\u5c06\u8f93\u5165\u56fe\u50cf\u3001\u89c6\u89c9\u793a\u4f8b\u548c\u6587\u672c\u67e5\u8be2\u7684\u4fe1\u606f\u7efc\u5408\u8d77\u6765</li> <li>\u7279\u5f81\u589e\u5f3a\u6a21\u5757 \\(f_{\\phi}\\) \u8f93\u51fa\u4e24\u7ec4\u7279\u5f81\uff0c\u5206\u522b\u8868\u793a\u4e3a  \\(z_{v,t}\\)  \u548c \\(z_I\\)</li> </ul> <p></p> <ul> <li>\u878d\u5408\u56fe\u50cf\u5757token\u3001\u6587\u672ctoken\u3001\u6837\u4f8b\u6846token</li> </ul> <p></p> <p>\u8bed\u8a00\u548c\u89c6\u89c9\u6837\u4f8b\u6846\u5f15\u5bfc\u7684\u67e5\u8be2\u9009\u62e9</p> <ul> <li>k\u4e2a\u56fe\u50cf\u5757 token \\(z_I\\) \u548c\u6587\u672c \u6807\u8bb0 \\(z_{v,t}\\) \u5177\u6709\u6700\u9ad8\u7684\u76f8\u4f3c\u5ea6\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u8868\u793a \\(Select(z_I,z_Iz_v^T,k)\\) </li> <li>\u5176\u4e2d \\(z_Iz_{v,t}^T \\in \\mathbb{R}^{n \u00d7(p+q)}\\)  \u8868\u793a n\u4e2a\u56fe\u50cf\u5757 token \u548c p+q\u4e2a\u89c6\u89c9\u6837\u4f8b\u6846\u548c\u6587\u672c token</li> <li>\u6b63\u5982 GroundingDINO\uff0ck\u8bbe\u7f6e\u4e3a900</li> <li>\u5177\u6709\u66f4\u9ad8\u76f8\u4f3c\u5ea6\u7684900\u4e2a\u56fe\u50cftoken\u4f5c\u4e3a\u8de8\u6a21\u6001\u67e5\u8be2 \u8f93\u5165\u5230 \u8de8\u6a21\u6001\u89e3\u7801\u5668 \\(f_{\\phi}\\)</li> </ul> <p></p> <p>\u8de8\u6a21\u6001\u89e3\u7801\u5668 \\(f_{\\psi}\\)</p> <ul> <li>\u8de8\u6a21\u6001\u89e3\u7801\u5668 \\(f_{\\psi}\\) \u4f7f\u7528\u81ea\u6ce8\u610f\u529b\u589e\u5f3a\u8de8\u6a21\u6001\u67e5\u8be2</li> <li>\u56fe\u50cf\u4ea4\u53c9\u6ce8\u610f\u529b\u5c06\u56fe\u50cf\u5757\u7279\u5f81 \\(z_I\\) \u878d\u5408\u5230 \u8de8\u6a21\u6001\u67e5\u8be2\u4e2d</li> <li>\u4f7f\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u5c06\u89c6\u89c9\u793a\u4f8b\u548c\u6587\u672c\u7279\u5f81 \\(z_{v,t}\\) \u878d\u5408\u5230\u8de8\u6a21\u6001\u67e5\u8be2\u4e2d</li> <li>\u8de8\u6a21\u6001\u89e3\u7801\u5668\u75316\u4e2a\u8fd9\u6837\u7684\u81ea\u6ce8\u610f\u529b\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u7ec4\u6210</li> <li>\u8de8\u6a21\u6001\u67e5\u8be2\u4e0e\u878d\u5408\u540e\u7684\u89c6\u89c9\u793a\u4f8b\u548c\u6587\u672c\u6807\u8bb0 \\(z_{v,t}\\) \u8fdb\u884c\u70b9\u79ef\uff0c\u5e76\u901a\u8fc7\u9010\u5143\u7d20\u7684Sigmoid\u51fd\u6570\u5904\u7406\uff0c\u4ee5\u83b7\u5f97\u6700\u7ec8\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\uff0c\u5982\u4e0b\u6240\u793a\uff1a</li> </ul> <p></p> <ul> <li>\\(z_{v,t}\\)\u662f\u878d\u5408\u7684\u89c6\u89c9\u793a\u4f8b\u548c\u6587\u672c\u7279\u5f81</li> <li>\\(z_I\\) \u662f\u67e5\u8be2\uff08\u5373\u68c0\u6d4b\u5230\u7684\u5bf9\u8c61\u7684\u6700\u5927\u6570\u91cf\uff09</li> <li>\\(\\hat{Y}\\) \u6700\u7ec8\u76f8\u4f3c\u5ea6\u5206\u6570</li> <li>\u5206\u6570\u6839\u636e\u7f6e\u4fe1\u5ea6\u9608\u503c \\(\\sigma\\) \u8fdb\u884c\u9608\u503c\u5904\u7406\uff0c\u5e76\u5728\u63a8\u7406\u65f6 \u7528\u4e8e\u4f30\u8ba1\u6700\u7ec8\u7684\u5bf9\u8c61\u8ba1\u6570 \\(\\hat{y}\\)</li> </ul> <p></p> <p>\u8bbe\u8ba1\u9009\u62e9\u4e0eGroundingDINO\u7684\u5173\u7cfb</p> <p>\u6211\u4eec\u9009\u62e9GroundingDINO[30]\u800c\u4e0d\u662f\u5176\u4ed6\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\uff0c\u662f\u56e0\u4e3a\u5176\u5728\u89c6\u89c9\u5b9a\u4f4d\u6570\u636e\u4e0a\u7684\u9884\u8bad\u7ec3\uff0c\u4f7f\u5176\u4e0e\u5176\u4ed6VLMs\uff08\u5982CLIP[17]\uff09\u76f8\u6bd4\u5177\u6709\u66f4\u7ec6\u7c92\u5ea6\u7684\u7279\u5f81\u3002</p> <p>\u4e3a\u4e86\u6269\u5c55GroundingDINO\u4ee5\u63a5\u53d7\u89c6\u89c9\u793a\u4f8b\uff0c\u6211\u4eec\u5c06\u5176\u89c6\u4e3a\u6587\u672c\u6807\u8bb0\u3002\u56e0\u4e3a\u89c6\u89c9\u793a\u4f8b\u548c\u6587\u672c\u90fd\u6307\u5b9a\u4e86\u5bf9\u8c61\uff0c\u6211\u4eec\u8ba4\u4e3a\u89c6\u89c9\u793a\u4f8b\u53ef\u4ee5\u88abGroundingDINO\u50cf\u6587\u672c\u6807\u8bb0\u4e00\u6837\u5bf9\u5f85\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u3002\u5728\u5c06\u89c6\u89c9\u793a\u4f8b\u89c6\u4e3a\u77ed\u8bed\u4e2d\u7684\u9644\u52a0\u6587\u672c\u6807\u8bb0\u65f6\uff0c\u6211\u4eec\u5728\u5bf9\u5e94\u4e8e\u89c6\u89c9\u793a\u4f8b\u7684\u77ed\u8bed\u548c\u89c6\u89c9\u793a\u4f8b\u4e4b\u95f4\u6dfb\u52a0\u81ea\u6ce8\u610f\u529b\uff0c\u800c\u4e0d\u662f\u5c06\u5b83\u4eec\u5206\u5f00\u3002\u8fd9\u4f7f\u5f97COUNTGD\u80fd\u591f\u5b66\u4e60\u878d\u5408\u89c6\u89c9\u793a\u4f8b\u548c\u6587\u672c\u6807\u8bb0\uff0c\u4ee5\u5f62\u6210\u5bf9\u8981\u8ba1\u6570\u5bf9\u8c61\u7684\u66f4\u5177\u4fe1\u606f\u6027\u7684\u89c4\u8303\u3002\u540c\u6837\uff0cGroundingDINO\u7684\u7279\u5f81\u589e\u5f3a\u5668\u548c\u8de8\u6a21\u6001\u89e3\u7801\u5668\u4e2d\u56fe\u50cf\u548c\u6587\u672c\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u5728COUNTGD\u4e2d\u53d8\u4e3a\u56fe\u50cf\u4e0e\u878d\u5408\u540e\u7684\u89c6\u89c9\u793a\u4f8b\u548c\u6587\u672c\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u3002\u5728GroundingDINO\u4e2d\u7684\u8bed\u8a00\u5f15\u5bfc\u67e5\u8be2\u9009\u62e9\u5728COUNTGD\u4e2d\u53d8\u4e3a\u8bed\u8a00\u548c\u89c6\u89c9\u793a\u4f8b\u5f15\u5bfc\u7684\u67e5\u8be2\u9009\u62e9\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0cCOUNTGD\u81ea\u7136\u5730\u6269\u5c55\u4e86GroundingDINO\uff0c\u4f7f\u5176\u80fd\u591f\u8f93\u5165\u6587\u672c\u548c\u89c6\u89c9\u793a\u4f8b\u6765\u63cf\u8ff0\u5bf9\u8c61\u3002</p> <p>\u5728GroundingDINO\u4e2d\uff0c\u56fe\u50cf\u7f16\u7801\u5668 \\(f_{\\theta_{\\text{SwinT}}}\\) \u4e0e\u6587\u672c\u7f16\u7801\u5668 \\(f_{\\theta_{\\text{TT}}}\\) \u4e00\u8d77\u5728\u4e30\u5bcc\u7684\u68c0\u6d4b\u548c\u77ed\u8bed\u5b9a\u4f4d\u6570\u636e\u4e0a\u8fdb\u884c\u4e86\u9884\u8bad\u7ec3\uff0c\u4e3a\u5176\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u533a\u57df\u548c\u6587\u672c\u611f\u77e5\u7279\u5f81\u3002\u7531\u4e8e\u6211\u4eec\u5e0c\u671b\u5efa\u7acb\u5728\u8fd9\u4e2a\u9884\u8bad\u7ec3\u7684\u8054\u5408\u89c6\u89c9-\u8bed\u8a00\u5d4c\u5165\u4e4b\u4e0a\uff0c\u6211\u4eec\u4fdd\u6301\u56fe\u50cf\u7f16\u7801\u5668  \\(f_{\\theta_{\\text{SwinT}}}\\) \u548c\u6587\u672c\u7f16\u7801\u5668 \\(f_{\\theta_{\\text{TT}}}\\) \u4e0d\u53d8\u3002</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/","title":"rank10 SPDCN","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 2769 \u4e2a\u5b57  8 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 14 \u5206\u949f</p> <p></p> <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u94fe\u63a5</p> <p>\u5f15\u7528\uff1a2022\u5e74\u7684\u6587\u732e</p> TeX<pre><code>@inproceedings{Lin_2022_BMVC,\nauthor    = {Wei Lin and Kunlin Yang and Xinzhu Ma and Junyu Gao and Lingbo Liu and Shinan Liu and Jun Hou and Shuai Yi and Antoni Chan},\ntitle     = {Scale-Prior Deformable Convolution for Exemplar-Guided Class-Agnostic Counting},\nbooktitle = {33rd British Machine Vision Conference 2022, {BMVC} 2022, London, UK, November 21-24, 2022},\npublisher = {{BMVA} Press},\nyear      = {2022},\nurl       = {https://bmvc2022.mpi-inf.mpg.de/0313.pdf}\n}\n</code></pre> <p>\u6807\u9898\uff1aScale-Prior Deformable Convolution for Exemplar-Guided Class-Agnostic Counting  \u57fa\u4e8e\u793a\u4f8b\u7684\uff0c\u5c3a\u5ea6\u5148\u9a8c\u53ef\u53d8\u5377\u79ef\uff0c\u7c7b\u65e0\u5173\u8ba1\u6570\uff08\u7a81\u7136\u60f3\u8d77\u6765\uff0c\u5404\u79cd\u5377\u79ef\uff0c\u7a7a\u6d1e\u5377\u79ef\u3001\u8f6c\u7f6e\u5377\u79ef\u3001\u5206\u7ec4\u5377\u79ef\uff09</p> <p>\u4f5c\u8005\uff1aConference 2022  \u00b7 Wei Lin, Kunlin Yang, Xinzhu Ma, Junyu Gao, Lingbo Liu, Shinan Liu, Jun Hou, Shuai Yi, Antoni B. Chan    \u9999\u6e2f\u5927\u5b66</p> <p></p> <p>\u671f\u520a\uff1aBMVC2022\uff1bCCF-C\u7c7b</p> <p>\u672c\u6587 \u4e3a\u4e86\u89e3\u51b3.......\u63d0\u51fa\u4e86...........</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#_1","title":"\u6458\u8981","text":"<p>CAC\u4efb\u52a1\u8fdb\u5c55\u4e0d\u9519(\u8fd9\u662f22\u5e74\u7684\u6587\u7ae0\uff0c\u73b0\u5728\u505a\u7684\u90fd\u662fCAC\u7684)</p> <p>Class-agnostic counting has recently emerged as a more practical counting task, which aims to predict the number and distribution of any exemplar objects, instead of counting specific categories like pedestrians or cars. </p> <p>\u73b0\u6709\u7684\u65b9\u6cd5</p> <ul> <li>\u8bbe\u8ba1\u5408\u9002\u7684\u76f8\u4f3c\u6027\u5339\u914d\u89c4\u5219 \u5728\u793a\u4f8b\u548c\u67e5\u8be2\u56fe\u50cf\u4e4b\u95f4</li> <li>\u5ffd\u7565\u4e86\u63d0\u53d6\u7279\u5f81\u7684\u9c81\u68d2\u6027</li> </ul> <p>However, recent methods are developed by designing suitable similarity matching rules between exemplars and query images, but ignoring the robustness of extracted features. </p> <p>\u4e3a\u4e86 \u63d0\u53d6\u7279\u5f81\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51fa  \u5c3a\u5ea6\u5148\u9a8c\u53ef\u53d8\u5377\u79ef\uff0c\u6574\u5408\u793a\u4f8b\u4fe1\u606f</p> <p>To address this issue, we propose a scale-prior deformable convolution by integrating exemplars\u2019 information, e.g., scale, into the counting network backbone.\uff08\u6548\u679c\uff09As a result, the proposed counting network can extract semantic features of objects similar to the given exemplars and effectively filter irrelevant backgrounds. \u63d0\u51fa\u7684\u8ba1\u6570\u7f51\u7edc\u53ef\u4ee5\u63d0\u53d6 \u7ed9\u5b9a\u793a\u4f8b\u76f8\u4f3c\u76ee\u6807\u7684 \u8bed\u4e49\u7279\u5f81 \u5e76\u4e14 \u8fc7\u6ee4\u6389 \u4e0d\u76f8\u5173\u7684\u80cc\u666f\u4fe1\u606f</p> <p>\u4f20\u7edf\u7684L2\u635f\u5931\u548c\u6cdb\u5316\u635f\u5931 \u5bf9\u4e8eCAC \u8ba1\u6570\u95ee\u9898 \u4e0d\u5408\u9002\uff1b\u56e0\u4e3a\u5bf9\u4e8e\u4e0d\u540c\u76ee\u6807\u7684\u5c3a\u5ea6\u53d8\u5316\u662f\u6bd4\u8f83\u5927\u7684</p> <p>Besides, we find that traditional L2 and generalized loss are not suitable for class-agnostic counting due to the variety of object scales in different samples. </p> <p>\u4e3a\u4e86\u89e3\u51b3 \u4f20\u7edf\u7684L2\u635f\u5931\u5bf9\u4e8e\u793a\u4f8b\u5c3a\u5ea6\u591a\u53d8\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5c3a\u5ea6\u654f\u611f\u7684\u6cdb\u5316\u635f\u5931\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898</p> <p>Here we propose a scale-sensitive generalized loss to tackle this problem. </p> <p>\u6211\u4eec\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570 \u80fd\u505a\u4ec0\u4e48\uff1f</p> <ul> <li>\u6839\u636e\u7ed9\u5b9a\u793a\u4f8b\u7684\u5927\u5c0f \u8c03\u6574\u635f\u5931\u51fd\u6570\u7684\u5f62\u5f0f\u2192\u9884\u6d4b\u503c\u548c\u771f\u5b9e\u503c\u7684\u5dee\u5f02\u66f4\u52a0\u660e\u663e</li> </ul> <p>It can adjust the cost function formulation according to the given exemplars, making the difference between prediction and ground truth more prominent. </p> <p>\u7ed3\u679c</p> <p>Extensive experiments show that our model obtains remarkable improvement and achieves state-of-the-art performance on a public class-agnostic counting benchmark. the source code is available at https://github.com/Elin24/SPDCN-CAC.</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#_2","title":"\u603b\u7ed3\u6458\u8981","text":"<ol> <li>\u4e3a\u4e86 \u63d0\u53d6\u7279\u5f81\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51fa  \u5c3a\u5ea6\u5148\u9a8c\u53ef\u53d8\u5377\u79ef\uff0c\u6574\u5408\u793a\u4f8b\u4fe1\u606f</li> <li>\u4e3a\u4e86\u89e3\u51b3 \u4f20\u7edf\u7684L2\u635f\u5931\u5bf9\u4e8e\u793a\u4f8b\u5c3a\u5ea6\u591a\u53d8\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5c3a\u5ea6\u654f\u611f\u7684\u6cdb\u5316\u635f\u5931\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898</li> </ol>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#_3","title":"\u5f15\u5165\u2014\u2014\u8d21\u732e","text":"<p>To summarize, the key contributions of this paper are:</p> <ul> <li>To address class-agnostic counting, we propose a scale-prior deformable network to better extract exemplar-related features, followed by a segmentation-then-counting stage to count objects. </li> </ul> <p>\u4e3a\u4e86\u89e3\u51b3CAC\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5c3a\u5ea6\u4f18\u5148\u53ef\u53d8\u5377\u79ef \u66f4\u597d\u7684\u63d0\u53d6\u4e0e\u6837\u4f8b\u6846\u6709\u5173\u7684\u7279\u5f81\uff1b\u8ddf\u7740\u4e00\u4e2a\u5148\u5206\u5272\u540e\u8ba1\u6570\u7684\u9636\u6bb5\u6765\u6570\u76ee\u6807</p> <ul> <li>We propose a scale-sensitive generalized loss to make the model training adaptive to objects of different sizes, boosting the performance and generalization of trained models. </li> </ul> <p>\u63d0\u51fa\u4e86 \u5c3a\u5ea6\u654f\u611f\u7684\u6cdb\u5316\u635f\u5931\uff0c\u4f7f\u5f97\u6a21\u578b\u66f4\u597d\u7684\u9002\u7528 \u4e0d\u540c\u5c3a\u5bf8\u7684\u7269\u4f53\uff1b\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u6027\u548c\u6027\u80fd</p> <ul> <li>\uff08\u7ed3\u679c\uff09Extensive experiments and visualizations demonstrate these two designs work well, and outstanding performance is obtained when our model is tested on benchmarks.\uff08\u6709\u5b9e\u9a8c\u3001\u6709\u53ef\u89c6\u5316\uff09</li> </ul>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#_4","title":"\u603b\u7ed3","text":"<ul> <li>\u5c3a\u5ea6\u4f18\u5148\u53ef\u53d8\u5377\u79ef \u63d0\u53d6\u6837\u4f8b\u6846\u7279\u5f81\uff1b</li> <li>\u5c3a\u5ea6\u654f\u611f\u7684\u6cdb\u5316\u635f\u5931</li> </ul>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#_5","title":"\u7ed3\u8bba","text":"<p>\u7b2c\u4e00\u4e2a\u63d0\u51fa</p> <p>In this paper, we explore exemplar-guided class-agnostic counting. </p> <p>\u8fd9\u7bc7\u6587\u7ae0 \u96c0\u6c0f\u4e3b\u8981\u7814\u7a76\u7684\u6837\u4f8b\u6846\u6307\u5bfc\u7684CAC\u8ba1\u6570\u95ee\u9898</p> <p>\u5c3a\u5ea6\u4f18\u5148\u7684\u53ef\u53d8\u5377\u79ef\u662f\u4e3a\u4e86 \u6574\u5408\u6837\u4f8b\u6846\u4fe1\u606f\uff0c\u4f7f\u5f97\u63d0\u53d6\u5230\u7684\u7279\u5f81\u66f4\u5177\u6709\u7a33\u5065\u6027</p> <p>To take advantage of scale information provided by exemplars, scale-prior deformable convolution is proposed to adjust the receptive fields according to the given exemplars. </p> <p>\u4e3a\u4e86\u66f4\u597d\u5730\u5229\u7528\u5c3a\u5ea6\u4fe1\u606f\uff0c\u5c3a\u5ea6\u4f18\u5148\u7684\u53ef\u53d8\u5377\u79ef \u88ab\u63d0\u51fa \u66f4\u597d\u7684\u9002\u5e94 \u7ed9\u5b9a\u793a\u4f8b\u7684\u611f\u53d7\u91ce</p> <p>\uff08\u7ed3\u679c\uff09Experimental results show that this operation decreases counting errors dramatically and gives a more accurate density distribution. </p> <p>\u7b2c\u4e8c\u4e2a\u63d0\u51fa</p> <p>We also propose scale-sensitive generalized loss to adapt the cost function according to exemplars, so that different training samples with different object scales have their own distance function for optimal transport.</p> <p>\u540c\u6837\u63d0\u51fa \u5c3a\u5ea6\u654f\u611f\u7684\u6cdb\u5316\u635f\u5931 \u9002\u5e94\u635f\u5931\u51fd\u6570\uff0c\u56e0\u4e3a\u793a\u4f8b\u662f\u5c3a\u5ea6\u53d8\u5316\u7684</p> <p>\u4e0d\u540c\u7684\u8bad\u7ec3\u6837\u672c\u6709\u4e0d\u540c\u7684\u5c3a\u5ea6\u53d8\u5316</p> <p>\uff08\u7ed3\u679c\uff09 This new loss further helps our model perform better than previous models on the class-agnostic counting benchmark.</p> <p>Note</p> <p>\u5199\u4f5c\u903b\u8f91\uff1a   (1)\u63d0\u51fa\u65b9\u6cd5   (2)\u8bf4\u660e\u4f60\u7ed3\u679c  </p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#_6","title":"\u5f15\u5165","text":"<p>Introduction</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#p1","title":"P1 \u4ece\u7279\u5b9a\u7c7b\u522b\u8bf4\u8d77","text":"<p>Info</p> <p>P1 </p> <p>\uff081\uff09\u4ece\u7279\u5b9a\u7c7b\u522b\u7684\u76ee\u6807\u8ba1\u6570\u5f00\u59cb\u8bf4\uff0c\u5e94\u8be5\u662f\u6587\u7ae0\u6bd4\u8f83\u65e9\uff0c\u6240\u4ee5\u5bf9\u4e8e\u4e3a\u4ec0\u4e48\u8981\u6c42CAC\u8ba1\u6570\u7684\u80cc\u666f\u548c\u52a8\u673a\u8bf4\u7684\u5f88\u5177\u4f53</p> <p>\uff082\uff09\u5f15\u5165\u90e8\u5206 \u90fd\u662f\u4ecesepcific\u8bf4\u8d77</p> <p>In recent years, remarkable progress has been achieved in counting tasks. However, most methods only work in a category-specific manner, like counting crowd [34] or vehicles [20], and thus they fail to meet the requirements of some real-world applications.  \u7279\u5b9a\u7c7b\u522b\u7684\u8ba1\u6570\uff1a\u4eba\u7fa4\u8ba1\u6570&amp;\u8f66\u8f86\u8ba1\u6570\uff1b\u4e0d\u80fd\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u7684\u9700\u8981\uff1b</p> <p>CAC\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f</p> <p>\uff081\uff09For example, there exist demands for counting goods in various categories in supermarkets or warehouses [7]; \u8d85\u5e02\u6216\u8005\u4ed3\u5e93\u4e2d \u5546\u54c1\u8ba1\u6570</p> <p>\uff082\uff09 in agriculture, predicting the crop yield of different fruits/vegetables is required [14, 37]; \u519c\u4e1a\u4e2d\uff0c\u4e0d\u540c\u679c\u852c\u4f5c\u7269\u4ea7\u91cf\u9884\u6d4b</p> <p>\uff083\uff09and some may want to know the number of different trees [3, 21]. \u4e0d\u540c\u6811\u6570\u91cf\u9884\u6d4b</p> <p>\u4f46\u662f\uff0c\u5f15\u51fa\u4e0b\u4e00\u6bb5   However, with traditional counting methods, a separate counting model is needed for each object class, which limits its practical applications.</p> <p>Info</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#p2-cac","title":"P2  CAC\u95ee\u9898\u7684\u8bf4\u660e\uff0c\u4ece\u5b9a\u4e49\u3001\u635f\u5931\u5230\u6a21\u578b\u6982\u8ff0","text":"Text Only<pre><code>\u8fd9\u91cc\u7684\u6a21\u578b\u6982\u8ff0\u8ddf\u4ee5\u524d\u7684\u4e0d\u5927\u4e00\u6837\uff0c\u662f\u8bf4\u6a21\u578b\u65b9\u6cd5\u4ee5\u540e \u5c31\u4f1a\u6307\u51fa\u95ee\u9898\n</code></pre> <p>CAC\u95ee\u9898\u7684\u5b9a\u4e49</p> <p>To tackle the above problem, this paper considers class-agnostic counting, in which counting models predict the number and distribution of objects indicated by a few object exemplars in a set of query images. </p> <p>CAC\u7684\u635f\u5931\u662f\u5982\u4f55\u5b9a\u4e49\u7684</p> <p>During training, both images and exemplars are input to the counting model, and then the loss is calculated between the predicted density maps and human-annotated dot maps [23]. </p> <p>\u73b0\u5728\u7684CAC\u633a\u597d\u7684\uff0c\u4f46\u8fd8\u6709\u6539\u8fdb\u7684\u7a7a\u95f4</p> <p>Although existing class-agnostic counting methods have achieved good performance, there is still much room for improvement.</p> <p>CAC\u6587\u732e\u6982\u8ff0</p> <p>\u7b2c\u4e00\u4e2aCAC\u5f15\u7528\uff1aGMN</p> <p>For example, GMN [16] resizes the given exemplars to a fixed size and then calculates the distance between the exemplar\u2019s feature and local regions of the query image to localize the object of interest. One problem in this process is that exemplar features will lose the scale information provided by the exemplar\u2019s size.  \u95ee\u9898\u5728\u4e8e\uff1a\u635f\u5931\u4e86\u793a\u4f8b\u7684\u5c3a\u5bf8\u4fe1\u606f</p> <p>\u7b2c\u4e8c\u4e2aCAC\u5f15\u7528\uff1aBMNet [26] </p> <p>Although BMNet [26] adds a scale embedding to its network to tackle this problem, its function is not intuitive. BMNet\u89e3\u51b3\u901a\u8fc7 \u5c3a\u5ea6\u5d4c\u5165 \u89e3\u51b3GMN\u7684\u95ee\u9898\uff1b\u4f46\u662f\u5e76\u4e0d\u76f4\u89c2</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#p3","title":"P3 \u5f15\u51fa\u5c3a\u5ea6\u4f18\u5148\u53ef\u53d8\u5377\u79ef","text":"<p>\u4e0a\u9762\u63d0\u51fa\u95ee\u9898\uff0c\u63a5\u4e0b\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u4e3a\u4e86\u66f4\u597d\u7684\u5229\u7528\u5c3a\u5ea6\u4fe1\u606f\uff0c\u63d0\u51fa\u5c3a\u5ea6\u4f18\u5148\u53ef\u53d8\u5377\u79ef\uff0c\u63d0\u53d6\u7279\u5b9a\u5c3a\u5bf8\u7684\u76ee\u6807\u7279\u5f81</p> <p>To take advantage of scale information, we design a Scale-Prior Deformable Convolution Network (SPDCN) to extract features of objects with specific size. </p> <p>\u5177\u4f53\u600e\u4e48\u5b9e\u73b0\u7684</p> <p>SPDCN embeds the scale information into the deformable convolution, so that its receptive field is adjusted automatically and extracts features corresponding to the scale of the given exemplars. </p> <p>SPDCN\u628a\u5c3a\u5ea6\u4fe1\u606f\u5d4c\u5165\u5230\u53ef\u53d8\u5377\u79ef\u4e2d\uff0c\u8fd9\u6837\u611f\u53d7\u91ce\u5c31\u80fd\u81ea\u9002\u5e94\u7684\u8c03\u6574\uff1b\u5e76\u4e14\u63d0\u53d6\u7ed9\u5b9a\u793a\u4f8b\u5c3a\u5ea6\u7279\u5f81</p> <p>This design significantly boosts the counting performance because objects in the same category typically have similar scale in an image, whereas different object categories may have vastly different scales. </p> <p>\u8fd9\u79cd\u8bbe\u8ba1\u80fd\u663e\u8457\u63d0\u9ad8\u8ba1\u6570\u6027\u80fd\uff0c\u56e0\u4e3a\u76f8\u540c\u7c7b\u522b\u7684\u76ee\u6807\u5728\u540c\u4e00\u5f20\u56fe\u7247\u4e0a\u7684\u5c3a\u5bf8\u662f\u76f8\u540c\u7684\uff1b\u7136\u800c\u4e0d\u540c\u7c7b\u522b\u7684\u76ee\u6807\u7269\u4f53\u5c3a\u5bf8\u53d8\u5316\u662f\u5f88\u5927\u7684</p> <p>With the extracted features, SPDCN then computes the similarity between exemplars and query images to segment out regions containing the counted objects. After that, the generated similarity map and features are sent to a decoder to estimate the density map.</p> <p>\u7136\u540e\uff0c\u5229\u7528\u63d0\u53d6\u7684\u7279\u5f81\uff0cSPDCN\u8ba1\u7b97\u793a\u4f8b\u56fe\u50cf\u548c\u67e5\u8be2\u56fe\u50cf\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\uff0c\u4ee5\u5206\u5272\u51fa\u5305\u542b\u88ab\u7edf\u8ba1\u5bf9\u8c61\u7684\u533a\u57df\u3002\u4e4b\u540e\uff0c\u5c06\u751f\u6210\u7684\u76f8\u4f3c\u5ea6\u56fe\u548c\u7279\u5f81\u9001\u5165\u89e3\u7801\u5668\u6765\u4f30\u8ba1\u5bc6\u5ea6\u56fe\u3002 </p> <p>SPDCN \u4e3b\u8981\u5904\u7406\u7684\u5c31\u662f\u6837\u4f8b\u6846\u5c3a\u5bf8\u53d8\u5316\u6bd4\u8f83\u5927\u7684\u95ee\u9898\uff0c\u8fd9\u91cc\u7528\u7684\u8bcd\uff1a\u5206\u5272</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#p4-scale-sensitive-generalized-loss","title":"P4  \u6307\u51fa \u6211\u4eec\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570 scale-sensitive generalized loss","text":"<p>We apply the generalized loss [31] to train SPDCN. However, we find that the vanilla generalized loss is unsuitable for class-agnostic counting because its cost function assumes all objects (people) are the same size, whereas in class-agnostic counting, different object categories have different scales. To tackle this problem, we propose a scale-sensitive generalized loss, in which the cost function is adjusted adaptively based on the object scale. Experiments show that the performance is further improved with our adaptive loss function.</p> <p>P5 \u8d21\u732e \u60f3\u770b\u70b9\u5de6\u4fa7\u76ee\u5f55\u8df3\u8f6c</p> <p>Info</p> <p>\u5f15\u5165\u90e8\u5206\u7684\u5199\u4f5c\u903b\u8f91</p> <ol> <li>\u7279\u5b9a\u7c7b\u522b\u7684\u76ee\u6807\u8ba1\u6570   </li> <li>CAC\u8ba1\u6570   </li> <li>\u5f15\u51fa\u53ef\u53d8\u5377\u79ef    </li> <li>\u5f15\u51fa \u5c3a\u5ea6\u654f\u611f\u7684\u635f\u5931    </li> <li>\u8d21\u732e   </li> </ol>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#_7","title":"\u76f8\u5173\u5de5\u4f5c","text":"<p>Info</p> <p>\u5206\u6210\u7684\u4e09\u90e8\u5206\uff1a</p> <p>Class-Agnostic Counting. \u7c7b\u522b\u4e0d\u654f\u611f\u8ba1\u6570</p> <p>Deformable Convolution. \u53ef\u53d8\u5377\u79ef</p> <p>Generalized Loss. \u6cdb\u5316\u635f\u5931</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#sepcific-cac","title":"\u7b2c\u4e00\u6bb5\uff1a\u4ecesepcific \u2192 CAC","text":"<p>Class-Agnostic Counting. </p> <p>\u7279\u5b9a\u7c7b\u522b\u8ba1\u6570</p> <p>Previous counting tasks mainly aim at counting objects in a specific category. </p> <p>The most popular task is crowd counting [17, 19, 29, 31, 32, 34, 35]. Vehicle [11, 20], cell [8, 9] and animal [24] counting also attract researchers\u2019 attention, and are applied in various aspects like vehicular management [33], medical research [4], wildlife conservation [1], and so on.</p> <p>However, only a few methods have considered class-agnostic object counting, and relevant datasets are rare. </p> <p>CAC\u8ba1\u6570</p> <p>FamNet</p> <p>FamNet [23] defines class-agnostic counting as predicting the number of given objects represented by only a few exemplars in the same image and constructs the first dataset called FSC-147 [23]. Its baseline model is designed based on self-similarities matching [25]. One problem is that the scale of exemplars is modeled by the kernel size, which is normally too large to compute, so FamNet freezes the parameters in the extractor to overcome this problem. </p> <p>GMN</p> <p>Another similar work is the generic matching network (GMN) [16], which encodes the semantic feature of exemplars to an embedding, and then uses a matching network to model the relation between the exemplar embedding and the image\u2019s feature maps. However, GMN does not consider the scale problem because the size of the embedding vector is fixed. </p> <p>BMNet</p> <p>BMNet [26] considers the scale problem and adds scale embedding into its model, but it is not intuitive. </p> <p>Our SPDCN</p> <p>Compared with these previous works, our proposed SPDCN embeds scale information into the deformable convolution so that the extracted feature can match the exemplar more accurately, yielding improved performance.</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#_8","title":"\u7b2c\u4e8c\u6bb5 \u53ef\u53d8\u5377\u79ef\u7684\u76f8\u5173\u5de5\u4f5c","text":"<p>Deformable Convolution. </p> <p>\u56e0\u4e3a\u672c\u6587\u7528\u5230\u4e86\u53ef\u53d8\u5377\u79ef\uff0c\u6240\u4ee5\u4ecb\u7ecd\u4e86\u53ef\u53d8\u5377\u79ef\u7684\u76f8\u5173\u5de5\u4f5c</p> <p>Deformable convolution [2, 38] was proposed for modeling geometric transformations dynamically, and has been applied to video super-resolution [30], font generation [36] and other computer vision tasks. \u53ef\u53d8\u5377\u79ef\u7528\u6765\u5e72\u5565\u7684\uff1a\u52a8\u6001\u5efa\u6a21\u51e0\u4f55\u53d8\u6362\uff0c\u5df2\u7ecf\u5e94\u7528\u4e8e\u89c6\u9891\u8d85\u5206\u8fa8\u7387[ 30 ]\u3001\u5b57\u4f53\u751f\u6210[ 36 ]\u7b49\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\uff08\u6ca1\u4e86\u89e3\u8fc7 \u53ef\u53d8\u5377\u79ef</p> <p>Compared to the previous works, we introduce scale-prior deformable convolution to class-agnostic counting, where the receptive fields of the counting network are adjusted according to the given exemplars.\u4e0e\u4e4b\u524d\u7684\u5de5\u4f5c\u76f8\u6bd4\uff0c\u6211\u4eec\u5c06\u5c3a\u5ea6\u5148\u9a8c\u53ef\u53d8\u5f62\u5377\u79ef\u5f15\u5165\u5230\u7c7b\u522b\u65e0\u5173\u8ba1\u6570\u4e2d\uff0c\u5176\u4e2d\u8ba1\u6570\u7f51\u7edc\u7684\u611f\u53d7\u91ce\u6839\u636e\u7ed9\u5b9a\u7684\u6837\u672c\u8fdb\u884c\u8c03\u6574\u3002</p>"},{"location":"literature/ObejectCounting/rank10%20SPDCN/#_9","title":"\u7b2c\u4e09\u6bb5 \u5173\u4e8e\u635f\u5931\u7684\u989d\u76f8\u5173\u5de5\u4f5c","text":"<p>Generalized Loss. </p> <p>\uff08\u4e4b\u524d\u4eba\u7684\u5de5\u4f5c\uff09</p> <p>The generalized loss [31] is designed based on the unbalanced optimal transport (UOT) problem. [31] prove that both L2 loss and Bayesian loss [18] are special cases of the generalized loss. </p> <p>\uff08\u4f5c\u8005\u7684\u5de5\u4f5c\uff09</p> <p>In contrast to [31], which uses a fixed cost function assuming all objects are similar sizes, we propose a scale-sensitive generalized loss for class-agnostic counting, where different object categories have different sizes. Experimental results show that class-agnostic counting models perform better with the scale-sensitive generalized loss, compared to the original version.</p> <ul> <li>\u6211\u4eec\u6ca1\u6709\u91c7\u7528\u56fa\u5b9a\u4e0d\u53d8\u7684\u635f\u5931\u51fd\u6570\u3001\u4e3a\u76f8\u4f3c\u5c3a\u5bf8\u7684\u6240\u6709\u76ee\u6807</li> <li>\u6211\u4eec\u63d0\u51fa\u5c3a\u5ea6\u654f\u611f\u7684 \u6cdb\u5316\u635f\u5931\uff0c\u4e0d\u540c\u7c7b\u7684\u76ee\u6807 \u6709 \u4e0d\u540c\u7684\u5c3a\u5bf8\uff0c\u6240\u4ee5\u635f\u5931\u51fd\u6570\u4e5f\u4e0d\u4e00\u6837</li> <li>\u7ed3\u679c</li> </ul>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/","title":"rank11 GCA SUN","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 2393 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 12 \u5206\u949f</p> <p></p> <p>2024\u5e74\u7684\u65b0\u6587\u7ae0\uff0c\u53ef\u4ee5\u770b\u770b</p> <p>\u6e90\u7801\u672a\u516c\u5f00\uff0c\u7b80\u5355\u770b\u770b</p> <p></p> <p>arxiv\u65e5\u671f\uff1a2024\u5e749\u670818\u65e5</p> <p>\u4e00\u773c\u6807\u9898\uff1abuff\u53e0\u6ee1\u4e86\uff0cSwinTransformer &amp; Unet</p> <p>\u4f5c\u8005\uff1a</p> <p>18 Sep 2024 \u00b7 Yuzhe Wu, Yipeng Xu, Tianyu Xu, Jialu Zhang, Jianfeng Ren, Xudong Jiang </p> <p>\u5b81\u6ce2\u8bfa\u4e01\u6c49\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u9662</p> <p>\u5b81\u6ce2\u8bfa\u4e01\u6c49\u5927\u5b66\u5353\u8d8a\u7814\u7a76\u521b\u65b0\u4e2d\u5fc3</p> <p>\u65b0\u52a0\u5761\u5357\u6d0b\u7406\u5de5\u5927\u5b66\u7535\u6c14\u4e0e\u7535\u5b50\u5de5\u7a0b\u5b66\u9662</p> <ul> <li> \u6b63\u5f0f\u53d1\u8868\u65e5\u671f\uff1a</li> </ul> <p>GCA \u8ba9\u6211\u60f3\u8d77\u6765 \u7ea7\u8054\u6ce8\u610f\u529b</p> <ul> <li> \u4e3a\u4ec0\u4e482024\u5e74\u7684\u6587\u7ae0\uff0c\u6392\u540d\u8fd8\u8fd9\u4e48\u4f4e\uff1f</li> <li> \u671f\u520a\uff1f</li> </ul> <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u672a\u516c\u5f00</p> <p>\u6807\u9898\uff1aGCA-SUN: A Gated Context-Aware Swin-UNet for Exemplar-Free Counting </p> <p>\u95e8\u63a7\u4e0a\u4e0b\u6587\u611f\u77e5\u3001Swin-UNet\u67b6\u6784\u3001Exemplar-Free Counting\uff08\u5c31\u662f0-shot\u95ee\u9898\uff09</p>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#_1","title":"\u6458\u8981","text":"<p>\uff08\u672c\u6587\u4e3b\u9898\uff1aExemplar-Free Counting\uff09Exemplar-Free Counting aims to count objects of interest without intensive annotations of objects or exemplars. </p> <p>\u672c\u6587\u7684\u7b2c\u4e00\u4e2a\u63d0\u51fa\uff1a\u4e3a\u4e86\u5b9e\u73b0 Exemplar-Free Counting\uff0c\u63d0\u51fa Gated Context-Aware Swin-UNet (GCA-SUN) </p> <p>To achieve this, we propose Gated Context-Aware Swin-UNet (GCA-SUN) to directly map an input image to the density map of countable objects. \u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u95e8\u63a7\u4e0a\u4e0b\u6587\u611f\u77e5Swin - UNet ( GCA-SUN )\uff0c\u5c06\u8f93\u5165\u56fe\u50cf\u76f4\u63a5\u6620\u5c04\u4e3a\u53ef\u6570\u7269\u4f53\u7684\u5bc6\u5ea6\u56fe</p> <p>Swin-UNet \u7684\u529f\u80fd \u4e00\u53e5\u8bdd\u8bf4\u660e\uff1a\u76f4\u63a5\u5c06\u8f93\u5165\u56fe\u50cf\u6620\u5c04\u5230\u5bc6\u5ea6\u56fe</p> <p>\u5c55\u5f00\u8bf4\u8bf4</p> <p>Specifically, a Gated Context-Aware Modulation module is designed in the encoder to suppress irrelevant objects or background through a gate mechanism and exploit the attentive support of objects of interest through a self-similarity matrix.</p> <p>\u5728\u7f16\u7801\u5668\u4e2d\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u95e8\u63a7\u4e0a\u4e0b\u6587\u611f\u77e5\u8c03\u5236\u6a21\u5757\uff0c\u901a\u8fc7\u95e8\u673a\u5236\u6765\u6291\u5236\u65e0\u5173\u5bf9\u8c61\u6216\u80cc\u666f\uff0c\u5e76\u901a\u8fc7\u81ea\u76f8\u4f3c\u77e9\u9635\u6765\u5229\u7528\u611f\u5174\u8da3\u5bf9\u8c61\u7684\u6ce8\u610f\u529b\u652f\u6301\u3002</p> <p>The gate strategy is also incorporated into the bottleneck network and the decoder to highlight the features most relevant to objects of interest.\u95e8\u7b56\u7565\u4e5f\u88ab\u7eb3\u5165\u5230\u74f6\u9888\u7f51\u7edc\u548c\u89e3\u7801\u5668\u4e2d\uff0c\u4ee5\u7a81\u51fa\u4e0e\u611f\u5174\u8da3\u5bf9\u8c61\u6700\u76f8\u5173\u7684\u7279\u5f81\u3002</p> <p>By explicitly exploiting the attentive support among countable objects and eliminating irrelevant features through the gate mechanisms, the proposed GCA-SUN focuses on and counts objects of interest without relying on predefined categories or exemplars.</p> <p>\u901a\u8fc7\u663e\u5f0f\u5730\u5229\u7528\u53ef\u6570\u5bf9\u8c61\u4e4b\u95f4\u7684\u6ce8\u610f\u529b\u652f\u6301\u548c\u901a\u8fc7\u95e8\u673a\u5236\u6d88\u9664\u65e0\u5173\u7279\u5f81\uff0cGCA - SUN\u5728\u4e0d\u4f9d\u8d56\u9884\u5b9a\u4e49\u7c7b\u522b\u6216\u793a\u4f8b\u7684\u60c5\u51b5\u4e0b\u5173\u6ce8\u548c\u8ba1\u6570\u611f\u5174\u8da3\u7684\u5bf9\u8c61\u3002</p> <p>\u7ed3\u679c\uff09</p> <p>Experimental results on the FSC-147 and CARPK datasets demonstrate that GCA-SUN outperforms state-of-the-art methods. </p> <p>\u6240\u7528\u6570\u636e\u96c6\uff1aFSC147\u3001CARPK</p> <p>Index Terms\u2014Object counting, Exemplar-free counting, Gate mechanism, Self-similarity matrix</p>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#_2","title":"\u5f15\u5165\u2014\u8d21\u732e","text":"<p>Our contributions can be summarized as follows. </p> <ol> <li>The proposed GCA-SUN achieves exemplar-free counting through a UNet-like architecture that utilizes Swin transformer blocks for feature encoding and decoding, avoiding the sample bias of exemplar-based approaches [11].   \u6240\u63d0\u51fa\u7684GCA - SUN\u901a\u8fc7\u7c7bUNet\u7ed3\u6784\u5b9e\u73b0\u4e86\u65e0\u6837\u672c\u8ba1\u6570\uff0c\u8be5\u7ed3\u6784\u5229\u7528Swin\u53d8\u6362\u5757\u8fdb\u884c\u7279\u5f81\u7f16\u7801\u548c\u89e3\u7801\uff0c\u907f\u514d\u4e86\u6837\u672c\u504f\u5dee\uff08EFC\u8ba1\u6570\uff09</li> <li>The proposed GCAM exploits attentive support of repetitive objects through the self similarity matrix, to focus on countable objects. \u63d0\u51fa\u7684GCAM\u901a\u8fc7\u81ea\u76f8\u4f3c\u77e9\u9635\u5229\u7528\u5bf9\u91cd\u590d\u5bf9\u8c61\u7684\u7ec6\u5fc3\u652f\u6301\uff0c\u805a\u7126\u4e8e\u53ef\u6570\u5bf9\u8c61\u3002</li> <li>The gate mechanism is integrated into various modules, e.g., GCAM, GEFS and GAFU, which suppresses the features of irrelevant objects or background while highlighting the most relevant features to countable objects.  \u5c06\u95e8\u673a\u5236\u96c6\u6210\u5230GCAM\u3001GEFS\u548cGAFU\u7b49\u6a21\u5757\u4e2d\uff0c\u5728\u7a81\u51fa\u4e0e\u53ef\u6570\u5bf9\u8c61\u6700\u76f8\u5173\u7684\u7279\u5f81\u7684\u540c\u65f6\uff0c\u6291\u5236\u65e0\u5173\u5bf9\u8c61\u6216\u80cc\u666f\u7684\u7279\u5f81\u3002</li> <li>The proposed GCA-SUN is evaluated on the FSC-147 and CARPK datasets. It outperforms state-of-the-art methods for exemplar-free counting.  \u5728FSC - 147\u548cCARPK\u6570\u636e\u96c6\u4e0a\u5bf9\u63d0\u51fa\u7684GCA - SUN\u8fdb\u884c\u8bc4\u4f30\u3002\u5728\u65e0\u6837\u672c\u8ba1\u6570\u65b9\u9762\uff0c\u5b83\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002</li> </ol> <ul> <li>\u672c\u6587\u63d0\u51fa\u7684\u7f51\u7edc\u7ed3\u6784\uff1a GCA-SUN\u3001\u4f7f\u7528\u4e86SwinTransformer</li> <li>\u6a21\u5757\uff1a GCAM</li> <li>\u95e8\u673a\u5236\uff1aGCAM, GEFS and GAFU</li> <li>\u6570\u636e\u96c6\uff1a FSC-147 and CARPK datasets</li> </ul>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#_3","title":"\u7ed3\u8bba","text":"<p>\u4e00\u3001GCA-SUN</p> <p>The proposed GCA-SUN effectively tackles the problems of exemplar-free counting by using a Swin-UNet architecture to directly map the input image to the density map of countable objects. </p> <p>GCA - SUN\u901a\u8fc7\u4f7f\u7528Swin - UNet\u67b6\u6784\u5c06\u8f93\u5165\u56fe\u50cf\u76f4\u63a5\u6620\u5c04\u5230\u53ef\u6570\u7269\u4f53\u7684\u5bc6\u5ea6\u56fe\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u65e0\u6837\u672c\u8ba1\u6570\u95ee\u9898\u3002</p> <p>\u4e8c\u3001GCAM </p> <p>The proposed GCAM exploits the attention information among the tokens of repetitive objects through the self-similarity matrix, and suppresses the features of irrelevant objects through a gate mechanism.</p> <p>\u6240\u63d0\u51fa\u7684GCAM\u901a\u8fc7\u81ea\u76f8\u4f3c\u77e9\u9635\u6316\u6398\u91cd\u590d\u5bf9\u8c61\u6807\u8bb0\u95f4\u7684\u6ce8\u610f\u529b\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u95e8\u673a\u5236\u6291\u5236\u65e0\u5173\u5bf9\u8c61\u7684\u7279\u5f81\u3002</p> <p>\u4e09\u3001The gate mechanism &amp;  GEFS module  &amp; GAFU module</p> <p>The gate mechanism is also incorporated into the GEFS module and the GAFU module, which highlight the features most relevant to countable objects while suppressing irrelevant ones. </p> <p>\u95e8\u673a\u5236\u4e5f\u88ab\u7eb3\u5165\u5230GEFS\u6a21\u5757\u548cGAFU\u6a21\u5757\u4e2d\uff0c\u7a81\u51fa\u4e0e\u53ef\u6570\u5bf9\u8c61\u6700\u76f8\u5173\u7684\u7279\u5f81\uff0c\u540c\u65f6\u6291\u5236\u4e0d\u76f8\u5173\u7684\u7279\u5f81\u3002</p> <p>\u56db\u3001\u7ed3\u679c</p> <p>Our experiments on the FSC-147 and CARPK datasets demonstrate that GCASUN outperforms state-of-the-art methods, achieving superior performance in both intra-domain and cross-domain scenarios.</p> <p>\u5728FSC - 147\u548cCARPK\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGCASUN\u4f18\u4e8e\u73b0\u6709\u7684\u65b9\u6cd5\uff0c\u5728\u57df\u5185\u548c\u8de8\u57df\u573a\u666f\u4e2d\u90fd\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u3002</p>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#_4","title":"\u5f15\u5165","text":""},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#exemplar-free","title":"\u7b2c\u4e00\u6bb5 \u76ee\u6807\u8ba1\u6570\u5206\u6210\u4e09\u7c7b\uff0c\u7279\u5b9a\u7c7b\u522b\u8ba1\u6570\u3001\u7c7b\u65e0\u5173\u8ba1\u6570\u3001exemplar-free\u8ba1\u6570","text":"<p>Object counting determines the number of instances of a specific object class in an image [1], e.g., vehicles [2], crowd [3], and cells [4]. It can be broadly categorized as:</p> <p>1) Class-Specific Counting (CSC), counting specific categories like fruits [5] and animals [6];  2) Class-Agnostic Counting (CAC), counting objects based on visual exemplars [1], [7], [8] or text prompts [9], [10];  3) Exemplar-Free Counting (EFC), counting objects without exemplars, presenting a significant challenge in discerning countable objects and determining their repetitions [8], [11], [12].</p> <p>Note</p> <p>CSC\u8ba1\u6570\u3001CAC\u8ba1\u6570\uff1b\u7279\u5b9a\u7c7b\u522b\u8ba1\u6570\u3001\u7c7b\u522b\u4e0d\u654f\u611f\u8ba1\u6570</p> <p>FSC\u8ba1\u6570\u3001ZSC\u8ba1\u6570\uff1b\u5c0f\u6837\u672c\u8ba1\u6570\u30010\u6837\u672c\u8ba1\u6570</p>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#exemplar-free-counting-efc","title":"\u7b2c\u4e8c\u6bb5   Exemplar-Free Counting (EFC)\u7684\u7814\u7a76\u73b0\u72b6","text":"<p>Exemplar-Free Counting shows promise for automated systems such as wildlife monitoring [13], healthcare [14], and anomaly detection [15]. </p> <p>Hobley and Prisacariu directly regressed the image-level features learned by attention modules into a density map [12]. </p> <p>CounTR [8] and LOCA [16] are originally designed for CAC tasks, but can be adapted to EFC tasks by using trainable components to simulate exemplars. </p> <p>RepRPN-Counter i==dentifies exemplars from region proposals by majority voting [11], and ==DAVE selects valuable objects using a strategy similar to majority voting based on [17].</p>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#gca-sunencoder-bottleneckdecoder","title":"\u7b2c\u4e09\u6bb5 GCA-SUN=encoder + bottleneck+decoder","text":"<p>\u73b0\u6709EFC\u8ba1\u6570\u5b58\u5728\u4e0d\u8db3 RepRPN-Counter </p> <p>Despite the advancements, existing models [8], [16], [17] often explicitly require exemplars to count similar objects.EFC methods such as RepRPN-Counter do not require exemplars but generate them through region proposal [11]. Either explicit or implicit exemplars may induce sample bias as exemplars can\u2019t cover the sample distribution.  \u7531\u4e8e\u6837\u4f8b\u65e0\u6cd5\u8986\u76d6\u6837\u672c\u5206\u5e03\uff0c\u4e0d\u8bba\u662f\u5916\u663e\u6837\u4f8b\u8fd8\u662f\u5185\u9690\u6837\u4f8b\u90fd\u53ef\u80fd\u5bfc\u81f4\u6837\u672c\u504f\u5dee\u3002</p> <p>\u95e8\u63a7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684 Gated Context-Aware Swin-UNet (GCA-SUN)\uff1b\u76f4\u63a5\u5c06\u8f93\u5165\u56fe\u7247\u6620\u5c04\u6210\u5bc6\u5ea6\u56fe\uff0c\u4e0d\u9700\u8981\u4efb\u4f55\u793a\u4f8b</p> <p>To address the challenge, we propose Gated Context-Aware Swin-UNet (GCA-SUN), which directly maps an input image to the density map of countable objects, without any exemplars. </p> <p>encoder\u5305\u542b\u4e24\u90e8\u5206\uff1a</p> <ul> <li>SwinTransformer \u63d0\u53d6\u7279\u5f81</li> <li>\u95e8\u63a7\u611f\u77e5\u6a21\u5757 </li> </ul> <p>Specifically, the encoder consists of a set of Swin Transformers to extract features, and Gated Context-Aware Modulation (GCAM) blocks to exploit the attentive supports of countable objects. </p> <p>bottleneck network  \u95e8\u63a7\u589e\u5f3a\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u589e\u5f3a encoder\u7279\u5f81 Gated Enhanced Feature Selector (GEFS)</p> <p>The bottleneck network includes a Gated Enhanced Feature Selector (GEFS) to emphasize the encoded features that are relevant to countable objects. </p> <p>decoder\uff1a</p> <ul> <li>SwinTransformer \u751f\u6210\u5bc6\u5ea6\u56fe\uff1a\u7ed3\u5408Gated Adaptive Fusion Units (GAFUs) \u95e8\u63a7\u9002\u5e94\u878d\u5408\u5355\u5143\uff0c\u6309\u7167\u4e0e\u76ee\u6807\u7684\u76f8\u5173\u5ea6\u8fdb\u884c\u52a0\u6743</li> <li>\u6700\u540e \u56de\u5f52\u5934 \u88ab\u4f7f\u7528\uff0c\u4ece\u52a0\u6743\u7279\u5f81\u4e2d\u4ea7\u751f\u5bc6\u5ea6\u56fe</li> </ul> <p>The decoder includes a set of Swin transformers for generating the density map, with the help of Gated Adaptive Fusion Units (GAFUs) to selectively weigh features based on their relevance to countable objects. Finally, a regression head is utilized to derive the density map from the aggregated features.</p> <p>\u603b\u7ed3\u8fd9\u6bb5</p> <ol> <li>Gated Context-Aware Swin-UNet (GCA-SUN)</li> <li>encoder= Swin Transformers +  Gated Context-Aware Modulation (GCAM) blocks </li> <li>bottleneck = Gated Enhanced Feature Selector (GEFS)</li> <li>decoder = Swin transformers + Gated Adaptive Fusion Units (GAFUs)</li> <li>regression head</li> </ol> <p>\u7528\u4e86\u5f88\u591a\u95e8\u63a7\u673a\u5236</p>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#gcam","title":"\u7b2c\u56db\u6bb5 GCAM","text":"<p>One key challenge in EFC is to effectively differentiate countable objects from other objects.  </p> <p>EFC\u7684\u4e00\u4e2a\u6311\u6218\u662f \u5982\u4f55\u6709\u6548\u7684\u4ece\u5176\u4ed6\u76ee\u6807\u4e2d \u533a\u5206\u51fa \u8ba1\u6570\u7269\u4f53\uff1b</p> <p>EFC\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u6311\u6218\u662f\u6709\u6548\u5730\u533a\u5206\u53ef\u6570\u5bf9\u8c61\u4e0e\u5176\u4ed6\u5bf9\u8c61</p> <p>The GCAM blocks tackle the challenge by first evaluating feature qualities by computing the feature score for each token, and then prioritizing those with informative content.</p> <p>GCAM\u6a21\u5757\u9996\u5148\u901a\u8fc7\u8ba1\u7b97\u6bcf\u4e2atoken\u7684\u7279\u5f81\u5f97\u5206\u6765\u8bc4\u4f30\u7279\u5f81\u8d28\u91cf\uff0c\u7136\u540e\u4f18\u5148\u8003\u8651\u90a3\u4e9b\u5177\u6709\u4fe1\u606f\u542b\u91cf\u7684\u7279\u5f81\u3002</p> <p>GCAM\u6a21\u5757\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898</p> <p>GACM\u6a21\u5757\u7684\u529f\u80fd</p> <p>\u95ee\u9898\uff1aeffectively differentiate countable objects from other objects  Solution\uff1aGCAM</p> <p>In addition, GCAM computes pairwise similarities between tokens through a self-similarity matrix, exploiting the support of repeating objects in the same scene.</p> <p>\u6b64\u5916\uff0cGCAM\u901a\u8fc7\u81ea\u76f8\u4f3c\u77e9\u9635\u8ba1\u7b97token\u4e4b\u95f4\u7684\u6210\u5bf9\u76f8\u4f3c\u5ea6\uff0c\u5229\u7528\u540c\u4e00\u573a\u666f\u4e2d\u91cd\u590d\u5bf9\u8c61\u7684\u652f\u6301\u5ea6\u3002</p> <p>Lastly, a gate mechanism is incorporated to highlight the most relevant features while suppressing irrelevant ones.</p> <p>\u6700\u540e\uff0c\u5f15\u5165\u95e8\u673a\u5236\uff0c\u7a81\u51fa\u6700\u76f8\u5173\u7684\u7279\u5f81\uff0c\u540c\u65f6\u6291\u5236\u4e0d\u76f8\u5173\u7684\u7279\u5f81\u3002\u2018</p>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#_5","title":"\u7b2c\u4e94\u6bb5","text":"<p>Another challenge is that foreground objects often share similar low-level features with background content. </p> <p>\u53e6\u4e00\u4e2a\u6311\u6218\u662f\uff0c\u524d\u666f\u5bf9\u8c61\u5f80\u5f80\u4e0e\u80cc\u666f\u5185\u5bb9\u5171\u4eab\u76f8\u4f3c\u7684\u4f4e\u7ea7\u7279\u5f81\u3002</p> <p>The skip connections directly fuse low-level features in the encoder with high-level semantics in the decoder, potentially impeding counting performance as the background information could disturb the foreground objects. </p> <p>\u8df3\u8dc3\u8fde\u63a5\u76f4\u63a5\u5c06\u7f16\u7801\u5668\u4e2d\u7684\u4f4e\u7ea7\u7279\u5f81\u4e0e\u89e3\u7801\u5668\u4e2d\u7684\u9ad8\u7ea7\u8bed\u4e49\u8fdb\u884c\u878d\u5408\uff0c\u7531\u4e8e\u80cc\u666f\u4fe1\u606f\u4f1a\u5bf9\u524d\u666f\u7269\u4f53\u4ea7\u751f\u5e72\u6270\uff0c\u53ef\u80fd\u4f1a\u5f71\u54cd\u8ba1\u6570\u6027\u80fd\u3002</p> <p>To tackle this issue, gate mechanisms are incorporated into both GEFS and GAFU to suppress irrelevant low-level features while preserving as much information on objects of interest as possible. </p> <p>\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5728GEFS\u548cGAFU\u4e2d\u90fd\u878d\u5165\u4e86\u95e8\u673a\u5236\uff0c\u4ee5\u6291\u5236\u4e0d\u76f8\u5173\u7684\u4f4e\u7ea7\u7279\u5f81\uff0c\u540c\u65f6\u5c3d\u53ef\u80fd\u591a\u5730\u4fdd\u7559\u611f\u5174\u8da3\u5bf9\u8c61\u7684\u4fe1\u606f\u3002</p> <p>The former selectively enhances the compressed features at the bottleneck, and the latter filters the features in the decoder.</p> <p>\u524d\u8005\u9009\u62e9\u6027\u5730\u589e\u5f3a\u74f6\u9888\u5904\u7684\u538b\u7f29\u7279\u5f81\uff0c\u540e\u8005\u5728\u89e3\u7801\u5668\u4e2d\u8fc7\u6ee4\u7279\u5f81\u3002</p> <p>\u7b2c\u516d\u6bb5\uff1a\u8d21\u732e</p>"},{"location":"literature/ObejectCounting/rank11%20GCA_SUN/#_6","title":"\u76f8\u5173\u5de5\u4f5c","text":"<p>\u6ca1\u6709\u76f8\u5173\u5de5\u4f5c\uff0c\u672c\u6587\u7684\u76ee\u5f55\u7ed3\u6784\uff1a</p> <p>\u6807\u9898\uff1aGCA-SUN: A Gated Context-Aware Swin-UNet for Exemplar-Free Counting</p> <p>Abstract</p> <p>I. INTRODUCTION</p> <p>II. PROPOSED METHOD</p> <p>A. Overview of Proposed Method</p> <p>B. Swin-T Encoder with GCAM</p> <p>C. Bottleneck with GEFS</p> <p>D. Swin-T Decoder with GAFU</p> <p>III. EXPERIMENTAL RESULTS</p> <p>A. Experimental Settings</p> <p>B. Comparison with State-of-the-Art Methods</p> <p>C. Cross-Domain Evaluation on CARPK Dataset</p> <p>D. Visualization of GCAM </p> <p>E. Ablation Study</p> <p>IV. CONCLUSION</p> <p>24\u00b711\u00b719\uff1a\u7b2c\u4e00\u6b21\u8bfb\uff0c\u56de\u987e</p> <p>CSC\u8ba1\u6570\uff0c\u51e0\u4e2a\u8ba1\u6570\u7684\u7b80\u5199 \u672c\u6587\u95e8\u63a7\u673a\u5236\u591a \u5176\u5b9e\uff0c\u6ca1\u7528U-Net\uff1fSwinTransformer\u6bd4\u8f83\u7c7b\u4f3cU-Net</p>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/","title":"rank12 SAFECount","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 1968 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 10 \u5206\u949f</p> <p>today\uff1a241119 TUE</p> <p></p> <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u94fe\u63a5</p> <p>axriv\u65e5\u671f\uff1a2022\u5e749\u670811\u65e5</p> <p>\u4f5c\u8005\uff1a\u6e05\u534e\u5927\u5b66\u3001\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66</p> <p>\u4f1a\u8bae\uff1a</p> <p>WACV </p> <p>WACV\uff08IEEE Winter Conference on Applications of Computer Vision\uff09 IEEE\u51ac\u5b63\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u4f1a\u8bae  \u4f1a\u8bae\uff08\u91cd\u8981\u4f1a\u8bae\uff09</p> <p>22 Jan 2022 \u00b7 Zhiyuan You, Kai Yang, Wenhan Luo, Xin Lu, Lei Cui, Xinyi Le </p> <p>\u4e09\u5e74\u524d\u7684\u6587\u7ae0</p> <p></p> <p>Title\uff1aFew-shot Object Counting with Similarity-Aware Feature Enhancement</p> <p>\u57fa\u4e8e\u76f8\u4f3c\u6027\u611f\u77e5\u7279\u5f81\u589e\u5f3a\u7684\u5c11\u6837\u672c\u8ba1\u6570</p>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/#_1","title":"\u6458\u8981","text":"<p>\uff08\u95ee\u9898\u5b9a\u4e49\uff09This work studies the problem of few-shot object counting, which counts the number of exemplar objects (i.e., described by one or several support images) occurring in the query image. </p> <p>\uff08\u6307\u51fa\u95ee\u9898\uff09The major challenge lies in that the target objects can be densely packed in the query image, making it hard to recognize every single one.</p> <p>\uff08\u89e3\u51b3\u95ee\u9898\uff09 To tackle the obstacle, we propose a novel learning block, equipped with a similarity comparison module and a feature enhancement module. </p> <p>\u63d0\u51fa\u76f8\u4f3c\u6027\u6bd4\u8f83\u6a21\u5757\u548c\u7279\u5f81\u589e\u5f3a\u6a21\u5757 \u89e3\u51b3 \u76ee\u6807\u5806\u53e0\u7684\u73b0\u8c61</p> <p>\uff08\u5177\u4f53\u6765\u8bf4\uff09Concretely, given a support image and a query image, we first derive a score map by comparing their projected features at every spatial position. </p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u7ed9\u5b9a\u4e00\u5e45\u652f\u6301\u56fe\u50cf\u548c\u4e00\u5e45\u67e5\u8be2\u56fe\u50cf\uff0c\u6211\u4eec\u9996\u5148\u901a\u8fc7\u6bd4\u8f83\u5b83\u4eec\u5728\u6bcf\u4e2a\u7a7a\u95f4\u4f4d\u7f6e\u4e0a\u7684\u6295\u5f71\u7279\u5f81\u5f97\u5230\u4e00\u4e2a\u5f97\u5206\u56fe\u3002</p> <p>The score maps regarding all support images are collected together and normalized across both the exemplar dimension and the spatial dimensions, producing a reliable similarity map. </p> <p>\u6240\u6709\u652f\u6301\u56fe\u50cf\u7684\u5f97\u5206\u56fe\u88ab\u6536\u96c6\u5728\u4e00\u8d77\uff0c\u5e76\u5728\u6837\u672c\u7ef4\u5ea6\u548c\u7a7a\u95f4\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u4ece\u800c\u4ea7\u751f\u53ef\u9760\u7684\u76f8\u4f3c\u5ea6\u56fe\u3002</p> <p>We then enhance the query feature with the support features by employing the developed point-wise similarities as the weighting coefficients. </p> <p>\u7136\u540e\uff0c\u6211\u4eec\u901a\u8fc7\u4f7f\u7528\u70b9\u76f8\u4f3c\u6027\u4f5c\u4e3a\u52a0\u6743\u7cfb\u6570\uff0c\u7528\u652f\u6301\u7279\u5f81\u6765\u589e\u5f3a\u67e5\u8be2\u7279\u5f81\u3002</p> <p>Such a design encourages the model to inspect the query image by focusing more on the regions akin to the support images, leading to much clearer boundaries between different objects. </p> <p>\u8fd9\u6837\u7684\u8bbe\u8ba1\u9f13\u52b1\u6a21\u578b\u5bf9\u67e5\u8be2\u56fe\u50cf\u8fdb\u884c\u68c0\u67e5\uff0c\u66f4\u591a\u5730\u5173\u6ce8\u4e0e\u652f\u6301\u56fe\u50cf\u76f8\u4f3c\u7684\u533a\u57df\uff0c\u4f7f\u5f97\u4e0d\u540c\u5bf9\u8c61\u4e4b\u95f4\u7684\u8fb9\u754c\u66f4\u52a0\u6e05\u6670\u3002</p> <p>\uff08\u7ed3\u679c\uff09Extensive experiments on various benchmarks and training setups suggest that we surpass the state-of-the-art methods by a sufficiently large margin. For instance, on a recent large-scale FSC-147 dataset, we surpass the state-of-the-art method by improving the mean absolute error from 22.08 to 14.32 (35%\u2191). Code has been released here.</p>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/#intro-contribution","title":"intro-contribution","text":"<p>In this work, we propose a S imilarity-A ware F eature  E  nhancement block for object Counting (SAFECount). </p> <p>\u76f8\u4f3c\u6027\u611f\u77e5\u7279\u5f81\u589e\u5f3a\u6a21\u5757</p> <p>As discussed above, feature is more informative while similarity better captures the support-query relationship. Our novel block adequately integrates both of the advantages by exploiting similarity as a guidance to enhance the features for regression. Intuitively, the enhanced feature not only carries the rich semantics extracted from the image, but also gets aware of which regions within the query image are similar to the exemplar object. Specifically, we come up with a similarity comparison module (SCM) and a feature enhancement module (FEM), as illustrated in Fig. 2c. On one hand, different from the naive feature comparison in Fig. 2b, our SCM learns a feature projection, then performs a comparison on the projected features to derive a score map. This design helps select from features the information that is most appropriate for object counting. After the comparison, we derive a reliable similarity map by collecting the score maps with respect to all support images (i.e., few-shot) and normalizing them along both the exemplar dimension and the spatial dimensions. On the other hand, the FEM takes the point-wise similarities as the weighting coefficients, and fuses the support features into the query feature. Such a fusion is able to make the enhanced query feature focus more on the regions akin to the exemplar object defined by support images, facilitating more precise counting.</p>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/#conclusion","title":"Conclusion","text":""},{"location":"literature/ObejectCounting/rank12%20SAFECount/#intro","title":"intro","text":""},{"location":"literature/ObejectCounting/rank12%20SAFECount/#p1-specific-object-class-csc","title":"P1 specific object class  CSC\u8ba1\u6570","text":"<p>Object counting [3, 4], which aims at investigating how many times a certain object occurs in the query image, has received growing attention due to its practical usage [8, 13, 19, 51]. Most existing studies assume that the object to count at the test stage is covered by the training data [1, 10, 11, 19, 31, 50, 51]. As a result, each learned model can only handle a specific object class, greatly limiting its application.</p>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/#p2-fsc","title":"P2  FSC\u8ba1\u6570 \u5b9a\u4e49","text":"<p>To alleviate the generalization problem, few-shot object counting (FSC) is recently introduced [24]. Instead of predefining a common object that is shared by all training images, FSC allows users to customize the object of their own interests with a few support images, as shown in Fig. 1. In this way, we can use a single model to unify the counting of various objects, and even adapt the model to novel classes (i.e., unseen in the training phase) without any retraining.</p>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/#p3-fsc","title":"P3  FSC\u65b9\u6cd5\u6982\u8ff0","text":"<p>A popular solution to FSC is to first represent both the exemplar object (i.e. the support image) and the query image with expressive features, and then pinpoint the candidates via analyzing the feature correlation [20, 24, 46].  FSC\u7684\u4e00\u4e2a\u6d41\u884c\u7684\u89e3\u51b3\u65b9\u6848\u662f\u9996\u5148\u5c06\u793a\u4f8b\u5bf9\u8c61(\u5373\u652f\u6491\u56fe\u50cf)\u548c\u67e5\u8be2\u56fe\u50cf\u90fd\u8868\u793a\u4e3a\u5177\u6709\u8868\u8fbe\u6027\u7684\u7279\u5f81\uff0c\u7136\u540e\u901a\u8fc7\u5206\u6790\u7279\u5f81\u76f8\u5173\u6027[ 20\u300124\u300146 ]\u6765\u786e\u5b9a\u5019\u9009\u5bf9\u8c61\u3002</p> <p>Active attempts roughly fall into two folds. One is feature based [20], as shown in Fig. 2a, where the pooled support feature is concatenated onto the query feature, followed by a regress head to recognize whether the two features are close enough. </p> <p>\u5c1d\u8bd5\u5927\u81f4\u5206\u4e3a\u4e24\u79cd\u3002\u4e00\u79cd\u662f\u57fa\u4e8e\u7279\u5f81\u7684\u65b9\u6cd5[ 20 ]\uff0c\u5982\u56fe2a\u6240\u793a\uff0c\u5176\u4e2d\u6c60\u5316\u7684\u652f\u6301\u7279\u5f81\u88ab\u8fde\u63a5\u5230\u67e5\u8be2\u7279\u5f81\u4e0a\uff0c\u7136\u540e\u662f\u4e00\u4e2a\u56de\u5f52\u5934\u6765\u8bc6\u522b\u4e24\u4e2a\u7279\u5f81\u662f\u5426\u8db3\u591f\u63a5\u8fd1\u3002</p> <p>\u7a7a\u95f4\u4fe1\u606f\u7531\u4e8e\u6c60\u5316\u6ca1\u6709\u4e86</p> <p>However, the spatial information of the support image is omitted by pooling, leaving the feature comparison unreliable. </p> <p></p> <p>The other is similarity-based [24,46], as shown in Fig. 2b, where a similarity map is developed from raw features as the regression object. Nevertheless, the similarity is far less informative than feature, making it hard to identify clear boundaries between objects (see Fig. 5). Accordingly, the counting performance heavily deteriorates when the target objects are densely packed in the query image, like the shoal of fish in Fig. 1.</p> <p>\u53e6\u4e00\u79cd\u662f\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684[ 24\u300146 ]\uff0c\u5982\u56fe2b\u6240\u793a\uff0c\u5176\u4e2d\u76f8\u4f3c\u6027\u56fe\u662f\u7531\u539f\u59cb\u7279\u5f81\u4f5c\u4e3a\u56de\u5f52\u5bf9\u8c61\u5f00\u53d1\u7684\u3002\u7136\u800c\uff0c\u76f8\u4f3c\u5ea6\u7684\u4fe1\u606f\u91cf\u8fdc\u4e0d\u5982\u7279\u5f81\uff0c\u8fd9\u4f7f\u5f97(\u89c1\u56fe5)\u7684\u5bf9\u8c61\u4e4b\u95f4\u5f88\u96be\u8bc6\u522b\u51fa\u6e05\u6670\u7684\u8fb9\u754c\u3002\u56e0\u6b64\uff0c\u5f53\u76ee\u6807\u7269\u4f53\u5728\u67e5\u8be2\u56fe\u50cf\u4e2d\u5bc6\u96c6\u6392\u5217\u65f6\uff0c\u8ba1\u6570\u6027\u80fd\u4e25\u91cd\u6076\u5316\uff0c\u5982\u56fe1\u4e2d\u7684\u9c7c\u7fa4\u3002</p>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/#p4","title":"P4\u8d21\u732e","text":"<p>P5\uff1aFSC147\u6570\u636e\u96c6 &amp; CARPK\u6570\u636e\u96c6</p>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/#related-work","title":"related work","text":"<p>\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206</p> <ul> <li>\u7279\u5b9a\u7269\u4f53\u8ba1\u6570</li> <li>FSC \u5c0f\u6837\u672c\u8ba1\u6570</li> <li>\u5c0f\u6837\u672c\u5b66\u4e60</li> </ul>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/#csc","title":"\u7b2c\u4e00\u90e8\u5206\uff1aCSC \u8ba1\u6570","text":"<p>CAC\u8ba1\u6570 &amp; CSC\u8ba1\u6570 \u8ba1\u6570\u7269\u4f53</p> <p>FSC\u8ba1\u6570 &amp; ZSC\u8ba1\u6570  \u8ba1\u6570\u65b9\u6cd5 density-based\uff1bdetection-based</p> <p>\u63cf\u8ff0\u73b0\u72b6 Class-specific object counting counts objects of a specific class, such as people [19, 31, 50, 51], animals [1], cars [10], among which crowd counting has been widely explored. For this purpose, traditional methods [14, 33, 38] count the number of people occurring in an image through person detection. </p> <p>\u51fa\u73b0\u95ee\u9898 However, object detection is not particularly designed for the counting task and hence shows unsatisfying performance when the crowd is thick. </p> <p>\u89e3\u51b3\u95ee\u9898 To address this issue, recent work [37] employs a deep model to predict the density map from the crowd image, where the sum over the density map gives the counting result [15]. Based on this thought, many attempts have been made to handle more complicated cases [2, 18, 23, 27\u201329, 42, 44, 47, 48, 51]. Some recent studies [31, 36] propose effective loss functions that help predict the position of each person precisely. </p> <p>\u51fa\u73b0\u95ee\u9898 However, all of these methods can only count objects regarding a particular class (e.g., person), making them hard to generalize. </p> <p>\u89e3\u51b3\u95ee\u9898 There are also some approaches targeting counting objects of multiple classes [13, 21, 32, 43]. In particular, Stahl et al. [32] propose to divide the query image into regions and regress the counting results with the inclusion-exclusion principle. Laradji et al. [13] formulate counting as a segmentation problem for better localization. Michel et al. [21] detect target objects and regress multi-class density maps simultaneously. Xu et al. [43] mitigate the mutual interference across various classes by proposing categoryattention module. </p> <p>\u8fd8\u662f\u4e0d\u80fd\u6570\u6ca1\u5728\u8bad\u7ec3\u96c6\u89c1\u8fc7\u7684 Nevertheless, they still can not handle the object classes beyond the training data.</p>"},{"location":"literature/ObejectCounting/rank12%20SAFECount/#fsc","title":"\u7b2c\u4e8c\u90e8\u5206 FSC\u8ba1\u6570","text":"<p>Few-shot object counting (FSC) has recently been proposed [20, 24, 46] and presents a much stronger generalization ability. Instead of pre-knowing the type of object to count, FSC allows users to describe the exemplar object of their own interests with one or several support images. This setting makes the model highly flexible in that it does not require the test object to be covered by the training samples. </p> <p>In other words, a well-learned model could easily make inferences on novel classes (i.e., unseen in the training phase) as long as the support images are provided. To help the model dynamically get adapted to an arbitrary class, a great choice is to compare the object and the query image in feature space [20, 24, 46]. </p> <p>GMN [20] pools the support feature, and concatenates the pooling result onto the query feature, then learns a regression head for pointwise feature comparison. However, the comparison built on concatenation is not as reliable as the similarity [46]. </p> <p>Instead, CFOCNet [46] first performs feature comparison with dot production, and then regresses the density map from the similarity map derived before. </p> <p>FamNet [24] further improves the reliability of the similarity map through multi-scale augmentation and test-time adaptation. But similarities are far less informative than features, hence regressing from the similarity map fails to identify clear boundaries between the densely packed objects. In this work, we propose a similarity-aware feature enhancement block, which integrates the advantages of both features and similarities.</p>"},{"location":"literature/ObejectCounting/rank2%20GeCo/","title":"rank2 GeCo","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u94fe\u63a5</p> <p>reading in 241117</p> <p>arxiv\u65e5\u671f\uff1a2024\u5e749\u670827\u65e5</p> <p>\u6807\u9898\uff1aA Novel Unified Architecture for Low-Shot Counting by Detection and Segmentation</p> <p>\u4e0e\u5206\u5272\u6709\u4ec0\u4e48\u5173\u7cfb\uff1f</p>"},{"location":"literature/ObejectCounting/rank2%20GeCo/#abstract","title":"Abstract","text":"<p> \u7ea6 5819 \u4e2a\u5b57  7 \u884c\u4ee3\u7801  33 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 29 \u5206\u949f</p> <p>Low-shot object counters estimate the number of objects in an image using few or no annotated exemplars. \u95ee\u9898\u5b9a\u4e49</p> <p>Objects are localized by matching them to prototypes, which are constructed by unsupervised image-wide object appearance aggregation. </p> <p>Due to potentially diverse object appearances, the existing approaches often lead to over-generalization and false positive detections. </p> <p>**\u63d0\u51fa\u95ee\u9898\uff1a **   \u7531\u4e8e\u6f5c\u5728\u7684\u591a\u6837\u5316\u7684\u76ee\u6807\u5916\u89c2\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u5f80\u5f80\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u6cdb\u5316\u548c\u8bef\u68c0\u3002</p> <p>Furthermore, the best-performing methods train object localization by a surrogate loss, that predicts a unit Gaussian at each object center. </p> <p>\u6b64\u5916\uff0c\u6027\u80fd\u6700\u597d\u7684\u65b9\u6cd5\u901a\u8fc7\u4e00\u4e2a\u66ff\u4ee3\u635f\u5931\u6765\u8bad\u7ec3\u76ee\u6807\u5b9a\u4f4d\uff0c\u5373\u5728\u6bcf\u4e2a\u76ee\u6807\u4e2d\u5fc3\u9884\u6d4b\u4e00\u4e2a\u5355\u4f4d\u9ad8\u65af\u3002</p> <p>This loss is sensitive to annotation error, hyperparameters and does not directly optimize the detection task, leading to suboptimal counts. </p> <p>\u8fd9\u79cd\u635f\u5931\u5bf9\u6807\u6ce8\u9519\u8bef\u3001\u8d85\u53c2\u6570\u654f\u611f\uff0c\u5e76\u4e14\u6ca1\u6709\u76f4\u63a5\u4f18\u5316\u68c0\u6d4b\u4efb\u52a1\uff0c\u5bfc\u81f4\u6b21\u4f18\u8ba1\u6570\u3002</p> <p>We introduce GeCo, a novel low-shot counter that achieves accurate object detection, segmentation, and count estimation in a unified architecture. </p> <p>Note</p> <p>GeCo:\u5c0f\u6837\u672c\u8ba1\u6570\u5668\uff0c\u540c\u65f6\u662f\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u3001\u5206\u5272\u548c\u8ba1\u6570</p> <p>GeCo robustly generalizes the prototypes across objects appearances through a novel dense object query formulation. </p> <p>GeCo\u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u7a20\u5bc6\u5bf9\u8c61\u67e5\u8be2\u516c\u5f0f\uff0c\u9c81\u68d2\u5730\u6982\u62ec\u4e86\u8de8\u8d8a\u5bf9\u8c61\u5916\u89c2\u7684\u539f\u578b\u3002</p> <p>In addition, a novel counting loss is proposed, that directly optimizes the detection task and avoids the issues of the standard surrogate loss. </p> <p>\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8ba1\u6570\u635f\u5931\uff0c\u76f4\u63a5\u4f18\u5316\u4e86\u68c0\u6d4b\u4efb\u52a1\uff0c\u907f\u514d\u4e86\u6807\u51c6\u66ff\u4ee3\u635f\u5931\u7684\u95ee\u9898\u3002</p> <p>\uff08\u8bf4\u7ed3\u679c\uff09GeCo surpasses the leading few-shot detection-based counters by \u223c25% in the total count MAE, achieves superior detection accuracy and sets a new solid state-of-the-art result across all low-shot counting setups. The code will be available on GitHub.</p> <p>GeCo\u5728\u603b\u8ba1\u6570MAE\u4e0a\u8d85\u8fc7\u4e86\u9886\u5148\u7684\u57fa\u4e8e\u5c0f\u6837\u672c\u68c0\u6d4b\u7684\u8ba1\u6570\u566825 %\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u5728\u6240\u6709\u7684\u5c0f\u6837\u672c\u8ba1\u6570\u8bbe\u7f6e\u4e2d\u90fd\u53d6\u5f97\u4e86\u6700\u65b0\u7684\u56fa\u6001\u7ed3\u679c\u3002</p>"},{"location":"literature/ObejectCounting/rank2%20GeCo/#introduction-contribution","title":"Introduction contribution","text":"<p>\uff08\u7b2c\u4e94\u6bb5\uff09 \u8d21\u732e</p> <p>We address the aforementioned challenges by proposing a new single-stage low-shot counter GeCo, which is implemented as an add-on network for SAM [12] backbone. </p> <ul> <li> <p>\u9488\u5bf9\u4e0a\u9762\u7684\u95ee\u9898\uff0c\u63d0\u51faGeCo </p> </li> <li> <p>\u4f18\u70b9\uff1a\u5355\u9636\u6bb5</p> </li> <li> <p>SAM\u662f\u5565\uff1f</p> </li> </ul> <p>A single architecture is thus trained for both few-shot and zero-shot setup, it enables counting by detection and provides segmentation masks for each of the detected objects. </p> <ul> <li>\u4f18\u70b9\uff1a\u5355\u9636\u6bb5\u68c0\u6d4b\u8ba1\u6570\u65b9\u6cd5\uff0c few-shot &amp; zero-shot \u90fd\u662f\u5355\u9636\u6bb5\u8ba1\u6570</li> <li>\u4e3a\u6bcf\u4e2a\u88ab\u68c0\u6d4b\u7684\u5bf9\u8c61\u63d0\u4f9b\u5206\u5272\u63a9\u7801</li> <li>\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570\u65b9\u6cd5</li> </ul> <p>Our first contribution  is a dense object query formulation, which applies a non-parametric model for image-wide prototype generalization (hence GeCo) in the encoder, and decodes the queries into highly dense predictions.</p> <p>\u6211\u4eec\u7684\u7b2c\u4e00\u4e2a\u8d21\u732e\u662f\u4e00\u4e2a\u7a20\u5bc6\u5bf9\u8c61\u67e5\u8be2\u516c\u5f0f\uff0c\u5b83\u5728\u7f16\u7801\u5668\u4e2d\u5e94\u7528\u4e86\u4e00\u4e2a\u975e\u53c2\u6570\u6a21\u578b\u7528\u4e8e\u56fe\u50cf\u8303\u56f4\u7684\u539f\u578b\u6cdb\u5316(\u56e0\u6b64\u662fGeCo )\uff0c\u5e76\u5c06\u67e5\u8be2\u89e3\u7801\u4e3a\u9ad8\u5ea6\u7a20\u5bc6\u7684\u9884\u6d4b\u3002</p> <p>The formulation simultaneously enables reliable detection in densely-populated regions (Figure 1, column 3&amp;4) and prevents prototype over-generalization, leading to an improved detection precision at a high recall. </p> <p>\u8be5\u516c\u5f0f\u540c\u65f6\u5b9e\u73b0\u4e86\u5728\u4eba\u53e3\u5bc6\u96c6\u533a\u57df(\u56fe1\u7b2c3\u30014\u5217)\u7684\u53ef\u9760\u68c0\u6d4b\uff0c\u5e76\u9632\u6b62\u4e86\u539f\u578b\u7684\u8fc7\u5ea6\u6cdb\u5316\uff0c\u4ece\u800c\u5728\u9ad8\u53ec\u56de\u7387\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u3002</p> <p>Our second contribution  is a new loss function for dense detection training that avoids the ad-hoc surrogate loss with unit Gaussians, it directly optimizes the detection task, and leads to improved detection not biased towards blob-like regions (Figure 1, column 1&amp;2).</p> <p>\u6211\u4eec\u7684\u7b2c\u4e8c\u4e2a\u8d21\u732e\u662f\u4e00\u4e2a\u65b0\u7684\u7528\u4e8e\u5bc6\u96c6\u68c0\u6d4b\u8bad\u7ec3\u7684\u635f\u5931\u51fd\u6570\uff0c\u5b83\u907f\u514d\u4e86\u4f7f\u7528\u5355\u4f4d\u9ad8\u65af\u7684ad - hoc\u4ee3\u7406\u635f\u5931\uff0c\u5b83\u76f4\u63a5\u4f18\u5316\u4e86\u68c0\u6d4b\u4efb\u52a1\uff0c\u5e76\u5bfc\u81f4\u6539\u8fdb\u7684\u68c0\u6d4b\u4e0d\u504f\u5411\u4e8e\u56e2\u5757\u72b6\u533a\u57df(\u56fe1\u7b2c1\u30012\u5217)\u3002</p> <p>\u8bf4\u660e\u4e24\u4e2a\u8d21\u732e</p> <ul> <li>\uff1f</li> <li>\u63d0\u51fa\u4e86\u65b0\u7684\u635f\u5931\u51fd\u6570</li> </ul> <p>\uff08\u7b2c\u516d\u6bb5\uff09  \u7ed3\u679c GeCo outperforms all detection-based counters on challenging benchmarks by 24% MAE and the density-based long-standing winner [4] by 27% MAE, while delivering superior detection accuracy. </p> <p>\u4f18\u4e8e\u6240\u6709 \u57fa\u4e8e\u68c0\u6d4b \u548c \u57fa\u4e8e\u5bc6\u5ea6\u7684 \u8ba1\u6570\u65b9\u6cd5</p> <p>The method shows substantial robustness to the number of exemplars. In one-shot scenario, GeCo outperforms the best detection method in 5% AP50, </p> <p>\u57281-shot\u573a\u666f\u7684\u68c0\u6d4b\u6027\u80fd</p> <p>45% MAE and by 14% in a zero-shot scenario. </p> <p>0-shot\u7684\u8ba1\u6570\u6027\u80fd</p> <p>GeCo is the first detection-based counter that outperforms density based counters in all measures by using the number of detections as the estimator, and thus sets a milestone in low-shot detection-based counting.</p>"},{"location":"literature/ObejectCounting/rank2%20GeCo/#5-conclusion","title":"5 Conclusion","text":"<p>\u7b2c\u4e00\u6bb5 </p> <p>We proposed GeCo, a novel single-stage low-shot counter that integrates accurate detection, segmentation, and count prediction within a unified architecture, and covers all low-shot scenarios with a single trained model. </p> <p>GeCo</p> <ul> <li>\u5355\u9636\u6bb5\u8ba1\u6570\u65b9\u6cd5\u3001\u51c6\u786e\u7684\u68c0\u6d4b\u3001\u5206\u5272\u6027\u80fd</li> </ul> <p>GeCo features remarkables dense object query formulation, and prototype generalization across the image, rather than just into a few prototypes.</p> <p>\uff1fGe Co\u7684\u663e\u8457\u7279\u70b9\u662f\u5bf9\u8c61\u67e5\u8be2\u63cf\u8ff0\u5bc6\u96c6\uff0c\u539f\u578b\u6cdb\u5316\u904d\u5e03\u6574\u4e2a\u56fe\u50cf\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u751f\u6210\u51e0\u4e2a\u539f\u578b\u3002</p> <p>It employs a novel loss function specifically designed for detection tasks, avoiding the biases of traditional Gaussian-based losses. </p> <p>\uff1f\u5b83\u91c7\u7528\u4e86\u4e00\u79cd\u4e13\u95e8\u4e3a\u68c0\u6d4b\u4efb\u52a1\u8bbe\u8ba1\u7684\u65b0\u9896\u7684\u635f\u5931\u51fd\u6570\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u7684\u57fa\u4e8e\u9ad8\u65af\u7684\u635f\u5931\u7684\u504f\u5dee\u3002</p> <p>The loss optimizes detection accuracy directly, leading to more precise detection and counting. </p> <p>\u8be5\u635f\u5931\u76f4\u63a5\u4f18\u5316\u4e86\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u5bfc\u81f4\u66f4\u7cbe\u786e\u7684\u68c0\u6d4b\u548c\u8ba1\u6570\u3002</p> <p>\u6307\u51fa\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411</p> <p>The main limitation of the presented method is that it cannot process arbitrarily large images, due to memory constraints, since it, as all current methods, operates globally. In future work, we will explore local counting and incremental image-wide count aggregation.</p> <p>\u672c\u6587\u65b9\u6cd5\u7684\u4e3b\u8981\u5c40\u9650\u6027\u5728\u4e8e\uff0c\u7531\u4e8e\u5185\u5b58\u9650\u5236\uff0c\u65e0\u6cd5\u5904\u7406\u4efb\u610f\u5927\u7684\u56fe\u50cf\uff0c\u56e0\u4e3a\u5b83\u4e0e\u73b0\u6709\u7684\u6240\u6709\u65b9\u6cd5\u4e00\u6837\uff0c\u662f\u5168\u5c40\u64cd\u4f5c\u7684\u3002\u5728\u672a\u6765\u7684\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5c06\u63a2\u7d22\u5c40\u90e8\u8ba1\u6570\u548c\u589e\u91cf\u56fe\u50cf\u8303\u56f4\u5185\u7684\u8ba1\u6570\u805a\u5408\u3002</p> <p>\uff08\u7b2c\u4e8c\u6bb5\uff09  \uff08\u8bf4\u7ed3\u679c\u4e86\uff0c\u6ca1\u5565\u53ef\u770b\u7684\uff09 Extensive analysis showcases that GeCo surpasses the best detection-based counters by approximately 25% in total count MAE, achieving state-of-the-art performance in a few-shot counting setup and demonstrates superior detection capabilities. GeCo showcases remarkable robustness to the number of provided exemplars, and sets a new state-of-the-art in one-shot as well as zero-shot counting.</p> <p>\u5927\u91cf\u7684\u5206\u6790\u8868\u660e\uff0cGeCo\u5728\u603b\u8ba1\u6570MAE\u4e0a\u8d85\u8fc7\u4e86\u6700\u597d\u7684\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570\u5668\u7ea625 %\uff0c\u5728\u5c11\u91cf\u7684\u8ba1\u6570\u8bbe\u7f6e\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u663e\u793a\u51fa\u5353\u8d8a\u7684\u68c0\u6d4b\u80fd\u529b\u3002GeCo\u5bf9\u6240\u63d0\u4f9b\u7684\u6837\u672c\u6570\u91cf\u8868\u73b0\u51fa\u663e\u8457\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u5355\u6837\u672c\u548c\u96f6\u6837\u672c\u8ba1\u6570\u4e2d\u8bbe\u7f6e\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002</p>"},{"location":"literature/ObejectCounting/rank2%20GeCo/#1-introduction","title":"1 Introduction","text":"<p>\uff08\u7b2c\u4e00\u6bb5\uff09  Low-shot object counting considers estimating the number of objects of previously unobserved category in the image, given only a few annotated exemplars (few-shot) or without any supervision (zero-shot) [21]. The current state-of-the-art methods are predominantly based on density estimation [4; 14; 31; 25; 21; 30; 7; 30]. These methods predict a density map over the image and estimate the total count by summing the density.</p> <p>\u6700\u8fd1\u7684\u7814\u7a76\u90fd\u662f\u57fa\u4e8e\u5bc6\u5ea6\u7684\u8ba1\u6570</p> <p>\uff08\u7b2c\u4e8c\u6bb5\uff09   While being remarkably robust for global count estimation, density outputs lack explainability such as object location and size, which is crucial for many practical applications [32; 29]. This recently gave rise to detection-based low-shot counters [20; 19; 33], which predict the object bounding boxes and estimate the total count as the number of detections\uff08\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570\u65b9\u6cd5\u662f\u5982\u4f55\u5177\u4f53\u5b9e\u73b0\u7684\uff1a\u9884\u6d4b\u8fb9\u754c\u6846\uff0c\u6570\u76d2\u5b50\u6570\uff09. Nevertheless, detection-based counting falls behind the density-based methods in total count estimation, leaving a performance gap.</p> <p>\uff08\u70b9\u660e\u57fa\u4e8e\u5bc6\u5ea6\u7684\u8ba1\u6570\u65b9\u6cd5\u5b58\u5728\u7684\u95ee\u9898\uff09\u57fa\u4e8e\u5bc6\u5ea6\u7684\u8ba1\u6570\u51c6\u786e\u6027\u6bd4\u8f83\u9ad8\uff0c\u4f46\u662f\u4e0d\u80fd\u7ed9\u51fa\u76ee\u6807\u7684\u5b9a\u4f4d\u548c\u5c3a\u5bf8</p> <p>\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570\u65b9\u6cd5\u80fd\u8be6\u7ec6\u7ed9\u51fa\u76ee\u6807\u7684\u4fe1\u606f\uff0c\u4f46\u662f\u8ba1\u6570\u51c6\u786e\u6027\u4e0d\u9ad8</p> <p>\uff08\u7b2c\u4e09\u6bb5\uff09   In detection-based counters, a dominant approach to identify locations of the objects in the image involves construction of object prototypes from few (e.g., three) annotated exemplar bounding boxes and correlating them with image features [20; 33; 19].</p> <p>\u5728\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570\u5668\u4e2d\uff0c\u8bc6\u522b\u56fe\u50cf\u4e2d\u7269\u4f53\u4f4d\u7f6e\u7684\u4e3b\u8981\u65b9\u6cd5\u662f\u901a\u8fc7\u5c11\u91cf\u7684(\u4f8b\u5982,\u4e09\u4e2a)\u5e26\u6ce8\u91ca\u7684\u6837\u672c\u8fb9\u754c\u6846\u6784\u5efa\u7269\u4f53\u539f\u578b\uff0c\u5e76\u5c06\u5176\u4e0e\u56fe\u50cf\u7279\u5f81[ 20 ; 33 ; 3 . 19 ]\u76f8\u5173\u8054\u3002</p> <p>The exemplar construction process is trained to account for potentially large diversity of object appearances in the image, often leading to overgeneralization, which achieves a high recall, but is also prone to false positive detection. </p> <p>\u6837\u4f8b\u6784\u5efa\u8fc7\u7a0b\u88ab\u8bad\u7ec3\u7528\u4e8e\u89e3\u91ca\u56fe\u50cf\u4e2d\u6f5c\u5728\u7684\u5de8\u5927\u7684\u7269\u4f53\u5916\u89c2\u591a\u6837\u6027\uff0c\u901a\u5e38\u4f1a\u5bfc\u81f4\u8fc7\u5ea6\u6cdb\u5316\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u8f83\u9ad8\u7684\u53ec\u56de\u7387\uff0c\u4f46\u4e5f\u5bb9\u6613\u4ea7\u751f\u8bef\u68c0\u3002</p> <p>Note</p> <p>\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570\u65b9\u6cd5\u5b58\u5728\u7684\u95ee\u9898\uff1a\u53ec\u56de\u7387\u592a\u9ad8\u4e86</p> <p>Post-hoc detection verification methods have been considered [20; 33] to address the issue, but their multi-stage formulation prevents exploiting the benefits of end-to-end training.</p> <p>\u4e8b\u540e\u68c0\u6d4b\u9a8c\u8bc1\u65b9\u6cd5\u4e00\u76f4\u88ab\u8ba4\u4e3a\u662f[ 20 ; 33]\u6765\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u7684\u591a\u9636\u6bb5\u5236\u5b9a\u963b\u6b62\u4e86\u5229\u7528\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u597d\u5904\u3002</p> <p>me\uff1a\u5148\u68c0\u6d4b\u518d\u9a8c\u8bc1\u633a\u597d\u7684\uff0c\u4f46\u662f \u4e0d\u662f\u5355\u4e00\u9636\u6bb5\u7684\uff0c\u4ed6\u8bf4\u7684\u662fDAVE\uff0c\u4e00\u4e2a\u4f5c\u8005\u7684\u5de5\u4f5c</p> <p></p> <p>\uff08\u7b2c\u56db\u6bb5\uff09    Currently, the best detection counters [20; 33] predict object locations based on the local maxima in the correlation map. </p> <p>\u76ee\u524d\uff0c\u6700\u597d\u7684\u68c0\u6d4b\u8ba1\u6570\u5668[ 20 ; 33]\u662f\u6839\u636e\u76f8\u5173\u56fe\u4e2d\u7684\u5c40\u90e8\u6781\u5927\u503c\u6765\u9884\u6d4b\u76ee\u6807\u4f4d\u7f6e\u3002</p> <p>During training, the map prediction is supervised by a unit Gaussian placed on each object center. </p> <p>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u9884\u6d4b\u7531\u6bcf\u4e2a\u76ee\u6807\u4e2d\u5fc3\u7684\u5355\u4f4d\u9ad8\u65af\u5206\u5e03\u76d1\u7763</p> <p>However, the resulting surrogate loss is susceptible to the center annotation noise, requires nontrivial heuristic choice of the Gaussian kernel size and in practice leads to detection preference of compact blob-like structures (see Figure 1, column 1&amp;2). </p> <p>\u7136\u800c\uff0c\u7531\u6b64\u4ea7\u751f\u7684\u66ff\u4ee3\u635f\u5931\u5bb9\u6613\u53d7\u5230\u4e2d\u5fc3\u6807\u6ce8\u566a\u58f0\u7684\u5f71\u54cd\uff0c\u9700\u8981\u975e\u5e73\u51e1\u7684\u542f\u53d1\u5f0f\u9009\u62e9\u9ad8\u65af\u6838\u5927\u5c0f\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u4e2d\u5bfc\u81f4\u7d27\u51d1\u7684\u5757\u72b6\u7ed3\u6784(\u89c1\u56fe1 ,\u52171\u548c2)\u7684\u68c0\u6d4b\u504f\u597d\u3002</p> <p>Recently, DETR [1] inspired counter was proposed to avoid this issue [19], however, it fails in densely populated regions even though it applies a very large number of detection queries in a regular grid (see Figure 1, column 3&amp;4).</p> <p>\u6700\u8fd1\uff0cDETR [ 1 ]\u542f\u53d1\u7684\u8ba1\u6570\u5668\u88ab\u63d0\u51fa\u6765\u907f\u514d\u8fd9\u4e2a\u95ee\u9898[ 19 ]\uff0c\u7136\u800c\uff0c\u5c3d\u7ba1\u5b83\u5728\u89c4\u5219\u7f51\u683c(\u89c1\u56fe1 ,\u7b2c3\u30014\u5217)\u4e2d\u5e94\u7528\u4e86\u5927\u91cf\u7684\u68c0\u6d4b\u67e5\u8be2\uff0c\u4f46\u5b83\u5728\u4eba\u53e3\u5bc6\u96c6\u7684\u5730\u533a\u5931\u8d25\u4e86\u3002</p> <p></p> <p>Figure 1: DAVE [20] predicts object centers (red dots) biased towards blob-like structures, leading to incorrect partial detections of ants (bottom left), while GeCo(ours) addresses this with the new loss (top left). \u56fe1\uff1aDAVE [ 20 ]\u9884\u6d4b\u7684\u76ee\u6807\u4e2d\u5fc3(\u7ea2\u8272\u5706\u70b9)\u504f\u5411\u4e8eblob - like\u7ed3\u6784\uff0c\u5bfc\u81f4\u9519\u8bef\u7684\u90e8\u5206\u8682\u8681\u68c0\u6d4b(\u5de6\u4e0b)\uff0c\u800cGeCo (\u6211\u4eec\u7684)\u7528\u65b0\u7684\u635f\u5931(\u5de6\u4e0a)\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002</p> <p>CDETR [19] fails in densely populated regions (bottom right), while GeCo addresses this with the new dense query formulation by prototype generalization (top right). Exploiting the SAM backbone, GeCo delivers segmentations as well. Exemplars are denoted in blue.CDETR [ 19 ]\u5728\u4eba\u53e3\u7a20\u5bc6\u533a\u57df(\u53f3\u4e0b\u89d2)\u5931\u6548\uff0c\u800cGe Co\u901a\u8fc7\u539f\u578b\u6cdb\u5316(\u53f3\u4e0a\u89d2)\u7684\u65b0\u7684\u7a20\u5bc6\u67e5\u8be2\u5f62\u5f0f\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u5229\u7528SAM\u9aa8\u5e72\u7f51\uff0cGeCo\u4e5f\u63d0\u4f9b\u4e86\u5206\u6bb5\u3002\u56fe\u4f8b\u7528\u84dd\u8272\u8868\u793a\u3002</p> <p>\u8fd9\u4e00\u6bb5\u3001\u8fd9\u4e2a\u56fe\uff0c\u6211\u90fd\u770b\u4e0d\u61c2\uff1bGeCo\u6709\u4e00\u4e2a\u65b0\u635f\u5931\uff1bGeCo\uff0c\u5bf9\u6bd4\u4e86DAVE\uff08\u4ed6\u81ea\u5df1\u7684\u5de5\u4f5c\uff09\u3001CDETR\uff08\uff1f\uff09</p> <p>Summary</p> <p>\u95ee\u9898\u7684\u5f15\u5165\uff08\u80cc\u666f&amp;\u7814\u7a76\u610f\u4e49\uff09\uff1a</p> <ol> <li>Low-shot object counting</li> <li>\u57fa\u4e8e\u68c0\u6d4b &amp; \u57fa\u4e8e\u56de\u5f52\uff08\u8fd1\u6765\u4e3b\u6d41\uff0c\u4f46\u8ba1\u6570\u5c31\u4ec5\u4ec5\u662f\u8ba1\u6570\uff0c\u65e0\u6cd5\u7ed9\u51fa\u5173\u4e8e\u76ee\u6807\u66f4\u8be6\u7ec6\u7684\u4fe1\u606f\uff09</li> <li>\u57fa\u4e8e\u68c0\u6d4b</li> <li>\u57fa\u4e8e\u68c0\u6d4b</li> <li>\u672c\u6587\u8d21\u732e</li> <li>\u7ed3\u679c</li> </ol>"},{"location":"literature/ObejectCounting/rank2%20GeCo/#2-related-works","title":"2 Related works","text":"<p>\u7b2c\u4e00\u6bb5 </p> <p>Traditional counting methods focus on predefined categories like vehicles[3], cells [5], people[15], and polyps, [32] requiring extensive annotated training data and lacking generalization to other categories, necessitating retraining or conceptual changes. Low-shot counting methods address this limitation by estimating counts for arbitrary categories with minimal or no annotations, enabling test-time adaptation.\u4f20\u7edf\u7684\u8ba1\u6570\u65b9\u6cd5\u96c6\u4e2d\u4e8e\u9884\u5b9a\u4e49\u7684\u7c7b\u522b\uff0c\u5982\u8f66\u8f86[ 3 ]\uff0c\u7ec6\u80de[ 5 ]\uff0c\u4eba[ 15 ]\u548c\u606f\u8089[ 32 ]\uff0c\u9700\u8981\u5927\u91cf\u6807\u6ce8\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u7f3a\u4e4f\u5bf9\u5176\u4ed6\u7c7b\u522b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u6216\u6982\u5ff5\u66f4\u6539\u3002\u4f4e\u6837\u672c\u8ba1\u6570\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u6700\u5c11\u6216\u6ca1\u6709\u6ce8\u91ca\u6765\u4f30\u8ba1\u4efb\u610f\u7c7b\u522b\u7684\u8ba1\u6570\u6765\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u4ece\u800c\u5b9e\u73b0\u6d4b\u8bd5\u65f6\u95f4\u7684\u81ea\u9002\u5e94\u3002</p> <p>me\uff1a\u6307\u51fa\u4ece \u7279\u5b9a\u7269\u4f53 \u53d1\u5c55\u5230 \u901a\u7528\u7269\u4f53\u8ba1\u6570</p> <p>\u7b2c\u4e8c\u6bb5 </p> <p>With the proposal of the   FSC147   dataset [23] low-shot counting methods emerged, which predict global counts by summing over a predicted density maps. The first method [23] proposed an adaptation of a tracking backbone for density map regression. </p> <p>few-shot \u95ee\u9898\u7684\u7b2c\u4e00\u7bc7\u5de5\u4f5c\uff1aFSC147 \uff1b\u4e14\u662f\u57fa\u4e8e \u56de\u5f52\u7684</p> <p>BMNet+ [25] tackled learning representation and similarity metric, while SAFECount [31] introduced a new feature enhancement module, improving appearance generalization. CounTR [14] utilized a vision transformer for image feature extraction and a convolutional network for encoding the exemplar features. LOCA [4] argued that exemplar shape information should be considered along with the appearance, and proposed an iterative object prototype extraction module. This led to a simplified counter architecture that remains a top-performer among density-based counters.</p> <p>BMNet + [ 25 ]\u89e3\u51b3\u4e86\u5b66\u4e60\u8868\u793a\u548c\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u800cSAFECount [ 31 ]\u5f15\u5165\u4e86\u65b0\u7684\u7279\u5f81\u589e\u5f3a\u6a21\u5757\uff0c\u63d0\u9ad8\u4e86\u5916\u89c2\u6cdb\u5316\u6027\u3002Coun TR [ 14 ]\u4f7f\u7528\u89c6\u89c9\u8f6c\u6362\u5668\u8fdb\u884c\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\uff0c\u4f7f\u7528\u5377\u79ef\u7f51\u7edc\u5bf9\u6837\u672c\u7279\u5f81\u8fdb\u884c\u7f16\u7801\u3002LOCA [ 4 ]\u8ba4\u4e3a\u6837\u4f8b\u7684\u5f62\u72b6\u4fe1\u606f\u5e94\u8be5\u4e0e\u5916\u89c2\u4e00\u8d77\u8003\u8651\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fed\u4ee3\u7684\u5bf9\u8c61\u539f\u578b\u63d0\u53d6\u6a21\u5757\u3002\u8fd9\u5bfc\u81f4\u4e86\u4e00\u4e2a\u7b80\u5316\u7684\u8ba1\u6570\u5668\u67b6\u6784\uff0c\u5b83\u4ecd\u7136\u662f\u57fa\u4e8e\u5bc6\u5ea6\u7684\u8ba1\u6570\u5668\u4e2d\u7684\u4f7c\u4f7c\u8005\u3002</p> <p>Note</p> <p>5\u7bc7\u6587\u7ae0  1. \uff082021\u5e74\uff09FSC147\uff1a\u7b2c\u4e00\u7bc7  few-shot\u95ee\u9898\uff0c\u63d0\u51fa\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u56de\u5f52\u7684\u65b9\u6cd5 2. BMNet+ [25] 3. SAFECount [31] 4. CounTR [14]   ViT\u56fe\u7247\u7279\u5f81\u63d0\u53d6\uff1bCNN\u6837\u4f8b\u6846\u7279\u5f81 5. LOCA [4] \u5916\u89c2\u7279\u5f81\u3001\u5f62\u72b6\u7279\u5f81\u3001\u539f\u578b\u8fed\u4ee3\u6a21\u5757\uff1b\u57fa\u4e8e\u5bc6\u5ea6\uff08\u56de\u5f52\uff09\u7684\u8ba1\u6570\u65b9\u6cd5</p> <p>\u7b2c\u4e09\u6bb5</p> <p>To improve explainability of the estimated counts and estimate object locations as well, detectionbased methods emerged. </p> <p>\u4e3a\u4e86\u63d0\u9ad8\u4f30\u8ba1\u8ba1\u6570\u548c\u4f30\u8ba1\u76ee\u6807\u4f4d\u7f6e\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u57fa\u4e8e\u68c0\u6d4b\u7684\u65b9\u6cd5\u5e94\u8fd0\u800c\u751f\u3002</p> <p>\uff08\u5148\u8bf4 \u6700\u65e9\u7684\uff09   The first few-shot detection-based counter [19] was an extended transformer-based object detector [2] with the ability to detect objects specified by the exemplars. </p> <p>\u6700\u65e9\u7684\u57fa\u4e8e\u5c0f\u6837\u672c\u68c0\u6d4b\u7684\u8ba1\u6570\u5668[ 19 ]\u662f\u4e00\u79cd\u6269\u5c55\u7684\u57fa\u4e8e\u8f6c\u6362\u5668\u7684\u76ee\u6807\u68c0\u6d4b\u5668[ 2 ]\uff0c\u5177\u6709\u68c0\u6d4b\u6837\u672c\u6307\u5b9a\u76ee\u6807\u7684\u80fd\u529b\u3002</p> <p>\uff08\u73b0\u5728\u6700\u597d\u7684\uff09   Current state-of-the-art DAVE [20] proposed a two-stage detect-and-verify paradigm for low-shot counting and detection, where in the first stage it generates object proposals with a high recall, but low precision, which is improved by a subsequent verification step. </p> <p>\u76ee\u524d\u6700\u5148\u8fdb\u7684DAVE [ 20 ]\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u68c0\u6d4b-\u9a8c\u8bc1\u8303\u5f0f\u7528\u4e8e\u4f4e\u955c\u5934\u8ba1\u6570\u548c\u68c0\u6d4b\uff0c\u5176\u4e2d\u7b2c\u4e00\u9636\u6bb5\u751f\u6210\u7684\u7269\u4f53\u63d0\u8bae\u5177\u6709\u8f83\u9ad8\u7684\u53ec\u56de\u7387\uff0c\u4f46\u7cbe\u5ea6\u8f83\u4f4e\uff0c\u5e76\u901a\u8fc7\u540e\u7eed\u7684\u9a8c\u8bc1\u6b65\u9aa4\u8fdb\u884c\u6539\u8fdb\u3002</p> <p>PSECO [33] proposed a three-stage approach called point-segment-and-count, which employs more involved proposal generation with better detection accuracy and also applies a verification step to improve precision. </p> <p>PSECO [ 33 ]\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u70b9-\u6bb5-\u8ba1\u6570\u7684\u4e09\u9636\u6bb5\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u4e86\u66f4\u591a\u53c2\u4e0e\u7684\u5efa\u8bae\u751f\u6210\uff0c\u5177\u6709\u66f4\u597d\u7684\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u4e14\u8fd8\u5e94\u7528\u4e86\u9a8c\u8bc1\u6b65\u9aa4\u6765\u63d0\u9ad8\u7cbe\u5ea6\u3002</p> <p>Both DAVE and PSECO are multi-stage methods that train a network for the surrogate task of predicting density maps for object centers, from which the bounding boxes are predicted. </p> <p>Although detection-based counters offer additional applicability, they fall behind the best density-based counters in global count estimation.</p> <p>DAVE\u548cPSECO\u90fd\u662f\u591a\u9636\u6bb5\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bad\u7ec3\u4e00\u4e2a\u7f51\u7edc\uff0c\u7528\u4e8e\u9884\u6d4b\u76ee\u6807\u4e2d\u5fc3\u7684\u5bc6\u5ea6\u56fe\u7684\u66ff\u4ee3\u4efb\u52a1\uff0c\u5e76\u4ece\u4e2d\u9884\u6d4b\u8fb9\u754c\u6846\u3002\u5c3d\u7ba1\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570\u5668\u63d0\u4f9b\u4e86\u989d\u5916\u7684\u9002\u7528\u6027\uff0c\u4f46\u5b83\u4eec\u843d\u540e\u4e8e\u5168\u5c40\u8ba1\u6570\u4f30\u8ba1\u4e2d\u6700\u597d\u7684\u57fa\u4e8e\u5bc6\u5ea6\u7684\u8ba1\u6570\u5668\u3002</p> <p>summary</p> <p>DAVE\u548cPSECO \u591a\u9636\u6bb5\u3001\u6bd4\u4e0d\u8fc7\u73b0\u5728\u6700\u597d\u7684\uff0c\u73b0\u5728\u6700\u597d\u7684\u662f \u57fa\u4e8e\u5bc6\u5ea6\u56de\u5f52\u56fe\u7684CountGD \u00b7 \u6587\u672c&amp;\u56fe\u50cf</p> <p>Note</p> <p>\u884c\u6587\u903b\u8f91</p> <p>\u7b2c\u4e00\u6bb5\uff1a\u4ece\u7279\u5b9a \\(\\rightarrow\\)  \u901a\u7528 \u76ee\u6807\u8ba1\u6570</p> <p>\u7b2c\u4e8c\u6bb5\uff1a\u901a\u7528\u76ee\u6807\u8ba1\u6570\uff1a\u57fa\u4e8e\u5bc6\u5ea6\u56de\u5f52\u56fe\u8ba1\u6570\u65b9\u6cd5\u7684\u53d1\u5c55</p> <p>\u7b2c\u4e09\u6bb5\uff1a\u901a\u7528\u76ee\u6807\u8ba1\u6570\uff1a\u57fa\u4e8e\u68c0\u6d4b\u8ba1\u6570\u65b9\u6cd5\u53d1\u5c55\uff0c\u53ef\u89e3\u91ca\u6027\u6bd4\u8f83\u597d\uff0c\u8ba1\u6570\u4e0d\u53ea\u662f\u4e3a\u4e86\u8ba1\u6570\uff0c\u4e5f\u8981\u6709\u76ee\u6807\u7684\u7279\u5b9a\u4fe1\u606f\uff1aLocation&amp;size</p>"},{"location":"literature/ObejectCounting/rank2%20GeCo/#_1","title":"\u6458\u8981\uff1a","text":"<p>Objects are localized by matching them to prototypes, which are constructed by unsupervised image-wide object appearance aggregation. </p> <p>Due to potentially diverse object appearances, the existing approaches often lead to overgeneralization and false positive detections. </p> <p>Furthermore, the best-performing methods train object localization by a surrogate loss, that predicts a unit Gaussian at each object center. </p> <p>This loss is sensitive to annotation error, hyperparameters and does not directly optimize the detection task, leading to suboptimal counts. </p> <p>We introduce GeCo, a novel low-shot counter that achieves accurate object detection, segmentation, and count estimation in a unified architecture. </p> <p>GeCo robustly generalizes the prototypes across objects appearances through a novel dense object query formulation.</p> <p>In addition, a novel counting loss is proposed, that directly optimizes the detection task and avoids the issues of the standard surrogate loss.</p> <p>bg\uff1a</p> <ul> <li>\u76ee\u6807\u5916\u89c2\u591a\u6837\u5316\u5bfc\u81f4\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8fc7\u5ea6\u6cdb\u5316\u548c\u8bef\u68c0\u95ee\u9898\u3002</li> <li>\u4ee3\u7406\u635f\u5931\u51fd\u6570\u5bf9\u6807\u6ce8\u8bef\u5dee\u548c\u8d85\u53c2\u6570\u654f\u611f\uff0c\u4e14\u672a\u76f4\u63a5\u4f18\u5316\u68c0\u6d4b\u4efb\u52a1\u3002</li> </ul> <p>GeCo \u7684\u89e3\u51b3\u65b9\u6848\uff1a</p> <ul> <li>\u901a\u8fc7**\u5bc6\u96c6\u76ee\u6807\u67e5\u8be2**\u673a\u5236\uff0c\u5b9e\u73b0\u76ee\u6807\u5916\u89c2\u7684\u9c81\u68d2\u6cdb\u5316\u3002</li> <li>\u63d0\u51fa**\u8ba1\u6570\u635f\u5931\u51fd\u6570**\uff0c\u76f4\u63a5\u4f18\u5316\u68c0\u6d4b\u4efb\u52a1\uff0c\u63d0\u5347\u8ba1\u6570\u7cbe\u5ea6\u3002</li> </ul> <p>GeCo \u7684\u4f18\u52bf\uff1a</p> <ul> <li>\u5728\u7edf\u4e00\u67b6\u6784\u4e2d\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u3001\u5206\u5272\u548c\u8ba1\u6570\u3002</li> <li>\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002</li> </ul> <p></p> <p>Figure 1: DAVE [20] predicts object centers (red dots) biased towards blob-like structures, leading to incorrect partial detections of ants (bottom left), while GeCo(ours) addresses this with the new loss (top left). CDETR [19] fails in densely populated regions (bottom right), while GeCo addresses this with the new dense query formulation by prototype generalization (top right). Exploiting the SAM backbone, GeCo delivers segmentations as well. Exemplars are denoted in blue.\uff08\u84dd\u8272\u6846\u662f\u6b63\u786e\u7684\u6807\u6ce8\u6846\uff09</p> <p>\u89e3\u91ca\uff1a</p> <p>DAVE \u7684\u5c40\u9650\u6027\uff1a</p> <ul> <li>\u76ee\u6807\u4e2d\u5fc3\u9884\u6d4b\u504f\u5411\u6591\u70b9\u72b6\u7ed3\u6784\uff0c\u5bfc\u81f4\u5bf9\u590d\u6742\u76ee\u6807\uff08\u5982\u8682\u8681\uff09\u7684\u90e8\u5206\u68c0\u6d4b\u9519\u8bef\u3002</li> <li>DAVE \u65b9\u6cd5\u5728\u76ee\u6807\u4e2d\u5fc3\u9884\u6d4b\u65f6\u5b58\u5728\u504f\u5dee\uff0c\u503e\u5411\u4e8e\u5c06\u76ee\u6807\u4e2d\u5fc3\u9884\u6d4b\u4e3a\u6591\u70b9\u72b6\u7ed3\u6784\uff0c\u5bfc\u81f4\u5bf9\u8682\u8681\u7b49\u76ee\u6807\u7684\u90e8\u5206\u68c0\u6d4b\u9519\u8bef\u3002GeCo \u901a\u8fc7\u5f15\u5165\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002</li> </ul> <p>CDETR \u7684\u5c40\u9650\u6027\uff1a</p> <ul> <li>\u5728\u76ee\u6807\u5bc6\u96c6\u533a\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u5904\u7406\u9ad8\u5bc6\u5ea6\u76ee\u6807\u3002</li> <li>CDETR \u5728\u5904\u7406\u76ee\u6807\u5bc6\u96c6\u533a\u57df\u65f6\u8868\u73b0\u8f83\u5dee\uff0c\u800c GeCo \u901a\u8fc7\u5f15\u5165\u5bc6\u96c6\u67e5\u8be2\u673a\u5236\u548c\u539f\u578b\u6cdb\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u5bc6\u96c6\u533a\u57df\u4e2d\u7684\u68c0\u6d4b\u6027\u80fd\u3002</li> </ul> <p>GeCo \u7684\u6539\u8fdb\uff1a</p> <ul> <li>\u901a\u8fc7\u65b0\u7684\u635f\u5931\u51fd\u6570\u89e3\u51b3\u4e86\u76ee\u6807\u4e2d\u5fc3\u9884\u6d4b\u504f\u5dee\u95ee\u9898\u3002</li> <li>\u901a\u8fc7\u5bc6\u96c6\u67e5\u8be2\u516c\u5f0f\u548c\u539f\u578b\u6cdb\u5316\u63d0\u5347\u4e86\u5728\u5bc6\u96c6\u533a\u57df\u4e2d\u7684\u68c0\u6d4b\u6027\u80fd\u3002</li> <li>\u57fa\u4e8e SAM \u9aa8\u5e72\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u76ee\u6807\u68c0\u6d4b\u3001\u8ba1\u6570\u548c\u5206\u5272\u7684\u7edf\u4e00\u3002</li> </ul> <p>\u2764\u6838\u5fc3\uff1a\u635f\u5931\u51fd\u6570 \u548c \u5bc6\u96c6\u573a\u666f\u7684\u8ba1\u6570\u8bef\u5dee</p> <p>3 Single-stage low-shot object counting by detection and segmentation</p> <p>\u672c\u6587\u7684\u521b\u65b0\uff1a</p> <p>3.1 DQE</p> <p>3.2 DQD</p> <p>3.3 Detections extraction and refinement</p> <p>3.4  A novel loss for dense detection training</p> <p>\u5176\u5b9e\u6211\u4f1a\u5947\u602a\uff0c\u6d88\u878d\u5b9e\u9a8c\u7684\u90e8\u5206\u548c\u63d0\u51fa\u7684\u4e1c\u897f\u6ca1\u6709\u5341\u5206\u5bf9\u5e94</p> <p></p> <p>\u597d\u597d\u8bfb\u8bfb\u65b9\u6cd5</p> <p></p> <p>\u57fa\u4e8e\u6846\u7684\u8ba1\u6570\u65b9\u6cd5</p> Python<pre><code>outputs, ref_points, centerness, outputs_coord = model(img, bboxes)\n\ndef forward(self, x, bboxes):\n    x.shape torch.Size([1, 3, 1024, 1024])\n    bboxes.shape torch.Size([1, 3, 4])\n</code></pre> <p></p> Python<pre><code>src, src_hq = self.backbone(x) # SAM backbone\n</code></pre> <p></p> <p>\uff1f</p> <p></p> <p>\u6839\u636e\u540e\u9762\u7684\u4ee3\u7801\uff0c\u7528\u7684 src\uff0c\u6240\u4ee5</p> <p></p> <p>\\(H_0=1024\\)</p> <p></p> <p>\\(h=64\uff0cr=16\uff0cd=256\\)</p> <p></p> <p></p> <p>\u7ee7\u7eed\u5f80\u4e0b\u8bfb\uff1a</p> <p></p> <p>0-shot \u60c5\u51b5\u4e0b\uff0c\u539f\u578b p \u7684\u63d0\u53d6</p> <p></p> <p>\u539f\u578b p \u63d0\u53d6\u5b8c\u4ee5\u540e\uff0c\u8981\u8fdb\u884c\u540e\u7eed\u7684\u5904\u7406\uff1a</p> <p>\u539f\u578b\u751f\u6210</p> <ul> <li>\u539f\u578bp\u6765\u6e90\u4e8efew-shot\uff08\u5c0f\u6837\u672c\uff09\u6216zero-shot\uff08\u96f6\u6837\u672c\uff09\u5b66\u4e60\u8bbe\u7f6e\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u5b9e\u73b0\u5728\u5168\u56fe\u8303\u56f4\u5185\u7684\u6cdb\u5316\u5e94\u7528\u3002</li> </ul> <p>\u5bc6\u96c6\u67e5\u8be2\u7f16\u7801\u5668\uff08DQE\uff09</p> <ul> <li>\u57fa\u4e8e\u6cdb\u5316\u7684\u539f\u578b\uff0cDQE\u6a21\u5757\u8d1f\u8d23\u6784\u5efa\u5bc6\u96c6\u7684\u7269\u4f53\u68c0\u6d4b\u67e5\u8be2\u5411\u91cf\uff0c\u4e3a\u540e\u7eed\u68c0\u6d4b\u63d0\u4f9b\u7a7a\u95f4\u5bc6\u96c6\u7684\u7279\u5f81\u8868\u793a\u3002</li> </ul> <p>\u5bc6\u96c6\u67e5\u8be2\u89e3\u7801\u5668\uff08DQD\uff09</p> <ul> <li>DQD\u6a21\u5757\u5c06DQE\u751f\u6210\u7684\u67e5\u8be2\u5411\u91cf\u89e3\u7801\u4e3a\u521d\u6b65\u7684\u5bc6\u96c6\u7269\u4f53\u68c0\u6d4b\u7ed3\u679c\uff0c\u5b9e\u73b0\u4ece\u7279\u5f81\u7a7a\u95f4\u5230\u68c0\u6d4b\u6846\u7684\u6620\u5c04\u3002</li> </ul> <p>\u540e\u5904\u7406\u4f18\u5316</p> <ul> <li>\u901a\u8fc7\u975e\u6781\u5927\u503c\u6291\u5236\u7b49\u540e\u5904\u7406\u7b97\u6cd5\uff0c\u5bf9DQD\u8f93\u51fa\u7684\u5bc6\u96c6\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u7b5b\u9009\u548c\u7cbe\u4fee\uff0c\u6700\u7ec8\u8f93\u51fa\u9ad8\u8d28\u91cf\u7684\u68c0\u6d4b\u6846\u3002</li> </ul> <p>\u8be5\u6846\u67b6\u901a\u8fc7\u7f16\u7801-\u89e3\u7801\u67b6\u6784\u5b9e\u73b0\u4e86\u4ece\u539f\u578b\u6cdb\u5316\u5230\u5bc6\u96c6\u68c0\u6d4b\u7684\u7aef\u5230\u7aef\u5904\u7406\uff0c\u7ed3\u5408\u540e\u5904\u7406\u6b65\u9aa4\u4fdd\u8bc1\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u4e0e\u6548\u7387\u7684\u5e73\u8861</p> <p></p> <p></p> <p>\u8fd9\u4e00\u90e8\u5206\u5bf9\u5e94\u6e90\u7801\u7684</p> <p></p> <p>\u7406\u7531\uff1a</p> <p></p> <p>\u4f1a\u6709\u70b9\u5947\u602a\uff0c\\(P_i = CA(P_{i-1},p,p)\\) \u5bf9\u5e94\u6e90\u7801\u7684\u4ec0\u4e48\u90e8\u5206\uff0c\u6ca1\u627e\u5230\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u3002</p> <p></p> <p>\u627e\u5230\u4e86 3.1 \u516c\u5f0f 1</p> <p></p> <p>3.1 \u516c\u5f0f 2</p> <p></p> <p>\\(f^I = src\\)</p> <p>\u5f00\u59cb 3.2</p> <p></p> <p>\u5728\u7b2c\\(3.1\\)\u8282\u4e2d\uff0c\u5bc6\u96c6\u67e5\u8be2\\(Q\\)\u901a\u8fc7\u5bc6\u96c6\u5bf9\u8c61\u67e5\u8be2\u89e3\u7801\u5668\uff08\\(DQD\\)\uff09\u88ab\u89e3\u7801\u4e3a\u5bf9\u8c61\u68c0\u6d4b\u7ed3\u679c\u3002</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\\(SAM\\)\u4e3b\u5e72\u7f51\u7edc\u5bf9\u56fe\u50cf\u7684\u7a7a\u95f4\u964d\u91c7\u6837\u53ef\u80fd\u5bfc\u81f4\u591a\u4e2a\u5c0f\u5bf9\u8c61\u88ab\u7f16\u7801\u5230\\(Q\\)\u4e2d\u7684\u540c\u4e00\u4e2a\u67e5\u8be2\u4e2d\u3002</p> <p>\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u9996\u5148\u5c06\u5bf9\u8c61\u67e5\u8be2\u5728\u7a7a\u95f4\u4e0a\u89e3\u5305\u4e3a\u9ad8\u5206\u8fa8\u7387\u7684\u5bc6\u96c6\u5bf9\u8c61\u67e5\u8be2\uff0c\u5373\\(Q^{HR} \u2208 R^{H\u00d7W\u00d7d}\\)\uff0c\u5176\u4e2d\\(H = H0/2=1024/2=512\uff0cW = W0/2\\)\uff0c\\(d=256\\)\u662f\u7279\u5f81\u901a\u9053\u6570\u3002</p> <p>\u89e3\u5305\u8fc7\u7a0b\u5305\u62ec\u4e09\u4e2a\u5377\u79ef\u4e0a\u91c7\u6837\u9636\u6bb5\uff0c\u6bcf\u4e2a\u9636\u6bb5\u7531\u4e00\u4e2a\\(3\u00d73\\)\u5377\u79ef\u3001\u4e00\u4e2a\\(Leaky ReLU\\)\u548c\u4e00\u4e2a\\(2\u00d7\u53cc\u7ebf\u6027\u4e0a\u91c7\u6837\\)\u7ec4\u6210\u3002</p> <p></p> <p>\u4e3a\u4e86\u4fbf\u4e8e\u5c0f\u5bf9\u8c61\u7684\u89e3\u5305\uff0c\u7b2c\u4e8c\u9636\u6bb5\u540e\u7684\u7279\u5f81\u4f1a\u4e0e\\(SAM-HQ\\)\u7279\u5f81\\(f^{HQ}\\)\u62fc\u63a5\u540e\u8f93\u5165\u5230\u6700\u7ec8\u9636\u6bb5\u3002</p> <p></p> <p>\u6700\u540e\uff0c\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u7684\u53d8\u6362\u8ba1\u7b97\u5bf9\u8c61\u5f97\u5206\\(y^o \u2208 \\mathbb{R}^{H\u00d7W\u00d71}\\)\uff0c\u5373\\(y^o = \\mathrm{LRelu(W_O \u00b7 Q^{HR})}\\)\uff0c\u5176\u4e2d\\(\\mathrm{W_O}\\)\u662f\u5b66\u4e60\u5230\u7684\u6295\u5f71\u77e9\u9635\uff0c\\(\\mathrm{LReLU(\u00b7)}\\)\u662f\\(\\mathrm{Leaky ReLU}\\)\u3002\u6bcf\u4e2a\u67e5\u8be2\u8fd8\u901a\u8fc7\u4e00\u4e2a\u4e09\u5c42\\(MLP\\)\u89e3\u7801\u4e3a\u5bf9\u8c61\u59ff\u6001\uff0c\u5373\\(y^{BB} = \\sigma(MLP(QHR))\\)\uff0c\u5176\u4e2d\\(\u03c3(\u00b7)\\)\u662fsigmoid\u51fd\u6570\uff0c\\(y^{BB} \u2208 R^{H\u00d7W\u00d74}\\)\u662f\\(tlrb\\)\u683c\u5f0f[26]\u7684\u8fb9\u754c\u6846\u53c2\u6570\u3002</p> <ul> <li>\\(tlrb\\)\u683c\u5f0f \u4ec0\u4e48\u683c\u5f0f\uff1f</li> <li> <p>DQD \u4e0d\u662f\u4e00\u4e2a\u51fd\u6570</p> </li> <li> <p>\u627e\u5230\u5206\u522b\u5bf9\u5e94\u6e90\u7801\u7684\u54ea\u91cc</p> </li> <li> <p>DQD\u5c06\u5bc6\u96c6\u67e5\u8be2Q\u89e3\u7801\u4e3a\u5bf9\u8c61\u68c0\u6d4b\u7ed3\u679c\uff0c\u5e76\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5982\u4f55\u901a\u8fc7\u7a7a\u95f4\u89e3\u5305\u548c\u7279\u5f81\u589e\u5f3a\u6765\u89e3\u51b3\u5c0f\u5bf9\u8c61\u7f16\u7801\u95ee\u9898\uff0c\u6700\u7ec8\u8ba1\u7b97\u51fa\u5bf9\u8c61\u5f97\u5206\u548c\u8fb9\u754c\u6846\u53c2\u6570</p> </li> </ul> <p></p> <p></p> <p>\u8bf4\u660e tlrb \u683c\u5f0f</p> <p>bounding box\uff08\u8fb9\u754c\u6846\uff09\u901a\u5e38\u7528\u4e8e\u6807\u6ce8\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u7269\u4f53\u3002\u5e38\u89c1\u7684\u8fb9\u754c\u6846\u683c\u5f0f\u6709\u591a\u79cd\uff0c\u5305\u62ec <code>xyxy</code>\u3001<code>xywh</code> \u548c <code>tlrb</code> \u7b49\u3002</p> <p><code>tlrb</code> \u683c\u5f0f\u8868\u793a\u7684\u662f\u8fb9\u754c\u6846\u7684\u56db\u4e2a\u8fb9\u7684\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u5177\u4f53\u5982\u4e0b\uff1a</p> <ul> <li><code>t</code> (top): \u8fb9\u754c\u6846\u7684\u4e0a\u8fb9\u7f18\u76f8\u5bf9\u4e8e\u56fe\u50cf\u9876\u90e8\u7684\u8ddd\u79bb\u3002</li> <li><code>l</code> (left): \u8fb9\u754c\u6846\u7684\u5de6\u8fb9\u7f18\u76f8\u5bf9\u4e8e\u56fe\u50cf\u5de6\u4fa7\u7684\u8ddd\u79bb\u3002</li> <li><code>r</code> (right): \u8fb9\u754c\u6846\u7684\u53f3\u8fb9\u7f18\u76f8\u5bf9\u4e8e\u56fe\u50cf\u5de6\u4fa7\u7684\u8ddd\u79bb\u3002</li> <li><code>b</code> (bottom): \u8fb9\u754c\u6846\u7684\u4e0b\u8fb9\u7f18\u76f8\u5bf9\u4e8e\u56fe\u50cf\u9876\u90e8\u7684\u8ddd\u79bb\u3002</li> </ul> <p>\u5728\u4ee3\u7801\u4e2d\uff0c<code>outputs_coord</code> \u662f\u4e00\u4e2a\u5f62\u72b6\u4e3a <code>(bs, w, h, 4)</code> \u7684\u5f20\u91cf\uff0c\u5176\u4e2d <code>bs</code> \u662f\u6279\u6b21\u5927\u5c0f\uff0c<code>w</code> \u548c <code>h</code> \u662f\u7279\u5f81\u56fe\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\uff0c<code>4</code> \u8868\u793a <code>tlrb</code> \u683c\u5f0f\u7684\u56db\u4e2a\u8fb9\u754c\u53c2\u6570\u3002</p> <p>\u4ee5\u4e0b\u662f\u4ee3\u7801\u4e2d\u76f8\u5173\u90e8\u5206\u7684\u89e3\u91ca\uff1a</p> Python<pre><code>outputs_coord = self.bbox_embed(adapted_f).sigmoid().view(bs, w, h, 4).permute(0, 3, 1, 2)\n</code></pre> <ul> <li><code>self.bbox_embed(adapted_f)</code>: \u4f7f\u7528\u4e00\u4e2a\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u5bf9 <code>adapted_f</code> \u8fdb\u884c\u5904\u7406\uff0c\u5f97\u5230\u8fb9\u754c\u6846\u7684\u56db\u4e2a\u8fb9\u754c\u53c2\u6570\u3002</li> <li><code>.sigmoid()</code>: \u4f7f\u7528 sigmoid \u51fd\u6570\u5c06\u8f93\u51fa\u9650\u5236\u5728 <code>[0, 1]</code> \u8303\u56f4\u5185\u3002</li> <li><code>.view(bs, w, h, 4)</code>: \u5c06\u8f93\u51fa\u91cd\u65b0\u8c03\u6574\u5f62\u72b6\u4e3a <code>(bs, w, h, 4)</code>\u3002</li> <li><code>.permute(0, 3, 1, 2)</code>: \u8c03\u6574\u7ef4\u5ea6\u987a\u5e8f\uff0c\u4f7f\u5176\u53d8\u4e3a <code>(bs, 4, w, h)</code>\u3002</li> </ul> <p>\u8fd9\u6837\uff0c<code>outputs_coord</code> \u5c31\u5305\u542b\u4e86\u6bcf\u4e2a\u50cf\u7d20\u70b9\u7684\u8fb9\u754c\u6846\u53c2\u6570\uff0c\u683c\u5f0f\u4e3a <code>tlrb</code>\u3002</p>"},{"location":"literature/ObejectCounting/rank2%20GeCo/#32-2","title":"3.2\u8282 \u7b2c 2 \u6bb5\uff0c\u6700\u540e\u4e00\u53e5","text":""},{"location":"literature/ObejectCounting/rank2%20GeCo/#33","title":"3.3 \u8282","text":"<p>\u6700\u7ec8\u7684\u68c0\u6d4b\u7ed3\u679c\u662f\u4ece \\(y^O\\) \u548c \\(y^{BB}\\) \u4e2d\u63d0\u53d6\u7684\uff0c\u5177\u4f53\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ol> <li>\u5728\u9608\u503c\u5316\u7684 \\(y^O\\) \u4e0a\uff0c\u4f7f\u7528 \\(3\u00d73\\) \u7684\u975e\u6781\u5927\u503c\u6291\u5236\uff08NMS\uff09\u7b97\u6cd5\uff0c\u4ece \\(y^{BB}\\) \u4e2d\u8bfb\u53d6\u5c40\u90e8\u6700\u5927\u503c\u5904\u7684\u8fb9\u754c\u6846\u53c2\u6570\u3002</li> <li>\u5c06\u8fd9\u4e9b\u8fb9\u754c\u6846\u4f5c\u4e3a\u63d0\u793a\uff0c\u8f93\u5165\u5230 \\(SAM\\) \u89e3\u7801\u5668 [12] \u4e2d\uff0c\u5229\u7528\u5df2\u7ecf\u8ba1\u7b97\u597d\u7684\u4e3b\u5e72\u7279\u5f81 \\(f^I\\) \u5bf9\u5176\u8fdb\u884c\u7ec6\u5316\u3002</li> <li>\u901a\u8fc7\u6700\u5c0f-\u6700\u5927\u64cd\u4f5c\u5c06\u8fb9\u754c\u6846\u9002\u914d\u5230\u63a9\u7801\u4e0a\uff0c\u5e76\u6700\u7ec8\u5e94\u7528 \\(IoU = 0.5\\) \u7684\u975e\u6781\u5927\u503c\u6291\u5236\uff0c\u4ee5\u53bb\u9664\u91cd\u590d\u7684\u68c0\u6d4b\u7ed3\u679c\u3002</li> <li>\u8fd9\u4e2a\u8fc7\u7a0b\u6700\u7ec8\u8f93\u51fa\u9884\u6d4b\u7684\u8fb9\u754c\u6846 \\(B^P\\) \u53ca\u5176\u5bf9\u5e94\u7684\u63a9\u7801 \\(M^P\\)\u3002</li> </ol> <p>\u8bfb\u4ec0\u4e48\uff1f</p> <ul> <li>\u8bfb\u8bba\u6587\u4e0e\u4ee3\u7801\u7684\u5bf9\u5e94</li> <li>\u8bfb\u4ee3\u7801\u7684\u8f93\u5165\u3001\u5904\u7406\u3001\u8f93\u51fa</li> </ul> <p>3.4 A novel loss for dense detection training</p> <p></p> <p>GeCotraining\u9700\u8981\u5bf9\u5bc6\u96c6\u76ee\u6807\u6027\u5f97\u5206yO\u548c\u8fb9\u754c\u6846\u53c2\u6570yBB\u8fdb\u884c\u76d1\u7763\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u7f51\u7edc\u5e94\u8be5\u5b66\u4f1a\u9884\u6d4b\u90a3\u4e9b\u53ef\u4ee5\u88ab\u975e\u6781\u5927\u503c\u6291\u5236\uff08NMS\uff09\u53ef\u9760\u68c0\u6d4b\u5230\u7684\u76ee\u6807\u4e0a\u7684\u70b9\uff0c\u540c\u65f6\u8fd9\u4e9b\u70b9\u4e5f\u53ef\u4ee5\u53ef\u9760\u5730\u9884\u6d4b\u51fa\u8fb9\u754c\u6846\u53c2\u6570\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5bc6\u96c6\u76ee\u6807\u68c0\u6d4b\u635f\u5931\u51fd\u6570\uff0c\u65e8\u5728\u8ffd\u6c42\u8fd9\u4e00\u7279\u6027\u3002</p> <p></p> <p></p>"},{"location":"literature/ObejectCounting/rank3%20DAVE/","title":"rank3 DAVE","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 2183 \u4e2a\u5b57  7 \u884c\u4ee3\u7801  6 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 11 \u5206\u949f</p> <p></p> <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u94fe\u63a5</p> <p></p> <p>arxiv\u65e5\u671f\uff1a2024\u5e744\u670825\u65e5</p> <p>\u8bba\u6587\u6b63\u5f0f\u53d1\u8868\u9875\u9762</p> <p>today\uff1a241117</p> <p>\u6807\u9898\uff1aDAVE \u2013 A Detect-and-Verify Paradigm for Low-Shot Counting </p> <ul> <li>\u4e24\u9636\u6bb5\u8ba1\u6570\u65b9\u6cd5\uff1a\u5148\u68c0\u6d4b\u518d\u9a8c\u8bc1</li> <li>\u68c0\u6d4b\uff1a\u9ad8\u53ec\u56de\uff0c\u590d\u7528\u4e86LOCA\u7684\u67b6\u6784</li> <li>\u9a8c\u8bc1\uff1a\u8c31\u805a\u7c7b\u9a8c\u8bc1</li> </ul> <p>\u671f\u520a\uff1aCVPR2024</p> <p>\u5f15\u7528\uff1a</p> TeX<pre><code>@inproceedings{pelhan2024dave,\n  title={DAVE-A Detect-and-Verify Paradigm for Low-Shot Counting},\n  author={Pelhan, Jer and Zavrtanik, Vitjan and Kristan, Matej and others},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={23293--23302},\n  year={2024}\n}\n</code></pre> <p>LOCA  &amp; DAVE</p> <p></p>"},{"location":"literature/ObejectCounting/rank3%20DAVE/#abstract","title":"Abstract","text":"<p>Low-shot counters estimate the number of objects corresponding to a selected category, based on only few or no exemplars annotated in the image. The current state-ofthe-art estimates the total counts as the sum over the object location density map, but does not provide individual object locations and sizes\uff08\u63d0\u51fa\u95ee\u9898\uff09, which are crucial for many applications. This is addressed by detection-based counters, which, however fall behind in the total count accuracy \uff08\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570\u65b9\u6cd5\u53ef\u4ee5\u89e3\u51b3\uff0c\u4f46\u662f\u51c6\u786e\u6027\u4e0d\u9ad8\uff09. Furthermore, both approaches tend to overestimate the counts in the presence of other object classes due to many false positives. \uff08\u8fd9\u4e9b\u65b9\u6cd5\u7684\u5171\u6027\u95ee\u9898\uff1a\u5047\u9633\u6027\u8fc7\u9ad8\uff09</p> <p>\uff08\u672c\u6587\uff09We propose DAVE, a low-shot counter based on a detect-and-verify paradigm, that avoids the aforementioned issues by first generating a high-recall detection set and then verifying the detections to identify and remove the outliers. This jointly increases the recall and precision, leading to accurate counts. </p> <ul> <li>first generating a high-recall detection set and then </li> <li>verifying the detections to identify and remove the outliers. </li> </ul> <p>\uff08\u7ed3\u679c\uff09DAVE outperforms the top densitybased counters by \u223c20% in the total count MAE, it outperforms the most recent detection-based counter by \u223c20% in detection quality and sets a new state-of-the-art in zero-shot as well as text-prompt-based counting. The code and models are available on GitHub.</p>"},{"location":"literature/ObejectCounting/rank3%20DAVE/#introduction-contribution","title":"Introduction-contribution","text":"<ul> <li> <p>We address the aforementioned issues by proposing a low-shot counter DAVE, which combines the benefits of density-based and detection-based formulations, and introduces a novel detect-and-verify paradigm. </p> </li> <li> <p>DAVE tackles the specificity-generalization issues of the existing counters by applying a two-stage pipeline (Figure 1). </p> </li> <li> <p>In the first, detection stage , DAVE leverages density-based estimation to obtain a high-recall set of candidate detections, which however may contain false positives. </p> </li> <li> <p>This is addressed by the second,  verification stage , where outliers are identified and rejected by analyzing the candidate appearances, thus increasing the detection precision. Regions corresponding to the outliers are then removed from the location density map estimated in the first stage, thus improving the densitybased total count estimates as well. </p> </li> <li> <p>In addition, we extend DAVE to text-prompt-based and to a zero-shot scenario, which makes DAVE the first zero-shot as well as textprompt detection-capable counter.</p> </li> </ul> <p>text prompt &amp; zero-shot</p> <p>The primary contribution of the paper is the detect-andverify paradigm for low-shot counting that simultaneously achieves high recall and precision. </p> <p>The proposed architecture is the first to extend to all low-shot counting scenarios. DAVE uniquely merges the benefits of both density and detection-based counting and is the first zero-shot-capable counter with detection output. </p> <p>\uff08\u7ed3\u679c\uff09</p> <ol> <li>DAVE outperforms all stateof-the-art density-based counters on the challenging benchmark [26], including the longstanding winner [6], achieving a relative 20% MAE and 43% RMSE total-count error reductions. </li> <li>It also outperforms all state-of-the-art detectionbased counters on the recent benchmark FSCD147 [22] by \u223c20% in detection metrics, as well as in the total count estimation by 38% MAE. </li> <li>Furthermore, it sets a new state-ofthe-art in text-prompt-based counting. </li> <li>The zero-shot DAVE variant outperforms all zero-shot density-based counters and delivers detection accuracy on-par with the most recent few-shot counters. </li> <li>DAVE thus simultaneously outperforms both density-based and detection-based counters in a range of counting setups.</li> </ol>"},{"location":"literature/ObejectCounting/rank3%20DAVE/#5-conclusion","title":"5. Conclusion","text":"<p>\u7b2c\u4e00\u6bb5</p> <ol> <li>We presented a novel low-shot object counting and detection method DAVE, that narrows the performance gap between density-based and detection-based counters.</li> </ol> <p>DAVE\u662f\u57fa\u4e8e\u68c0\u6d4b\u7684\u8ba1\u6570\u65b9\u6cd5</p> <p>2.DAVE spans the entire low-shot spectrum, also covering text-prompt setups, and is the first method capable of zero-shot detection-based counting. </p> <p>DAVE \u57fa\u4e8e\u6587\u672c &amp; 0-shot</p> <p>3.This is achieved by the novel detect-and-verify paradigm, which increases the recall as well as precision of the detections. \u68c0\u6d4b&amp;\u9a8c\u8bc1\uff0c\u51c6\u786e\u7387 \u53ec\u56de\u7387\u90fd\u5f88\u9ad8</p> <p>\u7b2c\u4e8c\u6bb5</p> <p>Extensive analysis demonstrates that DAVE sets a new state-of-the-art in total count estimation, as well as in detection accuracy on several benchmarks with comparable complexity to related methods, running 110ms/image.</p> <p>In particular, DAVE outperforms the long-standing top low-shot counter [6], as well as the recent detection-based counter [22]. </p> <p>In a zero-shot setup, DAVE outperforms all density-based counters and delivers detections on par with the most recent few-shot counter that requires at least few annotations. </p> <p>DAVE also sets a new state-of-the-art in prompt-based counting.</p> <p>In our future work, we plan to explore interactive counting with the human in the loop and improve detection in extremely dense regions.\u672a\u6765\u7684\u5de5\u4f5c\uff1a\u4eba\u7684\u4ea4\u4e92\u3001\u5bc6\u96c6\u573a\u666f\u7684\u68c0\u6d4b</p>"},{"location":"literature/ObejectCounting/rank3%20DAVE/#1-introduction","title":"1. Introduction","text":"<p>P1 \u4eceLow-shot counting\u5f00\u59cb\u8bf4</p> <p>Low-shot counting considers estimating the number of target objects in an image, based only on a few annotated exemplars (few-shot) or even without providing the exemplars (zero-shot). Owing to the emergence of focused benchmarks [22, 26], there has been a surge in low-shot counting research recently. The current state-of-the-art low-shot counters are all density-based [6, 26, 28, 38]. This means that they estimate the total count by summing over an estimated object presence density map. Only recently, fewshot detection-based methods emerged [22] that estimate the counts as the number of detected objects.</p> <p>P2 \u6bd4\u8f83 Density-based &amp; detection-based \uff1b\u6307\u51fa\u76ee\u524d\u57fa\u4e8e\u5bc6\u5ea6\uff08Density-based \uff09\u7684\u8ba1\u6570\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002\u5e76\u8bf4\u660e\uff1aexplainability is crucial \u672c\u6587\u503e\u5411\u4e8e\u57fa\u4e8e\u68c0\u6d4b\u7684\u65b9\u6cd5</p> <p>Density-based methods substantially outperform the detection-based counters in total count estimation, but they do not provide detailed outputs such as object locations and sizes. The latter are however important in many downstream tasks such as bio-medical analysis [35, 41], where explainability is crucial for human expert verification as well as for subsequent analyses. There is thus a large applicability gap between the density-based and detection-based low-shot counters.</p> <p>P3  \u5171\u540c\u7684\u7f3a\u70b9 \u5047\u9633\u6027\u8fc7\u9ad8</p> <p>Furthermore, both density-based and detection-based counters are prone to failure in scenes with several object types (Figure 1). The reason lies in the specificity  generalization tradeoff. Obtaining a high recall requires generalizing over the potentially diverse appearances of the selected object type instances in the image. However, this also leads to false activations on objects of other categories (false positives), leading to a reduced precision and count overestimation. A possible solution is to train on multiple-class images [22], however, this typically leads to a reduced recall and underestimated counts.</p> <p>P4-P5 \u8d21\u732e</p>"},{"location":"literature/ObejectCounting/rank3%20DAVE/#2-related-work","title":"2. Related Work","text":"<p>\u7b2c\u4e00\u6bb5</p> <p>Object counting emerged as detection-based counting of objects belonging to specific classes, such as vehicles [5], cells [8], people [17], and polyps [41]. To address poor performance in densely populated regions, density-based methods [3, 4, 29\u201331] emerged as an alternative.</p> <p>\u76ee\u6807\u8ba1\u6570\u3001\u5c31\u6709\u68c0\u6d4b\u7684\u65b9\u6cd5\u3001\u7279\u5b9a\u7c7b\u522b\uff1b\u8ba1\u6570\u51c6\u786e\u6027\uff0c\u57fa\u4e8e\u5bc6\u5ea6\u56de\u5f52\u56fe\u7684\u8ba1\u6570\u65b9\u6cd5</p> <p>\u7b2c\u4e8c\u6bb5</p> <p>All these methods rely on the availability of large datasets to train category-specific models, which, however are not available in many applications.\u6570\u636e\u96c6</p> <p>\u7b2c\u4e09\u6bb5</p> <p>Class-agnostic approaches addressed this issue by test-time adaptation to various object categories with minimal supervision.</p> <p>\u7c7b\u65e0\u5173\u8ba1\u6570\u65b9\u6cd5\u3001\u6700\u5c11\u7684\u76d1\u7763\u4fe1\u53f7\u3001\u6d4b\u8bd5\u9636\u6bb5\u8c03\u6574</p> <p>Early representatives [19] and [37] proposed predicting the density map by applying a siamese matching network \u5b6a\u751f\u5339\u914d\u7f51\u7edc to compare image and exemplar features. \u6bd4\u8f83\u56fe\u50cf&amp;\u6837\u4f8b\u6846\u7279\u5f81</p> <ul> <li>Recently, the FSC147 dataset [26] was proposed to encourage the development of few-shot counting methods. Famnet [26] proposed a test-time adaptation of the backbone to improve density map estimation. FSC147\u6570\u636e\u96c6\u3001 Famnet  || FSC147\u6570\u636e\u96c6[ 26 ]\u7684\u63d0\u51fa\u9f13\u52b1\u4e86\u5c0f\u6837\u672c\u8ba1\u6570\u65b9\u6cd5\u7684\u53d1\u5c55\u3002Famnet [ 26 ]\u63d0\u51fa\u4e86\u4e00\u79cd\u9aa8\u5e72\u6d4b\u8bd5\u65f6\u95f4\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u5bc6\u5ea6\u56fe\u4f30\u8ba1\u3002</li> <li>BMNet+ [28] improved localization by jointly learning representation and a non-linear similarity metric. A self-attention mechanism was applied to reduce the intra-class appearance variability. BMNet + [ 28 ]\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u8868\u793a\u548c\u975e\u7ebf\u6027\u76f8\u4f3c\u6027\u5ea6\u91cf\u6765\u6539\u8fdb\u5b9a\u4f4d\u3002\u5e94\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6765\u51cf\u5c11\u7c7b\u5185\u5916\u89c2\u53d8\u5f02\u6027\u3002</li> <li>SAFECount [38] introduced a feature enhancement module, improving generalization capabilities. SAFECount [ 38 ]\u5f15\u5165\u4e86\u7279\u5f81\u589e\u5f3a\u6a21\u5757\uff0c\u63d0\u9ad8\u4e86\u6cdb\u5316\u80fd\u529b\u3002</li> <li>CounTR [16] used a vision transformer [7] for image feature extraction and a convolutional encoder to extract exemplar features. An interaction module based on cross-attention was proposed to fuse both, image and exemplar features. Coun TR [ 16 ]\u4f7f\u7528\u89c6\u89c9\u8f6c\u6362\u5668[ 7 ]\u8fdb\u884c\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\uff0c\u4f7f\u7528\u5377\u79ef\u7f16\u7801\u5668\u63d0\u53d6\u6837\u672c\u7279\u5f81\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u4ea4\u4e92\u6a21\u5757\u6765\u878d\u5408\u56fe\u50cf\u7279\u5f81\u548c\u6837\u672c\u7279\u5f81\u3002</li> <li>LOCA [6] proposed an object prototype extraction module, which combined exemplar appearance and shape with an iterative adaptation.LOCA [ 6 ]\u63d0\u51fa\u4e86\u4e00\u4e2a\u5bf9\u8c61\u539f\u578b\u63d0\u53d6\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u5c06\u6837\u672c\u5916\u89c2\u548c\u5f62\u72b6\u4e0e\u8fed\u4ee3\u81ea\u9002\u5e94\u76f8\u7ed3\u5408\u3002</li> </ul> <p>Note</p> <p>Summary   5\u4e2a\u6a21\u578b   \u7c7b\u522b\u4e0d\u654f\u611f\u8ba1\u6570\u65b9\u6cd5\u3001\u6d4b\u8bd5\u9636\u6bb5\u81ea\u9002\u5e94\u3001\u5c11\u91cf\u76d1\u7763\u4fe1\u53f7\uff08\u4f60\u53bb\u770bGeCo\uff1a\u76f8\u5173\u5de5\u4f5c\uff0c\u4e5f\u662f\u8fd95\u4e2a\u6a21\u578b\u7684 \u7814\u7a76\u73b0\u72b6</p> <ul> <li>FamNet  </li> <li>BMNet+  </li> <li>SAFECount   </li> <li>CounTR  </li> <li>LOCA  </li> </ul> <p>\u7b2c\u56db\u6bb5</p> <p>All few-shot counting methods require few annotated exemplars to specify the object class. With the recent development of large language models (e.g. [23]) text-prompt based counting methods emerged.</p> <p>\u8f93\u5165\u4fe1\u53f7\u7684\u53d1\u5c55\uff1a\u4ece\u524d\u662f\u6807\u6ce8\u7684\u6837\u4f8b\u6846\u6307\u5b9a\u7c7b\u522b $\\rightarrow $  \u73b0\u5728\u57fa\u4e8e\u6587\u672c\u7684\u8ba1\u6570\u65b9\u6cd5\uff08\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff09</p> <p>Instead of specifying exemplars by bounding box annotations, these methods use text descriptions of the target object class. </p> <p>\u2764\ufe0f\u8fd9\u6bb5\u7684\u6587\u732e\u6982\u8ff0\uff1a\u5173\u4e8e\u7684\u662f\u4f7f\u7528\u6587\u672c\u63cf\u8ff0\u6307\u5b9a\u76ee\u6807\u7c7b\u522b </p> <p>ZeroCLIP [36] proposed text-based construction of prototypes, which are used to select relevant image patches acting as exemplars for counting.</p> <p>ZeroCLIP [ 36 ]\u63d0\u51fa\u4e86\u57fa\u4e8e\u6587\u672c\u7684\u539f\u578b\u6784\u9020\uff0c\u7528\u4e8e\u9009\u62e9\u76f8\u5173\u7684\u56fe\u50cf\u5757\u4f5c\u4e3a\u8ba1\u6570\u7684\u8303\u4f8b\u3002</p> <p>CLIPCount [15] leveraged CLIP [23] for image-text alignment and introduced patch-text contrastive loss for learning the visual representations used for density prediction. </p> <p>CLIPCount [ 15 ]\u5229\u7528CLIP [ 23 ]\u8fdb\u884c\u56fe\u50cf-\u6587\u672c\u5bf9\u9f50\uff0c\u5e76\u5f15\u5165\u5757-\u6587\u672c\u5bf9\u6bd4\u635f\u5931\u6765\u5b66\u4e60\u7528\u4e8e\u5bc6\u5ea6\u9884\u6d4b\u7684\u89c6\u89c9\u8868\u793a\u3002</p> <p>Several works [13, 25] address the extreme case in which no exemplars are provided and the task is to count the majority class objects (i.e., zero-shot counting).</p> <p>\u4e00\u4e9b\u5de5\u4f5c[ 13\u300125]\u89e3\u51b3\u4e86\u6ca1\u6709\u63d0\u4f9b\u6837\u4f8b\u7684\u6781\u7aef\u60c5\u51b5\uff0c\u5176\u4efb\u52a1\u662f\u5bf9\u591a\u6570\u7c7b\u5bf9\u8c61\u8fdb\u884c\u8ba1\u6570(\u5373\u96f6\u6837\u672c\u8ba1\u6570)</p> <p>Note</p> <p>summary  1. ZeroCLIP  2. CLIPCount   </p> <p>Info</p> <p>DAVE  \u2460\u57fa\u4e8e\u68c0\u6d4b   \u2461text-prompt  \u2462zero-shot</p> <p>\u7b2c\u4e94\u6bb5</p> <p>With minimal architectural changes, the recent few-shot methods [6, 16] also demonstrated a remarkable zero-shot counting performance. A common drawback of densitybased counters is that they do not provide object locations.</p> <p>\u5728\u7ed3\u6784\u53d8\u5316\u5f88\u5c0f\u7684\u60c5\u51b5\u4e0b\uff0c\u6700\u8fd1\u7684\u5c11\u6837\u672c\u65b9\u6cd5[ 6\u300116 ]\u4e5f\u8868\u73b0\u51fa\u4e86\u51fa\u8272\u7684\u96f6\u6837\u672c\u8ba1\u6570\u6027\u80fd\u3002\u57fa\u4e8e\u5bc6\u5ea6\u7684\u8ba1\u6570\u5668\u7684\u4e00\u4e2a\u5171\u540c\u7f3a\u70b9\u662f\u5b83\u4eec\u4e0d\u63d0\u4f9b\u5bf9\u8c61\u4f4d\u7f6e\u3002</p> <p></p> <p></p> <p>[6]  LOCA  [16]CounTR</p> <p>\u5f00\u59cb\u5f15\u51fa\u53ef\u4ee5\u63d0\u4f9b\u5b9a\u4f4d\u7684\u8ba1\u6570 \u65b9\u6cd5</p> <p>\u7b2c\u516d\u6bb5</p> <p>To address the aforementioned limitation of density based counters, the first few shot counting and detection method [22] has been recently proposed by extending a transformer-based object detector [2] with an ability to detect objects specified by exemplars.</p> <p>\u6587\u732e22 \u7b2c\u4e00\u4e2a\u57fa\u4e8e\u68c0\u6d4b\u7684FSC\u65b9\u6cd5 </p> <p></p> <p>However, the detection based counter falls far behind in total count estimation compared with the best density-based counters.</p> <p>\u57fa\u4e8e\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u6700\u5927\u7684\u5f0a\u7aef\uff1a\u8ba1\u6570\u51c6\u786e\u6027\u4e0d\u9ad8(241117)</p>"},{"location":"literature/ObejectCounting/rank3%20DAVE/#3-counting-by-detection-and-verification","title":"3. Counting by detection and verification","text":"<p>todo</p>"},{"location":"literature/ObejectCounting/rank4%20CACViT/","title":"rank4 CACViT","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 2544 \u4e2a\u5b57  16 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 13 \u5206\u949f</p> <p></p> <p>Info</p> <p>\u672c\u6587\u6982\u62ec  1.\u57fa\u4e8eViT \u540c\u65f6\u8fdb\u884c\u63d0\u53d6\u548c\u5339\u914d\uff0cdecoupled view  \uff08\u89e3\u51b3\u4e86\u4ee5\u524d\uff1a\u5148\u63d0\u53d6\u540e\u5339\u914d\u7684\u6a21\u5f0f\uff09  2.\u7eb5\u6a2a\u6bd4\u611f\u77e5\u7684\u5c3a\u5ea6\u5d4c\u5165 \u548c \u6570\u91cf\u7ea7\u5d4c\u5165  3.\u6570\u636e\u96c6\uff1aFSC147 &amp; CARPK  </p> <p>\u5f15\u7528\uff1a</p> Text Only<pre><code>@inproceedings{wang2024vision,\n  title={Vision transformer off-the-shelf: A surprising baseline for few-shot class-agnostic counting},\n  author={Wang, Zhicheng and Xiao, Liwen and Cao, Zhiguo and Lu, Hao},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  year={2024}\n}\n</code></pre> <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u94fe\u63a5</p> <p>arxiv\u65e5\u671f\uff1a2024\u5e743\u67084\u65e5</p> <p>today\uff1a 241117</p> <p>\u6b63\u5f0f\u53d1\u8868\u9875\u9762 \u63d0\u4f9b\u89c6\u9891\u8bb2\u89e3</p> <p></p> <p>\u4f5c\u8005\uff1a\u534e\u4e2d\u79d1\u6280\u5927\u5b66</p> <p></p> <p>\u6807\u9898\uff1aVision Transformer Off-the-Shelf: A Surprising Baseline for Few-Shot Class-Agnostic Counting</p> <p>\u57fa\u4e8e\u73b0\u6709\u7684ViT\u67b6\u6784\uff1aFSC\u8ba1\u6570\u65b9\u6cd5</p> <p></p> <p>\u4f5c\u8005</p> <ul> <li>\u6559\u80b2\u90e8\u56fe\u50cf\u5904\u7406\u548c\u667a\u80fd\u63a7\u5236\u91cd\u70b9\u5b9e\u9a8c\u5ba4</li> <li>\u534e\u4e2d\u79d1\u6280\u5927\u5b66 \u4eba\u5de5\u667a\u80fd\u4e0e\u81ea\u52a8\u5316\u5b66\u9662</li> </ul>"},{"location":"literature/ObejectCounting/rank4%20CACViT/#abstract","title":"Abstract","text":"<p>Class-agnostic counting (CAC) aims to count objects of interest from a query image given few exemplars. </p> <p>\u95ee\u9898\u5b9a\u4e49\uff1aFSC few shot counting</p> <p>CAC\uff1aclass-agnostic counting</p> <p>\u5408\u8d77\u6765\u81ea\u5df1\u9020\u4e2a\u5c31\u662f\uff1aFSCAC few-shot class-agnostic counting\u5c0f\u6837\u672c\u7c7b\u65e0\u5173\u8ba1\u6570\u65b9\u6cd5\u7814\u7a76</p> <p>This task is typically addressed by extracting the features of query image and exemplars respectively and then matching their feature similarity, leading to an extract-then-match paradigm.</p> <p>\u56fe\u7247\u7279\u5f81  \u548c \u6837\u4f8b\u6846\u7279\u5f81  \u5206\u522b\u63d0\u53d6 \u7136\u540e\u8fdb\u884c\u5339\u914d</p> <p>\u6307\u51fa\u7814\u7a76\u73b0\u72b6\uff1a\u5148\u63d0\u53d6\u518d\u5339\u914d  extract-then-match paradigm</p> <p>In this work, we show that CAC can be simplified in an extract-and-match manner, particularly using a vision transformer (ViT) where feature extraction and similarity matching are executed simultaneously within the self-attention. </p> <p>ViT\u4e2d\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548c\u5339\u914d</p> <p>We reveal the rationale of such simplification from a decoupled view of the self-attention. The resulting model, termed CACViT, simplifies the CAC pipeline into a single pretrained plain ViT. </p> <p>Further, to compensate the loss of the scale and the order-of-magnitude information due to resizing and normalization in plain ViT, we present two effective strategies for scale and magnitude embedding.</p> <p>\u4e3a\u4e86\u5f25\u8865\u7f3a\u5931\u7684\u4fe1\u606f\uff1a\u5c3a\u5ea6\u5d4c\u5165 &amp; \u6570\u91cf\u7ea7\u5d4c\u5165</p> <p>Extensive experiments on the FSC147 and the CARPK datasets show that CACViT significantly outperforms state-of-the-art CAC approaches in both effectiveness (23.60% error reduction) and generalization, which suggests CACViT provides a concise and strong baseline for CAC. Code will be available.</p> <p>\u672c\u6587\u7684\u6570\u636e\u96c6\uff1a the FSC147 and the CARPK datasets</p> <p>Note</p> <p>\u672c\u6587\u7684\u521b\u65b0\u70b9\uff1a1+2</p> <p>1:CACViT:\u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u51fa\u548c\u5339\u914d\uff0c\u5229\u7528ViT\u67b6\u6784\uff0cdecoupled view</p> <p>2:\u5c3a\u5ea6\u5d4c\u5165\u3001\u6570\u91cf\u7ea7\u5d4c\u5165</p>"},{"location":"literature/ObejectCounting/rank4%20CACViT/#introduction-contribution","title":"Introduction contribution","text":"<p>In a nutshell, our contributions are three-fold: </p> <ul> <li>A novel extract-and-match paradigm: we show that simultaneous feature extraction and matching can be made possible in CAC; \u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548c\u5339\u914d</li> <li>CACViT: a simple and strong ViT-based baseline, sets the new state-of-the-art on the FSC-147 benchmark; \u57fa\u4e8eViT</li> <li>We introduce two effective strategies to embed scale, aspect ratio, and order of magnitude information tailored to CACViT. \u57fa\u4e8e\u7eb5\u6a2a\u6bd4\u611f\u77e5\u7684\u5c3a\u5ea6\u5d4c\u5165\u3001\u6570\u91cf\u7ea7\u5d4c\u5165</li> </ul>"},{"location":"literature/ObejectCounting/rank4%20CACViT/#conclusions","title":"Conclusions","text":"<p>In this work, we propose a simple yet efficient ViT-based model CACViT for CAC. \u57fa\u4e8eViT\u67b6\u6784\uff0c\u89e3\u51b3CAC\u95ee\u9898\uff0c\u53d6\u540d\uff1aCACViT</p> <p>Specifically, we show that the ViT is naturally suitable for the CAC task from a decoupled view. \u89e3\u8026\u89c6\u89d2\u4e0b\uff0c\u89e3\u8bfbViT</p> <p>And we propose a ViT-based extract-and-match paradigm for CAC. \u57fa\u4e8eViT\u540c\u65f6\u8fdb\u884c\u63d0\u53d6&amp;\u5339\u914d</p> <p>Then we introduce aspect-ratio-aware scale embedding and magnitude embedding to compensate for the information loss. \u7eb5\u6a2a\u6bd4\u611f\u77e5\u7684\u5c3a\u5ea6\u5d4c\u5165\u548c\u6570\u91cf\u7ea7\u5d4c\u5165\uff0c\u5f25\u8865\u4e22\u5931\u7684\u4fe1\u606f</p> <p>Our CACViT achieves stat-of-the-art results on FSC147, and we also verify the generality on CARPK.</p> <p>\u6570\u636e\u96c6\uff1aFSC147&amp;CARPK</p>"},{"location":"literature/ObejectCounting/rank4%20CACViT/#introduction","title":"Introduction","text":"<p>P1 \u76ee\u6807\u8ba1\u6570\uff0c\u6700\u5f00\u59cb\u9488\u5bf9\u7279\u5b9a\u9886\u57df</p> <p>Object counting aims to estimate the number of objects from a query image. Most prior object counting approaches target a specific domain, e.g., crowd (Zhang et al. 2015; Shu et al. 2022; Zou et al. 2021), plant (Lu et al. 2017; Madec et al. 2019), and car (Onoro-Rubio and L \u0301 opez-Sastre 2016). </p> <p>They often require numerous class-specific training data to learn a good model (Wang et al. 2020). </p> <p>\u8fc7\u6e21\u5230\u7c7b\u65e0\u5173\u8ba1\u6570\u65b9\u6cd5</p> <p>In contrast, Class-Agnostic Counting (CAC), whose goal is to estimate the counting value of arbitrary categories given only few exemplars \u7ed9\u5b9a\u793a\u4f8b\u6846\u8ba1\u6570\u4efb\u610f\u7c7b\u522b, has recently received much attention due to its potential to generalize to unseen scenes and reduced reliance on class-specific training data (Lu, Xie, and Zisserman 2019; Ranjan et al. 2021; Shi et al. 2022; Liu et al. 2022).</p> <p>P2 \u8bf4\u7684\u662f  extract-then-match paradigm</p> <p>CAC is first introduced by Lu et al. (Lu, Xie, and Zisserman 2019), which is by default formulated as a template matching problem, leading to an extract-then-match paradigm. </p> <p>CAC\u4efb\u52a1\u6700\u65e9\u5f15\u5165\uff1a Lu et al. (Lu, Xie, and Zisserman 2019)\uff0c\u5b9a\u4e49\u4e3a\u6a21\u677f\u5339\u914d\u95ee\u9898\uff0c\u5148\u63d0\u53d6\u540e\u5339\u914d\u7684\u6a21\u5f0f</p> <p>Previous models (Ranjan et al. 2021; Shi et al. 2022; Lin et al. 2022) use shared CNN for query images and exemplars feature extraction, as the bottom-up feature extraction approach of the CNN can adapt to images of entirely different sizes. CNN\u81ea\u5e95\u5411\u4e0a\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u5f0f\u53ef\u4ee5\u9002\u5e94\u5927\u5c0f\u5b8c\u5168\u4e0d\u540c\u7684\u56fe\u50cf\u3002</p> <p>\uff08CounTR\uff09  Witnessing the ability of marking the responses on the attention map by cross-attention mechanism, some models such as CounTR (Liu et al. 2022) employs cross-attention to match the features of query image and exemplars.However, in CounTR the query feature and exemplar feature are embedded separately by a ViT and a CNN, and the matching part is achieved by an extra cross-attention stage. This strategy introduces much redundancy and task-specific designs, which is not in line with the trend of task-agnostic foundation models.</p> <p>\u4e00\u4e9b\u6a21\u578b\u5982CounTR ( Liu et al 2022)\u7b49\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5728\u6ce8\u610f\u529b\u56fe\u4e0a\u6807\u8bb0\u54cd\u5e94\u7684\u80fd\u529b\u6765\u5339\u914d\u67e5\u8be2\u56fe\u50cf\u548c\u793a\u4f8b\u7684\u7279\u5f81\u3002\u7136\u800c\uff0c\u5728CounTR\u4e2d\uff0c\u67e5\u8be2\u7279\u5f81\u548c\u6837\u4f8b\u7279\u5f81\u5206\u522b\u7531\u4e00\u4e2aViT\u548c\u4e00\u4e2aCNN\u5d4c\u5165\uff0c\u5339\u914d\u90e8\u5206\u7531\u989d\u5916\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u9636\u6bb5\u5b9e\u73b0\u3002\u8fd9\u79cd\u7b56\u7565\u5f15\u5165\u4e86\u5927\u91cf\u7684\u5197\u4f59\u548c\u4efb\u52a1\u76f8\u5173\u7684\u8bbe\u8ba1\uff0c\u4e0d\u7b26\u5408\u4efb\u52a1\u65e0\u5173\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u8d8b\u52bf\u3002</p> <p>P3 ViT\u7684\u53d1\u5c55</p> <p>Recently, the computer vision community has witnessed great success with plain ViT in large multi-modal architectures (Touvron et al. 2023; Yu et al. 2022). Soon much work emerges for better adaptation of ViT on downstream vision tasks, such as object detection (Li et al. 2022; Lin et al. 2023), pose estimation (Xu et al. 2022, 2023) and image matting (Yao et al. 2023). As a template matching task, CAC is essentially suitable for using ViT with its attention mechanism; however, there is little focus on the adaptation of ViT on CAC task.</p> <p>P4 \u5f15\u51faViT\u548cCAC\u7684\u5173\u7cfb</p> <p>In this work, we share insights that the attention mechanism in plain ViT has the ability to extract the features for both the query image and the exemplars and perform feature matching for them. By grouping the query and exemplar tokens into concatenation and feeding them to a plain ViT, the self-attention process in ViT can be divide into two groups of self-attention, and two groups of cross-attention. The former self-attentions are to extract features for the query image and the exemplars, while the latter cross-attentions contains the matching process between the query image and the exemplars. Therefore, without multiple feature extractors or extra post-matching, it produces a novel extract-andmatch paradigm. Compared with prior arts, the extra attention from the query feature to the exemplars would further provide additional class information to the query image in this paradigm, enabling better perception of objects.Based on this idea, we propose a framework for CAC that mainly contains a single pretrained ViT, which verifies the feasibility of plain ViT for CAC task.</p> <p>P5</p> <p>For better adaptation of ViT to the specific CAC task, we introduce more insights closely related to CAC task in our model design. Specifically, we observe that certain restrictions or functions such as resizing and softmax normalization within this architecture can result in the loss of scale information and the order of magnitude of counting values. First, the exemplars must be resized to fit the ViT input, which introduces size ambiguity during matching. Prior CNN-based models (Shi et al. 2022) attempt to compensate for the scale information with scale embedding for exemplars; however, they neglect the information of aspect ratios, which is crucial for classes with abnormal ratios. This is largely overlooked in the existing literature. Second, the attention map with softmax function can represent the relative distribution of objects in the query image and therefore weakens the awareness of the model to the number of objects. We address this by restoring the magnitude order in the normalized attention map. Both the proposed scale embedding and magnitude embedding are easy to implement. By infusing the scale and the magnitude information into the plain ViT architecture, we acquire a surprisingly simple yet highly effective ViT baseline for CAC. The resulting model, termed CACViT, fully leverages the self-attention mechanism in ViT while also being tuned to mitigate the defects of this architecture in this task.</p> <p>P6</p> <p>Experiments on the public benchmark FSC147 (Ranjan et al. 2021) show that CACVit outperforms the previous best approaches by large margins, with relative error reductions of 19.04% and 23.60% on the validation and test sets, respectively, in terms of mean absolute error. Its cross-dataset generalization is also demonstrated on a car counting dataset CARPK (Hsieh, Lin, and Hsu 2017). We also provide extensive ablation studies to justify our propositions.</p> <p>P7 \u8d21\u732e</p>"},{"location":"literature/ObejectCounting/rank4%20CACViT/#related-work","title":"Related Work","text":"<p>P1 </p> <p>The task of CAC is composed of two main components: feature extraction and feature matching. We first review each component in previous counting models, then discuss jointly feature extraction and matching in the other fields.</p> <p>Note</p> <p>Feature Extraction in Class-Agnostic Counting. CAC \u7684\u7279\u5f81\u63d0\u53d6 Feature Matching in Class-Agnostic Counting CAC\u4e2d\u7684\u7279\u5f81\u5339\u914d\u95ee\u9898 Jointly Feature Extraction and Matching. \u540c\u65f6\u8fdb\u884c\u63d0\u53d6 &amp; \u5339\u914d </p> <p>P2 CAC\u95ee\u9898\u4e2d\u7684\u7279\u5f81\u63d0\u53d6</p> <p>Feature Extraction in Class-Agnostic Counting.</p> <p>The investigation of feature extraction in counting first began with class-specific counting (Abousamra et al. 2021; Cao et al. 2018; He et al. 2021; Idrees et al. 2018; Laradji et al. 2018; Cheng et al. 2022). In class-specific counting, most works are designed to address the challenges posed by quantity variance and scale variance. (\u7279\u5b9a\u7c7b\u522b)</p> <p>Abousamra et al. 2021; </p> <p></p> <p>Cao et al. 2018;</p> <p></p> <p>He et al. 2021;</p> <p></p> <p>Idrees et al. 2018; </p> <p></p> <p>Laradji et al. 2018;</p> <p></p> <p>Cheng et al. 2022</p> <p></p> <p>\u90fd\u662f\u4e00\u4e9b \u6211\u6ca1\u4e86\u89e3\u8fc7\u7684\u53c2\u8003\u6587\u732e\uff0c\u7b11)</p> <p>For class-agnostic counting\uff08\u7c7b\u65e0\u5173\uff09, the core of feature extraction include unified matching space apart from challenges as above. To obtain a unified matching space, most previous work (Ranjan et al. 2021; Shi et al. 2022; You et al. 2023) uses the shared CNN-based feature extractors for query images and exemplars. CounTR (Liu et al. 2022), which first introduces the ViT for feature extraction in CAC, uses different feature extractors for the query images (a ViT) and exemplars (a CNN). Hence, a two-stage training scheme is used for unifying the feature space.</p> <p>Ranjan et al. 2021;  FamNet FSC147\u6570\u636e\u96c6\u3001CAC\u4efb\u52a1\u7684\u7b2c\u4e00\u7bc7\u561b\uff1fanyway\u7ecf\u5178\u6587\u732e\u4e86\u5c5e\u4e8e</p> <p></p> <p>Shi et al. 2022;   BMNet</p> <p></p> <p>You et al. 2023</p> <p></p> <p>CounTR (Liu et al. 2022) \u8001\u719f\u4eba\u60f9\u5012\u662f</p> <p></p> <p>P3 CAC\u95ee\u9898\u4e2d\u7684\u7279\u5f81\u5339\u914d</p> <p>Feature Matching in Class-Agnostic Counting.</p> <p>Compared with feature extraction, matching strategies in CAC have garnered more attention. \uff08\u7279\u5f81\u5339\u914d\u5b9e\u9645\u4e0a\u6709\u66f4\u591a\u7684\u5173\u6ce8\u5ea6\uff09</p> <p>The key points of the matching include the following two:  \u5339\u914d\u95ee\u9898\u4e2d\u4e3b\u8981\u5173\u6ce8\u7684\u4e24\u4e2a\u65b9\u9762</p> <p>1) robustness to appearance variance, and  \u5bf9\u4e8e\u5916\u89c2\u7684\u591a\u53d8 \u4f9d\u7136\u4fdd\u6301\u7a33\u5065\u6027 2) ability to characterize quantity levels.  \u5bf9\u4e8e\u6570\u91cf\u53d8\u5316\u7684\u7a33\u5065\u6027</p> <p>In the early attempt, naive inner product (Ranjan et al. 2021; Yang et al. 2021) is used, which is not robust to the appearance variance of objects to be counted. </p> <p>Ranjan et al. 2021  FamNet </p> <p></p> <p>Yang et al. 2021  </p> <p> </p> <p>Shi et al. (Shi et al. 2022) developed a bilinear matching network (BMNet) that expands the fixed inner product to a learnable bilinear similarity metric, which improves the robustness compared with the inner product. </p> <p>The recent ViT-based model CounTR (Liu et al. 2022) uses cross-attention for matching, which seems a natural choice for a transformer-based solution at first glance. However, we show that, in our plain ViT model CACViT, we can perform feature matching at the same time of extracting features by self-attention.</p> <p>CounTR</p> <p>CACViT</p> <p>P4</p> <p>Jointly Feature Extraction and Matching. </p> <p>For template matching and multi-modal tasks, feature extraction and matching are two main components. In tracking and detection tasks, MixFormer network (Chen et al. 2022) and FCT network (Han et al. 2022) were proposed to enhance the correlation between the target object and the image, thereby obtaining enhanced features for localization head.</p> <p>In multimodal tasks, ViLT (Kim, Son, and Kim 2021) strengthens the interaction between text and image during the feature extraction stage, resulting in efficient multi-modal features that benefit the performance of downstream tasks.  \u591a\u6a21\u6001</p> <p>To the best of our knowledge, we are the first to simultaneously consider feature extraction and matching in CAC, and we provide a decoupled analysis of the feasibility of this paradigm in the CAC, thereby streamlining the workflow of CAC task.\u6211\u4eec\u662f\u7b2c\u4e00\u4e2a\u540c\u65f6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6&amp;\u5339\u914d\u7684|241117</p>"},{"location":"literature/ObejectCounting/rank4%20CACViT/#class-agnostic-counting-vision-transformer","title":"Class-Agnostic Counting Vision Transformer","text":"<p>Todo</p>"},{"location":"literature/ObejectCounting/rank5%20SSD/","title":"rank5 SSD","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 114 \u4e2a\u5b57  5 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p></p> <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u94fe\u63a5</p> <p>arxiv\u65e5\u671f\uff1a2024\u5e745\u670820\u65e5</p> <p></p> <p>\u4f5c\u8005\uff1a\u5357\u4eac\u7406\u5de5\u5927\u5b66\u4eba\u5de5\u667a\u80fd\u5b66\u9662</p> <p>\u5f15\u7528</p> Text Only<pre><code>@inproceedings{ijcai2024p167,\ntitle = {Learning Spatial Similarity Distribution for Few-shot Object Counting},\nauthor = {Xu, Yuanwu and Song, Feifan and Zhang, Haofeng},\nbooktitle = {Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, {IJCAI-24}},\npublisher = {International Joint Conferences on Artificial Intelligence Organization},\npages = {1507--1515},\nyear = {2024},\ndoi = {10.24963/ijcai.2024/167},\nurl = {https://doi.org/10.24963/ijcai.2024/167},\n}\n</code></pre> <p>\ud83d\udcdd \u5b66\u4e60\u5c11\u6837\u672c\u76ee\u6807\u8ba1\u6570\u7684\u7a7a\u95f4\u76f8\u4f3c\u5ea6\u5206\u5e03.</p> <p></p> <p>\u4e2d\u6587\u89e3\u91ca\uff1a</p> <p></p> <p></p> <p>\u4e0d\u662f\u6211\u60f3\u4ed4\u7ec6\u7814\u7a76\u7684\u65b9\u5411\uff0cpass</p>"},{"location":"literature/ObejectCounting/rank6%20LOCA/","title":"rank6 LOCA","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u94fe\u63a5</p> <p>\u5f15\u7528\uff1a</p> Text Only<pre><code>@InProceedings{Dukic_2023_ICCV,\n    author    = {{\\DJ}uki\\'c, Nikola and Luke\\v{z}i\\v{c}, Alan and Zavrtanik, Vitjan and Kristan, Matej},\n    title     = {A Low-Shot Object Counting Network With Iterative Prototype Adaptation},\n    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},\n    month     = {October},\n    year      = {2023},\n    pages     = {18872-18881}\n}\n</code></pre> <p>arxiv\u65e5\u671f\uff1a2023\u5e749\u670828\u65e5</p> <p>\u6b63\u5f0f\u53d1\u8868\u9875\u9762 ICCV2023</p> <p>today 241117</p> <p></p> <p>\u6807\u9898\uff1aA Low-Shot Object Counting Network With Iterative Prototype Adaptation</p> <p>\u5c0f\u6837\u672c\u8ba1\u6570\u795e\u7ecf\u7f51\u7edc\uff1a\u8fed\u4ee3\u539f\u578b\u9002\u5e94\u6a21\u5757</p> <p>\u2764\ufe0f\uff1a\u4e22\u5931\u5f62\u72b6\u4fe1\u606f\uff08size or aspect\uff09\uff0c\u56e0\u6b64\u672c\u6587\u63d0\u51fa\u4e86OPE\uff08\u76ee\u6807\u539f\u578b\u63d0\u53d6\u6a21\u5757\uff09\u6765\u628a\u5f62\u72b6\u4fe1\u606f\u8fdb\u884c\u8fed\u4ee3\u878d\u5408</p> <p>\u672c\u6587\u505a\u4e86\u4ec0\u4e48\u4e8b\uff1f</p> <ul> <li>\u6458\u8981</li> <li>\u5f15\u5165\u2014\u8d21\u732e</li> <li>\u7ed3\u8bba</li> </ul> <p>\u5177\u4f53\u600e\u4e48\u5b9e\u73b0\uff1amethod</p> <p>\u7ed3\u679c\uff1aExperiment</p> <p>\u7814\u7a76\u95ee\u9898\u7684\u52a8\u673a\uff1aIntroduction</p> <p>\u7814\u7a76\u73b0\u72b6\uff1arelated work</p>"},{"location":"literature/ObejectCounting/rank6%20LOCA/#_1","title":"\u6458\u8981","text":"<p>We consider low-shot counting of arbitrary semantic categories in the image using only few annotated exemplars (few-shot) or no exemplars (no-shot). \u91c7\u7528\u5c0f\u6837\u672c\u6216\u80050\u6837\u672c \u8ba1\u6570\u4efb\u610f\u8bed\u4e49\u7c7b\u522b</p> <p>The standard few-shot pipeline follows extraction of appearance queries from exemplars and matching them with image features to infer the object counts. </p> <p>\u6807\u51c6\u7684\u5c0f\u6837\u672c \u9075\u5faa\u4ece\u6837\u672c\u4e2d\u63d0\u53d6\u5916\u89c2\u67e5\u8be2\uff0c\u5e76\u5c06\u5176\u4e0e\u56fe\u50cf\u7279\u5f81\u8fdb\u884c\u5339\u914d\uff0c\u4ee5\u63a8\u65ad\u7269\u4f53\u8ba1\u6570\u3002</p> <p>Existing methods extract queries by feature pooling which neglects the shape information (e.g., size and aspect) and leads to a reduced object localization accuracy and count estimates. \u4e22\u5931\u4e86\u5f62\u72b6\u4fe1\u606f\u548c\u5b9a\u4f4d\u4fe1\u606f\u3001\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u7279\u5f81\u6c60\u5316\u63d0\u53d6\u67e5\u8be2\uff0c\u5ffd\u7565\u4e86\u5f62\u72b6\u4fe1\u606f(\u4f8b\u5982,\u5927\u5c0f\u548c\u7eb5\u6a2a\u6bd4)\uff0c\u5bfc\u81f4\u76ee\u6807\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u8ba1\u6570\u4f30\u8ba1\u503c\u964d\u4f4e\u3002</p> <p>We propose a L ow-shot  O bject C ounting network with iterative prototype A daptation (LOCA). </p> <p>\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u8fed\u4ee3\u539f\u578b\u81ea\u9002\u5e94( LOCA )\u7684\u5c0f\u6837\u672c\u7269\u4f53\u8ba1\u6570\u7f51\u7edc\u3002</p> <p>Our main contribution is the new object prototype extraction module, which iteratively fuses the exemplar shape and appearance information with image features. </p> <p>\u76ee\u6807\u539f\u578b\u63d0\u53d6\u6a21\u5757\uff0c\u8fed\u4ee3\u878d\u5408\u793a\u4f8b\u6846\u5f62\u72b6\u548c\u5916\u89c2\u4fe1\u606f</p> <p>\u6211\u4eec\u7684\u4e3b\u8981\u8d21\u732e\u662f\u65b0\u7684\u76ee\u6807\u539f\u578b\u63d0\u53d6\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u5c06\u6837\u672c\u5f62\u72b6\u548c\u5916\u89c2\u4fe1\u606f\u4e0e\u56fe\u50cf\u7279\u5f81\u8fdb\u884c\u8fed\u4ee3\u878d\u5408\u3002</p> <p>The module is easily adapted to zero-shot scenarios, enabling LOCA to cover the entire spectrum of low-shot counting problems. \u8be5\u6a21\u5757\u53ef\u4ee5\u9002\u7528\u4e8e0-shot\u573a\u666f\uff0c\u4f7f\u5f97LOCA\u80fd\u591f\u8986\u76d6\u6574\u4e2a\u4f4e\u6837\u672c\u8ba1\u6570\u95ee\u9898\u3002</p> <p>LOCA outperforms all recent state-of-the-art methods on FSC147 benchmark by 20-30% in RMSE on one-shot and fewshot and achieves state-of-the-art on zero-shot scenarios, while demonstrating better generalization capabilities. The code and models are available.</p>"},{"location":"literature/ObejectCounting/rank6%20LOCA/#-","title":"\u5f15\u5165-\u8d21\u732e","text":"<p>Introduction</p> <p>\u5012\u6570\u7b2c\u4e8c\u6bb5</p> <p>\uff08\u7b2c\u4e00\u4e2a\u8d21\u732e\uff0c\u63d0\u51faLOCA\uff09We propose a Low-shot Object Counting network with iterative prototype Adaptation (LOCA).</p> <p>\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u8fed\u4ee3\u539f\u578b\u81ea\u9002\u5e94( LOCA )\u7684\u5c0f\u6837\u672c\u7269\u4f53\u8ba1\u6570\u7f51\u7edc\u3002</p> <p>\uff08LOCA\u7684\u4e3b\u8981\u8d21\u732e\u662fOPE\u6a21\u5757\uff0cOPE\u6a21\u5757\u7684\u7a81\u51fa\u7279\u70b9\uff09Our main contribution is the new object prototype extraction module, which separately extracts the exemplar shape and appearance queries. The shape queries are gradually adapted into object prototypes by considering the exemplar appearance as well as the appearance of non-annotated objects, obtaining excellent localization properties and leading to highly accurate counts (Figure 1). </p> <ul> <li>OPE\u6a21\u5757\uff0c\u5206\u522b\u63d0\u53d6\u6837\u4f8b\u6846\u5f62\u72b6\u548c\u5916\u89c2\u67e5\u8be2</li> <li>\u5f62\u72b6\u7279\u5f81 \u662f\u9010\u6e10\u7684\u878d\u5408\u5230 \u76ee\u6807\u539f\u578b\u7684\u3002\uff08\u901a\u8fc7\u8003\u8651\u6837\u4f8b\u5916\u89c2\u548c\u975e\u6807\u6ce8\u5bf9\u8c61\u7684\u5916\u89c2\uff09 $\\rightarrow $  \u83b7\u5f97\u826f\u597d\u7684\u5b9a\u4f4d\u5c5e\u6027\uff0c\u5e76\u5f97\u5230\u9ad8\u5ea6\u51c6\u786e\u7684\u8ba1\u6570(\u56fe1 )\u3002</li> </ul> <p>\uff08\u4eae\u70b9\uff1aLOCA\u7b2c\u4e00\u4e2a\u4f7f\u7528\u6837\u4f8b\u6846\u5f62\u72b6\u4fe1\u606f\u6307\u5bfc\u8ba1\u6570)     To the best of our knowledge, LOCA is the first low-shot counting method that explicitly uses exemplars shape information for counting.</p> <p>\u5012\u6570\u7b2c\u4e00\u6bb5 \uff08\u5f15\u5165\u6700\u540e\u4e00\u6bb5 \u7ed3\u679c\u6bb5\uff09\u6307\u51fa\u672c\u6587\u6240\u7528\u6570\u636e\u96c6\uff1a</p> <ul> <li>FSC148\u6570\u636e\u96c6</li> <li>CARPK</li> </ul>"},{"location":"literature/ObejectCounting/rank6%20LOCA/#_2","title":"\u7ed3\u8bba","text":"<p>P1  \u7b2c\u4e00\u70b9\uff1a\u63d0\u51fa\u4e86LOCA\uff0c\u5206\u522b\u8003\u8651\u793a\u4f8b\u7684\u5f62\u72b6\u7279\u5f81\u548c\u5916\u89c2\u7279\u5f81\uff0c\u5e76\u5206\u522b\u901a\u8fc7OPE\u6a21\u5757\u8fdb\u884c\u8fed\u4ee3\u878d\u5408</p> <p>\u56e0\u6b64\uff0c\u539f\u578b\u6cdb\u5316\u5230\u56fe\u50cf\u4e2d\u7684\u975e\u6807\u6ce8\u5bf9\u8c61\uff0c\u4ece\u800c\u5f97\u5230\u66f4\u597d\u7684\u5b9a\u4f4d\u6027\u8d28\u548c\u8ba1\u6570\u4f30\u8ba1\u3002</p> <p>We presented a new low-shot counting method LOCA, that addresses the limitations of the current state-of-the-art methods. LOCA considers the exemplar shape and appearance properties separately and iteratively adapts these into object prototypes by a new object prototype extraction (OPE) module considering the image-wide features. The prototypes thus generalize to the non-annotated objects in the image, leading to better localization properties and count estimates.</p> <p>P2 \u8bf4\u660e\u7ed3\u679c</p> <p>P3 \u6307\u51fa\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411</p> <p>We envision several possible future research directions. </p> <ul> <li>Additional supervision levels such as introducing negative exemplar annotations could be introduced in LOCA for better specification of the selected object class. This could lead to interactive tools for accurate object counting. </li> </ul> <p>\u4e3a\u4e86\u66f4\u597d\u5730\u89c4\u8303\u6240\u9009\u5bf9\u8c61\u7c7b\uff0c\u53ef\u4ee5\u5728LOCA\u4e2d\u5f15\u5165\u989d\u5916\u7684\u76d1\u7763\u7ea7\u522b\uff0c\u5982\u5f15\u5165\u8d1f\u4f8b\u6ce8\u91ca\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u7528\u4e8e\u7cbe\u786e\u7269\u4f53\u8ba1\u6570\u7684\u4ea4\u4e92\u5f0f\u5de5\u5177\u3002</p> <ul> <li>Furthermore, a gap between low-shot counters and object detectors could be further narrowed by enabling bounding box or segmentation mask prediction in LOCA to output additional statistics about the counted objects such as average size, etc., which is useful for many practical applications such as biomedical analysis.  </li> </ul> <p>\u6b64\u5916\uff0c\u901a\u8fc7\u5728LOCA\u4e2d\u5b9e\u73b0\u8fb9\u754c\u6846\u6216\u5206\u5272\u63a9\u7801\u9884\u6d4b\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u7f29\u5c0f\u4f4e\u6837\u672c\u8ba1\u6570\u5668\u548c\u76ee\u6807\u68c0\u6d4b\u5668\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4ee5\u8f93\u51fa\u5173\u4e8e\u8ba1\u6570\u5bf9\u8c61\u7684\u989d\u5916\u7edf\u8ba1\u4fe1\u606f\uff0c\u4f8b\u5982\u5e73\u5747\u5927\u5c0f\u7b49\uff0c\u8fd9\u5bf9\u4e8e\u751f\u7269\u533b\u5b66\u5206\u6790\u7b49\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\u662f\u6709\u7528\u7684\u3002</p>"},{"location":"literature/ObejectCounting/rank6%20LOCA/#_3","title":"\u5f15\u5165","text":"<p>P1 \u7279\u5b9a\u7269\u4f53\u8ba1\u6570\uff1b\u4eba\u7fa4\u3001\u6c7d\u8f66\u3001\u7269\u79cd\uff1b\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u8bad\u7ec3\u6570\u636e \u2192 \u5c0f\u6837\u672c\u8ba1\u6570\uff08\u7531\u6837\u4f8b\u6846\u6807\u51fa\u76ee\u6807\uff09\u30010\u6837\u672c\u8ba1\u6570\uff08\u8ba1\u6570\u591a\u6570\u7c7b\u522b\uff09</p> <p>Object counting considers estimation of the number of specific objects in the image. Solutions based on object detectors have been extensively explored for categories such as people [1, 33], cars [20, 12] or animal species [2, 32]. However, these methods require huge annotated training datasets and are not applicable to counting new, previously unobserved, classes with potentially only few annotations. The latter problem is explored by low-shot counting, which encompasses few-shot and zero-shot counting. Few-shot counters count all present objects of some class with only few of them annotated by bounding boxes (exemplars), while zero-shot counters consider counting the most frequent class without annotations.</p> <p>P2   \u89d2\u5ea61\uff1a\u5c0f\u6837\u672c\u8ba1\u6570&amp;\u56de\u5f52\u5bc6\u5ea6\u56fe\uff1b\u89d2\u5ea62\uff1a0-shot</p> <ul> <li> <p>Few-shot counters have recently gained momentum with the emergence of a challenging dataset [24] and follow a common pipeline [18, 24, 13, 26, 31]\uff08\u5c0f\u6837\u672c\u8ba1\u6570\uff0c\u968f\u7740\u6570\u636e\u96c6\u7684\u51fa\u73b0\uff09. Image and exemplar features are extracted into object prototypes, which are matched to the image by correlation.\uff08\u56fe\u50cf\u548c\u6837\u4f8b\u7279\u5f81\u88ab\u63d0\u53d6\u5230\u5bf9\u8c61\u539f\u578b\u4e2d\uff0c\u5bf9\u8c61\u539f\u578b\u901a\u8fc7\u76f8\u5173\u6027\u4e0e\u56fe\u50cf\u8fdb\u884c\u5339\u914d\u3002\uff09 Finally, the obtained intermediate image representation is regressed into a 2D object density map, whose values sum to the object count estimate.\uff08\u6700\u540e\uff0c\u5c06\u5f97\u5230\u7684\u4e2d\u95f4\u56fe\u50cf\u8868\u793a\u56de\u5f52\u4e3a2D\u7269\u4f53\u5bc6\u5ea6\u56fe\uff0c\u5c06\u503c\u76f8\u52a0\u5f97\u5230\u76ee\u6807\u8ba1\u6570\u7684\u4f30\u8ba1\u503c\uff09 The methods primarily differ in the intermediate image representation construction method\uff08\u8fd9\u4e9b\u65b9\u6cd5\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e \u4e2d\u95f4\u56fe\u50cf\u8868\u793a\u7684\u6784\u5efa\u8fc7\u7a0b\uff09\uff08\u4e3e\u4f8b\u5b50\u8bf4\u660e\uff09, which is based either on Siamese similarity [18, 24], cross-attention [16, 13] or feature and similarity fusion [26, 31].</p> </li> <li> <p>While receiving much less attention, zero-shot counters follow a similar principle, but either identify possible exemplars by majority vote from region proposals [22] or implicitly by attention modules [11].\u867d\u7136\u96f6\u6837\u672c\u8ba1\u6570\u5668\u53d7\u5230\u7684\u5173\u6ce8\u8f83\u5c11\uff0c\u4f46\u9075\u5faa\u7c7b\u4f3c\u7684\u539f\u5219\uff0c\u6216\u8005\u901a\u8fc7\u533a\u57df\u63d0\u6848\u7684\u591a\u6570\u6295\u7968\u6765\u8bc6\u522b\u53ef\u80fd\u7684\u6837\u672c[ 22 ]\uff0c\u6216\u8005\u901a\u8fc7\u6ce8\u610f\u529b\u6a21\u5757\u9690\u5f0f\u5730\u8bc6\u522b\u53ef\u80fd\u7684\u6837\u672c[ 11 ]\u3002</p> </li> </ul> <p>P3   \u5f15\u51fa\u672c\u6587\u8981\u8ba8\u8bba\u7684\u95ee\u9898\uff1a</p> <p>All few-shot counters construct object prototypes by pooling image features extracted from the exemplars into fixed-sized correlation filters. The prototypes thus fail to encode the object shape information (i.e., width, height and aspect), resulting in a reduced accuracy of the density map. Recent works have shown that this information loss can be partially addressed by complex architectures for learning a nonlinear similarity function [26]. Nevertheless, we argue that a much simpler counting architecture can be used instead, by explicitly addressing the exemplar shape and by applying an appropriate object prototype adaptation method.</p> <p>P4\u3001P5\uff1b\u8d21\u732e </p> <p>structure</p> <ol> <li>\u7279\u5b9a\u7269\u4f53\u8ba1\u6570</li> <li>\u5c0f\u6837\u672c\u8ba1\u6570 &amp;  \u56de\u5f52\u5bc6\u5ea6\u56fe</li> <li>\u5f15\u51fa\u95ee\u9898\uff1a\u4e22\u5931\u5f62\u72b6\u4fe1\u606f\uff0c\u5c3d\u7ba1\u73b0\u5728\u4e5f\u6709\u7814\u7a76\u65b9\u6cd5\u5728\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u662f\u7ed3\u6784\u6bd4\u8f83\u590d\u6742</li> <li> <ol> <li>\u8d21\u732e\u3001\u7ed3\u679c</li> </ol> </li> </ol>"},{"location":"literature/ObejectCounting/rank6%20LOCA/#_4","title":"\u76f8\u5173\u5de5\u4f5c","text":"<p> \u7ea6 2890 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 14 \u5206\u949f</p> <p>P1 \u7279\u5b9a\u7269\u4f53\u8ba1\u6570</p> <p>Historically, object counting has been addressed by class-specific detectors for people [1, 33], cars [20, 12] and animals [2], but these methods do not cope well with extremely crowded scenes. In a jellyfish polyp counting scenario, [32] thus proposed to segment the image and interpret the segmentation as a collection of circular objects. Alternatively, [1, 6] framed counting as a regression of object density map, whose summation predicts the number of objects. A major drawback of these methods is that they require large annotated training datasets for each object class, which is often an unrealistic requirement.</p> <p>P2 class-agnostic counters  \u7c7b\u65e0\u5173\u8ba1\u6570\u7684\u53d1\u5c55</p> <p>In response, class-agnostic counters have been explored, that specialize to the object category at test-time using only a few user-provided object exemplars. </p> <p>\u6587\u732e\u6982\u8ff0</p> <ol> <li>An early representative [18] proposed a two-stream Generic Matching Network, that extracts the image and exemplar object features, concatenates them and regresses the representation into the final density map.  \u65e9\u671f\u7684\u4ee3\u8868[ 18 ]\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u6d41\u7684\u901a\u7528\u5339\u914d\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u63d0\u53d6\u56fe\u50cf\u548c\u6837\u672c\u5bf9\u8c61\u7279\u5f81\uff0c\u5e76\u5c06\u5b83\u4eec\u4e32\u8054\u8d77\u6765\uff0c\u5c06\u8868\u793a\u56de\u5f52\u5230\u6700\u7ec8\u7684\u5bc6\u5ea6\u56fe\u4e2d\u3002</li> <li>CFOCNet [30] noted that a mere concatenation leads to unreliable localization and proposed a Siamese correlation network(\u5b6a\u751f\u5339\u914d\u7f51) inspired by the tracking literature [3] to improve the localization and counts. CFOCNet [ 30 ]\u6307\u51fa\u7b80\u5355\u7684\u7ea7\u8054\u4f1a\u5bfc\u81f4\u4e0d\u53ef\u9760\u7684\u5b9a\u4f4d\uff0c\u5e76\u53d7\u8ddf\u8e2a\u5347\u7684\u542f\u53d1\u63d0\u51fa\u4e86\u5b6a\u751f\u76f8\u5173\u7f51\u7edc\u6539\u8fdb\u4e86\u5b9a\u4f4d\u548c\u8ba1\u6570\u3002</li> <li>Ranjan et al. [24] proposed a further improvement of correlation robustness by test-time Siamese backbone adaptation. Ranjan\u7b49\u4eba[ 24 ]\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u6d4b\u8bd5\u65f6\u5b6a\u751f\u9aa8\u5e72\u7f51\u81ea\u9002\u5e94\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u76f8\u5173\u9c81\u68d2\u6027\u7684\u65b9\u6cd5\u3002</li> <li>Shi et al. [26] proposed an alternative approach for jointly learning the representation as well as a nonlinear similarity metric for improved localization and applied self-attention to reduce the within-class appearance variability in the test image. Shi\u7b49\u4eba[ 26 ]\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u5b66\u4e60\u8868\u793a\u7684\u66ff\u4ee3\u65b9\u6cd5\u4ee5\u53ca\u6539\u8fdb\u5b9a\u4f4d\u7684\u975e\u7ebf\u6027\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u5e76\u5e94\u7528\u81ea\u6ce8\u610f\u529b\u6765\u51cf\u5c11\u6d4b\u8bd5\u56fe\u50cf\u4e2d\u7684\u7c7b\u5185\u5916\u89c2\u53d8\u5f02\u6027\u3002</li> <li>You et al. [31] combined the similarity map with the image features before applying location regression to improve count accuracy and proposed a learnable similarity metric to guide the fusion of exemplar and image features.You\u7b49[ 31 ]\u5728\u5e94\u7528\u4f4d\u7f6e\u56de\u5f52\u4e4b\u524d\u5c06\u76f8\u4f3c\u6027\u56fe\u4e0e\u56fe\u50cf\u7279\u5f81\u7ed3\u5408\u4ee5\u63d0\u9ad8\u8ba1\u6570\u7cbe\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5b66\u4e60\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u6765\u6307\u5bfc\u793a\u4f8b\u548c\u56fe\u50cf\u7279\u5f81\u7684\u878d\u5408\u3002</li> <li>Liu et al. [16] adopted a vision transformer [7] for image feature extraction and a convolutional encoder to extract the exemplars. Cross-attention is used to fuse image and exemplar features and a convolutional decoder regresses the density map. Liu\u7b49[ 16 ]\u91c7\u7528\u89c6\u89c9\u8f6c\u6362\u5668[ 7 ]\u8fdb\u884c\u56fe\u50cf\u7279\u5f81\u63d0\u53d6\uff0c\u91c7\u7528\u5377\u79ef\u7f16\u7801\u5668\u63d0\u53d6\u6837\u672c\u3002\u4ea4\u53c9\u6ce8\u610f\u529b\u7528\u4e8e\u878d\u5408\u56fe\u50cf\u548c\u6837\u672c\u7279\u5f81\uff0c\u5377\u79ef\u89e3\u7801\u5668\u5bf9\u5bc6\u5ea6\u56fe\u8fdb\u884c\u56de\u5f52\u3002</li> <li>Recently, few-shot counting has been extended to few-shot detection [21] by adopting the transformer-based object detector [29] to predict also the object bounding box in addition to location.\u6700\u8fd1\uff0c\u5c0f\u6837\u672c\u8ba1\u6570\u5df2\u7ecf\u6269\u5c55\u5230\u5c0f\u6837\u672c\u68c0\u6d4b[ 21 ]\uff0c\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u76ee\u6807\u68c0\u6d4b\u5668[ 29 ]\uff0c\u9664\u4e86\u4f4d\u7f6e\u5916\uff0c\u8fd8\u9884\u6d4b\u76ee\u6807\u8fb9\u754c\u6846\u3002</li> </ol> <p>P3  3-shot\u2192 fewer shot</p> <p>\uff08\u8fd9\u6bb5\u6587\u732e\u7efc\u8ff0\u7684\u4e3b\u9898\uff09While most works addressed situations with several (typically three) exemplars available, only few recent works considered reducing this number. </p> <ul> <li>Lin et al. [13] proposed a counting method that requires only a single exemplar. Their method is based on a transformer architecture and formulates correlation between image and exemplar features by several self- and cross-attention blocks. </li> </ul> <p>Lin\u7b49\u4eba[ 13 ]\u63d0\u51fa\u4e86\u4e00\u79cd\u53ea\u9700\u8981\u5355\u4e2a\u6837\u672c\u7684\u8ba1\u6570\u65b9\u6cd5\u3002\u4ed6\u4eec\u7684\u65b9\u6cd5\u57fa\u4e8e\u4e00\u79cd\u8f6c\u6362\u5668\u7ed3\u6784\uff0c\u901a\u8fc7\u51e0\u4e2a\u81ea\u6ce8\u610f\u529b\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u5757\u6765\u5efa\u7acb\u56fe\u50cf\u548c\u6837\u672c\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002</p> <p>\uff08\u6781\u7aef\u60c5\u51b5 0-shot\uff09An extreme case of zero-shot counting [22, 11] has been explored as well. </p> <ul> <li>Ranjan and Hoai [22] proposed RepRPN-Counter, which combines a region proposal network [25] that also predicts a repetition score of each proposal.Ranjan\u548cHoai</li> </ul> <p>[ 22 ]\u63d0\u51fa\u4e86RepRPN - Counter\uff0c\u5b83\u7ed3\u5408\u4e86\u4e00\u4e2a\u533a\u57df\u63d0\u6848\u7f51\u7edc[ 25 ]\uff0c\u8be5\u7f51\u7edc\u4e5f\u9884\u6d4b\u6bcf\u4e2a\u63d0\u6848\u7684\u91cd\u590d\u8bc4\u5206\u3002</p> <ul> <li>Proposals with the highest repetition scores are used as exemplars and sent through FamNet [24] to predict multiple density maps. </li> </ul> <p>\u91cd\u590d\u5f97\u5206\u6700\u9ad8\u7684\u63d0\u6848\u4f5c\u4e3a\u793a\u4f8b\uff0c\u901a\u8fc7Fam Net [ 24 ]\u53d1\u9001\uff0c\u9884\u6d4b\u591a\u4e2a\u5bc6\u5ea6\u56fe\u3002</p> <ul> <li>On the other hand, Hobley and Prisacariu [11] developed a weakly supervised method that implicitly identifies object category most likely to be counted and predicts a density map for that category. </li> </ul> <p>\u53e6\u4e00\u65b9\u9762\uff0cHobley\u548cPrisacariu [ 11 ]\u53d1\u5c55\u4e86\u4e00\u79cd\u5f31\u76d1\u7763\u65b9\u6cd5\uff0c\u5b83\u9690\u5f0f\u5730\u8bc6\u522b\u6700\u6709\u53ef\u80fd\u88ab\u8ba1\u6570\u7684\u5bf9\u8c61\u7c7b\u522b\uff0c\u5e76\u9884\u6d4b\u8be5\u7c7b\u522b\u7684\u5bc6\u5ea6\u56fe\u3002</p> <ul> <li>Vision transformer with a unsupervised training stage [16] has also shown success in zero-shot counting. </li> </ul> <p>\u5177\u6709\u65e0\u76d1\u7763\u8bad\u7ec3\u9636\u6bb5\u7684\u89c6\u89c9\u8f6c\u6362\u5668[ 16 ]\u5728\u96f6\u6837\u672c\u8ba1\u6570\u65b9\u9762\u4e5f\u53d6\u5f97\u4e86\u6210\u529f\u3002</p> <p>241118</p> <p>todo\uff1a\u540e\u9762\u7684\u65b9\u6cd5</p>"},{"location":"literature/ObejectCounting/rank7%20SemAug_CountTR/","title":"rank7 SemAug CountTR","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 4223 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 21 \u5206\u949f</p> <p></p> <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u94fe\u63a5</p> <p></p> <p>\u6807\u9898\uff1aSemantic Generative Augmentations for Few-Shot Counting  \u5c0f\u6837\u672c\u8ba1\u6570 \u8bed\u4e49\u751f\u6210\u589e\u5f3a</p> <p>\u672c\u6587\u2764\ufe0f\uff1a</p> <ul> <li>\u4e3a\u4e86\u4f7f\u751f\u6210\u7684\u56fe\u50cf \u7684\u76ee\u6807\u6570\u91cf\u548c\u539f\u56fe\u50cf\u4fdd\u6301\u4e0d\u53d8\uff0c\u4f7f\u7528 stable diffusion\u5408\u6210\u56fe\u50cf\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u53cc\u6761\u4ef6\uff1aprompt &amp; \u5bc6\u5ea6\u56fe</li> <li>\u4e3a\u4e86\u89e3\u51b3\u751f\u6210\u56fe\u50cf\u603b\u662f\u8ddf\u8bad\u7ec3\u56fe\u50cf\u76f8\u540c\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u589e\u5f3a\u56fe\u50cf\u591a\u6837\u6027\u7684\u7b56\u7565\uff1a\u968f\u673a\u6253\u4e71\u5b57\u5e55\u63cf\u8ff0\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u521b\u5efa\u6ca1\u89c1\u8fc7\u4f46\u662f\u5408\u7406\u7684 \u5bf9\u8c61\u7c7b\u578b\u548c\u7a7a\u95f4\u5206\u5e03</li> </ul> <p>\u5408\u6210\u56fe\u50cf &amp; \u591a\u6837\u5316\u7b56\u7565</p>"},{"location":"literature/ObejectCounting/rank7%20SemAug_CountTR/#abstract","title":"Abstract","text":"<p>\uff08\u6587\u751f\u56fe\u6269\u6563\u6a21\u578b\uff09</p> <p>With the availability of powerful text-to-image diffusion models, recent works have explored the use of synthetic data to improve image classification performances. </p> <p>\u968f\u7740\u5f3a\u5927\u7684\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u7684\u53ef\u7528\u6027\uff0c\u6700\u8fd1\u7684\u5de5\u4f5c\u63a2\u7d22\u4e86\u4f7f\u7528\u5408\u6210\u6570\u636e\u6765\u63d0\u9ad8\u56fe\u50cf\u5206\u7c7b\u6027\u80fd\u3002</p> <p>These works show that it can effectively augment or even replace real data.</p> <p>\u8fd9\u4e9b\u5de5\u4f5c\u8868\u660e\uff0c\u5b83\u53ef\u4ee5\u6709\u6548\u5730\u589e\u5f3a\u751a\u81f3\u66ff\u4ee3\u771f\u5b9e\u6570\u636e\u3002 </p> <p>In this work, we investigate how synthetic data can benefit few-shot class-agnostic counting. </p> <p>\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u5408\u6210\u6570\u636e\u5982\u4f55\u6709\u5229\u4e8e\u5c0f\u6837\u672c\u7c7b\u522b\u65e0\u5173\u8ba1\u6570\u3002</p> <p>\u5408\u6210\u56fe\u50cf\u7684\u7b2c\u4e00\u4e2a\u8981\u6c42\uff1a\u5408\u6210\u7684\u56fe\u7247 \u76ee\u6807\u6570\u91cf\u662f\u76f8\u7b49\u7684</p> <p>This requires to generate images that correspond to a given input number of objects. </p> <p>\u8fd9\u5c31\u9700\u8981\u751f\u6210\u4e0e\u7ed9\u5b9a\u7684\u8f93\u5165\u7269\u4f53\u6570\u91cf\u76f8\u5bf9\u5e94\u7684\u56fe\u50cf\u3002</p> <p>However, text-to-image models struggle to grasp the notion of count.</p> <p>\u7136\u800c\uff0c\u6587\u672c\u5230\u56fe\u50cf\u7684\u6a21\u578b\u5f88\u96be\u628a\u63e1\u8ba1\u6570\u7684\u6982\u5ff5\u3002</p> <p>\u5408\u6210\u56fe\u50cf\u7684\u76d1\u7763\u4fe1\u53f7\uff1aprompt\u548c\u5bc6\u5ea6\u56fe\uff1b\u5177\u4f53\u7528\u7684\u6a21\u578b\uff1aStable Diffusion </p> <p>We propose to rely on a double conditioning of Stable Diffusion with both a prompt and a density map in order to augment a training dataset for few-shot counting. </p> <p>\u6211\u4eec\u63d0\u51fa\u4f7f\u7528\u7a33\u5b9a\u6269\u6563( Stable Diffusion )\u7684\u63d0\u793a\u56fe\u548c\u5bc6\u5ea6\u56fe\u7684\u53cc\u91cd\u6761\u4ef6\u6765\u589e\u52a0\u5c11\u6837\u672c\u8ba1\u6570\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u3002</p> <p>Due to the small dataset size, the fine-tuned model tends to generate images close to the training images. </p> <p>\u7531\u4e8e\u6570\u636e\u96c6\u89c4\u6a21\u8f83\u5c0f\uff0c\u5fae\u8c03\u540e\u7684\u6a21\u578b\u503e\u5411\u4e8e\u751f\u6210\u63a5\u8fd1\u8bad\u7ec3\u56fe\u50cf\u7684\u56fe\u50cf\u3002</p> <p>\u4e3a\u4e86\u89e3\u51b3 \u56fe\u50cf\u603b\u662f\u63a5\u8fd1\u8bad\u7ec3\u56fe\u50cf\u7684\u95ee\u9898\uff0c\u63d0\u51fa \u968f\u673a\u6253\u4e71\u56fe\u50cf\u4e4b\u95f4\u7684\u5b57\u5e55</p> <p>We propose to enhance the diversity of synthesized images by exchanging captions between images thus creating unseen configurations of object types and spatial layout. </p> <p>\u6211\u4eec\u63d0\u51fa\u901a\u8fc7\u5728\u56fe\u50cf\u4e4b\u95f4\u4ea4\u6362\u5b57\u5e55\u6765\u589e\u5f3a\u5408\u6210\u56fe\u50cf\u7684\u591a\u6837\u6027\uff0c\u4ece\u800c\u521b\u5efa\u770b\u4e0d\u89c1\u7684\u5bf9\u8c61\u7c7b\u578b\u548c\u7a7a\u95f4\u5e03\u5c40\u914d\u7f6e\u3002</p> <p>\uff08\u7ed3\u679c\uff09Our experiments show that our diversified generation strategy significantly improves the counting accuracy of two recent and performing few-shot counting models on FSC147 and CARPK.</p> <p>\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u591a\u6837\u5316\u751f\u6210\u7b56\u7565\u663e\u8457\u63d0\u9ad8\u4e86FSC147\u548cCARPK\u4e0a\u6700\u8fd1\u6267\u884c\u7684\u4e24\u4e2a\u5c11\u6837\u672c\u8ba1\u6570\u6a21\u578b\u7684\u8ba1\u6570\u51c6\u786e\u7387\u3002</p> <p>\u6570\u636e\u96c6\uff1a</p> <ul> <li>FSC147</li> <li>CARPK</li> </ul>"},{"location":"literature/ObejectCounting/rank7%20SemAug_CountTR/#-","title":"\u5f15\u5165-\u8d21\u732e","text":"<p>To tackle few-shot counting, we propose to synthesize unseen data with Stable Diffusion conditioned by both a textual prompt and a density map.</p> <p>\u4e3a\u4e86\u89e3\u51b3\u5c0f\u6837\u672c\u8ba1\u6570\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4f7f\u7528\u7a33\u5b9a\u6269\u6563\u6765\u5408\u6210\u770b\u4e0d\u89c1\u7684\u6570\u636e\uff0c\u5176\u6761\u4ef6\u662f\u6587\u672c\u63d0\u793a\u548c\u5bc6\u5ea6\u56fe\u3002</p> stable diffusion\uff1f <p>Note</p> <p>\u2460 \u4f7f\u7528stable diffusion\u5408\u6210\u6570\u636e  \u2461 \u76d1\u7763\u4fe1\u53f7\uff1a\u6587\u672c\u63d0\u793a\u548c\u5bc6\u5ea6\u56fe       </p> <p>We thus build an augmented FSC dataset that is used to train a deep counting network. </p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u589e\u5e7f\u7684FSC\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u6df1\u5ea6\u8ba1\u6570\u7f51\u7edc\u3002</p> <p>The double conditioning, implemented with ControlNet [42], allows us to generate novel synthetic images with a precise control, preserving the ground truth for the counting task. </p> <p>\u7528controlnet\u7f51\u7edc[ 42 ]\u5b9e\u73b0\u7684\u53cc\u91cd\u6761\u4ef6\u5316\uff0c\u53ef\u4ee5\u4f7f\u6211\u4eec\u5728\u7cbe\u786e\u63a7\u5236\u4e0b\u751f\u6210\u65b0\u7684\u5408\u6210\u56fe\u50cf\uff0c\u4ece\u800c\u4e3a\u8ba1\u6570\u4efb\u52a1\u4fdd\u7559\u57fa\u672c\u7684\u771f\u503c\u3002</p> <p>It deals well with large numbers of objects, while current methods fail in such cases [19, 27]. </p> <p>\u5b83\u53ef\u4ee5\u5f88\u597d\u5730\u5904\u7406\u5927\u91cf\u7684\u5bf9\u8c61\uff0c\u800c\u76ee\u524d\u7684\u65b9\u6cd5\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u5931\u6548[ 19\u300127]\u3002</p> <p>To increase the diversity of the augmented training set, we swap image descriptions between the n available training samples, leading to $\\frac{n(n\u22121)}{2} $ novel couples, each being the source of several possible synthetic images.</p> <p>\u4e3a\u4e86\u589e\u52a0\u6269\u5145\u8bad\u7ec3\u96c6\u7684\u591a\u6837\u6027\uff0c\u6211\u4eec\u5728n\u4e2a\u53ef\u7528\u7684\u8bad\u7ec3\u6837\u672c\u4e4b\u95f4\u4ea4\u6362\u56fe\u50cf\u63cf\u8ff0\uff0c\u5f97\u5230n ( n-1 ) 2\u4e2a\u65b0\u7684\u5bf9\u5b50\uff0c\u6bcf\u4e2a\u5bf9\u5b50\u90fd\u662f\u82e5\u5e72\u53ef\u80fd\u7684\u5408\u6210\u56fe\u50cf\u7684\u6765\u6e90\u3002</p> <p>However, we show that some combinations do not make sense and lead to poor quality samples. </p> <p>\u7136\u800c\uff0c\u6211\u4eec\u8868\u660e\u4e00\u4e9b\u7ec4\u5408\u6ca1\u6709\u610f\u4e49\uff0c\u5e76\u5bfc\u81f4\u8d28\u91cf\u8f83\u5dee\u7684\u6837\u672c\u3002</p> <p>Therefore, we only select plausible pairs, resulting in improved augmentation quality. </p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u53ea\u9009\u62e9\u4e86\u4f3c\u662f\u800c\u975e\u7684\u914d\u5bf9\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u589e\u5f3a\u8d28\u91cf\u3002</p> <p>We evaluate our approach on two class-agnostic counting networks, namely SAFECount [41] and CounTR [6]. We show that it significantly improves the performances on the benchmark dataset FSC147 [28] and allow for a better generalization on the CARPK dataset [14].</p> <p>\u6211\u4eec\u5728SAFECount [ 41 ]\u548cCoun TR [ 6 ]\u4e24\u4e2a\u7c7b\u4e0d\u53ef\u77e5\u8ba1\u6570\u7f51\u7edc\u4e0a\u5bf9\u6211\u4eec\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u6211\u4eec\u8bc1\u660e\u4e86\u5b83\u5728\u57fa\u51c6\u6570\u636e\u96c6FSC147 [ 28 ]\u4e0a\u7684\u6027\u80fd\u663e\u8457\u63d0\u9ad8\uff0c\u5e76\u4e14\u5728CARPK\u6570\u636e\u96c6[ 14 ]\u4e0a\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002</p> <ul> <li> <p>\u5bf9\u6bd4\u6a21\u578b\uff1aSAFECount [41] and CounTR [6]</p> </li> <li> <p>benchmark\uff1aFSC147\u3001CARPK</p> </li> <li>\u672c\u6587\u63d0\u51fa\u7684\u662f \u5bf9\u6570\u636e\u8f93\u5165\u7684\u591a\u6837\u6027\u8fdb\u884c\u6269\u5145</li> </ul>"},{"location":"literature/ObejectCounting/rank7%20SemAug_CountTR/#_1","title":"\u7ed3\u8bba","text":"<p>7 Conclusion</p> <p>\u7531\u6269\u6563\u6a21\u578b\u5408\u6210\u6570\u636e\u63d0\u9ad8FSC\u8ba1\u6570\u6027\u80fd</p> <p>We show that synthetic data generated by diffusion models improve deep models for few-shot counting. </p> <p>\u4ee5\u5bc6\u5ea6\u56fe\u4e3a\u6761\u4ef6\uff0c\u91c7\u7528\u9884\u8bad\u7ec3\u7684\u6587\u751f\u56fe\u6a21\u578b</p> <p>We adapt a pretrained text-to-image model with a density map conditioning and </p> <p>\u6211\u4eec\u63d0\u51fa\u7684\u591a\u6837\u5316\u7b56\u7565\uff1a\u5229\u7528\u5b57\u5e55\u76f8\u4f3c\u6027\uff0c\u751f\u6210\u5408\u7406\u7684\u4f46\u662f \u6df7\u5408\u4e86\u4e0d\u540c\u8bad\u7ec3\u56fe\u50cf\u548c\u8bed\u4e49\u548c\u51e0\u4f55\u4fe1\u606f</p> <p>we propose a diversification strategy that exploits caption similarities to generate unseen but plausible data that mixes the semantics and the geometry of different training images. </p> <p>\u5c55\u793a\u4e86\u9009\u62e9  compatible images \uff08\u76f8\u5bb9\u7684\u56fe\u50cf\uff1f\uff09\u5408\u6210\u56fe\u50cf\uff0c\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd|| \u6211\u8bb0\u5f97\u6709\u4e00\u4e2a\u6a21\u578b\u7684\u62fc\u63a5\u56fe\u50cf\u6765\u7740\uff0c\u54ea\u7bc7\u8bba\u6587\u6765\u7740\uff1f</p> <p>We show that selecting compatible images improves synthetic image quality with beneficial effects on model performance. </p> <p>\u6211\u4eec\u63d0\u51fa\u7684\u591a\u6837\u6027\u6570\u636e\u5408\u6210\u7b56\u7565\u63d0\u9ad8\u4e86\u8ba1\u6570\u6027\u80fd\uff0cFSC147 \u548c CARPK</p> <p>We demonstrate that learning with our diverse synthetic data leads to improved counting accuracy on FSC147 and state of the art generalization on CARPK.</p> <p>\u6211\u4eec\u63d0\u51fa\u7684\u6570\u636e\u5408\u6210\u7b56\u7565\u7ecf\u8fc7\u5fae\u8c03\u53ef\u4ee5\u7528\u4e8e\u5176\u4ed6\u9886\u57df\uff1a\u76ee\u6807\u68c0\u6d4b\u548c\u8bed\u4e49\u5206\u5272</p> <p>This strategy could be adapted to other tasks requiring fine grained compositionality, such as object detection and semantic segmentation. </p> <p>\u6211\u4eec\u7684\u591a\u6837\u5316\u7b56\u7565\uff1a\u901a\u8fc7\u5728\u5bc6\u5ea6\u56fe\u5f15\u5165\u5408\u9002\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u3001\u901a\u8fc7\u6587\u672c\u4e4b\u95f4\u76f8\u4e92\u4ea4\u6362\u548c\u5bc6\u5ea6\u56fe\u7684\u63a7\u5236\uff0c\u80fd\u591f\u8fdb\u4e00\u6b65\u6269\u5c55</p> <p>Our diversification scheme could be further extended by swapping both the captions and the density controls, by introducing a suitable similarity metric that operates on the density maps.</p>"},{"location":"literature/ObejectCounting/rank7%20SemAug_CountTR/#_2","title":"\u5f15\u5165","text":"<p>1 Introduction</p> <p>P1 </p> <p>\u76ee\u6807\u8ba1\u6570\u7684\u5e94\u7528\u9886\u57df</p> <p>Counting objects is a task with applications in many domains e.g. manufacturing, medicine, monitoring, that involve different types of objects.</p> <p>\u7279\u5b9a\u76ee\u6807\u8ba1\u6570 \u2192FSC CAC\u8ba1\u6570</p> <p>\u4e24\u4e2a\u7a81\u51fa\u7279\u70b9\uff1a\u2460 bounding boxes (cf. Fig. 2),  \u2461 an extract-then-match manner [21].</p> <p>(\u540e\u9762\u6709\u4eba\u521b\u65b0\uff0c\u5c31\u628a\u8fd9\u4e2athen\u6539\u6210 and)</p> <p>While earlier works focused on learning specialized networks [2, 7, 14, 16], Few-Shot object Counting (FSC) [31] was recently introduced to train models that can count any object, including from categories outside the training data. Methods tackling FSC rely on exemplar objects annotated with bounding boxes (cf. Fig. 2), in an extract-then-match manner [21]. </p> <p>\u5982\u4f55\u5bf9\u56fe\u50cf\u7279\u5f81 \u548c \u6837\u4f8b\u6846\u7279\u5f81 \u8fdb\u884c\u5339\u914d\uff1a\u2460 correlation maps [31, 41]   \u2461attention [6, 9]</p> <p>The features of the exemplars and query image are compared using e.g. correlation maps [31, 41] or attention [6, 9]. Matched features are then transformed into a density map indicating at each location in the image the density of the objects of interest. The density map is then summed to obtain the predicted count.</p> <p>P2</p> <p>\u6570\u636e\u96c6\u751f\u6210\uff1a\u4eceGAN \u2192 \u6269\u6563\u6a21\u578b</p> <p>\u63d0\u51fachallenge  FSC147\u6570\u636e\u96c6\u6709\u9650 The reference dataset for FSC, namely FSC147 [31], contains a limited amount of data (3659 train images) thus bounding\u9650\u5236 the performances of counting networks [30]. </p> <p>\u6269\u5145\u6570\u636e\u96c6\u5f88\u9ebb\u70e6 Expanding such a dataset is costly as the annotation process requires pinpointing the center of each object present in a query image, with a potentially high number of occurrences. </p> <p>solutions To overcome the small dataset size, Ranjan et al. [30] augment FSC147 using a GAN to diversify the image styles.solutions**\u2460  Ranjan et al. [30]\u8fd9\u4e2a\u4eba\u7528GAN \u591a\u6837\u5316\u56fe\u50cf\u7684\u683c\u5f0f**</p> <p>Diffusion models have now surpassed GANs owing to their training stability and lower sensitivity to mode collapse. \u73b0\u72b6\uff1a\u6269\u6563\u6a21\u578b\ud83d\udd25\u4e86</p> <p>These models produce more effective and diverse augmentations [12, 37, 39]. Recent works mostly aim at augmenting classification datasets e.g. ImageNet [8], where augmentations are generated by prompting the models with the image labels. \u6269\u6563\u6a21\u578b\ud83d\udd25\u7684\u8bc1\u636e\uff0c\u4e14\u4e3b\u8981\ud83d\udd25\u5728\u5206\u7c7b\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u56fe\u50cf\u6807\u7b7e\u6765\u63d0\u793a\u6a21\u578b</p> <p>**motivation \u5230\u4e86\u6211\u4eec\u8981\u8ba8\u8bba\u7684\u95ee\u9898\uff1a\u6ca1\ud83d\udd25\u5230\u8ba1\u6570\u6570\u636e\u96c6**This fails to produce satisfying images for counting datasets as text-to-image models struggle to generate the correct number of objects [26]. \u56e0\u4e3a\u6587\u672c\u5230\u56fe\u50cf\u5f88\u96be\u4ea7\u751f \u5bf9\u8c61\u6570\u91cf\u6b63\u786e\u7684\u6570\u636e\u96c6</p> <p>\u505a\u7684\u4e00\u4e9b\u52aa\u529b Some works tackle improving compositionality in vision-language models [19, 25, 27] but are limited to small numbers of objects. \u4e00\u4e9b\u5de5\u4f5c\u81f4\u529b\u4e8e\u63d0\u9ad8\u89c6\u89c9\u8bed\u8a00\u6a21\u578b[ 19\u300125\u300127]\u7684\u7ec4\u5408\u6027\uff0c\u4f46\u4ec5\u9650\u4e8e\u5c11\u91cf\u5bf9\u8c61\u3002</p> <p>Other works add more control to pre-trained text-to-image models [15, 23, 42].\u5176\u4ed6\u5de5\u4f5c\u5728\u9884\u8bad\u7ec3\u7684\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b[ 15\u300123\u300142]\u4e2d\u6dfb\u52a0\u4e86\u66f4\u591a\u7684\u63a7\u5236\u3002</p> <p>P3 \u672c\u6587\u7684\uff1aStable Diffusion &amp; ControlNet [42]</p> <p>\u6211\u4eec\u7684\u5de5\u4f5c \u2b50\ufe0f**To tackle few-shot counting, **we propose to synthesize unseen data with Stable Diffusion conditioned by both a textual prompt and a density map. </p> <p>\u57fa\u4e8e\u6587\u672c\u63d0\u793a\u548c\u5bc6\u5ea6\u56fe \u4f7f\u7528\u6269\u6563\u6a21\u578b \u751f\u6210\u6570\u636e</p> <p>We thus build an augmented FSC dataset that is used to train a deep counting network. </p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u589e\u5e7f\u7684FSC\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u6df1\u5ea6\u8ba1\u6570\u7f51\u7edc\u3002</p> <p>The double conditioning, implemented with ControlNet [42], allows us to generate novel synthetic images with a precise control, preserving the ground truth for the counting task. </p> <p>\u7528controlnet\u7f51\u7edc[ 42 ]\u5b9e\u73b0\u7684\u53cc\u91cd\u6761\u4ef6\u5316\uff0c\u53ef\u4ee5\u4f7f\u6211\u4eec\u5728\u7cbe\u786e\u63a7\u5236\u4e0b\u751f\u6210\u65b0\u7684\u5408\u6210\u56fe\u50cf\uff0c\u4ece\u800c\u4e3a\u8ba1\u6570\u4efb\u52a1\u4fdd\u7559\u57fa\u672c\u7684\u771f\u503c\u3002</p> <p>It deals well with large numbers of objects, while current methods fail in such cases [19, 27].</p> <p>\u5b83\u53ef\u4ee5\u5f88\u597d\u5730\u5904\u7406\u5927\u91cf\u7684\u5bf9\u8c61\uff0c\u800c\u76ee\u524d\u7684\u65b9\u6cd5\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u5931\u6548[ 19\u300127]\u3002</p> <p>To increase the diversity of the augmented training set, we swap image descriptions between the \\(n\\) available training samples, leading to $\\frac{n(n\u22121)}{2} $ novel couples, each being the source of several possible synthetic images. </p> <p>\u4e3a\u4e86\u589e\u52a0\u6269\u5145\u8bad\u7ec3\u96c6\u7684\u591a\u6837\u6027\uff0c\u6211\u4eec\u5728n\u4e2a\u53ef\u7528\u7684\u8bad\u7ec3\u6837\u672c\u4e4b\u95f4\u4ea4\u6362\u56fe\u50cf\u63cf\u8ff0\uff0c\u5f97\u5230n ( n-1 ) 2\u4e2a\u65b0\u7684\u5bf9\u5b50\uff0c\u6bcf\u4e2a\u5bf9\u5b50\u90fd\u662f\u82e5\u5e72\u53ef\u80fd\u7684\u5408\u6210\u56fe\u50cf\u7684\u6765\u6e90\u3002</p> <p>However, we show that some combinations do not make sense and lead to poor quality samples. </p> <p>\u7136\u800c\uff0c\u6211\u4eec\u8868\u660e\u4e00\u4e9b\u7ec4\u5408\u6ca1\u6709\u610f\u4e49\uff0c\u5e76\u5bfc\u81f4\u8d28\u91cf\u8f83\u5dee\u7684\u6837\u672c\u3002</p> <p>Therefore, we only select plausible pairs, resulting in improved augmentation quality. </p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u53ea\u9009\u62e9\u4e86\u4f3c\u662f\u800c\u975e\u7684\u914d\u5bf9\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u589e\u5f3a\u8d28\u91cf\u3002</p> <p>We evaluate our approach on two class-agnostic counting networks, namely SAFECount [41] and CounTR [6].</p> <p>\u6211\u4eec\u5728SAFECount [ 41 ]\u548cCoun TR [ 6 ]\u4e24\u4e2a\u7c7b\u4e0d\u53ef\u77e5\u8ba1\u6570\u7f51\u7edc\u4e0a\u5bf9\u6211\u4eec\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002</p> <p>We show that it significantly improves the performances on the benchmark dataset FSC147 [28] and allow for a better generalization on the CARPK dataset [14].</p> <p>\u6211\u4eec\u8bc1\u660e\u4e86\u5b83\u5728\u57fa\u51c6\u6570\u636e\u96c6FSC147 [ 28 ]\u4e0a\u7684\u6027\u80fd\u663e\u8457\u63d0\u9ad8\uff0c\u5e76\u4e14\u5728CARPK\u6570\u636e\u96c6[ 14 ]\u4e0a\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002</p>"},{"location":"literature/ObejectCounting/rank7%20SemAug_CountTR/#_3","title":"\u603b\u7ed3","text":"<p>\u672c\u6587\u7684\u5f15\u5165\u662f\u4e09\u6bb5\uff1a</p> <p>\u7b2c\u4e00\u6bb5\uff1a\u76ee\u6807\u8ba1\u6570\u7684\u5e94\u7528\u9886\u57df \u7ecf\u5386\u4e86\u4ece\u7279\u5b9a\u7269\u4f53 \u5230 \u901a\u7528\u7269\u4f53</p> <p>\u7b2c\u4e8c\u6bb5\uff1a\u4ecb\u7ecd\u6570\u636e\u96c6\u5408\u6210\u65b9\u6cd5\uff1a\u4eceGAN \u5230 Stable Diffusion</p> <p>\u7b2c\u4e09\u6bb5\uff1a\u6307\u51fa\u672c\u6587\u8d21\u732e\uff0c\u518d\u6b21\u5f3a\u8c03</p> <ul> <li>\u751f\u6210\u56fe\u50cf\uff1aStable diffusion</li> <li>\u5408\u6210\u56fe\u50cf\u7684\u76ee\u6807\u6570\u91cf  \u548c \u53c2\u8003\u56fe\u50cf \u662f\u76f8\u540c\u7684</li> <li>prompt \u548c density map\u540c\u65f6\u6307\u5bfc\u56fe\u50cf\u5408\u6210</li> <li>\u5408\u6210\u56fe\u50cf\u7684\u591a\u6837\u6027\u7b56\u7565\uff1a</li> <li>swap image descriptions \uff1b\u968f\u673a\u4ea4\u6362\u56fe\u50cf\u63cf\u8ff0</li> </ul>"},{"location":"literature/ObejectCounting/rank7%20SemAug_CountTR/#_4","title":"\u76f8\u5173\u5de5\u4f5c","text":"<p>\u603b\u7ed3\uff1a\u672c\u6587\u7684\u76f8\u5173\u5de5\u4f5c\u4ece\u4e24\u65b9\u9762\u5c55\u5f00\uff1a</p> <p>Learning with Generated Data</p> <p>Few-shot Object Counting</p> <p>\u751f\u6210\u6570\u636e\u7684\u5b66\u4e60 \u548c \u5c0f\u6837\u672c\u8ba1\u6570</p> <p>\u7b2c\u4e00\u6bb5\uff1a</p> <p>\u7b2c\u4e00\u90e8\u5206\uff1aLearning with Generated Data</p> <p>\uff08\u73b0\u72b6\uff1a\uff09</p> <p>Improvements in image synthesis using generative models have sparked great interest in generating fake images to train deep neural networks. </p> <p>\u4f7f\u7528\u751f\u6210\u6a21\u578b\u8fdb\u884c\u56fe\u50cf\u5408\u6210\u7684\u6539\u8fdb\u6fc0\u53d1\u4e86\u4eba\u4eec\u5bf9\u751f\u6210\u5047\u56fe\u50cf\u4ee5\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6781\u5927\u5174\u8da3\u3002 </p> <p>\uff08\u4eceGAN\u5f00\u59cb\uff09</p> <p>GANs were the first popular models to synthesize data for image classification [1, 5, 17], crowd counting [40] and image segmentation [43]. </p> <p>GANs\u662f\u7b2c\u4e00\u4e2a\u6d41\u884c\u7684\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b[ 1\u30015\u300117]\u3001\u4eba\u7fa4\u8ba1\u6570[ 40 ]\u548c\u56fe\u50cf\u5206\u5272[ 43 ]\u7684\u6570\u636e\u5408\u6210\u6a21\u578b\u3002 </p> <p>\uff08\u5230\u73b0\u5728\u7684\u6269\u6563\u6a21\u578b\uff1aDDPM\u3001 Latent Diffusion \uff09</p> <p>Nowadays, diffusion models such as DDPM [13] or Latent Diffusion [32] seem to outperform GANs, demonstrating more stable training, better coverage of the training distribution and higher image quality. </p> <p>\u5982\u4eca\uff0c\u6269\u6563\u6a21\u578b\u5982DDPM [ 13 ]\u6216Latent Diffusion [ 32 ]\u4f3c\u4e4e\u4f18\u4e8eGANs\uff0c\u663e\u793a\u51fa\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\uff0c\u66f4\u597d\u7684\u8bad\u7ec3\u5206\u5e03\u8986\u76d6\u7387\u548c\u66f4\u9ad8\u7684\u56fe\u50cf\u8d28\u91cf\u3002 </p> <p>\uff08\u6269\u6563\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4ee5\u6587\u672c\u4e3a\u6761\u4ef6\u7684\u6269\u6563\u6a21\u578b\uff09</p> <p>The availability of powerful text-conditioned diffusion models \u6587\u672c\u6761\u4ef6\u6269\u6563\u6a21\u578b [24, 29, 32, 33] has led to many works exploring how to leverage synthetic data for computer vision \u5229\u7528\u751f\u6210\u6570\u636e\u8fdb\u884c\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1, e.g. image classification in low-data regime [12], zero/few-shot learning [37, 39], ImageNet classification [3, 4, 34] and self-supervised learning [38]. </p> <p>\u5f3a\u5927\u7684\u6587\u672c\u6761\u4ef6\u6269\u6563\u6a21\u578b[ 24\u300129\u300132\u300133]\u7684\u51fa\u73b0\uff0c\u5f15\u53d1\u4e86\u8bb8\u591a\u7814\u7a76\u5982\u4f55\u5229\u7528\u5408\u6210\u6570\u636e\u8fdb\u884c\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5de5\u4f5c\u3002</p> <p>These works focus on how to reduce domain gap \u51cf\u5c11\u9886\u57df\u9e3f\u6c9f [12], improve the prompts \u6539\u8fdb\u63d0\u793a using e.g. text-to-sentence model [12] or WordNet [34] and increase diversity \u589e\u52a0\u591a\u6837\u6027 by optimizing the guidance scale [3, 34, 37].   \u4f18\u5316\u6307\u5bfc\u5c3a\u5ea6</p> <p>\u8fd9\u4e9b\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u5982\u4f55\u51cf\u5c11\u9886\u57df\u9e3f\u6c9f[ 12 ]\uff0c\u4f7f\u7528\u6587\u672c\u5230\u53e5\u5b50\u6a21\u578b[ 12 ]\u6216\u8bcd\u7f51[ 34 ]\u6765\u6539\u8fdb\u63d0\u793a\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u6307\u5bfc\u5c3a\u5ea6[ 3,34,37]\u6765\u589e\u52a0\u591a\u6837\u6027\u3002</p> <p>This body of literature consistently demonstrates how generated data allow deep networks to learn more robust representations and improve generalization for image classification. </p> <p>\u8fd9\u7ec4\u6587\u732e\u4e00\u81f4\u5730\u5c55\u793a\u4e86\u751f\u6210\u6570\u636e\u5982\u4f55\u8ba9\u6df1\u5ea6\u7f51\u7edc\u5b66\u4e60\u66f4\u9c81\u68d2\u7684\u8868\u793a\uff0c\u5e76\u63d0\u9ad8\u56fe\u50cf\u5206\u7c7b\u7684\u6cdb\u5316\u6027\u3002 </p> <p>\u6211\u4eec\u5728\u56fe\u50cf\u5408\u6210\u9886\u57df\u7684\u5de5\u4f5c\uff1a</p> <p>\u2764\ufe0f\uff1aTo bring the power of synthetic data to counting,  we propose to condition diffusion models  not only on text prompts but also on counting density maps to generate images with the correct number of objects in the desired spatial configuration. </p> <ul> <li>\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff1a\u57fa\u4e8e\u6587\u672c\u63d0\u793a\u548c\u5bc6\u5ea6\u56fe</li> <li>\u5728\u671f\u671b\u7684\u7a7a\u95f4\u4f4d\u7f6e\u4e0a\uff0c\u751f\u6210\u6709\u6b63\u786e\u6570\u91cf\u7684\u56fe\u7247</li> </ul> <p>We focus more specifically on few-shot class-agnostic object counting. Compared to image classification, this task involves small datasets and local spatial understanding, as objects can be small and follow complex layouts.</p> <p>\u6211\u4eec\u66f4\u4e13\u6ce8\u4e8e\u5c11\u6837\u672c\u7c7b\u65e0\u5173\u7269\u4f53\u8ba1\u6570\u3002\u4e0e\u56fe\u50cf\u5206\u7c7b\u76f8\u6bd4\uff0c\u8fd9\u9879\u4efb\u52a1\u6d89\u53ca\u5c0f\u578b\u6570\u636e\u96c6\u548c\u5c40\u90e8\u7a7a\u95f4\u7406\u89e3\uff0c\u56e0\u4e3a\u5bf9\u8c61\u53ef\u4ee5\u662f\u5c0f\u578b\u7684\uff0c\u5e76\u4e14\u9075\u5faa\u590d\u6742\u7684\u5e03\u5c40\u3002</p> <p>The generated data needs a level of compositionality that current generative models, including diffusion models \u6269\u6563\u6a21\u578b, struggle to achieve. </p> <p>\u751f\u6210\u7684\u6570\u636e\u9700\u8981\u4e00\u79cd \u7ec4\u5408\u6027\u6c34\u5e73 \uff0c\u8fd9\u662f\u5f53\u524d\u7684\u751f\u6210\u6a21\u578b\uff0c\u5305\u62ec**\u6269\u6563\u6a21\u578b**\uff0c\u5728\u5b9e\u73b0\u4e0a\u5b58\u5728\u56f0\u96be\u7684\u3002</p> <p>\u751f\u6210\u6570\u636e\u9700\u8981\u7ec4\u5408\uff0c\u8fd9\u662f\u73b0\u5728\u7684\u751f\u6210\u6a21\u578b\uff0c\u5305\u62ec\u6269\u6563\u6a21\u578b\uff0c\u96be\u4ee5\u5b9e\u73b0\u7684\u3002</p> <p>To bring the power of synthetic data to counting,  we propose to condition diffusion models \u6761\u4ef6\u6269\u6563\u6a21\u578b not only on text prompts but also on counting density maps \u6587\u672c\u63d0\u793a+\u5bc6\u5ea6\u56fe to generate images with the correct number of objects \u751f\u6210\u6709\u6b63\u786e\u5bf9\u8c61\u6570\u91cf\u7684\u56fe\u7247 in the desired spatial configuration. \u5728\u671f\u671b\u7684\u7a7a\u95f4\u4f4d\u7f6e\u4e0a </p> <p>\u4e3a\u4e86\u5c06\u5408\u6210\u6570\u636e\u7684\u80fd\u529b\u7528\u4e8e\u8ba1\u6570\uff0c\u6211\u4eec\u63d0\u51fa\u4e0d\u4ec5\u5728\u6587\u672c\u63d0\u793a\u4e0a\uff0c\u800c\u4e14\u5728\u8ba1\u6570\u5bc6\u5ea6\u56fe\u4e0a\u5bf9\u6269\u6563\u6a21\u578b\u8fdb\u884c\u6761\u4ef6\u5316\uff0c\u4ee5\u751f\u6210\u6240\u9700\u7a7a\u95f4\u914d\u7f6e\u4e2d\u5177\u6709\u6b63\u786e\u6570\u91cf\u5bf9\u8c61\u7684\u56fe\u50cf\u3002</p> <p>We exploit this double control to generate diversified unseen data by prompting the model with novel combinations of the controls.</p> <p>\u6211\u4eec\u5229\u7528\u8fd9\u79cd\u53cc\u91cd\u63a7\u5236\u6765\u751f\u6210\u591a\u6837\u5316\u7684\u672a\u89c1\u6570\u636e\uff0c\u901a\u8fc7\u4f7f\u7528\u65b0\u7684\u63a7\u5236\u7ec4\u5408\u6765\u4fc3\u4f7f\u6a21\u578b\u3002</p> <p>Tip</p> <p>\u6211\u5199\u8fd9\u90e8\u5206\u6587\u732e\u7efc\u8ff0\u7684\u65f6\u5019\uff0c\u4e5f\u4eceGAN\u5f00\u59cb\uff0c\u5199\u5230diffusion\uff0c\u6700\u540e\u5230\u5173\u4e8e\u76ee\u6807\u8ba1\u6570</p> <p>\u7b2c\u4e8c\u6bb5</p> <p>\u7b2c\u4e8c\u90e8\u5206\uff1aFew-shot Object Counting \u5c0f\u6837\u672c\u8ba1\u6570\u7684\u53d1\u5c55</p> <p>CAC\u4efb\u52a1\u7684\u5b9a\u4e49</p> <p>The goal of few-shot class agnostic object counting is to count how many instances of objects of any arbitrary category there are in a given image, by leveraging only a few exemplars of the category of interest. </p> <p>\u6587\u732e1\uff1aFamNet</p> <p>This was initially formulated as matching exemplars and image patch features [21]. FSC147 [31] was later put forward as the main dataset for this task, with an open set train and test split to evaluate generalization to unseen object categories. Its authors introduced FamNet, a deep net trained to infer density maps from feature similarities.</p> <p>\u6587\u732e2\uff1aBMNet</p> <p>In the same lineage, BMNet [36] refines the similarity map by learning the similarity metric jointly with the counting network. </p> <p>\u6587\u732e3\uff1aSAFECount</p> <p>In SAFECount [41], the similarities are used to fuse exemplars features into the query image features. The density map is then predicted from the enhanced features.</p> <p>\u6587\u732e4\u30015\uff1aCounTR [6] and LOCA [9]</p> <p>Other works e.g. CounTR [6] and LOCA [9] focus on improving the feature representations using a Transformer backbone as the visual encoder and injecting information about the exemplars\u2019 shape in the network [9]. </p> <p>\u6587\u732e6\uff1a\u4e0e\u6211\u4eec\u5de5\u4f5c\u6700\u76f8\u5173\u7684\u6587\u732e Vicinal Couting Network from Rajan et al. [30]  \u2192 \u8bf4\u660e \u56fe\u50cf\u589e\u5f3a\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u8ba1\u6570\u6027\u80fd</p> <p>The closest comparison to our work is the Vicinal Couting Network from Rajan et al. [30]. It augments FSC147 with generated data by training a conditional GAN jointly with the counting network, producing augmentations that preserve the image content while modifying its visual appearance. While outperformed by later models, it introduced the idea that well-chosen augmentations can significantly boost counting accuracy. </p> <p>\u6211\u4eec\u7684\u5de5\u4f5c\uff1a\u591a\u6837\u6027\u5408\u6210\u7b56\u7565\uff1a\u4e0d\u4ec5\u5408\u6210\u5916\u89c2\uff0c\u8fd8\u53ef\u4ee5\u6539\u53d8\u5185\u5bb9\uff1b\u4f7f\u7528\u7684\u6587\u751f\u56fe\u7684\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b</p> <p>In this work, we leverage large pre-trained text-to-image diffusion models to produce diverse augmentations that not only alter the appearance, but are also able to change the content, to synthesize augmentations with a variety of object semantics.</p> <p>24\u00b711\u00b718</p> <p>todo\uff1amethod</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/","title":"rank8 CounTR","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 5081 \u4e2a\u5b57  33 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 25 \u5206\u949f</p> <p></p> <p>\u539f\u6587\u94fe\u63a5</p> <p>\u6e90\u7801\u94fe\u63a5</p> <p>\u671f\u520a\uff1aBMVC</p> <p></p> <ul> <li>\u53d1\u8868\u65f6\u95f4\uff1aBMVC2022 \u3010British Machine Vision Conference\u3011</li> <li>\u4f5c\u8005\uff1a\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\uff1bVGG \u89c6\u89c9\u51e0\u4f55\u7ec4 \u82f1\u56fd\u54c8\u4f5b\u5927\u5b66</li> <li> <p>arxiv\u65e5\u671f\uff1a2023\u5e742\u67082\u65e5\uff08\u5148\u53d1\u8868\u3001\u540e\u6302\u7684arxiv\uff09</p> </li> <li> <p>\u5f15\u7528\uff1a</p> </li> </ul> Text Only<pre><code>@inproceedings{liu2022countr,\n  author = {Chang, Liu and Yujie, Zhong and Andrew, Zisserman and Weidi, Xie},\n  title = {CounTR: Transformer-based Generalised Visual Counting},\n  booktitle={British Machine Vision Conference (BMVC)},\n  year = {2022}\n}\n</code></pre> <ul> <li>\u6587\u7ae0\u6807\u9898\uff1aCounTR: Transformer-based Generalised Visual Counting</li> </ul> <p>\u57fa\u4e8eTransformer\u7684\u901a\u7528\u3001\u6cdb\u5316\u89c6\u89c9\u8ba1\u6570</p> <ul> <li>\u672c\u6587\u53d1\u73b0\u4ec0\u4e48\u95ee\u9898\uff0c\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898\uff1f</li> </ul> <p></p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#_1","title":"\u2764 \u5168\u6587\u6982\u62ec","text":"<p>\u8bbe\u8ba1\u6a21\u5757\u3011\uff08\u5520\u5520\u53e8\u53e8\u8bf4\u4e86\u4e09\u904d\uff1b\u6458\u8981\u8bf4\u3001\u8d21\u732e\u8bf4\u3001\u7ed3\u8bba\u8bf4\uff09\uff1a</p> <ul> <li> <p>CountTR\uff1b</p> </li> <li> <p>\u4e24\u9636\u6bb5\u8bad\u7ec3\u3010why\uff1f\u3011\uff1b</p> </li> <li> <p>\u5408\u6210\u8bad\u7ec3\u56fe\u50cf\u3010input\u7684\u521b\u65b0\u3011\uff1b</p> </li> <li> <p>\u7ed3\u679csota</p> </li> </ul> <p>\u3010\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898? \u3011\uff1a\u8fd9\u7bc7\u6587\u7ae0\u597d\u50cf\u66f4\u5173\u6ce8\u76ee\u6807\u8ba1\u6570\u7684\u6cdb\u5316\u6027\u3002</p> <p>\u6838\u5fc3\u7684\u4e00\u53e5\u8bdd\uff1a</p> <p>\u2b50\ufe0f the generalised visual object counting problem of counting the number of objects from arbitrary semantic categories using arbitrary number of \u201cexemplars\u201d</p> <p>\u2b50\ufe0f Any shot counting</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#_2","title":"\u6458\u8981","text":"<p>\u672c\u6587\u6838\u5fc3\uff1a</p> <ul> <li> <p>\u901a\u7528\u89c6\u89c9\u7269\u4f53\u8ba1\u6570</p> </li> <li> <p>\u5bf9\u4e8e\u4efb\u610f\u7c7b\u522b\u3001\u7ed9\u5b9a\u4efb\u610f\u793a\u4f8b</p> </li> </ul> <p>In this paper, we consider the problem of generalised visual object counting, with the goal of developing a computational model for counting the number of objects from arbitrary semantic categories, using arbitrary number of \u201cexemplars\u201d, i.e. zero-shot or few shot counting. </p> <p>\u56db\u4e2a\u8d21\u732e\uff1a</p> <p>To this end, we make the following four contributions:</p> <ol> <li>We introduce a novel transformer-based architecture for generalised visual object counting, termed as Counting TRansformer (CounTR), which explicitly captures the similarity between image patches or with given \u201cexemplars\u201d using the attention mechanism; </li> <li>We adopt a two-stage training regime, that first pre-trains the model with self-supervised learning, and followed by supervised fine-tuning; </li> <li>We propose a simple, scalable pipeline for synthesizing training images with a large number of instances or that from different semantic categories, explicitly forcing the model to make use of the given \u201cexemplars\u201d; </li> <li>We conduct thorough ablation studies on the large-scale counting benchmark, e.g. FSC147, and demonstrate state-of-the-art performance on both zero and few-shot settings. Project page: https://verg-avesta.github.io/CounTR_Webpage/.</li> </ol> <p>\u672c\u6587\u7f3a\u9677\uff1a\u540e\u9762\u7684CACViT\u5bf9\u6bd4\u8fd9\u7bc7\u8bba\u6587</p> <p>\u4e24\u9636\u6bb5 extract-then-match  \u2192 \u5355\u4e00\u9636\u6bb5\uff0c\u540c\u65f6 extract-and-match</p> <p>\u56db\u4e2a\u8d21\u732e\uff1a</p> <ol> <li>\u57fa\u4e8eTransformer\u7684\u89c6\u89c9\u8ba1\u6570\u67b6\u6784\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6355\u6349\u56fe\u50cf\u5757\u548c\u793a\u4f8b\u7684\u76f8\u4f3c\u6027</li> <li>\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a</li> <li>\u7b2c\u4e00\u9636\u6bb5\uff1a\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u9884\u8bad\u7ec3\u6a21\u578b</li> <li>\u7b2c\u4e8c\u9636\u6bb5\uff1a\u76d1\u7763\u3001\u5fae\u8c03</li> <li>\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u3001\u53ef\u4f38\u7f29\u7684\u3001\u80fd\u591f\u5408\u6210\u8bad\u7ec3\u56fe\u50cf\u7684\uff0c\u5927\u91cf\u5b9e\u4f8b\u3001\u6765\u81ea\u4e0d\u540c\u7684\u8bed\u4e49\u7c7b\u522b\u3001\u4f7f\u5f97\u6a21\u578b\u5145\u5206\u5229\u7528\u7ed9\u5b9a\u793a\u4f8b</li> <li>\u6d88\u878d\u5b9e\u9a8c</li> </ol> <p>\u5bf9\uff01\u5c31\u662f\u8fd9\u7bc7\u8bba\u6587\uff0c\u56db\u5f20\u56fe\u7247\u62fc\u63a5\u8fdb\u884c\u56fe\u50cf\u5408\u6210\uff01\u628a\u8fd9\u7bc7\u8bba\u6587\u548cSemAug CounTR\u533a\u5206\uff1b</p> <ul> <li>\u90fd\u662f\u5408\u6210\u56fe\u50cf\uff0c\u672c\u6587\u7528\u7684\u662f\u88c1\u526a\u3001\u62fc\u63a5\u3001\u6df7\u5408\u3001\u7f29\u653e</li> <li>\u8bed\u4e49\u589e\u5f3a\u7684SemAug CounTR\u7528\u7684\u662f\uff1aStable duffusion</li> </ul> <p></p> <p>\u7ffb\u8bd1\u4e00\u4e0b\u8fd9\u91cc\u7684\u6587\u5b57\uff1a\u5408\u6210\u8bad\u7ec3\u56fe\u50cf\u7684\u5904\u7406\u6d41\u7a0b</p> <p>(1) \u4ee3\u8868\u88c1\u526a\u548c\u7f29\u653e</p> <p>(2) \u4ee3\u8868\u62fc\u8d34\u548c\u6df7\u5408</p> <p>\u5728\u63a5\u4e0b\u6765\u7684\u90e8\u5206\u4e2d\uff0c\u6211\u4eec\u5c06\u88c1\u526a\u3001\u7f29\u653e\u548c\u62fc\u8d34\u5408\u5e76\u4e3a\u62fc\u8d34\u9636\u6bb5\u3002Type A \u4f7f\u7528\u56db\u5f20\u4e0d\u540c\u7684\u56fe\u50cf\u6765\u63d0\u9ad8\u80cc\u666f\u591a\u6837\u6027\uff0c\u800c Type B \u53ea\u4f7f\u7528\u4e00\u5f20\u56fe\u50cf\u6765\u589e\u52a0\u56fe\u50cf\u4e2d\u5305\u542b\u7684\u7269\u4f53\u6570\u91cf\u3002\u767d\u8272\u9ad8\u5149\u533a\u57df\u662f\u7ecf\u8fc7\u9ad8\u65af\u6ee4\u6ce2\u540e\u7684\u70b9\u6ce8\u91ca\u5bc6\u5ea6\u56fe\uff0c\u7528\u4e8e\u53ef\u89c6\u5316\u3002</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#_3","title":"\u603b\u7ed3\u6458\u8981","text":"<ul> <li> <p>\u8003\u8651\u7684\u95ee\u9898\uff1a\u89c6\u89c9\u76ee\u6807\u8ba1\u6570\u7684\u6cdb\u5316\u6027</p> </li> <li> <p>\u76ee\u7684\u662f\u4e3a\u4e86\u8bbe\u8ba1\u4e00\u4e2a\u6a21\u578b\uff1a\u7ed9\u5b9a\u4efb\u610f\u6570\u91cf\u7684\u793a\u4f8b\u6846\uff0c\u8ba1\u6570 \u4efb\u610f\u7684\u8bed\u4e49\u7269\u4f53   </p> </li> </ul> <p>\u6211\u4eec\u7684\u6a21\u578b\u65e2\u9002\u7528\u4e8e0-shot\u60c5\u5f62 \u4e5f\u9002\u5408 few-shot\u60c5\u5f62</p> <ul> <li>4\u4e2a\u8d21\u732e\uff1a</li> </ul> <ol> <li> <p>\u8bbe\u8ba1\u4e00\u4e2a\u65b0\u7684Transformer\u67b6\u6784 \u2192 \u6355\u6349\u56fe\u50cfpatch \u4e0e \u793a\u4f8b\u6846\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027</p> </li> <li> <p>\u91c7\u7528\u4e24\u9636\u6bb5\u8fdb\u884c\u8bad\u7ec3</p> Text Only<pre><code>\u7b2c\u4e00\u6b65\uff1a\u81ea\u76d1\u7763\u5b66\u4e60\u9884\u8bad\u7ec3\u6a21\u578b\n\u7b2c\u4e8c\u6b65\uff1a\u76d1\u7763\u5b66\u4e60\u8fdb\u884c\u5fae\u8c03\n</code></pre> </li> <li> <p>\u8bbe\u8ba1\u4e86\u4e00\u4e2apipeline\uff0c\u7528\u4e8e\u5408\u6210\u8bad\u7ec3\u56fe\u50cf</p> <ol> <li> <p>\u3010\u4ec0\u4e48\u6837\u7684\u8bad\u7ec3\u56fe\u50cf\uff1f\u3011</p> Text Only<pre><code>\u6709\u5927\u91cf\u5b9e\u4f8b\n \u6765\u81ea\u4e0d\u540c\u7684\u8bed\u4e49\u7c7b\u522b\n</code></pre> </li> <li> <p>\u3010\u4e3a\u4ec0\u4e48\u8fd9\u4e48\u505a\uff1f\u3011</p> <ol> <li>\u5f3a\u8feb\u6a21\u578b\u4f7f\u7528 \u7ed9\u5b9a\u7684\u793a\u4f8b\u6846</li> </ol> <p>\u3010\u793a\u4f8b\u6846\u4e3a\u4ec0\u4e48\u52a0\u5f15\u53f7\uff1f\u3011</p> </li> </ol> </li> <li> <p>\u3010\u7ed3\u679c\u3011\u5728FSC147\u6570\u636e\u96c6\u4e0a\u505a\u6d88\u878d\u5b9e\u9a8c\uff0c\u57280-shot  &amp; 1-shot\u4e0a\u90fd\u8fbe\u5230\u4e86SOTA</p> </li> </ol> <ul> <li>\u4ee3\u7801\u516c\u5f00\u3001\u81ea\u5df1\u505a\u4e86\u4e2a\u7f51\u9875\uff1ahttps://verg-avesta.github.io/CounTR_Webpage/</li> </ul>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#-","title":"\u5f15\u5165-\u8d21\u732e","text":"<p>\uff08\u539f\u6587\uff09To summarise, in this paper, we make four contributions: </p> <p>First, we introduce an architecture for generalised visual object counting based on transformer, termed as CounTR (pronounced as counter). It exploits the attention mechanisms to explicitly capture the similarity between image patches, or with the few-shot instance \u201cexemplars\u201d provided by the end user; </p> <p>Second, we adopt a two-stage training regime (self-supervised pre-training, followed by supervised fine-tuning) and show its effectiveness for the task of visual counting; </p> <p>Third, we propose a simple yet scalable pipeline for synthesizing training images with a large number of instances, and demonstrate that it can significantly improve the performance on images containing a large number of object instances; </p> <p>Fourth, we conduct thorough ablation studies on the large-scale counting benchmark, e.g. FSC-147 [24], and demonstrate state-of-the-art performance on both zero-shot and few-shot settings, improving the previous best approach by over 18.3% on the mean absolute error of the test set.</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#-_1","title":"\u603b\u7ed3 \u5f15\u5165-\u8d21\u732e","text":"<p>\u6211\u4eec\u7684\u6a21\u578b\u67094\u4e2a\u8d21\u732e\uff1a</p> <ol> <li> <p>\u3010\u65b0\u7684\u7f51\u7edc\u67b6\u6784\u3011CounTR : \u57fa\u4e8eTransformer\uff1b\u5173\u6ce8\u53ef\u89c1\u7269\u4f53\u7684\u6cdb\u5316 \u8ba1\u6570\u80fd\u529b\uff0c\u8fd9\u8868\u660e\uff1a</p> </li> <li> <p>\u6ce8\u610f\u529b\u673a\u5236\u80fd\u6e05\u695a\u5730\u6355\u6349\u5230image patches\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027</p> </li> <li> <p>\u6216\u8005 few-shot\u4efb\u52a1\u4e2d\uff0c\u7ed9\u5b9a\u793a\u4f8b\u6846\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027</p> </li> <li> <p>\u3010\u4e24\u9636\u6bb5\u8bad\u7ec3\u3011\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f</p> </li> <li> <p>\u81ea\u76d1\u7763\u5b66\u4e60\u8fdb\u884c\u9884\u8bad\u7ec3</p> </li> <li>\u76d1\u7763\u5b66\u4e60\u8fdb\u884c\u5fae\u8c03</li> </ol> <p>\u5e76\u9a8c\u8bc1\u4e86\u8fd9\u4e2a\u65b9\u6cd5 \u5bf9\u4e8e\u89c6\u89c9\u8ba1\u6570\u4efb\u52a1\u7684\u6709\u6548\u6027</p> <ol> <li> <p>\u3010\u5408\u6210\u56fe\u7247\u3011\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355 \u5e76\u4e14\u5c3a\u5ea6\u53ef\u53d8\u7684 pipeline \u6765\u5408\u6210\u6709\u5927\u91cf\u5b9e\u4f8b\u7684 \u8bad\u7ec3\u56fe\u7247\uff1b\u5e76\u8868\u660e \u5b83\u80fd\u663e\u8457\u63d0\u9ad8 \u6a21\u578b  \u56fe\u50cf\u5728\u6709\u5927\u91cf\u8ba1\u6570\u5bf9\u8c61\u7684\u60c5\u51b5\u4e0b\u7684 \u8ba1\u6570\u6027\u80fd</p> </li> <li> <p>\u3010\u7ed3\u679c\u3011\u6211\u4eec\u5728\u5927\u89c4\u6a21\u8ba1\u6570benchmark\u4e0b\uff0c\u8fdb\u884c\u4e86\u6574\u4e2a\u6d88\u878d\u5b9e\u9a8c\uff0c\u6bd4\u5982FSC147\u6570\u636e\u96c6</p> </li> <li> <p>\u6211\u4eec\u7684\u7ed3\u679c\uff1a0-shot\u30011-shot \u90fd\u662fsota</p> </li> <li>\u5177\u4f53\u6765\u8bf4\uff1aMAE\uff1b test set \uff1b\u4e4b\u524d\u6700\u597d\u7684\u65b9\u6cd5 \u63d0\u5347\u8d8518.3%</li> </ol>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#_4","title":"\u7ed3\u8bba","text":"<p>\u539f\u6587\uff1a</p> <p>In this work, we aim at the generalised visual object counting problem of counting the number of objects from arbitrary semantic categories using arbitrary number of \u201cexemplars\u201d. We propose a novel transformer-based architecture for it, termed as CounTR. It is first pretrained with self-supervised learning, and followed by supervised fine-tuning. We also propose a simple, scalable pipeline for synthesizing training images that can explicitly force the model to make use of the given \u201cexemplars\u201d. Our model achieves state-of-the-art performance on both zero-shot and few-shot settings.</p> <p>\u3010\u518d\u6b21\u91cd\u7533\u672c\u6587\u7684\u7814\u7a76target\u3011</p> <p>\u6458\u8981\u548c\u7ed3\u8bba\u90fd\u5728\u5f3a\u8c03</p> <p>\u6211\u4eec\u7684\u6a21\u578b\u81f4\u529b\u4e8e\uff1a\u4e00\u822c\u5316\u7684\u89c6\u89c9\u7269\u4f53\u8ba1\u6570\u95ee\u9898</p> <p>\u5177\u4f53\u6765\u8bf4\u5c31\u662f\uff1a  \u4f7f\u7528\u4efb\u610f\u6570\u91cf\u7684\u6837\u4f8b \u8ba1\u6570 \u4efb\u610f\u8bed\u4e49\u7c7b\u522b\u7684\u5bf9\u8c61\u6570\u91cf</p> <p>\u56e0\u6b64\uff0c</p> <p>\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a \u65b0\u7684 \u57fa\u4e8eTransformer\u7684\u67b6\u6784 \u53eb CountTR\uff0c</p> <p>CountTR =\u300b \u4e24\u9636\u6bb5\u8bad\u7ec3 = \u81ea\u76d1\u7763\u5b66\u4e60 \u9884\u8bad\u7ec3  + \u76d1\u7763\u5b66\u4e60 \u5fae\u8c03</p> <p>pipeline\uff1a\u5408\u6210\u8bad\u7ec3\u56fe\u50cf  =\u300b\u662f\u7684\u6a21\u578b\u80fd\u591f\u5229\u7528\u7ed9\u5b9a\u7684 \u6837\u4f8b</p> <p>0-shot\u3001few-shot \u90fd\u662f sota</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#_5","title":"\u968f\u624b\u8bb0","text":"<p>scalable\uff1a\u53ef\u4f38\u7f29\u7684</p> <p>pipeline\uff1a\u6574\u4e2a\u6570\u636e\u5904\u7406\u548c\u6a21\u578b\u8bad\u7ec3\u7684\u6d41\u7a0b\u3001\u7aef\u5230\u7aef\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u6db5\u76d6\u4e86\u4ece\u539f\u59cb\u6570\u636e\u5230\u6700\u7ec8\u7ed3\u679c\u7684\u5168\u8fc7\u7a0b</p> <p>pipeline\u662f\u6574\u4e2a\u6d41\u7a0b\u7684\u6982\u8ff0</p> <p>backbone\u662f\u6a21\u578b\u4e2d\u7684\u5173\u952e\u7279\u5f81\u63d0\u53d6\u90e8\u5206</p> <p>benchmark\u662f\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u7684\u6807\u51c6\u6d4b\u8bd5\u548c\u6307\u6807</p> <p>mosaic training data generation, namely, collage and blending</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#_6","title":"\u5f15\u5165","text":"<p>\u7b2c\u4e00\u6bb5\uff1a\u5c0f\u4e8e5\u7684\u80fd\u5feb\u901f\u8ba1\u6570\uff0c\u6570\u91cf\u589e\u591a\u8ba1\u6570\u80fd\u529b\u6025\u5267\u4e0b\u964d</p> <p>Despite all the exceptional abilities, the human visual system is particularly weak in counting objects in the image. In fact, given a visual scene with a collection of objects, one can only make a rapid, accurate, and confident judgment if the number of items is below five, with an ability termed as subitizing [16]. While for scenes with an increasing number of objects, the accuracy and confidence of the judgments tend to decrease dramatically. Until at some point, counting can only be accomplished by calculating estimates or enumerating the instances, which incurs low accuracy or tremendous time cost.</p> <p>\u7b2c\u4e8c\u6bb5\uff1a\u6211\u4eec\u6587\u7ae0\u7684\u76ee\u6807 \u901a\u7528\u89c6\u89c9\u7269\u4f53\u8ba1\u6570\u7cfb\u7edf</p> <p>In this paper, our goal is to develop a generalised visual object counting system, that augments humans\u2019 ability for recognising the number of objects in a visual scene. .......</p> <p>To this end, we propose a novel architecture that transforms the input image (with the few-shot annotations if any) into a density map, and the final count can be obtained by simply summing over the density map.</p> <p>\u7b2c\u4e09\u6bb5\uff1a</p> <p>Specifically, we take inspiration from Lu et al. [19] that self-similarity is a strong prior in visual object counting, and introduce a transformer-based architecture where the self-similarity prior can be explicitly captured by the built-in attention mechanisms, both among the input image patches and with the few-shot annotations (if any).</p> <p>\u89c6\u89c9\u7269\u4f53\u7684\u81ea\u76f8\u4f3c\u6027\uff1bTransformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u80fd\u6355\u6349\u56fe\u50cf\u5757\u548c\u793a\u4f8b\u7684\u81ea\u76f8\u4f3c\u6027</p> <p>We propose a two-stage training scheme, with the transformer-based image encoder being firstly pre-trained with self-supervision via masked image modeling [11], followed by supervised fine-tuning for the task at hand.</p> <p>\u4e24\u9636\u6bb5\u8bad\u7ec3\u6a21\u5f0f\uff1b</p> <p>\u57fa\u4e8eTransformer\u7684\u56fe\u50cf\u7f16\u7801\u5668\u9996\u5148\u901a\u8fc7\u63a9\u7801\u56fe\u50cf\u5efa\u6a21\u8fdb\u884c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3</p> <p>\u7136\u540e\u5bf9\u624b\u5934\u7684\u4efb\u52a1\u8fdb\u884c\u6709\u76d1\u7763\u7684\u5fae\u8c03\u3002</p> <p>We demonstrate that self-supervised pre-training can effectively learn the visual representation for counting, thus significantly improving the performance. </p> <p>\u6211\u4eec\u8bc1\u660e\u4e86\u81ea\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u80fd\u6709\u6548\u5b66\u4e60\u8ba1\u6570\u7684\u89c6\u89c9\u8868\u793a\u3001\u5e76\u63d0\u9ad8\u6027\u80fd</p> <p>Additionally, to tackle the long-tailed challenge in existing generalised visual object counting datasets, where the majority of images only contain a small number of objects, we propose a simple, yet scalable pipeline for synthesizing training images with a large number of instances, as a consequence, establishing reliable data sources for model training, to condition the user provided instance exemplars.\uff08\u53e5\u5b50\u662f\u771f\u957f\uff09</p> <p>\u2b50\ufe0f \u4e3a\u4e86\u89e3\u51b3 \u73b0\u6709\u901a\u7528\u89c6\u89c9\u76ee\u6807\u8ba1\u6570\u6570\u636e\u96c6\u7684 \u4e00\u76f4\u5b58\u5728\u7684\u95ee\u9898\uff0c\u90a3\u5c31\u662f \u5927\u591a\u6570\u8bad\u7ec3\u56fe\u50cf\u53ea\u5305\u542b\u4e00\u5c0f\u90e8\u5206\u6570\u91cf\u7684\u7269\u4f53\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u7b80\u5355\u7684\u3001\u53ef\u4f38\u7f29\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u5408\u6210\u542b\u6709\u5927\u91cf\u5b9e\u4f8b\u7684\u8bad\u7ec3\u56fe\u7247\u2192\u5efa\u7acb\u4e86\u53ef\u9760\u7684\u6570\u636e\u96c6 \u7528\u4e8e\u6a21\u578b\u8bad\u7ec3</p> <p>\u7b2c\u56db\u6bb5\uff1a\u8d21\u732e</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#_7","title":"\u76f8\u5173\u5de5\u4f5c","text":"<p>\u76f8\u5173\u5de5\u4f5c\u5c31\u4e24\u6bb5\uff1a</p> <ul> <li>\u89c6\u89c9\u7269\u4f53\u8ba1\u6570</li> <li>\u7c7b\u65e0\u5173\u76ee\u6807\u8ba1\u6570</li> </ul> <p>\u7b2c\u4e00\u6bb5\uff1aVisual object counting. </p> <p>\u9996\u5148\u6307\u51fa\uff0c\u76ee\u6807\u8ba1\u6570\u95ee\u9898\u7684\u65b9\u6cd5\u5206\u6210\u4e24\u7c7b\uff1a\u57fa\u4e8e\u68c0\u6d4b\u7684\u548c\u57fa\u4e8e\u56de\u5f52\u7684</p> <p>In the literature, object counting approaches can generally be cast into two categories: detection-based counting [3, 5, 13] or regression-based counting [1, 2, 4, 15, 17, 20, 29]. </p> <p>\u57fa\u4e8e\u68c0\u6d4b\u7684......</p> <p>The former relies on a visual object detector that can localize object instances in an image. This method, however, requires training individual detectors for different objects, and the detection problem remains challenging if only a small number of annotations are given. </p> <p>\u57fa\u4e8e\u56de\u5f52\u7684......\u5c06\u56fe\u50cf\u6620\u5c04\u6210\u6807\u91cf\uff0c\u6216\u8005\u5c06\u56fe\u50cf\u6620\u5c04\u6210\u5bc6\u5ea6\u56fe</p> <p>The latter avoids solving the hard detection problem, instead, methods are designed to learn either a mapping from global image features to a scalar (number of objects), or a mapping from dense image features to a density map, achieving better results on counting overlapping instances. </p> <p>\u4f46\u662f\u6307\u51fa\u95ee\u9898\uff0c\u5148\u524d\u7684\u8ba1\u6570\u65b9\u6cd5\u4e0d\u7ba1\u662f\u57fa\u4e8e\u68c0\u6d4b\u7684\u8fd8\u662f\u57fa\u4e8e\u56de\u5f52\u7684\uff0c\u90fd\u53ea\u80fd\u8ba1\u6570\u7279\u5b9a\u7c7b\u522b\u7684\u7269\u4f53\uff0c\u6240\u4ee5\u5f15\u51fa\u7b2c\u4e8c\u6bb5\uff0c\u7c7b\u65e0\u5173\u8ba1\u6570</p> <p>However, previous methods from both lines (detection, regression) have only been able to count objects of one particular class (e.g. cars, cells).</p> <p>\u7b2c\u4e8c\u6bb5 Class-agnostic object counting. </p> <p>\u7ed9\u51fa\u95ee\u9898\u5b9a\u4e49</p> <p>Recently, class-agnostic few-shot counting [19, 24, 30] has witnessed a rise in research interest in the community. Unlike the class-specific models that could only count objects of specific classes like cars, cells, or people, class-agnostic counting aims to count the objects in an image based on a few given \u201cexemplar\u201d instances,thus is also termed as few-shot counting. </p> <p>\u76ee\u6807\uff1a\u8bad\u7ec3\u9636\u6bb5\uff0c\u6316\u6398\u4e0d\u540c\u7c7b\u522b\u76ee\u6807\u7684\u5171\u6027</p> <p>Generally speaking, class-agnostic few-shot counting models need to mine the commonalities between the counts of different classes of objects during training. </p> <p>\u6587\u732e GMN</p> <p>In [19], the authors propose a generic matching network (GMN), which regresses the density map by computing the similarity between the CNN features from image and exemplar shots; </p> <p>FamNet </p> <p>FamNet [24] utilizes feature correlation for prediction and uses adaptation loss to update the model\u2019s parameters at test time; </p> <p>SAFECount</p> <p>SAFECount [30] uses the support feature to enhance the query feature, making the extracted features more refined and then regresses to obtain density maps; </p> <p>[12]</p> <p>In a very recent work [12], the authors exploit a pre-trained DINO [21] model and a lightweight regression head to count without exemplars. </p> <p></p> <p>\u672c\u6587\uff1a\u57fa\u4e8eTransformer\u7684\uff0cCounTR</p> <p>In this paper, we also use transformer-based architecture, however, train it from scratch, and augment it with the ability to count the objects with any shot.</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#3-methods","title":"3 Methods","text":"<p>\u672c\u6587\u4e3b\u8981\u8003\u8651 \u6cdb\u5316\u7269\u4f53\u8ba1\u6570</p> <p>\u8ba1\u6570\u56fe\u7247\u4e2d\u4efb\u610f\u7c7b\u522b\u7684\u7269\u4f53\uff0c\u4f7f\u7528\u4efb\u610f\u6570\u91cf\u7684\u6837\u4f8b\u6846\uff0c\u6837\u4f8b\u6846\u7684\u6570\u91cf\u4ece0~few</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#overview","title":"Overview","text":"<p>\u7b26\u53f7\u8bf4\u660e\uff1a</p> <ul> <li> <p>\\(\\mathcal{D_{train}}={(\\mathcal{X_1,S_1,y_1}),...,(\\mathcal{X_N,S_N,y_N})}\\)</p> </li> <li> <p>\u8f93\u5165\u56fe\u7247\uff1a \\(\\mathcal{X_i} \\in \\mathbb{R}^{H \\times W \\times3}\\)</p> </li> <li> <p>\u6837\u4f8b\u6846\u7b26\u53f7\u8bf4\u660e\uff1a</p> <ul> <li>\\(\\mathcal{S_i} = \\{b_i\\}^K\\) exemplar \u793a\u4f8b\u6846</li> <li>\\(b_i^k \\in \\mathbb{R}^4\\) </li> <li>\\(K \\in \\{0,1,2,3....\\}\\)</li> </ul> </li> <li> <p>\\(y_i \\in \\mathbb{R}^{H \\times W \\times 1}\\)</p> </li> <li> <p>\\(\\mathcal{D_{test}}={(\\mathcal{X_{N+1},S_{N+1}}),...,(\\mathcal{X_M,S_M})}\\)</p> </li> <li> <p>disjoint</p> </li> </ul> <p></p> <ul> <li>\u57fa\u4e8eTransformer\u7684\u8ba1\u6570\u6a21\u578b\uff0c\u6240\u4ee5\u53ebCounTR</li> <li>Transformer\u4e2d\u7684\u6ce8\u610f\u529b\u673a\u5236\u80fd\u591f\u663e\u5f0f\u5730\u6bd4\u8f83\u4efb\u4f55\u5176\u4ed6\u7a7a\u95f4\u4f4d\u7f6e\u548c\"\u6837\u4f8b\"\u4e4b\u95f4\u7684\u89c6\u89c9\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u662f\u7531\u6700\u7ec8\u7528\u6237\u5728\u5c0f\u6837\u672c\u573a\u666f\u4e2d\u63d0\u4f9b\u7684</li> <li>3.2\u8282 \u4ecb\u7ecd\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u7684\u8bad\u7ec3\u673a\u5236\uff0c\u5373\u9996\u5148\u901a\u8fc7\u63a9\u7801\u56fe\u50cf\u91cd\u5efa( MAE )\u8fdb\u884c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5728\u4e0b\u6e38\u8ba1\u6570\u4efb\u52a1\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5c55\u793a\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5bf9\u901a\u7528\u89c6\u89c9\u5bf9\u8c61\u8ba1\u6570\u7684\u6709\u6548\u6027\u7684\u5de5\u4f5c</li> <li>3.3\u8282  \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u53ef\u6269\u5c55\u7684\u56fe\u50cf\u5408\u6210\u67b6\u6784\uff1b\u4ee5\u89e3\u51b3\u73b0\u6709\u7269\u4f53\u8ba1\u6570\u6570\u636e\u96c6\u4e2d\u957f\u5c3e\u5206\u5e03(\u4e5f\u5c31\u662f\u8bf4,\u5177\u6709\u5927\u91cf\u5b9e\u4f8b\u7684\u56fe\u50cf\u5f80\u5f80\u662f\u4e0d\u9891\u7e41\u7684)\u7684\u6311\u6218</li> <li>3.4\u8282 \u5c06\u4ecb\u7ecd\u6d4b\u8bd5\u65f6\u95f4\u6b63\u89c4\u5316\u65b9\u6cd5\uff0c\u5305\u62ec\u6d4b\u8bd5\u65f6\u95f4\u6b63\u89c4\u5316\u548c\u6d4b\u8bd5\u65f6\u95f4\u88c1\u526a(?)</li> </ul>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#31-architecture","title":"3.1 Architecture","text":"<ul> <li>\u89c6\u89c9\u7279\u5f81\u7f16\u7801\u5668  \\(\\Phi_{VIT-ENC}(\\cdot)\\) \u3001\\(\\Phi_{CNN-ENC}(\\cdot)\\)</li> <li>\u7279\u5f81\u4ea4\u4e92\u6a21\u5757</li> <li>\u89e3\u7801\u5668</li> </ul> <ul> <li>\u56fe\u50cf\u7279\u5f81\uff1aquery</li> <li> <p>\u793a\u4f8b\u6846\u7279\u5f81\uff1akey &amp; value</p> </li> <li> <p>\u6ca1\u6709\u793a\u4f8b\u6846\uff0c\u5c31\u6709\u4e2a\u53ef\u5b66\u4e60\u7684token\u4f5c\u4e3akey &amp; value</p> </li> </ul>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#311-visual-encoder","title":"3.1.1 Visual Encoder","text":"<p>\u89c6\u89c9\u7f16\u7801\u5668\u5305\u62ec\u4e24\u4e2a\u90e8\u5206</p> <ul> <li>\u57fa\u4e8eViT\u7684\u7f16\u7801\u5668\uff0c\u5904\u7406\u8f93\u5165\u56fe\u50cf\u7279\u5f81\uff0c\u6620\u5c04\u4e3a\u9ad8\u7ef4\u7279\u5f81\u56fe</li> <li>\u8ba1\u7b97\u793a\u4f8b\u6846\u7684\u89c6\u89c9\u7279\u5f81</li> <li>\u5bf9\u4e8eViT\u6765\u8bf4\uff0c\u8f93\u5165\u56fe\u7247\u5212\u5206\u621016\u00d716\u7684patches</li> <li> <p>12\u5c42\uff0c\u4f7f\u7528\u4e86\u4f4d\u7f6e\u7f16\u7801\uff0c\u6ca1\u6709cls token</p> </li> <li> <p>ViT\u7684\u8f93\u51fa\u662f\u4e00\u4e2ad\u7ef4\u5411\u91cf</p> </li> </ul> <p></p> <p></p> <p>CNN\u63d0\u53d6\u793a\u4f8b\u6846\u7279\u5f81</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#312-feature-interaction-module","title":"3.1.2 Feature Interaction Module","text":"<ul> <li>\u7279\u5f81\u4ea4\u4e92\u6a21\u5757 \u878d\u5408\u4fe1\u606f</li> <li>\u7531\u4e00\u7cfb\u5217\u89e3\u7801\u5668\u7ec4\u6210</li> <li>\u56fe\u50cf\u7279\u5f81\u4f5c\u4e3aquery\u3001\u6837\u672c\u7279\u5f81 \u7ecf\u8fc7\u4e24\u4e2a\u4e0d\u540c\u7684\u7ebf\u6027\u5c42 \u5904\u7406\uff0c\u5f97\u5230 key \u548c value</li> <li>FIM\u7684\u8f93\u51fa \u548c \\(\\mathcal{F_{VIT}}\\) \u7684\u8f93\u51fa\u4fdd\u6301\u76f8\u540c\u7684\u7ef4\u5ea6</li> </ul> <p>\u603b\u7ed3\u4e00\u4e0b\uff0c\u516c\u5f0f\uff1a</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#313-decoder","title":"3.1.3 Decoder","text":"<ul> <li> <p>\u7279\u5f81\u4ea4\u4e92\u6a21\u5757\u7684\u8f93\u51fa\u7ed3\u679c\u88ab\u8fdb\u4e00\u6b65\u91cd\u5851\u56de\u4e8c\u7ef4\u7279\u5f81\u56fe\uff0c\u5e76\u6062\u590d\u5230\u539f\u59cb\u5206\u8fa8\u7387\u4f5c\u4e3a\u8f93\u5165\u56fe\u50cf</p> </li> <li> <p>\u91c7\u7528\u6e10\u8fdb\u5f0f\u4e0a\u91c7\u6837\u8bbe\u8ba1\uff0c\u9996\u5148\u5c06\u5411\u91cf\u5e8f\u5217\u91cd\u5851\u4e3a\u7a20\u5bc6\u7684\u7279\u5f81\u56fe\uff0c\u7136\u540e\u901a\u8fc7\u57fa\u4e8eConvNet\u7684\u89e3\u7801\u5668\u8fdb\u884c\u5904\u7406\u3002</p> </li> </ul> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u4f7f\u7528\u4e864\u4e2a\u4e0a\u91c7\u6837\u5757\uff0c\u6bcf\u4e2a\u4e0a\u91c7\u6837\u5757\u7531\u4e00\u4e2a\u5377\u79ef\u5c42\u548c\u4e00\u4e2a2 \u00d7\u53cc\u7ebf\u6027\u63d2\u503c\u7ec4\u6210\u3002\u5728\u6700\u540e\u4e00\u6b21\u4e0a\u91c7\u6837\u4e4b\u540e\uff0c\u91c7\u7528\u7ebf\u6027\u5c42\u4f5c\u4e3a\u5bc6\u5ea6\u56de\u5f52\u5668\uff0c\u8f93\u51fa\u5355\u901a\u9053\u7684\u5bc6\u5ea6\u70ed\u56fe</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#32-two-stage-training-scheme","title":"3.2 Two-stage Training Scheme","text":"<p>\u6307\u51fa\u95ee\u9898\uff1a\u89c6\u89c9\u4fe1\u53f7\u662f\u9ad8\u5ea6\u5197\u4f59\u7684\uff0c\u7269\u4f53\u901a\u5e38\u4ee5\u76f8\u540c\u7684\u5f62\u5f0f\u591a\u6b21\u51fa\u73b0</p> <p>\u56e0\u6b64\u91c7\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668 \\(\\Phi_{VIT-ENC}(\\cdot)\\)</p> <p>\u91c7\u7528Masked\u81ea\u7f16\u7801\u5668( MAE )\u7684\u601d\u60f3\uff0c\u901a\u8fc7\u4ec5\u4f7f\u7528\u90e8\u5206\u89c2\u6d4b\u503c\u7684\u56fe\u50cf\u91cd\u5efa\u6765\u8bad\u7ec3\u6a21\u578b\u3002</p> <p></p> <p>\u5408\u6210\u8bad\u7ec3\u56fe\u50cf</p> <p>\u7b2c\u4e00\u6b65\uff0c\u88c1\u526a &amp; \u7f29\u653e</p> <p>\u7b2c\u4e8c\u6b65 \uff0c\u62fc\u63a5 &amp; \u6df7\u5408</p> <p>\u878d\u5408\u624d\u53eb\u3001\u7f29\u653e\u3001\u62fc\u63a5</p> <p>A\u7c7b\u4f7f\u75284\u5e45\u4e0d\u540c\u7684\u56fe\u50cf\u6765\u63d0\u9ad8\u80cc\u666f\u591a\u6837\u6027\uff0cB\u7c7b\u53ea\u4f7f\u7528\u4e00\u5e45\u56fe\u50cf\u6765\u589e\u52a0\u4e00\u5e45\u56fe\u50cf\u4e2d\u5305\u542b\u7684\u7269\u4f53\u6570\u91cf\u3002\u767d\u8272\u9ad8\u5149\u662f\u9ad8\u65af\u6ee4\u6ce2\u540e\u7528\u4e8e\u53ef\u89c6\u5316\u7684\u70b9\u6807\u6ce8\u5bc6\u5ea6\u56fe\u3002</p> <p></p> <p>\u81ea\u76d1\u7763\u9884\u8bad\u7ec3 \u63a9\u7801\u81ea\u7f16\u7801\u5668</p> <p>\u9996\u5148\u5c06\u56fe\u50cf\u5212\u5206\u4e3a\u89c4\u5219\u7684\u975e\u91cd\u53e0\u5757\uff0c\u5e76\u4e14\u53ea\u91c7\u6837\u5757( 50 %)\u7684\u5b50\u96c6\u4f5c\u4e3aViT\u7f16\u7801\u5668\u7684\u8f93\u5165\u3002</p> <p>\u8ba1\u7b97\u5f97\u5230\u7684\u7279\u5f81\u8fdb\u4e00\u6b65\u901a\u8fc7\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u89e3\u7801\u5668\u4f20\u9012\uff0c\u8be5\u89e3\u7801\u5668\u7531\u82e5\u5e72\u4e2a\u8f6c\u6362\u5668\u89e3\u7801\u5668\u5c42\u7ec4\u6210\uff0c\u5176\u4e2d\u53ef\u5b66\u4e60\u7684\u63a9\u7801token\u548c\u4f4d\u7f6e\u7f16\u7801\u7684\u7ec4\u5408\u88ab\u7528\u4f5cQuery\uff0c\u4ec5\u4ece\u89c2\u5bdf\u5230\u7684patch\u91cd\u5efa\u8f93\u5165\u56fe\u50cf\u3002</p> <p>\u8bad\u7ec3\u635f\u5931\u7b80\u5355\u5b9a\u4e49\u4e3a\u91cd\u5efa\u56fe\u50cf\u4e0e\u8f93\u5165\u56fe\u50cf\u5728\u50cf\u7d20\u7a7a\u95f4\u7684\u5747\u65b9\u8bef\u5dee( MSE )\u3002</p> <p></p> <p>\u6709\u76d1\u7763\u7684\u5fae\u8c03</p> <ul> <li>\u4f7f\u7528\u9884\u8bad\u7ec3\u7684ViT\u7684\u521d\u59cb\u6743\u91cd\uff0c\u521d\u59cb\u5316\u56fe\u50cf\u7f16\u7801\u5668</li> <li>\u5e76\u5bf9\u6211\u4eec\u63d0\u51fa\u7684\u901a\u7528\u7269\u4f53\u8ba1\u6570\u67b6\u6784\u8fdb\u884c\u5fae\u8c03</li> <li>\u6a21\u578b\u7684\u8f93\u5165\uff1a\u539f\u59cb\u56fe\u50cf \\(\\mathcal{X}_i\\) + \\(K\\) \u4e2a\u793a\u4f8b\u6846 \\(\\mathcal{S}_i =\\{b_i\\}\\)</li> <li>\u8f93\u51fa\u5bc6\u5ea6\u56fe \\(\\hat{y}_i \\in \\mathbb{R}^{H\u00d7W\u00d71}\\)</li> <li>\u56fe\u50cf \\(C_i \\in \\mathbb{R}\\) \u4e2d\u663e\u8457\u7269\u4f53\u7684\u7edf\u8ba1\u6570\u91cf \u901a\u8fc7\u5bf9 \u79bb\u6563\u5bc6\u5ea6\u56fe  \\(y_i\\) \u6c42\u548c\u5f97\u5230</li> <li>\u6211\u4eec\u4f7f\u7528\u6bcf\u4e2a\u50cf\u7d20\u7684\u5747\u65b9\u8bef\u5dee \u8ba1\u6570\u4f30\u8ba1\u5bc6\u5ea6\u56fe \\(\\hat{y_i}\\) \u548c\u771f\u5b9e \u5bc6\u5ea6\u56fe  \\(y_i\\) \u5dee\u5f02</li> <li>\u771f\u5b9e\u5bc6\u5ea6\u56fe\u7684\u751f\u6210\uff1a\u57fa\u4e8e\u70b9\u6ce8\u91ca</li> </ul>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#33-scalable-mosaicing","title":"3.3 Scalable Mosaicing","text":"<p>\u7f29\u653e\u62fc\u63a5\u6846\u67b6\u3001\u5408\u6210\u8bad\u7ec3\u56fe\u50cf\u3001\u5904\u7406\u957f\u5c3e\u6548\u5e94</p> <p>\u73b0\u6709\u7684\u6570\u636e\u96c6 \u76ee\u6807\u7269\u4f53\u7684\u6570\u91cf\u8f83\u5c11</p> <ul> <li>\u5728FSC - 147\u6570\u636e\u96c6\u4e2d\uff0c\u5728\u8bad\u7ec3\u96c6\u4e2d\u76843659\u5f20\u56fe\u50cf\u4e2d\uff0c\u4ec5\u67096\u5f20\u56fe\u50cf\u5305\u542b\u8d85\u8fc71000\u4e2a\u7269\u4f53\u3002\u8fd9\u53ef\u80fd\u662f\u7531\u4e8e\u63d0\u4f9b\u4eba\u5de5\u6ce8\u91ca\u7684\u6602\u8d35\u7a0b\u5e8f\u9020\u6210\u7684</li> <li>\u63a5\u4e0b\u6765\uff0c\u4ecb\u7ecd\u63d0\u51fa\u7684 \u5408\u6210\u8bad\u7ec3\u6570\u636e\u751f\u6210\u7684\u4e24\u4e2a\u6b65\u9aa4</li> </ul> <p></p> <p></p> <p>\u62fc\u63a5</p> <p>\u9996\u5148\u4ece\u56fe\u50cf\u4e2d\u88c1\u526a\u4e00\u4e2a\u968f\u673a\u5927\u5c0f\u7684\u6b63\u65b9\u5f62\u533a\u57df\uff0c\u5e76\u5c06\u5176\u7f29\u653e\uff0c\u4f8b\u5982\u539f\u59cb\u56fe\u50cf\u5927\u5c0f\u7684\u56db\u5206\u4e4b\u4e00\u3002\u5728\u591a\u6b21\u91cd\u590d\u533a\u57df\u88c1\u526a\u540e\uff0c\u6211\u4eec\u5c06\u88c1\u526a\u7684\u533a\u57df\u62fc\u8d34\u5728\u4e00\u8d77\u5e76\u66f4\u65b0\u76f8\u5e94\u7684\u5bc6\u5ea6\u56fe\u3002\u5b83\u6709\u4e24\u79cd\u4e0d\u540c\u7684\u5f62\u5f0f\uff1a\u53ea\u4f7f\u7528\u4e00\u5f20\u56fe\u50cf\u6216\u4f7f\u7528\u56db\u5f20\u4e0d\u540c\u7684\u56fe\u50cf\u3002</p> <p>\u5982\u679c\u6211\u4eec\u53ea\u4f7f\u7528\u4e00\u5f20\u56fe\u50cf\uff0c\u6211\u4eec\u53ef\u4ee5\u589e\u52a0\u56fe\u50cf\u4e2d\u5305\u542b\u7684\u5bf9\u8c61\u6570\u91cf\uff0c\u8fd9\u5728\u89e3\u51b3\u957f\u5c3e\u95ee\u9898\u4e0a\u975e\u5e38\u6709\u5e2e\u52a9\u3002\u5982\u679c\u6211\u4eec\u4f7f\u7528\u56db\u5f20\u4e0d\u540c\u7684\u56fe\u50cf\uff0c\u6211\u4eec\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u56fe\u50cf\u7684\u80cc\u666f\u591a\u6837\u6027\uff0c\u5e76\u589e\u5f3a\u6a21\u578b\u533a\u5206\u4e0d\u540c\u7c7b\u522b\u5bf9\u8c61\u7684\u80fd\u529b\u3002\u4e3a\u4e86\u5145\u5206\u5229\u7528\u8fd9\u4e24\u4e2a\u4f18\u52bf\uff0c\u6211\u4eec\u5236\u5b9a\u4e86\u4ee5\u4e0b\u8bbe\u7f6e\u3002\u5982\u679c\u56fe\u50cf\u4e2d\u5305\u542b\u7684\u5bf9\u8c61\u6570\u91cf\u8d85\u8fc7\u67d0\u4e2a\u9608\u503c\uff0c\u6211\u4eec\u4f7f\u7528\u76f8\u540c\u7684\u56fe\u50cf\u8fdb\u884c\u62fc\u8d34\uff1b\u5982\u679c\u6ca1\u6709\uff0c\u6211\u4eec\u4f7f\u7528\u56db\u5f20\u4e0d\u540c\u7684\u56fe\u50cf\u3002\u8bf7\u6ce8\u610f\uff0c\u5982\u679c\u4f7f\u7528\u4e86\u56db\u5f20\u4e0d\u540c\u7684\u56fe\u50cf\uff0c\u6211\u4eec\u53ea\u80fd\u4f7f\u7528\u5c11\u91cf\u6837\u672c\uff08few-shot\uff09\u8bbe\u7f6e\u8fdb\u884c\u63a8\u7406\uff0c\u5426\u5219\u6a21\u578b\u5c06\u4e0d\u77e5\u9053\u8981\u8ba1\u6570\u54ea\u4e2a\u5bf9\u8c61\u3002\u5982\u679c\u6211\u4eec\u4f7f\u7528\u76f8\u540c\u7684\u56fe\u50cf\uff0c\u62fc\u8d34\u540e\u7684\u56fe\u50cf\u53ef\u4ee5\u7528\u6765\u8bad\u7ec3\u5c11\u91cf\u6837\u672c\u8bbe\u7f6e\u548c\u96f6\u6837\u672c\uff08zero-shot\uff09\u8bbe\u7f6e\u3002</p> <p></p> <p></p> <p>\u56fe3. \u6d4b\u8bd5\u65f6\u5f52\u4e00\u5316\u8fc7\u7a0b\u7684\u53ef\u89c6\u5316\u3002\u5728\u6d4b\u8bd5\u65f6\u5f52\u4e00\u5316\u4e2d\uff0c\u5982\u679c\u5bc6\u5ea6\u56fe\u4e2d\u793a\u4f8b\u4f4d\u7f6e\u7684\u5e73\u5747\u603b\u548c\u8d85\u8fc71.8\uff0c\u5219\u5bc6\u5ea6\u56fe\u7684\u603b\u548c\u5c06\u9664\u4ee5\u8fd9\u4e2a\u5e73\u5747\u503c\u4ee5\u6210\u4e3a\u6700\u7ec8\u9884\u6d4b\u3002\u5728\u6d4b\u8bd5\u65f6\u88c1\u526a\u4e2d\uff0c\u5982\u679c\u81f3\u5c11\u6709\u4e00\u4e2a\u793a\u4f8b\u7684\u8fb9\u957f\u5c0f\u4e8e10\u50cf\u7d20\uff0c\u56fe\u50cf\u5c06\u88ab\u88c1\u526a\u62109\u4e2a\u90e8\u5206\uff0c\u6a21\u578b\u5c06\u5206\u522b\u5904\u7406\u8fd99\u4e2a\u56fe\u50cf\u3002\u6700\u7ec8\u9884\u6d4b\u5c06\u662f\u8fd99\u4e2a\u56fe\u50cf\u7ed3\u679c\u7684\u603b\u548c\u3002</p> <p></p> <p>\u6df7\u5408</p> <p>\u6df7\u5408\u3002\u7b80\u5355\u5730\u88c1\u526a\u548c\u62fc\u63a5\u5e76\u4e0d\u80fd\u5408\u6210\u5b8c\u7f8e\u7684\u56fe\u50cf\uff0c\u56e0\u4e3a\u8fb9\u754c\u4e4b\u95f4\u4ecd\u7136\u5b58\u5728\u660e\u663e\u7684\u4eba\u5de5\u75d5\u8ff9\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u4eba\u5de5\u75d5\u8ff9\uff0c\u6211\u4eec\u5229\u7528\u56fe\u50cf\u8fde\u63a5\u5904\u7684\u6df7\u5408\u6280\u672f\u3002\u5728\u5b9e\u8df5\u4e2d\uff0c\u6211\u4eec\u88c1\u526a\u7684\u56fe\u50cf\u5c3a\u5bf8\u7565\u5927\u4e8e\u539f\u59cb\u56fe\u50cf\u5c3a\u5bf8\u7684\u56db\u5206\u4e4b\u4e00\uff0c\u8fd9\u6837\u6211\u4eec\u53ef\u4ee5\u5728\u8fb9\u754c\u7559\u51fa\u7279\u5b9a\u7684\u7a7a\u95f4\u7528\u4e8e\u03b1\u901a\u9053\u6df7\u5408\u3002\u6211\u4eec\u4f7f\u7528\u968f\u673a\u7684\u03b1\u901a\u9053\u8fb9\u754c\u5bbd\u5ea6\uff0c\u8fd9\u4f7f\u5f97\u56fe\u50cf\u7684\u5408\u6210\u66f4\u52a0\u771f\u5b9e\u3002\u8bf7\u6ce8\u610f\uff0c\u6211\u4eec\u53ea\u6df7\u5408\u539f\u59cb\u56fe\u50cf\u800c\u4e0d\u662f\u5bc6\u5ea6\u56fe\uff0c\u4ee5\u4fdd\u6301\u70b9\u6ce8\u91ca\u7684\u5f62\u5f0f\uff08\u53ea\u67090\u548c1\uff09\u3002\u7531\u4e8e\u6df7\u5408\u8fb9\u754c\u5185\u7684\u5bf9\u8c61\u5f88\u5c11\uff0c\u4e14\u4f7f\u7528\u4e00\u5f20\u56fe\u50cf\u5236\u4f5c\u7684\u9a6c\u8d5b\u514b\u4ec5\u9002\u7528\u4e8e\u5bf9\u8c61\u6570\u91cf\u975e\u5e38\u591a\u7684\u56fe\u50cf\uff0c\u56e0\u6b64\u6df7\u5408\u5f15\u8d77\u7684\u8bef\u5dee\u51e0\u4e4e\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002</p>"},{"location":"literature/ObejectCounting/rank8%20CounTR/#34-test-time-normalisation","title":"3.4 Test-time Normalisation","text":"<p>\u5bf9\u4e8e\u5c11\u91cf\u6837\u672c\u8ba1\u6570\uff0c\u6211\u4eec\u5728\u6b63\u6587\u4e2d\u5f15\u5165\u4e86\u4e00\u79cd\u6d4b\u8bd5\u65f6\u7684\u5f52\u4e00\u5316\u7b56\u7565\u6765\u6821\u51c6\u8f93\u51fa\u5bc6\u5ea6\u56fe\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u63a8\u7406\u65f6\uff0c\u6211\u4eec\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\uff0c\u5373\u793a\u4f8b\u4f4d\u7f6e\u7684\u5bf9\u8c61\u8ba1\u6570\u5e94\u8be5\u6070\u597d\u662f1.0\uff0c\u56e0\u6b64\u4efb\u4f55\u9884\u6d4b\u504f\u5dee\u90fd\u53ef\u4ee5\u901a\u8fc7\u5c06\u5bc6\u5ea6\u56fe\u9664\u4ee5\u793a\u4f8b\u4f4d\u7f6e\u5f53\u524d\u9884\u6d4b\u7684\u8ba1\u6570\u6765\u6821\u51c6\u3002\u6211\u4eec\u91c7\u53d6\u8fd9\u79cd\u65b9\u6cd5\u662f\u56e0\u4e3a\u7531\u4e8e\u8fb9\u754c\u6846\u7684\u6b67\u4e49\uff0c\u6a21\u578b\u6709\u65f6\u9009\u62e9\u5bf9\u8c61\u7684\u6700\u5c0f\u81ea\u76f8\u4f3c\u5355\u5143\u8fdb\u884c\u8ba1\u6570\uff0c\u800c\u4e0d\u662f\u6574\u4e2a\u5bf9\u8c61\uff0c\u5982\u56fe3\uff08a\uff09\u6240\u793a\u3002\u56e0\u6b64\uff0c\u5982\u679c\u5bf9\u5e94\u4e8e\u8fb9\u754c\u6846\u7684\u5bc6\u5ea6\u56fe\u533a\u57df\u7684\u5e73\u5747\u603b\u548c\u8d85\u8fc7\u4e00\u4e2a\u9608\u503c\uff0c\u4f8b\u59821.8\uff0c\u6211\u4eec\u5c06\u5229\u7528\u8fd9\u79cd\u6d4b\u8bd5\u65f6\u7684\u5f52\u4e00\u5316\u65b9\u6cd5\u3002</p> <p></p> <p></p> <p>\u6b64\u5916\uff0c\u5bf9\u4e8e\u5305\u542b\u5fae\u5c0f\u7269\u4f53\u7684\u56fe\u50cf\uff08\u4e00\u4e2a\u793a\u4f8b\u7684\u8fb9\u957f\u5c0f\u4e8e10\u50cf\u7d20\uff09\uff0c\u6211\u4eec\u91c7\u7528\u6ed1\u52a8\u7a97\u53e3\u9884\u6d4b\u65b9\u6cd5\uff0c\u5c06\u56fe\u50cf\u7b49\u5206\u4e3a\u4e5d\u4e2a\u90e8\u5206\uff0c\u5e76\u5c06\u5176\u7f29\u653e\u56de\u539f\u59cb\u5927\u5c0f\uff0c\u4ee5\u4fbf\u6211\u4eec\u7684\u6a21\u578b\u5206\u522b\u5904\u7406\u3002\u7269\u4f53\u7684\u603b\u6570\u662f\u8fd9\u4e5d\u4e2a\u56fe\u50cf\u7684\u5355\u72ec\u8ba1\u6570\u7ed3\u679c\u7684\u603b\u548c\u3002</p>"},{"location":"literature/ObejectCounting/rank9%20SemAug_SAFECount/","title":"rank9 SemAug SAFECount","text":"2024-11-15 22:40:032025-09-28 12:54:06 <p> \u7ea6 92 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p></p> <p>SemAug \u63d0\u51fa\u7684\u662f\u4e00\u4e2a\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u5206\u522b\u5bf9\u4e24\u4e2a\u4e0d\u540c\u7684\u6a21\u578b\u8fdb\u884c\u4e86\u6570\u636e\u589e\u5f3a\uff1aCounTR\u548cSAFECount\uff0c\u5237\u7684\u540c\u4e00\u4e2a\u6570\u636e\u96c6\u90fd\u662fFSC147\u6570\u636e\u96c6\uff0c\u91cd\u70b9\u5728\u4e8e\uff0c\u7ecf\u8fc7\u6570\u636e\u589e\u5f3a\u540e\u7684\u6a21\u578b\uff0c\u6548\u679c\u90fd\u6bd4\u539f\u6765\u7684\u597d</p> <p>\u91cd\u70b9\u5728\u4e8e\u6570\u636e\u589e\u5f3a\u7684\u7b56\u7565\uff1a</p> <ul> <li>\u6269\u6563\u6a21\u578b\uff0c\u76d1\u7763\u4fe1\u53f7\uff1aprompt \u548c density map</li> </ul> <p></p>"},{"location":"literature/ObjectDetection/","title":"Index","text":"2024-11-26 22:43:322025-09-28 12:54:06 <p> \u7ea6 50 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <ul> <li> DINO \u8bba\u6587\u7b80\u4ecb</li> <li> Transformer DINO\u548cGrounding DINO\u8bb2\u89e3</li> <li> IDEA\u7814\u7a76\u9662CVR\u53d1\u5e03DINO-X\u76ee\u6807\u68c0\u6d4b\u89c6\u89c9\u5927\u6a21\u578b\uff1a\u5e26\u6765\u5168\u573a\u666f\u611f\u77e5\u7684\u65b0\u9ad8\u5ea6</li> <li> \u76ee\u6807\u68c0\u6d4b\uff1a\u4eceR-CNN\u3001YOLO\u5230DETR\u3001DINO</li> </ul>"},{"location":"literature/ObjectDetection/1/","title":"DETR\u8bba\u6587\u7cfb\u5217","text":""},{"location":"literature/ObjectDetection/1/#detr","title":"DETR\u8bba\u6587\u7cfb\u5217","text":"2024-11-26 22:43:322025-09-28 12:54:06 <p> \u7ea6 542 \u4e2a\u5b57  33 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <ul> <li>DETR\u8bba\u6587\u7cfb\u5217<ul> <li>DETR\u8bba\u6587<ul> <li>DETR\u662f\u4ec0\u4e48\uff1f</li> </ul> </li> <li>Deformable DETR \u53ef\u53d8\u5f62</li> <li>Conditional DETR \u6709\u6761\u4ef6\u7684DETR</li> <li>Anchor DETR</li> <li>DAB-DETR</li> <li>DN-DETR \u53bb\u566aDETR</li> <li>DINO</li> <li>Lite DETR</li> <li>Focus DETR</li> <li>H-DETR</li> </ul> </li> </ul>"},{"location":"literature/ObjectDetection/1/#detr_1","title":"DETR\u8bba\u6587","text":"<p>rpn\u9636\u6bb5\u3001roi\u9636\u6bb5\u4e24\u6b21sample\u6b63\u8d1f\u6837\u672c\u7684\u6570\u91cf</p> <p>\u9996\u5148\u5728rpn\u9636\u6bb5\uff0c\u9996\u5148\u751f\u6210\u4e0d\u540c\u6bd4\u4f8b\u7684\u5bbd\u9ad8\uff0c\u4ee5\u53ca\u5728\u4e0d\u540c\u6bd4\u4f8b\u7684\u7279\u5f81\u56fe\u7684\u6bd4\u4f8b\u4e0a\u751f\u6210</p> <p>\u9700\u8981\u5b9a\u4e49anchor\u7684\u5bbd\u9ad8\u6bd4\u3001\u6570\u91cf</p> <p>fast RCNN\u9700\u8981\u5728rpn\u9636\u6bb5\u3001roi\u9636\u6bb5\u8fdb\u884c\u4e24\u6b21NMS\u7684\u8ba1\u7b97\uff0c\u6d88\u9664\u76f8\u540c\u4f4d\u7f6e\u91cd\u590d\u533a\u57df\u7684\u9884\u6d4b</p> <p></p> <p></p> <p>DETR\u79fb\u9664\u4e86Anchor\u7684\u751f\u6210\uff0c\u5728fast rcnn\u4e2d\uff0c\u9700\u8981\u5728\u7b2c\u4e00\u9636\u6bb5\u751f\u6210\u9884\u8bbe\u7684\u6570\u91cf\u4ee5\u53ca\u5bbd\u9ad8\u6bd4\uff0c\u4e00\u4e9banchor\uff0c\u8fd9\u4e9banchor\u5728\u540e\u7eed\u7684\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5728\u7f51\u7edc\u7684\u8f93\u51fa\u4e2d\u8fdb\u884c\u5fae\u8c03\uff0cDETR\u5b8c\u5168\u6452\u5f03\u4e86\u8fd9\u79cd\u65b9\u5f0f</p> <p></p> <p>DETR\u5c5e\u4e8e\u96c6\u5408\u9884\u6d4b\u7684\u6a21\u578b</p> <p>\u76ee\u6807\u68c0\u6d4bNMS\u7684\u8fc7\u7a0b\u5c31\u662f\u6392\u9664\u6389\u5728\u4e00\u4e9b\u76f8\u8fd1\u7684\u4f4d\u7f6e\u4e0a\u5bf9\u4e8e\u540c\u4e00\u4e2a\u7c7b\u522b\u91cd\u590d\u7684\u9884\u6d4b</p> <p>\u5728DETR\u4e2d\uff0c\u662f\u6ca1\u6709\u4e86\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u7f51\u7edc\u6240\u7ed9\u51fa\u7684\u8f93\u51fa\u5728\u5b9a\u4e49\u4e2d\u5c31\u662f100\u4e2a\u7ed3\u679c\uff0c\u8fd9100\u4e2a\u7ed3\u679c\u4e5f\u662f\u6700\u7ec8\u7684\u7f51\u7edc\u9884\u6d4b\u7684\u7ed3\u679c\uff0c\u5305\u62ec\u56fe\u7247\u4e2d\u9690\u5f0f\u7c7b\u7684\u7ed3\u679c\uff0c\u6216\u8005\u67d0\u4e9b\u9884\u6d4b\u7ed3\u679c\u662f\u6ca1\u6709\u76ee\u6807\u7684\uff0c\u8fd9\u4e2a\u9884\u6d4b\u503c100\u6307\u7684\u662f\u5728\u6240\u6709\u53ef\u80fd\u7684\u9884\u6d4b\u7ed3\u679c\u4e2d\u7684\u6700\u5927\u503c\uff0c\u4e00\u822c\u6765\u8bf4\u4e00\u5f20\u56fe\u7247\u4e5f\u4e0d\u4f1a\u5b9a\u4e49100\u4e2agt\uff0c\u5728\u5176\u4ed6\u7684\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u5728\u6700\u540e\u4e00\u4e2a\u9636\u6bb5\u8f93\u51fa\u7684\u7f51\u7edc\u7ed3\u679c\u7684\u76ee\u6807\u6846\uff0c\u5728\u6ca1\u6709\u8fdb\u884cNMS\u4e4b\u524d\uff0c\u8fd9\u4e2a\u6570\u91cf\u662f\u591a\u8fc7\u4e8e100\u7684</p> <p>DETR\u7684\u4e24\u4e2a\u6838\u5fc3\u5185\u5bb9\uff1a</p> <p></p> <p>\u4e00\u4e2a\u662fTransformer\u7684\u7ed3\u679c\uff0c\u4ece\u6807\u9898\u4e2d\u5c31\u53ef\u4ee5\u770b\u51fa\uff1b\u7b2c\u4e8c\u4e2a\u662f\u6307\u7684\u4e8c\u5206\u56fe\u5339\u914d</p> <p>\u9996\u5148\u4ecb\u7ecd\u4e8c\u5206\u56fe\u5339\u914d</p> <p></p> <p>\u4e8c\u5206\u56fe\u5c31\u662f\u5b9a\u4e49\u4e86\u4e24\u4e2a\u96c6\u5408\uff0c\u5728\u6bcf\u4e00\u4e2a\u96c6\u5408\uff0c\u5728\u5404\u81ea\u7684\u96c6\u5408\u5185\uff0c\u6bcf\u4e00\u4e2a\u70b9\u6ca1\u6709\u8fde\u63a5\uff0c\u5728\u4e24\u4e2a\u96c6\u5408\u95f4\uff0c\u6709\u8fb9\u8fdb\u884c\u8fde\u63a5\uff1b\u4e8c\u5206\u56fe\u5339\u914d\u4e0e\u5308\u7259\u5229\u7b97\u6cd5\uff0c\u5c31\u662f\u5982\u4f55\u8ba1\u7b97\u4e24\u4e2a\u96c6\u5408\u5f97\u5230\u6700\u4f18\u5206\u914d\u7684\u95ee\u9898</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>\u8f85\u52a9\u635f\u5931</p> <p></p> <p></p> <p>\u4f46\u662f\u5bf9\u4e8e\u5c0f\u76ee\u6807\u7684\u7ed3\u679c\u4e0d\u592a\u597d\uff0c\u53ef\u80fdTransformer\u4e0d\u592a\u9002\u5408\u5c0f\u76ee\u6807</p> <p></p> <p></p>"},{"location":"literature/ObjectDetection/1/#detr_2","title":"DETR\u662f\u4ec0\u4e48\uff1f","text":""},{"location":"literature/ObjectDetection/1/#deformable-detr","title":"Deformable DETR \u53ef\u53d8\u5f62","text":""},{"location":"literature/ObjectDetection/1/#conditional-detr-detr","title":"Conditional DETR \u6709\u6761\u4ef6\u7684DETR","text":""},{"location":"literature/ObjectDetection/1/#anchor-detr","title":"Anchor DETR","text":""},{"location":"literature/ObjectDetection/1/#dab-detr","title":"DAB-DETR","text":""},{"location":"literature/ObjectDetection/1/#dn-detr-detr","title":"DN-DETR \u53bb\u566aDETR","text":""},{"location":"literature/ObjectDetection/1/#dino","title":"DINO","text":""},{"location":"literature/ObjectDetection/1/#lite-detr","title":"Lite DETR","text":""},{"location":"literature/ObjectDetection/1/#focus-detr","title":"Focus DETR","text":""},{"location":"literature/ObjectDetection/1/#h-detr","title":"H-DETR","text":""},{"location":"literature/ObjectDetection/2/","title":"\u76ee\u6807\u68c0\u6d4b\u57fa\u7840\u77e5\u8bc6","text":""},{"location":"literature/ObjectDetection/2/#_1","title":"\u76ee\u6807\u68c0\u6d4b\u57fa\u7840\u77e5\u8bc6","text":"2024-11-26 22:43:322025-09-28 12:54:06 <p> \u7ea6 1222 \u4e2a\u5b57  205 \u884c\u4ee3\u7801  19 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 9 \u5206\u949f</p>"},{"location":"literature/ObjectDetection/2/#iou","title":"IOU","text":""},{"location":"literature/ObjectDetection/2/#iou_1","title":"IOU\u662f\u4ec0\u4e48\uff1f","text":"<p>\u6587\u5b57\uff1aIntersection over Union\u3001\u4e24\u4e2abox\u533a\u57df\u7684\u4ea4\u96c6\u6bd4\u4e0a\u5e76\u96c6\u3001\u4ea4\u5e76\u6bd4</p> <p>\u56fe\u793a\uff1a</p>"},{"location":"literature/ObjectDetection/2/#iou_2","title":"IOU\u600e\u4e48\u5b9e\u73b0\uff1f","text":"<p>\u601d\u8def\uff1a\uff08\u6ce8\u610f\u7ef4\u5ea6\u4e00\u81f4\uff09</p> <ul> <li> <p>\u9996\u5148\u8ba1\u7b97\u4e24\u4e2abox\u5de6\u4e0a\u89d2\u70b9\u5750\u6807\u7684\u6700\u5927\u503c\u548c\u53f3\u4e0b\u89d2\u5750\u6807\u7684\u6700\u5c0f\u503c </p> </li> <li> <p>\u7136\u540e\u8ba1\u7b97\u4ea4\u96c6\u9762\u79ef </p> </li> <li> <p>\u6700\u540e\u628a\u4ea4\u96c6\u9762\u79ef\u9664\u4ee5\u5bf9\u5e94\u7684\u5e76\u96c6\u9762\u79ef</p> </li> </ul> <p>Note</p> <p>\u5de6\u4e0a\u89d2\u5750\u6807\u548c\u53f3\u4e0b\u89d2\u5750\u6807\u786e\u5b9a\u4e00\u4e2a\u6846</p>"},{"location":"literature/ObjectDetection/2/#api","title":"\u5b98\u65b9api","text":"<p>pytorch\u6e90\u7801\uff1a</p> <p>\uff08\u6ce8\u610f\u77e9\u9635\u7ef4\u5ea6\u7684\u53d8\u5316\uff09</p>"},{"location":"literature/ObjectDetection/2/#box_iou","title":"box_iou","text":"Python<pre><code>def box_iou(boxes1: Tensor, boxes2: Tensor) -&gt; Tensor:\n    \"\"\"\n    Return intersection-over-union (Jaccard index) between two sets of boxes.\n\n    Both sets of boxes are expected to be in ``(x1, y1, x2, y2)`` format with\n    ``0 &lt;= x1 &lt; x2`` and ``0 &lt;= y1 &lt; y2``.\n\n    Args:\n        boxes1 (Tensor[N, 4]): first set of boxes\n        boxes2 (Tensor[M, 4]): second set of boxes\n\n    Returns:\n        Tensor[N, M]: the NxM matrix containing the pairwise IoU values for every element in boxes1 and boxes2\n    \"\"\"\n    if not torch.jit.is_scripting() and not torch.jit.is_tracing():\n        _log_api_usage_once(box_iou)\n    inter, union = _box_inter_union(boxes1, boxes2)\n    iou = inter / union\n    return iou\n</code></pre> <p>\u61c2\u4e86\uff1aboxes1\u6709N\u4e2a\uff0cboxes2\u6709M\u4e2a\uff0c\u8fd4\u56de\u7684N\u00d7M\u662fboxes1\u4e2d\u7684\u6240\u6709\u68c0\u6d4b\u6846\u4e0eboxes2\u4e2d\u6240\u6709\u68c0\u6d4b\u6846\u7684IOU\u503c\uff0cboxes\uff1a\u96c6\u5408\u3001\u6846\u7684\u96c6\u5408</p>"},{"location":"literature/ObjectDetection/2/#_box_inter_union","title":"_box_inter_union","text":"Python<pre><code>def _box_inter_union(boxes1: Tensor, boxes2: Tensor) -&gt; Tuple[Tensor, Tensor]:\n    area1 = box_area(boxes1) # (x1, y1, x2, y2)\n    area2 = box_area(boxes2)\n\n    lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2] \u627e\u5230\u5de6\u4e0a\u89d2\u7684\u6700\u5927\u503c\n    rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2] \u627e\u5230\u53f3\u4e0b\u89d2\u7684\u6700\u5c0f\u503c\n\n    wh = _upcast(rb - lt).clamp(min=0)  # [N,M,2]\n    inter = wh[:, :, 0] * wh[:, :, 1]  # [N,M]\n\n    union = area1[:, None] + area2 - inter\n\n    return inter, union\n</code></pre>"},{"location":"literature/ObjectDetection/2/#box_area","title":"box_area","text":"<p>\u662f\u4ec0\u4e48\uff1f</p> <p>\u7ed9\u5b9a\u4e00\u7cfb\u5217\u8fb9\u754c\u6846\u5750\u6807\u96c6\u5408\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u8fb9\u754c\u6846\u7684\u9762\u79ef  </p> <p>\u8fd4\u56de\u503c\uff1aN\u7684\u8fb9\u754c\u6846\u7684\u9762\u79ef</p> <p>\u600e\u4e48\u5b9e\u73b0\u7684\uff1f \u9762\u79ef\u7684\u8ba1\u7b97\u516c\u5f0f\uff1a<code>(boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])</code></p> <p>\u8fb9\u754c\u6846\u7684\u5750\u6807\u96c6\u5408\uff1f <code>(x1, y1, x2, y2)</code> </p> Python<pre><code>def box_area(boxes: Tensor) -&gt; Tensor:\n    \"\"\"\n    Computes the area of a set of bounding boxes, which are specified by their\n    (x1, y1, x2, y2) coordinates.\n\n    Args:\n        boxes (Tensor[N, 4]): boxes for which the area will be computed. They\n            are expected to be in (x1, y1, x2, y2) format with\n            ``0 &lt;= x1 &lt; x2`` and ``0 &lt;= y1 &lt; y2``.\n\n    Returns:\n        Tensor[N]: the area for each box\n    \"\"\"\n    if not torch.jit.is_scripting() and not torch.jit.is_tracing():\n        _log_api_usage_once(box_area)\n    boxes = _upcast(boxes)\n    return (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n</code></pre>"},{"location":"literature/ObjectDetection/2/#reference","title":"Reference  \u4ee3\u7801\u5b9e\u73b0","text":"Python<pre><code>import torch\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# IOU\u8ba1\u7b97\n# \u5047\u8bbebox1\u7ef4\u5ea6\u4e3a[N,4]   box2\u7ef4\u5ea6\u4e3a[M,4]\ndef iou(box1, box2):\n    N = box1.size(0)\n    M = box2.size(0)\n\n    lt = torch.max(  # \u5de6\u4e0a\u89d2\u7684\u70b9\n        box1[:, :2].unsqueeze(1).expand(N, M, 2),   # [N,2]-&gt;[N,1,2]-&gt;[N,M,2]\n        box2[:, :2].unsqueeze(0).expand(N, M, 2),   # [M,2]-&gt;[1,M,2]-&gt;[N,M,2]\n    )\n    print(\"lt\",lt)\n    print(\"lt shape\",lt.shape)\n\n    rb = torch.min(\n        box1[:, 2:].unsqueeze(1).expand(N, M, 2),\n        box2[:, 2:].unsqueeze(0).expand(N, M, 2),\n    )\n    print(\"rb\",rb)\n    print(\"rb shape\",rb.shape)\n\n    wh = rb - lt  # [N,M,2]\n    print(\"wh\",wh)\n    wh[wh &lt; 0] = 0   # \u4e24\u4e2abox\u6ca1\u6709\u91cd\u53e0\u533a\u57df\n    inter = wh[:,:,0] * wh[:,:,1]   # [N,M]\n\n    area1 = (box1[:,2]-box1[:,0]) * (box1[:,3]-box1[:,1])  # (N,)\n    area2 = (box2[:,2]-box2[:,0]) * (box2[:,3]-box2[:,1])  # (M,)\n    area1 = area1.unsqueeze(1).expand(N,M)  # (N,M)\n    area2 = area2.unsqueeze(0).expand(N,M)  # (N,M)\n\n    iou = inter / (area1 + area2 - inter)\n    return iou\n\n# # \u6d4b\u8bd5\u4ee3\u78011\n# M=1\n# N=1\n# box1 = torch.tensor([[20, 30, 40, 50]], dtype=torch.float)  # \u624b\u52a8\u8bbe\u7f6e\u6709\u91cd\u53e0\u533a\u57df\u7684\u6846\n# box2 = torch.tensor([[30, 40, 50, 60]], dtype=torch.float)\n# # IOU: tensor([[0.1429]])\n\n# \u6d4b\u8bd5\u4ee3\u78012\nM=2\nN=1\nbox1 = torch.tensor([[20, 30, 40, 50]], dtype=torch.float)  # \u624b\u52a8\u8bbe\u7f6e\u6709\u91cd\u53e0\u533a\u57df\u7684\u6846\nprint(box1.shape)\nbox2 = torch.tensor([[30, 40, 50, 60], [15, 25, 35, 45]], dtype=torch.float)\nprint(box2.shape)\n\n# IOU: tensor([[0.1429, 0.3913]])\n\n# \u6d4b\u8bd5\u4ee3\u78013\n# N=2\n# M=3\n# box1 = torch.tensor([[20, 30, 40, 50], [60, 70, 80, 90]], dtype=torch.float)  # \u624b\u52a8\u8bbe\u7f6e\u6709\u91cd\u53e0\u533a\u57df\u7684\u6846\n# print(box1.shape)\n# box2 = torch.tensor([[30, 40, 50, 60], [70, 80, 90, 100], [15, 25, 35, 45]], dtype=torch.float)\n# print(box2.shape)\n\n# print(\"Box1:\", box1)\n# print(\"Box2:\", box2)\n# print(\"IOU:\", iou(box1, box2))\n\n# # \u7ed8\u5236\u8fb9\u754c\u6846\n# fig, ax = plt.subplots(1)\n\n# # \u7ed8\u5236box1\n# for i in range(N):\n#     rect = patches.Rectangle((box1[i, 0], box1[i, 1]), box1[i, 2] - box1[i, 0], box1[i, 3] - box1[i, 1], linewidth=1, edgecolor='r', facecolor='none')\n#     ax.add_patch(rect)\n\n# # \u7ed8\u5236box2\n# for i in range(M):\n#     rect = patches.Rectangle((box2[i, 0], box2[i, 1]), box2[i, 2] - box2[i, 0], box2[i, 3] - box2[i, 1], linewidth=1, edgecolor='b', facecolor='none')\n#     ax.add_patch(rect)\n\n# plt.xlim(0, 100)\n# plt.ylim(0, 100)\n# plt.gca().set_aspect('equal', adjustable='box')\n# plt.show()\n</code></pre> <p>\u5176\u4e2d\uff1a</p> <p>torch.unsqueeze(1) \u8868\u793a\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u589e\u52a0\u4f4d\u7f6e\u4e3a\u7ef4\u5ea61</p> <p>torch.squeeze(1) \u8868\u793a\u51cf\u5c11\u4e00\u4e2a\u7ef4\u5ea6</p> <p>\ud83c\udf30\uff1a</p> <p></p> <p>\\(\\frac{1}{7}\\)</p>"},{"location":"literature/ObjectDetection/2/#nms","title":"NMS","text":""},{"location":"literature/ObjectDetection/2/#nms_1","title":"NMS\u662f\u4ec0\u4e48\uff1f","text":"<p>5\u4e2a\u5b57\uff1a\u8fc7\u6ee4\u5197\u4f59\u6846</p> <p>\u6587\u5b57\u63cf\u8ff0\u3001\u6570\u5b66\u5b9e\u4f8b</p> <p>\u6587\u5b57\uff1a</p> <ul> <li>Non-maximum suppression\u3001\u975e\u6781\u5927\u503c\u6291\u5236\u7b97\u6cd5</li> </ul> <p>\u6570\u5b66\u5b9e\u4f8b</p> <p>\u56fe\u793a\uff1a</p> <p>\u9700\u8981\u7ed9\u5b9a\u7684\u8f93\u5165\uff1a\u9884\u6d4b\u7684\u8fb9\u754c\u6846\u53ca\u7f6e\u4fe1\u5ea6</p> <p>Note</p> <p>\u975e\u6781\u5927\u503c\u6291\u5236\uff08NMS\uff09\u7b97\u6cd5\uff0c\u7528\u4e8e\u53bb\u9664\u91cd\u53e0\u7684\u8fb9\u754c\u6846    :param bboxes: \u8fb9\u754c\u6846\u5217\u8868\uff0c\u6bcf\u4e2a\u8fb9\u754c\u6846\u683c\u5f0f\u4e3a[xmin, ymin, xmax, ymax]     :param scores: \u8fb9\u754c\u6846\u5bf9\u5e94\u7684\u7f6e\u4fe1\u5ea6\u5217\u8868   :param iou _thresh: IOU\uff08\u4ea4\u5e76\u6bd4\uff09\u9608\u503c\uff0c\u7528\u4e8e\u5224\u65ad\u4e24\u4e2a\u8fb9\u754c\u6846\u662f\u5426\u91cd\u53e0                :return: \u7ecf\u8fc7NMS\u5904\u7406\u540e\u7684\u8fb9\u754c\u6846\u548c\u7f6e\u4fe1\u5ea6\u5217\u8868</p> <p></p>"},{"location":"literature/ObjectDetection/2/#nms_2","title":"\u4e3a\u4ec0\u4e48NMS\uff1f","text":"<p>NMS\u7684\u4f5c\u7528\u662f\u53bb\u9664\u591a\u4e2a\u9884\u6d4b\u540c\u4e00\u7269\u4f53\u7684\u5197\u4f59\u68c0\u6d4b\u6846</p> <p>\u54ea\u91cc\u9700\u8981\u7528\uff1f</p> <p>\u4ee5RCNN\u7cfb\u5217\u3001Yolo\u7cfb\u5217\u4e3a\u9996\u7684\u4e00\u4e9b\u6a21\u578b\u5728\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u5df2\u7ecf\u53d6\u5f97\u4e86\u975e\u5e38\u6210\u719f\u7684\u5e94\u7528\u6548\u679c\uff0c\u4f46\u4e0d\u7ba1\u662f\u5355\u9636\u6bb5\u6a21\u578b\uff08\u5982Yolo\u3001SSD\uff09\u8fd8\u662f\u4e24\u9636\u6bb5\u6a21\u578b\uff08\u5982RCNN\uff09\uff0c\u90fd\u9700\u8981\u8fdb\u884c\u975e\u6781\u5927\u503c\u6291\u5236\uff08Non-Maximum Suppression\uff0c\u7b80\u79f0NMS\uff09\u7684\u540e\u5904\u7406\u64cd\u4f5c\u3002</p> <p>\u7f3a\u70b9</p> <p>\u2460 O(n)\u7684\u7b97\u6cd5\uff0c\u5f53\u6846\u5f88\u591a\u65f6\uff0c\u6bd4\u8f83\u8d39\u65f6\uff1b</p> <p>\u2461 \u5728\u8fdb\u884cNMS\u65f6\uff0c\u5e76\u6ca1\u6709\u4f7f\u7528\u5230\u56fe\u50cf\u7279\u5f81\uff0c\u800c\u662f\u4ec5\u4ec5\u4f7f\u7528\u4e86\u9884\u6d4b\u6846\u7684\u53c2\u6570\u3002\u4e5f\u5c31\u662f\u8bf4\uff0cNMS\u7b97\u6cd5\u662f\u6ca1\u6709\u201c\u770b\u5230\u201d\u56fe\u50cf\u7684\uff0c\u8fd9\u5c31\u4f1a\u5bfc\u81f4\u4e00\u4e2a\u95ee\u9898\uff0c\u6709\u4e9b\u79bb\u5f97\u975e\u5e38\u8fd1\u751a\u81f3\u91cd\u5408\u7684\u7269\u4f53\uff08\u6bd4\u5982\u4eba\u7fa4\u4e2d\u7684\u4e24\u4e2a\u4eba\uff09\u5bf9\u5e94\u7684\u68c0\u6d4b\u6846\u4f1a\u88abNMS\u7b97\u6cd5\u7ed9\u53bb\u9664\u6389\u800c\u53ea\u4fdd\u7559\u4e00\u4e2a\uff0c\u8fd9\u662f\u56e0\u4e3aNMS\u7b97\u6cd5\u6ca1\u6709\u201c\u770b\u5230\u201c\u56fe\u7247\uff0c\u5e76\u4e0d\u77e5\u9053\u8fd9\u91cc\u9762\u6709\u4e24\u4e2a\u4eba\uff0c\u53ea\u77e5\u9053\u4e24\u4e2a\u6846\u7684IoU\uff08intersection over union\uff09\u975e\u5e38\u5927\u800c\u5df2\uff1b</p> <p>\u2462 NMS\u9700\u8981\u8bbe\u7f6e\u8d85\u53c2\u6570\u9608\u503c\uff0c\u8fd9\u9700\u8981\u4e00\u5b9a\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u800c\u4e14\u5728\u8bbe\u8ba1\u65f6\u4f1a\u6839\u636e\u4e0d\u540c\u7684\u4efb\u52a1case by case\uff0c\u8fd9\u4f7f\u5f97\u65b9\u6cd5\u4e0d\u591fgeneral</p> <p>\u4e3a\u4ec0\u4e48\u4f1a\u6709\u5197\u4f59\u6846\uff1f</p> <p>\u4e3b\u8981\u7684\u539f\u56e0\uff1a\u5728\u5bf9\u6bcf\u4e2aanchor\u8fdb\u884c\u56de\u5f52\u7684\u65f6\u5019\uff0c\u662f\u72ec\u7acb\u8fdb\u884c\u7684\u3002</p> <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u5047\u8bbeanchor A\u548canchor B\u9884\u6d4b\u7684\u662f\u540c\u4e00\u4e2a\u4eba\uff0c\u7136\u800canchor A\u548canchor B\u4e4b\u95f4\u5e76\u6ca1\u6709\u4fe1\u606f\u4ea4\u6362\uff0c\u56e0\u6b64\u5b83\u4eec\u4f1a\u5206\u522b\u9884\u6d4b\u51fa\u76f8\u4f3c\u7684\u7ed3\u679c\uff08\u751a\u81f3\u53ef\u80fd\u7f6e\u4fe1\u5206\u6570\u90fd\u5f88\u9ad8\uff09\u3002\u56e0\u6b64\uff0c\u5982\u679c\u80fd\u591f\u8ba9anchor B\u77e5\u9053\uff0c\u5df2\u7ecf\u6709anchor A\u5728\u9884\u6d4b\u8fd9\u4e2a\u7269\u4f53\u4e86\uff0c\u5c31\u53ef\u4ee5\u907f\u514danchor B\u53bb\u9884\u6d4b\u91cd\u590d\u7684\u5197\u4f59\u6846\u4e86\u3002</p>"},{"location":"literature/ObjectDetection/2/#nms_3","title":"NMS\u600e\u4e48\u5b9e\u73b0\uff1f","text":"<p>\u4ee3\u7801</p>"},{"location":"literature/ObjectDetection/2/#api_1","title":"\u5b98\u65b9api","text":"<p>source</p> <p></p> <p>\u6211\u6252\u4e0d\u5230\u6e90\u7801</p>"},{"location":"literature/ObjectDetection/2/#_2","title":"\u4ee3\u7801\u5b9e\u73b0","text":"<ol> <li> <p>\u9009\u53d6\u8fd9\u7c7bbox\u4e2dscores\u6700\u5927\u7684\u54ea\u4e00\u4e2a\uff0c\u8bb0\u4e3abox_best\uff0c\u5e76\u4fdd\u7559\u5b83</p> </li> <li> <p>\u8ba1\u7b97box_best\u4e0e\u5176\u4f59\u7684box\u7684IOU</p> </li> <li> <p>\u5982\u679c\u5176IOU&gt;0.5\u4e86\uff0c\u90a3\u4e48\u5c31\u820d\u5f03\u8fd9\u4e2abox</p> </li> </ol> <p>\uff08\u7531\u4e8e\u53ef\u80fd\u8fd9\u4e24\u4e2abox\u8868\u793a\u540c\u4e00\u76ee\u6807\uff0c\u6240\u4ee5\u4fdd\u7559\u5206\u6570\u9ad8\u7684\u54ea\u4e00\u4e2a\uff09</p> <ol> <li>\u4ece\u6700\u540e\u5269\u4f59\u7684boxes\u4e2d\uff0c\u518d\u627e\u51fa\u6700\u5927scores\u7684\u54ea\u4e00\u4e2a\uff0c\u5982\u6b64\u5faa\u73af\u5f80\u590d</li> </ol> <p></p> Python<pre><code>import torch\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# NMS\u7b97\u6cd5\n# bboxes\u7ef4\u5ea6\u4e3a[N,4]\uff0cscores\u7ef4\u5ea6\u4e3a[N,], \u5747\u4e3atensor\ndef nms(bboxes, scores, threshold=0.5):\n    x1 = bboxes[:,0]\n    y1 = bboxes[:,1]\n    x2 = bboxes[:,2]\n    y2 = bboxes[:,3]\n    areas = (x2-x1)*(y2-y1)   # [N,] \u6bcf\u4e2abbox\u7684\u9762\u79ef\n    _, order = scores.sort(0, descending=True)    # \u964d\u5e8f\u6392\u5217\n\n    keep = []\n    while order.numel() &gt; 0:       # torch.numel()\u8fd4\u56de\u5f20\u91cf\u5143\u7d20\u4e2a\u6570\n        if order.numel() == 1:     # \u4fdd\u7559\u6846\u53ea\u5269\u4e00\u4e2a\n            i = order.item()\n            keep.append(i)\n            break\n        else:\n            i = order[0].item()    # \u4fdd\u7559scores\u6700\u5927\u7684\u90a3\u4e2a\u6846box[i]\n            keep.append(i)\n\n        # \u8ba1\u7b97box[i]\u4e0e\u5176\u4f59\u5404\u6846\u7684IOU(\u601d\u8def\u5f88\u597d)\n        xx1 = x1[order[1:]].clamp(min=x1[i])   # [N-1,]\n        yy1 = y1[order[1:]].clamp(min=y1[i])\n        xx2 = x2[order[1:]].clamp(max=x2[i])\n        yy2 = y2[order[1:]].clamp(max=y2[i])\n        inter = (xx2-xx1).clamp(min=0) * (yy2-yy1).clamp(min=0)   # [N-1,]\n\n        iou = inter / (areas[i]+areas[order[1:]]-inter)  # [N-1,]\n        idx = (iou &lt;= threshold).nonzero().squeeze() # \u6ce8\u610f\u6b64\u65f6idx\u4e3a[N-1,] \u800corder\u4e3a[N,]\n        if idx.numel() == 0:\n            break\n        order = order[idx+1]  # \u4fee\u8865\u7d22\u5f15\u4e4b\u95f4\u7684\u5dee\u503c\n    return torch.LongTensor(keep)   # Pytorch\u7684\u7d22\u5f15\u503c\u4e3aLongTensor\n\n# \u6d4b\u8bd5\u4ee3\u7801\nbboxes = torch.tensor([\n    [20, 30, 40, 50],\n    [22, 32, 42, 52],\n    [100, 100, 120, 130]\n], dtype=torch.float)\n\nscores = torch.tensor([0.9, 0.75, 0.6], dtype=torch.float)\n\n# \u8c03\u7528NMS\u51fd\u6570\nkeep_indices = nms(bboxes, scores, threshold=0.5)\nprint(\"\u4fdd\u7559\u7684\u6846\u7d22\u5f15:\", keep_indices)\n\n# # \u53ef\u89c6\u5316\u7ed3\u679c\n# fig, ax = plt.subplots(1)\n\n# # \u7ed8\u5236\u6240\u6709\u8fb9\u754c\u6846\n# for i in range(bboxes.size(0)):\n#     rect = patches.Rectangle((bboxes[i, 0], bboxes[i, 1]), bboxes[i, 2] - bboxes[i, 0], bboxes[i, 3] - bboxes[i, 1], linewidth=1, edgecolor='r', facecolor='none', label='All Boxes' if i == 0 else \"\")\n#     ax.add_patch(rect)\n\n# # \u7ed8\u5236\u4fdd\u7559\u7684\u8fb9\u754c\u6846\n# for i in keep_indices:\n#     rect = patches.Rectangle((bboxes[i, 0], bboxes[i, 1]), bboxes[i, 2] - bboxes[i, 0], bboxes[i, 3] - bboxes[i, 1], linewidth=2, edgecolor='b', facecolor='none', label='Kept Boxes' if i == keep_indices[0] else \"\")\n#     ax.add_patch(rect)\n\n# # \u6dfb\u52a0\u56fe\u4f8b\n# handles, labels = ax.get_legend_handles_labels()\n# by_label = dict(zip(labels, handles))\n# ax.legend(by_label.values(), by_label.keys())\n\n# plt.xlim(0, 150)\n# plt.ylim(0, 150)\n# plt.gca().set_aspect('equal', adjustable='box')\n# plt.show()\n</code></pre> <p>torch.numel() \u8868\u793a\u4e00\u4e2a\u5f20\u91cf\u603b\u5143\u7d20\u7684\u4e2a\u6570   </p> <p>torch.clamp(min, max) \u8bbe\u7f6e\u4e0a\u4e0b\u9650</p> <p>tensor.item() \u628atensor\u5143\u7d20\u53d6\u51fa\u4f5c\u4e3anumpy\u6570\u5b57</p> <p>\u53e6\u8865\u5145\u4ee3\u7801\u793a\u4f8b</p>"},{"location":"literature/ObjectDetection/2/#bounding-box-regression","title":"Bounding box regression","text":""},{"location":"literature/ObjectDetection/2/#anchor","title":"Anchor","text":"<p>\u951a\u6846A1\u8ddf\u4eba\u50cf\u533a\u57df\u975e\u5e38\u63a5\u8fd1</p>"},{"location":"literature/ObjectDetection/2/#_3","title":"\u4ea4\u5e76\u6bd4","text":"<ul> <li>\u4ec0\u4e48\u60c5\u51b5\u4e0b\u4e24\u4e2a\u77e9\u5f62\u6846\u7684IoU\u7b49\u4e8e1\uff1f </li> </ul> <p>\u7b54\u6848\uff1a\u4e24\u4e2a\u77e9\u5f62\u6846\u5b8c\u5168\u91cd\u5408\u3002</p> <ul> <li>\u4ec0\u4e48\u60c5\u51b5\u4e0b\u4e24\u4e2a\u77e9\u5f62\u6846\u7684IoU\u7b49\u4e8e0\uff1f</li> </ul> <p>\u7b54\u6848\uff1a\u4e24\u4e2a\u77e9\u5f62\u6846\u5b8c\u5168\u4e0d\u76f8\u4ea4\u3002</p> <p>\u5bf9\u4e8e\u540c\u4e00\u4e2a\u7269\u4f53\uff0c\u4f1a\u4ea7\u751f\u591a\u4e2a\u9884\u6d4b\u6846\u3002\u56e0\u6b64\u9700\u8981\u6d88\u9664\u91cd\u53e0\u8f83\u5927\u7684\u5197\u4f59\u9884\u6d4b\u6846\u3002\u5177\u4f53\u7684\u5904\u7406\u65b9\u6cd5\u5c31\u662f\u975e\u6781\u5927\u503c\u6291\u5236\uff08NMS\uff09\u3002</p>"},{"location":"literature/ObjectDetection/2/#nms_4","title":"NMS","text":"<p>\u5047\u8bbe\u4f7f\u7528\u6a21\u578b\u5bf9\u56fe\u7247\u8fdb\u884c\u9884\u6d4b\uff0c\u4e00\u5171\u8f93\u51fa\u4e8611\u4e2a\u9884\u6d4b\u6846\u53ca\u5176\u5f97\u5206\uff0c\u5728\u56fe\u4e0a\u753b\u51fa\u9884\u6d4b\u6846\u5982 \u56fe1 \u6240\u793a\u3002\u5728\u6bcf\u4e2a\u4eba\u50cf\u5468\u56f4\uff0c\u90fd\u51fa\u73b0\u4e86\u591a\u4e2a\u9884\u6d4b\u6846\uff0c\u9700\u8981\u6d88\u9664\u5197\u4f59\u7684\u9884\u6d4b\u6846\u4ee5\u5f97\u5230\u6700\u7ec8\u7684\u9884\u6d4b\u7ed3\u679c\u3002</p> <p></p> <p></p> <p></p>"},{"location":"literature/ObjectDetection/3/","title":"\uff08DETR\uff09End-to-End Object Detection with Transformer","text":""},{"location":"literature/ObjectDetection/3/#detrend-to-end-object-detection-with-transformer","title":"\uff08DETR\uff09End-to-End Object Detection with Transformer","text":"2024-11-26 22:43:322025-09-28 12:54:06 <p> \u7ea6 3272 \u4e2a\u5b57  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 16 \u5206\u949f</p> <p>\u8bba\u6587</p> <p>\u6e90\u7801</p> <p></p> <p>\u9898\u76ee\uff1a\u7aef\u5230\u7aef\u7684\u3001\u57fa\u4e8eTransformer\u7684\u76ee\u6807\u68c0\u6d4b</p> <p>\u4f5c\u8005\uff1aFacebook</p> <p>\u65f6\u95f4\uff1a2020\u5e745\u670828\u65e5</p> <p>\u671f\u520a\uff1a</p>"},{"location":"literature/ObjectDetection/3/#_1","title":"\u2b50\ufe0f \u6458\u8981","text":"<p>We present a new method that views object detection as a direct set prediction problem. </p> <p>\u5c06\u76ee\u6807\u68c0\u6d4b\u770b\u505a\u662f\u4e00\u4e2a\u9884\u6d4b\u95ee\u9898</p> <p>Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. </p> <p>\u7b80\u5316\u4e86\u68c0\u6d4b\u8fc7\u7a0b\u3001\u53bb\u6389\u4e86\u5f88\u591a\u4eba\u5de5\u6b65\u9aa4\uff1aNMS\u3001\u751f\u6210\u951a\u6846</p> <p>The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. </p> <p>\u6211\u4eec\u7684\u6a21\u578b\u540d\u5b57\uff1aDETR\u3001\u5168\u5c40\u635f\u5931\u3001\u5308\u7259\u5229\u4e8c\u5206\u5339\u914d\u7b97\u6cd5\u3001\u57fa\u4e8eTransformer Encoder decoder\u7684\u68c0\u6d4b\u7ed3\u6784</p> <p>Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel.</p> <p>\u7ed9\u5b9alearned object queries\uff1f\uff0cDETR\u63a8\u7406 \u5bf9\u8c61\u548c\u5168\u5c40\u56fe\u50cf\u7684\u4e0a\u4e0b\u6587\u5173\u7cfb\uff0c\u5e76\u884c\u7684\u8f93\u51fa\u6700\u7ec8\u7684\u9884\u6d4b\u96c6\u5408</p> <p>The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. </p> <p>DETR\u6982\u5ff5\u4e0a\u7b80\u5355\u3001\u4e0d\u9700\u8981\u4e13\u95e8\u7684\u5e93\u3001\u8ddf\u5176\u4ed6\u68c0\u6d4b\u5668\u4e0d\u592a\u4e00\u6837</p> <p>\uff08\u7ed3\u679c\uff09DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster RCNN baseline on the challenging COCO object detection dataset. </p> <p>DETR\u7684\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u6027\u80fd \u90fd\u53ef\u4ee5\u5ab2\u7f8e \u5f88\u6210\u719f\u7684\u3001\u4f18\u5316\u5f88\u597d\u7684 faster RCNN</p> <p>\u68c0\u6d4b\u6570\u636e\u96c6\u7684baseline\uff1aCOCO</p> <p>Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines.</p> <p>\u4efb\u52a1\u7684\u6cdb\u5316\u6027\u80fd\uff0cDETR\u53ef\u4ee5\u63a8\u5e7f\u5230\u5168\u666f\u5206\u5272\u4efb\u52a1</p>"},{"location":"literature/ObjectDetection/3/#introduction","title":"\u2b50\ufe0f Introduction","text":""},{"location":"literature/ObjectDetection/3/#modern-detectors","title":"\u7b2c\u4e00\u6bb5 Modern detectors","text":"<p>The goal of object detection is to predict a set of bounding boxes and category labels for each object of interest.</p> <p>\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684\u5b9a\u4e49</p> <p>Modern detectors address this set prediction task in an indirect way, by defining surrogate regression and classification problems on a large set of proposals [37,5], anchors [23], or window centers [53,46]. </p> <p>\u73b0\u5728\u7684\u68c0\u6d4b\u65b9\u6cd5\uff1a\u95f4\u63a5\u7684\u65b9\u6cd5\u8fdb\u884c\u68c0\u6d4b</p> <ul> <li> Their performances are significantly influenced by postprocessing steps to collapse near-duplicate predictions, by the design of the anchor sets and by the heuristics that assign target boxes to anchors [52]. </li> </ul> <p>\u73b0\u5728\u7684\u68c0\u6d4b\u65b9\u6cd5\uff1a\u8868\u73b0\u53d7\u5230\u540e\u5904\u7406\u6b65\u9aa4\u7684\u663e\u8457\u5f71\u54cd\uff0c\u8fd9\u4e9b\u6b65\u9aa4\u5305\u62ec\u5408\u5e76\u8fd1\u91cd\u590d\u7684\u9884\u6d4b\u3001\u951a\u70b9\u96c6\u7684\u8bbe\u8ba1\uff0c\u4ee5\u53ca\u5c06\u76ee\u6807\u6846\u5206\u914d\u7ed9\u951a\u70b9\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5[52]\u3002</p> <p>To simplify these pipelines, we propose a direct set prediction approach to bypass the surrogate tasks. </p> <p>\u4e3a\u4e86\u7b80\u5316\u8fd9\u4e9b\u6d41\u7a0b\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u76f4\u63a5\u7684\u96c6\u5408\u9884\u6d4b\u65b9\u6cd5</p> <p>This end-to-end philosophy has led to significant advances in complex structured prediction tasks such as machine translation or speech recognition, but not yet in object detection: previous attempts [43,16,4,39] either add other forms of prior knowledge, or have not proven to be competitive with strong baselines on challenging benchmarks.</p> <p>\u8fd9\u79cd\u7aef\u5230\u7aef\u7684\u7406\u5ff5\u5728\u590d\u6742\u7684\u7ed3\u6784\u5316\u9884\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u6bd4\u5982\u673a\u5668\u7ffb\u8bd1\u6216\u8bed\u97f3\u8bc6\u522b\uff0c\u4f46\u5728\u76ee\u6807\u68c0\u6d4b\u9886\u57df\u5c1a\u672a\u5b9e\u73b0\uff1a\u4e4b\u524d\u7684\u5c1d\u8bd5[43,16,4,39]\u8981\u4e48\u589e\u52a0\u4e86\u5176\u4ed6\u5f62\u5f0f\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u8981\u4e48\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u672a\u80fd\u8bc1\u660e\u4e0e\u5f3a\u5927\u7684\u57fa\u7ebf\u76f8\u7ade\u4e89\u3002</p> <p>This paper aims to bridge this gap.</p>"},{"location":"literature/ObjectDetection/3/#1","title":"\u56fe1","text":"<ul> <li>DETR\u76f4\u63a5\u3001\u5e76\u884c\u7684\u9884\u6d4b\u6700\u7ec8\u7684\u68c0\u6d4b\u96c6\u5408</li> <li>DETR\uff1aCNN\u548cTransformer\u67b6\u6784\u7ec4\u5408</li> <li>\u8bad\u7ec3\u9636\u6bb5\uff1a\u4e8c\u90e8\u56fe\u5339\u914d\u5c06\u9884\u6d4b\u548c\u771f\u5b9e\u6846\u5173\u8054\u8d77\u6765\u3001\u6ca1\u6709\u5339\u914d\u7684\u9884\u6d4b\u80fd\u591f\u4ea7\u751f\u4e00\u4e2a\u6ca1\u6709\u5bf9\u8c61\u7684\u7c7b\u522b\u9884\u6d4b</li> </ul>"},{"location":"literature/ObjectDetection/3/#based-on-transformers-self-attention-mechanisms","title":"\u7b2c\u4e8c\u6bb5 based on transformers &amp; self-attention mechanisms","text":"<p>We streamline the training pipeline by viewing object detection as a direct set prediction problem. </p> <p>\u5c06\u76ee\u6807\u68c0\u6d4b\u89c6\u4e3a\u4e00\u4e2a\u76f4\u63a5\u7684\u96c6\u5408\u9884\u6d4b\u95ee\u9898\u6765\u7b80\u5316\u8bad\u7ec3\u6d41\u7a0b</p> <p>We adopt an encoder-decoder architecture based on transformers [47], a popular architecture for sequence prediction. </p> <p>\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u7ed3\u6784</p> <p>The self-attention mechanisms of transformers, which explicitly model all pairwise interactions between elements in a sequence, make these architectures particularly suitable for specific constraints of set prediction such as removing duplicate predictions.</p> <p>Transformer\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff1a\u660e\u786e\u7ed9\u51fa\u5e8f\u5217\u4e2d\u6240\u6709\u5143\u7d20\u7684\u6210\u5bf9\u4ea4\u4e92\uff0c\u7279\u522b\u9002\u5408\u4e8e\u96c6\u5408\u9884\u6d4b\u7684\u7279\u5b9a\u7ea6\u675f\uff0c\u4f8b\u5982\u53bb\u9664\u91cd\u590d\u9884\u6d4b</p> <p>\uff08\u5c31\u662f\u8bf4\u660eTransformer\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5f88\u9002\u5408\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\uff0c\u7ed9\u51fa\u6210\u5bf9\u5143\u7d20\u4e4b\u95f4\u7684\u5173\u7cfb\uff09</p>"},{"location":"literature/ObjectDetection/3/#trained-end-to-end","title":"\u7b2c\u4e09\u6bb5 trained end-to-end","text":"<p>Our DEtection TRansformer (DETR, see Figure 1) predicts all objects at once, and is trained end-to-end with a set loss function which performs bipartite matching between predicted and ground-truth objects. </p> <ul> <li>\u4e00\u6b21\u6027\u3001\u7aef\u5230\u6bb5\u9884\u6d4b</li> <li>\u901a\u8fc7\u4e00\u4e2a\u96c6\u5408\u635f\u5931\u51fd\u6570\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u8be5\u51fd\u6570\u5728\u9884\u6d4b\u5bf9\u8c61\u548c\u771f\u5b9e\u5bf9\u8c61\u4e4b\u95f4\u6267\u884c\u4e8c\u5206\u56fe\u5339\u914d</li> </ul> <p>DETR simplifies the detection pipeline by dropping multiple hand-designed components that encode prior knowledge, like spatial anchors or non-maximal suppression. </p> <p>DETR\u901a\u8fc7\u820d\u5f03\u591a\u4e2a\u7f16\u7801\u5148\u9a8c\u77e5\u8bc6\u7684\u624b\u5de5\u8bbe\u8ba1\u7ec4\u4ef6\uff0c\u5982\u7a7a\u95f4\u951a\u70b9\u6216\u975e\u6781\u5927\u503c\u6291\u5236\uff0c\u7b80\u5316\u4e86\u68c0\u6d4b\u6d41\u7a0b\u3002</p> <p>Unlike most existing detection methods, DETR doesn\u2019t require any customized layers, and thus can be reproduced easily in any framework that contains standard CNN and transformer classes.1</p> <p>\u4e0e\u5927\u591a\u6570\u73b0\u6709\u7684\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u540c\uff0cDETR\u4e0d\u9700\u8981\u4efb\u4f55\u5b9a\u5236\u5c42\uff0c\u56e0\u6b64\u53ef\u4ee5\u5728\u5305\u542b\u6807\u51c6CNN\u548c\u53d8\u6362\u5668\u7c7b\u7684\u4efb\u4f55\u6846\u67b6\u4e2d\u8f7b\u677e\u590d\u73b0\u3002</p>"},{"location":"literature/ObjectDetection/3/#bipartite-matching-loss","title":"\u7b2c\u56db\u6bb5 bipartite matching loss","text":"<p>Compared to most previous work on direct set prediction, the main features of DETR are the conjunction of the bipartite matching loss and transformers with (non-autoregressive) parallel decoding [29,12,10,8]. </p> <p>DETR\u7684\u7279\u70b9\uff1a\u7ed3\u5408\u4e8c\u5206\u56fe\u5339\u914d\u635f\u5931\u548cTransformer\u7684\u5e76\u884c\u89e3\u7801\u635f\u5931</p> <p>\ud83d\udce2 transformers with (non-autoregressive) \u975e\u81ea\u56de\u5f52</p> <p>In contrast, previous work focused on autoregressive decoding with RNNs [43,41,30,36,42]. </p> <p>\u5148\u524d\u7684\u635f\u5931\u662f\uff1aRNN\u89e3\u7801\u5668\u7684\u81ea\u56de\u5f52\u635f\u5931</p> <p>Our matching loss function uniquely assigns a prediction to a ground truth object, and is invariant to a permutation of predicted objects, so we can emit them in parallel.</p> <p>\u5339\u914d\u635f\u5931\u51fd\u6570\u552f\u4e00\u5730\u5c06\u9884\u6d4b\u5206\u914d\u7ed9\u771f\u5b9e\u5bf9\u8c61\uff0c\u5e76\u4e14\u5bf9\u9884\u6d4b\u5bf9\u8c61\u7684\u6392\u5217\u662f\u4e0d\u53d8\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5e76\u884c\u5730\u8f93\u51fa\u5b83\u4eec\u3002</p>"},{"location":"literature/ObjectDetection/3/#baseline","title":"\u7b2c\u4e94\u6bb5 baseline","text":"<p>We evaluate DETR on one of the most popular object detection datasets, COCO [24], against a very competitive Faster R-CNN baseline [37]. </p> <p>\u6570\u636e\u96c6\uff1aobject detection datasets, COCO</p> <p>\u6a21\u578b\uff1aFaster R-CNN baseline</p> <p>More precisely, DETR demonstrates significantly better performance on large objects, a result likely enabled by the non-local computations of the transformer. </p> <p>DETR\u5728\u5927\u76ee\u6807\u7684\u68c0\u6d4b\u6027\u80fd\u6bd4\u8f83\u597d</p> <p>\u53ef\u80fd\u7684\u539f\u56e0\uff1aTransformer\u7684\u975e\u5c40\u90e8\u8ba1\u7b97\uff08\u662f\u7684\uff0cTransformer\u662f\u5bf9\u6240\u6709\u8bcd\uff0c\u4e24\u4e24\u4e4b\u95f4\u4efb\u610f\u53ef\u80fd\u5f97\u5173\u7cfb\u90fd\u8fdb\u884c\u5efa\u6a21\uff0c\u662f\u4e00\u79cd\u5168\u5c40\u5efa\u6a21\u65b9\u6cd5\uff0c\u95ee\u9898\u5c31\u662f \u4f1a\u5bf9\u4e0d\u90a3\u4e48\u91cd\u8981\u7684\u8bcd \u4e5f\u8fdb\u884c\u4e86\u5173\u6ce8\uff09</p> <p>It obtains, however, lower performances on small objects. We expect that future work will improve this aspect in the same way the development of FPN [22] did for Faster R-CNN.</p> <p>\u4f46\u662f\uff0c\u5c0f\u7269\u4f53\u68c0\u6d4b\u6027\u80fd\u5c31\u4e0d\u90a3\u4e48\u597d</p>"},{"location":"literature/ObjectDetection/3/#differ-from-standard-object-detectors","title":"\u7b2c\u516d\u6bb5 differ from standard object detectors","text":"<p>The new model requires extra-long training schedule and benefits from auxiliary decoding losses in the transformer. </p> <p>\u65b0\u6a21\u578b\uff08DETR\uff09\u9700\u8981\u4e00\u4e2a\u8d85\u957f\u7684\u8bad\u7ec3\u65f6\u95f4\u8868\uff0c\u5e76\u4e14\u4ecetransformer\u4e2d\u7684\u8f85\u52a9\u89e3\u7801\u635f\u5931\u4e2d\u53d7\u76ca</p>"},{"location":"literature/ObjectDetection/3/#extend-to-more-complex-tasks","title":"\u7b2c\u4e03\u6bb5 extend to more complex tasks","text":"<p>The design ethos of DETR easily extend to more complex tasks. </p> <p>\u53ef\u4ee5\u6269\u5c55\u5230\u5176\u4ed6\u4efb\u52a1</p> <p>In our experiments, we show that a simple segmentation head trained on top of a pretrained DETR outperfoms competitive baselines on Panoptic Segmentation [19], a challenging pixel-level recognition task that has recently gained popularity.</p> <p>\uff08\u5168\u666f\u5206\u5272\uff09\u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u5206\u5272\u5934\uff0c\u5b83\u5728\u9884\u8bad\u7ec3\u7684DETR\u4e4b\u4e0a\u8bad\u7ec3\uff0c\u5176\u6027\u80fd\u5728Panoptic\u5206\u5272[19]\u4e0a\u8d85\u8d8a\u4e86\u7ade\u4e89\u57fa\u7ebf\uff0cPanoptic\u5206\u5272\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u50cf\u7d20\u7ea7\u8bc6\u522b\u4efb\u52a1\uff0c\u6700\u8fd1\u53d8\u5f97\u6d41\u884c\u8d77\u6765\u3002</p>"},{"location":"literature/ObjectDetection/3/#related-work","title":"\u2b50\ufe0f Related work","text":"<p>Our work build on prior work in several domains: bipartite matching losses for set prediction, encoder-decoder architectures based on the transformer, parallel decoding, and object detection methods.</p> <p>DETR\u6d89\u53ca\u5230\u7684\u76f8\u5173\u9886\u57df\uff1a</p> <ul> <li>bipartite matching losses for set prediction \u5bf9\u4e8e\u96c6\u5408\u9884\u6d4b\u7684\u4e8c\u5206\u56fe\u5339\u914d\u635f\u5931</li> <li>encoder-decoder architectures based on the transformer </li> <li>parallel decoding \u5e76\u884c\u89e3\u7801</li> <li>object detection methods.</li> </ul>"},{"location":"literature/ObjectDetection/3/#1set-prediction-rightarrow","title":"\u76f8\u5173\u9886\u57df\u5de5\u4f5c1\uff1aSet Prediction $\\rightarrow  $ \u5308\u7259\u5229\u635f\u5931","text":"<p>There is no canonical\uff08\u6807\u51c6\u7684\uff09 deep learning model to directly predict sets. </p> <p>\u5bf9\u4e8e\u96c6\u5408\u9884\u6d4b\uff0c\u6ca1\u6709\u6807\u51c6\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b</p> <p>The basic set prediction task is multilabel classification for which the baseline approach, one-vs-rest, does not apply to problems such as detection where there is an underlying structure between elements (i.e., near-identical boxes). </p> <p>\u96c6\u5408\u9884\u6d4b\u4efb\u52a1\u662f\u4e00\u79cd\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\uff0c\u4e00\u5bf9\u591a\uff0c\u4e0d\u9002\u5408\u68c0\u6d4b\u4efb\u52a1</p> <p>\u68c0\u6d4b\u4efb\u52a1\u7684\u7279\u70b9\uff1a\u5143\u7d20\u4e4b\u95f4\u6709\u7ed3\u6784\u5173\u7cfb\uff0c\u4f8b\u5982\uff0c\u68c0\u6d4b\u4e2d\u7684\u8fd1\u76f8\u540c\u6846</p> <p>The first difficulty in these tasks is to avoid near-duplicates.\uff08\u907f\u514d\u8fd1\u4f3c\u91cd\u590d\uff09 </p> <p>\u68c0\u6d4b\u4efb\u52a1\u7684\u7b2c\u4e00\u4e2a\u96be\u70b9\uff1a\u53bb\u91cd</p> <p>Most current detectors use postprocessings such as non-maximal suppression to address this issue, but direct set prediction are postprocessing-free. </p> <p>\u68c0\u6d4b\u4efb\u52a1\u7684\u540e\u5904\u7406\u65b9\u6cd5\uff1aNMS</p> <p>\u4f46\u662f\uff0c\u96c6\u5408\u9884\u6d4b\u662f \u4e0d\u9700\u8981\u8fdb\u884c\u540e\u5904\u7406\u7684</p> <p>They need global inference schemes that model interactions between all predicted elements to avoid redundancy. </p> <p>\u96c6\u5408\u9884\u6d4b\u9700\u8981 \u5168\u5c40\u63a8\u7406</p> <p>\uff08\u8bf4\u7684\u662fIOU\u3001NMS\uff09\u9700\u8981\u5168\u5c40\u63a8\u7406\u65b9\u6848\uff0c\u8fd9\u4e9b\u65b9\u6848\u6a21\u62df\u6240\u6709\u9884\u6d4b\u5143\u7d20\u4e4b\u95f4\u7684\u4ea4\u4e92\u4ee5\u907f\u514d\u5197\u4f59</p> <p>For constant-size set prediction, dense fully connected networks [9] are sufficient but costly. A general approach is to use auto-regressive sequence models such as recurrent neural networks [48].</p> <p>\u5bf9\u4e8e\u56fa\u5b9a\u5927\u5c0f\u7684\u96c6\u5408\u9884\u6d4b\u95ee\u9898\uff1a\u5168\u8fde\u63a5\u7f51\uff0c\u7f3a\u70b9\uff1a\u6210\u672c\u9ad8</p> <p>\u89e3\u51b3\uff1a\u81ea\u56de\u5f52\u6a21\u578b RNN</p> <p>In all cases, the loss function should be invariant by a permutation of the predictions. </p> <p>\u96c6\u5408\u9884\u6d4b\u7684\u635f\u5931\u51fd\u6570 \u5e94\u8be5\u4e0e\u9884\u6d4b\u7684\u987a\u5e8f \u65e0\u5173</p> <p>The usual solution is to design a loss based on the Hungarian algorithm [20], to find a bipartite matching between ground-truth and prediction. </p> <p>\u5982\u4f55\u5b9e\u73b0 \u635f\u5931\u51fd\u6570\u4e0e\u987a\u5e8f\u65e0\u5173\uff1f \u5308\u7259\u5229\u7b97\u6cd5</p> <p>\u5bfb\u627egt\u548c\u9884\u6d4b\u7684\u4e8c\u5206\u5339\u914d</p> <p>This enforces permutation-invariance, and guarantees that each target element has a unique match. </p> <p>\u7279\u70b9\uff1a</p> <ul> <li>\u987a\u5e8f\u6392\u5217\u4e0d\u53d8\u5f62</li> <li>\u552f\u4e00\u5339\u914d</li> </ul> <p>We follow the bipartite matching loss approach. In contrast to most prior work however, we step away from autoregressive models and use transformers with parallel decoding.</p> <ul> <li>DETR \u4f7f\u7528 \u4e8c\u5206\u5339\u914d\u635f\u5931\u65b9\u6cd5</li> <li>\u4f7f\u7528Transformer\u7684\u5e76\u884c\u89e3\u7801\u6a21\u578b</li> <li>\u6ca1\u6709\u7528\u81ea\u56de\u5f52\u6a21\u578b</li> </ul>"},{"location":"literature/ObjectDetection/3/#2transformers-and-parallel-decoding","title":"\u76f8\u5173\u5de5\u4f5c2\uff1aTransformers and Parallel Decoding","text":""},{"location":"literature/ObjectDetection/3/#transformer","title":"\u7b2c\u4e00\u6bb5 \u4ecb\u7ecdTransformer\u662f\u4ec0\u4e48\uff0c\u4ee5\u53ca\u4f18\u70b9","text":"<p>Transformers  were introduced by Vaswani et al . [47] as a new attention-based building block for machine translation. </p> <p>Attention mechanisms  [2] are neural network layers that aggregate information from the entire input sequence. </p> <p>Transformers introduced self-attention layers, which, similarly to Non-Local Neural Networks [49], scan through each element of a sequence and update it by aggregating information from the whole sequence. </p> <p>\u81ea\u6ce8\u610f\u529b\u5c42\uff0c\u7c7b\u4f3c\u975e\u5c40\u90e8\u795e\u7ecf\u7f51\u7edc</p> <p>\u626b\u63cf\u5e8f\u5217\u4e2d\u6bcf\u4e2a\u5143\u7d20\uff0c\u805a\u5408\u6574\u4e2a\u5e8f\u5217\u7684\u4fe1\u606f\u5e76\u8fdb\u884c\u66f4\u65b0</p> <p>One of the main advantages  of attention-based models is their global computations and perfect memory, which makes them more suitable than RNNs on long sequences. Transformers are now replacing RNNs in many problems in natural language processing, speech processing and computer vision [8,27,45,34,31].</p>"},{"location":"literature/ObjectDetection/3/#tr","title":"\u7b2c\u4e8c\u6bb5  tr\u7684\u7f3a\u70b9 \u4ee5\u53ca \u6211\u4eec","text":"<p>Transformers were first used in auto-regressive models, following early sequence-to-sequence models [44], generating output tokens one by one. </p> <p>Transforme\u7684\u5e94\u7528\u9886\u57df\uff1a\u81ea\u56de\u5f52\u6a21\u578b\uff0cseq2seq\u6a21\u578b\uff0cone by one\u8f93\u51fa</p> <p>However, the prohibitive inference cost (proportional to output length, and hard to batch) lead to the development of parallel sequence generation, in the domains of audio [29], machine translation [12,10], word representation learning [8], and more recently speech recognition [6]. </p> <p>Transformer\u7684\u7f3a\u70b9\uff1a\u5e73\u65b9\u590d\u6742\u5ea6\uff0c\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c</p> <p>We also combine transformers and parallel decoding for their suitable trade-off between computational cost and the ability to perform the global computations required for set prediction.</p> <p>\u6211\u4eec\u7684\u505a\u6cd5\uff1aTransformer+\u5e76\u884c\u89e3\u7801</p> <p>\u6743\u8861 \u8ba1\u7b97\u6210\u672c \u548c \u5168\u5c40\u8ba1\u7b97\u80fd\u529b</p>"},{"location":"literature/ObjectDetection/3/#3-object-detection","title":"\u76f8\u5173\u5de5\u4f5c3 Object detection","text":""},{"location":"literature/ObjectDetection/3/#_2","title":"\u7b2c\u4e00\u6bb5 \u662f\u4ec0\u4e48","text":"<p>Most  modern object detection  methods make predictions relative to some initial guesses. </p> <p>\u73b0\u5728\u7684\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5 \u9700\u8981\u7ed9\u51fa \u521d\u59cb\u731c\u6d4b</p> <p>Two-stage detectors  [37,5] predict boxes w.r.t. proposals, whereas  single-stage methods  make predictions w.r.t. anchors [23] or a grid of possible object centers [53,46]. </p> <p>\u4e24\u9636\u6bb5\u68c0\u6d4b\u65b9\u6cd5 &amp; \u5355\u9636\u6bb5\u68c0\u6d4b\u65b9\u6cd5</p> <p>\u4e24\u9636\u6bb5\u9884\u6d4b \u9884\u6d4b\u6846</p> <p>\u5355\u9636\u6bb5\u9884\u6d4b \u9884\u6d4b\u951a\u70b9 or \u76ee\u6807\u4e2d\u5fc3\u7684\u7f51\u683c</p> <p>Recent work [52] demonstrate that the final performance of these systems heavily depends on the exact way these initial guesses are set.</p> <p>\u7f3a\u70b9\uff1a\u4f9d\u8d56\u521d\u503c</p> <p>In our model we are able to remove this hand-crafted process and streamline the detection process by directly predicting the set of detections with absolute box prediction w.r.t. the input image rather than an anchor.</p> <p>\u6211\u4eec\uff1a</p> <p>how\uff1f</p> <ul> <li>\u79fb\u9664\u624b\u5de5\u8fc7\u7a0b</li> <li>\u7b80\u5316\u68c0\u6d4b\u8fc7\u7a0b</li> </ul> <p>what\uff1f</p> <ul> <li>\uff08\u76f4\u63a5\u8bf4\u662f\u4ec0\u4e48\uff09\u76f4\u63a5\u9884\u6d4b\u68c0\u6d4b\u96c6\uff1a\u76f4\u63a5\u9884\u6d4b\u6846</li> <li>\uff08\u7528\u76f8\u5bf9\u5173\u7cfb\u8bf4\u662f\u4ec0\u4e48\uff09\u662f\u56fe\u50cf\u800c\u4e0d\u662f\u951a\u70b9</li> </ul>"},{"location":"literature/ObjectDetection/3/#set-based-loss","title":"\u7b2c\u4e00\u90e8\u5206 Set-based loss.\u57fa\u4e8e\u96c6\u5408\u7684\u635f\u5931","text":""},{"location":"literature/ObjectDetection/3/#_3","title":"\u7b2c\u4e8c\u6bb5","text":"<p>Several object detectors [9,25,35] used the bipartite matching loss. However, in these early deep learning models, the relation between different prediction was modeled with convolutional or fully-connected layers only and a hand-designed NMS post-processing can improve their performance. More recent detectors [37,23,53] use non-unique assignment rules between ground truth and predictions together with an NMS.</p>"},{"location":"literature/ObjectDetection/3/#_4","title":"\u7b2c\u4e09\u6bb5","text":"<p>Learnable NMS methods [16,4] and relation networks [17] explicitly model relations between different predictions with attention. Using direct set losses, they do not require any post-processing steps. However, these methods employ additional hand-crafted context features like proposal box coordinates to model relations between detections efficiently, while we look for solutions that reduce the prior knowledge encoded in the model.</p>"},{"location":"literature/ObjectDetection/3/#recurrent-detectors","title":"\u7b2c\u4e8c\u90e8\u5206 Recurrent detectors.  \u68c0\u6d4b\u65b9\u6cd5","text":""},{"location":"literature/ObjectDetection/3/#_5","title":"\u7b2c\u56db\u6bb5","text":"<p>Closest to our approach are end-to-end set predictions for object detection [43] and instance segmentation [41,30,36,42]. Similarly to us, they use bipartite-matching losses with encoder-decoder architectures based on CNN activations to directly produce a set of bounding boxes. These approaches, however, were only evaluated on small datasets and not against modern baselines. In particular, they are based on autoregressive models (more precisely RNNs), so they do not leverage the recent transformers with parallel decoding.</p>"},{"location":"literature/ObjectDetection/3/#_6","title":"\u2b50\ufe0f \u7ed3\u8bba","text":""},{"location":"literature/ObjectDetection/3/#_7","title":"\u7b2c\u4e00\u6bb5","text":"<p>We presented DETR, a new design for object detection systems based on transformers and bipartite matching loss for direct set prediction. The approach achieves comparable results to an optimized Faster R-CNN baseline on the challenging COCO dataset. DETR is straightforward to implement and has a flexible architecture that is easily extensible to panoptic segmentation, with competitive results. In addition, it achieves significantly better performance on large objects than Faster R-CNN, likely thanks to the processing of global information performed by the self-attention. </p>"},{"location":"literature/ObjectDetection/3/#_8","title":"\u7b2c\u4e8c\u6bb5","text":"<p>This new design for detectors also comes with new challenges, in particular regarding training, optimization and performances on small objects. Current detectors required several years of improvements to cope with similar issues, and we expect future work to successfully address them for DETR.</p>"},{"location":"literature/ObjectDetection/3/#the-detr-model","title":"\u2b50\ufe0f The DETR model","text":"<p>Two ingredients are essential for direct set predictions in detection: (1) a set prediction loss that forces unique matching between predicted and ground truth boxes; (2) an architecture that predicts (in a single pass) a set of objects and models their relation. We describe our architecture in detail in Figure 2.</p> <p>Object detection set prediction loss</p>"},{"location":"literature/TSP/","title":"TSP","text":""},{"location":"literature/TSP/#tsp","title":"TSP","text":"2025-03-04 21:01:002025-09-28 12:54:06 <p> \u7ea6 665 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>ML \u9886\u57df\u4e09\u5927\u9876\u520a </p> <ul> <li>NIPS\uff08\u6691\u5047\u8981\u5f00\u59cb\uff0c\u6536\u7a3f\u91cf\u975e\u5e38\u5927\uff0c\u540c\u65f6\u8d28\u91cf\u975e\u5e38\u8fc7\u786c\uff09\u2014\u2014OpenReview</li> <li>ICLR\uff08\u6691\u5047\u521a\u7ed3\u675f\uff09\u2014\u2014OpenReview</li> <li>ICML\uff08\u5bd2\u5047\u7ed3\u675f\uff09</li> </ul> <p>\u5173\u4e8e\u5206\u7c7b\uff1a</p> <ul> <li>Oral\uff1a12 \u5206\u949f\u53e3\u5934\u9648\u8ff0</li> <li>Splotlights\uff08\u7279\u522b\u5173\u6ce8\uff09\uff1a4 \u5206\u949f\u7684\u53e3\u5934\u6f14\u793a</li> <li>Posters\uff08\u6d77\u62a5\uff09\uff1a\u5176\u4f59\u88ab\u63a5\u6536\u7684\u8bba\u6587\u90fd\u662f\u6d77\u62a5\u6f14\u793a</li> <li>ORALS &gt;  Splotlights \uff1e POSTERS</li> </ul> <ul> <li> NeurIPS2019\u3001LogTrans</li> <li> ICLR2020\u3001Reformer</li> </ul> <ul> <li> NeurIPS2021 \u3001Autoformer\u3001\u6e05\u534e\u5927\u5b66\u5434\u6d77\u65ed</li> <li> AAAI2021(Best Paper)\u3001Informer</li> </ul> <ul> <li> ICLR2022  (Oral)\u3001Pyraformer\u3001\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66\u3001\u8682\u8681\u96c6\u56e2</li> <li> ICML2022\u3001Fedformer\u3001\u963f\u91cc\u8fbe\u6469\u9662</li> <li> IJCAI2022\u3001Triformer</li> <li> NeuraIPS2022\u3001SCINet</li> </ul> <ul> <li> AAAI2023 \u3001 LTSF-Linear(DLinear\u3001NLinear)</li> <li> NeurIPS2023 \u3001TLNets</li> <li> NeurIPS2023 (Spotlight)\u3001WITRAN\u3001\u5317\u4eac\u4ea4\u901a\u5927\u5b66\u4e07\u6000\u5b87\u56e2\u961f</li> <li> ICLR2023\u3001Crossformer</li> <li> 2023\u3001TimesNet</li> <li> ICLR2023\u3001PatchTST</li> <li> ICLR2023\u3001SegRNN\u3001\u534e\u5357\u7406\u5de5\u5927\u5b66</li> </ul> <ul> <li> ICLR2024\u3001TimeMixer\u3001\u8682\u8681\u96c6\u56e2\u3001\u6e05\u534e\u5927\u5b66\u5434\u6d77\u65ed</li> <li> ICLR 2024\u3001\u3001iTransformer\u3001</li> <li> 2024\u3001UnetTSF\u3001\u4e2d\u56fd\u79d1\u5b66\u6280\u672f\u5927\u5b66\u3001\u4e2d\u56fd\u79d1\u5b66\u9662</li> <li> VLDB2024\uff08CCF-A\uff09\u3001TFB\u3001\u534e\u4e1c\u5e08\u8303\u5927\u5b66\u51b3\u7b56\u667a\u80fd\u5b9e\u9a8c\u5ba4\uff0c\u534e\u4e3a\u4e91</li> </ul> <p>PaperWithCode\uff1aTime Series Forecasting  </p> <ul> <li>\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3001\u901a\u9053\u72ec\u7acb</li> <li>\u6ce8\u610f\u529b\u673a\u5236\u3001\u590d\u6742\u5ea6</li> </ul>"},{"location":"literature/TSP/#_1","title":"\u8bba\u6587\u5173\u952e\u8bcd","text":"<p>former \u7cfb\u3001linear \u7cfb\u3001RNN \u7cfb\u5206\u522b\u9002\u7528\u4e8e\u4ec0\u4e48\u60c5\u51b5\uff1f\uff08TFB \u4e2d\u505a\u4e86\u8be6\u7ec6\u7684\u5b9e\u9a8c\uff0c\u6709\u7ed3\u8bba\u3002</p>"},{"location":"literature/TSP/#-former","title":"- former \u7cfb\u9002\u7528\u4e8e\u5468\u671f\u6027\u660e\u663e\u7684\u6570\u636e","text":""},{"location":"literature/TSP/#informer","title":"Informer","text":"<p>\u6982\u7387\u7a00\u758f\u81ea\u6ce8\u610f\u529b</p>"},{"location":"literature/TSP/#autoformer","title":"Autoformer","text":"<p>\u5f15\u5165\u5e8f\u5217\u5206\u89e3&amp;\u81ea\u76f8\u5173\u673a\u5236</p> <p>\u57fa\u672c\u9075\u5faa\u539f\u59cb Transformer \u7684\u8bbe\u8ba1 \u6846\u67b6</p> <p>\u5e94\u7528\u4e8e2022\u5317\u4eac\u51ac\u5965\u4f1a 10 \u5206\u949f\u5929\u6c14\u9884\u6d4b\u3001\u6e05\u534e\u8f6f\u9662</p>"},{"location":"literature/TSP/#pyraformer","title":"Pyraformer","text":"<p>\u91d1\u5b57\u5854\u6ce8\u610f\u529b\uff0c\u5f88\u590d\u6742\uff0c\u6709\u8bc1\u660e\uff0c\u5f15\u5165\u4e86\u65b0\u6982\u5ff5\uff1a\u6700\u5927\u4fe1\u53f7\u4f20\u9012\u8def\u5f84</p>"},{"location":"literature/TSP/#fedformer","title":"Fedformer","text":"<p>\u9891\u57df\u4fe1\u606f\uff0c\u5085\u91cc\u53f6&amp;\u5c0f\u6ce2\uff0c\u6539\u8fdbAutoformer\u3001\u4e13\u5bb6\u6df7\u5408\u5206\u89e3\uff0c\u6709\u9891\u57df\u7684\u90fd\u4e0d\u7b80\u5355</p>"},{"location":"literature/TSP/#tsf-linear","title":"TSF-Linear","text":"<p>\uff1a Informer\u3001Pyraformer\u3001Autoformer\u3001Fedformer </p> <p>\u63d0\u51fa\u4e86 6 \u4e2a\u8d28\u7591\uff1a</p> <ol> <li>\u96be\u9053\u4e0d\u662f\u5386\u53f2\u56de\u6eaf\u7a97\u53e3\u8d8a\u957f\u8d8a\u597d\u5417\uff1f(\u8fd8\u771f\u4e0d\u662f\uff0c\u8f93\u5165\u5e8f\u5217\u592a\u957f\u4e86\u4ee5\u540e\uff0cTransformer \u7cfb\u7684\u6a21\u578b\u6027\u80fd\u53cd\u800c\u4e0b\u964d\u4e86)</li> <li>Transformer \u7cfb\u6a21\u578b\u4ece\u56de\u6eaf\u7a97\u53e3\u5b66\u5230\u4e86\u4ec0\u4e48\uff1f(close input&amp;far input)</li> <li>\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6709\u7528\u5417\uff1f\uff08Informer \u9010\u6e10\u6f14\u53d8\u4e3a\u7ebf\u6027\u6a21\u578b\u6027\u80fd upup\uff09</li> <li>Temporal Embedding\u771f\u7684\u4fdd\u7559\u4e86\u65f6\u95f4\u7684\u987a\u5e8f\u4fe1\u606f\u5417\uff1f(\u4f5c\u8005\u5bf9\u8f93\u5165\u98a0\u5012\u987a\u5e8f\uff0c\u53d1\u73b0Transformer \u7cfb\u7684\u6a21\u578b\u5e76\u6ca1\u6709\u53d7\u5230\u592a\u5927\u7684\u5f71\u54cd)</li> <li>\u5d4c\u5165\u7b56\u7565\u8d77\u4e86\u4ec0\u4e48\u4f5c\u7528\uff1f</li> <li>\u662f\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u89c4\u6a21\u9650\u5236\u4e86\u6a21\u578b\u7684\u6027\u80fd\u5417\uff1f(\u7136\u800c\u5e76\u6ca1\u6709\uff0c\u53cd\u800c\u4fdd\u5b58\u4e86\u5b8c\u6574\u5468\u671f\u4fe1\u606f\u7684\u8bad\u7ec3\u6570\u636e\u66f4\u597d)</li> <li>\u6548\u7387\u548c\u590d\u6742\u5ea6\u7684\u4f18\u5148\u7ea7\u771f\u7684\u90a3\u4e48\u91cd\u8981\u5417\uff1f</li> </ol>"},{"location":"literature/TSP/#witran","title":"WITRAN","text":"<p>RNN \u7cfb\u6587\u7ae0 </p> <p>\u6c34\u6ce2\u7eb9\u4fe1\u606f\u4f20\u8f93\u5faa\u73af\u52a0\u901f\u7f51\u7edc</p> <ul> <li>\u975e\u9010\u70b9\u8bed\u4e49\u4fe1\u606f\u6355\u83b7</li> <li>\u5185\u5b58\u5360\u7528 &amp;  \u65f6\u95f4\u590d\u6742\u5ea6</li> </ul> <p>\u8d21\u732e\uff1a</p> <p>\uff081\uff09\u6c34\u6ce2\u7eb9\u4fe1\u606f\u4f20\u8f93\uff1aWIT</p> <p>\uff082\uff09\u6c34\u5e73\u5782\u76f4 \u95e8\u63a7\u9009\u62e9\u5355\u5143\uff1a HVGSU</p> <p>\uff083\uff09\u5faa\u73af\u52a0\u901f\u7f51\u7edc\uff1aRAN</p>"},{"location":"literature/TSP/0_note/","title":"\u65f6\u5e8f\u9884\u6d4b\u57fa\u7840","text":""},{"location":"literature/TSP/0_note/#_1","title":"\u65f6\u5e8f\u9884\u6d4b\u57fa\u7840","text":"2025-03-04 21:01:002025-09-28 12:54:06 <p> \u7ea6 1392 \u4e2a\u5b57  42 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 7 \u5206\u949f</p>"},{"location":"literature/TSP/0_note/#_2","title":"\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u7684\u5b9a\u4e49","text":""},{"location":"literature/TSP/0_note/#_3","title":"\u57fa\u7840\u77e5\u8bc6","text":"<p>\u3010\u53c2\u770b\u3011</p> <p>\u5085\u91cc\u53f6\u5206\u6790\u4e4b\u6390\u6b7b\u6559\u7a0b\uff08\u5b8c\u6574\u7248\uff09\u66f4\u65b0\u4e8e2014.06.06</p> <p>\u3010\u4f38\u7f29 \u65cb\u8f6c\u4e0e\u590d\u6570\uff1f\u3011\u590d\u6570\u7684\u7269\u7406\u610f\u4e49\u662f\u4ec0\u4e48\uff1f</p>"},{"location":"literature/TSP/0_note/#_4","title":"\u590d\u6570\uff1f","text":"<ul> <li>\u4f38\u7f29\u4e0e\u65cb\u8f6c\u4e0e\u590d\u6570</li> </ul> <ul> <li>\u590d\u6570\u8868\u793a\uff0c\u4fdd\u7559\u4e86\u4e8c\u7ef4\u4fe1\u606f</li> </ul> <p>\u590d\u6570\u76f4\u89c2\u7684\u7406\u89e3\u5c31\u662f\u65cb\u8f6c\uff01\\(4*i*i = -4\\)</p> <p>\u5c31\u662f\u201c4\u201d\u5728\u6570\u8f74\u4e0a\u65cb\u8f6c\u4e86180\u5ea6\u3002\u90a3\u4e484*i\u5c31\u662f\u65cb\u8f6c\u4e8690\u5ea6\u3002</p> <p></p> <p></p> <p>\u55ef\uff0c\u4e3a\u5565\uff1f\u6307\u6570\u4e0a\u52a0 i\uff0c\u5c31\u8f6c\u8d77\u6765\u4e86\uff0c\u8fd8\u662f\u87ba\u65cb\u7ebf\uff1f\u5f97\u6709\u4e00\u4e2a\u4e0d\u53d8\u91cf\uff0c\u6bd4\u5982 \\(sin^2x+cos^2x=1\\) \u600e\u4e48\u4f53\u73b0</p> <p></p>"},{"location":"literature/TSP/0_note/#_5","title":"\u6b27\u62c9\u516c\u5f0f","text":"<p>\\(e^{ix}=cosx+isinx\\)</p> <p>\\(e^{ix}\\) \u4e2d <code>x</code> \u662f\u4e0d\u65ad\u53d8\u6362\u7684\uff0c\u662f\u4e00\u6761\u9006\u65f6\u9488\u65cb\u8f6c\u7684\u87ba\u65cb\u7ebf</p> <p>\u95ee\u9898\uff1a\u4e3a\u4ec0\u4e48 sinx \u548c cosx \u80fd\u8ddf\u6570\u8f74\u8054\u7cfb\u8d77\u6765\uff1f</p> <p></p> <p>\u8fd9\u91cc\u6709\u4e00\u6761\u6570\u8f74\uff0c\u5728\u6570\u8f74\u4e0a\u6709\u4e00\u4e2a\u7ea2\u8272\u7684\u7ebf\u6bb5\uff0c\u5b83\u7684\u957f\u5ea6\u662f1</p> <ul> <li> <p>\u5f53\u5b83\u4e58\u4ee53\u7684\u65f6\u5019\uff0c\u5b83\u7684\u957f\u5ea6\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u53d8\u6210\u4e86\u84dd\u8272\u7684\u7ebf\u6bb5\uff1b</p> </li> <li> <p>\u800c\u5f53\u5b83\u4e58\u4ee5-1\u7684\u65f6\u5019\uff0c\u5c31\u53d8\u6210\u4e86\u7eff\u8272\u7684\u7ebf\u6bb5\uff0c\u6216\u8005\u8bf4 \u7ebf\u6bb5\u5728\u6570\u8f74\u4e0a\u56f4\u7ed5\u539f\u70b9\u65cb\u8f6c\u4e86180\u5ea6\u3002</p> </li> </ul> <p>\u6211\u4eec\u77e5\u9053\u4e58<code>-1</code>\u5176\u5b9e\u5c31\u662f\u4e58\u4e86\u4e24\u6b21 <code>i</code>\u4f7f\u7ebf\u6bb5\u65cb\u8f6c\u4e86180\u5ea6\uff0c\u90a3\u4e48\u4e58\u4e00\u6b21 <code>i</code> \u5462\u2014\u2014\u7b54\u6848\u5f88\u7b80\u5355\u2014\u2014\u9006\u65f6\u9488\u65cb\u8f6c\u4e8690\u5ea6</p> <p></p> <p>\u540c\u65f6\uff0c\u6211\u4eec\u83b7\u5f97\u4e86\u4e00\u4e2a\u5782\u76f4\u7684\u865a\u6570\u8f74\u3002\u5b9e\u6570\u8f74\u4e0e\u865a\u6570\u8f74\u5171\u540c\u6784\u6210\u4e86\u4e00\u4e2a\u590d\u6570\u7684\u5e73\u9762\uff0c\u4e5f\u79f0\u590d\u5e73\u9762\u3002\u8fd9\u6837\u6211\u4eec\u5c31\u4e86\u89e3\u5230\uff0c\u4e58\u865a\u6570<code>i</code>\u7684\u4e00\u4e2a\u529f\u80fd\u2014\u2014\u65cb\u8f6c\u3002</p> <ul> <li>\\(sinx\\) \u662f\u5355\u4f4d\u5706\u534a\u5f84\u5230 \\(x\\) \u8f74\u7684\u8ddd\u79bb\uff0c\u4ece \\(x\\) \u8f74\u8eba\u7740\uff0c\u5f00\u59cb\u9006\u65f6\u9488\u8f6c</li> <li>\\(cosx\\) \u662f\u5355\u4f4d\u5706\u534a\u5f84\u4ece \\(y\\) \u8f74\u5f00\u59cb\u8f6c\uff0c\u63cf\u8ff0\u5230 \\(x\\) \u8f74\u7684\u8ddd\u79bb\uff0c\u7ee7\u7eed\u9006\u65f6\u9488\u8f6c</li> <li> <p>\u6240\u4ee5\u6309\u7167\u9006\u65f6\u9488\u65cb\u8f6c\u6cd5\u5219\uff1a1=</p> </li> <li> <p>\\(sin0=0\uff1bcos0=1\uff1b1=cos0+sin0\\)</p> </li> <li>\\(sin90=1\uff1bcos90=0\uff1b1=sin90+cos90\u00b0\\)</li> <li>\\(e^{ix}=cosx+isinx\\)</li> <li>\u4e3a\u4ec0\u4e48  \\(e^{ix}=cosx+isinx\\) \u4e0d\u7b49\u4e8e \\(sinx+icosx\\)</li> </ul> <p></p> <p>\u8fd8\u662f\u6298\u817e\u4e0d\u660e\u767d\uff0c\u5982\u679c\u90fd\u662f\u5355\u4f4d\u5706\u4e0a\u7684\u70b9\uff1a</p> <ul> <li>\u5982\u679c y \u8f74\u7684\u5ea6\u91cf\u662f 1\uff0c\u90a3\u4e48\u5c31\u662f\uff0ccos x,sinx\uff0c\u56e0\u4e3a\u8981\u4fdd\u8bc1\u6a21\u957f\u7b49\u4e8e 1</li> <li>\u5982\u679c y \u8f74\u7684\u5ea6\u91cf\u662f i\uff0c\u70b9\u8fd8\u662f\uff0ccosx,sinx\uff0c\u8fd8\u8981\u4fdd\u8bc1\u6a21\u957f\u662f 1\uff0c\u90a3\u5c31\u662f\uff0cisinx+cosx</li> <li>\u56e0\u4e3a sinx \u7684\u5b9a\u4e49\u5c31\u662f\uff0c\u5230 x \u8f74\u7684\u8ddd\u79bb\uff0c\u4ece x \u8f74\u7684\u6b63\u65b9\u5411\u5f00\u59cb\u8f6c\uff0c\u6240\u4ee5\u5728\u590d\u6570\u57df\uff0c\u540c\u6837\u662f sinx \u7684\u8ddd\u79bb\u5ea6\u91cf\uff0c\u5c31\u662f isinx</li> <li>\u90a3\u5982\u679c y \u8f74\u5ea6\u91cf\u5355\u4f4d\u662f 10\u300150\uff0c\u70b9\u8fd8\u662f cosx\uff0csinx\uff0c\u4ece x \u8f74\u7684\u6b63\u65b9\u5411\u5f00\u59cb\u8f6c\uff0c\u600e\u4e48\u4fdd\u8bc1\u6a21\u957f\u662f 1\uff0c\u4e0d\u77e5\u9053\uff0c\u8fd8\u662f\u8bf4\uff0c\u8fd9\u79cd\u5047\u8bbe\u5c31\u4e0d\u5bf9\uff0c\u56e0\u4e3a\u53ea\u6709\u590d\u6570\u6709\u6a21\u957f\u7684\u6982\u5ff5\u6709\u6807\u51c6\u7684\u8ba1\u7b97\u516c\u5f0f</li> <li>\u4e5f\u8bb8\u8d77\u4f5c\u7528\u7684\u70b9\u5728\uff0c\\(sin^{2}x+cos^{2}x = 1\\)\uff0c\u81f3\u4e8e\u522b\u7684\u90fd\u662f\u987a\u5e26\u7684\uff0c\u53ea\u662f\u521a\u597d\u5b9e\u6570\u57df\uff0c\u5355\u4f4d 1 \u7684\u5ea6\u91cf\u80fd\u591f\u6ee1\u8db3\u8fd9\u4e2a\u516c\u5f0f\uff0c\u4ee5\u53ca\u590d\u6570\u57df\u6a21\u957f\u7684\u8ba1\u7b97\u4e5f\u80fd\u591f\u6ee1\u8db3\u8fd9\u4e2a\u516c\u5f0f \\(a+bi\\)\uff0c\u4e8e\u662f\u53d1\u73b0\u4e86<code>cosx+isinx</code>\uff0c\u90a3\u4e3a\u4ec0\u4e48 <code>e^x</code>\u53ef\u4ee5\u4e0e <code>sinx</code> \u548c <code>cosx</code> \u8054\u7cfb\u8d77\u6765\u5462\uff1f</li> </ul>"},{"location":"literature/TSP/0_note/#_6","title":"\u9ad8\u9891\u4f4e\u9891","text":"<p>\u9ad8\u9891\u4fe1\u53f7\u7684\u5468\u671f\u8f83\u77ed\uff0c\u6ce2\u52a8\u9891\u7e41\uff0c\u53d8\u5316\u901f\u5ea6\u5feb\uff1b</p> <p>\u4f4e\u9891\u5219\u662f\u9891\u7387\u8f83\u4f4e\u7684\u4fe1\u53f7\u6216\u6ce2\u52a8\uff0c\u4f4e\u9891\u4fe1\u53f7\u7684\u5468\u671f\u8f83\u957f\uff0c\u6ce2\u52a8\u7f13\u6162\uff0c\u53d8\u5316\u901f\u5ea6\u6162\u3002</p>"},{"location":"literature/TSP/0_note/#fft","title":"FFT","text":"<p>\u52a8\u56fe</p> <p></p> <p></p> <p>\u52a8\u753b\u8bb2\u61c2\u5085\u91cc\u53f6\u53d8\u6362</p> <p></p> <p></p> <p>\u76f4\u89d2\u5750\u6807\u4e0b \uff084,3\uff09\uff0c\u5728 x \u8f74\u7684\u6295\u5f71\uff0cx \u7684\u5355\u4f4d\uff081,0\uff09\uff0c\u6240\u4ee5\u6295\u5f71\u7528\u5185\u79ef\u8868\u793a</p> <p>\uff084,3\uff09\u00d7\uff081,0\uff09=4 \u4e5f\u5c31\u662f\u5728 x \u8f74\u4e0a\u7684\u6295\u5f71</p> <p>\u5bf9\u5e94\u5230\u6df7\u5408\u6ce2\u00d7 \u7b2c\u4e00\u4e2a\u9891\u7387\u7684\u5355\u4f4d\u6ce2\uff0c\u5f97\u5230\u8fd9\u4e2a\u6ce2\u4e0a\u7684\u6295\u5f71\u957f\u5ea6\u4e5f\u5c31\u662f\u632f\u5e45</p> <p></p> <p>\u5185\u79ef\u7b49\u4e8e 0\uff0c\u8868\u793a\u4f5c\u7528\u4e0d\u53ef\u53d6\u4ee3\uff0c\u5c31\u6bd4\u5982 \\(x\\) \u8f74\\((1,0)\\)\u548c \\(y\\) \u8f74 \\((0,1)\\)\uff0c\u5185\u79ef=0\uff0c\u4f5c\u7528\u4e0d\u53ef\u53d6\u4ee3</p> <p></p> <p></p> <p></p> <p>\u8d1f\u9891\u7387\u548c\u76f4\u6d41\u5206\u91cf</p> <p></p>"},{"location":"literature/TSP/0_note/#_7","title":"\u5c0f\u6ce2\u53d8\u6362","text":""},{"location":"literature/TSP/0_note/#_8","title":"\u65b9\u6cd5\u7684\u5206\u7c7b","text":"<ul> <li>informer \u7684\u521b\u65b0\u5728\u4e8e</li> </ul> <p>\u6539\u8fdb\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u6240\u6709\u65f6\u95f4\u6b65\u90fd\u5728\u8ba1\u7b97\u4e24\u4e24\u76f8\u5173\u6027\uff0c\u4f46\u5176\u4e2d\u6700\u91cd\u8981\u7684\u662f\u524d\u51e0\u4e2a</p> <p>\u957f\u5c3e\u6548\u5e94</p> <p>\u7b5b\u9009\u6ce8\u610f\u529b\u9ad8\u7684 Query</p> <ul> <li>TimesNet\u7684\u521b\u65b0\u5728\u4e8e</li> </ul> <p>\u8f6c\u6362\u5468\u671f\u5185\u548c\u5468\u671f\u95f4\uff0c\u53d8\u6210\u4e8c\u7ef4\u7684\u505a\u5377\u79ef</p> <p>\u4e3e\u4f8b\u6765\u8bf4\uff0c\u8d85\u5e02\u6bcf 2 \u5929\u6253\u6298\uff0c\u6bcf\u4e09\u5929\u9001\u96f6\u98df\uff0c\u90a3\u7b2c\u516d\u5929\u5462\uff0c\u5373\u6253\u6298\u53c8\u9001\u96f6\u98df</p> <ul> <li>SegRNN</li> </ul> <p>\u5206\u6bb5\u65f6\u95f4\uff1b\u5e76\u884c\u8ba1\u7b97</p>"},{"location":"literature/TSP/0_note/#_9","title":"\u6570\u636e\u96c6\u4ecb\u7ecd","text":"<ul> <li>ETT\uff08\u7535\u53d8\u538b\u5668\u6e29\u5ea6\uff09</li> </ul> <p>\u7531\u4e24\u4e2a\u5c0f\u65f6\u7ea7\u6570\u636e\u96c6\uff08ETTh\uff09\u548c\u4e24\u4e2a 15 \u5206\u949f\u7ea7\u6570\u636e\u96c6\uff08ETTm\uff09\u7ec4\u6210\u3002</p> <p>\u5b83\u4eec\u4e2d\u7684\u6bcf\u4e00\u4e2a\u90fd\u5305\u542b 2016 \u5e74 7 \u6708\u81f3 2018 \u5e74 7 \u6708\u7684\u4e03\u79cd\u77f3\u6cb9\u548c\u7535\u529b\u53d8\u538b\u5668\u7684\u8d1f\u8f7d\u7279\u5f81\u3002</p> <ul> <li>traffic(\u4ea4\u901a) </li> </ul> <p>\u63cf\u8ff0\u4e86\u9053\u8def\u5360\u7528\u7387\u3002</p> <p>\u5b83\u5305\u542b 2015 \u5e74\u81f3 2016 \u5e74\u65e7\u91d1\u5c71\u9ad8\u901f\u516c\u8def\u4f20\u611f\u5668\u8bb0\u5f55\u7684\u6bcf\u5c0f\u65f6\u6570\u636e\u3002</p> <ul> <li>electrity\uff08\u7535\u529b\uff09</li> </ul> <p>\u4ece 2012 \u5e74\u5230 2014 \u5e74\u6536\u96c6\u4e86 321 \u4e2a\u5ba2\u6237\u6bcf\u5c0f\u65f6\u7535\u529b\u6d88\u8017</p> <ul> <li>exchange_rate\uff08\u6c47\u7387\uff09</li> </ul> <p>\u6536\u96c6\u4e86 1990 \u5e74\u81f3 2016 \u5e74 8 \u4e2a\u56fd\u5bb6\u7684\u6bcf\u65e5\u6c47\u7387</p> <ul> <li>Weather</li> </ul> <p>\u5305\u62ec 21 \u4e2a\u5929\u6c14\u6307\u6807\uff0c\u4f8b\u5982\u7a7a\u6c14\u6e29\u5ea6\u548c\u6e7f\u5ea6\u3002\u5b83\u7684\u6570\u636e\u5728 2020 \u5e74\u7684\u6bcf 10 \u5206\u949f\u8bb0\u5f55\u4e00\u6b21\u3002</p> <ul> <li>ILLNESS</li> </ul> <p>\u63cf\u8ff0\u4e86\u60a3\u6709\u6d41\u611f\u75be\u75c5\u7684\u60a3\u8005\u4e0e\u60a3\u8005\u6570\u91cf\u7684\u6bd4\u7387\u3002</p> <p>\u5b83\u5305\u62ec 2002 \u5e74\u81f3 2021 \u5e74\u7f8e\u56fd\u75be\u75c5\u63a7\u5236\u548c\u9884\u9632\u4e2d\u5fc3\u6bcf\u5468\u6570\u636e</p>"},{"location":"literature/TSP/0_note/#chanllenge","title":"chanllenge","text":""},{"location":"literature/TSP/0_note/#informer","title":"informer","text":"<p>\u5b83\u8bf4\u8981\u89e3\u51b3\u4f20\u7edf\u7684 Transformer \u4e0d\u80fd\u76f4\u63a5\u7528\u4e8e LTSF \u7684\u95ee\u9898\uff0c\u90a3\u95ee\u9898\u662f\uff0c\u4e3a\u4ec0\u4e48 Transformer \u80fd\u591f\u7528\u4e8e TSF\uff1f</p> <p>\u81ea\u5df1\u7684\u8bdd\u8bf4\uff1a</p> <p>Challenge1\uff1a \u81ea\u6ce8\u610f\u529b\u4e2d\u7684\u4e8c\u6b21\u590d\u6742\u5ea6--&gt; \u6982\u7387\u7a00\u758f\u81ea\u6ce8\u610f\u529b\u673a\u5236</p> <p>Challenge2\uff1a \u5806\u53e0\u5c42\u592a\u591a\u4e86-\u300b \u84b8\u998f\u673a\u5236\uff0c\uff08\u68af\u5f62\uff09</p> <p>Challenge3\uff1a \u81ea\u56de\u5f52\u5f0f\u9884\u6d4b\u592a\u6162\u4e86 --\u300b </p> <p></p> <p></p> <p></p> <p>3 \u4e2a\u6311\u6218\uff0c3 \u4e2a\u521b\u65b0\u70b9</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"literature/TSP/0_note/#_10","title":"\u6982\u7387\u7a00\u758f\u81ea\u6ce8\u610f\u529b\u673a\u5236 \u603b\u7ed3\uff1a","text":""},{"location":"literature/TSP/0_note/#_11","title":"\u81ea\u6ce8\u610f\u529b\u84b8\u998f\u673a\u5236","text":""},{"location":"literature/TSP/0_note/#_12","title":"\u89e3\u7801\u5668\u751f\u6210","text":""},{"location":"literature/TSP/0_note/#_13","title":"\u9884\u6d4b\u9884\u6d4b &amp; \u6eda\u52a8\u9884\u6d4b","text":"<p>\u4e0d\u518d\u662f \u81ea\u56de\u5f52\u9884\u6d4b</p>"},{"location":"literature/TSP/0_note/#_14","title":"\u603b\u7ed3","text":""},{"location":"literature/TSP/10_TimesMixer/","title":"2024\u3001TimeMixer","text":""},{"location":"literature/TSP/10_TimesMixer/#2024timemixer","title":"2024\u3001TimeMixer","text":"2025-04-14 22:46:482025-09-28 12:54:06 <p> \u7ea6 2354 \u4e2a\u5b57  4 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 12 \u5206\u949f</p> <p>2024ICLR\u3001\u8682\u8681\u96c6\u56e2\u3001\u5434\u6d77\u65ed</p> <p>\u8bba\u6587\uff1aTIMEMIXER: DECOMPOSABLE MULTISCALE MIXING FOR TIME SERIES FORECASTING</p> <p>\u4ee3\u7801\uff1ahttps://github.com/kwuking/TimeMixer </p> <ul> <li> \u4ee3\u7801\u6570\u636e\u6d41\u52a8\u56fe</li> </ul> <p>\u5173\u952e\u8bcd\uff1a </p> <p>TimeMixer = PDM + FMM</p> <ul> <li>\u53ef\u5206\u89e3</li> <li>\u591a\u5c3a\u5ea6\u6df7\u5408</li> </ul>"},{"location":"literature/TSP/10_TimesMixer/#_1","title":"\u6458\u8981","text":"<p>Time series forecasting is widely used in extensive applications, such as traffic planning and weather forecasting. However, real-world time series usually present intricate temporal variations, making forecasting extremely challenging. </p> <p>\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4f17\u591a\u9886\u57df\uff0c\u4f8b\u5982\u4ea4\u901a\u89c4\u5212\u548c\u5929\u6c14\u9884\u62a5\u3002\u7136\u800c\uff0c\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u901a\u5e38\u8868\u73b0\u51fa\u590d\u6742\u7684\u65f6\u95f4\u53d8\u5316\uff0c\u8fd9\u4f7f\u5f97\u9884\u6d4b\u6781\u5177\u6311\u6218\u6027\u3002</p> <p>Going beyond the mainstream paradigms of plain decomposition and multiperiodicity analysis, we analyze temporal variations in a novel view of multiscale-mixing, which is based on an intuitive but important observation that t==ime series present distinct patterns in different sampling scales.== </p> <p>\u4e0e\u4f20\u7edf\u7684\u7b80\u5355\u5206\u89e3\u548c\u591a\u5468\u671f\u6027\u5206\u6790\u8303\u5f0f\u4e0d\u540c\uff0c\u6211\u4eec\u4ece\u4e00\u79cd\u65b0\u9896\u7684\u591a\u5c3a\u5ea6\u6df7\u5408\u89c6\u89d2\u6765\u5206\u6790\u65f6\u95f4\u53d8\u5316\uff0c\u8fd9\u79cd\u89c6\u89d2\u57fa\u4e8e\u4e00\u4e2a\u76f4\u89c2\u4f46\u91cd\u8981\u7684\u89c2\u5bdf\u7ed3\u679c\uff1a\u65f6\u95f4\u5e8f\u5217\u5728\u4e0d\u540c\u7684\u91c7\u6837\u5c3a\u5ea6\u4e0a\u5448\u73b0\u51fa\u4e0d\u540c\u7684\u6a21\u5f0f\u3002</p> <p>The microscopic and the macroscopic information are reflected in fine and coarse scales respectively, and thereby complex variations can be inherently disentangled.</p> <p>\u5fae\u89c2\u548c\u5b8f\u89c2\u4fe1\u606f\u5206\u522b\u53cd\u6620\u5728\u7ec6\u7c92\u5ea6\u548c\u7c97\u7c92\u5ea6\u7684\u5c3a\u5ea6\u4e0a\uff0c\u4ece\u800c\u53ef\u4ee5\u5185\u5728\u5730\u89e3\u8026\u590d\u6742\u7684\u53d8\u5316\u3002</p> <p>Based on this observation, we propose TimeMixer as a fully MLP-based architecture with Past-Decomposable-Mixing (PDM) and Future-Multipredictor-Mixing (FMM) blocks to take full advantage of disentangled multiscale series in both past extraction and future prediction phases. </p> <p>\u57fa\u4e8e\u8fd9\u4e00\u89c2\u5bdf\u7ed3\u679c\uff0c\u6211\u4eec\u63d0\u51fa\u4e86TimeMixer\uff0c\u8fd9\u662f\u4e00\u79cd\u5b8c\u5168\u57fa\u4e8eMLP\uff08\u591a\u5c42\u611f\u77e5\u5668\uff09\u7684\u67b6\u6784\uff0c\u5305\u542bPast-Decomposable-Mixing\uff08PDM\uff09\u548cFuture-Multipredictor-Mixing\uff08FMM\uff09\u6a21\u5757\uff0c\u4ee5\u5145\u5206\u5229\u7528\u8fc7\u53bb\u63d0\u53d6\u548c\u672a\u6765\u9884\u6d4b\u9636\u6bb5\u4e2d\u89e3\u8026\u7684\u591a\u5c3a\u5ea6\u5e8f\u5217\u3002</p> <p>Concretely, PDM applies the decomposition to multiscale series and further mixes the decomposed seasonal and trend components in fine-to-coarse and coarse-to-fine directions separately, which successively aggregates the microscopic seasonal and macroscopic trend information.</p> <p>\u5177\u4f53\u6765\u8bf4\uff0cPDM\u5bf9\u591a\u5c3a\u5ea6\u5e8f\u5217\u8fdb\u884c\u5206\u89e3\uff0c\u5e76\u8fdb\u4e00\u6b65\u5728\u7ec6\u7c92\u5ea6\u5230\u7c97\u7c92\u5ea6\u548c\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u7684\u65b9\u5411\u4e0a\u5206\u522b\u6df7\u5408\u5206\u89e3\u540e\u7684\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6210\u5206\uff0c\u4ece\u800c\u9010\u6b65\u805a\u5408\u5fae\u89c2\u5b63\u8282\u6027\u548c\u5b8f\u89c2\u8d8b\u52bf\u4fe1\u606f\u3002</p> <p>FMM further ensembles multiple predictors to utilize complementary forecasting capabilities in multiscale observations. Consequently, TimeMixer is able to achieve consistent state-of-the-art performances in both long-term and short-term forecasting tasks with favorable run-time efficiency.</p> <p>FMM\u8fdb\u4e00\u6b65\u96c6\u6210\u591a\u4e2a\u9884\u6d4b\u5668\uff0c\u4ee5\u5229\u7528\u591a\u5c3a\u5ea6\u89c2\u6d4b\u4e2d\u7684\u4e92\u8865\u9884\u6d4b\u80fd\u529b\u3002\u56e0\u6b64\uff0cTimeMixer\u80fd\u591f\u5728\u957f\u671f\u548c\u77ed\u671f\u9884\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e00\u81f4\u7684\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5177\u6709\u826f\u597d\u7684\u8fd0\u884c\u65f6\u6548\u7387\u3002</p>"},{"location":"literature/TSP/10_TimesMixer/#_2","title":"\u65b9\u6cd5","text":"<p>Given a series \\(x\\) with one or multiple observed variates, the main objective of time series forecasting is to utilize past observations (length-\\(P\\) ) to obtain the most probable future prediction (length-\\(F\\) ). </p> <p>\u7ed9\u5b9a\u4e00\u4e2a\u5305\u542b\u4e00\u4e2a\u6216\u591a\u4e2a\u89c2\u6d4b\u53d8\u91cf\u7684\u65f6\u95f4\u5e8f\u5217 \\( x \\)\uff0c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u4e3b\u8981\u76ee\u6807\u662f\u5229\u7528\u8fc7\u53bb\u7684\u89c2\u6d4b\u503c\uff08\u957f\u5ea6\u4e3a \\( P \\)\uff09\u6765\u83b7\u5f97\u6700\u6709\u53ef\u80fd\u7684\u672a\u6765\u9884\u6d4b\u503c\uff08\u957f\u5ea6\u4e3a \\( F \\)\uff09\u3002</p> <p>As mentioned above, the key challenge of accurate forecasting is to tackle intricate temporal variations. </p> <p>\u5982\u4e0a\u6240\u8ff0\uff0c\u51c6\u786e\u9884\u6d4b\u7684\u5173\u952e\u6311\u6218\u5728\u4e8e\u5904\u7406\u590d\u6742\u7684\u65f6\u95f4\u53d8\u5316\u3002</p> <p>In this paper, we propose \\(\\text{TimeMixer}\\) of multiscale-mixing, benefiting from disentangled variations and complementary forecasting capabilities from multiscale series.</p> <p>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 TimeMixer\uff0c\u8fd9\u662f\u4e00\u79cd\u591a\u5c3a\u5ea6\u6df7\u5408\u65b9\u6cd5\uff0c\u5f97\u76ca\u4e8e\u4ece\u591a\u5c3a\u5ea6\u5e8f\u5217\u4e2d\u63d0\u53d6\u7684\u89e3\u8026\u53d8\u5316\u548c\u4e92\u8865\u7684\u9884\u6d4b\u80fd\u529b\u3002</p> <p>Technically, TimeMixer consists of a multiscale mixing architecture with Past-Decomposable-Mixing and Future-Multipredictor-Mixing for past information extraction and future prediction respectively.</p> <p>\u4ece\u6280\u672f\u89d2\u5ea6\u6765\u770b\uff0cTimeMixer \u5305\u62ec\u4e00\u4e2a\u591a\u5c3a\u5ea6\u6df7\u5408\u67b6\u6784\uff0c\u5176\u4e2d Past-Decomposable-Mixing \u7528\u4e8e\u63d0\u53d6\u8fc7\u53bb\u4fe1\u606f\uff0c\u800c Future-Multipredictor-Mixing \u7528\u4e8e\u8fdb\u884c\u672a\u6765\u9884\u6d4b\u3002</p>"},{"location":"literature/TSP/10_TimesMixer/#31-multiscale-mixing-architecture","title":"3.1 MULTISCALE MIXING ARCHITECTURE","text":"<p>Time series of different scales naturally exhibit distinct properties, where fine scales mainly depict detailed patterns and coarse scales highlight macroscopic variations (Mozer, 1991). </p> <p>\u4e0d\u540c\u5c3a\u5ea6\u7684\u65f6\u95f4\u5e8f\u5217\u81ea\u7136\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u7279\u6027\uff0c\u5176\u4e2d\u7ec6\u7c92\u5ea6\u5c3a\u5ea6\u4e3b\u8981\u63cf\u7ed8\u8be6\u7ec6\u7684\u6a21\u5f0f\uff0c\u800c\u7c97\u7c92\u5ea6\u5c3a\u5ea6\u5219\u7a81\u51fa\u5b8f\u89c2\u53d8\u5316\uff08Mozer, 1991\uff09\u3002</p> <p>This multiscale view can inherently disentangle intricate variations in multiple components, thereby benefiting temporal variation modeling. It is also notable that, especially for the forecasting task, multiscale time series present different forecasting capabilities, due to their distinct dominating temporal patterns (Ferreira et al., 2006). Therefore, we present TimeMixer in a multiscale mixing architecture to utilize multiscale series with distinguishing designs for past extraction and future prediction phases.</p> <p>\u8fd9\u79cd\u591a\u5c3a\u5ea6\u89c6\u89d2\u53ef\u4ee5\u5185\u5728\u5730\u89e3\u8026\u591a\u4e2a\u7ec4\u6210\u90e8\u5206\u4e2d\u7684\u590d\u6742\u53d8\u5316\uff0c\u4ece\u800c\u6709\u5229\u4e8e\u65f6\u95f4\u53d8\u5316\u5efa\u6a21\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9884\u6d4b\u4efb\u52a1\uff0c\u7531\u4e8e\u4e0d\u540c\u7684\u4e3b\u5bfc\u65f6\u95f4\u6a21\u5f0f\uff0c\u591a\u5c3a\u5ea6\u65f6\u95f4\u5e8f\u5217\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u9884\u6d4b\u80fd\u529b\uff08Ferreira et al., 2006\uff09\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86TimeMixer\uff0c\u91c7\u7528\u591a\u5c3a\u5ea6\u6df7\u5408\u67b6\u6784\uff0c\u5229\u7528\u591a\u5c3a\u5ea6\u5e8f\u5217\uff0c\u5e76\u4e3a\u8fc7\u53bb\u4fe1\u606f\u63d0\u53d6\u548c\u672a\u6765\u9884\u6d4b\u9636\u6bb5\u8bbe\u8ba1\u4e86\u4e0d\u540c\u7684\u65b9\u6848\u3002</p>"},{"location":"literature/TSP/10_TimesMixer/#_3","title":"\u4e0b\u91c7\u6837 \u5d4c\u5165&amp;\u5206\u89e3","text":"<p>\uff081\uff09\u5206\u89e3\uff1a </p> <p>\u8f93\u5165\uff1a\\(x \\in \\mathbb{R}^{P \\times C}\\)</p> <p>\u5904\u7406\uff1a\u901a\u8fc7\u5e73\u5747\u6c60\u5316 \u5206\u89e3\u6210 \\(M\\) \u4e2a\u5c3a\u5ea6\uff0c\u5f97\u5230\u4e00\u7cfb\u5217\u591a\u5c3a\u5ea6\u65f6\u95f4\u5e8f\u5217</p> <p>\u8f93\u51fa\uff1a\\(X = \\{x_0,...,x_M\\}\\)</p> <p>\u7b26\u53f7\u8bf4\u660e\uff1a</p> <ul> <li> <p>\\(x_m \\in \\mathbb{R}^{\\frac{P}{2^m}\\times C},m\\in\\{0,...,M\\}\\)</p> </li> <li> <p>\\(C\\)\u662f\u53d8\u91cf\u4e2a\u6570</p> </li> <li> <p>\\(x_0=x\\) \u662f\u8f93\u5165\u5e8f\u5217\uff0c\u5305\u542b\u6700\u7cbe\u7ec6\u7684\u65f6\u95f4\u7279\u5f81</p> </li> <li> <p>\\(x_M\\) \u7528\u4e8e\u8868\u793a\u5b8f\u89c2\u53d8\u5316</p> </li> </ul> <p>\uff082\uff09\u5d4c\u5165</p> <p>\u8f93\u5165\uff1a\u591a\u5c3a\u5ea6\u65f6\u95f4\u5e8f\u5217\u7684\u8f93\u5165 \\(X^0\\) \uff0c\u5206\u89e3\u5b8c\u4ee5\u540e\u5d4c\u5165</p> <p>\u8f93\u51fa\uff1a\\(X^0 = \\text{Embed}(X)\\)</p> <p></p>"},{"location":"literature/TSP/10_TimesMixer/#pdmpast-decomposable-mixing","title":"PDM(Past-Decomposable-Mixing)","text":"<p>\u5904\u7406\uff1a  \u8f93\u5165\u4e0a\u4e00\u5c42\u3001\u8f93\u51fa\u4e0b\u4e00\u5c42</p> <p>\\(X^l = PDM(X^{l-1}) ,l \\in \\{0,...,L\\}\\)</p> <p>\\(L\\) : \u603b\u5c42\u6570</p> <p>\\(X^l = \\{x_0^l,...,x_M^l\\},x_m^l\\in \\mathbb{R}^{{\\frac{P}{2^m}}\\times d_{model}}\\)</p>"},{"location":"literature/TSP/10_TimesMixer/#fmmfuture-multipredictor-mixing","title":"FMM(Future-Multipredictor-Mixing)","text":"<p>\\(\\hat{x} = FMM(X^L)\\)</p> <p>\\(\\hat{x}\\)  \u8868\u793a\u6700\u7ec8\u7684\u9884\u6d4b</p>"},{"location":"literature/TSP/10_TimesMixer/#32-past-decomposable-mixing","title":"3.2 PAST DECOMPOSABLE MIXING","text":"<p>\uff081\uff09</p> <p>\u8f93\u5165\uff1a\\(X_l\\)</p> <p>\u8f93\u51fa\uff1a\u5b63\u8282\u6027\u6210\u5206 \\(S^l =\\{s_0^l,...,s_M^l\\}\\)  \u8d8b\u52bf\u6027\u6210\u5206 \\(T^l = \\{t_0^l,...,t_m^l\\}\\)</p> <p>\u5904\u7406\uff1aAutoformer \u7684 \u5e8f\u5217\u5206\u89e3\u6a21\u5757</p> <p>\uff082\uff09PDM \u7b2c l \u5c42\u7684\u5904\u7406</p> <p></p> <p>\u7b26\u53f7\u8bf4\u660e\uff1a</p> <ul> <li>Feedforward \u5305\u542b\u4e24\u4e2a\u7ebf\u6027\u5c42\uff0c\u4e2d\u95f4\u662f GELU \u6fc0\u6d3b\u51fd\u6570\uff0c\u7528\u4e8e\u901a\u9053\u4e4b\u95f4\u4fe1\u606f\u4ea4\u4e92</li> <li>\\(S-Mix(\\cdot)\\) \\(T-Mix(\\cdot)\\)\u5206\u522b\u8868\u793a\u5b63\u8282\u6027\u6df7\u5408\u548c\u8d8b\u52bf\u6027\u6df7\u5408</li> </ul> <p>\uff083\uff09\u5b63\u8282\u6027\u6210\u5206\u6df7\u5408</p> <p>Therefore, in seasonal mixing, we adopt the bottom-up approach to incorporate information from the lower-level fine-scale time series upwards, which can supplement detailed information to the seasonality modeling of coarser scales.</p> <p>\u56e0\u6b64\uff0c\u5728\u5b63\u8282\u6027\u6df7\u5408\u4e2d\uff0c\u6211\u4eec\u91c7\u7528\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\uff0c\u5c06\u4f4e\u5c42\u6b21\u7cbe\u7ec6\u5c3a\u5ea6\u65f6\u95f4\u5e8f\u5217\u7684\u4fe1\u606f</p> <p>\u5411\u4e0a\u4f20\u9012\uff0c\u8fd9\u53ef\u4ee5\u5c06\u8be6\u7ec6\u4fe1\u606f\u8865\u5145\u5230\u66f4\u7c97\u7684\u5c3a\u5ea6\u7684\u5b63\u8282\u6027\u5efa\u6a21\u4e2d\u3002</p> <p>\u516c\u5f0f\uff1a</p> <p>\\(s_m^l = s_m^l + \\text{Bottom-Up-Mixing}(s_{m-1}^l)\\)</p> <ul> <li>\u81ea\u5e95\u5411\u4e0a\u6df7\u5408\uff0c\u7b2c \\(l\\) \u5c42\uff0c\u878d\u5165 \u7b2c \\(l-1\\) \u5c42\u7684\u4fe1\u606f\uff0c\u7528\u4e8e\u5b63\u8282\u6027\u5efa\u6a21</li> <li>\u8c01\u662f\u5e95\uff1f\u9ad8\u5206\u8fa8\u7387\uff1f\u957f\u5e8f\u5217\uff1f\u7cbe\u7ec6\u5316\uff1f\u8c01\u662f\u4e0a\uff1f</li> <li>\u5e95=\u4f4e\u5c42\u6b21=\u539f\u65f6\u95f4\u5e8f\u5217=\u7cbe\u7ec6\u5316\u65f6\u95f4\u5e8f\u5217</li> <li>\u6240\u4ee5\u5b63\u8282\u6027\u6df7\u5408 = \u5728\u7b2c \\(l\\) \u5c42 \u7eb3\u5165\u7cbe\u7ec6\u5316\u7684\u65f6\u95f4\u5e8f\u5217  \\(m-1\\)</li> <li>\u601d\u60f3\u4e5f\u5c31\u662f\uff1a\u56e0\u4e3a\u4e0b\u91c7\u6837\u4e22\u5931\u7ec6\u8282\u4fe1\u606f\uff0c\u6240\u4ee5\u8865\u4e0a\uff0c\u8fbe\u5230\u6743\u8861</li> <li>\u4e0b\u91c7\u6837\u4e00\u6b21\uff0c\u5c42\u6b21\u5c31\u9ad8\u4e00\u6b21\uff0c\u7c97\u5c3a\u5ea6</li> <li>\\(\\text{Bottom-Up-Mixing}(\\cdot)\\) \u7531\u4e24\u4e2a\u7ebf\u6027\u5c42\u521d\u59cb\u5316\uff0c\u4e2d\u95f4\u662f \\(\\text{GELU}\\) \u6fc0\u6d3b\u51fd\u6570</li> <li>\u8f93\u5165\u7ef4\u5ea6 \\(\\frac{P}{2^{m-1}}\\) \uff0c\u8f93\u51fa\u7ef4\u5ea6 \\(\\frac{P}{2^m}\\)</li> </ul> <p>\uff084\uff09\u8d8b\u52bf\u9879\u6df7\u5408</p> <ul> <li> <p>Note that the upper coarse scale time series can easily provide clear macro information than the lower level.</p> </li> <li> <p>\u9ad8\u5c42\u6b21\u3001\u7c97\u5c3a\u5ea6\u65f6\u95f4\u5e8f\u5217 \u53ef\u4ee5\u8f7b\u6613\u5730\u6355\u83b7\u5b8f\u89c2\u4fe1\u606f</p> </li> </ul> <p>\u516c\u5f0f\uff1a</p> <p>\\(t_m^l = t_m^l + \\text{Top-Down-Mixing}(t_{m+1}^l)\\)</p> <ul> <li>\u4e0e\u5b63\u8282\u6027\u6210\u76f8\u53cd\uff0c\u5bf9\u4e8e\u8d8b\u52bf\u9879\uff0c\u5728\u6355\u6349\u5b8f\u89c2\u8d8b\u52bf\u7684\u65f6\u5019\uff0c\u7ec6\u8282\u7684\u53d8\u5316\u4f1a\u5f15\u8fdb\u566a\u58f0</li> <li>\u6ce8\u610f\u5230\u9ad8\u5c42\u6b21\u7c97\u5c3a\u5ea6\u7684\u65f6\u95f4\u5e8f\u5217\u53ef\u4ee5\u5f88\u8f7b\u6613\u7684\u63d0\u4f9b\u8be6\u7ec6\u7684\u5b8f\u89c2\u4fe1\u606f\uff0c\u76f8\u6bd4\u4e8e\u4f4e\u5c42\u6b21\u6765\u8bf4</li> <li>\u56e0\u6b64\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4ece\u4e0a\u5230\u4e0b\u7684\u6df7\u5408\u65b9\u6cd5\u6765\u5229\u7528\u5b8f\u89c2\u4fe1\u606f\uff0c\u6765\u81ea\u7c97\u5c3a\u5ea6\u7684\u5b8f\u89c2\u4fe1\u606f\u6765\u6307\u5bfc\u7cbe\u7ec6\u5c3a\u5ea6\u7684\u8d8b\u52bf\u5efa\u6a21</li> <li>\u603b\u800c\u8a00\u4e4b\uff0c\u5bf9\u4e8e\u591a\u5c3a\u5ea6\u8d8b\u52bf\u6210\u5206 \\(T^l = \\{t_0^l,...,t_M^l\\}\\)  \uff0c\u6211\u4eec\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u6df7\u5408\u65b9\u5f0f\uff0c\u5bf9\u4e8e\u7b2c m \u4e2a\u5c3a\u5ea6\uff0c\u7528\u6b8b\u5dee\u8fde\u63a5\u7684\u65b9\u5f0f\u83b7\u5f97 \u81ea\u4e0a\u800c\u4e0b\u7684\u8d8b\u52bf\u4fe1\u606f\u4ea4\u4e92</li> <li>\u516c\u5f0f</li> <li>\\(\\text{Top-Down-Mixing}(\\cdot)\\) \u4e24\u5c42\u7ebf\u6027\u5c42\uff0c\u4e2d\u95f4\u662f GELU \u6fc0\u6d3b\u51fd\u6570</li> <li>\u8f93\u5165\u7ef4\u5ea6 \\({\\frac{P}{2^{m+1}}}\\)   \u8f93\u5165\u7c97\u5c3a\u5ea6</li> <li>\u8f93\u51fa\u7ef4\u5ea6  \\({\\frac{P}{2^{m}}}\\)   \u8f93\u51fa \u7cbe\u7ec6\u5c3a\u5ea6 \u81ea\u4e0a\u800c\u4e0b</li> <li>PDM \u9010\u6b65\u805a\u5408\u7ec6\u8282\u7684\u8d8b\u52bf\u6027\u6210\u5206\u5230\u7c97\u5c3a\u5ea6\uff0c\u5e76\u878d\u5165 \u5c06\u6765\u81ea\u7c97\u5c3a\u5ea6\u7684 \u5b8f\u89c2\u8d8b\u52bf\u4fe1\u606f \u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\u3002\uff08\u5bf9\u4e8e\u7b2c \\(l\\) \u5c42\u6765\u8bf4\uff0c\u65e2\u6709\u6765\u81ea \\(l-1\\) \u5c42\u7684\u5b63\u8282\u6027\u6210\u5206\uff0c\u53c8\u6709\u6765\u81ea \\(l+1\\) \u5c42\u7684\u8d8b\u52bf\u6210\u5206\uff09</li> </ul> <p> </p> <p>\u4e5f\u5c31\u662f\u539f\u6587\u7684\u56fe 2</p> <p> </p>"},{"location":"literature/TSP/10_TimesMixer/#33-fmmfuture-multipredictor-mixing","title":"3.3 (FMM)FUTURE MULTIPREDICTOR MIXING","text":"<p>\u5bf9\u4e8e\u7b2c \\(l\\) \u5c42\u7684 PDM \u6a21\u5757\uff0c\u6211\u4eec\u4f1a\u83b7\u5f97\u591a\u5c3a\u5ea6\u7684\u5386\u53f2\u4fe1\u606f\uff0c\u8bb0\u4f5c \uff1a</p> <p>\\(X^l=\\{x_0^L,...,x_M^L\\},x_m^L \\in \\mathbb{R}^{\\frac{P}{2^m}\\times d_{model}}\\) </p> <ul> <li>\u56e0\u4e3a\u4e0d\u540c\u5c3a\u5ea6\u7684\u5e8f\u5217\u8868\u793a\u4e0d\u540c\u7684\u4e3b\u5bfc\u53d8\u5316\uff1f\u56e0\u6b64\u6211\u4eec\u63d0\u51fa\u4e86 \u5bf9\u6765\u81ea\u4e0d\u540c\u5c3a\u5ea6\u7684\u5e8f\u5217\u8fdb\u884c\u805a\u5408\u9884\u6d4b\uff0c\u8bb0\u4f5c FMM \u6a21\u5757\uff1a</li> </ul> <p>\\(\\hat{x}_m =\\text{Predictor}(x_m^L),m \\in \\{0,...,M\\},\\hat{x}=\\sum_{m=0}^M \\hat{x}_m\\)</p> <p>\u7b26\u53f7\u8bf4\u660e\uff1a</p> <ul> <li>\\(\\hat{x}_m \\in \\mathbb{R}^{F \\times C}\\)  \u8868\u793a \u7b2c \\(m\\) \u5c42\u5c3a\u5ea6\u5e8f\u5217\u7684\u9884\u6d4b </li> <li>\u6700\u540e\u7684\u8f93\u51fa\u8bb0\u4f5c\uff1a \\(\\hat{x}\\in \\mathbb{R}^{F \\times C}\\) </li> <li>\\(\\text{Predictor}_m(\\cdot)\\)   \u8868\u793a \u7b2c \\(m\\) \u5c42\u5c3a\u5ea6\u5e8f\u5217\u7684\u9884\u6d4b\u5668</li> <li>\u9996\u5148\u4f7f\u7528\u5355\u5c42\u7ebf\u6027\u5c42\u76f4\u63a5\u5bf9\u672a\u6765\u7684 \\(F\\) \u957f\u5ea6 \u7684\u672a\u6765\u8fdb\u884c\u56de\u5f52\uff0c\u4ece \u957f\u5ea6\\(\\frac{P}{2^m}\\) \u8fc7\u53bb\u4fe1\u606f\u4e2d\u63d0\u53d6</li> </ul> <ul> <li>\u8f93\u5165   \\(\\frac{P}{2^m}\\)</li> <li>\u8f93\u51fa  \\(F\\)</li> </ul> <ul> <li>\u8fd8\u539f\u7ef4\u5ea6\uff0c\u5c06\u6df1\u5c42\u8868\u793a  \\(d_{model}\\) \u8fd8\u539f\u56de \\(C\\) </li> </ul>"},{"location":"literature/TSP/10_TimesMixer/#_4","title":"\u5b9e\u9a8c\u73af\u5883","text":"<ul> <li>a single NVIDIA A100 80GB GPU</li> <li>L2 \u635f\u5931</li> <li>M \u4e2a\u5c3a\u5ea6\u7684\u5212\u5206\uff0c\u6839\u636e\u65f6\u95f4\u5e8f\u5217\u7684\u957f\u5ea6\u8fdb\u884c\u8bbe\u7f6e</li> </ul>"},{"location":"literature/TSP/10_TimesMixer/#_5","title":"\u53c2\u8003\u94fe\u63a5","text":"<p>\u8bba\u6587\u7cbe\u8bfb | 2024[ICLR]TimeMixer: \u53ef\u5206\u89e3\u591a\u5c3a\u5ea6\u878d\u5408\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b </p> <p>\u8bba\u6587\u7814\u8bfb\u4e4b\u57fa\u4e8eMLP\u7684\u65f6\u5e8f\u9884\u6d4b\u6a21\u578bTimeMixer\uff1a\u65f6\u5e8f\u5206\u89e3+\u591a\u5c3a\u5ea6\u6df7\u5408 </p>"},{"location":"literature/TSP/11_Fedformer/","title":"2022\u3001FEDformer","text":""},{"location":"literature/TSP/11_Fedformer/#2022fedformer","title":"2022\u3001FEDformer","text":"2025-04-14 22:46:482025-09-28 12:54:06 <p> \u7ea6 6409 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 32 \u5206\u949f</p> <p>ICML2022\u3001\u963f\u91cc\u8fbe\u6469\u9662</p> <p>\u539f\u6587\uff1a\u300aFEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting\u300b</p> <p>\u6e90\u7801\uff1ahttps://github.com/DAMO-DI-ML/ICML2022-FEDformer</p> <p>\u5b98\u65b9\u516c\u4f17\u53f7\uff1ahttps://mp.weixin.qq.com/s/9doHueBCbsV7eUH2q3uv0A</p> <p>\u5173\u952e\u8bcd\uff1a </p> <ul> <li>Autoformer \u7684\u6539\u8fdb</li> <li>\u878d\u5408\u4e86transformer\u548c\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\uff1a\u4f8b\u5982\uff0c\u5229\u7528\u5085\u7acb\u53f6/\u5c0f\u6ce2\u53d8\u6362\u5c06\u65f6\u57df\u4fe1\u606f\u62c6\u89e3\u4e3a\u9891\u57df\u4fe1\u606f\uff0c\u8ba9transformer\u66f4\u597d\u5730\u5b66\u4e60\u957f\u65f6\u5e8f\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\uff1bFEDformer\u4e5f\u80fd\u6392\u9664\u5e72\u6270\uff0c\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002</li> <li>\u4e13\u95e8\u8bbe\u8ba1\u5468\u671f\u8d8b\u52bf\u9879\u5206\u89e3\u6a21\u5757\uff1a\u901a\u8fc7\u591a\u6b21\u5206\u89e3\u4ee5\u964d\u4f4e\u8f93\u5165\u8f93\u51fa\u7684\u6ce2\u52a8\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002</li> <li>\u4e24\u4e2a\u7248\u672c\uff1a\u5085\u91cc\u53f6\u7248\u672c\u548c\u5c0f\u6ce2\u53d8\u6362\u7248\u672c\uff08FEB-f \u548c FEB-w\uff09</li> <li>\u4e13\u5bb6\u6df7\u5408\u5206\u89e3\u673a\u5236</li> </ul>"},{"location":"literature/TSP/11_Fedformer/#_1","title":"\u6458\u8981","text":"<p>Although Transformer-based methods have significantly improved state-of-the-art results for long-term series forecasting, they are not only computationally expensive but more importantly, are unable to capture the global view of time series (e.g. overall trend). \u5c3d\u7ba1\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u957f\u671f\u5e8f\u5217\u9884\u6d4b\u7684\u6700\u65b0\u7ed3\u679c\uff0c\u4f46\u5b83\u4eec\u4e0d\u4ec5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u66f4\u91cd\u8981\u7684\u662f\uff0c\u65e0\u6cd5\u6355\u6349\u65f6\u95f4\u5e8f\u5217\u7684\u5168\u5c40\u89c6\u56fe\uff08\u4f8b\u5982\u6574\u4f53\u8d8b\u52bf\uff09\u3002</p> <p>To address these problems, we propose to combine Transformer with the seasonal-trend decomposition method, in which the decomposition method captures the global profile of time series while Transformers capture more detailed structures.</p> <p>\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u5c06Transformer\u4e0e\u5b63\u8282\u8d8b\u52bf\u5206\u89e3\u65b9\u6cd5\u7ed3\u5408\u8d77\u6765\uff0c\u5176\u4e2d\u5206\u89e3\u65b9\u6cd5\u6355\u6349\u65f6\u95f4\u5e8f\u5217\u7684\u5168\u5c40\u8f6e\u5ed3\uff0c\u800cTransformer\u6355\u6349\u66f4\u8be6\u7ec6\u7684\u7ed3\u6784\u3002</p> <p>To further enhance the performance of Transformer for longterm prediction, we exploit the fact that most time series tend to have a sparse representation in well-known basis such as Fourier transform, and develop a frequency enhanced Transformer.\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8Transformer\u5728\u957f\u671f\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u6211\u4eec\u5229\u7528\u5927\u591a\u6570\u65f6\u95f4\u5e8f\u5217\u5728\u8bf8\u5982\u5085\u91cc\u53f6\u53d8\u6362\u7b49\u8457\u540d\u57fa\u5e95\u4e2d\u5177\u6709\u7a00\u758f\u8868\u793a\u8fd9\u4e00\u4e8b\u5b9e\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u9891\u7387\u589e\u5f3a\u7684Transformer\u3002</p> <ul> <li>\u9891\u57df\u589e\u5f3a</li> <li>\u65f6\u95f4\u5e8f\u5217\u5728\u5085\u91cc\u53f6\u53d8\u6362\u4e2d\u5177\u6709\u7a00\u758f\u6027</li> </ul> <p>Besides being more effective, the proposed method, termed as Frequency Enhanced Decomposed Transformer (FEDformer), is more efficient than standard Transformer with a linear complexity to the sequence length. </p> <p>\u9664\u4e86\u66f4\u6709\u6548\u4e4b\u5916\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a\u9891\u7387\u589e\u5f3a\u5206\u89e3Transformer\uff08FEDformer\uff09\uff0c\u6bd4\u6807\u51c6Transformer\u66f4\u9ad8\u6548\uff0c\u5176\u590d\u6742\u5ea6\u4e0e\u5e8f\u5217\u957f\u5ea6\u5448\u7ebf\u6027\u5173\u7cfb\u3002</p> <p>\u590d\u6742\u5ea6\u5448\u73b0\u7ebf\u6027\u5173\u7cfb</p> <p>Our empirical studies with six benchmark datasets show that compared with state-of-the-art methods, FEDformer can reduce prediction error by 14.8% and 22.6% for multivariate and univariate time series, respectively. </p> <p>\u6211\u4eec\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cFEDformer\u53ef\u4ee5\u5c06\u591a\u53d8\u91cf\u548c\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u9884\u6d4b\u8bef\u5dee\u5206\u522b\u964d\u4f4e14.8%\u548c22.6%\u3002</p>"},{"location":"literature/TSP/11_Fedformer/#_2","title":"\u6a21\u578b\u7ed3\u6784\u56fe","text":"<p>FEDformer\uff08Frequency Enhanced Decomposed Transformer\uff09\u7684\u7ed3\u6784\u3002FEDformer\u662f\u4e00\u79cd\u7528\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6a21\u578b\uff0c\u5b83\u7ed3\u5408\u4e86\u9891\u7387\u589e\u5f3a\u5757\uff08Frequency Enhanced Block, FEB\uff09\u548c\u9891\u7387\u589e\u5f3a\u6ce8\u610f\u529b\uff08Frequency Enhanced Attention, FEA\uff09</p> <p>FEDformer Encoder</p> <ul> <li>**Encoder Input $ \\mathcal{X}_{en}^0 $ **: \u8f93\u5165\u6570\u636e\uff0c\u7ef4\u5ea6\u4e3a \\(\\mathbb{R}^{ I \\times D}\\) \u3002</li> <li>Frequency Enhanced Block (FEB): \u7eff\u8272\u5757\uff0c\u7528\u4e8e\u5728\u9891\u57df\u4e2d\u8fdb\u884c\u8868\u793a\u5b66\u4e60\u3002FEB\u6709\u4e24\u79cd\u53d8\u4f53\uff1a\u4f7f\u7528\u5085\u91cc\u53f6\u57fa\u7684FEB-f\u548c\u4f7f\u7528\u5c0f\u6ce2\u57fa\u7684FEB-w\u3002</li> <li>MOE Decomp (Mixture Of Expert Decomposition): \u9ec4\u8272\u5757\uff0c\u7528\u4e8e\u4ece\u8f93\u5165\u6570\u636e\u4e2d\u63d0\u53d6\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6a21\u5f0f\u3002</li> <li>Feed Forward: \u524d\u9988\u7f51\u7edc\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u5904\u7406\u6570\u636e\u3002</li> <li>\\(N\u00d7\\): \u8868\u793a\u7f16\u7801\u5668\u90e8\u5206\u91cd\u590dN\u6b21\u3002</li> </ul> <p>FEDformer Decoder</p> <ul> <li>**Seasonal Init   \\(\\mathcal{X}_{de}^{l,0}\\) **: \u5b63\u8282\u6027\u521d\u59cb\u5316\uff0c\u7ef4\u5ea6\u4e3a \\(\\mathbb{R}^{ (I/2+O) \\times D}\\) \u3002</li> <li>**Trend Init \\(\\mathcal{T}_{de}^0\\) **: \u8d8b\u52bf\u521d\u59cb\u5316\uff0c\u7ef4\u5ea6\u4e3a \\(\\mathbb{R}^{(T/2+O) \\times D}\\) \u3002</li> <li>Frequency Enhanced Block (FEB): \u4e0e\u7f16\u7801\u5668\u4e2d\u7684FEB\u76f8\u540c\uff0c\u7528\u4e8e\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u9891\u57df\u8868\u793a\u5b66\u4e60\u3002</li> <li>MOE Decomp: \u4e0e\u7f16\u7801\u5668\u4e2d\u7684MOE Decomp\u76f8\u540c\uff0c\u7528\u4e8e\u89e3\u7801\u8fc7\u7a0b\u4e2d\u63d0\u53d6\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6a21\u5f0f\u3002</li> <li>Frequency Enhanced Attention (FEA): \u7ea2\u8272\u5757\uff0c\u7528\u4e8e\u5728\u9891\u57df\u4e2d\u8fdb\u884c\u6ce8\u610f\u529b\u673a\u5236\u7684\u8868\u793a\u5b66\u4e60\u3002FEA\u4e5f\u6709\u4e24\u79cd\u53d8\u4f53\uff1aFEA-f\u548cFEA-w\u3002</li> <li>\\(M\u00d7\\): \u8868\u793a\u89e3\u7801\u5668\u90e8\u5206\u91cd\u590d\\(M\\)\u6b21\u3002</li> <li>Output: \u6700\u7ec8\u7684\u9884\u6d4b\u8f93\u51fa\u3002</li> </ul> <p>\u7b26\u53f7\u8bf4\u660e\uff1a</p> <ul> <li>\\(\\mathcal{T}_{de}^{l,i}\\) : \u8868\u793a\u7b2c  i \u5c42\u89e3\u7801\u5668\u7684\u8d8b\u52bf\u8f93\u51fa\u3002</li> <li>\\(\\mathcal{S}_{de}^{l,i}\\) : \u8868\u793a\u7b2c i  \u5c42\u89e3\u7801\u5668\u7684\u5b63\u8282\u6027\u8f93\u51fa\u3002</li> <li>\\(\\mathcal{S}_{de}^{l,3}\\) or $ \\mathcal{X}_{de}^l$ : \u6700\u7ec8\u7684\u5b63\u8282\u6027\u8f93\u51fa\u6216\u89e3\u7801\u5668\u8f93\u51fa\u3002</li> <li>\u770b\u4e0b\u6807\u662f\u7f16\u7801\u5668\u8fd8\u662f\u89e3\u7801\u5668\uff1bS \u8868\u793a\u5b63\u8282\u6027\u6210\u5206\uff0cT \u8868\u793a\u8d8b\u52bf\u6027\u6210\u5206\uff0c\u56e0\u4e3a\u771f\u6b63\u7684\u53c2\u6570\u8f93\u5165\u5b8c\u5168\u7684\u767d\u566a\u58f0\uff0c\u6240\u4ee5\u4e00\u822c\u53bb\u9664\u6389\u8d8b\u52bf\u6027\u6210\u5206\u90fd\u5f52\u4e3a\u5b63\u8282\u6027\u6210\u5206</li> </ul> <p>\u603b\u7ed3 </p> <p>FEDformer\u901a\u8fc7\u7ed3\u5408\u9891\u7387\u589e\u5f3a\u5757\u548c\u9891\u7387\u589e\u5f3a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u9891\u57df\u4e2d\u8fdb\u884c\u6709\u6548\u7684\u8868\u793a\u5b66\u4e60\u548c\u6ce8\u610f\u529b\u8ba1\u7b97\u3002\u540c\u65f6\uff0c\u4f7f\u7528\u4e13\u5bb6\u6df7\u5408\u5206\u89e3\u5757\uff08MOE Decomp\uff09\u6765\u63d0\u53d6\u8f93\u5165\u6570\u636e\u7684\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6a21\u5f0f\u3002</p>"},{"location":"literature/TSP/11_Fedformer/#3-model-structure","title":"3. Model Structure","text":"<p>In this section, we will introduce </p> <p>(1) the overall structure of FEDformer, as shown in Figure 2,</p> <p>(2) two subversion structures for signal process: one uses Fourier basis and the other uses Wavelet basis,</p> <p>(3) the mixture of experts mechanism for seasonal-trend decomposition, and</p> <p>(4) the complexity analysis of the proposed model.</p> <p>\u5728\u8fd9\u4e00\u90e8\u5206\uff0c\u6211\u4eec\u5c06\u4ecb\u7ecd\uff1a</p> <ol> <li>FEDformer\u7684\u6574\u4f53\u7ed3\u6784\uff0c\u5982\u56fe2\u6240\u793a\uff1b</li> <li>\u4e24\u79cd\u4fe1\u53f7\u5904\u7406\u7684\u5b50\u7248\u672c\u7ed3\u6784\uff1a\u4e00\u79cd\u4f7f\u7528\u5085\u91cc\u53f6\u57fa\uff0c\u53e6\u4e00\u79cd\u4f7f\u7528\u5c0f\u6ce2\u57fa\uff1b</li> <li>\u7528\u4e8e\u5b63\u8282\u6027-\u8d8b\u52bf\u5206\u89e3\u7684\u4e13\u5bb6\u6df7\u5408\u673a\u5236\uff1b</li> <li>\u6240\u63d0\u51fa\u6a21\u578b\u7684\u590d\u6742\u5ea6\u5206\u6790\u3002</li> </ol>"},{"location":"literature/TSP/11_Fedformer/#31-fedformer-framework","title":"3.1. FEDformer Framework","text":"<p>Preliminary Long-term time series forecasting is a sequence to sequence problem. We denote the input length as \\(I\\) and output length as \\(O\\). We denote \\(D\\) as the hidden states of the series. The input of the encoder is a \\(I \u00d7 D\\) matrix and the decoder has \\((I/2 + O) \u00d7 D\\) input.</p> <p>\u7b26\u53f7\u8bf4\u660e\uff1a</p> <ul> <li>\u8f93\u5165\u5e8f\u5217 \\(I\\)</li> <li>\u8f93\u51fa\u5e8f\u5217\u957f\u5ea6 \\(O\\)</li> <li>\u9690\u85cf\u5c42\u7ef4\u5ea6 \\(D\\)</li> <li>\u7f16\u7801\u5668\u7684\u8f93\u5165 \\(I \u00d7 D\\)</li> <li>\u89e3\u7801\u5668\u7684\u8f93\u5165 \\((I/2 + O) \u00d7 D\\) <code>label length</code></li> </ul> <p>FEDformer Structure Inspired by the seasonal-trend decomposition and distribution analysis as discussed in Section 1, </p> <p>we renovate Transformer as a deep decomposition architecture as shown in Figure 2, including Frequency Enhanced Block (FEB), Frequency Enhanced Attention(FEA) connecting encoder and decoder, and the Mixture Of Experts Decomposition block (MOEDecomp).</p> <p>The detailed description of FEB, FEA, and MOEDecomp blocks will be given in the following Section 3.2, 3.3, and 3.4 respectively.</p> <p>\u8d21\u732e\uff1aFEB\u3001FEA\u3001MOED</p> <ul> <li>\u9891\u7387\u589e\u5f3a\u6a21\u5757</li> <li>\u9891\u7387\u589e\u5f3a\u6ce8\u610f\u529b</li> <li>\u4e13\u5bb6\u6df7\u5408\u5206\u89e3\u673a\u5236</li> </ul> <p>Encoder </p> <p>The encoder adopts a multilayer structure as: </p> <p>\\(\\mathcal{X}_{en}^{l} = \\text{Encoder}(\\mathcal{X}_{en}^{l-1})\\)</p> <p>where \\(l \u2208 {1, \u00b7 \u00b7 \u00b7 , N }\\) denotes the output of \\(l\\)-th encoder layer and \\(\\mathcal{X}_{en}^{0} \u2208 R^{I\u00d7D}\\) is the embedded  historical series. </p> <ul> <li>\u7f16\u7801\u5668\u91c7\u7528\u591a\u5c42\u7ed3\u6784\uff0c\u6bcf\u4e00\u5c42\u7684\u8f93\u51fa\u8868\u793a\u4e3a \\(\\mathcal{X}_{en}^{l}\\)\uff0c\u5176\u4e2d \\(l\\) \u8868\u793a\u7b2c \\(l\\) \u5c42\uff0c\\(l \\in {1, \\dots, N}\\)\u3002 </li> <li>\u521d\u59cb\u8f93\u5165 $ \\mathcal{X}_{en}^{0}$ \u662f\u4e00\u4e2a\u5d4c\u5165\u7684\u5386\u53f2\u5e8f\u5217\uff0c\u7ef4\u5ea6\u4e3a $ I \\times D$\u3002</li> </ul> <p>The \\(\\text{Encoder(\u00b7)}\\) is formalized as</p> \\[\\begin{aligned} \\mathcal{S}_ {\\mathrm{en}}^{l,1}, &amp; =\\mathrm{MOEDecomp}(\\mathrm{FEB}\\left(\\mathcal{X}_{\\mathrm{en}}^{l-1}\\right)+\\mathcal{X}_{\\mathrm{en}}^{l-1}), \\\\ \\mathcal{S}_{\\mathrm{en}}^{l,2},_{-} &amp; =\\mathrm{MOEDecomp}(\\text{FeedForward}\\left(\\mathcal{S}_{\\mathrm{en}}^{l,1}\\right)+\\mathcal{S}_{\\mathrm{en}}^{l,1}),\\quad(1) \\\\ \\mathcal{X}_{\\mathrm{en}}^{l} &amp; =\\mathcal{S}_{\\mathsf{en}}^{l,2}, \\end{aligned}\\] <p>where \\(S_{en}^{l,i}, i \u2208 {1, 2}\\) represents the seasonal component after the \\(i\\)-th decomposition block in the \\(l\\)-th layer respectively. </p> <ul> <li>\u9996\u5148\uff0c\u5c06\u8f93\u5165 $ \\mathcal{X}{en}^{l-1} $ \u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u5757\uff08FEB\uff09\u5904\u7406\uff0c\u7136\u540e\u52a0\u4e0a\u8f93\u5165\u672c\u8eab\uff0c\u518d\u8fdb\u884c\u6df7\u5408\u4e13\u5bb6\u5206\u89e3\uff08MOEDecomp\uff09\uff0c\u5f97\u5230\u7b2c\u4e00\u4e2a\u5b63\u8282\u6027\u5206\u91cf $\\mathcal{S} $\u3002 }^{l,1</li> <li>\u63a5\u7740\uff0c\u5c06 $\\mathcal{S}_{en}^{l,1} $ \u901a\u8fc7\u524d\u9988\u7f51\u7edc\uff08FeedForward\uff09\u5904\u7406\uff0c\u518d\u52a0\u4e0a $ \\mathcal{S}{en}^{l,1}$\uff0c\u518d\u8fdb\u884c\u4e00\u6b21\u6df7\u5408\u4e13\u5bb6\u5206\u89e3\uff08MOEDecomp\uff09\uff0c\u5f97\u5230\u7b2c\u4e8c\u4e2a\u5b63\u8282\u6027\u5206\u91cf \\(\\mathcal{S}_{en}^{l,2}\\)\u3002</li> <li>\u6700\u7ec8\uff0c\u5c06 \\(\\mathcal{S}_{en}^{l,2}\\) \u4f5c\u4e3a\u5f53\u524d\u5c42\u7684\u8f93\u51fa \\(\\mathcal{X}_{en}^{l}\\)\u3002</li> </ul> <p>For FEB module, it has two different versions (FEB-f &amp; FEB-w) which are implemented through Discrete Fourier transform (DFT) and Discrete Wavelet transform (DWT) mechanism respectively and can seamlessly replace the self-attention block.</p> <p>FEB \u6a21\u5757\u6709\u4e24\u79cd\u7248\u672c\uff1a</p> <ul> <li>FEB-f\uff1a\u57fa\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08DFT\uff09\u5b9e\u73b0\u3002</li> <li>FEB-w\uff1a\u57fa\u4e8e\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\uff08DWT\uff09\u5b9e\u73b0\u3002</li> <li>\u8fd9\u4e24\u79cd\u6a21\u5757\u53ef\u4ee5\u65e0\u7f1d\u66ff\u6362\u4f20\u7edf\u7684\u81ea\u6ce8\u610f\u529b\u5757\u3002</li> </ul> <p>\u603b\u7ed3\uff1a</p> <p>\u57fa\u4e8e\u591a\u5c42\u7ed3\u6784\u7684\u7f16\u7801\u5668\uff0c\u5176\u4e2d\u6bcf\u4e00\u5c42\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u5757\uff08FEB\uff09\u548c\u6df7\u5408\u4e13\u5bb6\u5206\u89e3\uff08MOEDecomp\uff09\u6a21\u5757\u6765\u63d0\u53d6\u5b63\u8282\u6027\u5206\u91cf\u3002</p> <p>FEB \u6a21\u5757\u6709\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff08\u57fa\u4e8e DFT \u548c DWT\uff09\uff0c\u53ef\u4ee5\u66ff\u4ee3\u4f20\u7edf\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3002</p> <p>The decoder also adopts a multilayer structure as: </p> <p>\\(\\mathcal{X}_{de}^{l-1}, \\mathcal{T}_{de}^{l-1} = \\mathrm{Decoder}(\\mathcal{X}^{l\u22121}_{de} , \\mathcal{T}_{de}^{l\u22121} )\\),  </p> <p>where \\(l \u2208 {1, \u00b7 \u00b7 \u00b7 , M }\\)  denotes the output of \\(l\\)-th decoder layer. </p> <p>The \\(\\mathrm{Decoder}(\u00b7)\\) is formalized as</p> \\[\\begin{aligned} \\mathcal{S}_{\\mathrm{de}}^{l,1},\\mathcal{T}_{\\mathrm{de}}^{l,1} &amp; =\\mathrm{MOEDecomp}\\left(\\mathrm{FEB}\\left(\\mathcal{X}_{\\mathrm{de}}^{l-1}\\right)+\\mathcal{X}_{\\mathrm{de}}^{l-1}\\right), \\\\ \\mathcal{S}_{\\mathrm{de}}^{l,2},\\mathcal{T}_{\\mathrm{de}}^{l,2} &amp; =\\mathrm{MOEDecomp}\\left(\\mathrm{FEA}\\left(\\mathcal{S}_{\\mathrm{de}}^{l,1},\\mathcal{X}_{\\mathrm{en}}^N\\right)+\\mathcal{S}_{\\mathrm{de}}^{l,1}\\right), \\\\ \\mathcal{S}_{\\mathrm{de}}^{l,3},\\mathcal{T}_{\\mathrm{de}}^{l,3} &amp; =\\mathrm{MOEDecomp}\\left(\\text{FeedForward}\\left(\\mathcal{S}_{\\mathrm{de}}^{l,2}\\right)+\\mathcal{S}_{\\mathrm{de}}^{l,2}\\right), \\\\ \\mathcal{X}_{\\mathrm{de}}^l &amp; =\\mathcal{S}_{\\mathsf{de}}^{l,3}, \\\\ \\mathcal{T}_{\\mathrm{de}}^l &amp; =\\mathcal{T}_{\\mathrm{de}}^{l-1}+\\mathcal{W}_{l,1}\\cdot\\mathcal{T}_{\\mathrm{de}}^{l,1}+\\mathcal{W}_{l,2}\\cdot\\mathcal{T}_{\\mathrm{de}}^{l,2}+\\mathcal{W}_{l,3}\\cdot\\mathcal{T}_{\\mathrm{de}}^{l,3}, \\end{aligned}\\] <p>where \\(\\mathcal{S}_{de}^{l,i} , \\mathcal{T}_{de}^{l,i}   , i \u2208 {1, 2, 3}\\) represent the seasonal and trend component after the \\(i\\)-th decomposition block in the \\(l\\)-th layer respectively.  \u7b2c \\(l\\) \u5c42\u7b2c \\(i\\) \u4e2a\u5206\u89e3\u5757</p> <p>$ W_{l,i}, i \u2208 {1, 2, 3}$ represents the projector for the \\(i\\)-th extracted trend \\(T^{l,i}_{de}\\) .</p> <ul> <li>\u4e0e\u7f16\u7801\u5668\u7c7b\u4f3c\uff0c\u4f46\u589e\u52a0\u4e86\u8d8b\u52bf\uff08Trend\uff09\u5206\u91cf\u7684\u5904\u7406\uff0c\u5e76\u5f15\u5165\u4e86\u7279\u5f81\u63d0\u53d6\u6a21\u5757\uff08FEA\uff09</li> <li>\u89e3\u7801\u5668\u91c7\u7528\u591a\u5c42\u7ed3\u6784\uff0c\u6bcf\u4e00\u5c42\u7684\u8f93\u51fa\u8868\u793a\u4e3a \\(\\mathcal{S}_{de}^{l,i}\\) \u548c \\(\\mathcal{T}_{de}^{l,i}\\)\uff0c\u5176\u4e2d \\(l\\) \u8868\u793a\u7b2c \\(l\\) \u5c42\uff0c\\((l \\in {1, \\dots, M})\\)</li> <li>\\(\\mathcal{X}_{de}^{l}\\) \u8868\u793a\u89e3\u7801\u5668\u7684\u8f93\u51fa\uff0c\u800c \\(\\mathcal{T}_{de}^{l}\\) \u8868\u793a\u8d8b\u52bf\u5206\u91cf\u3002</li> <li>\u7b2c\u4e00\u6b65\uff1a\u5c06\u8f93\u5165 \\(\\mathcal{X}_{de}^{l-1}\\) \u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u5757\uff08FEB\uff09\u5904\u7406\uff0c\u7136\u540e\u52a0\u4e0a\u8f93\u5165\u672c\u8eab\uff0c\u518d\u8fdb\u884c\u6df7\u5408\u4e13\u5bb6\u5206\u89e3\uff08MOEDecomp\uff09\uff0c\u5f97\u5230\u7b2c\u4e00\u4e2a\u5b63\u8282\u6027\u5206\u91cf \\(\\mathcal{S}_{de}^{l,1}\\) \u548c\u7b2c\u4e00\u4e2a\u8d8b\u52bf\u5206\u91cf \\(\\mathcal{T}_{de}^{l,1}\\)\u3002</li> <li>\u7b2c\u4e8c\u6b65\uff1a\u5c06 \\(\\mathcal{S}_{de}^{l,1}\\) \u548c\u7f16\u7801\u5668\u7684\u8f93\u51fa \\(\\mathcal{X}_{en}^N\\) \u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u6a21\u5757\uff08FEA\uff09\u5904\u7406\uff0c\u518d\u52a0\u4e0a \\(\\mathcal{S}_{de}^{l,1}\\)\uff0c\u518d\u8fdb\u884c\u4e00\u6b21\u6df7\u5408\u4e13\u5bb6\u5206\u89e3\uff08MOEDecomp\uff09\uff0c\u5f97\u5230\u7b2c\u4e8c\u4e2a\u5b63\u8282\u6027\u5206\u91cf \\(\\mathcal{S}_{de}^{l,2}\\) \u548c\u7b2c\u4e8c\u4e2a\u8d8b\u52bf\u5206\u91cf \\(\\mathcal{T}_{de}^{l,2}\\)\u3002</li> <li>\u7b2c\u4e09\u6b65\uff1a\u5c06 \\(\\mathcal{S}_{de}^{l,2}\\) \u901a\u8fc7\u524d\u9988\u7f51\u7edc\uff08FeedForward\uff09\u5904\u7406\uff0c\u518d\u52a0\u4e0a \\(\\mathcal{S}_{de}^{l,2}\\)\uff0c\u518d\u8fdb\u884c\u4e00\u6b21\u6df7\u5408\u4e13\u5bb6\u5206\u89e3\uff08MOEDecomp\uff09\uff0c\u5f97\u5230\u7b2c\u4e09\u4e2a\u5b63\u8282\u6027\u5206\u91cf \\(\\mathcal{S}_{de}^{l,3}\\) \u548c\u7b2c\u4e09\u4e2a\u8d8b\u52bf\u5206\u91cf \\(\\mathcal{T}_{de}^{l,3}\\)\u3002</li> <li>\u6700\u7ec8\u8f93\u51fa\uff1a\u5c06 \\(\\mathcal{S}_{de}^{l,3}\\) \u4f5c\u4e3a\u5f53\u524d\u5c42\u7684\u8f93\u51fa \\(\\mathcal{X}_{de}^{l}\\)\u3002</li> <li>\u8d8b\u52bf\u5206\u91cf\u66f4\u65b0\uff1a\u5c06 \\(\\mathcal{T}_{de}^{l}\\) \u66f4\u65b0\u4e3a \\(\\mathcal{T}_{de}^{l-1}\\) \u52a0\u4e0a\u4e09\u4e2a\u8d8b\u52bf\u5206\u91cf\u7684\u52a0\u6743\u548c\uff0c\u6743\u91cd\u5206\u522b\u4e3a \\(\\mathcal{W}_{l,1}\\)\u3001\\(\\mathcal{W}_{l,2}\\) \u548c \\(\\mathcal{W}_{l,3}\\)\u3002</li> </ul> <p>Similar to FEB, FEA has two different versions (FEA-f &amp; FEA-w) which are implemented through DFT and DWT projection respectively with attention design, and can replace the cross-attention block. </p> <p>FEA \u6a21\u5757\u6709\u4e24\u79cd\u7248\u672c\uff1a</p> <ul> <li>FEA-f\uff1a\u57fa\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08DFT\uff09\u5b9e\u73b0\u3002</li> <li>FEA-w\uff1a\u57fa\u4e8e\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\uff08DWT\uff09\u5b9e\u73b0\u3002</li> </ul> <p>\u8fd9\u4e24\u79cd\u6a21\u5757\u90fd\u8bbe\u8ba1\u4e86\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u4ee5\u65e0\u7f1d\u66ff\u6362\u4f20\u7edf\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u5757\u3002</p> <p>\u89e3\u7801\u5668\u7684\u591a\u5c42\u7ed3\u6784\uff1a</p> <p>\u6bcf\u4e00\u5c42\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u5757\uff08FEB\uff09\u3001\u7279\u5f81\u63d0\u53d6\u6a21\u5757\uff08FEA\uff09\u548c\u6df7\u5408\u4e13\u5bb6\u5206\u89e3\uff08MOEDecomp\uff09\u6765\u63d0\u53d6\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u5206\u91cf\u3002</p> <p>\u89e3\u7801\u5668\u7684\u8f93\u51fa\u5305\u62ec\u5b63\u8282\u6027\u5206\u91cf\u548c\u8d8b\u52bf\u5206\u91cf\uff0c\u8d8b\u52bf\u5206\u91cf\u901a\u8fc7\u52a0\u6743\u548c\u8fdb\u884c\u66f4\u65b0\u3002</p> <p>FEA \u6a21\u5757\u6709\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff08\u57fa\u4e8e DFT \u548c DWT\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u4ee5\u66ff\u4ee3\u4f20\u7edf\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u5757\u3002</p> <p>The final prediction is the sum of the two refined decomposed components as \\(\\mathcal{W}_S \u00b7 \\mathcal{X}_{de}^M + \\mathcal{T}_{de}^M\\) , where \\(\\mathcal{W}_S\\) is to  project the deep transformed seasonal component \\(\\mathcal{X}_{de}^M\\) to the target dimension.</p> <p>\u6700\u7ec8\u9884\u6d4b\u662f\u4e24\u4e2a\u7ecf\u8fc7\u7ec6\u5316\u7684\u5206\u89e3\u5206\u91cf\u7684\u548c\uff0c\u8868\u793a\u4e3a \\(\\mathcal{W}_S \\cdot \\mathcal{X}_{de}^M + \\mathcal{T}_{de}^M\\)\uff0c\u5176\u4e2d \\(\\mathcal{W}_S\\) \u7528\u4e8e\u5c06\u6df1\u5ea6\u53d8\u6362\u540e\u7684\u5b63\u8282\u6027\u5206\u91cf \\(\\mathcal{X}_{de}^M\\) \u6295\u5f71\u5230\u76ee\u6807\u7ef4\u5ea6\u3002</p>"},{"location":"literature/TSP/11_Fedformer/#32-fourier-enhanced-structure","title":"3.2. Fourier Enhanced Structure","text":"<p>Discrete Fourier Transform (DFT) </p> <p>The proposed Fourier Enhanced Structures use discrete Fourier transform (DFT). Let \\(\\mathcal{F}\\) denotes the Fourier transform and \\(\\mathcal{F}^{-1}\\) denotes the inverse Fourier transform. </p> <p>\u5085\u91cc\u53f6\u53d8\u6362\u548c\u9006\u53d8\u6362</p> <p>\u4ee4 \\(\\mathcal{F}\\) \u8868\u793a\u5085\u91cc\u53f6\u53d8\u6362\uff0c\\(\\mathcal{F}^{-1}\\) \u8868\u793a\u9006\u5085\u91cc\u53f6\u53d8\u6362\u3002</p> <p>Given a sequence of real numbers \\(x_n\\) in time domain, where \\(n = 1, 2...N\\) . DFT  is defined as \\(X_l = \\sum_{n=0}^{N-1} x_ne^{\u2212i\\omega ln}\\), where \\(i\\) is the imaginary unit and \\(X_l, l = 1, 2...L\\) is a sequence of complex numbers in the frequency domain. Similarly, the inverse  DFT is defined as \\(x_n = \\sum_{n=0}^{N-1} X_l e^{i\\omega ln}\\) . </p> <p>\u7ed9\u5b9a\u4e00\u4e2a\u5b9e\u6570\u5e8f\u5217 \\(x_n\\) \u5728\u65f6\u57df\u4e2d\uff0c\u5176\u4e2d \\(n = 1, 2, \\ldots, N\\)\u3002DFT \u5b9a\u4e49\u4e3a\uff1a $$ X_l = \\sum_{n=0}^{N-1} x_n e^{-i\\omega ln} $$ \u5176\u4e2d \\(i\\) \u662f\u865a\u6570\u5355\u4f4d\uff0c\\(X_l, l = 1, 2, \\ldots, L\\) \u662f\u4e00\u4e2a\u5728\u9891\u57df\u4e2d\u7684\u590d\u6570\u5e8f\u5217\u3002</p> <p>\u7c7b\u4f3c\u5730\uff0c\u9006 DFT \u5b9a\u4e49\u4e3a\uff1a $$ x_n = \\sum_{l=0}^{N-1} X_l e^{i\\omega ln} $$ The complexity of DFT is \\(O(N^2)\\). With fast Fourier transform (FFT), the computation complexity can be reduced to \\(O(N log N )\\). Here a random subset of the Fourier basis is used and the scale of the subset is bounded by a scalar. When we choose the mode index before DFT and reverse DFT operations, the computation complexity can be further reduced to \\(O(N )\\).</p> <ul> <li>DFT \u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u662f \\(O(N ^2)\\)\u3002</li> <li>\u4f7f\u7528\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u53ef\u4ee5\u964d\u4f4e\u5230 \\(O(N \\log N)\\)\u3002</li> <li>\u5728\u8fd9\u91cc\uff0c\u4f7f\u7528\u4e86\u5085\u91cc\u53f6\u57fa\u7684\u4e00\u4e2a\u968f\u673a\u5b50\u96c6\uff0c\u5e76\u4e14\u5b50\u96c6\u7684\u89c4\u6a21\u7531\u4e00\u4e2a\u6807\u91cf\u9650\u5236\u3002\u5f53\u5728 DFT \u548c\u9006 DFT \u64cd\u4f5c\u4e4b\u524d\u9009\u62e9\u6a21\u5f0f\u7d22\u5f15\u65f6\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u53ef\u4ee5\u8fdb\u4e00\u6b65\u964d\u4f4e\u5230 \\(O(N)\\)\u3002</li> </ul> <p>Frequency Enhanced Block with Fourier Transform (FEB-f) . The FEB-f is used in both encoder and decoder as shown in Figure 2. </p> <p>\u201c\u9891\u7387\u589e\u5f3a\u5757\u201d\uff08Frequency Enhanced Block\uff0c\u7b80\u79f0FEB-f\uff09\u4f7f\u7528\u5085\u91cc\u53f6\u53d8\u6362\uff08Fourier Transform\uff09\u6765\u5904\u7406\u6570\u636e\u3002FEB-f \u88ab\u7528\u4e8e\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e2d\u3002</p> <p>The input (\\(x \\in \\mathbb{R}^{N \\times D}\\)) of the FEB-f block is first linearly projected with \\(w \\in \\mathbb{R}^{D \\times D}\\), so \\(q = x \\cdot w\\). </p> <p>\u8f93\u5165\u5904\u7406\uff1a\u8f93\u5165\u6570\u636e \\(x \\in \\mathbb{R}^{N \\times D}\\) \u9996\u5148\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u6295\u5f71 \\(w \\in \\mathbb{R}^{D \\times D}\\) \u8fdb\u884c\u53d8\u6362\uff0c\u5f97\u5230 \\(q = x \\cdot w\\)\u3002</p> <p>Then \\(q\\) is converted from the time domain to the frequency domain. The Fourier transform of \\(q\\) is denoted as \\(Q \\in \\mathbb{C}^{N \\times D}\\).</p> <p>\u5085\u91cc\u53f6\u53d8\u6362\uff1a\u5c06 \\(q\\) \u4ece\u65f6\u57df\u8f6c\u6362\u5230\u9891\u57df\uff0c\u5f97\u5230 \\(Q \\in \\mathbb{C}^{N \\times D}\\)\u3002</p> <p>In frequency domain, only the randomly selected \\(M\\) modes are kept so we use a select operator as</p> <p>\u9009\u62e9\u64cd\u4f5c\uff1a\u5728\u9891\u57df\u4e2d\uff0c\u53ea\u4fdd\u7559\u968f\u673a\u9009\u62e9\u7684 \\(M\\) \u4e2a\u6a21\u5f0f\uff0c\u4f7f\u7528\u9009\u62e9\u64cd\u4f5c \\(\\text{Select}(Q) = \\text{Select}(\\mathcal{F}(q))\\)\uff0c\u5f97\u5230 \\(\\tilde{Q} \\in \\mathbb{C}^{M \\times D}\\)\uff0c\u5176\u4e2d \\(M \\ll N\\)\u3002 $$ \\tilde{Q} = \\text{Select}(Q) = \\text{Select}(\\mathcal{F}(q)), $$</p> <p>where \\(\\tilde{Q} \\in \\mathbb{C}^{M \\times D}\\) and \\(M \\ll N\\). </p> <p>Then, the FEB-f is defined as $$ \\text{FEB-f}(q) = \\mathcal{F}^{-1}(\\text{Padding}(\\tilde{Q} \\odot R)), $$</p> <p>where \\(R \\in \\mathbb{C}^{D \\times D \\times M}\\) is a parameterized kernel initialized randomly.</p> <p>FEB-f \u5b9a\u4e49\uff1aFEB-f \u7684\u5b9a\u4e49\u4e3a \\(\\text{FEB-f}(q) = \\mathcal{F}^{-1}(\\text{Padding}(\\tilde{Q} \\odot R))\\)\uff0c\u5176\u4e2d \\(R \\in \\mathbb{C}^{D \\times D \\times M}\\) \u662f\u4e00\u4e2a\u968f\u673a\u521d\u59cb\u5316\u7684\u53c2\u6570\u5316\u6838\u3002</p> <p>Let \\(Y = Q \\odot C\\), with \\(Y \\in \\mathbb{C}^{M \\times D}\\). The production operator \\(\\odot\\) is defined as: \\(Y_{m,d_o} = \\sum_{d_i=0}^{D} Q_{m,d_i} \\cdot R_{d_i,d_o,m}\\), where \\(d_i = 1, 2...D\\) is the input channel and \\(d_o = 1, 2...D\\) is the output channel. </p> <p>\u751f\u4ea7\u64cd\u4f5c\uff1a\u5b9a\u4e49\u4e86\u751f\u4ea7\u64cd\u4f5c \\(\\odot\\)\uff0c\u7528\u4e8e\u8ba1\u7b97 \\(Y = Q \\odot C\\)\uff0c\u5176\u4e2d \\(Y \\in \\mathbb{C}^{M \\times D}\\)\u3002\u751f\u4ea7\u64cd\u4f5c\u7684\u5177\u4f53\u5b9a\u4e49\u4e3a \\(Y_{m,d_o} = \\sum_{d_i=0}^{D} Q_{m,d_i} \\cdot R_{d_i,d_o,m}\\)\uff0c\u5176\u4e2d \\(d_i\\) \u548c \\(d_o\\) \u5206\u522b\u8868\u793a\u8f93\u5165\u548c\u8f93\u51fa\u901a\u9053\u3002</p> <p>The result of \\(Q \\odot R\\) is then zero-padded to \\(\\mathbb{C}^{N \\times D}\\) before performing inverse Fourier transform back to the time domain. The structure is shown in Figure 3.</p> <p>\u9006\u5085\u91cc\u53f6\u53d8\u6362\uff1a\\(Q \\odot R\\) \u7684\u7ed3\u679c\u9996\u5148\u8fdb\u884c\u96f6\u586b\u5145\u5230 \\(\\mathbb{C}^{N \\times D}\\)\uff0c\u7136\u540e\u6267\u884c\u9006\u5085\u91cc\u53f6\u53d8\u6362\u56de\u5230\u65f6\u57df\u3002 </p> <p>\u6d89\u53ca\u5230\u9891\u57df\u7684\u8bba\u6587\u90fd\uff0c\u597d\u96be\u554a\u554a\u554a\u554a\u03b5\uff1d\u03b5\uff1d\u03b5\uff1d(#&gt;\u0434&lt;)\uff89</p> <p> </p> <p>\u56fe 3 \u5c55\u793a\u4e86\u4e00\u4e2a\u4f7f\u7528\u5085\u91cc\u53f6\u53d8\u6362\uff08FEB-f\uff09\u7684\u9891\u7387\u589e\u5f3a\u5757\uff08Frequency Enhanced Block\uff09\u7684\u7ed3\u6784\uff1a</p> <ol> <li> <p>\u8f93\u5165\uff1a\u8f93\u5165\u6570\u636e \\(x^{l-1}_{en/de}\\) \u7ecf\u8fc7\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u5904\u7406\uff0c\u5f97\u5230 \\(q \\in \\mathbb{R}^{L \\times D}\\)\u3002</p> </li> <li> <p>\u5085\u91cc\u53f6\u53d8\u6362\uff1a\u5bf9 \\(q\\) \u8fdb\u884c\u5085\u91cc\u53f6\u53d8\u6362 \\(\\mathcal{F}\\)\uff0c\u5f97\u5230\u9891\u57df\u8868\u793a \\(Q \\in \\mathbb{C}^{N \\times D}\\)\u3002</p> </li> <li> <p>\u91c7\u6837\uff1a\u5728\u9891\u57df\u4e2d\uff0c\u5bf9 \\(Q\\) \u8fdb\u884c\u91c7\u6837\uff0c\u4fdd\u7559 \\(M\\) \u4e2a\u6a21\u5f0f\uff0c\u5f97\u5230 \\(\\tilde{Q} \\in \\mathbb{C}^{M \\times D}\\)\u3002</p> </li> <li> <p>\u53c2\u6570\u5316\u6838\uff1a\u4f7f\u7528\u4e00\u4e2a\u53c2\u6570\u5316\u6838 \\(R \\in \\mathbb{C}^{M \\times D \\times D}\\)\uff0c\u8be5\u6838\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\u3002</p> </li> <li> <p>\u4e58\u6cd5\u64cd\u4f5c\uff1a\u5c06 \\(\\tilde{Q}\\) \u548c \\(R\\) \u8fdb\u884c\u9010\u5143\u7d20\u4e58\u6cd5\uff08Hadamard \u4e58\u79ef\uff09\uff0c\u5f97\u5230 \\(\\tilde{Y} \\in \\mathbb{C}^{M \\times D}\\)\u3002</p> </li> <li> <p>\u586b\u5145\uff1a\u5c06 \\(\\tilde{Y}\\) \u8fdb\u884c\u96f6\u586b\u5145\uff08padding\uff09\uff0c\u4f7f\u5176\u7ef4\u5ea6\u6062\u590d\u5230 \\(Y \\in \\mathbb{C}^{N \\times D}\\)\u3002</p> </li> <li> <p>\u9006\u5085\u91cc\u53f6\u53d8\u6362\uff1a\u5bf9\u586b\u5145\u540e\u7684 \\(Y\\) \u8fdb\u884c\u9006\u5085\u91cc\u53f6\u53d8\u6362 \\(\\mathcal{F}^{-1}\\)\uff0c\u5f97\u5230\u65f6\u57df\u8868\u793a \\(y \\in \\mathbb{R}^{L_{de} \\times D}\\)\u3002</p> </li> </ol> <p>\u603b\u7ed3\u6765\u8bf4\uff0c\u8fd9\u4e2a\u9891\u7387\u589e\u5f3a\u5757\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u5c06\u8f93\u5165\u6570\u636e\u8f6c\u6362\u5230\u9891\u57df\uff0c\u7136\u540e\u9009\u62e9\u6027\u5730\u4fdd\u7559\u91cd\u8981\u7684\u9891\u7387\u6a21\u5f0f\uff0c\u518d\u901a\u8fc7\u53c2\u6570\u5316\u6838\u8fdb\u884c\u5904\u7406\uff0c\u6700\u540e\u901a\u8fc7\u9006\u5085\u91cc\u53f6\u53d8\u6362\u5c06\u7ed3\u679c\u8f6c\u6362\u56de\u65f6\u57df\u3002\u8fd9\u79cd\u7ed3\u6784\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u53d6\u548c\u5904\u7406\u9891\u7387\u4fe1\u606f\uff0c\u4ece\u800c\u589e\u5f3a\u6a21\u578b\u7684\u6027\u80fd\u3002</p> <p>Frequency Enhanced Attention with Fourier Transform (FEA-f) </p> <p>We use the expression of the canonical transformer. </p> <p>The input: queries, keys, values are denoted as \\(q \\in \\mathbb{R}^{L \\times D}\\), \\(k \\in \\mathbb{R}^{L \\times D}\\), \\(v \\in \\mathbb{R}^{L \\times D}\\). </p> <p>\u8f93\u5165\uff1a\u8f93\u5165\u5305\u62ec\u67e5\u8be2\uff08queries\uff09\u3001\u952e\uff08keys\uff09\u548c\u503c\uff08values\uff09\uff0c\u5206\u522b\u8868\u793a\u4e3a \\(q \\in \\mathbb{R}^{L \\times D}\\)\uff0c\\(k \\in \\mathbb{R}^{L \\times D}\\)\uff0c\\(v \\in \\mathbb{R}^{L \\times D}\\)\u3002</p> <p>In cross-attention, the queries come from the decoder and can be obtained by \\(q = x_{en} \\cdot w_q\\), where \\(w_q \\in \\mathbb{R}^{D \\times D}\\). </p> <p>The keys and values are from the encoder and can be obtained by \\(k = x_{de} \\cdot w_k\\) and \\(v = x_{de} \\cdot w_v\\), where \\(w_k, w_v \\in \\mathbb{R}^{D \\times D}\\). </p> <p>Formally, the canonical attention can be written as $$ \\text{Atten}(q, k, v) = \\text{Softmax}\\left(\\frac{q k^\\top}{\\sqrt{d_q}}\\right) v. $$</p> <p>\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\uff1a\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u53ef\u4ee5\u8868\u793a\u4e3a $$ \\text{Atten}(q, k, v) = \\text{Softmax}\\left(\\frac{q k^\\top}{\\sqrt{d_q}}\\right) v. $$ FEA-f \u673a\u5236 </p> <p>In FEA-f, we convert the queries, keys, and values with Fourier Transform and perform a similar attention mechanism in the frequency domain, by randomly selecting \\(M\\) modes. We denote the selected version after Fourier Transform as \\(\\tilde{Q} \\in \\mathbb{C}^{M \\times D}\\), \\(\\tilde{K} \\in \\mathbb{C}^{M \\times D}\\), \\(\\tilde{V} \\in \\mathbb{C}^{M \\times D}\\). </p> <p>\u9996\u5148\uff0c\u5bf9\u67e5\u8be2\u3001\u952e\u548c\u503c\u8fdb\u884c\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u5e76\u5728\u9891\u57df\u4e2d\u968f\u673a\u9009\u62e9 \\(M\\) \u4e2a\u6a21\u5f0f\uff0c\u5f97\u5230 \\(\\tilde{Q} \\in \\mathbb{C}^{M \\times D}\\)\uff0c\\(\\tilde{K} \\in \\mathbb{C}^{M \\times D}\\)\uff0c\\(\\tilde{V} \\in \\mathbb{C}^{M \\times D}\\)\u3002</p> <p>The FEA-f is defined as $$ \\tilde{Q} = \\text{Select}(\\mathcal{F}(q)) $$</p> \\[ \\tilde{K} = \\text{Select}(\\mathcal{F}(k)) \\] \\[ \\tilde{V} = \\text{Select}(\\mathcal{F}(v)) \\] \\[ \\text{FEA-f}(q, k, v) = \\mathcal{F}^{-1}(\\text{Padding}(\\sigma(\\tilde{Q} \\cdot \\tilde{K}^\\top) \\cdot \\tilde{V})), \\] <p>where \\(\\sigma\\) is the activation function. </p> <p>\u7136\u540e\uff0c\u5b9a\u4e49 FEA-f \u4e3a $$ \\text{FEA-f}(q, k, v) = \\mathcal{F}^{-1}(\\text{Padding}(\\sigma(\\tilde{Q} \\cdot \\tilde{K}^\\top) \\cdot \\tilde{V})), $$ We use softmax or tanh for activation, since their converging performance differs in different data sets. Let \\(Y = \\sigma(\\tilde{Q} \\cdot \\tilde{K}^\\top) \\cdot \\tilde{V}\\),</p> <p>\u5176\u4e2d \\(\\sigma\\) \u662f\u6fc0\u6d3b\u51fd\u6570\uff0c\u53ef\u4ee5\u4f7f\u7528 softmax \u6216 tanh\uff0c\u56e0\u4e3a\u5b83\u4eec\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u6536\u655b\u6027\u80fd\u4e0d\u540c\u3002</p> <p>\u6fc0\u6d3b\u51fd\u6570\uff1a\u6fc0\u6d3b\u51fd\u6570 \\(\\sigma\\) \u7528\u4e8e\u8ba1\u7b97 \\(\\tilde{Q} \\cdot \\tilde{K}^\\top\\) \u548c \\(\\tilde{V}\\) \u7684\u9010\u5143\u7d20\u4e58\u79ef\uff0c\u5f97\u5230 \\(Y = \\sigma(\\tilde{Q} \\cdot \\tilde{K}^\\top) \\cdot \\tilde{V}\\)\uff0c\u5176\u4e2d \\(Y \\in \\mathbb{C}^{M \\times D}\\)\u3002</p> <p>and \\(Y \\in \\mathbb{C}^{M \\times D}\\) needs to be zero-padded to \\(\\mathbb{C}^{L \\times D}\\) before performing inverse Fourier transform. The FEA-f structure is shown in Figure 4.</p> <p>\u9006\u5085\u91cc\u53f6\u53d8\u6362\uff1a\u5c06 \\(Y\\) \u8fdb\u884c\u96f6\u586b\u5145\u5230 \\(\\mathbb{C}^{L \\times D}\\)\uff0c\u7136\u540e\u8fdb\u884c\u9006\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u5f97\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u3002</p>"},{"location":"literature/TSP/11_Fedformer/#33-wavelet-enhanced-structure","title":"3.3. Wavelet Enhanced Structure","text":"<p>Discrete Wavelet Transform (DWT)  While the Fourier transform creates a representation of the signal in the frequency domain, the Wavelet transform creates a representation in both the frequency and time domain, allowing efficient access of localized information of the signal. </p> <p>Fourier \u53d8\u6362\u5728\u9891\u57df\u4e2d\u521b\u5efa\u4fe1\u53f7\u7684\u8868\u793a\uff0c\u800c\u5c0f\u6ce2\u53d8\u6362\u5219\u5728\u9891\u57df\u548c\u65f6\u57df\u4e2d\u540c\u65f6\u521b\u5efa\u4fe1\u53f7\u7684\u8868\u793a\uff0c\u5141\u8bb8\u9ad8\u6548\u8bbf\u95ee\u4fe1\u53f7\u7684\u5c40\u90e8\u4fe1\u606f\u3002</p> <p>The multiwavelet transform synergizes the advantages of orthogonal polynomials as well as wavelets. </p> <p>\u591a\u5c0f\u6ce2\u53d8\u6362\u7ed3\u5408\u4e86\u6b63\u4ea4\u591a\u9879\u5f0f\u548c\u5c0f\u6ce2\u7684\u4f18\u52bf\u3002</p> <p>For a given \\(f(x)\\), the multiwavelet coefficients at the scale \\(n\\) can be defined as \\(s_l^n = \\left[\\left\\langle f, \\phi_{il}^n \\right\\rangle_{\\mu_n}\\right]_{i=0}^{k-1}\\), \\(d_l^n = \\left[\\left\\langle f, \\psi_{il}^n \\right\\rangle_{\\mu_n}\\right]_{i=0}^{k-1}\\), respectively, w.r.t. measure \\(\\mu_n\\) with \\(s_l^n, d_l^n \\in \\mathbb{R}^{k \\times 2^n}\\). \\(\\phi_{il}^n\\) are wavelet orthonormal basis of piecewise polynomials. </p> <p>\u5bf9\u4e8e\u7ed9\u5b9a\u7684\u51fd\u6570 \\(f(x)\\)\uff0c\u5c3a\u5ea6\u4e3a \\(n\\) \u7684\u591a\u5c0f\u6ce2\u7cfb\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a \\(s_l^n = \\left[\\left\\langle f, \\phi_{il}^n \\right\\rangle_{\\mu_n}\\right]_{i=0}^{k-1}\\)\uff0c\\(d_l^n = \\left[\\left\\langle f, \\psi_{il}^n \\right\\rangle_{\\mu_n}\\right]_{i=0}^{k-1}\\)\uff0c\u5206\u522b\u5bf9\u5e94\u4e8e\u6d4b\u5ea6 \\(\\mu_n\\)\uff0c\u5176\u4e2d \\(s_l^n, d_l^n \\in \\mathbb{R}^{k \\times 2^n}\\)\u3002\\(\\phi_{il}^n\\) \u662f\u5206\u6bb5\u591a\u9879\u5f0f\u7684\u5c0f\u6ce2\u6b63\u4ea4\u57fa\u3002</p> <ul> <li>\u5bf9\u4e8e\u7ed9\u5b9a\u7684\u51fd\u6570 \\(f(x)\\)\uff0c\u5728\u5c3a\u5ea6 \\(n\\) \u4e0b\u7684\u591a\u5c0f\u6ce2\u7cfb\u6570\u53ef\u4ee5\u5b9a\u4e49\u4e3a\uff1a</li> <li>\u5c3a\u5ea6\u7cfb\u6570 \\(s_l^n = \\left[\\left\\langle f, \\phi_{il}^n \\right\\rangle_{\\mu_n}\\right]_{i=0}^{k-1}\\)</li> <li>\u7ec6\u8282\u7cfb\u6570 \\(d_l^n = \\left[\\left\\langle f, \\psi_{il}^n \\right\\rangle_{\\mu_n}\\right]_{i=0}^{k-1}\\)</li> <li>\u8fd9\u91cc\uff0c\\(\\left\\langle f, \\phi_{il}^n \\right\\rangle_{\\mu_n}\\) \u548c \\(\\left\\langle f, \\psi_{il}^n \\right\\rangle_{\\mu_n}\\) \u5206\u522b\u8868\u793a\u51fd\u6570 \\(f\\) \u4e0e\u5c3a\u5ea6\u51fd\u6570 \\(\\phi_{il}^n\\) \u548c\u5c0f\u6ce2\u51fd\u6570 \\(\\psi_{il}^n\\) \u7684\u5185\u79ef\uff0c\u76f8\u5bf9\u4e8e\u6d4b\u5ea6 \\(\\mu_n\\)\u3002</li> <li>\\(s_l^n, d_l^n \\in \\mathbb{R}^{k \\times 2^n}\\) \u8868\u793a\u8fd9\u4e9b\u7cfb\u6570\u7684\u7ef4\u5ea6\u3002</li> <li>\\(\\phi_{il}^n\\) \u662f\u5206\u6bb5\u591a\u9879\u5f0f\u7684\u5c0f\u6ce2\u6b63\u4ea4\u57fa\u51fd\u6570\uff0c\u8fd9\u4e9b\u57fa\u51fd\u6570\u7528\u4e8e\u6784\u5efa\u5c0f\u6ce2\u53d8\u6362\u3002</li> </ul> <p>The decomposition/reconstruction across scales is defined as</p> <p>\u5c3a\u5ea6\u5206\u89e3\u548c\u91cd\u5efa\u7ed3\u6784\u5b9a\u4e49\u5982\u4e0b\uff1a</p> \\[ \\begin{aligned} \\mathbf{s}_l^n &amp;= H^{(0)} \\mathbf{s}_{2l}^{n+1} + H^{(1)} \\mathbf{s}_{2l+1}^{n+1}, \\\\ \\mathbf{s}_{2l}^{n+1} &amp;= \\Sigma^{(0)} \\left( H^{(0)T} \\mathbf{s}_l^n + G^{(0)T} \\mathbf{d}_l^n \\right), \\\\ \\mathbf{d}_l^n &amp;= G^{(0)} \\mathbf{s}_{2l}^{n+1} + H^{(1)} \\mathbf{s}_{2l+1}^{n+1}, \\\\ \\mathbf{s}_{2l+1}^{n+1} &amp;= \\Sigma^{(1)} \\left( H^{(1)T} \\mathbf{s}_l^n + G^{(1)T} \\mathbf{d}_l^n \\right), \\end{aligned} \\] <p>where \\((H^{(0)}, H^{(1)}, G^{(0)}, G^{(1)})\\) are linear coefficients for multiwavelet decomposition filters. </p> <ul> <li>\u7ed9\u51fa\u4e86\u591a\u5c0f\u6ce2\u5206\u89e3\u7684\u4e00\u7ec4\u516c\u5f0f\uff0c\u6d89\u53ca\u5230\u5c3a\u5ea6\u7cfb\u6570 \\(\\mathbf{s}_l^n\\) \u548c\u7ec6\u8282\u7cfb\u6570 \\(\\mathbf{d}_l^n\\) \u7684\u8ba1\u7b97\u3002</li> <li>\u4f7f\u7528\u4e86\u56fa\u5b9a\u7684\u7ebf\u6027\u7cfb\u6570\u77e9\u9635 \\(H^{(0)}\\), \\(H^{(1)}\\), \\(G^{(0)}\\), \\(G^{(1)}\\) \u6765\u8868\u793a\u591a\u5c0f\u6ce2\u5206\u89e3\u6ee4\u6ce2\u5668\u3002</li> </ul> <p>They are fixed matrices used for wavelet decomposition. </p> <p>The multiwavelet representation of a signal can be obtained by the tensor product of multiscale and multiwavelet basis.</p> <p>\u4fe1\u53f7\u7684\u591a\u5c0f\u6ce2\u8868\u793a\u53ef\u4ee5\u901a\u8fc7\u591a\u5c3a\u5ea6\u548c\u591a\u5c0f\u6ce2\u57fa\u7684\u5f20\u91cf\u79ef\u83b7\u5f97\u3002</p> <p>Note that the basis at various scales are coupled by the tensor product, so we need to untangle it. Inspired by (Gupta et al., 2021), we adapt a non-standard wavelet representation to reduce the model complexity. </p> <p>\u8bf7\u6ce8\u610f\uff0c\u4e0d\u540c\u5c3a\u5ea6\u7684\u57fa\u901a\u8fc7\u5f20\u91cf\u79ef\u8026\u5408\u5728\u4e00\u8d77\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u5c06\u5176\u89e3\u8026\u3002\u53d7 Gupta \u7b49\u4eba\uff082021\uff09\u7684\u542f\u53d1\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u4e00\u79cd\u975e\u6807\u51c6\u7684\u5c0f\u6ce2\u8868\u793a\u6765\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u3002</p> <p>For a map function \\(F(x) = x'\\), the map under multiwavelet domain can be written as $$ U_{dl}^n = A_n d_l^n + B_n s_l^n, \\quad U_{sl}^n = C_n d_l^n, \\quad U_{sl}^L = \\bar{F} s_l^L, $$</p> <p>where \\((U_{sl}^n, U_{dl}^n, s_l^n, d_l^n)\\) are the multiscale, multiwavelet coefficients, \\(L\\) is the coarsest scale under recursive decomposition, and \\(A_n, B_n, C_n\\) are three independent FEB-f blocks modules used for processing different signal during decomposition and reconstruction. </p> <p>\u5bf9\u4e8e\u6620\u5c04\u51fd\u6570 \\(F(x) = x'\\)\uff0c\u5728\u591a\u5c0f\u6ce2\u57df\u4e2d\u7684\u6620\u5c04\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a $$ U_{dl}^n = A_n d_l^n + B_n s_l^n, \\quad U_{sl}^n = C_n d_l^n, \\quad U_{sl}^L = \\bar{F} s_l^L, $$</p> <p>\u5176\u4e2d \\((U_{sl}^n, U_{dl}^n, s_l^n, d_l^n)\\) \u662f\u591a\u5c3a\u5ea6\u3001\u591a\u5c0f\u6ce2\u7cfb\u6570\uff0c\\(L\\) \u662f\u9012\u5f52\u5206\u89e3\u4e0b\u7684\u6700\u7c97\u7cd9\u5c3a\u5ea6\uff0c\\(A_n, B_n, C_n\\) \u662f\u4e09\u4e2a\u72ec\u7acb\u7684 FEB-f \u5757\u6a21\u5757\uff0c\u7528\u4e8e\u5728\u5206\u89e3\u548c\u91cd\u6784\u8fc7\u7a0b\u4e2d\u5904\u7406\u4e0d\u540c\u7684\u4fe1\u53f7\u3002</p> <p>Here \\(\\bar{F}\\) is a single-layer of perceptrons which processes the remaining coarsest signal after \\(L\\) decomposed steps. More designed detail is described in Appendix D.</p> <p>\u8fd9\u91cc \\(\\bar{F}\\) \u662f\u4e00\u4e2a\u5355\u5c42\u611f\u77e5\u5668\uff0c\u7528\u4e8e\u5904\u7406 \\(L\\) \u6b21\u5206\u89e3\u6b65\u9aa4\u540e\u5269\u4f59\u7684\u6700\u7c97\u7cd9\u4fe1\u53f7\u3002\u66f4\u591a\u8bbe\u8ba1\u7ec6\u8282\u5728\u9644\u5f55 D \u4e2d\u63cf\u8ff0\u3002</p> <p>\u539f\u6587\u5982\u4e0b\uff1a</p> <p>Frequency Enhanced Block with Wavelet Transform (FEB-w) </p> <p>The overall FEB-w architecture is shown in Figure 5.</p> <p>\u9891\u7387\u589e\u5f3a\u5757\u4e0e\u5c0f\u6ce2\u53d8\u6362\uff08FEB-w\uff09\u7684\u6574\u4f53 FEB-w \u67b6\u6784\u5982\u56fe 5 \u6240\u793a\u3002</p> <p></p> <p>It differs from FEB-f in the recursive mechanism: the input is decomposed into 3 parts recursively and operates individually. </p> <p>\u5b83\u4e0e FEB-f \u5728\u9012\u5f52\u673a\u5236\u4e0a\u6709\u6240\u4e0d\u540c\uff1a\u8f93\u5165\u88ab\u9012\u5f52\u5730\u5206\u89e3\u4e3a 3 \u4e2a\u90e8\u5206\u5e76\u5206\u522b\u8fdb\u884c\u64cd\u4f5c\u3002</p> <p>For the wavelet decomposition part, we implement the fixed Legendre wavelets basis decomposition matrix. </p> <p>\u5bf9\u4e8e\u5c0f\u6ce2\u5206\u89e3\u90e8\u5206\uff0c\u6211\u4eec\u5b9e\u73b0\u4e86\u56fa\u5b9a\u7684\u52d2\u8ba9\u5fb7\u5c0f\u6ce2\u57fa\u5206\u89e3\u77e9\u9635\u3002</p> <p>Three FEB-f modules are used to process the resulting high-frequency part, low-frequency part, and remaining part from wavelet decomposition respectively. </p> <p>\u4e09\u4e2a FEB-f \u6a21\u5757\u5206\u522b\u7528\u4e8e\u5904\u7406\u5c0f\u6ce2\u5206\u89e3\u5f97\u5230\u7684\u9ad8\u9891\u90e8\u5206\u3001\u4f4e\u9891\u90e8\u5206\u548c\u5269\u4f59\u90e8\u5206\u3002</p> <p>For each cycle \\(L\\), it produces a processed high-frequency tensor \\(Ud(L)\\), a processed low-frequency frequency tensor \\(Us(L)\\), and the raw low-frequency tensor \\(X(L+1)\\). </p> <p>\u5bf9\u4e8e\u6bcf\u4e2a\u5468\u671f \\(L\\)\uff0c\u5b83\u751f\u6210\u4e00\u4e2a\u5904\u7406\u8fc7\u7684\u9ad8\u9891\u5f20\u91cf \\(Ud(L)\\)\uff0c\u4e00\u4e2a\u5904\u7406\u8fc7\u7684\u4f4e\u9891\u9891\u7387\u5f20\u91cf\\(Us(L)\\)\uff0c\u4ee5\u53ca\u539f\u59cb\u7684\u4f4e\u9891\u5f20\u91cf \\(X(L+1)\\)\u3002</p> <p>This is a ladder-down approach, and the decomposition stage performs the decimation of the signal by a factor of \\(1/2\\), running for a maximum of \\(L\\) cycles, where \\(L &lt; \\log_2(M)\\) for a given input sequence of size \\(M\\). </p> <p>\u8fd9\u662f\u4e00\u79cd\u9010\u7ea7\u4e0b\u964d\u7684\u65b9\u6cd5\uff0c\u5206\u89e3\u9636\u6bb5\u901a\u8fc7 \\(1/2\\) \u7684\u56e0\u5b50\u5bf9\u4fe1\u53f7\u8fdb\u884c\u964d\u91c7\u6837\uff0c\u6700\u591a\u8fd0\u884c \\(L\\) \u4e2a\u5468\u671f\uff0c\u5176\u4e2d\u5bf9\u4e8e\u7ed9\u5b9a\u5927\u5c0f\u4e3a \\(M\\) \u7684\u8f93\u5165\u5e8f\u5217\uff0c\\(L &lt; \\log_2(M)\\)\u3002</p> <p>In practice, \\(L\\) is set as a fixed argument parameter. The three sets of FEB-f blocks are shared during different decomposition cycles \\(L\\).</p> <p>\u5728\u5b9e\u8df5\u4e2d\uff0c\\(L\\) \u88ab\u8bbe\u5b9a\u4e3a\u4e00\u4e2a\u56fa\u5b9a\u7684\u53c2\u6570\u3002\u5728\u4e0d\u540c\u7684\u5206\u89e3\u5468\u671f \\(L\\) \u4e2d\uff0c\u4e09\u7ec4 FEB-f \u6a21\u5757\u662f\u5171\u4eab\u7684\u3002</p> <p>For the wavelet reconstruction part, we recursively build up our output tensor as well. \u5bf9\u4e8e\u5c0f\u6ce2\u91cd\u6784\u90e8\u5206\uff0c\u6211\u4eec\u540c\u6837\u9012\u5f52\u5730\u6784\u5efa\u8f93\u51fa\u5f20\u91cf\u3002</p> <p>For each cycle \\(L\\), we combine \\(X(L+1)\\), \\(Us(L)\\), and \\(Ud(L)\\) produced from the decomposition part and produce \\(X(L)\\) for the next reconstruction cycle. For each cycle, the length dimension of the signal tensor is increased by 2 times.</p> <p>\u5bf9\u4e8e\u6bcf\u4e2a\u5468\u671f \\(L\\)\uff0c\u6211\u4eec\u7ed3\u5408\u4ece\u5206\u89e3\u90e8\u5206\u4ea7\u751f\u7684 \\(X(L+1)\\)\u3001\\(Us(L)\\) \u548c \\(Ud(L)\\)\uff0c\u5e76\u751f\u6210\u4e0b\u4e00\u4e2a\u91cd\u6784\u5468\u671f\u7684 \\(X(L)\\)\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u5468\u671f\uff0c\u4fe1\u53f7\u5f20\u91cf\u7684\u957f\u5ea6\u7ef4\u5ea6\u589e\u52a0\u4e24\u500d\u3002</p> <p>\u5728\u4fe1\u53f7\u5904\u7406\u8fc7\u7a0b\u4e2d\uff0c\\(Us(L)\\) \u8868\u793a\u7b2c \\(L\\) \u5c42\u7684\u5c3a\u5ea6\u7cfb\u6570\uff0c\u800c \\(X(L+1)\\) \u4ee3\u8868\u539f\u59cb\u7684\u4f4e\u9891\u5f20\u91cf\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u9010\u7ea7\u4e0b\u964d\u7b56\u7565\uff0c\u5176\u4e2d\u5206\u89e3\u9636\u6bb5\u5c06\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u964d\u4f4e\u4e3a\u539f\u6765\u7684\u4e00\u534a\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u6700\u591a\u91cd\u590d \\(L\\) \u6b21\u3002\u8fd9\u91cc\uff0c\\(L\\) \u7684\u503c\u53d6\u51b3\u4e8e\u8f93\u5165\u5e8f\u5217\u7684\u5927\u5c0f \\(M\\)\uff0c\u5e76\u4e14\u6ee1\u8db3 \\(L &lt; \\log_2(M)\\)\u3002\u5728\u5b9e\u9645\u64cd\u4f5c\u4e2d\uff0c\\(L\\) \u4f5c\u4e3a\u4e00\u4e2a\u56fa\u5b9a\u53c2\u6570\u8fdb\u884c\u8bbe\u7f6e\u3002\u5728\u4e0d\u540c\u7684\u5206\u89e3\u5468\u671f\u4e2d\uff0c\u4e09\u7ec4 FEB-f \u6a21\u5757\u4f1a\u88ab\u91cd\u590d\u4f7f\u7528\u3002\u5728\u5c0f\u6ce2\u91cd\u6784\u9636\u6bb5\uff0c\u6211\u4eec\u9012\u5f52\u5730\u6784\u5efa\u6700\u7ec8\u7684\u8f93\u51fa\u5f20\u91cf\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u6bcf\u4e2a\u5468\u671f \\(L\\)\uff0c\u6211\u4eec\u5c06\u7531\u5206\u89e3\u9636\u6bb5\u751f\u6210\u7684 \\(X(L+1)\\)\u3001\\(Us(L)\\) \u548c \\(Ud(L)\\) \u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u4ea7\u751f\u7528\u4e8e\u4e0b\u4e00\u4e2a\u91cd\u6784\u5468\u671f\u7684 \\(X(L)\\)\u3002\u5728\u6bcf\u4e2a\u5468\u671f\u5185\uff0c\u4fe1\u53f7\u5f20\u91cf\u7684\u957f\u5ea6\u7ef4\u5ea6\u90fd\u4f1a\u7ffb\u500d\u3002</p> <p>\u539f\u6587\u8bc6\u522b\u5982\u4e0b\uff1a</p>"},{"location":"literature/TSP/11_Fedformer/#34-mixture-of-experts-for-seasonal-trend-decomposition","title":"3.4. Mixture of Experts for Seasonal-Trend Decomposition","text":"<p>3.4 \u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u5728\u5b63\u8282-\u8d8b\u52bf\u5206\u89e3\u4e2d\u7684\u5e94\u7528</p> <p>Because of the commonly observed complex periodic pattern coupled with the trend component on real-world data, extracting the trend can be hard with fixed window average pooling. </p> <p>\u7531\u4e8e\u5728\u5b9e\u9645\u6570\u636e\u4e2d\u5e38\u89c1\u7684\u590d\u6742\u5468\u671f\u6a21\u5f0f\u4e0e\u8d8b\u52bf\u6210\u5206\u76f8\u7ed3\u5408\uff0c\u4f7f\u7528\u56fa\u5b9a\u7a97\u53e3\u5e73\u5747\u6c60\u5316\u63d0\u53d6\u8d8b\u52bf\u53ef\u80fd\u8f83\u4e3a\u56f0\u96be\u3002</p> <p>To overcome such a problem, we design a Mixture Of Experts Decomposition block (MOEDecomp). It contains a set of average filters with different sizes to extract multiple trend components from the input signal and a set of data-dependent weights for combining them as the final trend. Formally, we have</p> <p>\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4e13\u5bb6\u6df7\u5408\u5206\u89e3\u6a21\u5757\uff08MOEDecomp\uff09\u3002\u8be5\u6a21\u5757\u5305\u542b\u4e00\u7ec4\u4e0d\u540c\u5c3a\u5bf8\u7684\u5e73\u5747\u6ee4\u6ce2\u5668\uff0c\u7528\u4e8e\u4ece\u8f93\u5165\u4fe1\u53f7\u4e2d\u63d0\u53d6\u591a\u4e2a\u8d8b\u52bf\u6210\u5206\uff0c\u4ee5\u53ca\u4e00\u7ec4\u6570\u636e\u4f9d\u8d56\u7684\u6743\u91cd\uff0c\u7528\u4e8e\u5c06\u8fd9\u4e9b\u6210\u5206\u7ec4\u5408\u6210\u6700\u7ec8\u8d8b\u52bf\u3002\u5f62\u5f0f\u4e0a\uff0c\u6211\u4eec\u6709\uff1a $$ X_{\\text{trend}} = \\text{Softmax}(L(x)) * (F(x)), $$</p> <p>where \\(F(\\cdot)\\) is a set of average pooling filters and \\(\\text{Softmax}(L(x))\\) is the weights for mixing these extracted trends.</p> \\[ X_{\\text{trend}} = \\text{Softmax}(L(x)) * (F(x)), \\] <p>\u5176\u4e2d \\(F(\\cdot)\\) \u8868\u793a\u4e00\u7ec4\u5e73\u5747\u6c60\u5316\u6ee4\u6ce2\u5668\uff0c\u800c \\(\\text{Softmax}(L(x))\\) \u8868\u793a\u7528\u4e8e\u6df7\u5408\u8fd9\u4e9b\u63d0\u53d6\u51fa\u7684\u8d8b\u52bf\u7684\u6743\u91cd\u3002</p>"},{"location":"literature/TSP/12_WITRAN/","title":"2023\u3001WITRAN","text":""},{"location":"literature/TSP/12_WITRAN/#2023witran","title":"2023\u3001WITRAN","text":"2025-04-14 22:46:482025-09-28 12:54:06 <p> \u7ea6 6196 \u4e2a\u5b57  8 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 31 \u5206\u949f</p> <p>NeurIPS 2023 </p> <p>\u8bba\u6587\uff1ahttps://openreview.net/pdf?id=y08bkEtNBK </p> <p>\u6e90\u7801\uff1ahttps://github.com/Water2sea/WITRAN/tree/main</p> <p>\u5b9e\u9a8c\u5ba4\u516c\u4f17\u53f7\uff1ahttps://mp.weixin.qq.com/s/kkNEpZOAn9MFUGg5P9ZfXQ</p>"},{"location":"literature/TSP/12_WITRAN/#_1","title":"\u6458\u8981","text":"<p>Capturing semantic information is crucial for accurate long-range time series forecasting, which involves modeling global and local correlations, as well as discovering long- and short-term repetitive patterns. Previous works have partially addressed these issues separately, but have not been able to address all of them simultaneously. </p> <p>\u6355\u83b7\u8bed\u4e49\u4fe1\u606f\u5bf9\u4e8e\u51c6\u786e\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u6d89\u53ca\u5230\u5bf9\u5168\u5c40\u548c\u5c40\u90e8\u76f8\u5173\u6027\u7684\u5efa\u6a21\uff0c\u4ee5\u53ca\u53d1\u73b0\u957f\u671f\u548c\u77ed\u671f\u7684\u91cd\u590d\u6a21\u5f0f\u3002\u4ee5\u5f80\u7684\u7814\u7a76\u5206\u522b\u90e8\u5206\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5c1a\u672a\u80fd\u591f\u540c\u65f6\u89e3\u51b3\u6240\u6709\u8fd9\u4e9b\u95ee\u9898\u3002</p> <p>Meanwhile, their time and memory complexities are still not sufficiently low for long-range forecasting. </p> <p>To address the challenge of capturing different types of semantic information, we propose a novel Water-wave Information Transmission (WIT) framework. </p> <p>This framework captures both long- and short-term repetitive patterns through bi-granular information transmission.</p> <p>\u540c\u65f6\uff0c\u5b83\u4eec\u5728\u957f\u671f\u9884\u6d4b\u4e2d\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u5185\u5b58\u590d\u6742\u5ea6\u4ecd\u7136\u4e0d\u591f\u4f4e\u3002\u4e3a\u4e86\u5e94\u5bf9\u6355\u83b7\u4e0d\u540c\u7c7b\u578b\u7684\u8bed\u4e49\u4fe1\u606f\u7684\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6c34\u6ce2\u4fe1\u606f\u4f20\u8f93\uff08WIT\uff09\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u53cc\u7c92\u5ea6\u4fe1\u606f\u4f20\u8f93\u6355\u83b7\u957f\u671f\u548c\u77ed\u671f\u7684\u91cd\u590d\u6a21\u5f0f\u3002</p> <p>It also models global and local correlations by recursively fusing and selecting information using Horizontal Vertical Gated Selective Unit (HVGSU). </p> <p>\u5b83\u8fd8\u901a\u8fc7\u9012\u5f52\u878d\u5408\u548c\u9009\u62e9\u4fe1\u606f\u4f7f\u7528\u6c34\u5e73\u5782\u76f4\u95e8\u63a7\u9009\u62e9\u5355\u5143\uff08HVGSU\uff09\u6765\u5efa\u6a21\u5168\u5c40\u548c\u5c40\u90e8\u76f8\u5173\u6027\u3002</p> <p>In addition, to improve the computing efficiency, we propose a generic Recurrent Acceleration Network (RAN) which  reduces the time complexity to \\(O(\\sqrt{L})\\) while maintaining the memory complexity at  \\(O(L)\\) . </p> <p>\u6b64\u5916\uff0c\u4e3a\u4e86\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u9012\u5f52\u52a0\u901f\u7f51\u7edc\uff08RAN\uff09\uff0c\u8be5\u7f51\u7edc\u5728\u4fdd\u6301\u5185\u5b58\u590d\u6742\u5ea6\u4e3a \\(O(L)\\) \u7684\u540c\u65f6\u5c06\u65f6\u95f4\u590d\u6742\u5ea6\u964d\u4f4e\u5230 \\(O(\\sqrt{L})\\)\u3002</p> <p>\u5185\u5b58\u590d\u6742\u5ea6 &amp; \u65f6\u95f4\u590d\u6742\u5ea6</p> <p>Our proposed method, called Water-wave Information Transmission and Recurrent Acceleration Network (WITRAN), outperforms the state-of-the-art methods by 5.80% and 14.28% on long-range and ultra-long-range time series forecasting tasks respectively, as demonstrated by experiments on four benchmark datasets. The code is available at: https://github.com/Water2sea/WITRAN.</p> <p>\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a\u6c34\u6ce2\u4fe1\u606f\u4f20\u8f93\u548c\u9012\u5f52\u52a0\u901f\u7f51\u7edc\uff08WITRAN\uff09\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u957f\u671f\u548c\u8d85\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u5206\u522b\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u9ad8\u4e865.80%\u548c14.28%\u3002\u4ee3\u7801\u53ef\u5728\u4ee5\u4e0b\u7f51\u5740\u83b7\u53d6\uff1aGitHub - Water2sea/WITRAN\u3002</p> <p>\u5173\u952e\u8bcd\uff1a</p> <ul> <li>\u6c34\u6ce2\u7eb9\u4fe1\u606f\u4f20\u8f93\u6846\u67b6</li> <li>\u6c34\u5e73\u5782\u76f4\u95e8\u63a7\u9009\u62e9\u5355\u5143</li> <li>\u5faa\u73af\u52a0\u901f\u7f51\u7edc\uff0c\u89e3\u51b3\u590d\u6742\u5ea6\u95ee\u9898</li> </ul>"},{"location":"literature/TSP/12_WITRAN/#1-introduction","title":"1 Introduction","text":"<p>\u8d21\u732e\uff1a</p> <ul> <li>We propose a Water-wave Information Transmission and Recurrent Acceleration Network (WITRAN), which represents a novel paradigm in information transmission by enabling bi-granular flows. We provide a comprehensive comparison of WITRAN with previous methods in Figure 1 to highlight its uniqueness. Furthermore, in order to compare the differences between WITRAN and the model (a)-(h) in Figure 1 more clearly, we have prepared Table 1 to highlight the advantages of WITRAN. </li> <li> <p>\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u6c34\u6ce2\u4fe1\u606f\u4f20\u8f93\u4e0e\u9012\u5f52\u52a0\u901f\u7f51\u7edc\uff08WITRAN\uff09\u7684\u65b0\u578b\u4fe1\u606f\u4f20\u8f93\u8303\u5f0f\uff0c\u5b83\u901a\u8fc7\u5b9e\u73b0\u53cc\u7c92\u5ea6\u4fe1\u606f\u6d41\u6765\u4ee3\u8868\u4fe1\u606f\u4f20\u8f93\u7684\u65b0\u65b9\u6cd5\u3002\u6211\u4eec\u901a\u8fc7\u56fe1\u4e0e\u4e4b\u524d\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6bd4\u8f83\uff0c\u4ee5\u7a81\u51fa\u5176\u72ec\u7279\u6027\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u66f4\u6e05\u6670\u5730\u6bd4\u8f83WITRAN\u4e0e\u56fe1\u4e2d\u7684\u6a21\u578b\uff08a\uff09-\uff08h\uff09\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u51c6\u5907\u4e86\u88681\u6765\u7a81\u51faWITRAN\u7684\u4f18\u52bf\u3002</p> </li> <li> <p>We propose a novel Horizontal Vertical Gated Selective Unit (HVGSU) which captures longand short-term periodic semantic information by using Gated Selective Cell (GSC) independently in both directions, preserving the characteristics of periodic semantic information. The fusion and selection in GSC can model the correlations of long- and short-term periodic semantic information. Furthermore, utilizing a recurrent structure with HVGSU facilitates the gradual capture of semantic information from local to global within a sequence.</p> </li> <li>\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u6c34\u5e73\u5782\u76f4\u95e8\u63a7\u9009\u62e9\u5355\u5143\uff08HVGSU\uff09\uff0c\u8be5\u5355\u5143\u901a\u8fc7\u5728\u4e24\u4e2a\u65b9\u5411\u4e0a\u72ec\u7acb\u4f7f\u7528\u95e8\u63a7\u9009\u62e9\u5355\u5143\uff08GSC\uff09\u6765\u6355\u83b7\u957f\u671f\u548c\u77ed\u671f\u7684\u5468\u671f\u6027\u8bed\u4e49\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u7559\u5468\u671f\u6027\u8bed\u4e49\u4fe1\u606f\u7684\u7279\u5f81\u3002GSC\u4e2d\u7684\u878d\u5408\u548c\u9009\u62e9\u53ef\u4ee5\u5bf9\u957f\u671f\u548c\u77ed\u671f\u5468\u671f\u6027\u8bed\u4e49\u4fe1\u606f\u7684\u76f8\u5173\u6027\u8fdb\u884c\u5efa\u6a21\u3002\u6b64\u5916\uff0c\u5229\u7528\u5305\u542bHVGSU\u7684\u9012\u5f52\u7ed3\u6784\u6709\u52a9\u4e8e\u5728\u5e8f\u5217\u4e2d\u4ece\u5c40\u90e8\u5230\u5168\u5c40\u9010\u6b65\u6355\u83b7\u8bed\u4e49\u4fe1\u606f\u3002</li> <li>We present a Recurrent Acceleration Network (RAN) which is a generic acceleration  framework that significantly reduces the time complexity to \\(\\mathcal{O}(\\sqrt{L})\\) while maintaining the memory complexity of  \\(\\mathcal{O}(L)\\) . We summarize the complexities of different methods in Table 2, demonstrating the superior efficiency of our method.</li> <li>\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u65f6\u95f4\u590d\u6742\u5ea6&amp;\u7a7a\u95f4\u590d\u6742\u5ea6</li> <li> <p>\u5faa\u73af\u52a0\u901f\u6846\u67b6</p> </li> <li> <p> </p> </li> </ul> <p></p> <ul> <li>\u975e\u9010\u70b9\u8bed\u4e49\u4fe1\u606f\u6355\u83b7</li> <li>\u8be5\u80fd\u529b\u6307\u7684\u662f\u6a21\u578b\u662f\u5426\u80fd\u591f\u6355\u83b7\u975e\u9010\u70b9\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u5373\u6a21\u578b\u662f\u5426\u80fd\u591f\u7406\u89e3\u6570\u636e\u4e2d\u7684\u5168\u5c40\u6216\u6574\u4f53\u6a21\u5f0f\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5355\u4e2a\u70b9\u7684\u4fe1\u606f\u3002</li> <li>RNN\u548cCNN\u5177\u6709\u8fd9\u79cd\u80fd\u529b\uff0c\u800cFull Attention\u3001LogTrans\u3001Pyraformer\u3001MICN\u3001PatchTST\u548cTimesNet\u4e0d\u5177\u5907\u3002</li> <li>WITRAN\u5177\u5907\u8fd9\u79cd\u80fd\u529b\u3002</li> <li>\u662f\u5426\u5177\u5907\u5e8f\u5217\u5efa\u6a21\u7684\u80fd\u529b</li> <li>\u6355\u83b7\u957f\u671f\u5468\u671f\u6027\u7684\u7279\u6b8a\u8bbe\u8ba1</li> <li>\u8be5\u80fd\u529b\u6307\u7684\u662f\u6a21\u578b\u662f\u5426\u5177\u6709\u4e13\u95e8\u8bbe\u8ba1\u6765\u6355\u83b7\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u957f\u671f\u91cd\u590d\u6a21\u5f0f\u3002</li> <li>LogTrans\u3001Pyraformer\u3001TimesNet\u548cWITRAN\u5177\u6709\u8fd9\u79cd\u80fd\u529b\uff0c\u800cRNN\u3001CNN\u3001Full Attention\u3001MICN\u548cPatchTST\u4e0d\u5177\u5907\u3002</li> <li>WITRAN\u5177\u5907\u8fd9\u79cd\u80fd\u529b\u3002</li> <li>\u9ad8\u6548\u5efa\u6a21\u5168\u5c40\u76f8\u5173\u6027</li> <li>\u8be5\u80fd\u529b\u6307\u7684\u662f\u6a21\u578b\u662f\u5426\u80fd\u591f\u9ad8\u6548\u5730\uff08\u4f7f\u75281\u62162\u5c42\uff09\u5efa\u6a21\u5168\u5c40\u76f8\u5173\u6027\u3002</li> <li>RNN\u3001MICN\u548cTimesNet\u5177\u6709\u8fd9\u79cd\u80fd\u529b\uff0c\u800cCNN\u3001Full Attention\u3001LogTrans\u3001Pyraformer\u548cWITRAN\u4e0d\u5177\u5907\u3002</li> <li>WITRAN\u5177\u5907\u8fd9\u79cd\u80fd\u529b\u3002</li> <li>\u89e3\u51b3 RNN \u68af\u5ea6\u7206\u70b8\u548c\u68af\u5ea6\u6d88\u5931\u95ee\u9898</li> <li>\u8be5\u80fd\u529b\u6307\u7684\u662f\u6a21\u578b\u662f\u5426\u80fd\u591f\u6709\u6548\u89e3\u51b3RNN\u4e2d\u7684\u68af\u5ea6\u6d88\u5931\u6216\u7206\u70b8\u95ee\u9898\u3002</li> <li> <p>\u53ea\u6709WITRAN\u5177\u5907\u8fd9\u79cd\u80fd\u529b\u3002</p> </li> <li> <p> </p> </li> </ul> <p></p> <ul> <li> <p>\u4e0a\u8868\u5c55\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6</p> </li> <li> <p>\u5176\u4e2d\u6c34\u6ce2\u7eb9\u4fe1\u606f\u4f20\u8f93\u5faa\u73af\u52a0\u901f\u7f51\u7edc\u5185\u5b58\u5360\u7528\u4e5f\u662f \\(\\mathcal{O}(L)\\)  \uff0c\u4f46\u662f\u65f6\u95f4\u590d\u6742\u5ea6\u4f18\u52bf\u663e\u8457 \\(\\mathcal{O}(\\sqrt{L})\\)</p> </li> <li> <p>\u5c24\u5176\u5bf9\u6bd4 former \u7cfb\u7684\uff0cInformer\u3001Autoformer \u901a\u8fc7\u7a00\u758f\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5c06\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u5185\u5b58\u590d\u6742\u5ea6\u964d\u4f4e\u5230\u4e86 \\(\\mathcal{O}(L\\log {L})\\) </p> </li> <li> <p> </p> </li> <li> <p>\u7ea2\u8272\u7bad\u5934\u8868\u793a\u539f\u59cb\u5e8f\u5217\u7684\u4fe1\u606f\u4f20\u8f93</p> </li> <li>\u7ea2\u8272\u865a\u7ebf\u7bad\u5934\u8868\u793a\u77ed\u671f\u5468\u671f\u4fe1\u606f\u4f20\u8f93</li> <li>\u84dd\u8272\u7bad\u5934\u8868\u793a\u957f\u671f\u5468\u671f\u4fe1\u606f\u4f20\u8f93</li> <li>\u84dd\u8272\u865a\u7ebf\u7bad\u5934\u8868\u793a\u4ece\u6e90\u5230\u6c47\u7684\u4fe1\u606f\u4f20\u8f93</li> <li>\u865a\u7ebf\u8868\u793a\u6e90\u4fe1\u606f\u7684\u53ef\u8fbe\u8303\u56f4</li> <li>\u5b9e\u7ebf\u8868\u793a\u4fe1\u606f\u6ce2</li> </ul> <p></p> <p>\u56fe 2 \u63cf\u8ff0\u4e86\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u8f93\u5165\u91cd\u6392\u548c\u6c34\u6ce2\u4fe1\u606f\u4f20\u8f93\u8fc7\u7a0b\u3002\u8be5\u56fe\u5206\u4e3a\u4e24\u4e2a\u90e8\u5206\uff1a</p> <p>(a) \u8f93\u5165\u5e8f\u5217\u91cd\u6392\u524d\u540e\u7684\u4fe1\u606f\u4f20\u8f93</p> <ul> <li>\u5de6\u4fa7\u56fe\uff1a\u5c55\u793a\u4e86\u539f\u59cb\u5e8f\u5217\u7684\u4fe1\u606f\u4f20\u8f93\u3002\u56fe\u4e2d\u7528\u7ea2\u8272\u7bad\u5934\u8868\u793a\u539f\u59cb\u5e8f\u5217\u7684\u4fe1\u606f\u4f20\u8f93\uff0c\u7528\u7ea2\u8272\u865a\u7ebf\u7bad\u5934\u8868\u793a\u77ed\u671f\u5468\u671f\u4fe1\u606f\u4f20\u8f93\u3002 </li> <li>\u53f3\u4fa7\u56fe\uff1a\u5c55\u793a\u4e86\u8f93\u5165\u5e8f\u5217\u91cd\u6392\u540e\u7684\u4fe1\u606f\u4f20\u8f93\u3002\u56fe\u4e2d\u7528\u84dd\u8272\u7bad\u5934\u8868\u793a\u957f\u671f\u5468\u671f\u4fe1\u606f\u4f20\u8f93\uff0c\u7528\u84dd\u8272\u865a\u7ebf\u7bad\u5934\u8868\u793a\u4ece\u6e90\u5230\u6c47\u7684\u4fe1\u606f\u4f20\u8f93\u3002</li> <li>\u91cd\u6392\uff1a\u901a\u8fc7\u91cd\u6392\u8f93\u5165\u5e8f\u5217\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u6355\u83b7\u957f\u671f\u4fe1\u606f\uff0c\u4ece\u800c\u6539\u5584\u4fe1\u606f\u4f20\u8f93\u3002</li> </ul> <p>(b) \u6c34\u6ce2\u4fe1\u606f\u4f20\u8f93\u8fc7\u7a0b </p> <ul> <li>\u56fe\u793a\uff1a\u5c55\u793a\u4e86\u6c34\u6ce2\u4fe1\u606f\u4f20\u8f93\u7684\u6a21\u62df\u8fc7\u7a0b\u3002\u56fe\u4e2d\u7528\u5b9e\u7ebf\u8868\u793a\u4fe1\u606f\u6ce2\uff0c\u7528\u865a\u7ebf\u8868\u793a\u6e90\u4fe1\u606f\u7684\u53ef\u8fbe\u8303\u56f4\u3002</li> <li>\u8fc7\u7a0b\uff1a\u4fe1\u606f\u6ce2\u4ece\u6e90\u70b9\u5f00\u59cb\u4f20\u64ad\uff0c\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u4fe1\u606f\u6ce2\u9010\u6e10\u6269\u6563\u5e76\u8986\u76d6\u66f4\u5e7f\u7684\u8303\u56f4\u3002\u8fd9\u79cd\u6a21\u62df\u6709\u52a9\u4e8e\u7406\u89e3\u4fe1\u606f\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u4f20\u64ad\u548c\u6269\u6563\u8fc7\u7a0b\u3002</li> </ul> <p>\u56fe 2 \u8bf4\u660e\u4e86</p> <ul> <li>\u8f93\u5165\u91cd\u6392\u53ef\u4ee5\u6539\u5584\u4fe1\u606f\u4f20\u8f93\uff0c\u7279\u522b\u662f\u957f\u671f\u4fe1\u606f\u7684\u6355\u83b7\uff1b</li> <li>\u6c34\u6ce2\u4fe1\u606f\u4f20\u8f93\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u7406\u89e3\u4fe1\u606f\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u4f20\u64ad\u548c\u6269\u6563</li> </ul>"},{"location":"literature/TSP/12_WITRAN/#3-the-witran-model","title":"3 The WITRAN Model","text":"<p>The time series forecasting task involves predicting future values \\(Y \\in \\mathbb{R}^{P \\times c_{\\text{out}}}\\) for \\(P\\) time steps based on the historical input sequences \\(X = \\{x_1, x_2, \\ldots, x_H\\} \\in \\mathbb{R}^{H \\times c_{\\text{in}}}\\) of \\(H\\) time steps, where \\(c_{\\text{in}}\\) and \\(c_{\\text{out}}\\) represent the number of input and output features respectively.</p> <p>\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u6d89\u53ca\u57fa\u4e8e\u5386\u53f2\u8f93\u5165\u5e8f\u5217 \\(X = \\{x_1, x_2, \\ldots, x_H\\} \\in \\mathbb{R}^{H \\times c_{\\text{in}}}\\) \u9884\u6d4b\u672a\u6765 \\(P\\) \u4e2a\u65f6\u95f4\u6b65\u957f\u5185\u7684\u672a\u6765\u503c \\(Y \\in \\mathbb{R}^{P \\times c_{\\text{out}}}\\)\uff0c\u5176\u4e2d \\(c_{\\text{in}}\\) \u548c \\(c_{\\text{out}}\\) \u5206\u522b\u8868\u793a\u8f93\u5165\u548c\u8f93\u51fa\u7279\u5f81\u7684\u6570\u91cf\u3002</p> <p>In order to integrate enough historical information for analysis, it is necessary for \\(H\\) to have a sufficient size [Liu et al., 2021, Zeng et al., 2023]. Furthermore, capturing semantic information from the historical input is crucial for accurate forecasting, which includes modeling global and local correlations, as well as discovering long- and short-term repetitive patterns. </p> <p>\u4e3a\u4e86\u6574\u5408\u8db3\u591f\u7684\u5386\u53f2\u4fe1\u606f\u8fdb\u884c\u5206\u6790\uff0c\\(H\\) \u5fc5\u987b\u5177\u6709\u8db3\u591f\u7684\u5927\u5c0f [Liu et al., 2021, Zeng et al., 2023]\u3002\u6b64\u5916\uff0c\u4ece\u5386\u53f2\u8f93\u5165\u4e2d\u6355\u83b7\u8bed\u4e49\u4fe1\u606f\u5bf9\u4e8e\u51c6\u786e\u9884\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u5305\u62ec\u5efa\u6a21\u5168\u5c40\u548c\u5c40\u90e8\u76f8\u5173\u6027\u4ee5\u53ca\u53d1\u73b0\u957f\u671f\u548c\u77ed\u671f\u7684\u91cd\u590d\u6a21\u5f0f\u3002</p> <p>However, how to address them simultaneously is a major challenge. With these in mind, we propose WITRAN, a novel information transmission framework akin to the propagation of water waves. WITRAN captures both long- and short-term periodic semantic information, as well as global-local semantic information simultaneously during information transmission. Moreover, WITRAN reduces time complexity while maintaining linear memory complexity. The overall structure of WITRAN is depicted in Figure 3.</p> <p>\u7136\u800c\uff0c\u5982\u4f55\u540c\u65f6\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u662f\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\u3002\u57fa\u4e8e\u8fd9\u4e9b\u8003\u8651\uff0c\u6211\u4eec\u63d0\u51fa\u4e86WITRAN\uff0c\u8fd9\u662f\u4e00\u79cd\u7c7b\u4f3c\u4e8e\u6c34\u6ce2\u4f20\u64ad\u7684\u65b0\u578b\u4fe1\u606f\u4f20\u8f93\u6846\u67b6\u3002WITRAN\u5728\u4fe1\u606f\u4f20\u8f93\u8fc7\u7a0b\u4e2d\u540c\u65f6\u6355\u83b7\u957f\u671f\u548c\u77ed\u671f\u7684\u5468\u671f\u6027\u8bed\u4e49\u4fe1\u606f\uff0c\u4ee5\u53ca\u5168\u5c40-\u5c40\u90e8\u8bed\u4e49\u4fe1\u606f\u3002\u6b64\u5916\uff0cWITRAN\u5728\u4fdd\u6301\u7ebf\u6027\u5185\u5b58\u590d\u6742\u5ea6\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u65f6\u95f4\u590d\u6742\u5ea6\u3002WITRAN\u7684\u6574\u4f53\u7ed3\u6784\u5982\u56fe3\u6240\u793a\u3002</p> <ul> <li>\u77ed\u671f\u548c\u957f\u671f\u7684\u5468\u661f\u91cd\u590d\u6a21\u5f0f</li> <li>\u5185\u5b58\u590d\u6742\u5ea6\uff1a\u7ebf\u6027\uff1b\u65f6\u95f4\u590d\u6742\u5ea6 \\(\\sqrt{L}\\)</li> </ul> <p> </p>"},{"location":"literature/TSP/12_WITRAN/#31-input-module","title":"3.1 Input Module","text":"<p>To facilitate the analysis of long- and short-term repetitive patterns, inspired by TimesNet [Wu et al., 2023], we first rearrange the sequence from 1D to 2D based on its natural period, as illustrated by Figure 2(a).</p> <p>\u4e3a\u4e86\u4fbf\u4e8e\u5206\u6790\u957f\u671f\u548c\u77ed\u671f\u7684\u91cd\u590d\u6a21\u5f0f\uff0c\u53d7TimesNet [Wu et al., 2023] \u7684\u542f\u53d1\uff0c\u6211\u4eec\u9996\u5148\u6839\u636e\u5176\u81ea\u7136\u5468\u671f\u5c06\u5e8f\u5217\u4ece\u4e00\u7ef4\u91cd\u65b0\u6392\u5217\u4e3a\u4e8c\u7ef4\uff0c\u5982\u56fe2(a)\u6240\u793a\u3002</p> <p>Importantly, our approach involves analyzing the natural period of time series and setting appropriate hyperparameters to determine the input rearrangement, rather than using Fast Fourier Transform (FFT) to learn multiple adaptive periods of inputs in TimesNet. </p> <p>\u91cd\u8981\u7684\u662f\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u6d89\u53ca\u5206\u6790\u65f6\u95f4\u5e8f\u5217\u7684\u81ea\u7136\u5468\u671f\uff0c\u5e76\u8bbe\u7f6e\u9002\u5f53\u7684\u8d85\u53c2\u6570\u6765\u786e\u5b9a\u8f93\u5165\u7684\u91cd\u65b0\u6392\u5217\uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\u6765\u5b66\u4e60TimesNet\u4e2d\u8f93\u5165\u7684\u591a\u4e2a\u81ea\u9002\u5e94\u5468\u671f\u3002</p> <p>Consequently, our method is much simpler. Additionally, in order to minimize the distribution shift in datasets, we draw inspiration from NLinear [Zeng et al., 2023] and employ an adaptive learning approach to determine whether to perform simple normalization. </p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u7b80\u5355\u5f97\u591a\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u6700\u5c0f\u5316\u6570\u636e\u96c6\u4e2d\u7684\u5206\u5e03\u504f\u79fb\uff0c\u6211\u4eec\u4eceNLinear [Zeng et al., 2023] \u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u5b66\u4e60\u65b9\u6cd5\u6765\u51b3\u5b9a\u662f\u5426\u6267\u884c\u7b80\u5355\u7684\u5f52\u4e00\u5316\u3002</p> <p>The input module can be described as follows:</p> <p>\u203b \u8f93\u5165\u6a21\u5757\u53ef\u4ee5\u63cf\u8ff0\u5982\u4e0b\uff1a $$ X_{1D} = \\begin{cases}  X &amp; , \\text{norm} = 0 \\ X - x_H &amp; , \\text{norm} = 1  \\end{cases} $$</p> \\[ X_{2D} = \\text{Rearrange}([X_{1D}, TF_{en}]), \\] <p>\u7b26\u53f7\u8bf4\u660e</p> <ul> <li>\\(X_{1D} \\in \\mathbb{R}^{H \\times c_{\\text{in}}}\\) \u8868\u793a\u539f\u59cb\u8f93\u5165\u5e8f\u5217\\(x_H \\in \\mathbb{R}^{c_{\\text{in}}}\\) \u8868\u793a\u539f\u59cb\u5e8f\u5217\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165</li> <li>\\(TF_{en} \\in \\mathbb{R}^{H \\times c_{\\text{time}}}\\) \u8868\u793a\u539f\u59cb\u8f93\u5165\u5e8f\u5217\u7684\u65f6\u95f4\u4e0a\u4e0b\u6587\u7279\u5f81\uff08\u4f8b\u5982\uff0cHourOfDay\u3001DayOfWeek\u3001DayOfMonth \u548c DayOfYear\uff09\uff0c\u5176\u4e2d \\(c_{\\text{time}}\\) \u662f\u65f6\u95f4\u7279\u5f81\u7684\u7ef4\u5ea6\u3002</li> <li>\\(X_{2D} \\in \\mathbb{R}^{H \\times C \\times (c_{\\text{in}} + c_{\\text{time}})}\\) \u8868\u793a\u91cd\u65b0\u6392\u5217\u540e\u7684\u8f93\u5165</li> <li>\u5176\u4e2d \\(R\\) \u8868\u793a\u6c34\u5e73\u884c\u7684\u603b\u6570</li> <li>\\(C\\) \u8868\u793a\u5782\u76f4\u5217</li> <li>\\(\\text{norm}\\) \u662f\u4e0d\u540c\u4efb\u52a1\u7684\u81ea\u9002\u5e94\u53c2\u6570</li> <li>\\([\\cdot]\\) \u8868\u793a\u8fde\u63a5\u64cd\u4f5c</li> <li>\\(\\text{Rearrange}\\) \u8868\u793a\u91cd\u65b0\u6392\u5217\u64cd\u4f5c\uff0c\u53c2\u89c1\u56fe2(a)\u3002</li> </ul> <p>here, \\(X_{1D} \\in \\mathbb{R}^{H \\times c_{\\text{in}}}\\) represents the original input sequences, \\(x_H \\in \\mathbb{R}^{c_{\\text{in}}}\\) represents the input at the last time step of the original sequence, \\(TF_{en} \\in \\mathbb{R}^{H \\times c_{\\text{time}}}\\) represents the temporal contextual features of original input sequence (e.g., HourOfDay, DayOfWeek, DayOfMonth and DayOfYear), where \\(c_{\\text{time}}\\) is the dimension of time features. \\(X_{2D} \\in \\mathbb{R}^{H \\times C \\times (c_{\\text{in}} + c_{\\text{time}})}\\) represents the inputs after rearrangement, where \\(R\\) denotes the total number of horizontal rows and \\(C\\) denotes the vertical columns. \\(\\text{norm}\\) is an adaptive parameter for different tasks. \\([\\cdot]\\) represents the concat operation and \\(\\text{Rearrange}\\) represents the rearrange operation, with reference to Figure 2(a).</p>"},{"location":"literature/TSP/12_WITRAN/#32-horizontal-vertical-gated-selective-unit","title":"3.2 Horizontal Vertical Gated Selective Unit","text":"<p>To capture long- and short-term periodic semantic information and reserve their characteristics, we propose a novel Horizontal Vertical Gated Selective Unit (HVGSU) which consists of Gated Selective Cells (GSCs) in two directions. </p> <p>\u4e3a\u4e86\u6355\u83b7\u957f\u671f\u548c\u77ed\u671f\u7684\u5468\u671f\u6027\u8bed\u4e49\u4fe1\u606f\u5e76\u4fdd\u7559\u5176\u7279\u5f81\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u6c34\u5e73\u5782\u76f4\u95e8\u63a7\u9009\u62e9\u5355\u5143\uff08HVGSU\uff09\uff0c\u5b83\u7531\u4e24\u4e2a\u65b9\u5411\u4e0a\u7684\u95e8\u63a7\u9009\u62e9\u5355\u5143\uff08GSCs\uff09\u7ec4\u6210\u3002</p> <p>To capture the correlation at each time step between periodic semantic information of both directions, we design the specific operations in GSC. </p> <p>\u4e3a\u4e86\u6355\u83b7\u4e24\u4e2a\u65b9\u5411\u4e0a\u5468\u671f\u6027\u8bed\u4e49\u4fe1\u606f\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u5173\u8054\uff0c\u6211\u4eec\u5728GSC\u4e2d\u8bbe\u8ba1\u4e86\u7279\u5b9a\u7684\u64cd\u4f5c\u3002</p> <p>Furthermore, HVGSU is capable of capturing both global and local information via a recurrent structure. In this subsection, we will provide a detailed introduction to them.</p> <p>\u6b64\u5916\uff0cHVGSU\u80fd\u591f\u901a\u8fc7\u9012\u5f52\u7ed3\u6784\u6355\u83b7\u5168\u5c40\u548c\u5c40\u90e8\u4fe1\u606f\u3002\u5728\u672c\u5c0f\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u8be6\u7ec6\u4ecb\u7ecd\u5b83\u4eec\u3002</p> <p>HVGSU As depicted in Figure 3, the process of HVGSU via a recurrent structure is:</p> <p>HVGSU \u5982\u56fe3\u6240\u793a\uff0c\u901a\u8fc7\u9012\u5f52\u7ed3\u6784\u7684HVGSU\u8fc7\u7a0b\u662f\uff1a $$ H_{\\text{hor}}, H_{\\text{ver}}, \\text{Out} = \\text{HVGSU}(X_{2D}), $$ where \\(H_{\\text{hor}} \\in \\mathbb{R}^{L \\times R \\times d_{\\text{model}}}\\) and \\(H_{\\text{ver}} \\in \\mathbb{R}^{L \\times C \\times d_{\\text{model}}}\\) represent the horizontal and the vertical output hidden state of HVGSU separately. \\(L\\) is the depth of the model, and \\(\\text{Out} \\in \\mathbb{R}^{R \\times C \\times d_{\\text{model}}}\\) denotes the output information of the last layer.</p> <ul> <li>\u5176\u4e2d \\(H_{\\text{hor}} \\in \\mathbb{R}^{L \\times R \\times d_{\\text{model}}}\\) \\(H_{\\text{ver}} \\in \\mathbb{R}^{L \\times C \\times d_{\\text{model}}}\\) \u5206\u522b\u8868\u793aHVGSU\u7684\u6c34\u5e73\u548c\u5782\u76f4\u8f93\u51fa\u9690\u85cf\u72b6\u6001\u3002</li> <li>\\(L\\) \u662f\u6a21\u578b\u7684\u6df1\u5ea6</li> <li>\\(\\text{Out} \\in \\mathbb{R}^{R \\times C \\times d_{\\text{model}}}\\) \u8868\u793a\u6700\u540e\u4e00\u5c42\u7684\u8f93\u51fa\u4fe1\u606f\u3002</li> </ul> <p>In greater detail, the cellular structure of HVGSU is shown in Figure 4(b), which consists of GSCs in two directions to capture the periodic semantic information of long- and short-term. The cell operations for row \\(r\\) (\\(1 \\leq r \\leq R\\)) and column \\(c\\) (\\(1 \\leq c \\leq C\\)) in layer \\(l\\) (\\(1 \\leq l \\leq L\\)) can be formalized as:</p> <p>\u66f4\u8be6\u7ec6\u5730\u8bf4\uff0cHVGSU\u7684\u7ec6\u80de\u7ed3\u6784\u5982\u56fe4(b)\u6240\u793a\uff0c\u5b83\u7531\u4e24\u4e2a\u65b9\u5411\u4e0a\u7684GSC\u7ec4\u6210\uff0c\u4ee5\u6355\u83b7\u957f\u671f\u548c\u77ed\u671f\u7684\u5468\u671f\u6027\u8bed\u4e49\u4fe1\u606f\u3002\u5bf9\u4e8e\u5c42\\(l\\)\uff08\\(1 \\leq l \\leq L\\)\uff09\u4e2d\u7684\u884c\\(r\\)\uff08\\(1 \\leq r \\leq R\\)\uff09\u548c\u5217\\(c\\)\uff08\\(1 \\leq c \\leq C\\)\uff09\u7684\u5355\u5143\u64cd\u4f5c\u53ef\u4ee5\u5f62\u5f0f\u5316\u4e3a\uff1a $$ h_{r,c,l}^{\\text{hor}} = \\text{GSC}{\\text{hor}}(\\text{input}_r, c, l, h) $$}^{\\text{hor}}, h_{r-1,c,l}^{\\text{ver}</p> \\[ h_{r,c,l}^{\\text{ver}} = \\text{GSC}_{\\text{ver}}(\\text{input}_r, c, l, h_{r-1,c,l}^{\\text{ver}}, h_{r,c-1,l}^{\\text{hor}}) \\] \\[ o_{r,c,l} = [h_{r,c,l}^{\\text{hor}}, h_{r,c,l}^{\\text{ver}}] \\] <ul> <li> <p>\u8fd9\u91cc\uff0c\\(\\text{input}_r, c, l \\in \\mathbb{R}^{d_{\\text{in}}}\\)\u3002</p> </li> <li> <p>\u5f53\\(l = 1\\)\u65f6\uff0c\\(\\text{input}_r, c, l = x_r, c \\in \\mathbb{R}^{c_{\\text{in}} + c_{\\text{time}}}\\)\u8868\u793a\u7b2c\u4e00\u5c42\u7684\u8f93\u5165</p> </li> <li> <p>\u5f53\\(l &gt; 1\\)\u65f6\uff0c\\(\\text{input}_r, c, l = o_r, c, l-1 \\in \\mathbb{R}^{2 \\times d_{\\text{model}}}\\)\u8868\u793a\u540e\u7eed\u5c42\u7684\u8f93\u5165</p> </li> <li>\\(h_{r,c-1,l}^{\\text{hor}}\\) \u548c \\(h_{r-1,c,l}^{\\text{ver}} \\in \\mathbb{R}^{d_{\\text{model}}}\\) \u5206\u522b\u8868\u793a\u5f53\u524d\u5355\u5143\u7684\u6c34\u5e73\u548c\u5782\u76f4\u9690\u85cf\u72b6\u6001\u8f93\u5165\u3002</li> <li>\u6ce8\u610f\uff0c\u5f53\\(r = 1\\)\u65f6\uff0c\\(h_{r-1,c,l}^{\\text{ver}}\\)\u88ab\u66ff\u6362\u4e3a\u76f8\u540c\u5927\u5c0f\u7684\u5168\u96f6\u5f20\u91cf</li> <li>\u5f53\\(c = 1\\)\u65f6\uff0c\\(h_{r,c-1,l}^{\\text{hor}}\\)\u4e5f\u662f\u5982\u6b64</li> <li>\\([\\cdot]\\)\u8868\u793a\u8fde\u63a5\u64cd\u4f5c</li> <li>\\(o_{r,c,l} \\in \\mathbb{R}^{2 \\times d_{\\text{model}}}\\)\u8868\u793a\u5f53\u524d\u5355\u5143\u7684\u8f93\u51fa\u3002</li> </ul> <p>here, \\(\\text{input}_r, c, l \\in \\mathbb{R}^{d_{\\text{in}}}\\). When \\(l = 1\\), \\(\\text{input}_r, c, l = x_r, c \\in \\mathbb{R}^{c_{\\text{in}} + c_{\\text{time}}}\\) represents the input for the first layer, and when \\(l &gt; 1\\), \\(\\text{input}_r, c, l = o_r, c, l-1 \\in \\mathbb{R}^{2 \\times d_{\\text{model}}}\\) represents the input for subsequent layers. \\(h_{r,c-1,l}^{\\text{hor}}\\) and \\(h_{r-1,c,l}^{\\text{ver}} \\in \\mathbb{R}^{d_{\\text{model}}}\\) represent the horizontal and vertical hidden state inputs of the current cell. Note that when \\(r = 1\\), \\(h_{r-1,c,l}^{\\text{ver}}\\) is replaced by an all-zero tensor of the same size, and the same is true for \\(h_{r,c-1,l}^{\\text{hor}}\\) when \\(c = 1\\). \\([\\cdot]\\) represents the concat operation and \\(o_{r,c,l} \\in \\mathbb{R}^{2 \\times d_{\\text{model}}}\\) represents the output of the current cell.</p> <p></p> <p>GSC Inspired by the two popular RNN-based models, LSTM [Hochreiter and Schmidhuber, 1997] and GRU [Chung et al., 2014] (for more details, see Appendix A), we propose a Gated Selective Cell (GSC) to fuse and select information. </p> <p>\u95e8\u63a7\u9009\u62e9\u5355\u5143\uff08GSC\uff09 \u53d7\u4e24\u4e2a\u6d41\u884c\u7684\u57fa\u4e8e\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u7684\u6a21\u578b\u2014\u2014\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09[Hochreiter \u548c Schmidhuber, 1997] \u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09[Chung \u7b49, 2014]\uff08\u66f4\u591a\u7ec6\u8282\u89c1\u9644\u5f55A\uff09\u7684\u542f\u53d1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u95e8\u63a7\u9009\u62e9\u5355\u5143\uff08GSC\uff09\u6765\u878d\u5408\u548c\u9009\u62e9\u4fe1\u606f\u3002</p> <p>Its structure is shown in Figure 4(a), which comprises two gates: the selection gate, and the output gate. The fused information consists of input and principal-subordinate hidden states, and the selection gate determines the retention of the original principal information and the addition of the fused information. Finally, the output gate determines the final output information of the cell.</p> <p>\u5176\u7ed3\u6784\u5982\u56fe4(a)\u6240\u793a\uff0c\u5305\u62ec\u4e24\u4e2a\u95e8\uff1a\u9009\u62e9\u95e8\u548c\u8f93\u51fa\u95e8\u3002\u878d\u5408\u7684\u4fe1\u606f\u7531\u8f93\u5165\u548c\u4e3b\u4ece\u9690\u85cf\u72b6\u6001\u7ec4\u6210\uff0c\u9009\u62e9\u95e8\u51b3\u5b9a\u4e86\u539f\u59cb\u4e3b\u4fe1\u606f\u7684\u4fdd\u7559\u548c\u878d\u5408\u4fe1\u606f\u7684\u6dfb\u52a0\u3002\u6700\u540e\uff0c\u8f93\u51fa\u95e8\u51b3\u5b9a\u4e86\u5355\u5143\u7684\u6700\u7ec8\u8f93\u51fa\u4fe1\u606f\u3002</p> <p>The different colored arrows in Figure 4(a) represent different semantic information transfer processes. The black arrow represents the input, the red arrows represent the process of transmitting principal hidden state information, the blue arrow represents the subordinate hidden state, and the purple arrows represent the process by which fused information of principal-subordinate hidden states is transmitted. The formulations are given as follows:</p> <p>\u56fe4(a)\u4e2d\u4e0d\u540c\u989c\u8272\u7684\u7bad\u5934\u4ee3\u8868\u4e0d\u540c\u7684\u8bed\u4e49\u4fe1\u606f\u4f20\u9012\u8fc7\u7a0b\u3002\u9ed1\u8272\u7bad\u5934\u4ee3\u8868\u8f93\u5165\uff0c\u7ea2\u8272\u7bad\u5934\u4ee3\u8868\u4e3b\u9690\u85cf\u72b6\u6001\u4fe1\u606f\u4f20\u9012\u7684\u8fc7\u7a0b\uff0c\u84dd\u8272\u7bad\u5934\u4ee3\u8868\u4ece\u9690\u85cf\u72b6\u6001\uff0c\u7d2b\u8272\u7bad\u5934\u4ee3\u8868\u4e3b\u4ece\u9690\u85cf\u72b6\u6001\u878d\u5408\u4fe1\u606f\u4f20\u9012\u7684\u8fc7\u7a0b\u3002\u516c\u5f0f\u5982\u4e0b\u6240\u793a\uff1a</p> \\[ S_t = \\sigma(W_s[h_{t-1}^{\\text{pri}}, h_{t-1}^{\\text{sub}}, x] + b_s) \\] \\[ O_t = \\sigma(W_o[h_{t-1}^{\\text{pri}}, h_{t-1}^{\\text{sub}}, x] + b_o) \\] \\[ h_f = \\tanh(W_f[h_{t-1}^{\\text{pri}}, h_{t-1}^{\\text{sub}}, x] + b_f) \\] \\[ \\widetilde{h_{t-1}^{\\text{pri}}} = (1 - S_t) \\odot h_{t-1}^{\\text{pri}} + S_t \\odot h_f \\] \\[ h_t^{\\text{pri}} = \\tanh(\\widetilde{h_{t-1}^{\\text{pri}}}) \\odot O_t, \\] <p>where \\(h_{t-1}^{\\text{pri}}\\) and \\(h_{t-1}^{\\text{sub}} \\in \\mathbb{R}^{d_{\\text{model}}}\\) represent the input principal and subordinate hidden state, \\(x \\in \\mathbb{R}^{d_{\\text{in}}}\\) represents the input.</p> <p>\u5176\u4e2d \\(h_{t-1}^{\\text{pri}}\\) \u548c \\(h_{t-1}^{\\text{sub}} \\in \\mathbb{R}^{d_{\\text{model}}}\\) \u5206\u522b\u8868\u793a\u8f93\u5165\u7684\u4e3b\u9690\u85cf\u72b6\u6001\u548c\u4ece\u9690\u85cf\u72b6\u6001\uff0c\\(x \\in \\mathbb{R}^{d_{\\text{in}}}\\) \u8868\u793a\u8f93\u5165\u3002</p> <p>\\(W_* \\in \\mathbb{R}^{d_{\\text{model}} \\times (2d_{\\text{model}} + d_{\\text{in}})}\\) are weight matrices and \\(b_* \\in \\mathbb{R}^{d_{\\text{model}}}\\) are bias vectors.</p> <p>\\(W_* \\in \\mathbb{R}^{d_{\\text{model}} \\times (2d_{\\text{model}} + d_{\\text{in}})}\\) \u662f\u6743\u91cd\u77e9\u9635\uff0c\\(b_* \\in \\mathbb{R}^{d_{\\text{model}}}\\) \u662f\u504f\u7f6e\u5411\u91cf\u3002</p> <p>\\(S_t\\) and \\(O_t\\) denote the selection gate and the output gate, \\(\\odot\\) denotes an element-wise product, \\(\\sigma(\\cdot)\\) and \\(\\tanh(\\cdot)\\) denote the sigmoid and tanh activation function.</p> <p>\\(S_t\\) \u548c \\(O_t\\) \u5206\u522b\u8868\u793a\u9009\u62e9\u95e8\u548c\u8f93\u51fa\u95e8\uff0c\\(\\odot\\) \u8868\u793a\u5143\u7d20\u7ea7\u4e58\u79ef\uff0c\\(\\sigma(\\cdot)\\) \u548c \\(\\tanh(\\cdot)\\) \u5206\u522b\u8868\u793asigmoid\u548ctanh\u6fc0\u6d3b\u51fd\u6570\u3002</p> <p>\\(h_f\\) and \\(\\widetilde{h_{t-1}^{\\text{pri}}} \\in \\mathbb{R}^{d_{\\text{model}}}\\) represent the intermediate variables of the calculation. \\(h_t^{\\text{pri}}\\) represents the output hidden state.</p> <p>\\(h_f\\) \u548c \\(\\widetilde{h_{t-1}^{\\text{pri}}} \\in \\mathbb{R}^{d_{\\text{model}}}\\) \u8868\u793a\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u7684\u4e2d\u95f4\u53d8\u91cf\u3002\\(h_t^{\\text{pri}}\\) \u8868\u793a\u8f93\u51fa\u9690\u85cf\u72b6\u6001\u3002</p>"},{"location":"literature/TSP/12_WITRAN/#33-recurrent-acceleration-network","title":"3.3 Recurrent Acceleration Network","text":"<p>In traditional recurrent structure, for two adjacent time steps in series, the latter one always waits for the former one until the information computation of the former one is completed. When the sequence becomes longer, this becomes slower. </p> <p>\u5728\u4f20\u7edf\u7684\u9012\u5f52\u7ed3\u6784\u4e2d\uff0c\u5bf9\u4e8e\u5e8f\u5217\u4e2d\u7684\u4e24\u4e2a\u76f8\u90bb\u65f6\u95f4\u6b65\uff0c\u540e\u8005\u603b\u662f\u8981\u7b49\u5f85\u524d\u8005\u5b8c\u6210\u4fe1\u606f\u8ba1\u7b97\u3002\u5f53\u5e8f\u5217\u53d8\u957f\u65f6\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u901f\u5ea6\u53d8\u6162\u3002</p> <p>Fortunately, in the WIT framework we designed, some of the time step information can be computed in parallel. </p> <p>\u5e78\u8fd0\u7684\u662f\uff0c\u5728\u6211\u4eec\u8bbe\u8ba1\u7684\u6c34\u6ce2\u4fe1\u606f\u4f20\u8f93\uff08WIT\uff09\u6846\u67b6\u4e2d\uff0c\u90e8\u5206\u65f6\u95f4\u6b65\u4fe1\u606f\u53ef\u4ee5\u5e76\u884c\u8ba1\u7b97\u3002</p> <p>As shown in Figure 2(b), after a point is calculated, the right point in its horizontal direction and the point below it in its vertical direction can start calculation without waiting for each other. </p> <p>\u5982\u56fe2(b)\u6240\u793a\uff0c\u5728\u8ba1\u7b97\u51fa\u4e00\u4e2a\u70b9\u4e4b\u540e\uff0c\u5176\u6c34\u5e73\u65b9\u5411\u4e0a\u7684\u53f3\u4fa7\u70b9\u548c\u5782\u76f4\u65b9\u5411\u4e0a\u7684\u4e0b\u65b9\u70b9\u53ef\u4ee5\u5f00\u59cb\u8ba1\u7b97\u800c\u65e0\u9700\u7b49\u5f85\u5f7c\u6b64\u3002</p> <p>Therefore, we propose the Recurrent Acceleration Network (RAN) as our accelerated framework, which enables parallel computation of data points without waiting for each other, greatly improving the efficiency of information transmission in HVGSU. </p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u9012\u5f52\u52a0\u901f\u7f51\u7edc\uff08RAN\uff09\u4f5c\u4e3a\u6211\u4eec\u7684\u52a0\u901f\u6846\u67b6\uff0c\u5b83\u80fd\u591f\u5728\u4e0d\u7b49\u5f85\u5f7c\u6b64\u7684\u60c5\u51b5\u4e0b\u5e76\u884c\u8ba1\u7b97\u6570\u636e\u70b9\uff0c\u4ece\u800c\u5927\u5927\u63d0\u9ad8\u4e86HVGSU\u4e2d\u4fe1\u606f\u4f20\u8f93\u7684\u6548\u7387\u3002</p> <p>We place parallelizable points in a slice, and the updated information transfer process is shown in Figure 4(c). Each green box in Figure 4(c) represents a slice, and the number of green boxes is the number of times we need to recursively compute. </p> <p>\u6211\u4eec\u5c06\u53ef\u5e76\u884c\u5316\u7684\u70b9\u653e\u7f6e\u5728\u4e00\u4e2a\u5207\u7247\u4e2d\uff0c\u66f4\u65b0\u7684\u4fe1\u606f\u4f20\u8f93\u8fc7\u7a0b\u5982\u56fe4(c)\u6240\u793a\u3002\u56fe4(c)\u4e2d\u7684\u6bcf\u4e2a\u7eff\u8272\u6846\u4ee3\u8868\u4e00\u4e2a\u5207\u7247\uff0c\u7eff\u8272\u6846\u7684\u6570\u91cf\u662f\u6211\u4eec\u9012\u5f52\u8ba1\u7b97\u6240\u9700\u7684\u6b21\u6570\u3002</p> <p>The meanings of the remaining markers are the same as those in Figure 2. Under the RAN framework, the recurrent length has changed from the sequence length \\(L = R \\times C\\) to \\(R + C - 1\\), while the complexity of \\(R\\) and \\(C\\) is \\(O(\\sqrt{L})\\). </p> <p>\u5269\u4f59\u6807\u8bb0\u7684\u542b\u4e49\u4e0e\u56fe2\u4e2d\u7684\u76f8\u540c\u3002\u5728RAN\u6846\u67b6\u4e0b\uff0c\u9012\u5f52\u957f\u5ea6\u4ece\u5e8f\u5217\u957f\u5ea6 \\(L = R \\times C\\) \u53d8\u4e3a \\(R + C - 1\\)\uff0c\u800c \\(R\\) \u548c \\(C\\) \u7684\u590d\u6742\u5ea6\u4e3a \\(O(\\sqrt{L})\\)\u3002</p> <p>Thus, we have reduced the time complexity to \\(O(\\sqrt{L})\\) via the RAN framework. It should be noted that although we parallelly compute some data points, which may increase some memory, the complexity of parallel computation, \\(O(\\sqrt{L})\\), is far less than the complexity of saving the output variables, \\(O(L)\\), because we need to save the output information of each point in the sequence. Implementation source code for RAN is given in Appendix D.</p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u901a\u8fc7RAN\u6846\u67b6\u5c06\u65f6\u95f4\u590d\u6742\u5ea6\u964d\u4f4e\u5230 \\(O(\\sqrt{L})\\)\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5c3d\u7ba1\u6211\u4eec\u5e76\u884c\u8ba1\u7b97\u4e86\u4e00\u4e9b\u6570\u636e\u70b9\uff0c\u8fd9\u53ef\u80fd\u4f1a\u589e\u52a0\u4e00\u4e9b\u5185\u5b58\uff0c\u4f46\u5e76\u884c\u8ba1\u7b97\u7684\u590d\u6742\u5ea6 \\(O(\\sqrt{L})\\) \u8fdc\u5c0f\u4e8e\u4fdd\u5b58\u8f93\u51fa\u53d8\u91cf\u7684\u590d\u6742\u5ea6 \\(O(L)\\)\uff0c\u56e0\u4e3a\u6211\u4eec\u9700\u8981\u4fdd\u5b58\u5e8f\u5217\u4e2d\u6bcf\u4e2a\u70b9\u7684\u8f93\u51fa\u4fe1\u606f\u3002RAN\u7684\u5b9e\u73b0\u6e90\u4ee3\u7801\u5728\u9644\u5f55D\u4e2d\u7ed9\u51fa\u3002</p>"},{"location":"literature/TSP/12_WITRAN/#34-forecasting-module","title":"3.4 Forecasting Module","text":"<p>In the forecasting module, we address the issue of error accumulation in the auto-regressive structure by drawing inspiration from Informer [Zhou et al., 2021] and Pyraformer [Liu et al., 2021], combining both horizontal and vertical hidden states, and then making predictions through a fully connected layer, as illustrated in Figure 3.</p> <p>\u5728\u9884\u6d4b\u6a21\u5757\u4e2d\uff0c\u6211\u4eec\u501f\u9274\u4e86Informer [Zhou et al., 2021] \u548c Pyraformer [Liu et al., 2021] \u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6c34\u5e73\u548c\u5782\u76f4\u9690\u85cf\u72b6\u6001\u6765\u89e3\u51b3\u81ea\u56de\u5f52\u7ed3\u6784\u4e2d\u7684\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\uff0c\u7136\u540e\u901a\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u9884\u6d4b\uff0c\u5982\u56fe3\u6240\u793a\u3002</p> <p>We utilize the last row of the horizontal hidden states as it contains sufficient global and latest shortterm semantic information from the historical sequence. </p> <p>\u6211\u4eec\u5229\u7528\u6c34\u5e73\u9690\u85cf\u72b6\u6001\u7684\u6700\u540e\u4e00\u884c\uff0c\u56e0\u4e3a\u5b83\u5305\u542b\u4e86\u6765\u81ea\u5386\u53f2\u5e8f\u5217\u7684\u5145\u8db3\u5168\u5c40\u548c\u6700\u65b0\u77ed\u671f\u8bed\u4e49\u4fe1\u606f\u3002</p> <p>In contrast, all columns of the vertical hidden states, which capture different long-term semantic information, are all preserved. </p> <p>\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5782\u76f4\u9690\u85cf\u72b6\u6001\u7684\u6240\u6709\u5217\u90fd\u6355\u83b7\u4e86\u4e0d\u540c\u7684\u957f\u671f\u8bed\u4e49\u4fe1\u606f\uff0c\u56e0\u6b64\u90fd\u88ab\u4fdd\u7559\u3002</p> <p>The combined operation not only maximizes the retention of the various semantic information needed for predicting the points, but also avoids excessive redundancy in order to obtain accurate predictions. This module can be formalized as follows:</p> <p>\u8fd9\u79cd\u7ec4\u5408\u64cd\u4f5c\u4e0d\u4ec5\u6700\u5927\u5316\u4e86\u4fdd\u7559\u9884\u6d4b\u70b9\u6240\u9700\u7684\u5404\u79cd\u8bed\u4e49\u4fe1\u606f\uff0c\u8fd8\u907f\u514d\u4e86\u8fc7\u5ea6\u5197\u4f59\uff0c\u4ee5\u83b7\u5f97\u51c6\u786e\u7684\u9884\u6d4b\u3002\u8be5\u6a21\u5757\u53ef\u4ee5\u516c\u5f0f\u5316\u8868\u793a\u5982\u4e0b\uff1a $$ H_{\\text{hor}}^{\\text{rep}} = \\text{Repeat}(h_{\\text{hor}}) $$</p> \\[ H_{h-v} = \\text{Reshape}([H_{\\text{hor}}^{\\text{rep}}, H_{\\text{ver}}]) \\] \\[ \\hat{Y} = \\text{FC1}(H_{h-v}) \\] \\[ Y = \\text{FC2}(\\text{Reshape}(\\hat{Y}) + TFE_{\\text{de}}) \\] <ul> <li> <p>where \\(TFE_{\\text{de}} \\in \\mathbb{R}^{P \\times C \\times d_{\\text{model}}}\\) represents time features encoding of the forecasting points separately.</p> </li> <li> <p>\\(TFE_{\\text{de}} \\in \\mathbb{R}^{P \\times C \\times d_{\\text{model}}}\\) \u8868\u793a\u5206\u522b\u5bf9\u9884\u6d4b\u70b9\u8fdb\u884c\u65f6\u95f4\u7279\u5f81\u7f16\u7801\u3002</p> </li> <li> <p>\\(h_{\\text{hor}} \\in \\mathbb{R}^{L \\times 1 \\times d_{\\text{model}}}\\) represents the last row hidden state in \\(H_{\\text{hor}}\\). </p> </li> <li>\\(h_{\\text{hor}} \\in \\mathbb{R}^{L \\times 1 \\times d_{\\text{model}}}\\) \u8868\u793a \\(H_{\\text{hor}}\\) \u4e2d\u7684\u6700\u540e\u4e00\u884c\u9690\u85cf\u72b6\u6001\u3002</li> <li>Repeat(\u00b7) is for repeat operation and Reshape(\u00b7) is for reshape operation. FC1 and FC2 represent two fully connected layers respectively. </li> <li>Repeat(\u00b7) \u662f\u91cd\u590d\u64cd\u4f5c\uff0cReshape(\u00b7) \u662f\u91cd\u5851\u64cd\u4f5c\u3002FC1 \u548c FC2 \u5206\u522b\u8868\u793a\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u3002</li> <li>\\(\\hat{Y} \\in \\mathbb{R}^{C \\times (R_{\\text{de}} \\times d_{\\text{model}})}\\) represents the intermediate variables of the calculation and \\(R_{\\text{de}} \\times C = P\\).</li> <li>\\(\\hat{Y} \\in \\mathbb{R}^{C \\times (R_{\\text{de}} \\times d_{\\text{model}})}\\) \u8868\u793a\u8ba1\u7b97\u7684\u4e2d\u95f4\u53d8\u91cf\uff0c\u4e14 \\(R_{\\text{de}} \\times C = P\\)\u3002</li> <li>\\(Y\\) represents the output of this module, and it is worth noting that we need to utilize the adaptive parameter \\(norm\\) for denormalization, when \\(norm = 1\\), \\(Y = Y + x_H\\).</li> <li>\\(Y\\) \u8868\u793a\u8be5\u6a21\u5757\u7684\u8f93\u51fa\uff0c\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u4eec\u9700\u8981\u5229\u7528\u81ea\u9002\u5e94\u53c2\u6570 \\(norm\\) \u8fdb\u884c\u53cd\u5f52\u4e00\u5316\uff0c\u5f53 \\(norm = 1\\) \u65f6\uff0c\\(Y = Y + x_H\\)\u3002</li> </ul>"},{"location":"literature/TSP/12_WITRAN/#_2","title":"\u8bba\u6587\u7814\u8bfb","text":"<p>\u53c2\u770b\u94fe\u63a5\uff1a\u8bba\u6587\u7814\u8bfb\u4e4b\u957f\u7a0b\u65f6\u5e8f\u9884\u6d4b\uff1a\u6c34\u6ce2\u7eb9\u4fe1\u606f\u4f20\u8f93WIT\u548c\u5faa\u73af\u52a0\u901f\u7f51\u7edcRAN</p> <p>\u95ee\u9898\u63cf\u8ff0\uff1a</p> <ul> <li>\u7cbe\u51c6\u7684\u8fdc\u7a0b\u548c\u8d85\u8fdc\u7a0b\u65f6\u5e8f\u9884\u6d4b\uff1a\u4f7f\u7528\u66f4\u957f\u7684\u5386\u53f2\u5e8f\u5217\u4f5c\u4e3a\u8f93\u5165</li> <li>\u6355\u83b7\u8bed\u4e49\u4fe1\u606f</li> <li>\u8003\u8651\u5efa\u6a21\u6548\u7387</li> </ul> <p></p> <p></p>"},{"location":"literature/TSP/13_TFB/","title":"TFB","text":""},{"location":"literature/TSP/13_TFB/#tfb","title":"TFB","text":"2025-04-15 17:02:482025-09-28 12:54:06 <p> \u7ea6 714 \u4e2a\u5b57  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p> <p>TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods</p> <p>\uff08CCF A\u7c7b\u4f1a\u8bae VLDB2024 \u6700\u4f73\u7814\u7a76\u8bba\u6587\u5956\u63d0\u540d\uff09</p> <p>\u4f5c\u8005\uff1a23 \u7ea7\u534e\u4e1c\u5e08\u8303\u5927\u5b66\u7814\u7a76\u751f</p> <p>International Conference on Very Large Data Bases\uff08\u6570\u636e\u5e93\u4e09\u5927\u9876\u4f1a\u4e4b\u4e00\uff1aVLDB\u3001SIGMOD\u3001ICDE\uff09</p> <p>\u4f5c\u8005\u7ed9\u51fa\u7684\u4e2d\u6587\u7248\u89e3\u8bfb\uff1ahttps://zhuanlan.zhihu.com/p/695413738</p> <p>\u539f\u6587\uff1ahttps://www.vldb.org/pvldb/vol17/p2363-hu.pdf </p> <p>\u6e90\u7801\uff1ahttps://github.com/decisionintelligence/TFB</p> <p>\u4e3b\u9875\uff1ahttps://decisionintelligence.github.io/OpenTS/</p> <p>\u89c6\u9891\u8bb2\u89e3\uff1a\u8bba\u6587\u7814\u8bfb\u4e4b\u65f6\u5e8f\u9884\u6d4b\u57fa\u51c6TFB</p> <p>\u540c\u56e2\u961f\u6587\u7ae0 FOUNDTS\uff1ahttps://arxiv.org/pdf/2410.11802</p> <p>\u672c\u6587\u5173\u952e\u8bcd\uff1a</p> <ul> <li>\u76ee\u7684\uff1abenchmark</li> <li>8,068 time series \uff0c25 multivariate time series</li> <li>Statistical Learning (SL)\u3001Machine Learning(ML)\u3001Deep Learning (DL)\u3001</li> </ul> <p>\u6d89\u53ca\u4e0d\u540c\u7684\u5e74\u5468\u671f\u3001\u6708\u5468\u671f\uff0c\u5177\u6709\u4e0d\u540c\u7684\u8d8b\u52bf</p> <p>\u6d4b\u8bc4\u4e86\u4f20\u7edf\u65f6\u5e8f\u65b9\u6cd5\u3001\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3001\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08\u4f1a\u5f15\u51fa\u4e00\u4e2a\u601d\u8003\uff0c\u590d\u6742\u7684\u5c31\u662f\u597d\u5417</p> <p>\u5b9e\u9a8c\u7ed3\u8bba\uff1a</p> <p>\u4f5c\u8005\u5bf9TFB\u4e2d\u5305\u542b\u7684\u6240\u6709\u6570\u636e\u96c6\uff0c\u5305\u62ec25\u4e2a\u591a\u53d8\u91cf\u6570\u636e\u96c6\u548c8,068\u4e2a\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\uff0c\u4ee5\u53ca\u524d\u6587\u63d0\u5230\u7684\u6240\u6709baseline\u65b9\u6cd5\uff0c\u8fdb\u884c\u7ec6\u81f4\u7684\u5b9e\u9a8c\u5206\u6790\uff0c\u9650\u4e8e\u7bc7\u5e45\u4e0d\u5728\u5c55\u793a\u3002\u6211\u6bd4\u8f83\u5173\u5fc3\u7684\u4e00\u4e9b\u7ed3\u8bba\uff1a</p> <ul> <li>**\u7ebf\u6027\u6a21\u578b**\u5728\u6570\u636e\u96c6==\u5448\u589e\u957f\u8d8b\u52bf\u6216\u5177\u6709\u663e\u8457\u6f02\u79fb==\u65f6\u8868\u73b0\u51fa\u8272\u3002\u8fd9\u53ef\u4ee5\u5f52\u56e0\u4e8e\u7ebf\u6027\u6a21\u578b\u7684\u7ebf\u6027\u5efa\u6a21\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u5f88\u597d\u5730\u6355\u6349\u7ebf\u6027\u8d8b\u52bf\u548c\u6f02\u79fb\u3002</li> <li>Transformer\u65b9\u6cd5 \u5728\u5c55\u73b0\u660e\u663e==\u5b63\u8282\u6027\u3001\u5e73\u7a33\u6027\u548c\u975e\u7ebf\u6027\u6a21\u5f0f==\uff0c\u4ee5\u53ca\u66f4\u660e\u663e\u6a21\u5f0f\u6216\u5185\u5728\u76f8\u4f3c\u6027\u7684\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u7ebf\u6027\u65b9\u6cd5\u3002\u8fd9\u79cd\u4f18\u8d8a\u6027\u53ef\u80fd\u6e90\u4e8eTransformer\u65b9\u6cd5\u589e\u5f3a\u7684\u975e\u7ebf\u6027\u5efa\u6a21\u80fd\u529b\u3002</li> </ul> <p>\u56fe 1</p> <p></p> <p>\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0d\u540c\u7279\u6027\u53ef\u89c6\u5316\uff0c\u8bf4\u660e\u4ec0\u4e48\u662f\u5b63\u8282\u6027\u3001\u8d8b\u52bf\u6027\u3001\u504f\u79fb\u6027\u3001\u5e73\u7a33\u6027\u548c\u8f6c\u79fb</p> <p>\u56fe1\u5305\u542b12\u4e2a\u5b50\u56fe\uff0c\u6bcf\u4e2a\u5b50\u56fe\u4ee3\u8868\u4e00\u79cd\u6570\u636e\u7279\u5f81\u7684\u53ef\u89c6\u5316\uff1a</p> <p>(a) Seasonality\uff08\u5b63\u8282\u6027\uff09\uff1a\u663e\u793a\u4e86\u5177\u6709\u660e\u663e\u5468\u671f\u6027\u6ce2\u52a8\u7684\u6570\u636e\u3002</p> <p>(b) Trend\uff08\u8d8b\u52bf\uff09\uff1a\u5c55\u793a\u4e86\u6570\u636e\u968f\u65f6\u95f4\u5448\u73b0\u7684\u957f\u671f\u589e\u957f\u6216\u4e0b\u964d\u8d8b\u52bf\u3002</p> <p>(c) Shifting\uff08\u53d8\u5316\uff09\uff1a\u6570\u636e\u5728\u67d0\u4e2a\u65f6\u95f4\u70b9\u51fa\u73b0\u4e86\u660e\u663e\u7684\u6c34\u5e73\u53d8\u5316\u3002</p> <p>(d) Stationarity\uff08\u5e73\u7a33\u6027\uff09\uff1a\u6570\u636e\u7684\u7edf\u8ba1\u7279\u6027\uff08\u5982\u5747\u503c\u548c\u65b9\u5dee\uff09\u968f\u65f6\u95f4\u4fdd\u6301\u4e0d\u53d8\u3002</p> <p>(e) Transition\uff08\u8f6c\u6362\uff09\uff1a\u6570\u636e\u5728\u67d0\u4e2a\u65f6\u95f4\u70b9\u51fa\u73b0\u4e86\u7a81\u53d8\uff0c\u53ef\u80fd\u662f\u7531\u4e8e\u5916\u90e8\u4e8b\u4ef6\u6216\u7cfb\u7edf\u5185\u90e8\u53d8\u5316\u5f15\u8d77\u7684\u3002</p> <p>(f) Non-Seasonality\uff08\u975e\u5b63\u8282\u6027\uff09\uff1a\u6570\u636e\u6ca1\u6709\u660e\u663e\u7684\u5468\u671f\u6027\u6ce2\u52a8\u3002</p> <p>(g) Non-Trend\uff08\u975e\u8d8b\u52bf\uff09\uff1a\u6570\u636e\u6ca1\u6709\u660e\u663e\u7684\u957f\u671f\u589e\u957f\u6216\u4e0b\u964d\u8d8b\u52bf\u3002</p> <p>(h) Non-Shifting\uff08\u975e\u53d8\u5316\uff09\uff1a\u6570\u636e\u6ca1\u6709\u51fa\u73b0\u660e\u663e\u7684\u6c34\u5e73\u53d8\u5316\u3002</p> <p>(i) Non-Stationarity\uff08\u975e\u5e73\u7a33\u6027\uff09\uff1a\u6570\u636e\u7684\u7edf\u8ba1\u7279\u6027\u968f\u65f6\u95f4\u53d8\u5316\u3002</p> <p>(j) Non-Transition\uff08\u975e\u8f6c\u6362\uff09\uff1a\u6570\u636e\u6ca1\u6709\u51fa\u73b0\u660e\u663e\u7684\u7a81\u53d8\u3002</p> <p>\u6bcf\u4e2a\u5b50\u56fe\u7684\u53f3\u4e0a\u89d2\u90fd\u6709\u4e00\u4e2a\u5c0f\u7684\u6570\u503c\u6846\uff0c\u663e\u793a\u4e86\u8be5\u7279\u5f81\u7684\u67d0\u79cd\u7edf\u8ba1\u5ea6\u91cf\uff08\u4f8b\u5982\uff0c\u5b63\u8282\u6027\u5f3a\u5ea6\u3001\u8d8b\u52bf\u659c\u7387\u3001\u53d8\u5316\u5e45\u5ea6\u3001\u5e73\u7a33\u6027\u6d4b\u8bd5\u7684p\u503c\u7b49\uff09</p>"},{"location":"literature/TSP/14_TSLib/","title":"TSLib","text":""},{"location":"literature/TSP/14_TSLib/#tslib","title":"TSLib","text":"2025-04-15 17:02:482025-09-28 12:54:06 <p> \u7ea6 10 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6e05\u534e\u5927\u5b66-\u65f6\u5e8f\u5e93\uff1ahttps://github.com/thuml/Time-Series-Library?tab=readme-ov-file</p>"},{"location":"literature/TSP/1_SegRNN/","title":"2023\u3001SegRNN","text":""},{"location":"literature/TSP/1_SegRNN/#2023segrnn","title":"2023\u3001SegRNN","text":"2025-03-04 21:01:002025-09-28 12:54:06 <p> \u7ea6 829 \u4e2a\u5b57  20 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 4 \u5206\u949f</p> <p>\u6a21\u578b\u67b6\u6784\u56fe</p> <p> </p> <p>https://paperswithcode.com/paper/segrnn-segment-recurrent-neural-network-for</p> <p>https://github.com/lss-1138/SegRNN?tab=readme-ov-file</p> <p>Time Series Forecasting on Weather (192) #rank1</p> <p></p> <p>SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting</p> <p></p>"},{"location":"literature/TSP/1_SegRNN/#_1","title":"\u6458\u8981","text":"<p>Time Series Forecasting (LTSF) domain when dealing with excessively long look-back windows and forecast horizons.</p> <p>\uff08\u8fc7\u957f\u7684\u56de\u6eaf\u7a97\u53e3\uff09</p> <p>\uff08\u8fc7\u957f\u7684\u9884\u6d4b\u8303\u56f4\uff09</p> <p>\u5bfc\u81f4 RNN \u8fed\u4ee3\u6b65\u6570\u8fc7\u591a</p> <p>To address these issues, we propose two novel strategies to reduce the number of iterations in RNNs for LTSF tasks: Segment-wise Iterations and Parallel Multi-step Forecasting (PMF).</p> <p>\u9010\u6bb5\u8fed\u4ee3\u4ee3\u66ff\u9010\u70b9\u8fed\u4ee3</p> <p>\u5e76\u884c\u591a\u6b65\u9884\u6d4b</p>"},{"location":"literature/TSP/1_SegRNN/#_2","title":"\u5f15\u5165","text":"<p>However, extending the forecast horizon poses significant challenges: </p> <p>(i) Forecasting further into the future leads to increased uncertainty, resulting in decreased forecast accuracy.</p> <p>\u9884\u6d4b\u8303\u56f4\u592a\u8fdc\uff0c\u5bfc\u81f4\u9884\u6d4b\u7cbe\u5ea6\u7684\u4e0b\u964d</p> <p>(ii) Longer forecast horizons require models to consider a more extensive historical context for accurate predictions, significantly increasing the complexity of modeling.</p> <p>\u8fc7\u957f\u7684\u9884\u6d4b\u8303\u56f4\uff0c\u9700\u8981\u8003\u8651\u66f4\u591a\u7684\u4e0a\u4e0b\u6587\u8bed\u4e49\u4fe1\u606f\uff0c\u663e\u8457\u589e\u52a0\u4e86\u6a21\u578b\u590d\u6742\u5ea6</p> <p>\u56fe 1\uff0c\u6307\u51fa\u95ee\u9898\uff1a</p> <p> </p> <ul> <li>\u8f83\u957f\u7684\u56de\u6eaf\u7a97\u53e3</li> <li>\u9884\u6d4b\u8303\u56f4\u8d8a\u957f\uff0c\u7cbe\u5ea6\u8d8a\u5dee\u3001\u82b1\u8d39\u65f6\u95f4\u8d8a\u591a</li> </ul> <p>\u8d21\u732e\uff1a</p> <p>\u2022 We propose SegRNN, which utilizes time-series segment technique to replace point-wise iterations with <code>segmentwise iterations</code> in LTSF. </p> <p>\u2022 We further introduce the <code>PMF technique</code> to enhance the inference speed and performance of RNNs.</p> <p></p> <p><code>PMF</code> \u4e2d\u7684\u4f4d\u7f6e\u5d4c\u5165 \\(pe_i\\) \u4f5c\u4e3a\u5faa\u73af\u7ed3\u6784\u7684\u987a\u5e8f\u4fe1\u606f\u7684\u66ff\u4ee3\u3002</p>"},{"location":"literature/TSP/1_SegRNN/#_3","title":"\u76f8\u5173\u5de5\u4f5c","text":"<ul> <li>Transformers</li> </ul> <ol> <li>LogTrans (Li et al. 2019), </li> <li>Informer (Zhou et al. 2021), </li> <li>Pyraformer (Liu et al. 2021), </li> <li>Autoformer (Wu et al. 2021), and </li> <li>FEDformer (Zhou et al. 2022), aimed at reducing the complexity of Transformers. </li> </ol> <p>More recently, </p> <ol> <li>PatchTST (Nie et al. 2023) and </li> <li>Crossformer (Zhang and Yan 2023) </li> </ol> <p>leveraged patch-based techniques from computer vision (Dosovitskiy et al. 2021; He et al. 2022),</p> <ul> <li>MLPs</li> </ul> <p>DLinear achieved superiority over then-state-of-the-art Transformerbased models through a simple linear layer and channel independent strategy (Zeng et al. 2023). </p> <p>MTS-Mixers (Li et al. 2023), </p> <p>TSMixer (Vijay et al. 2023), and </p> <p>TiDE (Das et al. 2023). </p> <p>The accomplishments of these MLP-based models have raised questions about the necessity of employing complex and cumbersome Transformers for time series prediction.</p> <ul> <li>CNNs</li> </ul> <ul> <li>MICN (Wang et al. 2023), </li> <li>TimesNet(Wu et al. 2023), and </li> <li>SCINet (LIU et al. 2022)</li> </ul> <p>have demonstrated impressive results in the LTSF field.</p> <ul> <li>RNNs</li> </ul> <p>Numerous efforts have been devoted to utilizing RNNs for short-term and probabilistic forecasting, achieving significant advancements (Lai et al. 2018; Bergsma et al. 2022; Wen et al. 2018; Tan, Xie, and Cheng 2023).</p> <p>However, in the LTSF domain with excessively long look-back windows and forecast horizons, RNNs have been considered inadequate for effectively capturing long-term dependencies, leading to their gradual abandonment (Zhou et al. 2021, 2022). </p> <p>The emergence of SegRNN aims to challenge and change this situation by attempting to address these limitations.</p>"},{"location":"literature/TSP/1_SegRNN/#preliminaries","title":"Preliminaries","text":"<p>\u8fed\u4ee3\u6b65\u6570\u8fc7\u591a\u4f1a\u9020\u6210 \u68af\u5ea6\u7206\u70b8\u548c\u68af\u5ea6\u6d88\u5931\uff0c\u5bfc\u81f4\u8bad\u7ec3\u9636\u6bb5\u7684\u6a21\u578b\u6536\u655b\u95ee\u9898</p> <p>The vanilla RNN faces challenges such as vanishing and exploding gradients, which hinder the model\u2019s convergence during training</p> <p>\u672c\u6587\u91c7\u7528\u7684 RNN \u5355\u5143\u662f GRU</p> <p>Therefore, for consistency throughout the text, the SegRNN model is assumed to be based on the GRU cell</p> <p></p>"},{"location":"literature/TSP/1_SegRNN/#_4","title":"\u6a21\u578b\u7ed3\u6784","text":""},{"location":"literature/TSP/1_SegRNN/#_5","title":"\u5b9e\u9a8c","text":""},{"location":"literature/TSP/1_SegRNN/#_6","title":"\u5b9e\u9a8c\u73af\u5883","text":"<p>All experiments in this section are implemented in PyTorch and executed on two NVIDIA T4 GPUs, each equipped with 16GB of memory</p>"},{"location":"literature/TSP/1_SegRNN/#_7","title":"\u6570\u636e\u96c6","text":""},{"location":"literature/TSP/1_SegRNN/#_8","title":"\u53c2\u6570\u8bbe\u7f6e","text":"<p>Model configuration. The uniform configuration of SegRNN consists of a look-back of 720, a segment length of 48, a single GRU layer, a hidden size of 512, 30 training epochs, a learning rate decay of 0.8 after the initial 3 epochs, and early stopping with a patience of 10. The dropout rate, batch size, and learning rate vary based on the scale of the data.</p> <p>\u56de\u6eaf\u6b65\u6570\uff1a720</p> <p>\u5206\u6bb5\u957f\u5ea6\uff1a48</p> <p>\u5355\u5c42GRU\uff0c\u9690\u542b\u5c42\u5c42\u6570\uff1a512</p> <p>\u8fed\u4ee3\u6b21\u6570\uff1a30 \u6b21</p>"},{"location":"literature/TSP/1_SegRNN/#_9","title":"\u5bf9\u6bd4\u5b9e\u9a8c","text":"<p>\u5bf9\u6bd4\u6a21\u578b &amp; \u6307\u6807</p> <p></p> <p>7 \u4e2a\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u6570\u636e\u96c6 4 \u79cd\u9884\u6d4b\u6b65\u6570\uff0c2\u4e2a\u6307\u6807\uff0c\u6240\u4ee5\u4e00\u5171\u662f 56 \u79cd\u7ec4\u5408\uff0cSegRNN \u62ff\u5230\u4e86 50 \u6b21\u597d\u540d\u6b21</p>"},{"location":"literature/TSP/1_SegRNN/#_10","title":"\u6d88\u878d\u5b9e\u9a8c","text":"<p>Segment-wise iterations vs. point-wise iterations. </p> <p></p> <p>PMF vs. RMF.</p> <p></p> <p>\u65f6\u5e8f\u9884\u6d4b\u7bc7-SegRNN\u9605\u8bfb\u7b14\u8bb0</p> <p>SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting</p> <ol> <li>\u8ba1\u7b97\u91cf\u5927</li> <li>\u6a21\u578b\u8bad\u7ec3\u7f13\u6162</li> <li>\u68af\u5ea6\u7206\u70b8\u6216\u8005\u68af\u5ea6\u6d88\u5931</li> </ol>"},{"location":"literature/TSP/2_DLinear/","title":"2022\u3001LTSF-Linear","text":""},{"location":"literature/TSP/2_DLinear/#2022ltsf-linear","title":"2022\u3001LTSF-Linear","text":"2025-03-04 21:01:002025-09-28 12:54:06 <p> \u7ea6 20999 \u4e2a\u5b57  20 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 105 \u5206\u949f</p> <p>\u539f\u6587\uff1aAre Transformers Effective for Time Series Forecasting? </p> <p>\u6e90\u7801\uff1ahttps://github.com/cure-lab/LTSF-Linear</p> <p></p> <p>\u65f6\u5e8f\u9884\u6d4b\u7bc7-DLinear&amp;NLinear\u9605\u8bfb\u7b14\u8bb0</p>"},{"location":"literature/TSP/2_DLinear/#abstract","title":"Abstract","text":"<p>Recently, there has been a surge of Transformer-based solutions for the long-term time series forecasting (LTSF) task. Despite the growing performance over the past few years, we question the validity of this line of research in this work. </p> <p>\u8fd1\u671f\uff0c\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u5728\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u4efb\u52a1\u4e2d\u5448\u73b0\u51fa\u8fc5\u731b\u53d1\u5c55\u7684\u6001\u52bf\u3002\u5c3d\u7ba1\u8fc7\u53bb\u51e0\u5e74\u5176\u6027\u80fd\u4e0d\u65ad\u63d0\u5347\uff0c\u4f46\u6211\u4eec\u5728\u672c\u7814\u7a76\u4e2d\u5bf9\u8be5\u7814\u7a76\u65b9\u5411\u7684\u6709\u6548\u6027\u63d0\u51fa\u4e86\u8d28\u7591\u3002</p> <p>Specifically, Transformers is arguably the most successful solution to extract the semantic correlations among the elements in a long sequence. However, in time series modeling, we are to extract the temporal relations in an ordered set of continuous points. </p> <p>\u5177\u4f53\u800c\u8a00\uff0cTransformer\u65e0\u7591\u662f\u63d0\u53d6\u957f\u5e8f\u5217\u4e2d\u5143\u7d20\u4e4b\u95f4\u8bed\u4e49\u5173\u8054\u6700\u4e3a\u6210\u529f\u7684\u89e3\u51b3\u65b9\u6848\u3002\u7136\u800c\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4e2d\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u4ece\u8fde\u7eed\u70b9\u7684\u6709\u5e8f\u96c6\u5408\u4e2d\u63d0\u53d6\u65f6\u95f4\u5173\u7cfb\u3002</p> <p>While employing positional encoding and using tokens to embed sub-series in Transformers facilitate preserving some ordering information, the nature of the permutation-invariant self-attention mechanism inevitably results in temporal information loss.</p> <p>\u867d\u7136\u5728Transformer\u4e2d\u4f7f\u7528\u4f4d\u7f6e\u7f16\u7801\u4ee5\u53ca\u5229\u7528\u6807\u8bb0\u5d4c\u5165\u5b50\u5e8f\u5217\u6709\u52a9\u4e8e\u4fdd\u7559\u90e8\u5206\u987a\u5e8f\u4fe1\u606f\uff0c\u4f46\u6392\u5217\u4e0d\u53d8\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u56fa\u6709\u7279\u6027\u4e0d\u53ef\u907f\u514d\u5730\u4f1a\u5bfc\u81f4\u65f6\u95f4\u4fe1\u606f\u7684\u4e22\u5931\u3002</p> <p>To validate our claim, we introduce a set of embarrassingly simple one-layer linear models named LTSF-Linear for comparison. Experimental results on nine real-life datasets show that LTSF-Linear surprisingly outperforms existing sophisticated Transformer-based LTSF models in all cases, and often by a large margin. </p> <p>Moreover, we conduct comprehensive empirical studies to explore the impacts of various design elements of LTSF models on their temporal relation extraction capability. We hope this surprising finding opens up new research directions for the LTSF task. We also advocate revisiting the validity of Transformer-based solutions for other time series analysis tasks (e.g., anomaly detection) in the future. Code is available at: https://github.com/cure-lab/LTSFLinear.</p> <p>\u4e3a\u4e86\u9a8c\u8bc1\u6211\u4eec\u7684\u89c2\u70b9\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u7ec4\u6781\u5176\u7b80\u5355\u7684\u5355\u5c42\u7ebf\u6027\u6a21\u578b\uff0c\u547d\u540d\u4e3a LTSF-Linear\uff0c\u7528\u4e8e\u5bf9\u6bd4\u3002\u5728\u4e5d\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cLTSF-Linear \u610f\u5916\u5730\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u590d\u6742\u57fa\u4e8e Transformer \u7684 LTSF \u6a21\u578b\uff0c\u4e14\u901a\u5e38\u4f18\u52bf\u663e\u8457\u3002</p> <p>\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u4ee5\u63a2\u7d22 LTSF \u6a21\u578b\u7684\u5404\u79cd\u8bbe\u8ba1\u5143\u7d20\u5bf9\u5176\u65f6\u95f4\u5173\u7cfb\u63d0\u53d6\u80fd\u529b\u7684\u5f71\u54cd\u3002\u6211\u4eec\u5e0c\u671b\u8fd9\u4e00\u4ee4\u4eba\u610f\u5916\u7684\u53d1\u73b0\u80fd\u591f\u4e3a LTSF \u4efb\u52a1\u5f00\u8f9f\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002\u6211\u4eec\u8fd8\u5021\u5bfc\u5728\u672a\u6765\u91cd\u65b0\u5ba1\u89c6\u57fa\u4e8e Transformer \u7684\u89e3\u51b3\u65b9\u6848\u5728\u5176\u4ed6\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4efb\u52a1\uff08\u4f8b\u5982\u5f02\u5e38\u68c0\u6d4b\uff09\u4e2d\u7684\u6709\u6548\u6027\u3002\u4ee3\u7801\u53ef\u5728\u4ee5\u4e0b\u94fe\u63a5\u83b7\u53d6\uff1ahttps://github.com/cure-lab/LTSFLinear\u3002</p>"},{"location":"literature/TSP/2_DLinear/#1-introduction","title":"1. Introduction","text":"<p>Time series are ubiquitous in today\u2019s data-driven world. Given historical data, time series forecasting (TSF) is a long-standing task that has a wide range of applications, including but not limited to traffic flow estimation, energy management, and financial investment. Over the past several decades, TSF solutions have undergone a progression from traditional statistical methods (e.g., ARIMA [1]) and machine learning techniques (e.g., GBRT [11]) to deep learning-based solutions, e.g., Recurrent Neural Networks [15] and Temporal Convolutional Networks [3, 17].</p> <p>\u5728\u5f53\u4eca\u6570\u636e\u9a71\u52a8\u7684\u4e16\u754c\u4e2d\uff0c\u65f6\u95f4\u5e8f\u5217\u65e0\u5904\u4e0d\u5728\u3002\u57fa\u4e8e\u5386\u53f2\u6570\u636e\uff0c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u662f\u4e00\u9879\u7531\u6765\u5df2\u4e45\u7684\u4efb\u52a1\uff0c\u5176\u5e94\u7528\u8303\u56f4\u6781\u4e3a\u5e7f\u6cdb\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u4ea4\u901a\u6d41\u91cf\u4f30\u8ba1\u3001\u80fd\u6e90\u7ba1\u7406\u548c\u91d1\u878d\u6295\u8d44\u7b49\u9886\u57df\u3002\u5728\u8fc7\u53bb\u51e0\u5341\u5e74\u95f4\uff0c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u89e3\u51b3\u65b9\u6848\u7ecf\u5386\u4e86\u4ece\u4f20\u7edf\u7684\u7edf\u8ba1\u65b9\u6cd5\uff08\u4f8b\u5982ARIMA\uff09\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\uff08\u4f8b\u5982GBRT\uff09\u5230\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u89e3\u51b3\u65b9\u6848\uff08\u4f8b\u5982\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548c\u65f6\u95f4\u5377\u79ef\u7f51\u7edc\uff09\u7684\u53d1\u5c55\u6f14\u53d8\u3002</p> <p>Transformer [26] is arguably the most successful sequence modeling architecture, demonstrating unparalleled performances in various applications, such as natural language processing (NLP) [7], speech recognition [8], and computer vision [19, 29]. Recently, there has also been a surge of Transformer-based solutions for time series analysis, as surveyed in [27]. Most notable models, which focus on the less explored and challenging long-term time series forecasting (LTSF) problem, include LogTrans [16] (NeurIPS 2019), Informer [30] (AAAI 2021 Best paper), Autoformer [28] (NeurIPS 2021), Pyraformer [18] (ICLR 2022 Oral), Triformer [5] (IJCAI 2022) and the recent FEDformer [31] (ICML 2022).</p> <p>Transformer\u65e0\u7591\u662f\u5e8f\u5217\u5efa\u6a21\u9886\u57df\u6700\u4e3a\u6210\u529f\u7684\u67b6\u6784\uff0c\u5728\u8bf8\u591a\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u4e86\u65e0\u4e0e\u4f26\u6bd4\u7684\u6027\u80fd\uff0c\u4f8b\u5982\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u3001\u8bed\u97f3\u8bc6\u522b\u4ee5\u53ca\u8ba1\u7b97\u673a\u89c6\u89c9\u7b49\u3002\u8fd1\u671f\uff0c\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u89e3\u51b3\u65b9\u6848\u4e5f\u5448\u73b0\u51fa\u8fc5\u731b\u53d1\u5c55\u7684\u6001\u52bf\uff0c\u76f8\u5173\u7814\u7a76\u7efc\u8ff0\u53ef\u89c1\u4e8e\u6587\u732e[27]\u3002\u5176\u4e2d\uff0c\u4e13\u6ce8\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u8fd9\u4e00\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u4e14\u6781\u5177\u6311\u6218\u6027\u7684\u95ee\u9898\u7684\u6700\u5177\u4ee3\u8868\u6027\u7684\u6a21\u578b\u5305\u62ecLogTrans[16]\uff08NeurIPS 2019\uff09\u3001Informer[30]\uff08AAAI 2021\u6700\u4f73\u8bba\u6587\uff09\u3001Autoformer[28]\uff08NeurIPS 2021\uff09\u3001Pyraformer[18]\uff08ICLR 2022\u53e3\u5934\u62a5\u544a\uff09\u3001Triformer[5]\uff08IJCAI 2022\uff09\u4ee5\u53ca\u6700\u8fd1\u7684FEDformer[31]\uff08ICML 2022\uff09\u3002</p> <p>The main working power of Transformers is from its multi-head self-attention mechanism, which has a remarkable capability of extracting semantic correlations among elements in a long sequence (e.g., words in texts or 2D patches in images). However, self-attention is permutationinvariant and \u201canti-order\u201d to some extent. While using various types of positional encoding techniques can preserve some ordering information, it is still inevitable to have temporal information loss after applying self-attention on top of them. </p> <p>Transformer\u7684\u4e3b\u8981\u5de5\u4f5c\u539f\u7406\u6e90\u4e8e\u5176\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8be5\u673a\u5236\u5728\u63d0\u53d6\u957f\u5e8f\u5217\u4e2d\u5143\u7d20\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u8054\uff08\u4f8b\u5982\u6587\u672c\u4e2d\u7684\u8bcd\u8bed\u6216\u56fe\u50cf\u4e2d\u7684\u4e8c\u7ef4\u5757\uff09\u65b9\u9762\u5177\u6709\u663e\u8457\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u662f\u6392\u5217\u4e0d\u53d8\u7684\uff0c\u5e76\u4e14\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u662f\u201c\u53cd\u5e8f\u201d\u7684\u3002\u5c3d\u7ba1\u4f7f\u7528\u5404\u79cd\u7c7b\u578b\u7684\u4f4d\u7f6e\u7f16\u7801\u6280\u672f\u53ef\u4ee5\u4fdd\u7559\u4e00\u4e9b\u987a\u5e8f\u4fe1\u606f\uff0c\u4f46\u5728\u5e94\u7528\u81ea\u6ce8\u610f\u529b\u4e4b\u540e\uff0c\u4ecd\u7136\u4e0d\u53ef\u907f\u514d\u5730\u4f1a\u5bfc\u81f4\u65f6\u95f4\u4fe1\u606f\u7684\u4e22\u5931\u3002</p> <p>This is usually not a serious concern for semanticrich applications such as NLP, e.g., the semantic meaning of a sentence is largely preserved even if we reorder some words in it. However, when analyzing time series data, there is usually a lack of semantics in the numerical data itself, and we are mainly interested in modeling the temporal changes among a continuous set of points. That is, the order itself plays the most crucial role. Consequently, we pose the following intriguing question: Are Transformers really effective for long-term time series forecasting?</p> <p>\u5bf9\u4e8e\u8bed\u4e49\u4e30\u5bcc\u7684\u5e94\u7528\uff08\u5982\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff09\uff0c\u8fd9\u901a\u5e38\u4e0d\u662f\u4e25\u91cd\u7684\u95ee\u9898\uff0c\u4f8b\u5982\uff0c\u5373\u4f7f\u6211\u4eec\u91cd\u65b0\u6392\u5217\u53e5\u5b50\u4e2d\u7684\u4e00\u4e9b\u8bcd\u8bed\uff0c\u53e5\u5b50\u7684\u8bed\u4e49\u610f\u4e49\u4ecd\u7136\u5f97\u4ee5\u5927\u90e8\u5206\u4fdd\u7559\u3002\u7136\u800c\uff0c\u5728\u5206\u6790\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\uff0c\u6570\u503c\u6570\u636e\u672c\u8eab\u901a\u5e38\u7f3a\u4e4f\u8bed\u4e49\uff0c\u800c\u6211\u4eec\u4e3b\u8981\u5173\u6ce8\u7684\u662f\u5efa\u6a21\u8fde\u7eed\u70b9\u96c6\u4e4b\u95f4\u7684\u65f6\u95f4\u53d8\u5316\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u987a\u5e8f\u672c\u8eab\u8d77\u7740\u6700\u5173\u952e\u7684\u4f5c\u7528\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4ee5\u4e0b\u5f15\u4eba\u5165\u80dc\u7684\u95ee\u9898\uff1aTransformer\u662f\u5426\u771f\u7684\u9002\u7528\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff1f</p> <p>Moreover, while existing Transformer-based LTSF solutions have demonstrated considerable prediction accuracy improvements over traditional methods, in their experiments, all the compared (non-Transformer) baselines perform autoregressive or iterated multi-step (IMS) forecasting [1, 2, 22, 24], which are known to suffer from significant error accumulation effects for the LTSF problem. Therefore, in this work, we challenge Transformer-based LTSF solutions with direct multi-step (DMS) forecasting strategies to validate their real performance.</p> <p>\u6b64\u5916\uff0c\u5c3d\u7ba1\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u89e3\u51b3\u65b9\u6848\u5df2\u663e\u793a\u51fa\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u663e\u8457\u9884\u6d4b\u7cbe\u5ea6\u63d0\u5347\uff0c\u4f46\u5728\u5176\u5b9e\u9a8c\u4e2d\uff0c\u6240\u6709\u88ab\u6bd4\u8f83\u7684\uff08\u975eTransformer\uff09\u57fa\u7ebf\u5747\u91c7\u7528\u81ea\u56de\u5f52\u6216\u8fed\u4ee3\u591a\u6b65\uff08IMS\uff09\u9884\u6d4b\u7b56\u7565\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5df2\u77e5\u5728LTSF\u95ee\u9898\u4e2d\u5b58\u5728\u663e\u8457\u7684\u8bef\u5dee\u7d2f\u79ef\u6548\u5e94\u3002\u56e0\u6b64\uff0c\u5728\u672c\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u91c7\u7528\u76f4\u63a5\u591a\u6b65\uff08DMS\uff09\u9884\u6d4b\u7b56\u7565\u6765\u6311\u6218\u57fa\u4e8eTransformer\u7684LTSF\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u9a8c\u8bc1\u5176\u771f\u5b9e\u6027\u80fd\u3002</p> <p>\u8fd8\u662f\u5f97\u591a\u770b\u6587\u732e\uff0c\u73b0\u5728\u90fd\u662f\u591a\u6b65\u5e76\u884c\u9884\u6d4b</p> <p>Not all time series are predictable, let alone long-term forecasting (e.g., for chaotic systems). </p> <p>We hypothesize that long-term forecasting is only feasible for those time series with a relatively clear trend and periodicity. </p> <p>As linear models can already extract such information, we introduce a set of embarrassingly simple models named LTSF-Linear as a new baseline for comparison. </p> <p>LTSF-Linear regresses historical time series with a one-layer linear model to forecast future time series directly. </p> <p>\u5e76\u975e\u6240\u6709\u65f6\u95f4\u5e8f\u5217\u90fd\u5177\u5907\u53ef\u9884\u6d4b\u6027\uff0c\u957f\u671f\u9884\u6d4b\u66f4\u662f\u5982\u6b64\uff08\u4f8b\u5982\u6df7\u6c8c\u7cfb\u7edf\uff09\u3002\u6211\u4eec\u63a8\u6d4b\uff0c\u957f\u671f\u9884\u6d4b\u4ec5\u9002\u7528\u4e8e\u90a3\u4e9b\u8d8b\u52bf\u548c\u5468\u671f\u6027\u8f83\u4e3a\u660e\u663e\u7684\u65f6\u95f4\u5e8f\u5217\u3002\u7531\u4e8e\u7ebf\u6027\u6a21\u578b\u5df2\u7ecf\u80fd\u591f\u63d0\u53d6\u6b64\u7c7b\u4fe1\u606f\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u7ec4\u6781\u4e3a\u7b80\u5355\u7684\u6a21\u578b\uff0c\u547d\u540d\u4e3a LTSF-Linear\uff0c\u4f5c\u4e3a\u65b0\u7684\u6bd4\u8f83\u57fa\u7ebf\u3002LTSF-Linear \u901a\u8fc7\u5355\u5c42\u7ebf\u6027\u6a21\u578b\u5bf9\u5386\u53f2\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u56de\u5f52\uff0c\u76f4\u63a5\u9884\u6d4b\u672a\u6765\u7684\u5e8f\u5217\u3002</p> <p>We conduct extensive experiments on nine widely-used benchmark datasets that cover various real-life applications: traffic, energy, economics, weather, and disease predictions. </p> <p>Surprisingly, our results show that LTSF-Linear outperforms existing complex Transformerbased models in all cases, and often by a large margin (20% \u223c 50%). </p> <p>Moreover, we find that, in contrast to the claims in existing Transformers, most of them fail to extract temporal relations from long sequences, i.e., the forecasting errors are not reduced (sometimes even increased) with the increase of look-back window sizes. </p> <p>Finally, we conduct various ablation studies on existing Transformer-based TSF solutions to study the impact of various design elements in them.</p> <p>\u6211\u4eec\u5728\u6db5\u76d6\u4ea4\u901a\u3001\u80fd\u6e90\u3001\u7ecf\u6d4e\u3001\u5929\u6c14\u548c\u75be\u75c5\u9884\u6d4b\u7b49\u591a\u79cd\u5b9e\u9645\u5e94\u7528\u7684\u4e5d\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u3002\u4ee4\u4eba\u610f\u5916\u7684\u662f\uff0c\u7ed3\u679c\u663e\u793a LTSF-Linear \u5728\u6240\u6709\u60c5\u51b5\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u590d\u6742\u57fa\u4e8e Transformer \u7684\u6a21\u578b\uff0c\u4e14\u4f18\u52bf\u663e\u8457\uff0820% \u81f3 50%\uff09\u3002</p> <p>\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0\uff0c\u4e0e\u73b0\u6709 Transformer \u4e2d\u7684\u4e3b\u5f20\u76f8\u53cd\uff0c\u5927\u591a\u6570 Transformer \u65e0\u6cd5\u4ece\u957f\u5e8f\u5217\u4e2d\u63d0\u53d6\u65f6\u95f4\u5173\u7cfb\uff0c\u5373\u968f\u7740\u56de\u987e\u7a97\u53e3\u5927\u5c0f\u7684\u589e\u52a0\uff0c\u9884\u6d4b\u8bef\u5dee\u5e76\u672a\u964d\u4f4e\uff08\u6709\u65f6\u751a\u81f3\u589e\u52a0\uff09\u3002\u6700\u540e\uff0c\u6211\u4eec\u5bf9\u73b0\u6709\u7684\u57fa\u4e8e Transformer \u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u4e86\u5404\u79cd\u6d88\u878d\u7814\u7a76\uff0c\u4ee5\u63a2\u7a76\u5176\u4e2d\u5404\u79cd\u8bbe\u8ba1\u5143\u7d20\u7684\u5f71\u54cd\u3002</p> <p>\u6240\u4ee5\u8bf4\uff0cTransformer \u7684\u56de\u671b\u7a97\u53e3\u8fb9\u957f\u8bef\u5dee\u4f1a\u589e\u52a0</p>"},{"location":"literature/TSP/2_DLinear/#contributions","title":"contributions","text":"<p>To sum up, the contributions of this work include:</p> <ul> <li>To the best of our knowledge, this is the first work to challenge the effectiveness of the booming Transformers for the long-term time series forecasting task.</li> <li>\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u662f\u9996\u6b21\u5bf9\u5728\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u84ec\u52c3\u53d1\u5c55\u7684Transformer\u7684\u6709\u6548\u6027\u63d0\u51fa\u6311\u6218\u3002</li> <li>To validate our claims, we introduce a set of embarrassingly simple one-layer linear models, named LTSF-Linear, and compare them with existing Transformer-based LTSF solutions on nine benchmarks. LTSF-Linear can be a new baseline for the LTSF problem.</li> <li>\u4e3a\u4e86\u9a8c\u8bc1\u6211\u4eec\u7684\u89c2\u70b9\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u7ec4\u6781\u5176\u7b80\u5355\u7684\u5355\u5c42\u7ebf\u6027\u6a21\u578b\uff0c\u547d\u540d\u4e3aLTSF-Linear\uff0c\u5e76\u5728\u4e5d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5c06\u5176\u4e0e\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684LTSF\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u6bd4\u8f83\u3002LTSF-Linear\u53ef\u4ee5\u4f5c\u4e3aLTSF\u95ee\u9898\u7684\u4e00\u4e2a\u65b0\u7684\u57fa\u7ebf\u6a21\u578b\u3002</li> <li> <p>We conduct comprehensive empirical studies on various aspects of existing Transformer-based solutions, including the capability of modeling long inputs, the sensitivity to time series order, the impact of positional encoding and sub-series embedding, and efficiency comparisons. Our findings would benefit future research in this area.</p> </li> <li> <p>\u6211\u4eec\u5bf9\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u7684\u5404\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5305\u62ec\u5bf9\u957f\u8f93\u5165\u7684\u5efa\u6a21\u80fd\u529b\u3001\u5bf9\u65f6\u95f4\u5e8f\u5217\u987a\u5e8f\u7684\u654f\u611f\u6027\u3001\u4f4d\u7f6e\u7f16\u7801\u548c\u5b50\u5e8f\u5217\u5d4c\u5165\u7684\u5f71\u54cd\u4ee5\u53ca\u6548\u7387\u6bd4\u8f83\u7b49\u3002\u6211\u4eec\u7684\u53d1\u73b0\u5c06\u6709\u52a9\u4e8e\u8be5\u9886\u57df\u672a\u6765\u7684\u7814\u7a76\u3002</p> </li> </ul> <p>With the above, we conclude that \u2460 the temporal modeling capabilities of Transformers for time series are exaggerated, at least for the existing LTSF benchmarks. At the same time, \u2461 while LTSF-Linear achieves a better prediction accuracy compared to existing works, it merely serves as a simple baseline for future research on the challenging longterm TSF problem. </p> <p>With our findings, we also advocate revisiting the validity of Transformer-based solutions for other time series analysis tasks in the future.</p> <p>\u57fa\u4e8e\u4e0a\u8ff0\u7814\u7a76\uff0c\u6211\u4eec\u5f97\u51fa\u7ed3\u8bba\uff1aTransformer\u5728\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u65b9\u9762\u7684\u80fd\u529b\u88ab\u9ad8\u4f30\u4e86\uff0c\u81f3\u5c11\u5bf9\u4e8e\u73b0\u6709\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u57fa\u51c6\u6d4b\u8bd5\u800c\u8a00\u662f\u8fd9\u6837\u3002\u4e0e\u6b64\u540c\u65f6\uff0c\u5c3d\u7ba1LTSF-Linear\u76f8\u8f83\u4e8e\u73b0\u6709\u7814\u7a76\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4f46\u5b83\u4ec5\u4ec5\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u7528\u4e8e\u672a\u6765\u5bf9\u6781\u5177\u6311\u6218\u6027\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u95ee\u9898\u7684\u7814\u7a76\u3002\u9274\u4e8e\u6211\u4eec\u7684\u53d1\u73b0\uff0c\u6211\u4eec\u8fd8\u5021\u5bfc\u5728\u672a\u6765\u91cd\u65b0\u5ba1\u89c6\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u5728\u5176\u4ed6\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002</p>"},{"location":"literature/TSP/2_DLinear/#2-preliminaries-tsf-problem-formulation","title":"2. Preliminaries: TSF Problem Formulation","text":"<p>For time series containing C variates, given historical data $ \\mathcal{X} = {X_1^t, ..., X_C<sup>t}_{t=1}</sup>L $, wherein L is the look-back window size and $ X_i^t $ is the value of the i^th variate at the t^th time step. The time series forecasting task is to predict the values $ \\hat{\\mathcal{X}} = {\\hat{X}_1^t, ..., \\hat{X}_C<sup>t}_{t=L+1}</sup> $ at the T future time steps. </p> <p>When T &gt; 1, iterated multi-step (IMS) forecasting learns a single-step forecaster and iteratively applies it to obtain multi-step predictions. Alternatively, direct multi-step (DMS) forecasting directly optimizes the multi-step forecasting objective at once.</p> <p>\u5bf9\u4e8e\u5305\u542b C \u4e2a\u53d8\u91cf\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u7ed9\u5b9a\u5386\u53f2\u6570\u636e $ \\mathcal{X} = {X_1^t, ..., X_C<sup>t}_{t=1}</sup>L \\(\uff0c\u5176\u4e2d L \u662f\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\uff0c\\) X_i^t $ \u662f\u7b2c i \u4e2a\u53d8\u91cf\u5728\u7b2c t \u4e2a\u65f6\u95f4\u6b65\u7684\u503c\u3002\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u662f\u9884\u6d4b\u672a\u6765 T \u4e2a\u65f6\u95f4\u6b65\u7684\u503c $ \\hat{\\mathcal{X}} = {\\hat{X}_1^t, ..., \\hat{X}_C<sup>t}_{t=L+1}</sup> $\u3002\u5f53 T &gt; 1 \u65f6\uff0c\u8fed\u4ee3\u591a\u6b65\uff08IMS\uff09\u9884\u6d4b\u5b66\u4e60\u4e00\u4e2a\u5355\u6b65\u9884\u6d4b\u5668\uff0c\u5e76\u8fed\u4ee3\u5730\u5e94\u7528\u5b83\u6765\u83b7\u5f97\u591a\u6b65\u9884\u6d4b\u3002\u6216\u8005\uff0c\u76f4\u63a5\u591a\u6b65\uff08DMS\uff09\u9884\u6d4b\u76f4\u63a5\u4e00\u6b21\u6027\u4f18\u5316\u591a\u6b65\u9884\u6d4b\u76ee\u6807\u3002</p> <p>Compared to DMS forecasting results, IMS predictions have smaller variance thanks to the autoregressive estimation procedure, but they inevitably suffer from error accumulation effects. </p> <p>Consequently, IMS forecasting is preferable when there is a highly-accurate single-step forecaster, and \\(T\\) is relatively small.</p> <p>In contrast, DMS forecasting generates more accurate predictions when it is hard to obtain an unbiased single-step forecasting model, or \\(T\\) is large.</p> <p>\u4e0e\u76f4\u63a5\u591a\u6b65\uff08DMS\uff09\u9884\u6d4b\u7ed3\u679c\u76f8\u6bd4\uff0c\u8fed\u4ee3\u591a\u6b65\uff08IMS\uff09\u9884\u6d4b\u7531\u4e8e\u81ea\u56de\u5f52\u4f30\u8ba1\u8fc7\u7a0b\u800c\u5177\u6709\u8f83\u5c0f\u7684\u65b9\u5dee\uff0c\u4f46\u5b83\u4eec\u4e0d\u53ef\u907f\u514d\u5730\u4f1a\u906d\u53d7\u8bef\u5dee\u7d2f\u79ef\u6548\u5e94\u7684\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u5f53\u5b58\u5728\u9ad8\u5ea6\u7cbe\u786e\u7684\u5355\u6b65\u9884\u6d4b\u5668\uff0c\u4e14 \\(T\\) \u76f8\u5bf9\u8f83\u5c0f\u65f6\uff0cIMS\u9884\u6d4b\u66f4\u4e3a\u53ef\u53d6\u3002\u76f8\u53cd\uff0c\u5f53\u96be\u4ee5\u83b7\u5f97\u65e0\u504f\u7684\u5355\u6b65\u9884\u6d4b\u6a21\u578b\uff0c\u6216\u8005 \\(T\\) \u8f83\u5927\u65f6\uff0cDMS\u9884\u6d4b\u80fd\u591f\u751f\u6210\u66f4\u51c6\u786e\u7684\u9884\u6d4b\u3002</p> <p>\u8fd9\u90e8\u5206\u8ba8\u8bba\u4e86\u4ec0\u4e48\u65f6\u5019\u4f7f\u7528\u81ea\u56de\u5f52\u9884\u6d4b\uff0c\u4ec0\u4e48\u65f6\u5019\u91c7\u7528\u5e76\u884c\u9884\u6d4b</p> <p>\u90a3\u6211\u7684\u9884\u6d4b\u903b\u8f91\u662f\u6709\u70b9\u95ee\u9898</p> <p>\u6536\u83b7\uff1a\u5e76\u884c\u591a\u6b65\u9884\u6d4b\uff1b\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\uff0c\u662f\u91c7\u7528\u901a\u9053\u72ec\u7acb\u7b56\u7565\u8fd8\u662f\u6df7\u5408</p>"},{"location":"literature/TSP/2_DLinear/#3-transformer-based-ltsf-solutions","title":"3. Transformer-Based LTSF Solutions","text":"<p>Transformer-based models [26] have achieved unparalleled performances in many long-standing AI tasks in natural language processing and computer vision fields, thanks to the effectiveness of the multi-head self-attention mechanism. </p> <p>This has also triggered lots of research interest in Transformer-based time series modeling techniques [20, 27]. </p> <p>In particular, a large amount of research works are dedicated to the LTSF task (e.g., [16, 18, 28, 30, 31]). Considering the ability to capture long-range dependencies with Transformer models, most of them focus on the less-explored long-term forecasting problem (\\(T \\gg 1\\)) [1].</p> <p>\u57fa\u4e8eTransformer\u7684\u6a21\u578b[26]\u7531\u4e8e\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u6709\u6548\u6027\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u7684\u8bb8\u591a\u957f\u671f\u5b58\u5728\u7684AI\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u65e0\u4e0e\u4f26\u6bd4\u7684\u6027\u80fd\u3002\u8fd9\u4e5f\u6fc0\u53d1\u4e86\u5bf9\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u6280\u672f[20, 27]\u7684\u5927\u91cf\u7814\u7a76\u5174\u8da3\u3002\u7279\u522b\u662f\uff0c\u5927\u91cf\u7684\u7814\u7a76\u5de5\u4f5c\u81f4\u529b\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u4efb\u52a1\uff08\u4f8b\u5982\uff0c[16, 18, 28, 30, 31]\uff09\u3002\u8003\u8651\u5230\u4f7f\u7528Transformer\u6a21\u578b\u6355\u6349\u957f\u8ddd\u79bb\u4f9d\u8d56\u5173\u7cfb\u7684\u80fd\u529b\uff0c\u4ed6\u4eec\u4e2d\u7684\u5927\u591a\u6570\u90fd\u96c6\u4e2d\u5728\u63a2\u7d22\u8f83\u5c11\u7684\u957f\u671f\u9884\u6d4b\u95ee\u9898\uff08\\(T \\gg 1\\)\uff09[1]\u3002</p> <p>\u6240\u4ee5\u957f\u671f\u9884\u6d4b\u95ee\u9898\uff0c\u53cd\u800c\u662f Transformer \u51fa\u73b0\u4ee5\u540e\u5f00\u59cb\u7684</p> <p>When applying the vanilla Transformer model to the LTSF problem, it has some limitations, including the quadratic time/memory complexity with the original selfattention scheme and error accumulation caused by the autoregressive decoder design. Informer [30] addresses these issues and proposes a novel Transformer architecture with reduced complexity and a DMS forecasting strategy. Later, more Transformer variants introduce various time series features into their models for performance or efficiency improvements [18,28,31]. We summarize the design elements of existing Transformer-based LTSF solutions as follows (see Figure 1).</p> <p>\u5c06\u7ecf\u5178\u7684Transformer\u6a21\u578b\u5e94\u7528\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u95ee\u9898\u65f6\uff0c\u5b58\u5728\u4e00\u4e9b\u9650\u5236\uff0c\u5305\u62ec\u539f\u59cb\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u65f6\u95f4\u548c\u5185\u5b58\u590d\u6742\u5ea6\u4ee5\u53ca\u7531\u81ea\u56de\u5f52\u89e3\u7801\u5668\u8bbe\u8ba1\u5f15\u8d77\u7684\u8bef\u5dee\u7d2f\u79ef\u3002Informer [30] \u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u964d\u4f4e\u590d\u6742\u5ea6\u548c\u76f4\u63a5\u591a\u6b65\uff08DMS\uff09\u9884\u6d4b\u7b56\u7565\u7684\u65b0\u578bTransformer\u67b6\u6784\u3002\u968f\u540e\uff0c\u66f4\u591a\u7684Transformer\u53d8\u4f53\u5c06\u5404\u79cd\u65f6\u95f4\u5e8f\u5217\u7279\u5f81\u5f15\u5165\u4ed6\u4eec\u7684\u6a21\u578b\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u6027\u80fd\u6216\u6548\u7387[18, 28, 31]\u3002\u6211\u4eec\u5982\u4e0b\u603b\u7ed3\u4e86\u73b0\u6709\u57fa\u4e8eTransformer\u7684LTSF\u89e3\u51b3\u65b9\u6848\u7684\u8bbe\u8ba1\u5143\u7d20\uff08\u89c1\u56fe1\uff09\u3002</p> <ul> <li>\u6307\u51fa Transformer \u5bf9\u4e8e\u65f6\u5e8f\u4efb\u52a1\u7684\u95ee\u9898\uff1a\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6&amp;\u7a7a\u95f4\u590d\u6742\u5ea6</li> <li>Informer\uff0c\u964d\u4f4e\u590d\u6742\u5ea6&amp;\u76f4\u63a5\u591a\u6b65\u9884\u6d4b\uff08mark\uff09</li> </ul> <p>Time series decomposition: For data preprocessing, normalization with zero-mean is common in TSF. Besides, Autoformer [28] first applies seasonal-trend decomposition behind each neural block, which is a standard method in time series analysis to make raw data more predictable [6, 13]. Specifically, they use a moving average kernel on the input sequence to extract the trend-cyclical component of the time series. The difference between the original sequence and the trend component is regarded as the seasonal component. On top of the decomposition scheme of Autoformer, FEDformer [31] further proposes the mixture of experts\u2019 strategies to mix the trend components extracted by moving average kernels with various kernel sizes.</p> <p>\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\uff1a\u5728\u6570\u636e\u9884\u5904\u7406\u4e2d\uff0c\u96f6\u5747\u503c\u5f52\u4e00\u5316\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u4e2d\u5f88\u5e38\u89c1\u3002\u6b64\u5916\uff0cAutoformer[28]\u9996\u6b21\u5728\u6bcf\u4e2a\u795e\u7ecf\u5757\u540e\u9762\u5e94\u7528\u5b63\u8282\u8d8b\u52bf\u5206\u89e3\uff0c\u8fd9\u662f\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u4f7f\u539f\u59cb\u6570\u636e\u66f4\u53ef\u9884\u6d4b\u7684\u6807\u51c6\u65b9\u6cd5[6, 13]\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4ed6\u4eec\u4f7f\u7528\u79fb\u52a8\u5e73\u5747\u6838\u5728\u8f93\u5165\u5e8f\u5217\u4e0a\u63d0\u53d6\u65f6\u95f4\u5e8f\u5217\u7684\u8d8b\u52bf\u5468\u671f\u6210\u5206\u3002\u539f\u59cb\u5e8f\u5217\u4e0e\u8d8b\u52bf\u6210\u5206\u4e4b\u95f4\u7684\u5dee\u503c\u88ab\u89c6\u4e3a\u5b63\u8282\u6210\u5206\u3002\u5728Autoformer\u7684\u5206\u89e3\u65b9\u6848\u57fa\u7840\u4e0a\uff0cFEDformer[31]\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u4e13\u5bb6\u6df7\u5408\u7b56\u7565\uff0c\u5c06\u901a\u8fc7\u4e0d\u540c\u6838\u5927\u5c0f\u7684\u79fb\u52a8\u5e73\u5747\u6838\u63d0\u53d6\u7684\u8d8b\u52bf\u6210\u5206\u8fdb\u884c\u6df7\u5408\u3002</p> <p>Fedformer \u662f\u5bf9 Autoformer \u7684\u6539\u8fdb\uff0c\u5f15\u5165\u4e86\u9891\u57df\u4fe1\u606f</p> <p>Input embedding strategies: The self-attention layer in the Transformer architecture cannot preserve the positional information of the time series. </p> <p>However, local positional information, i.e. the ordering of time series, is important. </p> <p>Besides, global temporal information, such as hierarchical timestamps (week, month, year) and agnostic timestamps (holidays and events), is also informative [30]. </p> <p>To enhance the temporal context of time-series inputs, a practical design in the SOTA Transformer-based methods is injecting several embeddings, like a fixed positional encoding, a channel projection embedding, and learnable temporal embeddings into the input sequence. </p> <p>\u662f\uff1a\u4f4d\u7f6e\u7f16\u7801\u3001\u901a\u9053\u5d4c\u5165\u3001\u65f6\u95f4\u5d4c\u5165</p> <p>Moreover, temporal embeddings with a temporal convolution layer [16] or learnable timestamps [28] are introduced.</p> <p>\u8fd9\u91cc\u662f\u5728\u8bf4\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u5d4c\u5165</p> <p>\u8f93\u5165\u5d4c\u5165\u7b56\u7565\uff1aTransformer\u67b6\u6784\u4e2d\u7684\u81ea\u6ce8\u610f\u529b\u5c42\u65e0\u6cd5\u4fdd\u7559\u65f6\u95f4\u5e8f\u5217\u7684\u4f4d\u7f6e\u4fe1\u606f\u3002\u7136\u800c\uff0c\u5c40\u90e8\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5373\u65f6\u95f4\u5e8f\u5217\u7684\u987a\u5e8f\uff0c\u662f\u91cd\u8981\u7684\u3002\u6b64\u5916\uff0c\u5168\u5c40\u65f6\u95f4\u4fe1\u606f\uff0c\u5982\u5c42\u6b21\u5316\u7684\u65f6\u95f4\u6233\uff08\u5468\u3001\u6708\u3001\u5e74\uff09\u548c\u4e0d\u53ef\u77e5\u7684\u65f6\u95f4\u6233\uff08\u5047\u671f\u548c\u4e8b\u4ef6\uff09\uff0c\u4e5f\u5177\u6709\u4fe1\u606f\u4ef7\u503c[30]\u3002\u4e3a\u4e86\u589e\u5f3a\u65f6\u95f4\u5e8f\u5217\u8f93\u5165\u7684\u65f6\u95f4\u4e0a\u4e0b\u6587\uff0c\u6700\u5148\u8fdb\u7684\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u4e2d\u4e00\u4e2a\u5b9e\u7528\u7684\u8bbe\u8ba1\u662f\u5c06\u51e0\u79cd\u5d4c\u5165\uff0c\u5982\u56fa\u5b9a\u7684\u4f4d\u7f6e\u7f16\u7801\u3001\u901a\u9053\u6295\u5f71\u5d4c\u5165\u548c\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u5d4c\u5165\u6ce8\u5165\u5230\u8f93\u5165\u5e8f\u5217\u4e2d\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u5177\u6709\u65f6\u95f4\u5377\u79ef\u5c42[16]\u6216\u53ef\u5b66\u4e60\u65f6\u95f4\u6233[28]\u7684\u65f6\u95f4\u5d4c\u5165\u3002</p> <p>Self-attention schemes: Transformers rely on the self-attention mechanism to extract the semantic dependencies between paired elements. Motivated by reducing the \\(O(L^2)\\) time and memory complexity of the vanilla Transformer, recent works propose two strategies for efficiency. </p> <p>\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff1aTransformer \u4f9d\u8d56\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6765\u63d0\u53d6\u6210\u5bf9\u5143\u7d20\u4e4b\u95f4\u7684\u8bed\u4e49\u4f9d\u8d56\u5173\u7cfb\u3002\u4e3a\u4e86\u964d\u4f4e\u539f\u59cb Transformer \u7684 \\(O(L^2)\\) \u65f6\u95f4\u548c\u5185\u5b58\u590d\u6742\u5ea6\uff0c\u6700\u8fd1\u7684\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e24\u79cd\u63d0\u9ad8\u6548\u7387\u7684\u7b56\u7565\u3002</p> <p>On the one hand, LogTrans and Pyraformer explicitly introduce a sparsity bias into the self-attention scheme. Specifically, LogTrans uses a Logsparse mask to reduce the computational complexity to \\(O(L \\log L)\\) while Pyraformer adopts pyramidal attention that captures hierarchically multi-scale temporal dependencies with an \\(O(L)\\) time and memory complexity. </p> <p>\u4ec0\u4e48\u53eb\u5728\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u5f15\u5165 \u7a00\u758f\u6027\u504f\u5dee</p> <p>\u4e00\u65b9\u9762\uff0cLogTrans \u548c Pyraformer \u660e\u786e\u5730\u5728\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u5f15\u5165\u4e86\u7a00\u758f\u6027\u504f\u5dee\u3002\u5177\u4f53\u6765\u8bf4\uff0cLogTrans \u4f7f\u7528 Logsparse \u63a9\u7801\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e\u5230 \\(O(L \\log L)\\)\uff0c\u800c Pyraformer \u91c7\u7528\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ee5 \\(O(L)\\) \u7684\u65f6\u95f4\u548c\u5185\u5b58\u590d\u6742\u5ea6\u6355\u83b7\u5c42\u6b21\u5316\u7684\u591a\u5c3a\u5ea6\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002</p> <p>On the other hand, Informer and FEDformer use the low-rank property in the self-attention matrix. Informer proposes a ProbSparse self-attention mechanism and a self-attention distilling operation to decrease the complexity to \\(O(L \\log L)\\), and FEDformer designs a Fourier enhanced block and a wavelet enhanced block with random selection to obtain \\(O(L)\\) complexity. Lastly, Autoformer designs a series-wise auto-correlation mechanism to replace the original self-attention layer.</p> <p>\u53e6\u4e00\u65b9\u9762\uff0cInformer \u548c FEDformer \u5728\u81ea\u6ce8\u610f\u529b\u77e9\u9635\u4e2d\u4f7f\u7528\u4e86\u4f4e\u79e9\u5c5e\u6027\u3002Informer \u63d0\u51fa\u4e86\u4e00\u79cd ProbSparse \u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u81ea\u6ce8\u610f\u529b\u84b8\u998f\u64cd\u4f5c\u6765\u964d\u4f4e\u590d\u6742\u5ea6\u81f3 \\(O(L \\log L)\\)\uff0c\u800c FEDformer \u8bbe\u8ba1\u4e86\u5085\u91cc\u53f6\u589e\u5f3a\u5757\u548c\u5c0f\u6ce2\u589e\u5f3a\u5757\uff0c\u901a\u8fc7\u968f\u673a\u9009\u62e9\u83b7\u5f97 \\(O(L)\\) \u590d\u6742\u5ea6\u3002\u6700\u540e\uff0cAutoformer \u8bbe\u8ba1\u4e86\u4e00\u79cd\u5e8f\u5217\u81ea\u76f8\u5173\u673a\u5236\u6765\u66ff\u4ee3\u539f\u59cb\u7684\u81ea\u6ce8\u610f\u529b\u5c42\u3002</p> <p>\u5176\u5b9e\u65f6\u95f4\u5e8f\u5217\u5355\u4e2a\u70b9\u7684\u4fe1\u606f\u662f\u975e\u5e38\u7a00\u758f\u7684\uff0c\u6240\u4ee5\u540e\u9762\u63d0\u51fa PatchTST \u6216\u8005\u8f6c\u4e8c\u7ef4\u628a\u4fe1\u606f\u5265\u79bb\u51fa\u6765\u4e5f\u662f\u5408\u7406\u7684</p> <p>Decoders: The vanilla Transformer decoder outputs sequences in an autoregressive manner, resulting in a slow inference speed and error accumulation effects, especially for long-term predictions. </p> <p>\u89e3\u7801\u5668\uff1a \u4f20\u7edf\u7684Transformer\u89e3\u7801\u5668\u4ee5\u81ea\u56de\u5f52\u65b9\u5f0f\u8f93\u51fa\u5e8f\u5217\uff0c\u5bfc\u81f4\u63a8\u7406\u901f\u5ea6\u6162\u548c\u8bef\u5dee\u7d2f\u79ef\u6548\u5e94\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u957f\u671f\u9884\u6d4b\u3002</p> <p>\u957f\u671f\u9884\u6d4b\u522b\u7528\u81ea\u56de\u5f52</p> <p>Informer designs a generative-style decoder for  DMS forecasting. Other Transformer variants employ similar DMS strategies. For instance, Pyraformer uses a fully-connected layer concatenating Spatio-temporal axes as the decoder. Autoformer  sums up two refined decomposed features from trend-cyclical components and the stacked auto-correlation mechanism for seasonal components to get the final prediction. FEDformer also uses a decomposition scheme with the proposed frequency attention block to decode the final results.</p> <p>Informer\u4e3a\u76f4\u63a5\u591a\u6b65\uff08DMS\uff09\u9884\u6d4b\u8bbe\u8ba1\u4e86\u751f\u6210\u5f0f\u89e3\u7801\u5668\u3002\u5176\u4ed6Transformer\u53d8\u4f53\u91c7\u7528\u7c7b\u4f3c\u7684DMS\u7b56\u7565\u3002\u4f8b\u5982\uff0cPyraformer\u4f7f\u7528\u5168\u8fde\u63a5\u5c42\u5c06\u65f6\u7a7a\u8f74\u8fde\u63a5\u8d77\u6765\u4f5c\u4e3a\u89e3\u7801\u5668\u3002Autoformer\u5c06\u8d8b\u52bf\u5468\u671f\u6210\u5206\u7684\u4e24\u4e2a\u7ec6\u5316\u5206\u89e3\u7279\u5f81\u548c\u5b63\u8282\u6210\u5206\u7684\u5806\u53e0\u81ea\u76f8\u5173\u673a\u5236\u76f8\u52a0\uff0c\u4ee5\u83b7\u5f97\u6700\u7ec8\u9884\u6d4b\u3002FEDformer\u4e5f\u4f7f\u7528\u5206\u89e3\u65b9\u6848\u548c\u63d0\u51fa\u7684\u9891\u7387\u6ce8\u610f\u529b\u5757\u6765\u89e3\u7801\u6700\u7ec8\u7ed3\u679c\u3002</p> <p>\u524d\u9762\u5206\u522b\u4ece\u4e0d\u540c\u7684\u65b9\u6cd5\u8bf4\u660eTransformer-based \u6a21\u578b</p> <ol> <li>Time series decomposition</li> <li>Input embedding strategies</li> <li>Self-attention schemes</li> <li>Decoders</li> </ol> <p>The premise of Transformer models is the semantic correlations between paired elements, while the self-attention mechanism itself is permutation-invariant, and its capability of modeling temporal relations largely depends on positional encodings associated with input tokens. </p> <p>Considering the raw numerical data in time series (e.g., stock prices or electricity values), there are hardly any point-wise semantic correlations between them. In time series modeling, we are mainly interested in the temporal relations among a continuous set of points, and the order of these elements instead of the paired relationship plays the most crucial role. While employing positional encoding and using tokens to embed sub-series facilitate preserving some ordering information, the nature of the permutation-invariant self-attention mechanism inevitably results in temporal information loss. Due to the above observations, we are interested in revisiting the effectiveness of Transformer-based LTSF solutions.</p> <p>Transformer\u6a21\u578b\u7684\u57fa\u7840\u662f\u6210\u5bf9\u5143\u7d20\u4e4b\u95f4\u7684\u8bed\u4e49\u76f8\u5173\u6027\uff0c\u800c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u672c\u8eab\u662f\u6392\u5217\u4e0d\u53d8\u7684\uff0c\u5176\u5bf9\u65f6\u95f4\u5173\u7cfb\u7684\u5efa\u6a21\u80fd\u529b\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u4e0e\u8f93\u5165\u6807\u8bb0\u76f8\u5173\u8054\u7684\u4f4d\u7f6e\u7f16\u7801\u3002\u8003\u8651\u5230\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u539f\u59cb\u6570\u503c\u6570\u636e\uff08\u4f8b\u5982\uff0c\u80a1\u7968\u4ef7\u683c\u6216\u7535\u529b\u503c\uff09\uff0c\u5b83\u4eec\u4e4b\u95f4\u51e0\u4e4e\u6ca1\u6709\u70b9\u5bf9\u70b9\u7684\u8bed\u4e49\u76f8\u5173\u6027\u3002\u5728\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u5173\u6ce8\u7684\u662f\u8fde\u7eed\u70b9\u96c6\u4e4b\u95f4\u7684\u65f6\u95f4\u5173\u7cfb\uff0c\u8fd9\u4e9b\u5143\u7d20\u7684\u987a\u5e8f\u800c\u975e\u6210\u5bf9\u5173\u7cfb\u8d77\u7740\u6700\u5173\u952e\u7684\u4f5c\u7528\u3002\u867d\u7136\u4f7f\u7528\u4f4d\u7f6e\u7f16\u7801\u548c\u4f7f\u7528\u6807\u8bb0\u6765\u5d4c\u5165\u5b50\u5e8f\u5217\u6709\u52a9\u4e8e\u4fdd\u7559\u4e00\u4e9b\u987a\u5e8f\u4fe1\u606f\uff0c\u4f46\u6392\u5217\u4e0d\u53d8\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u672c\u8d28\u4e0d\u53ef\u907f\u514d\u5730\u5bfc\u81f4\u65f6\u95f4\u4fe1\u606f\u7684\u4e22\u5931\u3002\u57fa\u4e8e\u4e0a\u8ff0\u89c2\u5bdf\uff0c\u6211\u4eec\u6709\u5174\u8da3\u91cd\u65b0\u5ba1\u89c6\u57fa\u4e8eTransformer\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u89e3\u51b3\u65b9\u6848\u7684\u6709\u6548\u6027\u3002</p> <p>\u8fd9\u6bb5\u6df1\u6709\u4f53\u4f1a\uff0c\u4f7f\u7528\u4e86\u4f4d\u7f6e\u7f16\u7801\uff0c\u6ce8\u610f\u529b\u673a\u5236\u7684\u7cbe\u5ea6\u4f1a\u6781\u5927\u7684\u63d0\u9ad8\u3002\u505a\u8fc7\u5b9e\u9a8c\u3002</p> <p></p> <p>\u56fe 1 \u5c55\u793a\u4e86\u73b0\u6709\u7684\u57fa\u4e8e Transformer \u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u89e3\u51b3\u65b9\u6848\u7684\u6d41\u7a0b\u3002\u6574\u4e2a\u6d41\u7a0b\u5206\u4e3a\u56db\u4e2a\u4e3b\u8981\u9636\u6bb5\uff1a\u9884\u5904\u7406\uff08Preprocessing\uff09\u3001\u5d4c\u5165\uff08Embedding\uff09\u3001\u7f16\u7801\u5668\uff08Encoder\uff09\u548c\u89e3\u7801\u5668\uff08Decoder\uff09\u3002</p> <p>(a) \u9884\u5904\u7406\uff08Preprocessing\uff09\uff1a - \u5305\u62ec\u5f52\u4e00\u5316\uff08Normalization\uff09\u548c\u65f6\u95f4\u6233\u51c6\u5907\uff08Timestamp preparation\uff09\u3002 - \u53ef\u9009\u64cd\u4f5c\u6709\u5b63\u8282\u8d8b\u52bf\u5206\u89e3\uff08Seasonal-trend decomposition\uff09\u3002</p> <p>(b) \u5d4c\u5165\uff08Embedding\uff09\uff1a - \u5305\u62ec\u901a\u9053\u6295\u5f71\uff08Channel projection\uff09\u548c\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801\uff08Fixed position\uff09\u3002 - \u53ef\u9009\u64cd\u4f5c\u6709\u672c\u5730\u65f6\u95f4\u6233\uff08Local timestamp\uff09\u548c\u5168\u5c40\u65f6\u95f4\u6233\uff08Global timestamp\uff09\u3002</p> <p>(c) \u7f16\u7801\u5668\uff08Encoder\uff09\uff1a - \u5305\u62ec LogSparse \u548c\u5377\u79ef\u81ea\u6ce8\u610f\u529b\uff08LogSparse and convolutional self-attention @LogTrans\uff09\u3002 - \u5305\u62ec ProbSparse \u548c\u84b8\u998f\u81ea\u6ce8\u610f\u529b\uff08ProbSparse and distilling self-attention @Informer\uff09\u3002 - \u5305\u62ec\u5e8f\u5217\u81ea\u76f8\u5173\u4e0e\u5206\u89e3\uff08Series auto-correlation with decomposition @Autoformer\uff09\u3002 - \u5305\u62ec\u591a\u5206\u8fa8\u7387\u91d1\u5b57\u5854\u6ce8\u610f\u529b\uff08Multi-resolution pyramidal attention @Pyraformer\uff09\u3002 - \u5305\u62ec\u9891\u7387\u589e\u5f3a\u5757\u4e0e\u5206\u89e3\uff08Frequency enhanced block with decomposition @FEDformer\uff09\u3002</p> <p>(d) \u89e3\u7801\u5668\uff08Decoder\uff09\uff1a - \u5305\u62ec\u8fed\u4ee3\u591a\u6b65\uff08IMS\uff09\u9884\u6d4b\uff08Iterated Multi-Step (IMS) @LogTrans\uff09\u3002 - \u5305\u62ec\u76f4\u63a5\u591a\u6b65\uff08DMS\uff09\u9884\u6d4b\uff08Direct Multi-Step (DMS) @Informer\uff09\u3002 - \u5305\u62ec DMS \u4e0e\u81ea\u76f8\u5173\u548c\u5206\u89e3\uff08DMS with auto-correlation and decomposition @Autoformer\uff09\u3002 - \u5305\u62ec DMS \u6cbf\u65f6\u7a7a\u7ef4\u5ea6\uff08DMS along spatio-temporal dimension @Pyraformer\uff09\u3002 - \u5305\u62ec DMS \u4e0e\u9891\u7387\u6ce8\u610f\u529b\u548c\u5206\u89e3\uff08DMS with frequency attention and decomposition @FEDformer\uff09\u3002</p> <p>\u56fe\u4e2d\u5b9e\u7ebf\u6846\u8868\u793a\u57fa\u672c\u64cd\u4f5c\uff0c\u865a\u7ebf\u6846\u8868\u793a\u53ef\u9009\u64cd\u4f5c\u3002(c) \u548c (d) \u90e8\u5206\u9488\u5bf9\u4e0d\u540c\u7684\u65b9\u6cd5\u6709\u4e0d\u540c\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u5206\u522b\u5bf9\u5e94\u6587\u732e [16, 18, 28, 30, 31] \u4e2d\u7684\u65b9\u6cd5\u3002</p> <p>\u5df2\u7ecf\u8bc1\u660e\u4e86\u5e76\u884c\u591a\u6b65\u9884\u6d4b\u6548\u679c\u66f4\u597d</p>"},{"location":"literature/TSP/2_DLinear/#4-an-embarrassingly-simple-baseline","title":"4. An Embarrassingly Simple Baseline","text":"<p>In the experiments of existing Transformer-based LTSF solutions (\\(T \\gg 1\\)), all the compared (non-Transformer) baselines are IMS forecasting techniques, which are known to suffer from significant error accumulation effects. We hypothesize that the performance improvements in these works are largely due to the DMS strategy used in them.</p> <p>\u5728\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u89e3\u51b3\u65b9\u6848\uff08\\(T \\gg 1\\)\uff09\u7684\u5b9e\u9a8c\u4e2d\uff0c\u6240\u6709\u6bd4\u8f83\u7684\uff08\u975eTransformer\uff09\u57fa\u7ebf\u90fd\u662f\u8fed\u4ee3\u591a\u6b65\uff08IMS\uff09\u9884\u6d4b\u6280\u672f\uff0c\u8fd9\u4e9b\u6280\u672f\u5df2\u77e5\u4f1a\u906d\u53d7\u663e\u8457\u7684\u8bef\u5dee\u7d2f\u79ef\u6548\u5e94\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u5de5\u4f5c\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u662f\u7531\u4e8e\u5176\u4e2d\u4f7f\u7528\u7684\u76f4\u63a5\u591a\u6b65\uff08DMS\uff09\u7b56\u7565\u3002</p> <p>To validate this hypothesis, we present the simplest DMS model via a temporal linear layer, named LTSF-Linear, as a baseline for comparison. </p> <p>The basic formulation of LTSF-Linear directly regresses historical time series for future prediction via a weighted sum operation (as illustrated in Figure 2). </p> <p>The mathematical expression is \\(\\hat{X}_i = W X_i\\), where \\(W \\in \\mathbb{R}^{T \\times L}\\) is a linear layer along the temporal axis. \\(\\hat{X}_i\\) and \\(X_i\\) are the prediction and input for each \\(i^{th}\\) variate. Note that LTSF-Linear shares weights across different variates and does not model any spatial correlations.</p> <p>\u4e3a\u4e86\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\uff0c\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u65f6\u95f4\u7ebf\u6027\u5c42\u63d0\u51fa\u4e86\u6700\u7b80\u5355\u7684\u76f4\u63a5\u591a\u6b65\uff08DMS\uff09\u6a21\u578b\uff0c\u547d\u540d\u4e3aLTSF-Linear\uff0c\u4f5c\u4e3a\u6bd4\u8f83\u7684\u57fa\u7ebf\u3002LTSF-Linear\u7684\u57fa\u672c\u516c\u5f0f\u76f4\u63a5\u901a\u8fc7\u52a0\u6743\u6c42\u548c\u64cd\u4f5c\u56de\u5f52\u5386\u53f2\u65f6\u95f4\u5e8f\u5217\u4ee5\u8fdb\u884c\u672a\u6765\u9884\u6d4b\uff08\u5982\u56fe2\u6240\u793a\uff09\u3002\u6570\u5b66\u8868\u8fbe\u5f0f\u4e3a \\(\\hat{X}_i = W X_i\\)\uff0c\u5176\u4e2d \\(W \\in \\mathbb{R}^{T \\times L}\\) \u662f\u6cbf\u65f6\u95f4\u8f74\u7684\u7ebf\u6027\u5c42\u3002\\(\\hat{X}_i\\) \u548c \\(X_i\\) \u5206\u522b\u662f\u6bcf\u4e2a\u7b2c \\(i\\) \u4e2a\u53d8\u91cf\u7684\u9884\u6d4b\u548c\u8f93\u5165\u3002\u8bf7\u6ce8\u610f\uff0cLTSF-Linear\u5728\u4e0d\u540c\u53d8\u91cf\u4e4b\u95f4\u5171\u4eab\u6743\u91cd\uff0c\u5e76\u4e14\u4e0d\u5efa\u6a21\u4efb\u4f55\u7a7a\u95f4\u76f8\u5173\u6027\u3002</p> <p></p> <p>LTSF-Linear is a set of linear models. Vanilla Linear is a one-layer linear model. To handle time series across different domains (e.g., finance, traffic, and energy domains), we further introduce two variants with two preprocessing methods, named DLinear and NLinear.</p> <p>LTSF-Linear\u662f\u4e00\u7ec4\u7ebf\u6027\u6a21\u578b\u3002\u5176\u4e2d\uff0cVanilla Linear\u662f\u4e00\u4e2a\u5355\u5c42\u7ebf\u6027\u6a21\u578b\u3002\u4e3a\u4e86\u5904\u7406\u4e0d\u540c\u9886\u57df\uff08\u4f8b\u5982\u91d1\u878d\u3001\u4ea4\u901a\u548c\u80fd\u6e90\u9886\u57df\uff09\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u5f15\u5165\u4e86\u4e24\u79cd\u9884\u5904\u7406\u65b9\u6cd5\u7684\u4e24\u4e2a\u53d8\u4f53\uff0c\u5206\u522b\u547d\u540d\u4e3aDLinear\u548cNLinear\u3002</p> <p>Specifically, DLinear is a combination of a Decomposition scheme used in Autoformer and FEDformer with linear layers. It first decomposes a raw data input into a trend component by a moving average kernel and a remainder (seasonal) component. Then, two one-layer linear layers are applied to each component, and we sum up the two features to get the final prediction. By explicitly handling trend, DLinear enhances the performance of a vanilla linear when there is a clear trend in the data.</p> <p>\u5177\u4f53\u6765\u8bf4\uff0cDLinear\u662f\u7ed3\u5408\u4e86Autoformer\u548cFEDformer\u4e2d\u4f7f\u7528\u7684\u5206\u89e3\u65b9\u6848\u4e0e\u7ebf\u6027\u5c42\u7684\u7ec4\u5408\u3002\u5b83\u9996\u5148\u901a\u8fc7\u79fb\u52a8\u5e73\u5747\u6838\u5c06\u539f\u59cb\u6570\u636e\u8f93\u5165\u5206\u89e3\u4e3a\u8d8b\u52bf\u6210\u5206\u548c\u5269\u4f59\uff08\u5b63\u8282\u6027\uff09\u6210\u5206\u3002\u7136\u540e\uff0c\u5bf9\u6bcf\u4e2a\u6210\u5206\u5e94\u7528\u4e24\u4e2a\u5355\u5c42\u7ebf\u6027\u5c42\uff0c\u5e76\u5c06\u4e24\u4e2a\u7279\u5f81\u76f8\u52a0\u4ee5\u83b7\u5f97\u6700\u7ec8\u9884\u6d4b\u3002\u901a\u8fc7\u660e\u786e\u5904\u7406\u8d8b\u52bf\uff0c\u5f53\u6570\u636e\u4e2d\u5b58\u5728\u660e\u663e\u8d8b\u52bf\u65f6\uff0cDLinear\u589e\u5f3a\u4e86\u666e\u901a\u7ebf\u6027\u6a21\u578b\u7684\u6027\u80fd\u3002</p> <p>\u5e8f\u5217\u5206\u89e3\u6709\u7528</p> <ul> <li>Meanwhile, to boost the performance of LTSF-Linear when there is a distribution shift in the dataset, NLinear first subtracts the input by the last value of the sequence. Then, the input goes through a linear layer, and the subtracted part is added back before making the final prediction. The subtraction and addition in NLinear are a simple normalization for the input sequence.</li> </ul> <p>\u540c\u65f6\uff0c\u4e3a\u4e86\u5728\u6570\u636e\u96c6\u4e2d\u51fa\u73b0\u5206\u5e03\u504f\u79fb\u65f6\u63d0\u5347LTSF-Linear\u7684\u6027\u80fd\uff0cNLinear\u9996\u5148\u5c06\u8f93\u5165\u5e8f\u5217\u7684\u6700\u540e\u4e00\u4e2a\u503c\u4ece\u8f93\u5165\u4e2d\u51cf\u53bb\u3002\u7136\u540e\uff0c\u8f93\u5165\u7ecf\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\uff0c\u6700\u540e\u5728\u505a\u51fa\u6700\u7ec8\u9884\u6d4b\u524d\u5c06\u51cf\u53bb\u7684\u90e8\u5206\u52a0\u56de\u3002NLinear\u4e2d\u7684\u51cf\u6cd5\u548c\u52a0\u6cd5\u662f\u5bf9\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u7684\u4e00\u79cd\u7b80\u5355\u5f52\u4e00\u5316\u5904\u7406\u3002</p> <p>\u51cf\u53bb\u6700\u540e\u4e00\u4e2a\u503c\uff0c\u51cf\u5c11\u5206\u5e03\u504f\u79fb</p>"},{"location":"literature/TSP/2_DLinear/#5-experiments","title":"5. Experiments","text":"<p>\u6240\u4ee5\u8bf4\u8fd9\u7bc7\u8bba\u6587\u4e00\u5b9a\u8981\u8bfb\u8bfb\uff0c\u56e0\u4e3a\u5b83\u90fd\u6ca1\u6709method \u90e8\u5206\uff0c\u505a\u4e86\u5f88\u591a\u5b9e\u9a8c</p>"},{"location":"literature/TSP/2_DLinear/#51-experimental-settings","title":"5.1. Experimental Settings","text":"<p>Dataset. We conduct extensive experiments on nine widely-used real-world datasets, including ETT (Electricity Transformer Temperature) [30] (ETTh1, ETTh2, ETTm1, ETTm2), Traffic, Electricity, Weather, ILI, ExchangeRate [15]. All of them are multivariate time series. We leave data descriptions in the Appendix.</p> <p>\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c</p> <p></p> <p>Evaluation metric. Following previous works [28, 30, 31], we use Mean Squared Error (MSE) and Mean Absolute Error (MAE) as the core metrics to compare performance. </p> <p>Compared methods. We include five recent Transformer-based methods: FEDformer [31], Autoformer [28], Informer [30], Pyraformer [18], and LogTrans [16]. Besides, we include a naive DMS method: Closest Repeat (Repeat), which repeats the last value in the look-back window, as another simple baseline. Since there are two variants of FEDformer, we compare the one with better accuracy (FEDformer-f via Fourier transform).</p> <p>\u6bd4\u8f83\u65b9\u6cd5\u3002 \u6211\u4eec\u7eb3\u5165\u4e86\u4e94\u79cd\u8fd1\u671f\u7684\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\uff1aFEDformer[31]\u3001Autoformer[28]\u3001Informer[30]\u3001Pyraformer[18]\u548cLogTrans[16]\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5305\u542b\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u76f4\u63a5\u591a\u6b65\uff08DMS\uff09\u65b9\u6cd5\uff1aClosest Repeat\uff08Repeat\uff09\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u91cd\u590d\u56de\u6eaf\u7a97\u53e3\u4e2d\u7684\u6700\u540e\u4e00\u4e2a\u503c\u6765\u4f5c\u4e3a\u53e6\u4e00\u4e2a\u7b80\u5355\u7684\u57fa\u7ebf\u3002\u7531\u4e8eFEDformer\u6709\u4e24\u79cd\u53d8\u4f53\uff0c\u6211\u4eec\u6bd4\u8f83\u7684\u662f\u51c6\u786e\u5ea6\u66f4\u9ad8\u7684\u90a3\u4e00\u79cd\uff08\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u7684FEDformer-f\uff09\u3002</p>"},{"location":"literature/TSP/2_DLinear/#52-comparison-with-transformers","title":"5.2. Comparison with Transformers","text":"<p>Quantitative results. In Table 2, we extensively evaluate all mentioned Transformers on nine benchmarks, following the experimental setting of previous work [28, 30, 31]. Surprisingly, the performance of LTSF-Linear surpasses the SOTA FEDformer in most cases by 20% \u223c 50% improvements on the multivariate forecasting, where LTSFLinear even does not model correlations among variates. For different time series benchmarks, NLinear and DLinear show the superiority to handle the distribution shift and trend-seasonality features. We also provide results for univariate forecasting of ETT datasets in the Appendix, where LTSF-Linear still consistently outperforms Transformerbased LTSF solutions by a large margin.</p> <p>\u5b9a\u91cf\u7ed3\u679c\u3002 \u5728\u88682\u4e2d\uff0c\u6211\u4eec\u6839\u636e\u4e4b\u524d\u5de5\u4f5c[28, 30, 31]\u7684\u5b9e\u9a8c\u8bbe\u7f6e\uff0c\u5bf9\u6240\u6709\u63d0\u5230\u7684Transformer\u6a21\u578b\u5728\u4e5d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u8bc4\u4f30\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0cLTSF-Linear\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u8d85\u8fc7\u4e86\u6700\u5148\u8fdb\u7684FEDformer\uff0c\u5176\u5728\u591a\u53d8\u91cf\u9884\u6d4b\u4e0a\u7684\u6539\u8fdb\u5e45\u5ea6\u8fbe\u5230\u4e8620%\u81f350%\uff0c\u5c3d\u7ba1LTSF-Linear\u751a\u81f3\u6ca1\u6709\u5bf9\u53d8\u91cf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u8fdb\u884c\u5efa\u6a21\u3002\u5bf9\u4e8e\u4e0d\u540c\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u51c6\u6d4b\u8bd5\uff0cNLinear\u548cDLinear\u663e\u793a\u51fa\u5728\u5904\u7406\u5206\u5e03\u504f\u79fb\u548c\u8d8b\u52bf\u5b63\u8282\u6027\u7279\u5f81\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002\u6211\u4eec\u8fd8\u5728\u9644\u5f55\u4e2d\u63d0\u4f9b\u4e86ETT\u6570\u636e\u96c6\u7684\u5355\u53d8\u91cf\u9884\u6d4b\u7ed3\u679c\uff0c\u5176\u4e2dLTSF-Linear\u4ecd\u7136\u4ee5\u8f83\u5927\u4f18\u52bf\u6301\u7eed\u8d85\u8d8a\u57fa\u4e8eTransformer\u7684LTSF\u89e3\u51b3\u65b9\u6848\u3002</p> <p></p> <p>\u88682. \u591a\u53d8\u91cf\u957f\u671f\u9884\u6d4b\u8bef\u5dee\u4ee5\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u548c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u8868\u793a\uff0c\u6570\u503c\u8d8a\u4f4e\u8d8a\u597d\u3002\u5176\u4e2d\uff0cILI\u6570\u636e\u96c6\u7684\u9884\u6d4b\u8303\u56f4 \\(T\\) \u5c5e\u4e8e \\(\\{24, 36, 48, 60\\}\\)\u3002\u5bf9\u4e8e\u5176\u4ed6\u6570\u636e\u96c6\uff0c\\(T\\) \u5c5e\u4e8e \\(\\{96, 192, 336, 720\\}\\)\u3002Repeat\u65b9\u6cd5\u901a\u8fc7\u91cd\u590d\u56de\u6eaf\u7a97\u53e3\u4e2d\u7684\u6700\u540e\u4e00\u4e2a\u503c\u6765\u8fdb\u884c\u9884\u6d4b\u3002\u6700\u4f73\u7ed3\u679c\u4ee5\u7c97\u4f53\u663e\u793a\uff0c\u800c\u57fa\u4e8eTransformer\u7684\u6700\u4f73\u7ed3\u679c\u5219\u4ee5\u4e0b\u5212\u7ebf\u6807\u51fa\u3002\u76f8\u5e94\u5730\uff0cIMP.\u8868\u793a\u4e0e\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u76f8\u6bd4\uff0c\u7ebf\u6027\u6a21\u578b\u7684\u6700\u4f73\u7ed3\u679c\u3002</p> <p>FEDformer achieves competitive forecasting accuracy on ETTh1. This because FEDformer employs classical time series analysis techniques such as frequency processing, which brings in time series inductive bias and benefits the ability of temporal feature extraction. In summary, these results reveal that existing complex Transformer-based LTSF solutions are not seemingly effective on the existing nine benchmarks while LTSF-Linear can be a powerful baseline.</p> <p>FEDformer\u5728ETTh1\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u8fd9\u662f\u56e0\u4e3aFEDformer\u91c7\u7528\u4e86\u8bf8\u5982\u9891\u7387\u5904\u7406\u7b49\u7ecf\u5178\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u6280\u672f\uff0c\u8fd9\u4e9b\u6280\u672f\u5f15\u5165\u4e86\u65f6\u95f4\u5e8f\u5217\u7684\u5f52\u7eb3\u504f\u597d\uff0c\u5e76\u6709\u52a9\u4e8e\u65f6\u95f4\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\u3002\u603b\u7ed3\u6765\u8bf4\uff0c\u8fd9\u4e9b\u7ed3\u679c\u63ed\u793a\u4e86\u73b0\u6709\u7684\u590d\u6742\u57fa\u4e8eTransformer\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u89e3\u51b3\u65b9\u6848\u5728\u73b0\u6709\u7684\u4e5d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f3c\u4e4e\u5e76\u4e0d\u5341\u5206\u6709\u6548\uff0c\u800cLTSF-Linear\u53ef\u4ee5\u6210\u4e3a\u4e00\u4e2a\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u3002</p> <p>Another interesting observation is that even though the naive Repeat method shows worse results when predicting long-term seasonal data (e.g., Electricity and Traffic), it surprisingly outperforms all Transformer-based methods on Exchange-Rate (around 45%). This is mainly caused by the wrong prediction of trends in Transformer-based solutions, which may overfit toward sudden change noises in the training data, resulting in significant accuracy degradation (see Figure 3(b)). Instead, Repeat does not have the bias.</p> <p>\u53e6\u4e00\u4e2a\u6709\u8da3\u7684\u89c2\u5bdf\u662f\uff0c\u5c3d\u7ba1\u6734\u7d20\u7684Repeat\u65b9\u6cd5\u5728\u9884\u6d4b\u957f\u671f\u5b63\u8282\u6027\u6570\u636e\uff08\u4f8b\u5982\uff0c\u7535\u529b\u548c\u4ea4\u901a\uff09\u65f6\u8868\u73b0\u66f4\u5dee\uff0c\u4f46\u5b83\u5728\u6c47\u7387\uff08Exchange-Rate\uff09\u4e0a\u610f\u5916\u5730\u4f18\u4e8e\u6240\u6709\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\uff08\u5927\u7ea645%\uff09\u3002\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u8d8b\u52bf\u7684\u9519\u8bef\u9884\u6d4b\uff0c\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\u53ef\u80fd\u8fc7\u5ea6\u62df\u5408\u8bad\u7ec3\u6570\u636e\u4e2d\u7a81\u7136\u53d8\u5316\u7684\u566a\u58f0\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u51c6\u786e\u6027\u4e0b\u964d\uff08\u89c1\u56fe3(b)\uff09\u3002\u76f8\u53cd\uff0cRepeat\u65b9\u6cd5\u6ca1\u6709\u8fd9\u79cd\u504f\u5dee\u3002</p> <p>Qualitative results. As shown in Figure 3, we plot the prediction results on three selected time series datasets with Transformer-based solutions and LTSF-Linear: Electricity (Sequence 1951, Variate 36), Exchange-Rate (Sequence 676, Variate 3), and ETTh2 ( Sequence 1241, Variate 2), where these datasets have different temporal patterns. </p> <p>When the input length is 96 steps, and the output horizon is 336 steps, Transformers [28, 30, 31] fail to capture the scale and bias of the future data on Electricity and ETTh2. </p> <p>Moreover, they can hardly predict a proper trend on aperiodic data such as Exchange-Rate. </p> <p>These phenomena further indicate the inadequacy of existing Transformer-based solutions for the LTSF task.</p> <p>\u5b9a\u6027\u7ed3\u679c\u3002 \u5982\u56fe3\u6240\u793a\uff0c\u6211\u4eec\u7ed8\u5236\u4e86\u4e09\u4e2a\u9009\u5b9a\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u5177\u6709\u4e0d\u540c\u7684\u65f6\u95f4\u6a21\u5f0f\uff1a\u7535\u529b\uff08Sequence 1951, Variate 36\uff09\u3001\u6c47\u7387\uff08Sequence 676, Variate 3\uff09\u548cETTh2\uff08Sequence 1241, Variate 2\uff09\uff0c\u5e76\u5c06\u5176\u4e0e\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u548cLTSF-Linear\u8fdb\u884c\u6bd4\u8f83\u3002\u5f53\u8f93\u5165\u957f\u5ea6\u4e3a96\u6b65\uff0c\u8f93\u51fa\u8303\u56f4\u4e3a336\u6b65\u65f6\uff0cTransformers[28, 30, 31]\u672a\u80fd\u6355\u6349\u5230\u7535\u529b\u548cETTh2\u6570\u636e\u7684\u89c4\u6a21\u548c\u504f\u5dee\u3002\u6b64\u5916\uff0c\u5b83\u4eec\u51e0\u4e4e\u65e0\u6cd5\u9884\u6d4b\u8bf8\u5982\u6c47\u7387\u8fd9\u6837\u7684\u975e\u5468\u671f\u6027\u6570\u636e\u7684\u9002\u5f53\u8d8b\u52bf\u3002\u8fd9\u4e9b\u73b0\u8c61\u8fdb\u4e00\u6b65\u8868\u660e\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u4efb\u52a1\u7684\u4e0d\u8db3\u3002</p>"},{"location":"literature/TSP/2_DLinear/#53-more-analyses-on-ltsf-transformers","title":"5.3. More Analyses on LTSF-Transformers","text":"<p>\u8fd9\u90e8\u5206\u7684\u8109\u7edc\uff1a</p> <ol> <li>Can existing LTSF-Transformers extract temporal relations well from longer input sequences? \u56de\u6eaf\u7a97\u53e3\u7684\u957f\u5ea6</li> <li>What can be learned for long-term forecasting?\uff08close input&amp;far input\uff09</li> <li>Are the self-attention scheme effective for LTSF?\u590d\u6742\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u662f\u5426\u6709\u7528</li> <li>Can existing LTSF-Transformers preserve temporal order well?\u73b0\u6709\u7684 Transformer \u6a21\u578b\u662f\u5426\u4fdd\u5b58\u4e86\u65f6\u95f4\u987a\u5e8f</li> <li>How effective are different embedding strategies?\u5d4c\u5165\u7b56\u7565\u7684\u8ba8\u8bba</li> <li>Is training data size a limiting factor for existing LTSFTransformers?\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u89c4\u6a21\u5927\u5c0f\u662f\u5426\u5bf9\u6a21\u578b\u6709\u663e\u8457\u5f71\u54cd</li> <li>Is efficiency really a top-level priority?</li> </ol> <p>\u4f5c\u8005\u63d0\u51fa\u4e86 6 \u4e2a\u95ee\u9898\uff0c\u5e76\u4e14\u5206\u522b\u8fdb\u884c\u5b9e\u9a8c</p>"},{"location":"literature/TSP/2_DLinear/#1","title":"(1)\u56de\u6eaf\u7a97\u53e3\u7684\u957f\u5ea6","text":"<p>Can existing LTSF-Transformers extract temporal relations well from longer input sequences? </p> <p>The size of the look-back window greatly impacts forecasting accuracy as it determines how much we can learn from historical data. Generally speaking, a powerful TSF model with a strong temporal relation extraction capability should be able to achieve better results with larger look-back window sizes.</p> <p>\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u6a21\u578b\u80fd\u5426\u5f88\u597d\u5730\u4ece\u8f83\u957f\u7684\u8f93\u5165\u5e8f\u5217\u4e2d\u63d0\u53d6\u65f6\u95f4\u5173\u7cfb\uff1f</p> <p>\u56de\u6eaf\u7a97\u53e3\u7684\u5927\u5c0f\u5bf9\u9884\u6d4b\u51c6\u786e\u6027\u6709\u5f88\u5927\u5f71\u54cd\uff0c\u56e0\u4e3a\u5b83\u51b3\u5b9a\u4e86\u6211\u4eec\u53ef\u4ee5\u4ece\u5386\u53f2\u6570\u636e\u4e2d\u5b66\u5230\u591a\u5c11\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u4e00\u4e2a\u5f3a\u5927\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u6a21\u578b\u5982\u679c\u5177\u6709\u5f3a\u5927\u7684\u65f6\u95f4\u5173\u7cfb\u63d0\u53d6\u80fd\u529b\uff0c\u5e94\u8be5\u80fd\u591f\u5728\u66f4\u5927\u7684\u56de\u6eaf\u7a97\u53e3\u5c3a\u5bf8\u4e0b\u53d6\u5f97\u66f4\u597d\u7684\u7ed3\u679c\u3002\u7136\u800c\uff0c\u73b0\u6709\u7814\u7a76\u8868\u660e\uff0c\u5f53\u56de\u6eaf\u7a97\u53e3\u5c3a\u5bf8\u589e\u5927\u65f6\uff0c\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u7684\u6027\u80fd\u4f1a\u6076\u5316\u6216\u4fdd\u6301\u7a33\u5b9a\u3002\u8fd9\u8fdb\u4e00\u6b65\u8868\u660e\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u4efb\u52a1\u7684\u4e0d\u8db3\u3002</p> <p>To study the impact of input look-back window sizes, we conduct experiments with \\(L \\in \\{24, 48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720\\}\\) for long-term forecasting (\\(T=720\\)). </p> <p>Figure 4 demonstrates the MSE results on two datasets. </p> <p>Similar to the observations from previous studies [27, 30], existing Transformer-based models\u2019 performance deteriorates or stays stable when the look-back window size increases. </p> <p>In contrast, the performances of all LTSF-Linear are significantly boosted with the increase of look-back window size. Thus, existing solutions tend to overfit temporal noises instead of extracting temporal information if given a longer sequence, and the input size 96 is exactly suitable for most Transformers.</p> <p>\u4e3a\u4e86\u7814\u7a76\u8f93\u5165\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u7684\u5f71\u54cd\uff0c\u6211\u4eec\u9488\u5bf9\u957f\u671f\u9884\u6d4b (\\(T=720\\)) \u8fdb\u884c\u4e86 \\(L \\in \\{24, 48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720\\}\\) \u7684\u5b9e\u9a8c\u3002\u56fe4\u5c55\u793a\u4e86\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u7684MSE\u7ed3\u679c\u3002\u4e0e\u4e4b\u524d\u7814\u7a76[27, 30]\u7684\u89c2\u5bdf\u7ed3\u679c\u76f8\u4f3c\uff0c\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u5728\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u589e\u52a0\u65f6\u6027\u80fd\u4f1a\u6076\u5316\u6216\u4fdd\u6301\u7a33\u5b9a\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6240\u6709LTSF-Linear\u7684\u6027\u80fd\u968f\u7740\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u7684\u589e\u52a0\u800c\u663e\u8457\u63d0\u5347\u3002</p> <p>\u56e0\u6b64\uff0c\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u5728\u7ed9\u5b9a\u66f4\u957f\u5e8f\u5217\u65f6\u5f80\u5f80\u4f1a\u8fc7\u5ea6\u62df\u5408\u65f6\u95f4\u566a\u58f0\uff0c\u800c\u4e0d\u662f\u63d0\u53d6\u65f6\u95f4\u4fe1\u606f\uff0c\u8f93\u5165\u5927\u5c0f96\u5bf9\u4e8e\u5927\u591a\u6570Transformer\u6765\u8bf4\u6070\u597d\u5408\u9002\u3002</p> <p> </p> <p>\u56fe3\u5c55\u793a\u4e86\u4e94\u4e2a\u6a21\u578b\u5728\u4e09\u4e2a\u4e0d\u540c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u7684\u957f\u671f\u9884\u6d4b\u8f93\u51fa\uff08Y\u8f74\uff09\u4e0e\u771f\u5b9e\u503c\uff08GrowthTruth\uff09\u7684\u5bf9\u6bd4\u3002\u8fd9\u4e9b\u6570\u636e\u96c6\u5206\u522b\u662f\u7535\u529b\uff08Electricity\uff09\u3001\u6c47\u7387\uff08Exchange-Rate\uff09\u548cETTh2\u3002X\u8f74\u4ee3\u8868\u65f6\u95f4\u5e8f\u5217\u7684\u7d22\u5f15\u3002</p> <ul> <li> <p>\u7535\u529b\uff08Electricity\uff09\uff1a\u5728\u7535\u529b\u6570\u636e\u96c6\u4e0a\uff0cDLinear\u6a21\u578b\uff08\u9ec4\u8272\u7ebf\uff09\u548cFEDformer\uff08\u9ec4\u8272\u7ebf\uff09\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u503c\uff08\u7ea2\u8272\u7ebf\uff09\u8f83\u4e3a\u63a5\u8fd1\uff0c\u5c24\u5176\u662f\u5728\u9884\u6d4b\u7684\u524d\u534a\u90e8\u5206\u3002Informer\uff08\u84dd\u8272\u7ebf\uff09\u548cAutoformer\uff08\u6d45\u84dd\u8272\u7ebf\uff09\u7684\u9884\u6d4b\u7ed3\u679c\u5728\u67d0\u4e9b\u533a\u57df\u504f\u79bb\u771f\u5b9e\u503c\u8f83\u5927\u3002</p> </li> <li> <p>\u6c47\u7387\uff08Exchange-Rate\uff09\uff1a\u5728\u6c47\u7387\u6570\u636e\u96c6\u4e0a\uff0cDLinear\u6a21\u578b\uff08\u9ec4\u8272\u7ebf\uff09\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u503c\uff08\u7ea2\u8272\u7ebf\uff09\u6700\u4e3a\u63a5\u8fd1\uff0c\u5c24\u5176\u662f\u5728\u9884\u6d4b\u7684\u540e\u534a\u90e8\u5206\u3002FEDformer\uff08\u9ec4\u8272\u7ebf\uff09\u548cInformer\uff08\u84dd\u8272\u7ebf\uff09\u7684\u9884\u6d4b\u7ed3\u679c\u5728\u67d0\u4e9b\u533a\u57df\u504f\u79bb\u771f\u5b9e\u503c\u8f83\u5927\u3002</p> </li> <li> <p>ETTh2\uff1a\u5728ETTh2\u6570\u636e\u96c6\u4e0a\uff0cDLinear\u6a21\u578b\uff08\u9ec4\u8272\u7ebf\uff09\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u503c\uff08\u7ea2\u8272\u7ebf\uff09\u8f83\u4e3a\u63a5\u8fd1\uff0c\u5c24\u5176\u662f\u5728\u9884\u6d4b\u7684\u4e2d\u95f4\u90e8\u5206\u3002Informer\uff08\u84dd\u8272\u7ebf\uff09\u548cAutoformer\uff08\u6d45\u84dd\u8272\u7ebf\uff09\u7684\u9884\u6d4b\u7ed3\u679c\u5728\u67d0\u4e9b\u533a\u57df\u504f\u79bb\u771f\u5b9e\u503c\u8f83\u5927\u3002</p> </li> </ul> <p>\u603b\u4f53\u6765\u770b\uff0cDLinear\u6a21\u578b\u5728\u8fd9\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u503c\u6700\u4e3a\u63a5\u8fd1\uff0c\u8868\u73b0\u51fa\u8f83\u597d\u7684\u9884\u6d4b\u6027\u80fd\u3002\u800c\u5176\u4ed6\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08\u5982Informer\u3001Autoformer\u548cFEDformer\uff09\u5728\u67d0\u4e9b\u533a\u57df\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u503c\u5b58\u5728\u8f83\u5927\u504f\u5dee\u3002\u8fd9\u8868\u660e\u5728\u8fd9\u4e9b\u7279\u5b9a\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\uff0cDLinear\u6a21\u578b\u53ef\u80fd\u66f4\u9002\u5408\u6355\u6349\u6570\u636e\u7684\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002</p> <p>Additionally, we provide more quantitative results in the Appendix, and our conclusion holds in almost all cases.</p> <p>\u6b64\u5916\uff0c\u6211\u4eec\u5728\u9644\u5f55\u4e2d\u63d0\u4f9b\u4e86\u66f4\u5b9a\u91cf\u7684\u7ed3\u679c\uff0c\u5e76\u4e14\u5728\u51e0\u4e4e\u6240\u6709\u60c5\u51b5\u4e0b\u6211\u4eec\u7684\u7ed3\u8bba\u90fd\u4f1a\u5f97\u51fa\u3002</p> <p></p> <p>\u56fe4\u5c55\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u4ea4\u901a\uff08Traffic\uff09\u548c\u7535\u529b\uff08Electricity\uff09\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u957f\u671f\u9884\u6d4b\uff08\\(T=720\\)\u6b65\uff09\u65f6\u7684\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u7ed3\u679c\u3002X\u8f74\u8868\u793a\u4e0d\u540c\u7684\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\uff0cY\u8f74\u8868\u793aMSE\u503c\uff0c\u6570\u503c\u8d8a\u4f4e\u8868\u793a\u9884\u6d4b\u6027\u80fd\u8d8a\u597d\u3002</p> <p>(a) 720\u6b65-\u4ea4\u901a\uff1a - \u8be5\u56fe\u663e\u793a\u4e86\u5728\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\uff0c\u968f\u7740\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u7684\u589e\u52a0\uff0c\u4e0d\u540c\u6a21\u578b\u7684MSE\u53d8\u5316\u60c5\u51b5\u3002 - \u4ece\u56fe\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5927\u591a\u6570\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08\u5982Informer\u3001Autoformer\u3001Pyraformer\u548cFEDformer\uff09\u7684MSE\u968f\u7740\u7a97\u53e3\u5927\u5c0f\u7684\u589e\u52a0\u800c\u589e\u52a0\u6216\u4fdd\u6301\u7a33\u5b9a\uff0c\u8fd9\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u5728\u5904\u7406\u66f4\u957f\u7684\u5e8f\u5217\u65f6\u53ef\u80fd\u4f1a\u8fc7\u62df\u5408\u65f6\u95f4\u566a\u58f0\uff0c\u800c\u4e0d\u662f\u63d0\u53d6\u65f6\u95f4\u4fe1\u606f\u3002 - \u76f8\u6bd4\u4e4b\u4e0b\uff0cLTSF-Linear\u6a21\u578b\uff08\u5305\u62ecNLinear\u548cDLinear\uff09\u7684MSE\u968f\u7740\u7a97\u53e3\u5927\u5c0f\u7684\u589e\u52a0\u800c\u663e\u8457\u964d\u4f4e\uff0c\u663e\u793a\u51fa\u66f4\u597d\u7684\u6027\u80fd\u63d0\u5347\u3002</p> <p>(b) 720\u6b65-\u7535\u529b\uff1a - \u8be5\u56fe\u663e\u793a\u4e86\u5728\u7535\u529b\u6570\u636e\u96c6\u4e0a\uff0c\u4e0d\u540c\u6a21\u578b\u7684MSE\u968f\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u7684\u53d8\u5316\u60c5\u51b5\u3002 - \u540c\u6837\uff0c\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08\u5982Informer\u3001Autoformer\u3001Pyraformer\u548cFEDformer\uff09\u7684MSE\u5728\u7a97\u53e3\u5927\u5c0f\u589e\u52a0\u65f6\u8868\u73b0\u4e0d\u7a33\u5b9a\u6216\u589e\u52a0\u3002 - LTSF-Linear\u6a21\u578b\uff08\u5305\u62ecNLinear\u548cDLinear\uff09\u5728\u4e0d\u540c\u7a97\u53e3\u5927\u5c0f\u4e0b\u7684\u8868\u73b0\u76f8\u5bf9\u7a33\u5b9a\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u7a97\u53e3\u5927\u5c0f\u4e0b\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002</p> <p>\u603b\u4f53\u800c\u8a00\uff0c\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u5728\u5904\u7406\u957f\u671f\u9884\u6d4b\u4efb\u52a1\u65f6\u53ef\u80fd\u4e0d\u5982LTSF-Linear\u6a21\u578b\u6709\u6548\uff0c\u7279\u522b\u662f\u5728\u56de\u6eaf\u7a97\u53e3\u8f83\u5927\u7684\u60c5\u51b5\u4e0b\u3002LTSF-Linear\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u5229\u7528\u66f4\u957f\u7684\u5386\u53f2\u6570\u636e\u6765\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002</p>"},{"location":"literature/TSP/2_DLinear/#2close-input-far-input","title":"(2)close input &amp; far input","text":"<p>What can be learned for long-term forecasting? While the temporal dynamics in the look-back window significantly impact the forecasting accuracy of short-term time series forecasting, we hypothesize that long-term forecasting depends on whether models can capture the trend and periodicity well only. That is, the farther the forecasting horizon, the less impact the look-back window itself has.</p> <p>\u957f\u671f\u9884\u6d4b\u7684\u542f\u793a\uff1a \u5c3d\u7ba1\u56de\u6eaf\u7a97\u53e3\u4e2d\u7684\u65f6\u95f4\u52a8\u6001\u5bf9\u77ed\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u51c6\u786e\u6027\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u6211\u4eec\u5047\u8bbe\u957f\u671f\u9884\u6d4b\u4ec5\u4f9d\u8d56\u4e8e\u6a21\u578b\u662f\u5426\u80fd\u591f\u5f88\u597d\u5730\u6355\u6349\u8d8b\u52bf\u548c\u5468\u671f\u6027\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u9884\u6d4b\u8303\u56f4\u8d8a\u8fdc\uff0c\u56de\u6eaf\u7a97\u53e3\u672c\u8eab\u7684\u5f71\u54cd\u5c31\u8d8a\u5c0f\u3002</p> <p>em\u6211\u4e5f\u4ee5\u4e3a\u56de\u6eaf\u7a97\u53e3\u8d8a\u957f\uff0c\u9884\u6d4b\u51c6\u786e\u6027\u8d8a\u9ad8\uff0c\u53ef\u5b9e\u9a8c\u7ed3\u679c\u5374\u597d\u597d\u50cf\u662f\uff0c\u5982\u679c\u56de\u6eaf\u7a97\u53e3\u592a\u957f\uff0c\u65e0\u5173\u4fe1\u606f\u9020\u6210\u7684\u5197\u4f59\u4fe1\u606f\u8d8a\u591a\uff0c\u53cd\u800c\u8d8a\u6765\u8d8a\u5b66\u4e0d\u5230\u6709\u7528\u7684\u4fe1\u606f\u3002\u65f6\u5e8f\u6570\u636e\u5cf0\u503c\u6570\u636e\u53ef\u80fd\u5360\u4e86\u66f4\u591a\u7684\u6743\u91cd</p> <p></p> <p>\u56fe3\u5c55\u793a\u4e86FEDformer\u548cAutoformer\u4e24\u79cd\u6a21\u578b\u5728\u4e0d\u540c\u8f93\u5165\u5e8f\u5217\uff08Close\u548cFar\uff09\u4e0b\u7684\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u6bd4\u8f83\uff0c\u7528\u4e8e\u63a2\u7d22\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u6a21\u578b\u4f9d\u8d56\u4e8e\u54ea\u4e9b\u8f93\u5165\u5e8f\u5217\u3002\u8868\u4e2d\u5217\u51fa\u4e86\u4e24\u79cd\u6a21\u578b\u5728\u7535\u529b\uff08Electricity\uff09\u548c\u4ea4\u901a\uff08Traffic\uff09\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002</p> <ul> <li>Close\u8f93\u5165\uff1a\u6307\u7684\u662f\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u4e2d\u8f83\u8fd1\u7684\u65f6\u95f4\u6b65\uff08\u4f8b\u5982\uff0c\u5bf9\u4e8e\u7535\u529b\u6570\u636e\u96c6\u662f\u7b2c \\(96_{th}\\) \u5230 \\(191_{th}\\) \u65f6\u95f4\u6b65\uff09\u4f5c\u4e3a\u8f93\u5165\u5e8f\u5217\u3002</li> <li>Far\u8f93\u5165\uff1a\u6307\u7684\u662f\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u4e2d\u8f83\u8fdc\u7684\u65f6\u95f4\u6b65\uff08\u4f8b\u5982\uff0c\u5bf9\u4e8e\u7535\u529b\u6570\u636e\u96c6\u662f\u7b2c \\(0_{th}\\) \u5230 \\(95_{th}\\) \u65f6\u95f4\u6b65\uff09\u4f5c\u4e3a\u8f93\u5165\u5e8f\u5217\u3002</li> <li>\u4e24\u79cd\u8f93\u5165\u5e8f\u5217\u90fd\u9884\u6d4b\u4ece\u7b2c \\(192_{th}\\) \u65f6\u95f4\u6b65\u5f00\u59cb\u7684\u672a\u6765 \\(720\\) \u4e2a\u65f6\u95f4\u6b65\u3002</li> </ul> <p>\u4ece\u8868\u4e2d\u53ef\u4ee5\u770b\u51fa\uff1a - \u5728\u7535\u529b\u6570\u636e\u96c6\u4e0a\uff0c\u65e0\u8bba\u662fClose\u8fd8\u662fFar\u8f93\u5165\uff0cFEDformer\u7684MSE\u90fd\u7565\u4f4e\u4e8eAutoformer\uff0c\u8868\u660eFEDformer\u5728\u5904\u7406\u7535\u529b\u6570\u636e\u65f6\u8868\u73b0\u7a0d\u597d\u3002 - \u5728\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\uff0c\u5f53\u8f93\u5165\u4e3aClose\u65f6\uff0cFEDformer\u548cAutoformer\u7684MSE\u76f8\u8fd1\uff1b\u4f46\u5f53\u8f93\u5165\u4e3aFar\u65f6\uff0cAutoformer\u7684MSE\u660e\u663e\u9ad8\u4e8eFEDformer\uff0c\u8868\u660eFEDformer\u5728\u5904\u7406\u8fdc\u7aef\u8f93\u5165\u65f6\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002</p> <p>\u603b\u4f53\u800c\u8a00\uff0c\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e\u957f\u671f\u9884\u6d4b\u4efb\u52a1\uff0c\u8f93\u5165\u5e8f\u5217\u7684\u9009\u62e9\u5bf9\u6a21\u578b\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002\u7279\u522b\u662f\uff0cFEDformer\u5728\u5904\u7406\u8fdc\u7aef\u8f93\u5165\u65f6\u8868\u73b0\u51fa\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002</p> <p>\u8bf4\u660e\u9891\u57df\u4fe1\u606f\u6709\u7528</p> <p>To validate the above hypothesis, in Table 3, we compare the forecasting accuracy for the same future 720 time steps with data from two different look-back windows: (i). the original input L=96 setting (called Close) and (ii). the far input L=96 setting (called Far) that is before the original 96 time steps. From the experimental results, the performance of the SOTA Transformers drops slightly, indicating these models only capture similar temporal information from the adjacent time series sequence. Since capturing the intrinsic characteristics of the dataset generally does not require a large number of parameters, i,e. one parameter can represent the periodicity. Using too many parameters will even cause overfitting, which partially explains why LTSFLinear performs better than Transformer-based methods.</p> <p>\u4e3a\u4e86\u9a8c\u8bc1\u4e0a\u8ff0\u5047\u8bbe\uff0c\u5728\u88683\u4e2d\uff0c\u6211\u4eec\u6bd4\u8f83\u4e86\u4f7f\u7528\u4e24\u79cd\u4e0d\u540c\u56de\u6eaf\u7a97\u53e3\u6570\u636e\u9884\u6d4b\u76f8\u540c\u672a\u6765720\u4e2a\u65f6\u95f4\u6b65\u7684\u51c6\u786e\u6027\uff1a</p> <p>(i) \u539f\u59cb\u8f93\u5165\u8bbe\u7f6e \\(L=96\\)\uff08\u79f0\u4e3aClose\uff09\u548c</p> <p>(ii) \u8fdc\u7aef\u8f93\u5165\u8bbe\u7f6e \\(L=96\\)\uff08\u79f0\u4e3aFar\uff09\uff0c\u5373\u5728\u539f\u59cb96\u4e2a\u65f6\u95f4\u6b65\u4e4b\u524d\u7684\u8bbe\u7f6e\u3002</p> <p>\u4ece\u5b9e\u9a8c\u7ed3\u679c\u6765\u770b\uff0c\u6700\u5148\u8fdb\u7684Transformer\u6a21\u578b\u7684\u6027\u80fd\u7565\u6709\u4e0b\u964d\uff0c\u8fd9\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u4ec5\u4ece\u76f8\u90bb\u7684\u65f6\u95f4\u5e8f\u5217\u4e2d\u6355\u83b7\u4e86\u7c7b\u4f3c\u7684\u65f6\u95f4\u4fe1\u606f\u3002\u7531\u4e8e\u6355\u83b7\u6570\u636e\u96c6\u7684\u5185\u5728\u7279\u5f81\u901a\u5e38\u4e0d\u9700\u8981\u5927\u91cf\u7684\u53c2\u6570\uff0c\u5373\u4e00\u4e2a\u53c2\u6570\u5c31\u53ef\u4ee5\u4ee3\u8868\u5468\u671f\u6027\u3002\u4f7f\u7528\u8fc7\u591a\u7684\u53c2\u6570\u751a\u81f3\u4f1a\u5bfc\u81f4\u8fc7\u62df\u5408\uff0c\u8fd9\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48LTSF-Linear\u7684\u6027\u80fd\u4f18\u4e8e\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u3002</p> <p>\u55ef\uff01</p> <p>models only capture similar temporal information from the adjacent time series sequence</p> <p>\u76f8\u90bb\u65f6\u95f4\u5e8f\u5217\u6355\u83b7\u76f8\u540c\u7684\u8d8b\u52bf\u3002\u6240\u4ee5\u76f4\u89c9\u4e0a\u4ee5\u4e3a\uff0c\u6cb9\u6e29\u548c\u6e29\u5ea6\u3001\u6e7f\u5ea6\u6709\u5173\u7684\u5f71\u54cd\u53cd\u800c\u4e0d\u5927\uff0c\u53cd\u800c\u5e26\u6765\u66f4\u591a\u7684\u566a\u58f0</p>"},{"location":"literature/TSP/2_DLinear/#3","title":"(3)\u81ea\u6ce8\u610f\u529b\u673a\u5236\u662f\u5426\u6709\u7528","text":"<p>Are the self-attention scheme effective for LTSF? </p> <p>We verify whether these complex designs in the existing Transformer (e.g., Informer) are essential. In Table 4, we gradually transform Informer to Linear. First, we replace each self-attention layer by a linear layer, called Att.-Linear, since a self-attention layer can be regarded as a fullyconnected layer where weights are dynamically changed. Furthermore, we discard other auxiliary designs (e.g., FFN) in Informer to leave embedding layers and linear layers, named Embed + Linear. Finally, we simplify the model to one linear layer. Surprisingly, the performance of Informer grows with the gradual simplification, indicating the unnecessary of the self-attention scheme and other complex modules at least for existing LTSF benchmarks.</p> <p>\u81ea\u6ce8\u610f\u529b\u673a\u5236\u662f\u5426\u5bf9\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u6709\u6548\uff1f </p> <p>\u6211\u4eec\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u73b0\u6709Transformer\u6a21\u578b\uff08\u4f8b\u5982Informer\uff09\u4e2d\u8fd9\u4e9b\u590d\u6742\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u3002\u5728\u88684\u4e2d\uff0c\u6211\u4eec\u9010\u6b65\u5c06Informer\u8f6c\u53d8\u4e3a\u7ebf\u6027\u6a21\u578b\u3002\u9996\u5148\uff0c\u6211\u4eec\u7528\u7ebf\u6027\u5c42\u66ff\u6362\u6bcf\u4e2a\u81ea\u6ce8\u610f\u529b\u5c42\uff0c\u79f0\u4e3aAtt.-Linear\uff0c\u56e0\u4e3a\u81ea\u6ce8\u610f\u529b\u5c42\u53ef\u4ee5\u88ab\u89c6\u4e3a\u6743\u91cd\u52a8\u6001\u53d8\u5316\u7684\u5168\u8fde\u63a5\u5c42\u3002\u6b64\u5916\uff0c\u6211\u4eec\u4e22\u5f03Informer\u4e2d\u7684\u5176\u4ed6\u8f85\u52a9\u8bbe\u8ba1\uff08\u4f8b\u5982\uff0cFFN\uff09\uff0c\u4ec5\u4fdd\u7559\u5d4c\u5165\u5c42\u548c\u7ebf\u6027\u5c42\uff0c\u547d\u540d\u4e3aEmbed + Linear\u3002\u6700\u540e\uff0c\u6211\u4eec\u5c06\u6a21\u578b\u7b80\u5316\u4e3a\u4e00\u4e2a\u7ebf\u6027\u5c42\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u968f\u7740\u6a21\u578b\u7684\u9010\u6b65\u7b80\u5316\uff0cInformer\u7684\u6027\u80fd\u53cd\u800c\u63d0\u9ad8\uff0c\u8fd9\u8868\u660e\u81f3\u5c11\u5bf9\u4e8e\u73b0\u6709\u7684LTSF\u57fa\u51c6\u6d4b\u8bd5\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u5176\u4ed6\u590d\u6742\u6a21\u5757\u662f\u4e0d\u5fc5\u8981\u7684\u3002</p> <p></p> <p>\u56fe4\u4e2d\u7684\u8868\u683c\u5c55\u793a\u4e86\u5c06Informer\u6a21\u578b\u9010\u6b65\u7b80\u5316\u4e3a\u7ebf\u6027\u6a21\u578b\u7684\u8fc7\u7a0b\u4e2d\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u4e24\u4e2a\u6570\u636e\u96c6\uff08Exchange\u548cETTh1\uff09\u4e0a\u7684\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u6bd4\u8f83\u3002\u8868\u683c\u4e2d\u7684\u5217\u5206\u522b\u4ee3\u8868\u4e0d\u540c\u7684\u6a21\u578b\u53d8\u4f53\uff0c\u884c\u4ee3\u8868\u4e0d\u540c\u7684\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u3002\u5177\u4f53\u6765\u8bf4\uff1a</p> <ul> <li>Informer\uff1a\u539f\u59cb\u7684\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u3002</li> <li>Att.-Linear\uff1a\u7528\u7ebf\u6027\u5c42\u66ff\u6362\u6bcf\u4e2a\u81ea\u6ce8\u610f\u529b\u5c42\u7684\u6a21\u578b\uff0c\u56e0\u4e3a\u81ea\u6ce8\u610f\u529b\u5c42\u53ef\u4ee5\u88ab\u89c6\u4e3a\u6743\u91cd\u52a8\u6001\u53d8\u5316\u7684\u5168\u8fde\u63a5\u5c42\u3002</li> <li>Embed + Linear\uff1a\u53bb\u6389Informer\u4e2d\u7684\u5176\u4ed6\u8f85\u52a9\u8bbe\u8ba1\uff08\u4f8b\u5982\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0cFFN\uff09\uff0c\u4ec5\u4fdd\u7559\u5d4c\u5165\u5c42\u548c\u7ebf\u6027\u5c42\u3002</li> <li>Linear\uff1a\u8fdb\u4e00\u6b65\u7b80\u5316\u4e3a\u5355\u4e00\u7ebf\u6027\u5c42\u7684\u6a21\u578b\u3002</li> </ul> <p>\u8868\u683c\u4e2d\u7684\u6570\u636e\u5c55\u793a\u4e86\u968f\u7740\u6a21\u578b\u4ece\u5de6\u5230\u53f3\u9010\u6b65\u7b80\u5316\uff0cMSE\u7684\u53d8\u5316\u60c5\u51b5\u3002\u53ef\u4ee5\u89c2\u5bdf\u5230\u4ee5\u4e0b\u51e0\u70b9\uff1a</p> <ol> <li> <p>\u6027\u80fd\u63d0\u5347\uff1a\u968f\u7740\u6a21\u578b\u7684\u7b80\u5316\uff0cInformer\u7684\u6027\u80fd\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u6709\u6240\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728ETTh1\u6570\u636e\u96c6\u4e0a\uff0c\u7b80\u5316\u540e\u7684\u6a21\u578b\uff08Embed + Linear\u548cLinear\uff09\u8868\u73b0\u51fa\u66f4\u4f4e\u7684MSE\u3002</p> </li> <li> <p>\u7b80\u5316\u7684\u6709\u6548\u6027\uff1a\u5728Exchange\u6570\u636e\u96c6\u4e0a\uff0c\u7b80\u5316\u540e\u7684\u6a21\u578b\uff08Embed + Linear\u548cLinear\uff09\u5728\u8f83\u5927\u7684\u56de\u6eaf\u7a97\u53e3\uff08336\u548c720\uff09\u4e0b\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\uff0c\u800c\u5728\u8f83\u5c0f\u7684\u56de\u6eaf\u7a97\u53e3\uff0896\u548c192\uff09\u4e0b\uff0c\u539f\u59cbInformer\u6a21\u578b\u7684\u6027\u80fd\u7565\u597d\u3002</p> </li> <li> <p>\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u5fc5\u8981\u6027\uff1a\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e\u73b0\u6709\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u57fa\u51c6\u6d4b\u8bd5\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u5176\u4ed6\u590d\u6742\u6a21\u5757\u53ef\u80fd\u5e76\u4e0d\u662f\u5fc5\u9700\u7684\u3002\u7b80\u5316\u540e\u7684\u6a21\u578b\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u80fd\u591f\u63d0\u4f9b\u66f4\u597d\u7684\u9884\u6d4b\u6027\u80fd\u3002</p> </li> </ol> <p>\u603b\u7ed3\u6765\u8bf4\uff0c\u8fd9\u4e9b\u7ed3\u679c\u6311\u6218\u4e86\u73b0\u6709Transformer\u6a21\u578b\u5728\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u5fc5\u8981\u6027\u548c\u6709\u6548\u6027\uff0c\u8868\u660e\u7b80\u5355\u7684\u7ebf\u6027\u6a21\u578b\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u66f4\u4e3a\u6709\u6548\u3002</p> <p>\u554a\uff1f\u4e5f\u8bb8\u6a21\u578b\u5e76\u4e0d\u662f\u8d8a\u590d\u6742\u8d8a\u597d</p>"},{"location":"literature/TSP/2_DLinear/#4","title":"(4)\u4f4d\u7f6e\u4fe1\u606f\u7684\u4fdd\u7559","text":"<p>Can existing LTSF-Transformers preserve temporal order well?</p> <p></p> <p>\u8be5\u56fe\u7247\u5c55\u793a\u4e86\u4e00\u5f20\u8868\u683c\uff0c\u6807\u9898\u4e3a\u201cTable 5. The MSE comparisons of models when shuffling the raw input sequence.\u201d \u8868\u683c\u6bd4\u8f83\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u8f93\u5165\u5e8f\u5217\u88ab\u6253\u4e71\u65f6\u7684\u5e73\u5747\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8868\u683c\u4e2d\u5217\u51fa\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u6253\u4e71\u7b56\u7565\uff1a\u539f\u59cb\u5e8f\u5217\uff08Ori.\uff09\u3001\u968f\u673a\u6253\u4e71\uff08Shuf.\uff09\u3001\u534a\u4ea4\u6362\uff08Half-Ex.\uff09\uff0c\u4ee5\u53ca\u5728\u8fd9\u4e9b\u6253\u4e71\u7b56\u7565\u4e0b\u6a21\u578b\u7684\u6027\u80fd\u8868\u73b0\u3002</p> <p>\u8868\u683c\u4e2d\u5305\u542b\u7684\u6a21\u578b\u6709\uff1a - Linear\uff08\u7ebf\u6027\u6a21\u578b\uff09 - FEDformer - Autoformer - Informer</p> <p>\u9884\u6d4b\u957f\u5ea6\uff08Predict Length\uff09\u5206\u4e3a\u56db\u4e2a\u4e0d\u540c\u7684\u503c\uff1a96\u3001192\u3001336\u3001720\u3002</p> <p>\u5bf9\u4e8e\u6bcf\u4e2a\u6a21\u578b\u548c\u9884\u6d4b\u957f\u5ea6\uff0c\u8868\u683c\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u6253\u4e71\u7b56\u7565\u4e0b\u7684\u5e73\u5747MSE\u503c\u3002\u6b64\u5916\uff0c\u8fd8\u8ba1\u7b97\u4e86\u6bcf\u79cd\u6253\u4e71\u7b56\u7565\u76f8\u5bf9\u4e8e\u539f\u59cb\u5e8f\u5217\uff08Ori.\uff09\u7684\u5e73\u5747\u6027\u80fd\u4e0b\u964d\u767e\u5206\u6bd4\uff08Average Drop\uff09\u3002</p> <p>\u4ece\u8868\u683c\u4e2d\u53ef\u4ee5\u89c2\u5bdf\u5230\uff1a - \u7ebf\u6027\u6a21\u578b\uff08Linear\uff09\u5728\u6240\u6709\u9884\u6d4b\u957f\u5ea6\u4e0b\uff0c\u968f\u673a\u6253\u4e71\uff08Shuf.\uff09\u548c\u534a\u4ea4\u6362\uff08Half-Ex.\uff09\u7b56\u7565\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u767e\u5206\u6bd4\u6700\u5927\uff0c\u5206\u522b\u4e3a27.26%\u548c46.81%\uff08\u5bf9\u4e8eExchange Rate\u6570\u636e\u96c6\uff09\u4ee5\u53ca81.06%\u548c4.78%\uff08\u5bf9\u4e8eETTh1\u6570\u636e\u96c6\uff09\u3002 - FEDformer\u548cAutoformer\u5728\u968f\u673a\u6253\u4e71\uff08Shuf.\uff09\u7b56\u7565\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u767e\u5206\u6bd4\u76f8\u5bf9\u8f83\u5c0f\uff0c\u5206\u522b\u4e3a-0.09%\u548c0.09%\uff08\u5bf9\u4e8eExchange Rate\u6570\u636e\u96c6\uff09\u4ee5\u53ca73.28%\u548c56.91%\uff08\u5bf9\u4e8eETTh1\u6570\u636e\u96c6\uff09\u3002 - Informer\u6a21\u578b\u5728\u6240\u6709\u6253\u4e71\u7b56\u7565\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u767e\u5206\u6bd4\u6700\u5c0f\uff0c\u5206\u522b\u4e3a-0.12%\u548c-0.18%\uff08\u5bf9\u4e8eExchange Rate\u6570\u636e\u96c6\uff09\u4ee5\u53ca1.98%\u548c0.18%\uff08\u5bf9\u4e8eETTh1\u6570\u636e\u96c6\uff09\u3002</p> <p>\u8868\u683c\u5e95\u90e8\u7684\u6ce8\u91ca\u8bf4\u660e\u4e86\u8fd9\u4e9b\u7ed3\u679c\u662f\u57fa\u4e8e\u4e94\u6b21\u8fd0\u884c\u7684\u5e73\u5747\u6d4b\u8bd5MSE\u5f97\u51fa\u7684\u3002\u603b\u4f53\u6765\u770b\uff0cInformer\u6a21\u578b\u5728\u5904\u7406\u6253\u4e71\u7684\u8f93\u5165\u5e8f\u5217\u65f6\u8868\u73b0\u66f4\u4e3a\u7a33\u5065\uff0c\u800c\u7ebf\u6027\u6a21\u578b\u7684\u6027\u80fd\u4e0b\u964d\u6700\u4e3a\u663e\u8457\u3002</p> <p>Self-attention is inherently permutation invariant, i.e., regardless of the order. </p> <p>However, in timeseries forecasting, the sequence order often plays a crucial role. We argue that even with positional and temporal embeddings, existing Transformer-based methods still suffer from temporal information loss. </p> <p>\uff08\u6253\u4e71\u7b56\u7565\uff09In Table 5, we shuffle the raw input before the embedding strategies. </p> <p>Two shuffling strategies are presented: \u2460 Shuf. randomly shuffles the whole input sequences and \u2461 Half-Ex. exchanges the first half of the input sequence with the second half.</p> <p>\uff08\u6253\u4e71\u4ee5\u540e\u5f97\u5b9e\u9a8c\u7ed3\u679c\uff09Interestingly, compared with the original setting (Ori.) on the Exchange Rate, the performance of all Transformer-based methods does not fluctuate even when the input sequence is randomly shuffled. </p> <p>By contrary, the performance of LTSF-Linear is damaged significantly. </p> <p>\uff08\u8ba8\u8bba\uff09These indicate that LTSF-Transformers with different positional and temporal embeddings preserve quite limited temporal relations and are prone to overfit on noisy financial data, while the LTSF-Linear can model the order naturally and avoid overfitting with fewer parameters.</p> <p>\u81ea\u6ce8\u610f\u529b\u673a\u5236\u672c\u8d28\u4e0a\u662f\u6392\u5217\u4e0d\u53d8\u7684\uff0c\u5373\u4e0e\u987a\u5e8f\u65e0\u5173\u3002\u7136\u800c\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\uff0c\u5e8f\u5217\u987a\u5e8f\u5f80\u5f80\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002\u6211\u4eec\u4e3b\u5f20\u5373\u4f7f\u4f7f\u7528\u4f4d\u7f6e\u548c\u65f6\u95f4\u5d4c\u5165\uff0c\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u4ecd\u7136\u5b58\u5728\u65f6\u95f4\u4fe1\u606f\u4e22\u5931\u7684\u95ee\u9898\u3002</p> <p>\u5728\u88685\u4e2d\uff0c\u6211\u4eec\u5728\u5d4c\u5165\u7b56\u7565\u4e4b\u524d\u5bf9\u539f\u59cb\u8f93\u5165\u8fdb\u884c\u4e86\u968f\u673a\u6253\u4e71\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e24\u79cd\u6253\u4e71\u7b56\u7565\uff1a\u201cShuf.\u201d\u968f\u673a\u6253\u4e71\u6574\u4e2a\u8f93\u5165\u5e8f\u5217\uff0c\u201cHalf-Ex.\u201d\u5c06\u8f93\u5165\u5e8f\u5217\u7684\u524d\u534a\u90e8\u5206\u4e0e\u540e\u534a\u90e8\u5206\u8fdb\u884c\u4ea4\u6362\u3002\u6709\u8da3\u7684\u662f\uff0c\u4e0e\u6c47\u7387\u6570\u636e\u96c6\u7684\u539f\u59cb\u8bbe\u7f6e\uff08\u201cOri.\u201d\uff09\u76f8\u6bd4\uff0c\u5373\u4f7f\u8f93\u5165\u5e8f\u5217\u88ab\u968f\u673a\u6253\u4e71\uff0c\u6240\u6709\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u7684\u6027\u80fd\u4e5f\u6ca1\u6709\u6ce2\u52a8\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0cLTSF-Linear\u7684\u6027\u80fd\u5374\u53d7\u5230\u4e86\u663e\u8457\u7684\u635f\u5bb3\u3002</p> <p>\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u5177\u6709\u4e0d\u540c\u4f4d\u7f6e\u548c\u65f6\u95f4\u5d4c\u5165\u7684LTSF-Transformer\u4fdd\u7559\u7684\u65f6\u95f4\u5173\u7cfb\u76f8\u5f53\u6709\u9650\uff0c\u4e14\u5bb9\u6613\u5728\u5608\u6742\u7684\u91d1\u878d\u6570\u636e\u4e0a\u8fc7\u62df\u5408\uff0c\u800c\u7b80\u5355\u7684LTSF-Linear\u80fd\u591f\u81ea\u7136\u5730\u6a21\u62df\u987a\u5e8f\uff0c\u5e76\u4e14\u7531\u4e8e\u53c2\u6570\u8f83\u5c11\u800c\u907f\u514d\u4e86\u8fc7\u62df\u5408\u3002</p> <p>For the ETTh1 dataset, FEDformer and Autoformer introduce time series inductive bias into their models, making them can extract certain temporal information when the dataset has more clear temporal patterns (e.g., periodicity) than the Exchange Rate.</p> <p>Therefore, the average drops of the two Transformers are 73.28% and 56.91% under the Shuf. setting, where it loses the whole order information. </p> <p>Moreover, Informer still suffers less from both Shuf. and Half-Ex. settings due to its no such temporal inductive bias. Overall, the average drops of LTSF-Linear are larger than Transformer-based methods for all cases, indicating the existing Transformers do not preserve temporal order well.</p> <p>\u5bf9\u4e8eETTh1\u6570\u636e\u96c6\uff0cFEDformer\u548cAutoformer\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u5e8f\u5217\u5f52\u7eb3\u504f\u7f6e\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u6570\u636e\u96c6\u5177\u6709\u66f4\u6e05\u6670\u7684\u65f6\u95f4\u6a21\u5f0f\uff08\u4f8b\u5982\u5468\u671f\u6027\uff09\u65f6\u63d0\u53d6\u7279\u5b9a\u7684\u65f6\u95f4\u4fe1\u606f\uff0c\u8fd9\u6bd4\u6c47\u7387\u6570\u636e\u96c6\u66f4\u5177\u4f18\u52bf\u3002</p> <p>\u56e0\u6b64\uff0c\u5728\u968f\u673a\u6253\u4e71\uff08Shuf.\uff09\u8bbe\u7f6e\u4e0b\uff0c\u8fd9\u4e24\u4e2aTransformer\u7684\u5e73\u5747\u6027\u80fd\u4e0b\u964d\u5e45\u5ea6\u5206\u522b\u4e3a73.28%\u548c56.91%\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6574\u4e2a\u987a\u5e8f\u4fe1\u606f\u4e22\u5931\u3002</p> <p>\u6b64\u5916\uff0c\u7531\u4e8eInformer\u6ca1\u6709\u8fd9\u79cd\u65f6\u95f4\u5f52\u7eb3\u504f\u7f6e\uff0c\u56e0\u6b64\u5728\u968f\u673a\u6253\u4e71\uff08Shuf.\uff09\u548c\u534a\u4ea4\u6362\uff08Half-Ex.\uff09\u8bbe\u7f6e\u4e0b\u53d7\u5230\u7684\u5f71\u54cd\u8f83\u5c0f\u3002\u603b\u4f53\u800c\u8a00\uff0cLTSF-Linear\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u5e73\u5747\u6027\u80fd\u4e0b\u964d\u5e45\u5ea6\u90fd\u5927\u4e8e\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\uff0c\u8fd9\u8868\u660e\u73b0\u6709\u7684Transformer\u5728\u4fdd\u7559\u65f6\u95f4\u987a\u5e8f\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002</p>"},{"location":"literature/TSP/2_DLinear/#5","title":"(5)\u8ba8\u8bba\u4e0d\u540c\u7684\u5d4c\u5165\u7b56\u7565","text":"<p>How effective are different embedding strategies? </p> <p>We study the benefits of position and timestamp embeddings used in Transformer-based methods. In Table 6, the forecasting errors of Informer largely increase without positional embeddings (wo/Pos.). Without timestamp embeddings (wo/Temp.) will gradually damage the performance of Informer as the forecasting lengths increase. Since Informer uses a single time step for each token, it is necessary to introduce temporal information in tokens.</p> <p>\u4e0d\u540c\u7684\u5d4c\u5165\u7b56\u7565\u5728Transformer\u6a21\u578b\u4e2d\u7684\u6548\u679c\u5982\u4f55\uff1f</p> <p>\u6211\u4eec\u7814\u7a76\u4e86\u4f4d\u7f6e\u5d4c\u5165\uff08positional embeddings\uff09\u548c\u65f6\u95f4\u6233\u5d4c\u5165\uff08timestamp embeddings\uff09\u5728\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u4e2d\u7684\u6548\u679c\u3002\u5982\u8868 6 \u6240\u793a\uff0c\u5bf9\u4e8eInformer\u6a21\u578b\u800c\u8a00\uff0c\u6ca1\u6709\u4f4d\u7f6e\u5d4c\u5165\uff08wo/Pos.\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u8bef\u5dee\u663e\u8457\u589e\u52a0\u3002 \u6ca1\u6709\u65f6\u95f4\u6233\u5d4c\u5165\uff08wo/Temp.\uff09\u4f1a\u968f\u7740\u9884\u6d4b\u957f\u5ea6\u7684\u589e\u52a0\u800c\u9010\u6e10\u635f\u5bb3Informer\u7684\u6027\u80fd\u3002\u8fd9\u662f\u56e0\u4e3aInformer\u6bcf\u4e2atoken\u4ec5\u4f7f\u7528\u4e00\u4e2a\u65f6\u95f4\u6b65\u957f\uff0c\u56e0\u6b64\u5728token\u4e2d\u5f15\u5165\u65f6\u95f4\u4fe1\u606f\u662f\u5fc5\u8981\u7684\u3002</p> <p></p> <p>\u201cTable 6. The MSE comparisons of different embedding strategies on Transformer-based methods with look-back window size 96 and forecasting lengths {96, 192, 336, 720}.\u201d </p> <p>\u8868\u683c\u6bd4\u8f83\u4e86\u4e0d\u540c\u5d4c\u5165\u7b56\u7565\u5728\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u4e0a\u7684\u5e73\u5747\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4f7f\u752896\u5927\u5c0f\u7684\u56de\u6eaf\u7a97\u53e3\uff0c\u5e76\u5728\u4e0d\u540c\u7684\u9884\u6d4b\u957f\u5ea6\uff0896\u3001192\u3001336\u3001720\uff09\u4e0b\u8fdb\u884c\u6d4b\u8bd5\u3002</p> <p>\u8868\u683c\u4e2d\u5305\u542b\u7684\u6a21\u578b\u6709\uff1a - FEDformer - Autoformer - Informer</p> <p>\u5d4c\u5165\u7b56\u7565\u5305\u62ec\uff1a - \u4f7f\u7528\u6240\u6709\u5d4c\u5165\uff08All\uff09 - \u4e0d\u4f7f\u7528\u4f4d\u7f6e\u5d4c\u5165\uff08wo/Pos.\uff09 - \u4e0d\u4f7f\u7528\u65f6\u95f4\u6233\u5d4c\u5165\uff08wo/Temp.\uff09 - \u540c\u65f6\u4e0d\u4f7f\u7528\u4f4d\u7f6e\u548c\u65f6\u95f4\u6233\u5d4c\u5165\uff08wo/Pos.-Temp.\uff09</p> <p>\u5bf9\u4e8e\u6bcf\u4e2a\u6a21\u578b\u548c\u9884\u6d4b\u957f\u5ea6\uff0c\u8868\u683c\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u5d4c\u5165\u7b56\u7565\u4e0b\u7684\u5e73\u5747MSE\u503c\u3002\u8fd9\u4e9b\u7ed3\u679c\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u7406\u89e3\u4f4d\u7f6e\u5d4c\u5165\u548c\u65f6\u95f4\u6233\u5d4c\u5165\u5728\u4e0d\u540c\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u6027\u3002</p> <p>\u4ece\u8868\u683c\u4e2d\u53ef\u4ee5\u89c2\u5bdf\u5230\uff1a - \u5bf9\u4e8eFEDformer\u6a21\u578b\uff0c\u4e0d\u4f7f\u7528\u4f4d\u7f6e\u5d4c\u5165\uff08wo/Pos.\uff09\u65f6\uff0cMSE\u503c\u7565\u6709\u4e0b\u964d\uff0c\u800c\u4e0d\u4f7f\u7528\u65f6\u95f4\u6233\u5d4c\u5165\uff08wo/Temp.\uff09\u6216\u540c\u65f6\u4e0d\u4f7f\u7528\u4e24\u8005\uff08wo/Pos.-Temp.\uff09\u65f6\uff0cMSE\u503c\u6709\u6240\u589e\u52a0\u3002 - \u5bf9\u4e8eAutoformer\u6a21\u578b\uff0c\u4e0d\u4f7f\u7528\u4f4d\u7f6e\u5d4c\u5165\uff08wo/Pos.\uff09\u65f6\uff0cMSE\u503c\u7565\u6709\u4e0b\u964d\uff0c\u800c\u4e0d\u4f7f\u7528\u65f6\u95f4\u6233\u5d4c\u5165\uff08wo/Temp.\uff09\u6216\u540c\u65f6\u4e0d\u4f7f\u7528\u4e24\u8005\uff08wo/Pos.-Temp.\uff09\u65f6\uff0cMSE\u503c\u663e\u8457\u589e\u52a0\u3002 - \u5bf9\u4e8eInformer\u6a21\u578b\uff0c\u4e0d\u4f7f\u7528\u4f4d\u7f6e\u5d4c\u5165\uff08wo/Pos.\uff09\u65f6\uff0cMSE\u503c\u663e\u8457\u589e\u52a0\uff0c\u800c\u4e0d\u4f7f\u7528\u65f6\u95f4\u6233\u5d4c\u5165\uff08wo/Temp.\uff09\u6216\u540c\u65f6\u4e0d\u4f7f\u7528\u4e24\u8005\uff08wo/Pos.-Temp.\uff09\u65f6\uff0cMSE\u503c\u4e5f\u663e\u8457\u589e\u52a0\uff0c\u5c24\u5176\u662f\u5728\u8f83\u957f\u7684\u9884\u6d4b\u957f\u5ea6\u4e0b\u3002</p> <p>\u4f4d\u7f6e\u5d4c\u5165\u548c\u65f6\u95f4\u6233\u5d4c\u5165\u5bf9\u4e8eInformer\u6a21\u578b\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u800c\u5bf9\u4e8eFEDformer\u548cAutoformer\u6a21\u578b\uff0c\u4f4d\u7f6e\u5d4c\u5165\u7684\u5f71\u54cd\u8f83\u5c0f\uff0c\u65f6\u95f4\u6233\u5d4c\u5165\u7684\u5f71\u54cd\u8f83\u4e3a\u663e\u8457\u3002</p> <p>Rather than using a single time step in each token, FEDformer and Autoformer input a sequence of timestamps to embed the temporal information. Hence, they can achieve comparable or even better performance without fixed positional embeddings. However, without timestamp embeddings, the performance of Autoformer declines rapidly because of the loss of global temporal information. Instead, thanks to the frequency-enhanced module proposed in FEDformer to introduce temporal inductive bias, it suffers less from removing any position/timestamp embeddings.</p> <p>\u4e0e\u6bcf\u4e2atoken\u4ec5\u4f7f\u7528\u5355\u4e00\u65f6\u95f4\u6b65\u957f\u4e0d\u540c\uff0cFEDformer\u548cAutoformer\u8f93\u5165\u4e00\u7cfb\u5217\u65f6\u95f4\u6233\u6765\u5d4c\u5165\u65f6\u95f4\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u5b83\u4eec\u80fd\u591f\u5728\u6ca1\u6709\u56fa\u5b9a\u4f4d\u7f6e\u5d4c\u5165\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u53ef\u6bd4\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u5982\u679c\u6ca1\u6709\u65f6\u95f4\u6233\u5d4c\u5165\uff0cAutoformer\u7684\u6027\u80fd\u4f1a\u56e0\u4e3a\u5931\u53bb\u5168\u5c40\u65f6\u95f4\u4fe1\u606f\u800c\u8fc5\u901f\u4e0b\u964d\u3002\u76f8\u53cd\uff0c\u7531\u4e8eFEDformer\u4e2d\u63d0\u51fa\u7684\u9891\u7387\u589e\u5f3a\u6a21\u5757\u5f15\u5165\u4e86\u65f6\u95f4\u5f52\u7eb3\u504f\u7f6e\uff0c\u5b83\u5728\u79fb\u9664\u4efb\u4f55\u4f4d\u7f6e/\u65f6\u95f4\u6233\u5d4c\u5165\u65f6\u53d7\u5230\u7684\u5f71\u54cd\u8f83\u5c0f\u3002</p> <p>\u4f5c\u8005\u597d\u61c2\u8fd9\u4e9b\u6a21\u578b</p>"},{"location":"literature/TSP/2_DLinear/#6","title":"(6)\u6570\u636e\u96c6\u7684\u89c4\u6a21","text":"<p>Is training data size a limiting factor for existing LTSFTransformers? Some may argue that the poor performance of Transformer-based solutions is due to the small sizes of the benchmark datasets. Unlike computer vision or natural language processing tasks, TSF is performed on collected time series, and it is difficult to scale up the training data size. In fact, the size of the training data would indeed have a significant impact on the model performance. Accordingly, we conduct experiments on Traffic, comparing the performance of the model trained on a full dataset (17,544*0.7 hours), named Ori., with that trained on a shortened dataset (8,760 hours, i.e., 1 year), called Short.Unexpectedly, Table 7 presents that the prediction errors with reduced training data are lower in most cases. This might because the whole-year data maintains more clear temporal features than a longer but incomplete data size. While we cannot conclude that we should use less data for training, it demonstrates that the training data scale is not the limiting reason for the performances of Autoformer and FEDformer.</p> <p>\u6709\u4eba\u53ef\u80fd\u4f1a\u8ba4\u4e3a\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u6027\u80fd\u4e0d\u4f73\u662f\u7531\u4e8e\u57fa\u51c6\u6570\u636e\u96c6\u7684\u89c4\u6a21\u8f83\u5c0f\u3002\u4e0e\u8ba1\u7b97\u673a\u89c6\u89c9\u6216\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e0d\u540c\uff0c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u662f\u5728\u6536\u96c6\u5230\u7684\u65f6\u95f4\u5e8f\u5217\u4e0a\u6267\u884c\u7684\uff0c\u5e76\u4e14\u5f88\u96be\u6269\u5927\u8bad\u7ec3\u6570\u636e\u7684\u89c4\u6a21\u3002\u5b9e\u9645\u4e0a\uff0c\u8bad\u7ec3\u6570\u636e\u7684\u5927\u5c0f\u786e\u5b9e\u4f1a\u5bf9\u6a21\u578b\u6027\u80fd\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5728Traffic\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u5728\u5b8c\u6574\u6570\u636e\u96c6\uff0817,544*0.7\u5c0f\u65f6\uff09\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\uff08\u547d\u540d\u4e3aOri.\uff09\u4e0e\u5728\u7f29\u77ed\u6570\u636e\u96c6\uff088,760\u5c0f\u65f6\uff0c\u53731\u5e74\uff09\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\uff08\u79f0\u4e3aShort\uff09\u7684\u6027\u80fd\u3002\u51fa\u4e4e\u610f\u6599\u7684\u662f\uff0c\u88687\u663e\u793a\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u51cf\u5c11\u8bad\u7ec3\u6570\u636e\u540e\u7684\u9884\u6d4b\u8bef\u5dee\u66f4\u4f4e\u3002\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u5168\u5e74\u6570\u636e\u6bd4\u66f4\u957f\u4f46\u4e0d\u5b8c\u6574\u7684\u6570\u636e\u96c6\u4fdd\u6301\u4e86\u66f4\u6e05\u6670\u7684\u65f6\u95f4\u7279\u5f81\u3002\u867d\u7136\u6211\u4eec\u4e0d\u80fd\u5f97\u51fa\u6211\u4eec\u5e94\u8be5\u4f7f\u7528\u66f4\u5c11\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u7684\u7ed3\u8bba\uff0c\u4f46\u5b83\u8868\u660e\u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u5e76\u4e0d\u662fAutoformer\u548cFEDformer\u6027\u80fd\u7684\u9650\u5236\u539f\u56e0\u3002</p> <p></p> <p>\u8bad\u7ec3\u6570\u636e\u96c6\u89c4\u6a21\u53d8\u5c0f\u4f46\u662f\u9884\u6d4b\u6548\u679c\u66f4\u597d\u4e86\uff0c\u56e0\u4e3a\u867d\u7136\u8bad\u7ec3\u6570\u636e\u96c6\u53d8\u5c0f\u4e86\uff0c\u4f46\u4fdd\u5b58\u4e86\u5b8c\u6574\u7684\u6570\u636e\u53d8\u5316\u6a21\u5f0f\u3002  </p>"},{"location":"literature/TSP/2_DLinear/#7","title":"(7)\u6548\u7387\u771f\u7684\u5f88\u91cd\u8981\u5417\uff1f","text":"<p>Is efficiency really a top-level priority? </p> <p>Existing LTSF-Transformers claim that the \\(O(L^2)\\) complexity of the vanilla Transformer is unaffordable for the LTSF problem.\u539f\u59cb Transformer \u662f\u5e73\u65b9\u7ea7\u5185\u5b58\u590d\u6742\u5ea6\u548c\u65f6\u95f4\u590d\u6742\u5ea6</p> <p>Although they prove to be able to improve the theoretical time and memory complexity from \\(O(L^2)\\) to \\(O(L)\\), it is unclear whether 1) the actual inference time and memory cost on devices are improved, and 2) the memory issue is unacceptable and urgent for today's GPU (e.g., an NVIDIA Titan XP here). </p> <p>\u6548\u7387\u771f\u7684\u662f\u6700\u4f18\u5148\u8003\u8651\u7684\u56e0\u7d20\u5417\uff1f\u73b0\u6709\u7684\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4bTransformer\uff08LTSF-Transformers\uff09\u58f0\u79f0\uff0c\u4f20\u7edfTransformer\u7684\\(O(L^2)\\)\u590d\u6742\u5ea6\u5bf9\u4e8e\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u95ee\u9898\u6765\u8bf4\u662f\u96be\u4ee5\u627f\u53d7\u7684\u3002\u5c3d\u7ba1\u5b83\u4eec\u8bc1\u660e\u4e86\u80fd\u591f\u5c06\u7406\u8bba\u65f6\u95f4\u548c\u5185\u5b58\u590d\u6742\u5ea6\u4ece\\(O(L^2)\\)\u6539\u8fdb\u5230\\(O(L)\\)\uff0c\u4f46\u76ee\u524d\u8fd8\u4e0d\u6e05\u695a1\uff09\u8bbe\u5907\u4e0a\u7684\u5b9e\u9645\u63a8\u7406\u65f6\u95f4\u548c\u5185\u5b58\u6210\u672c\u662f\u5426\u5f97\u5230\u6539\u5584\uff0c\u4ee5\u53ca2\uff09\u5185\u5b58\u95ee\u9898\u662f\u5426\u662f\u5f53\u524dGPU\uff08\u4f8b\u5982\uff0c\u8fd9\u91cc\u7684NVIDIA Titan XP\uff09\u6240\u4e0d\u80fd\u63a5\u53d7\u4e14\u7d27\u8feb\u7684\u3002</p> <p>In Table 8, we compare the average practical efficiencies with 5 runs. Interestingly, compared with the vanilla Transformer (with the same DMS decoder), most Transformer variants incur similar or even worse inference time and parameters in practice. These follow-ups introduce more additional design elements to make practical costs high. Moreover, the memory cost of the vanilla Transformer is practically acceptable, even for output length \\(L = 720\\), which weakens the importance of developing a memory-efficient Transformers, at least for existing benchmarks.</p> <p>\u5728\u88688\u4e2d\uff0c\u6211\u4eec\u6bd4\u8f83\u4e865\u6b21\u8fd0\u884c\u7684\u5e73\u5747\u5b9e\u9645\u6548\u7387\u3002\u6709\u8da3\u7684\u662f\uff0c\u4e0e\u4f20\u7edfTransformer\uff08\u4f7f\u7528\u76f8\u540c\u7684DMS\u89e3\u7801\u5668\uff09\u76f8\u6bd4\uff0c\u5927\u591a\u6570Transformer\u53d8\u4f53\u5728\u5b9e\u8df5\u4e2d\u4ea7\u751f\u4e86\u76f8\u4f3c\u751a\u81f3\u66f4\u5dee\u7684\u63a8\u7406\u65f6\u95f4\u548c\u53c2\u6570\u3002\u8fd9\u4e9b\u540e\u7eed\u5de5\u4f5c\u5f15\u5165\u4e86\u66f4\u591a\u7684\u8bbe\u8ba1\u5143\u7d20\uff0c\u4f7f\u5f97\u5b9e\u9645\u6210\u672c\u53d8\u9ad8\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u5bf9\u4e8e\u8f93\u51fa\u957f\u5ea6\\(L = 720\\)\uff0c\u4f20\u7edfTransformer\u7684\u5185\u5b58\u6210\u672c\u5728\u5b9e\u8df5\u4e2d\u4e5f\u662f\u53ef\u4ee5\u63a5\u53d7\u7684\uff0c\u8fd9\u524a\u5f31\u4e86\u81f3\u5c11\u5bf9\u4e8e\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u800c\u8a00\u5f00\u53d1\u5185\u5b58\u9ad8\u6548Transformer\u7684\u91cd\u8981\u6027\u3002</p> <p>\u8fd9\u7bc7\u8bba\u6587\u51fa\u6765\uff0c\u5927\u5bb6\u4ee5\u540e\u600e\u4e48\u7814\u7a76\u65f6\u5e8f\u5440\uff0c\u5168\u9762\u5426\u5b9a\u7684\u7a0b\u5ea6</p> <p></p> <p>\u201cTable 8. Comparison of practical efficiency of LTSF-Transformers under L=96 and T=720 on the Electricity.\u201d \u8868\u683c\u6bd4\u8f83\u4e86\u5728\u7535\u529b\u6570\u636e\u96c6\u4e0a\uff0c\u9884\u6d4b\u957f\u5ea6L=96\u548c\u65f6\u95f4\u6b65\u957fT=720\u65f6\uff0c\u4e0d\u540c\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09Transformer\u6a21\u578b\u7684\u5b9e\u9645\u6548\u7387\u3002\u6548\u7387\u901a\u8fc7\u56db\u4e2a\u6307\u6807\u6765\u8861\u91cf\uff1aMACs\uff08\u4e58\u7d2f\u52a0\u64cd\u4f5c\u6570\uff09\u3001\u53c2\u6570\u6570\u91cf\u3001\u63a8\u7406\u65f6\u95f4\u4ee5\u53ca\u5185\u5b58\u4f7f\u7528\u91cf\u3002</p> <p>\u8868\u683c\u4e2d\u5305\u542b\u7684\u6a21\u578b\u6709\uff1a - DLinear - Transformer\u00d7\uff08\u4fee\u6539\u81eaAutoformer\u7684\u4e00\u6b65\u89e3\u7801\u5668\uff09 - Informer - Autoformer - Pyraformer - FEDformer</p> <p>\u8868\u683c\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a - DLinear\u6a21\u578b\u7684MACs\u4e3a0.04G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a139.K7\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a0.4ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a687MiB\u3002 - Transformer\u00d7\u6a21\u578b\u7684MACs\u4e3a4.03G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a13.61M\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a26.8ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a6091MiB\u3002 - Informer\u6a21\u578b\u7684MACs\u4e3a3.93G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a14.39M\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a49.3ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a3869MiB\u3002 - Autoformer\u6a21\u578b\u7684MACs\u4e3a4.41G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a14.91M\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a164.1ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a7607MiB\u3002 - Pyraformer\u6a21\u578b\u7684MACs\u4e3a0.80G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a241.4M*\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a3.4ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a7017MiB\u3002\uff08\u6ce8\uff1aPyraformer\u7684\u53c2\u6570\u6570\u91cf\u4e2d236.7M\u6765\u81ea\u5176\u7ebf\u6027\u89e3\u7801\u5668\uff09 - FEDformer\u6a21\u578b\u7684MACs\u4e3a4.41G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a20.68M\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a40.5ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a4143MiB\u3002</p> <p>\u8868\u683c\u5e95\u90e8\u7684\u6ce8\u91ca\u8bf4\u660e\uff1a - Transformer\u00d7\u6a21\u578b\u88ab\u4fee\u6539\u4e3a\u4e0eAutoformer\u76f8\u540c\u7684\u4e00\u6b65\u89e3\u7801\u5668\u3002 - Pyraformer\u6a21\u578b\u7684\u53c2\u6570\u6570\u91cf\u4e2d\uff0c236.7M\u6765\u81ea\u5176\u7ebf\u6027\u89e3\u7801\u5668\u3002 - \u4f7f\u7528DLinear\u4f5c\u4e3a\u6bd4\u8f83\u57fa\u51c6\uff0c\u56e0\u4e3a\u5b83\u5728LTSF-Linear\u4e2d\u7684\u6210\u672c\u662fDLinear\u7684\u4e24\u500d\u3002 - \u63a8\u7406\u65f6\u95f4\u662f5\u6b21\u8fd0\u884c\u7684\u5e73\u5747\u503c\u3002</p> <p>\u603b\u4f53\u6765\u770b\uff0cDLinear\u6a21\u578b\u5728\u6240\u6709\u6307\u6807\u4e0a\u90fd\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u6548\u7387\uff0c\u800cAutoformer\u548cFEDformer\u5728\u5185\u5b58\u4f7f\u7528\u91cf\u4e0a\u8f83\u9ad8\uff0cInformer\u5728\u63a8\u7406\u65f6\u95f4\u4e0a\u6700\u9ad8\u3002</p> <p>\u8be5\u56fe\u7247\u5c55\u793a\u4e86\u4e00\u5f20\u8868\u683c\uff0c\u6807\u9898\u4e3a\u201cTable 8. Comparison of practical efficiency of LTSF-Transformers under L=96 and T=720 on the Electricity.\u201d \u8868\u683c\u6bd4\u8f83\u4e86\u5728\u7535\u529b\u6570\u636e\u96c6\u4e0a\uff0c\u9884\u6d4b\u957f\u5ea6L=96\u548c\u65f6\u95f4\u6b65\u957fT=720\u65f6\uff0c\u4e0d\u540c\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09Transformer\u6a21\u578b\u7684\u5b9e\u9645\u6548\u7387\u3002\u6548\u7387\u901a\u8fc7\u56db\u4e2a\u6307\u6807\u6765\u8861\u91cf\uff1aMACs\uff08\u4e58\u7d2f\u52a0\u64cd\u4f5c\u6570\uff09\u3001\u53c2\u6570\u6570\u91cf\u3001\u63a8\u7406\u65f6\u95f4\u4ee5\u53ca\u5185\u5b58\u4f7f\u7528\u91cf\u3002</p> <p>\u8868\u683c\u4e2d\u5305\u542b\u7684\u6a21\u578b\u6709\uff1a - DLinear - Transformer\u00d7\uff08\u4fee\u6539\u81eaAutoformer\u7684\u4e00\u6b65\u89e3\u7801\u5668\uff09 - Informer - Autoformer - Pyraformer - FEDformer</p> <p>\u8868\u683c\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a - DLinear\u6a21\u578b\u7684MACs\u4e3a0.04G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a139.K7\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a0.4ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a687MiB\u3002 - Transformer\u00d7\u6a21\u578b\u7684MACs\u4e3a4.03G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a13.61M\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a26.8ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a6091MiB\u3002 - Informer\u6a21\u578b\u7684MACs\u4e3a3.93G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a14.39M\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a49.3ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a3869MiB\u3002 - Autoformer\u6a21\u578b\u7684MACs\u4e3a4.41G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a14.91M\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a164.1ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a7607MiB\u3002 - Pyraformer\u6a21\u578b\u7684MACs\u4e3a0.80G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a241.4M*\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a3.4ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a7017MiB\u3002\uff08\u6ce8\uff1aPyraformer\u7684\u53c2\u6570\u6570\u91cf\u4e2d236.7M\u6765\u81ea\u5176\u7ebf\u6027\u89e3\u7801\u5668\uff09 - FEDformer\u6a21\u578b\u7684MACs\u4e3a4.41G\uff0c\u53c2\u6570\u6570\u91cf\u4e3a20.68M\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a40.5ms\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u4e3a4143MiB\u3002</p> <p>\u8868\u683c\u5e95\u90e8\u7684\u6ce8\u91ca\u8bf4\u660e\uff1a - Transformer\u00d7\u6a21\u578b\u88ab\u4fee\u6539\u4e3a\u4e0eAutoformer\u76f8\u540c\u7684\u4e00\u6b65\u89e3\u7801\u5668\u3002 - Pyraformer\u6a21\u578b\u7684\u53c2\u6570\u6570\u91cf\u4e2d\uff0c236.7M\u6765\u81ea\u5176\u7ebf\u6027\u89e3\u7801\u5668\u3002 - \u4f7f\u7528DLinear\u4f5c\u4e3a\u6bd4\u8f83\u57fa\u51c6\uff0c\u56e0\u4e3a\u5b83\u5728LTSF-Linear\u4e2d\u7684\u6210\u672c\u662fDLinear\u7684\u4e24\u500d\u3002 - \u63a8\u7406\u65f6\u95f4\u662f5\u6b21\u8fd0\u884c\u7684\u5e73\u5747\u503c\u3002</p> <p>\u603b\u4f53\u6765\u770b\uff0cDLinear\u6a21\u578b\u5728\u6240\u6709\u6307\u6807\u4e0a\u90fd\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u6548\u7387\uff0c\u800cAutoformer\u548cFEDformer\u5728\u5185\u5b58\u4f7f\u7528\u91cf\u4e0a\u8f83\u9ad8\uff0cInformer\u5728\u63a8\u7406\u65f6\u95f4\u4e0a\u6700\u9ad8\u3002</p> <p>emm</p>"},{"location":"literature/TSP/2_DLinear/#6-conclusion-and-future-work","title":"6. Conclusion and Future Work","text":"<p>Conclusion. This work questions the effectiveness of emerging favored Transformer-based solutions for the longterm time series forecasting problem. We use an embarrassingly simple linear model LTSF-Linear as a DMS forecasting baseline to verify our claims. Note that our contributions do not come from proposing a linear model but rather from throwing out an important question, showing surprising comparisons, and demonstrating why LTSFTransformers are not as effective as claimed in these works through various perspectives. We sincerely hope our comprehensive studies can benefit future work in this area.</p> <p>\u7ed3\u8bba\u3002\u672c\u5de5\u4f5c\u5bf9\u65b0\u5174\u7684\u57fa\u4e8eTransformer\u7684\u89e3\u51b3\u65b9\u6848\u5728\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\u4e0a\u7684\u6709\u6548\u6027\u63d0\u51fa\u4e86\u8d28\u7591\u3002\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u6781\u5176\u7b80\u5355\u7684\u7ebf\u6027\u6a21\u578bLTSF-Linear\u4f5c\u4e3aDMS\u9884\u6d4b\u7684\u57fa\u7ebf\u6765\u9a8c\u8bc1\u6211\u4eec\u7684\u8bba\u65ad\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u6211\u4eec\u7684\u8d21\u732e\u5e76\u975e\u6765\u81ea\u4e8e\u63d0\u51fa\u4e00\u4e2a\u7ebf\u6027\u6a21\u578b\uff0c\u800c\u662f\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u4ee4\u4eba\u60ca\u8bb6\u7684\u6bd4\u8f83\u7ed3\u679c\uff0c\u5e76\u4ece\u591a\u4e2a\u89d2\u5ea6\u8bc1\u660e\u4e86\u4e3a\u4ec0\u4e48LTSF-Transformers\u5e76\u4e0d\u50cf\u8fd9\u4e9b\u5de5\u4f5c\u4e2d\u6240\u58f0\u79f0\u7684\u90a3\u6837\u6709\u6548\u3002\u6211\u4eec\u771f\u8bda\u5730\u5e0c\u671b\u6211\u4eec\u5168\u9762\u7684\u7814\u7a76\u6240\u80fd\u4e3a\u8fd9\u4e00\u9886\u57df\u7684\u672a\u6765\u5de5\u4f5c\u5e26\u6765\u76ca\u5904\u3002</p> <p>\u73b0\u5728 DLinear \u53c8\u88ab\u5f88\u591a\u6a21\u578b\u5bf9\u6bd4\uff0c\u4f46\u4e5f\u56e0\u6b64\u51fa\u73b0\u5f88\u591a Linear \u7cfb\u7684\u6587\u7ae0\uff0c\u6bd4\u5982 UNetTSF</p> <p>Future work.  LTSF-Linear has a limited model capacity, and it merely serves a simple yet competitive baseline with strong interpretability for future research. For example, the one-layer linear network is hard to capture the temporal dynamics caused by change points [25]. Consequently, we believe there is a great potential for new model designs, data processing, and benchmarks to tackle the challenging LTSF problem.</p> <p>\u672a\u6765\u5de5\u4f5c\u3002LTSF-Linear\u6a21\u578b\u7684\u5bb9\u91cf\u6709\u9650\uff0c\u5b83\u4ec5\u4f5c\u4e3a\u4e00\u4e2a\u7b80\u5355\u4f46\u5177\u6709\u7ade\u4e89\u529b\u7684\u57fa\u7ebf\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u5f3a\u6709\u529b\u7684\u53ef\u89e3\u91ca\u6027\u3002\u4f8b\u5982\uff0c\u5355\u5c42\u7ebf\u6027\u7f51\u7edc\u5f88\u96be\u6355\u6349\u7531\u53d8\u5316\u70b9\u5f15\u8d77\u7684\u65f6\u95f4\u52a8\u6001\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u76f8\u4fe1\u5728\u65b0\u6a21\u578b\u8bbe\u8ba1\u3001\u6570\u636e\u5904\u7406\u548c\u57fa\u51c6\u6d4b\u8bd5\u65b9\u9762\uff0c\u89e3\u51b3\u5177\u6709\u6311\u6218\u6027\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08LTSF\uff09\u95ee\u9898\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002</p>"},{"location":"literature/TSP/2_DLinear/#appendix","title":"Appendix","text":"<p>In this Appendix, we provide descriptions of non Transformer-based TSF solutions, detailed experimental settings, more comparisons under different look-back window sizes, and the visualization of LTSF-Linear on all datasets. We also append our code to reproduce the results shown in the paper.</p> <p>\u5728\u672c\u9644\u5f55\u4e2d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u975eTransformer\u57fa\u7840\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u89e3\u51b3\u65b9\u6848\u7684\u63cf\u8ff0\u3001\u8be6\u7ec6\u7684\u5b9e\u9a8c\u8bbe\u7f6e\u3001\u5728\u4e0d\u540c\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u4e0b\u7684\u66f4\u591a\u6bd4\u8f83\uff0c\u4ee5\u53caLTSF-Linear\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u7684\u53ef\u89c6\u5316\u7ed3\u679c\u3002\u6211\u4eec\u8fd8\u9644\u4e0a\u4e86\u91cd\u73b0\u8bba\u6587\u4e2d\u5c55\u793a\u7ed3\u679c\u7684\u4ee3\u7801\u3002</p>"},{"location":"literature/TSP/2_DLinear/#a-related-work-non-transformer-based-tsf-solutions","title":"A. Related Work: Non-Transformer-Based TSF Solutions","text":"<p>As a long-standing problem with a wide range of applications, statistical approaches (e.g., autoregressive integrated moving average (ARIMA) [1], exponential smoothing [12], and structural models [14]) for time series forecasting have been used from the 1970s onward. Generally speaking, the parametric models used in statistical methods require significant domain expertise to build.</p> <p>\u4f5c\u4e3a\u4e00\u4e2a\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u7684\u957f\u671f\u95ee\u9898\uff0c\u81ea20\u4e16\u7eaa70\u5e74\u4ee3\u4ee5\u6765\uff0c\u7edf\u8ba1\u65b9\u6cd5\uff08\u4f8b\u5982\uff0c\u81ea\u56de\u5f52\u79ef\u5206\u6ed1\u52a8\u5e73\u5747\u6a21\u578b\uff08ARIMA\uff09[1]\u3001\u6307\u6570\u5e73\u6ed1[12]\u548c\u7ed3\u6784\u6a21\u578b[14]\uff09\u5df2\u88ab\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u7edf\u8ba1\u65b9\u6cd5\u4e2d\u4f7f\u7528\u7684\u53c2\u6570\u6a21\u578b\u9700\u8981\u663e\u8457\u7684\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u6765\u6784\u5efa\u3002</p> <p>To relieve this burden, many machine learning techniques such as gradient boosting regression tree (GBRT) [10, 11] gain popularity, which learns the temporal dynamics of time series in a data-driven manner. However, these methods still require manual feature engineering and model designs. With the powerful representation learning capability of deep neural networks (DNNs) from abundant data, various deep learning-based TSF solutions are proposed in the literature, achieving better forecasting accuracy than traditional techniques in many cases.</p> <p>\u4e3a\u4e86\u51cf\u8f7b\u8fd9\u4e00\u8d1f\u62c5\uff0c\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5982\u68af\u5ea6\u63d0\u5347\u56de\u5f52\u6811\uff08GBRT\uff09[10, 11]\uff0c\u56e0\u5176\u80fd\u591f\u4ee5\u6570\u636e\u9a71\u52a8\u7684\u65b9\u5f0f\u5b66\u4e60\u65f6\u95f4\u5e8f\u5217\u7684\u65f6\u95f4\u52a8\u6001\u800c\u53d8\u5f97\u6d41\u884c\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4ecd\u7136\u9700\u8981\u4eba\u5de5\u7279\u5f81\u5de5\u7a0b\u548c\u6a21\u578b\u8bbe\u8ba1\u3002\u5f97\u76ca\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNNs\uff09\u7684\u5f3a\u5927\u8868\u793a\u5b66\u4e60\u80fd\u529b\uff0c\u4ece\u5927\u91cf\u6570\u636e\u4e2d\uff0c\u6587\u732e\u4e2d\u63d0\u51fa\u4e86\u5404\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684TSF\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u6bd4\u4f20\u7edf\u6280\u672f\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002</p> <p>Besides Transformers, the other two popular DNN architectures are also applied for time series forecasting:</p> <p>\u9664\u4e86Transformers\uff0c\u53e6\u5916\u4e24\u79cd\u6d41\u884c\u7684DNN\u67b6\u6784\u4e5f\u88ab\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff1a</p> <p>\u5176\u5b9e\u662f\u80fd\u611f\u89c9\u5230\u7684\uff0c\u6df1\u5ea6\u5b66\u4e60\u8bbe\u8ba1\u7684\u7f51\u7edc\u5f88\u5c11\u6d89\u53ca\u4e13\u4e1a\u77e5\u8bc6\uff0c\u51e0\u4e4e\u4e0d\u9700\u8981\u6ce8\u5165\u592a\u591a\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u73b0\u5728\u65f6\u5e8f\u9884\u6d4b\u6a21\u578b\uff0c\u8bbe\u8ba1\u6df1\u5ea6\u5b66\u4e60\u7684\u5f00\u59cb\u5f15\u5165\u4f20\u7edf\u7edf\u8ba1\u77e5\u8bc6\uff0c\u6bd4\u5982\u5e8f\u5217\u5206\u89e3\uff0c\u9891\u57df\u77e5\u8bc6\uff0c\u521a\u5f00\u59cb\u7684\u8bbe\u8ba1\u4e5f\u4e0d\u50cf\u662f\u4e13\u95e8\u9488\u5bf9\u65f6\u5e8f\u6570\u636e\uff0c\u4f46\u5176\u5b9e\u628a\u5177\u6709\u957f\u671f\u8d8b\u52bf\u7684\u6210\u5206\u5265\u79bb\u51fa\u6765\uff0c\u4e0d\u5c31\u662f\u7528 Transformer</p> <ul> <li>Recurrent neural networks (RNNs) based methods (e.g., [21]) summarize the past information compactly in internal memory states and recursively update themselves for forecasting.</li> <li>\u57fa\u4e8e\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\uff08RNNs\uff09\u7684\u65b9\u6cd5\uff08\u4f8b\u5982\uff0c[21]\uff09\u5728\u5185\u90e8\u8bb0\u5fc6\u72b6\u6001\u4e2d\u7d27\u51d1\u5730\u603b\u7ed3\u8fc7\u53bb\u4fe1\u606f\uff0c\u5e76\u9012\u5f52\u5730\u81ea\u6211\u66f4\u65b0\u4ee5\u8fdb\u884c\u9884\u6d4b\u3002</li> <li>Convolutional neural networks (CNNs) based methods (e.g., [3]), wherein convolutional filters are used to capture local temporal features.</li> <li>\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNNs\uff09\u7684\u65b9\u6cd5\uff08\u4f8b\u5982\uff0c[3]\uff09\uff0c\u5176\u4e2d\u4f7f\u7528\u5377\u79ef\u6ee4\u6ce2\u5668\u6765\u6355\u6349\u5c40\u90e8\u65f6\u95f4\u7279\u5f81\u3002</li> </ul> <p>RNN-based TSF methods belong to IMS forecasting techniques. Depending on whether the decoder is implemented in an autoregressive manner, there are either IMS or DMS forecasting techniques for CNN-based TSF methods [3, 17].</p> <ul> <li>\u57fa\u4e8eRNN\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u65b9\u6cd5\u5c5e\u4e8e\u5355\u6b65\u9884\u6d4b\uff08IMS\uff09\u6280\u672f\u3002\u6839\u636e\u89e3\u7801\u5668\u662f\u5426\u4ee5\u81ea\u56de\u5f52\u65b9\u5f0f\u5b9e\u73b0\uff0c\u5bf9\u4e8e\u57fa\u4e8eCNN\u7684TSF\u65b9\u6cd5\uff0c\u53ef\u4ee5\u662f\u5355\u6b65\u9884\u6d4b\uff08IMS\uff09\u6216\u591a\u6b65\u9884\u6d4b\uff08DMS\uff09\u6280\u672f[3, 17]\u3002</li> </ul>"},{"location":"literature/TSP/2_DLinear/#b-experimental-details","title":"B. Experimental Details","text":""},{"location":"literature/TSP/2_DLinear/#b1-data-descriptions","title":"B.1. Data Descriptions","text":"<p>We use nine wildly-used datasets in the main paper. The details are listed in the following.</p> <ul> <li>ETT (Electricity Transformer Temperature) [30]2 consists of two hourly-level datasets (ETTh) and two 15minute-level datasets (ETTm). Each of them contains seven oil and load features of electricity transformers from July 2016 to July 2018.  </li> <li>ETT\uff08\u7535\u529b\u53d8\u538b\u5668\u6e29\u5ea6\uff09[30] \u5305\u542b\u4e24\u4e2a\u5c0f\u65f6\u7ea7\u522b\u7684\u6570\u636e\u96c6\uff08ETTh\uff09\u548c\u4e24\u4e2a15\u5206\u949f\u7ea7\u522b\u7684\u6570\u636e\u96c6\uff08ETTm\uff09\u3002\u6bcf\u4e2a\u6570\u636e\u96c6\u90fd\u5305\u542b\u4e86\u4ece2016\u5e747\u6708\u81f32018\u5e747\u6708\u7684\u7535\u529b\u53d8\u538b\u5668\u7684\u4e03\u4e2a\u6cb9\u548c\u8d1f\u8f7d\u7279\u5f81\u3002</li> <li>Traffic3 describes the road occupancy rates. It contains the hourly data recorded by the sensors of San Francisco freeways from 2015 to 2016.  </li> <li>\u4ea4\u901a[3] \u63cf\u8ff0\u4e86\u9053\u8def\u5360\u7528\u7387\u3002\u5b83\u5305\u542b\u4e862015\u5e74\u81f32016\u5e74\u65e7\u91d1\u5c71\u9ad8\u901f\u516c\u8def\u4f20\u611f\u5668\u8bb0\u5f55\u7684\u6bcf\u5c0f\u65f6\u6570\u636e\u3002</li> <li>Electricity4 collects the hourly electricity consumption of 321 clients from 2012 to 2014.  </li> <li>\u7535\u529b[4] \u6536\u96c6\u4e862012\u5e74\u81f32014\u5e74321\u4e2a\u5ba2\u6237\u7684\u6bcf\u5c0f\u65f6\u7535\u529b\u6d88\u8017\u6570\u636e\u3002</li> <li>Exchange-Rate [15]5 collects the daily exchange rates of 8 countries from 1990 to 2016.  </li> <li>\u6c47\u7387[15] \u6536\u96c6\u4e861990\u5e74\u81f32016\u5e748\u4e2a\u56fd\u5bb6\u7684\u6bcf\u65e5\u6c47\u7387\u3002</li> <li>Weather6 includes 21 indicators of weather, such as air temperature, and humidity. Its data is recorded every 10 min for 2020 in Germany.  </li> <li>\u5929\u6c14[6] \u5305\u62ec21\u4e2a\u6c14\u8c61\u6307\u6807\uff0c\u5982\u7a7a\u6c14\u6e29\u5ea6\u548c\u6e7f\u5ea6\u3002\u5176\u6570\u636e\u662f2020\u5e74\u5728\u5fb7\u56fd\u6bcf10\u5206\u949f\u8bb0\u5f55\u4e00\u6b21\u7684\u3002</li> <li>ILI7 describes the ratio of patients seen with influenzalike illness and the number of patients. It includes weekly data from the Centers for Disease Control and Prevention of the United States from 2002 to 2021.</li> <li>ILI[7] \u63cf\u8ff0\u4e86\u60a3\u6709\u6d41\u611f\u6837\u75be\u75c5\u7684\u60a3\u8005\u6bd4\u4f8b\u548c\u60a3\u8005\u6570\u91cf\u3002\u5b83\u5305\u62ec\u4e862002\u5e74\u81f32021\u5e74\u7f8e\u56fd\u75be\u75c5\u63a7\u5236\u4e0e\u9884\u9632\u4e2d\u5fc3\u7684\u6bcf\u5468\u6570\u636e\u3002</li> </ul>"},{"location":"literature/TSP/2_DLinear/#b2-implementation-details","title":"B.2. Implementation Details","text":"<p>For existing Transformer-based TSF solutions: the implementation of Autoformer [28], Informer [30], and the vanilla Transformer [26] are all taken from the Autoformer work [28]; the implementation of FEDformer [31] and Pyraformer [18] are from their respective code repository. We also adopt their default hyper-parameters to train the models. For DLinear, the moving average kernel size for decomposition is 25, which is the same as Autoformer. The total parameters of a vanilla linear model and a NLinear are TL. The total parameters of the DLinear are 2TL. Since LTSF-Linear will be underfitting when the input length is short, and LTSF-Transformers tend to overfit on a long lookback window size. To compare the best performance of existing LTSF-Transformers with LTSF-Linear, we report L=336 for LTSF-Linear and L=96 for Transformers by default. For more hyper-parameters of LTSF-Linear, please refer to our code.</p> <p>\u5bf9\u4e8e\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u89e3\u51b3\u65b9\u6848\uff1aAutoformer[28]\u3001Informer[30]\u548c\u4f20\u7edfTransformer[26]\u7684\u5b9e\u73b0\u90fd\u53d6\u81eaAutoformer\u7684\u5de5\u4f5c[28]\uff1bFEDformer[31]\u548cPyraformer[18]\u7684\u5b9e\u73b0\u5206\u522b\u6765\u81ea\u5b83\u4eec\u5404\u81ea\u7684\u4ee3\u7801\u5e93\u3002</p> <p>\u6211\u4eec\u8fd8\u91c7\u7528\u4e86\u5b83\u4eec\u7684\u9ed8\u8ba4\u8d85\u53c2\u6570\u6765\u8bad\u7ec3\u6a21\u578b\u3002\u5bf9\u4e8eDLinear\uff0c\u5206\u89e3\u65f6\u79fb\u52a8\u5e73\u5747\u6838\u7684\u5927\u5c0f\u4e3a25\uff0c\u8fd9\u4e0eAutoformer\u76f8\u540c\u3002</p> <p>\u4e00\u4e2a\u4f20\u7edf\u7ebf\u6027\u6a21\u578b\u548c\u4e00\u4e2aNLinear\u7684\u603b\u53c2\u6570\u91cf\u4e3aTL\u3002DLinear\u7684\u603b\u53c2\u6570\u91cf\u4e3a2TL\u3002</p> <p>\u7531\u4e8e\u5f53\u8f93\u5165\u957f\u5ea6\u8f83\u77ed\u65f6\uff0cLTSF-Linear\u53ef\u80fd\u4f1a\u51fa\u73b0\u6b20\u62df\u5408\uff0c\u800cLTSF-Transformers\u5728\u8f83\u957f\u7684\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u65f6\u5219\u503e\u5411\u4e8e\u8fc7\u62df\u5408\u3002\u4e3a\u4e86\u6bd4\u8f83\u73b0\u6709LTSF-Transformers\u4e0eLTSF-Linear\u7684\u6700\u4f73\u6027\u80fd\uff0c\u6211\u4eec\u9ed8\u8ba4\u62a5\u544aLTSF-Linear\u7684L=336\u548cTransformers\u7684L=96\u3002\u6709\u5173LTSF-Linear\u7684\u66f4\u591a\u8d85\u53c2\u6570\uff0c\u8bf7\u53c2\u9605\u6211\u4eec\u7684\u4ee3\u7801\u3002</p>"},{"location":"literature/TSP/2_DLinear/#c-additional-comparison-with-transformers","title":"C. Additional Comparison with Transformers","text":"<p>We further compare LTSF-Linear with LTSFTransformer for Univariate Forecasting on four ETT datasets. Moreover, in Figure 4 of the main paper, we demonstrate that existing Transformers fail to exploit large look-back window sizes with two examples. Here, we give comprehensive comparisons between LTSF-Linear and Transformer-based TSF solutions under various look-back window sizes on all benchmarks.</p> <p>\u6211\u4eec\u8fdb\u4e00\u6b65\u5c06LTSF-Linear\u4e0eLTSF-Transformer\u5728\u56db\u4e2aETT\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5355\u53d8\u91cf\u9884\u6d4b\u7684\u6bd4\u8f83\u3002\u6b64\u5916\uff0c\u5728\u4e3b\u8981\u8bba\u6587\u7684\u56fe4\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u4e24\u4e2a\u4f8b\u5b50\u5c55\u793a\u4e86\u73b0\u6709\u7684Transformer\u65e0\u6cd5\u5229\u7528\u5927\u7684\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u3002\u5728\u6b64\uff0c\u6211\u4eec\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u5728\u5404\u79cd\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u4e0b\uff0c\u5bf9LTSF-Linear\u548c\u57fa\u4e8eTransformer\u7684TSF\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6bd4\u8f83\u3002</p>"},{"location":"literature/TSP/2_DLinear/#c1-comparison-of-univariate-forecasting","title":"C.1. Comparison of Univariate Forecasting","text":"<p>We present the univariate forecasting results on the four ETT datasets in table 9. Similarly, LTSF-Linear, especially for NLinear can consistently outperform all transformerbased methods by a large margin in most time. We find that there are serious distribution shifts between training and test sets (as shown in Fig. 5 (a), (b)) on ETTh1 and ETTh2 datasets. Simply normalization via the last value from the lookback window can greatly relieve the distribution shift problem.</p> <p>\u6211\u4eec\u5728\u88689\u4e2d\u5c55\u793a\u4e86\u56db\u4e2aETT\u6570\u636e\u96c6\u4e0a\u7684\u5355\u53d8\u91cf\u9884\u6d4b\u7ed3\u679c\u3002\u540c\u6837\u5730\uff0cLTSF-Linear\uff0c\u7279\u522b\u662fNLinear\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u90fd\u80fd\u663e\u8457\u4f18\u4e8e\u6240\u6709\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u5728ETTh1\u548cETTh2\u6570\u636e\u96c6\u4e0a\uff0c\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e4b\u95f4\u5b58\u5728\u4e25\u91cd\u7684\u5206\u5e03\u504f\u79fb\uff08\u5982\u56fe5(a)\u3001(b)\u6240\u793a\uff09\u3002\u7b80\u5355\u5730\u901a\u8fc7\u56de\u6eaf\u7a97\u53e3\u7684\u6700\u540e\u4e00\u4e2a\u503c\u8fdb\u884c\u5f52\u4e00\u5316\u53ef\u4ee5\u5927\u5927\u7f13\u89e3\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002</p> <p></p> <p>\u201cTable 9. Univariate long sequence time-series forecasting results on ETT full benchmark.\u201d \u8868\u683c\u5217\u51fa\u4e86\u5728ETT\u5b8c\u6574\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u5355\u53d8\u91cf\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u8868\u683c\u4e2d\u5305\u542b\u7684\u6a21\u578b\u6709\uff1a</p> <ul> <li>Linear\uff08\u7ebf\u6027\u6a21\u578b\uff09</li> <li>NLinear</li> <li>DLinear</li> <li>FEDformer-f</li> <li>FEDformer-w</li> <li>Autoformer</li> <li>Informer</li> <li>LogTrans</li> </ul> <p>\u9884\u6d4b\u957f\u5ea6\uff08Predict Length\uff09\u5206\u4e3a\u56db\u4e2a\u4e0d\u540c\u7684\u503c\uff1a96\u3001192\u3001336\u3001720\u3002</p> <p>\u5bf9\u4e8e\u6bcf\u4e2a\u6a21\u578b\u548c\u9884\u6d4b\u957f\u5ea6\uff0c\u8868\u683c\u5c55\u793a\u4e86\u4e24\u79cd\u8bc4\u4ef7\u6307\u6807\uff1a\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u548c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u3002\u8868\u683c\u4e2d\u7528\u7c97\u4f53\u5b57\u7a81\u51fa\u663e\u793a\u4e86\u6700\u4f73\u7ed3\u679c\uff0c\u800c\u7528\u4e0b\u5212\u7ebf\u6807\u51fa\u4e86Transformer\u6a21\u578b\u7684\u6700\u4f73\u7ed3\u679c\u3002</p> <p>\u4ece\u8868\u683c\u4e2d\u53ef\u4ee5\u89c2\u5bdf\u5230\uff1a - \u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0cDLinear\u6a21\u578b\u5728MSE\u548cMAE\u6307\u6807\u4e0a\u90fd\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002 - \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0cNLinear\u6a21\u578b\u4e5f\u53d6\u5f97\u4e86\u76f8\u5bf9\u8f83\u597d\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728ETTh1\u6570\u636e\u96c6\u7684720\u9884\u6d4b\u957f\u5ea6\u4e0b\u3002 - \u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08FEDformer\u3001Autoformer\u3001Informer\u3001LogTrans\uff09\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4e5f\u8868\u73b0\u826f\u597d\uff0c\u4f46\u901a\u5e38\u4e0d\u5982DLinear\u548cNLinear\u6a21\u578b\u3002 - Linear\u6a21\u578b\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u90fd\u76f8\u5bf9\u8f83\u5dee\u3002</p> <p>\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u5728ETT\u6570\u636e\u96c6\u4e0a\u7684\u5355\u53d8\u91cf\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cDLinear\u548cNLinear\u6a21\u578b\u901a\u5e38\u6bd4\u5176\u4ed6\u6a21\u578b\uff08\u5305\u62ec\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff09\u8868\u73b0\u66f4\u597d\u3002</p> <p></p> <p>ETT \u6570\u636e\u96c6\u3001Electricity \u6570\u636e\u96c6\u3001ILI \u8bad\u7ec3\u96c6&amp;\u6d4b\u8bd5\u96c6\u4e0a\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898</p>"},{"location":"literature/TSP/2_DLinear/#c2-comparison-under-different-look-back-windows","title":"C.2. Comparison under Different Look-back Windows","text":"<p>In Figure 6, we provide the MSE comparisons of five LTSF-Transformers with LTSF-Linear under different lookback window sizes to explore whether existing Transformers can extract temporal well from longer input sequences. For hourly granularity datasets (ETTh1, ETTh2, Traffic, and Electricity), the increasing look-back window sizes are {24, 48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720}, which represent {1, 2, 3, 4, 5, 6, 7, 8, 14, 21, 28, 30} days. The forecasting steps are {24, 720}, which mean {1, 30} days. For 5-minute granularity datasets (ETTm1 and ETTm2), we set the look-back window size as {24, 36, 48, 60, 72, 144, 288}, which represent {2, 3, 4, 5, 6, 12, 24} hours. For 10-minute granularity datasets (Weather), we set the look-back window size as {24, 48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720}, which mean {4, 8, 12, 16, 20, 24, 28, 32, 56, 84, 112, 120} hours. The forecasting steps are {24, 720} that are {4, 120} hours. For weekly granularity dataset (ILI), we set the look-back window size as {26, 52, 78, 104, 130, 156, 208}, which represent {0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4} years. The corresponding forecasting steps are {26, 208}, meaning {0.5, 4} years.</p> <p>\u5728\u56fe6\u4e2d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e94\u79cdLTSF-Transformer\u4e0eLTSF-Linear\u5728\u4e0d\u540c\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u4e0b\u7684\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u6bd4\u8f83\uff0c\u4ee5\u63a2\u7d22\u73b0\u6709\u7684Transformer\u662f\u5426\u80fd\u591f\u4ece\u66f4\u957f\u7684\u8f93\u5165\u5e8f\u5217\u4e2d\u5f88\u597d\u5730\u63d0\u53d6\u65f6\u95f4\u7279\u5f81\u3002\u5bf9\u4e8e\u5c0f\u65f6\u7c92\u5ea6\u6570\u636e\u96c6\uff08ETTh1\u3001ETTh2\u3001\u4ea4\u901a\u548c\u7535\u529b\uff09\uff0c\u589e\u52a0\u7684\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u4e3a{24, 48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720}\uff0c\u8fd9\u4ee3\u8868{1, 2, 3, 4, 5, 6, 7, 8, 14, 21, 28, 30}\u5929\u3002\u9884\u6d4b\u6b65\u957f\u4e3a{24, 720}\uff0c\u8fd9\u610f\u5473\u7740{1, 30}\u5929\u3002</p> <p>\u5bf9\u4e8e5\u5206\u949f\u7c92\u5ea6\u6570\u636e\u96c6\uff08ETTm1\u548cETTm2\uff09\uff0c\u6211\u4eec\u5c06\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u8bbe\u7f6e\u4e3a{24, 36, 48, 60, 72, 144, 288}\uff0c\u8fd9\u4ee3\u8868{2, 3, 4, 5, 6, 12, 24}\u5c0f\u65f6\u3002</p> <p>\u5bf9\u4e8e10\u5206\u949f\u7c92\u5ea6\u6570\u636e\u96c6\uff08\u5929\u6c14\uff09\uff0c\u6211\u4eec\u5c06\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u8bbe\u7f6e\u4e3a{24, 48, 72, 96, 120, 144, 168, 192, 336, 504, 672, 720}\uff0c\u8fd9\u610f\u5473\u7740{4, 8, 12, 16, 20, 24, 28, 32, 56, 84, 112, 120}\u5c0f\u65f6\u3002\u9884\u6d4b\u6b65\u957f\u4e3a{24, 720}\uff0c\u5373{4, 120}\u5c0f\u65f6\u3002</p> <p>\u5bf9\u4e8e\u5468\u7c92\u5ea6\u6570\u636e\u96c6\uff08ILI\uff09\uff0c\u6211\u4eec\u5c06\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u8bbe\u7f6e\u4e3a{26, 52, 78, 104, 130, 156, 208}\uff0c\u8fd9\u4ee3\u8868{0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4}\u5e74\u3002\u76f8\u5e94\u7684\u9884\u6d4b\u6b65\u957f\u4e3a{26, 208}\uff0c\u610f\u5473\u7740{0.5, 4}\u5e74\u3002</p> <p>As shown in Figure 6, with increased look-back window sizes, the performance of LTSF-Linear is significantly boosted for most datasets (e.g., ETTm1 and Traffic), while this is not the case for Transformer-based TSF solutions. Most of their performance fluctuates or gets worse as the input lengths increase. To be specific, the results of Exchange-Rate do not show improved results with a long look-back window (from Figure 6(m) and (n)), and we attribute it to the low information-to-noise ratio in such financial data.</p> <p>\u5982\u56fe6\u6240\u793a\uff0c\u968f\u7740\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u7684\u589e\u52a0\uff0cLTSF-Linear\u5728\u5927\u591a\u6570\u6570\u636e\u96c6\uff08\u4f8b\u5982\uff0cETTm1\u548c\u4ea4\u901a\uff09\u4e0a\u7684\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u800c\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff08TSF\uff09\u89e3\u51b3\u65b9\u6848\u5219\u5e76\u975e\u5982\u6b64\u3002\u968f\u7740\u8f93\u5165\u957f\u5ea6\u7684\u589e\u52a0\uff0c\u5b83\u4eec\u7684\u5927\u591a\u6570\u6027\u80fd\u6ce2\u52a8\u6216\u53d8\u5f97\u66f4\u5dee\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6c47\u7387\u7684\u7ed3\u679c\u5e76\u672a\u663e\u793a\u51fa\u4f7f\u7528\u957f\u56de\u6eaf\u7a97\u53e3\u540e\u7684\u6539\u5584\uff08\u89c1\u56fe6(m)\u548c(n)\uff09\uff0c\u6211\u4eec\u5c06\u6b64\u5f52\u56e0\u4e8e\u8fd9\u7c7b\u91d1\u878d\u6570\u636e\u4e2d\u4f4e\u4fe1\u606f\u566a\u58f0\u6bd4\u3002</p> <p></p> <p></p> <p>\u56fe6. \u4e0d\u540c\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\uff08X\u8f74\uff09\u4e0b\u6a21\u578b\u7684\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u7ed3\u679c\uff08Y\u8f74\uff09\uff0c\u8fd9\u4e9b\u7ed3\u679c\u6db5\u76d6\u4e86\u957f\u671f\u9884\u6d4b\uff08\u4f8b\u5982\uff0c720\u4e2a\u65f6\u95f4\u6b65\u957f\uff09\u548c\u77ed\u671f\u9884\u6d4b\uff08\u4f8b\u5982\uff0c24\u4e2a\u65f6\u95f4\u6b65\u957f\uff09\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\u3002</p>"},{"location":"literature/TSP/2_DLinear/#d-ablation-study-on-the-ltsf-linear","title":"D. Ablation study on the LTSF-Linear","text":""},{"location":"literature/TSP/2_DLinear/#d1-motivation-of-nlinear","title":"D.1. Motivation of NLinear","text":"<p>If we normalize the test data by the mean and variance of train data, there could be a distribution shift in testing data, i.e, the mean value of testing data is not 0. If the model made a prediction that is out of the distribution of true value, a large error would occur. For example, there is a large error between the true value and the true value minus/add one. </p> <p>\u5982\u679c\u6211\u4eec\u6839\u636e\u8bad\u7ec3\u6570\u636e\u7684\u5747\u503c\u548c\u65b9\u5dee\u5bf9\u6d4b\u8bd5\u6570\u636e\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u6d4b\u8bd5\u6570\u636e\u53ef\u80fd\u4f1a\u51fa\u73b0\u5206\u5e03\u504f\u79fb\uff0c\u5373\u6d4b\u8bd5\u6570\u636e\u7684\u5747\u503c\u4e0d\u4e3a0\u3002\u5982\u679c\u6a21\u578b\u505a\u51fa\u7684\u9884\u6d4b\u8d85\u51fa\u4e86\u771f\u5b9e\u503c\u7684\u5206\u5e03\u8303\u56f4\uff0c\u5c31\u4f1a\u51fa\u73b0\u8f83\u5927\u7684\u8bef\u5dee\u3002\u4f8b\u5982\uff0c\u771f\u5b9e\u503c\u4e0e\u771f\u5b9e\u503c\u51cf\u4e00\u6216\u52a0\u4e00\u4e4b\u95f4\u5b58\u5728\u8f83\u5927\u7684\u8bef\u5dee\u3002</p> <p>Therefore, in NLinear, we use the subtraction and addition to shift the model prediction toward the distribution of true value. Then, large errors are avoided, and the model performances can be improved. Figure 5 illustrates histograms of the trainset-test set distributions, where each bar represents the number of data points. Clear distribution shifts between training and testing data can be observed in ETTh1, ETTh2, and ILI. Accordingly, from Table 9 and Table 2 in the main paper, we can observe that there are great improvements in the three datasets comparing the NLinear to the Linear, showing the effectiveness of the NLinear in relieving distribution shifts. Moreover, for the datasets without obvious distribution shifts, like Electricity in Figure 5(c), using the vanilla Linear can be enough, demonstrating the similar performance with NLinear and DLinear.</p> <p>\u56e0\u6b64\uff0c\u5728NLinear\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u51cf\u6cd5\u548c\u52a0\u6cd5\u5c06\u6a21\u578b\u9884\u6d4b\u5411\u771f\u5b9e\u503c\u7684\u5206\u5e03\u65b9\u5411\u8c03\u6574\u3002\u8fd9\u6837\uff0c\u5c31\u53ef\u4ee5\u907f\u514d\u5927\u7684\u8bef\u5dee\uff0c\u5e76\u4e14\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002\u56fe5\u5c55\u793a\u4e86\u8bad\u7ec3\u96c6-\u6d4b\u8bd5\u96c6\u5206\u5e03\u7684\u76f4\u65b9\u56fe\uff0c\u5176\u4e2d\u6bcf\u4e2a\u6761\u5f62\u4ee3\u8868\u6570\u636e\u70b9\u7684\u6570\u91cf\u3002\u5728ETTh1\u3001ETTh2\u548cILI\u4e2d\u53ef\u4ee5\u89c2\u5bdf\u5230\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\u4e4b\u95f4\u660e\u663e\u7684\u5206\u5e03\u504f\u79fb\u3002\u76f8\u5e94\u5730\uff0c\u4ece\u4e3b\u8bba\u6587\u4e2d\u7684\u88689\u548c\u88682\uff0c\u6211\u4eec\u53ef\u4ee5\u89c2\u5bdf\u5230\u5728\u8fd9\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u5c06NLinear\u4e0eLinear\u8fdb\u884c\u6bd4\u8f83\u65f6\uff0c\u6027\u80fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u8fd9\u663e\u793a\u4e86NLinear\u5728\u7f13\u89e3\u5206\u5e03\u504f\u79fb\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u6ca1\u6709\u660e\u663e\u5206\u5e03\u504f\u79fb\u7684\u6570\u636e\u96c6\uff0c\u5982\u56fe5(c)\u4e2d\u7684\u7535\u529b\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u4f20\u7edf\u7684Linear\u53ef\u80fd\u5c31\u8db3\u591f\u4e86\uff0c\u8fd9\u8868\u660eLinear\u4e0eNLinear\u548cDLinear\u7684\u6027\u80fd\u76f8\u4f3c\u3002</p>"},{"location":"literature/TSP/2_DLinear/#d2-the-features-of-ltsf-linear","title":"D.2. The Features of LTSF-Linear","text":"<p>Although LTSF-Linear is simple, it has some compelling characteristics:</p> <p>\u5c3d\u7ba1LTSF-Linear\u6a21\u578b\u7b80\u5355\uff0c\u4f46\u5b83\u5177\u6709\u4e00\u4e9b\u5f15\u4eba\u6ce8\u76ee\u7684\u7279\u6027\uff1a</p> <ul> <li>An O(1) maximum signal traversing path length: The shorter the path, the better the dependencies are captured [18], making LTSF-Linear capable of capturing both short-range and long-range temporal relations.</li> <li>\\(O(1)\\)\u7684\u6700\u5927\u4fe1\u53f7\u7a7f\u8d8a\u8def\u5f84\u957f\u5ea6\uff1a\u8def\u5f84\u8d8a\u77ed\uff0c\u6355\u83b7\u7684\u4f9d\u8d56\u5173\u7cfb\u8d8a\u597d[18]\uff0c\u4f7f\u5f97LTSF-Linear\u80fd\u591f\u6355\u6349\u5230\u77ed\u671f\u548c\u957f\u671f\u7684\u65f6\u5e8f\u5173\u7cfb\u3002</li> <li>High-efficiency: As LTSF-Linear is a linear model with two linear layers at most, it costs much lower memory and fewer parameters and has a faster inference speed than existing Transformers (see Table 8 in main paper).</li> <li>\u9ad8\u6548\u7387\uff1a\u7531\u4e8eLTSF-Linear\u6700\u591a\u5305\u542b\u4e24\u4e2a\u7ebf\u6027\u5c42\u7684\u7ebf\u6027\u6a21\u578b\uff0c\u5b83\u7684\u5185\u5b58\u6d88\u8017\u66f4\u4f4e\uff0c\u53c2\u6570\u66f4\u5c11\uff0c\u5e76\u4e14\u6bd4\u73b0\u6709\u7684Transformer\u5177\u6709\u66f4\u5feb\u7684\u63a8\u7406\u901f\u5ea6\uff08\u89c1\u4e3b\u8bba\u6587\u4e2d\u7684\u88688\uff09\u3002</li> <li>Interpretability: After training, we can visualize weights from the seasonality and trend branches to have some insights on the predicted values [9].</li> <li>\u53ef\u89e3\u91ca\u6027\uff1a\u8bad\u7ec3\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u4ece\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u5206\u652f\u4e2d\u53ef\u89c6\u5316\u6743\u91cd\uff0c\u4ee5\u5bf9\u9884\u6d4b\u503c\u6709\u6240\u4e86\u89e3[9]\u3002</li> <li>Easy-to-use: LTSF-Linear can be obtained easily without tuning model hyper-parameters.</li> <li>\u6613\u7528\u6027\uff1aLTSF-Linear\u53ef\u4ee5\u8f7b\u677e\u83b7\u5f97\uff0c\u65e0\u9700\u8c03\u6574\u6a21\u578b\u8d85\u53c2\u6570\u3002</li> </ul>"},{"location":"literature/TSP/2_DLinear/#d3-interpretability-of-ltsf-linear","title":"D.3. Interpretability of LTSF-Linear","text":"<p>Because LTSF-Linear is a set of linear models, the weights of linear layers can directly reveal how LTSFLinear works. The weight visualization of LTSF-Linear can also reveal certain characteristics in the data used for forecasting.</p> <p>\u7531\u4e8eLTSF-Linear\u662f\u4e00\u7ec4\u7ebf\u6027\u6a21\u578b\uff0c\u7ebf\u6027\u5c42\u7684\u6743\u91cd\u53ef\u4ee5\u76f4\u63a5\u63ed\u793aLTSF-Linear\u7684\u5de5\u4f5c\u539f\u7406\u3002LTSF-Linear\u7684\u6743\u91cd\u53ef\u89c6\u5316\u8fd8\u53ef\u4ee5\u63ed\u793a\u7528\u4e8e\u9884\u6d4b\u7684\u6570\u636e\u4e2d\u7684\u67d0\u4e9b\u7279\u5f81\u3002</p> <p>Here we take DLinear as an example. Accordingly, we visualize the trend and remainder weights of all datasets with a fixed input length of 96 and four different forecasting horizons. To obtain a smooth weight with a clear pattern in visualization, we initialize the weights of the linear layers in DLinear as 1/L rather than random initialization. That is, we use the same weight for every forecasting time step in the look-back window at the start of training.</p> <p>\u8fd9\u91cc\u6211\u4eec\u4ee5DLinear\u4e3a\u4f8b\u3002\u76f8\u5e94\u5730\uff0c\u6211\u4eec\u53ef\u89c6\u5316\u4e86\u6240\u6709\u6570\u636e\u96c6\u7684\u8d8b\u52bf\u548c\u6b8b\u5dee\u6743\u91cd\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u5177\u6709\u56fa\u5b9a\u7684\u8f93\u5165\u957f\u5ea696\u548c\u56db\u4e2a\u4e0d\u540c\u7684\u9884\u6d4b\u8303\u56f4\u3002\u4e3a\u4e86\u5728\u53ef\u89c6\u5316\u4e2d\u83b7\u5f97\u5e73\u6ed1\u4e14\u5177\u6709\u6e05\u6670\u6a21\u5f0f\u7684\u6743\u91cd\uff0c\u6211\u4eec\u521d\u59cb\u5316DLinear\u4e2d\u7ebf\u6027\u5c42\u7684\u6743\u91cd\u4e3a\\(1/L\\)\uff0c\u800c\u4e0d\u662f\u968f\u673a\u521d\u59cb\u5316\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u5728\u8bad\u7ec3\u5f00\u59cb\u65f6\uff0c\u6211\u4eec\u5728\u56de\u6eaf\u7a97\u53e3\u4e2d\u7684\u6bcf\u4e2a\u9884\u6d4b\u65f6\u95f4\u6b65\u4f7f\u7528\u76f8\u540c\u7684\u6743\u91cd\u3002</p> <p>**How the model works:**Figure 7(c) visualize the weights of the trend and the remaining layers on the Exchange-Rate dataset. Due to the lack of periodicity and seasonality in financial data, it is hard to observe clear patterns, but the trend layer reveals greater weights of information closer to the outputs, representing their larger contributions to the predicted values.</p> <p>**\u6a21\u578b\u5de5\u4f5c\u539f\u7406\uff1a**\u56fe7(c)\u5c55\u793a\u4e86\u6c47\u7387\u6570\u636e\u96c6\u4e0a\u8d8b\u52bf\u5c42\u548c\u5269\u4f59\u5c42\u7684\u6743\u91cd\u3002\u7531\u4e8e\u91d1\u878d\u6570\u636e\u7f3a\u4e4f\u5468\u671f\u6027\u548c\u5b63\u8282\u6027\uff0c\u5f88\u96be\u89c2\u5bdf\u5230\u6e05\u6670\u7684\u6a21\u5f0f\uff0c\u4f46\u8d8b\u52bf\u5c42\u63ed\u793a\u4e86\u66f4\u63a5\u8fd1\u8f93\u51fa\u7684\u4fe1\u606f\u5177\u6709\u66f4\u5927\u7684\u6743\u91cd\uff0c\u8fd9\u4ee3\u8868\u4e86\u5b83\u4eec\u5bf9\u9884\u6d4b\u503c\u7684\u66f4\u5927\u8d21\u732e\u3002</p> <p>Periodicity of data: For Traffic data, as shown in Figure 7(d), the model gives high weights to the latest time step of the look-back window for the 0,23,47...719 forecast ing steps. Among these forecasting time steps, the 0, 167, 335, 503, 671 time steps have higher weights. Note that 24 time steps are a day, and 168 time steps are a week. This indicates that Traffic has a daily periodicity and a weekly periodicity.</p> <p>\u6570\u636e\u7684\u5468\u671f\u6027\uff1a\u5bf9\u4e8e\u4ea4\u901a\u6570\u636e\uff0c\u5982\u56fe7(d)\u6240\u793a\uff0c\u6a21\u578b\u5bf9\u4e8e\u9884\u6d4b\u6b65\u957f0\u300123\u300147...719\u7684\u6700\u65b0\u65f6\u95f4\u6b65\u8d4b\u4e88\u4e86\u8f83\u9ad8\u7684\u6743\u91cd\u3002\u5728\u8fd9\u4e9b\u9884\u6d4b\u65f6\u95f4\u6b65\u4e2d\uff0c0\u3001167\u3001335\u3001503\u3001671\u65f6\u95f4\u6b65\u7684\u6743\u91cd\u66f4\u9ad8\u3002\u8bf7\u6ce8\u610f\uff0c24\u4e2a\u65f6\u95f4\u6b65\u4ee3\u8868\u4e00\u5929\uff0c168\u4e2a\u65f6\u95f4\u6b65\u4ee3\u8868\u4e00\u5468\u3002\u8fd9\u8868\u660e\u4ea4\u901a\u6570\u636e\u5177\u6709\u65e5\u5468\u671f\u6027\u548c\u5468\u5468\u671f\u6027\u3002</p> <p> </p> <p></p> <p> </p> <p>\u8fd9\u5e45\u56fe\u662fLTSF-Linear\u6a21\u578b\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6743\u91cd\uff08T*L\uff09\u53ef\u89c6\u5316\u3002\u56fe\u4e2d\u5c55\u793a\u4e86\u6a21\u578b\u5728\u56de\u6eaf\u7a97\u53e3\u5927\u5c0f\u4e3aL\uff08X\u8f74\uff09\u548c\u4e0d\u540c\u7684\u9884\u6d4b\u65f6\u95f4\u6b65\u957fT\uff08Y\u8f74\uff09\u4e0b\u8bad\u7ec3\u5f97\u5230\u7684\u6743\u91cd\u3002\u56fe\u4e2d\u5305\u62ec\u4e86\u8d8b\u52bf\u5c42\uff08Trend\uff09\u548c\u6b8b\u5dee\u5c42\uff08Remainder\uff09\u7684\u6743\u91cd\u3002</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u56fe\u4e2d\u5c55\u793a\u4e86\u4ee5\u4e0b\u56db\u79cd\u60c5\u51b5\u7684\u6743\u91cd\u5206\u5e03\uff1a 1. (f1) \u548c (f3)\uff1a\u6b8b\u5dee\u5c42\u7684\u6743\u91cd\uff0c\u5206\u522b\u5bf9\u5e94\u9884\u6d4b\u6b65\u957f\u4e3a24\u548c36\u3002 2. (f2) \u548c (f4)\uff1a\u8d8b\u52bf\u5c42\u7684\u6743\u91cd\uff0c\u5206\u522b\u5bf9\u5e94\u9884\u6d4b\u6b65\u957f\u4e3a24\u548c36\u3002 3. (f5) \u548c (f7)\uff1a\u6b8b\u5dee\u5c42\u7684\u6743\u91cd\uff0c\u5206\u522b\u5bf9\u5e94\u9884\u6d4b\u6b65\u957f\u4e3a48\u548c60\u3002 4. (f6) \u548c (f8)\uff1a\u8d8b\u52bf\u5c42\u7684\u6743\u91cd\uff0c\u5206\u522b\u5bf9\u5e94\u9884\u6d4b\u6b65\u957f\u4e3a48\u548c60\u3002</p> <p>\u6bcf\u4e2a\u5b50\u56fe\u7684X\u8f74\u8868\u793a\u56de\u6eaf\u7a97\u53e3\u4e2d\u7684\u65f6\u95f4\u6b65\u957f\uff0cY\u8f74\u8868\u793a\u9884\u6d4b\u7684\u65f6\u95f4\u6b65\u957f\u3002\u989c\u8272\u6761\u8868\u793a\u6743\u91cd\u7684\u5927\u5c0f\uff0c\u989c\u8272\u4ece\u84dd\u8272\uff08\u8d1f\u6743\u91cd\uff09\u5230\u9ec4\u8272\uff08\u6b63\u6743\u91cd\uff09\u53d8\u5316\uff0c\u6743\u91cd\u7684\u7edd\u5bf9\u503c\u8d8a\u5927\uff0c\u989c\u8272\u8d8a\u63a5\u8fd1\u9ec4\u8272\u3002</p> <p>\u901a\u8fc7\u8fd9\u4e9b\u53ef\u89c6\u5316\uff0c\u53ef\u4ee5\u89c2\u5bdf\u5230\u6a21\u578b\u5728\u4e0d\u540c\u65f6\u95f4\u6b65\u957f\u4e0a\u7684\u6743\u91cd\u5206\u5e03\u60c5\u51b5\uff0c\u4ece\u800c\u4e86\u89e3\u6a21\u578b\u662f\u5982\u4f55\u4ece\u8f93\u5165\u6570\u636e\u4e2d\u5b66\u4e60\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u7684\u3002\u4f8b\u5982\uff0c\u53ef\u4ee5\u89c2\u5bdf\u5230\u67d0\u4e9b\u65f6\u95f4\u6b65\u957f\u7684\u6743\u91cd\u5728\u7279\u5b9a\u9884\u6d4b\u6b65\u957f\u4e0a\u66f4\u4e3a\u663e\u8457\uff0c\u8fd9\u53ef\u80fd\u8868\u660e\u8fd9\u4e9b\u65f6\u95f4\u6b65\u957f\u5bf9\u9884\u6d4b\u7ed3\u679c\u6709\u66f4\u5927\u7684\u5f71\u54cd\u3002</p>"},{"location":"literature/TSP/3_TimesNet/","title":"2023\u3001TimesNet","text":""},{"location":"literature/TSP/3_TimesNet/#2023timesnet","title":"2023\u3001TimesNet","text":"2025-03-04 21:01:002025-09-28 12:54:06 <p> \u7ea6 459 \u4e2a\u5b57  18 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <ul> <li> \u4ee3\u7801\u7ed3\u6784\u56fe</li> </ul> <p>TIMESNET: TEMPORAL 2D-VARIATION MODELING FOR GENERAL TIME SERIES ANALYSIS</p> <p></p> <p>\u3010\u53c2\u770b\u3011\u8bba\u6587\u7814\u8bfb\u4e4b\u65f6\u5e8f\u5206\u6790\u901a\u7528\u57fa\u7840\u6a21\u578b\uff1aTimesNet \u9884\u6d4b/\u63d2\u8865/\u5206\u7c7b/\u5f02\u5e38\u68c0\u6d4b</p> <p>\u4f5c\u8005\u56e2\u961f</p> <p> </p> <p>\u671f\u520a\uff1aICLR2023</p>"},{"location":"literature/TSP/3_TimesNet/#_1","title":"\u95ee\u9898\u63cf\u8ff0","text":"<p>\u65f6\u95f4\u5e8f\u5217\u7684\u591a\u5468\u671f\u6027\uff0c\u76f8\u4e92\u91cd\u53e0\u3001\u76f8\u4e92\u5f71\u54cd</p> <p>\u4f8b\u5982\u4ea4\u901a\u6d41\u9886\u57df\uff0c\u4e00\u822c\u4f1a\u7528\u4e09\u4e2a\u5468\u671f\uff1a</p> <ul> <li>recently\uff1a\u76f8\u90bb 1 \u5c0f\u65f6\u7684\u53d8\u6362</li> <li>daily\uff1a\u5468\u4e00\u5230\u5468\u4e8c\u7684\u53d8\u5316\uff08\u5468\u4e00\u7684\u65e9\u4e0a\u548c\u5468\u4e8c\u7684\u65e9\u4e0a\uff09</li> <li>weekly\uff1a\u6bcf\u5468\u7684\u53d8\u6362\uff08\u6bcf\u5468\u7684\u5468\u4e00\u4e4b\u95f4\u4e5f\u76f8\u4e92\u6709\u5173\u7cfb\uff09</li> </ul> <p>\u8fd9\u7bc7\u6587\u7ae0\u7ed9\u4e86\u591a\u5468\u671f\u6027\u4e24\u4e2a\u5b9a\u4e49</p> <ul> <li>\u5468\u671f\u5185\u53d8\u5316\u53eb intra\uff1a\u76f8\u90bb\u533a\u57df\u7684\u65f6\u95f4\u3001\u77ed\u671f\u7684\u65f6\u95f4\u6a21\u5f0f</li> <li>\u5468\u671f\u95f4\u53d8\u5316\u53eb inter\uff1a\u76f8\u90bb\u65f6\u6bb5\u5b58\u5728\u4e00\u4e2a\u8fde\u7eed\u4e0d\u540c\u65f6\u671f\u7684\u4e00\u4e2a\u957f\u671f\u8d8b\u52bf\uff0c\u4f8b\u5982 \u4e24\u4e2a\u5468\u671f\u4e4b\u95f4\u7684\u5468\u4e00\u548c\u5468\u4e00</li> </ul> <p>\u4e0d\u540c\u7684\u5468\u671f\u5bfc\u81f4\u4e0d\u540c\u7684\u5468\u671f\u5185\u548c\u5468\u671f\u95f4\u7684\u53d8\u5316\uff0c\u8ddf\u5468\u671f\u957f\u5ea6\u662f\u6709\u5173\u7cfb\u7684</p>"},{"location":"literature/TSP/3_TimesNet/#_2","title":"\u521b\u65b0\u70b9","text":"<p>\u7b2c\u4e00\u4e2a\u521b\u65b0\u70b9\uff0c\u7528\u6a21\u5757\u5316\u5bf9\u65f6\u95f4\u53d8\u6362\u8fdb\u884c\u5efa\u6a21\uff0c\u628a\u4e00\u7ef4\u7684\u8fd9\u4e2a\u65f6\u95f4\u5e8f\u5217\u8f6c\u6210\u4e8c\u7ef4\u7684\u56fe\uff08\u6216\u8005\u8bf4\u77e9\u9635\uff09\uff0c\u540c\u65f6\u8868\u793a\u5468\u671f\u5185\u548c\u5468\u671f\u95f4\u7684\u53d8\u5316</p> <p>\u5177\u4f53\u6765\u8bf4\uff1a\u62fc\u63a5\u76f8\u540c\u5ea6\u91cf\u7684\u65f6\u95f4\u6b65</p> <p>\u5468\u671f\u95f4\uff1a\u4e0d\u540c\u5468\u671f\u540c\u4e00\u65f6\u6bb5\u7684\u70b9\u4e32\u8d77\u6765</p> <p>\u7ea2\u8272\u8868\u793a \u5468\u671f\u5185\uff0c\u84dd\u8272\u8868\u793a\u5468\u671f\u95f4</p> <p></p> <p>\u7b2c\u4e8c\u4e2a\u521b\u65b0\u70b9\uff0c\u8bbe\u8ba1\u4e86 \u65f6\u95f4\u6a21\u5757 times block\uff0c\u81ea\u9002\u5e94\u7684\u53d1\u73b0\u591a\u5468\u671f\uff0c\u8fd9\u4e2a\u6a21\u578b\u91cc\u9762\u5305\u542b\u4e86\u53d1\u73b0\u591a\u5468\u671f\u7684\u65b9\u5f0f\uff1b\u7b2c\u4e8c\u65b9\u9762\uff1a\u4ece\u8fd9\u4e2a\u4e8c\u7ef4\u5f20\u91cf\u91cc\u9762\u53ef\u4ee5\u6355\u83b7\u65f6\u95f4\u53d8\u5316</p> <p>\u7b2c\u4e09\u4e2a\uff0c\u4efb\u52a1\u901a\u7528\u7684\u57fa\u7840\u6a21\u578b</p>"},{"location":"literature/TSP/3_TimesNet/#_3","title":"\u65b9\u6cd5","text":"<p>\u7b2c\u4e00\u4e2a\u90e8\u5206\uff0c\u81ea\u9002\u5e94\u7684\u53d1\u73b0\u591a\u5468\u671f\uff0c</p> <p>\u8865\uff1a\u5085\u91cc\u53f6\u53d8\u6362</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"literature/TSP/3_TimesNet/#_4","title":"\u5b9e\u9a8c\u7ed3\u679c","text":""},{"location":"literature/TSP/3_TimesNet/#_5","title":"\u957f\u671f\u9884\u6d4b","text":""},{"location":"literature/TSP/3_TimesNet/#_6","title":"\u77ed\u671f\u9884\u6d4b","text":""},{"location":"literature/TSP/3_TimesNet/#_7","title":"\u63d2\u8865","text":""},{"location":"literature/TSP/3_TimesNet/#_8","title":"\u5206\u7c7b","text":""},{"location":"literature/TSP/3_TimesNet/#_9","title":"\u5f02\u5e38\u68c0\u6d4b","text":""},{"location":"literature/TSP/4_Informer/","title":"2021\u3001 Informer","text":""},{"location":"literature/TSP/4_Informer/#2021-informer","title":"2021\u3001 Informer","text":"2025-03-04 21:01:002025-09-28 12:54:06 <p> \u7ea6 1959 \u4e2a\u5b57  16 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 10 \u5206\u949f</p> <ul> <li> \u4ee3\u7801\u7ed3\u6784\u56fe</li> </ul> <p> </p> <p>\u53c2\u770b\uff1a\u6ed1\u52a8\u7a97\u53e3\u673a\u5236\u6982\u8ff0</p>"},{"location":"literature/TSP/4_Informer/#_1","title":"\u6a21\u578b\u63a5\u53d7\u8f93\u5165","text":"<ul> <li> <p>batch_size\uff1abatch\u4e2d\u6837\u672c\u7684\u6570\u91cf\uff0c\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u6bcf\u6b21\u4ee5\u4e00\u4e2abatch\u4e3a\u8f93\u5165\u5355\u4f4d\u6765\u8fdb\u884c\u8bad\u7ec3\u3002 </p> </li> <li> <p>seq_len\uff1aEncoder\u63a5\u6536\u7684\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\uff0c\u4e5f\u662f\u6ed1\u52a8\u7a97\u53e3\u4e2d\u7684\u7a97\u53e3\u957f\u5ea6\u3002</p> </li> <li> <p>label_len\uff1aDecoder\u5f00\u59cb\u9636\u6bb5\u63a5\u6536\u7684\u5df2\u77e5\u5e8f\u5217\u7684\u957f\u5ea6\uff08\u5373\u201c\u6807\u7b7e\u201d\u7528\u4e8e\u5f15\u5bfc\u89e3\u7801\u5668\u7684\u9884\u6d4b\uff09\u3002</p> </li> <li> <p>pred_len:Decoder\u9884\u6d4b\u672a\u6765\u65f6\u95f4\u70b9\u7684\u957f\u5ea6\u3002</p> </li> </ul> <p><code>Informer</code> \u5728\u8bad\u7ec3\u65f6<code>Encoder</code>\u8f93\u5165\u7684\u662f<code>batch_size</code>\u4e2a\u5927\u5c0f\u7684**\u89c4\u8303\u6837\u672c**\uff0c\u5176\u4e2d\u6bcf\u4e2a\u89c4\u8303\u6837\u672c\u90fd\u662f\u901a\u8fc7**\u6ed1\u52a8\u7a97\u53e3\u6280\u672f**\u4ece\u539f\u59cb\u6570\u636e\u96c6\u6837\u672c\u4e2d\u63d0\u53d6\u51fa\u6765\u7684\uff0c\u6bcf\u4e2a\u89c4\u8303\u6837\u672c\u90fd\u5305\u542b<code>seq_len</code>\u4e2a\u65f6\u95f4\u6b65\u957f\u7684\u6570\u636e\u70b9\uff08\u5373\u6bcf\u4e2a\u89c4\u8303\u6837\u672c\u90fd\u5305\u542b\u8bad\u7ec3\u96c6\u4e2d<code>seq_len</code>\u884c\u8fde\u7eed\u6570\u636e\uff09\u3002</p>"},{"location":"literature/TSP/4_Informer/#_2","title":"\u6ed1\u52a8\u7a97\u53e3","text":"<p>\u6ed1\u52a8\u7a97\u53e3\u5b9e\u73b0\u539f\u7406\uff1a </p> <p>\u4e3e\u4e2a\u4f8b\u5b50\uff0c\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u7ec4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u8bb0\u5f55\u4e86<code>1000h</code>\u7684\u6c14\u6e29\uff08<code>1000</code>\u884c\uff09\uff0c\u8bbe\u5b9a<code>seq_len=72</code>\uff08\u7a97\u53e3\u957f\u5ea6\uff09\uff0c<code>label_len=48</code>\uff0c<code>pred_len=24</code>\uff0c<code>batch_size=12</code>\u3002</p> <p>\u521d\u59cb\uff1a\u4ece<code>\u7b2c1h</code>\u5f00\u59cb\uff0c\u653e\u7f6e\u4e00\u4e2a<code>72h</code>\u7684\u6ed1\u52a8\u7a97\u53e3\uff0c\u7a97\u53e3\u5185\u6837\u672c\u5305\u542b<code>\u7b2c1h\u201472h</code>\u6c14\u6e29\uff0c\u8fd9\u65f6<code>batch</code>\u4e2d\u7684\u4e00\u4e2a\u89c4\u8303\u6837\u672c\u5c31\u662f\u5f53\u524d\u7a97\u53e3\u5185\u7684<code>72h</code>\u6837\u672c\uff0c\u8be5\u89c4\u8303\u6837\u672c\u5bf9\u5e94\u7684==\u6807\u7b7e==\u4e3a25h\u201472h\u6c14\u6e29\uff0c\u8be5\u89c4\u8303\u6837\u672c\u5bf9\u5e94\u7684==\u9884\u6d4b\u6837\u672c==\u4e3a<code>73h\u201496h</code>\u6c14\u6e29\u3002</p> <p></p>"},{"location":"literature/TSP/4_Informer/#embedding","title":"\u5173\u4e8e embedding","text":"<p>Embedding\u539f\u7406\uff1a  Embedding\u5bf9\u4f4e\u7ef4\u6570\u636e\u8fdb\u884c\u5347\u7ef4\u65f6\uff0c\u4f1a\u628a\u4e00\u4e9b\u7279\u5f81\u7ed9\u653e\u5927\uff0c\u6216\u8005\u628a\u7b3c\u7edf\u7684\u7279\u5f81\u7ed9\u5206\u5f00\u3002</p> <p>\u539f\u7406\u5c31\u662f\u77e9\u9635\u4e58\u6cd5\uff0c\u5176\u4e2d\u88ab\u4e58\u6570\u662f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u4e58\u6570\u662f\u5d4c\u5165\u77e9\u9635Embedding Matrix\uff0cEmbedding Matrix\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6839\u636e\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u548c\u4f18\u5316\u5668\u8fdb\u884c\u66f4\u65b0\uff0c\u4f7f\u5f97\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u4e58Embedding Matrix\u540e\u80fd\u66f4\u597d\u5730\u653e\u5927\u5176\u6570\u636e\u4e2d\u7684\u7279\u5f81\u3002</p> <p>\u56e0\u6b64\uff0c\u8fd9\u4e2aEmbedding\u5c42\u4e00\u76f4\u5728\u5b66\u4e60\u4f18\u5316\uff0c\u4f7f\u5f97\u6574\u4e2a\u6570\u636e\u5347\u7ef4\u8fc7\u7a0b\u6162\u6162\u5f62\u6210\u4e00\u4e2a\u826f\u597d\u7684\u89c2\u5bdf\u70b9\uff0c\u5373Embedding Matrix\u3002</p>"},{"location":"literature/TSP/4_Informer/#25-kprobattn","title":"\u968f\u673a\u9009\u62e9 25 \u4e2a K\u3001ProbAttn","text":"<p>\u7684\u89e3\u91ca\u662f\uff0c\u7c7b\u6bd4\u4e86\u89e3\u4e00\u4e2a\u4eba\u53ef\u4ee5\u901a\u8fc7\u5b83\u7684\u4e3a\u4eba\u5904\u4e16\u53bb\u4e86\u89e3\uff0c\u4f46\u4e5f\u4e0d\u53ef\u80fd\u5929\u5929\u89c2\u5bdf\u5b83\u600e\u4e48\u505a\u4e8b\uff0c\u90a3\u5c31\u968f\u610f\u89c2\u5bdf 5 \u5929\u4e5f\u53ef\u4ee5\u5927\u6982\u7684\u4e86\u89e3\u5230\u5b83\u8fd9\u4e2a\u4eba\uff0c\u6216\u8005\u968f\u610f\u7684\u89c2\u5bdf\u5b83\u505a\u7684 5 \u4ef6\u4e8b\u5c31\u53ef\u4ee5\u4e86</p> <p>\u3010\u53c2\u770b\u3011</p> <p></p> <p>\u89e3\u91ca\u8f93\u51fa\u7ed3\u679c\uff1a\u5f62\u72b6\u662f <code>32*8*96*25</code></p> <p><code>32</code>\uff1abatch</p> <p><code>8</code>\uff1a<code>8</code> \u5934\uff0c\u600e\u4e48\u7406\u89e3 <code>8</code> \u5934\uff0c\u9996\u5148\u628a\u7279\u5f81\u62c6\u6210 <code>8</code> \u4efd\uff0c\u7136\u540e\u5206\u522b\u8ba1\u7b97\uff0c\u968f\u540e\u518d\u62fc\u63a5</p> <p><code>96</code>\uff1a<code>96</code> \u4e2a query</p> <p><code>25</code>\uff1a<code>25</code> \u4e2a key</p> <p>\u4e5f\u5c31\u662f\u8fd9\u91cc\u7684\u6ce8\u610f\u529b\u77e9\u9635\u662f <code>96*25</code></p> <p>\u56fe\u793a\uff1a</p> <p></p> <p>\uff081\uff09\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u4e3a96\uff0c\u9996\u5148\u5728K\u4e2d\u8fdb\u884c\u91c7\u6837\uff0c\u968f\u673a\u9009\u53d625\u4e2ak\u3002 \uff082\uff09\u8ba1\u7b97\u6bcf\u4e2aq\u4e0e25\u4e2ak\u7684\u5185\u79ef\uff0c\u73b0\u5728\u4e00\u4e2aq\u4e00\u5171\u670925\u4e2a\u5f97\u5206\u3002 \uff083\uff09\u6bcf\u4e2aq\u572825\u4e2a\u5f97\u5206\u4e2d\uff0c\u9009\u53d6==\u6700\u9ad8\u5206\u7684\u4e0e\u5747\u503c==\u7b97\u5dee\u5f02\u3002 \uff084\uff09\u8fd9\u6837\u6211\u4eec\u8f93\u5165\u768496\u4e2aq\u90fd\u6709\u5bf9\u5e94\u7684\u5dee\u5f02\u5f97\u5206\uff0c\u6211\u4eec\u5c06\u5dee\u5f02\u4ece\u5927\u5230\u5c0f\u6392\u5217\uff0c\u9009\u51fa\u5dee\u5f02\u524d25\u5927\u7684q\u3002 \uff085\uff09\u5176\u4ed6\u6dd8\u6c70\u6389\u7684q\u4f7f\u7528V\u5411\u91cf\u7684\u5e73\u5747\u6765\u4ee3\u66ff\u3002</p> <p>\u4ee5\u4e0a\u89e3\u51b3\u4e86\u539f\u6587\u63d0\u5230\u7684\u95ee\u9898\uff1a</p> <p></p>"},{"location":"literature/TSP/4_Informer/#25","title":"\u8bf4\u660e\u9009\u51fa 25 \u4e2a\u66f4\u65b0\uff0c\u5176\u4f59\u5168\u4e3a\u5747\u503c\u5411\u91cf","text":"<p>\u89e3\u91ca\u5f62\u72b6\uff1a32 \u4e2a batch\uff0c8 \u4e2a\u5934\uff0c\u9009\u62e9\u51fa 25 \u4e2a query\uff0c\u8ddf 96 \u4e2a key \u8ba1\u7b97\u6ce8\u610f\u529b</p> <p>\u4f8b\u5b50\uff1a\u9009\u5230\u4e86 2 \u53f7 query\uff0c\u8ddf 1\u2014\u201496 \u53f7 key \u8ba1\u7b97\u6ce8\u610f\u529b\uff0c\u4e5f\u5c31\u662f\u53ea\u66f4\u65b0 2 \u53f7\u4ee5\u53ca\u9009\u5230\u7684 query\uff0c\u90a3\u4e48\u6ca1\u9009\u5230\u7684\u600e\u4e48\u529e\uff1f</p> <p>\u56de\u7b54\uff1a\u5747\u503c\u586b\u5145</p> <p>\u586b\u5145\u516c\u5f0f\uff1a </p> <p>\u4e3a\u9009\u5230\u7684 query \u586b\u5145\uff1a</p> <p>\\(\\frac{1}{96}V_1+\\frac{1}{96}V_2+......+\\frac{1}{96}V_{96}\\)</p> <p>\u7406\u7531\uff1a</p> <p>\u56e0\u4e3a \\(lazy \\ query\\) \u7684\u6ce8\u610f\u529b\u5206\u5e03\u5c31\u662f\u7c7b\u4f3c\u5747\u5300\u5206\u5e03\u7684\uff0c\u6240\u4ee5\u586b\u5145\u7684\u65f6\u5019\u7528 \\(V\\)\u7684\u5747\u503c\u586b\u5145\u662f\u6709\u9053\u7406\u7684</p> <p></p> <p>\u4ee5\u4e0a\u8bf4\u660e\u4e86 infomer \u4e2d\u6ce8\u610f\u529b\u6743\u503c\u7684\u8ba1\u7b97</p> <p>\u671f\u520a\uff1aAAAI21(best paper)</p>"},{"location":"literature/TSP/4_Informer/#distilling","title":"Distilling","text":"<p>\u6211\u4eec\u5904\u7406\u7684\u5355\u5143\uff1a\u662f 96 \u4e2a\u65f6\u95f4\u6b65\uff1b\u4e00\u4e2a\u89c4\u8303\u5316\u6837\u672c96 \u4e2a\u6570\u636e\u70b9\uff0c\u5173\u4e8e\u8fd9\u70b9\u8865\u5145\u89c1</p> <p>\u5728\u76f8\u90bb\u7684Attention Block\u4e4b\u95f4\u52a0\u5165\u5377\u79ef\u6c60\u5316\u64cd\u4f5c\uff0c\u6765\u5bf9\u7279\u5f81\u8fdb\u884c\u964d\u91c7\u6837\u3002\u5bf9==\u8f93\u5165\u7ef4\u5ea6==\u8fdb\u884c\u4fee\u526a\uff0c\u5806\u53e0n\u5c42\uff0c\u6bcf\u5c42==\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u51cf\u534a==\uff0c\u4ece\u800c\u5c06\u7a7a\u95f4\u590d\u6742\u5ea6\u964d\u4f4e\u5230O(nlogn)</p> <p>\u4e5f\u5c31\u662f\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\uff1a 96 \u2192 48</p> <p>\u8fd9\u6837\u5904\u7406\u4e4b\u540e\uff0c\u4e0b\u4e00\u6b21self attention\u8003\u8651\u7684\u5e8f\u5217\u957f\u5ea6\u5c31\u4e0d\u662f96\uff0c\u800c\u662f48</p> <p>\u601d\u8003\u4e3a\u4ec0\u4e48 \u5e8f\u5217\u957f\u5ea6\u6253\u6298\u6263\u4e5f\u53ef\u4ee5\uff1a</p> <p>encoder\u5c31\u662f\u628a\u539f\u59cb\u5e8f\u5217\u957f\u5ea6\u8f93\u5165\u6570\u636e\u7279\u5f81\u8fdb\u884c\u63d0\u53d6\uff0c\u539f\u59cb\u8f93\u5165\u7279\u5f81\u662f96\u4e2a\u7279\u5f81\u300148 \u4e2a\u7279\u5f81\uff0c24 \u4e2a\u7279\u5f81\u90fd\u662f\u53ef\u4ee5\u7684\uff0c\u53ea\u8981\u80fd\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u5c31\u53ef\u4ee5</p> <p>encoder \u8f93\u51fa\u7684\u4e1c\u897f\u8981\u8fdb\u884c\u9884\u6d4b\uff0c\u8f93\u51fa\u7684\u9884\u6d4b\u7684\u8ddf\u539f\u59cb\u8f93\u5165\u5e8f\u5217\u957f\u5ea61~96\u6ca1\u5173\u7cfb\uff0c\u53ea\u9700\u8981\u544a\u8bc9 decoder\u524d\u9762\u7279\u5f81\u662f\u5565\u5c31\u597d\u4e86</p> <p>\u5e8f\u5217\u957f\u5ea6\u51cf\u534a\u7684</p> <p>\ud83d\udd34 \u90a3 \u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u51cf\u534a\uff0c\u4e5f\u5c31\u662f query \u51cf\u534a\u4e86\uff0c\u90a3 key \u5462\uff1f\u8fd8\u662f 25 \u4e2a\u5417\uff1f</p> <p>\u5728\u6e90\u7801\u4e2d\u6709\u53c2\u6570\u63a7\u5236\uff0c\u901a\u8fc7 maxpool \u5bf9\u8f93\u5165\u5e8f\u5217\u51cf\u534a\u7684\u65f6\u5019\uff0c\u5e8f\u5217\u957f\u5ea6\u4ece 96 \u5230 48\uff0ckey \u7531 25\u219220\uff0c\u53c8\u7ecf\u8fc7\u4e00\u5c42 maxpool\uff0c\u8f93\u5165\u5e8f\u5217\u4ece 48\u219224\uff0ckey \u7531 20\u219210</p> <p>\u901a\u8fc7\u4e00\u7ec4\u53c2\u6570\u8bbe\u7f6e\uff0c\u9010\u5c42\u9012\u51cf</p> <p>\u56fe\u793a\uff1a\uff08\u4e2d\u95f4\u7684\u677f\u5b50 \u662f \u6ce8\u610f\u529b\u7684\u5934\u6570 \uff09</p> <p></p> <p>\u6548\u679c\uff1a</p> <p></p> <p>maxpool\u4f1a\u628a\u7279\u5f81\u9c9c\u660e\u7684\u9009\u51fa\u6765\uff0c\u9010\u5c42\u7b5b\u9009</p> <p>\u4f20\u7edfdecoder\uff1a</p> <p></p> <p>decoder \u7684\u8f93\u5165\uff1a </p> <p></p> <p>encoder \u4e2d\u7684\u505a\uff1aself attention</p> <p>decoder \u4e2d\u505a 2 \u79cd attention\uff1a</p> <p>\u2460  \u4e0e encoder \u7684\u8f93\u51fa\u7684\u505a attention\uff0c\u8868\u793a encoder \u4e2d\u7684\u7279\u5f81\u80fd\u63d0\u4f9b\u7528\u4e8e\u6307\u5bfcdecoder \u7684\u8f93\u5165</p> <p>\u2461 decoder \u8f93\u5165\u7684\u81ea\u6ce8\u610f\u529b\uff0c\u8fd9\u4e00\u90e8\u5206\u9700\u8981\u6ce8\u610f\u7684\u662f mask \u64cd\u4f5c\uff0c\u5f53\u524d\u4f4d\u7f6e\u5728\u505a\u81ea\u6ce8\u610f\u529b\u65f6\uff0c\u4e0d\u80fd\u770b\u5230\u672a\u6765\u7684\u4fe1\u606f</p> <p></p>"},{"location":"literature/TSP/4_Informer/#informer","title":"\u6a21\u578b\u8f93\u5165\u8f93\u51fa\u89d2\u5ea6\u7406\u89e3Informer\u8bad\u7ec3\u548c\u9884\u6d4b\u8fc7\u7a0b","text":"<p>\u6570\u636e\u96c6\uff1aBDG2</p> <p>(\u5c0f\u65f6\u7ef4\u5ea6\u7684\u6570\u636e) \u6570\u636e\u89c4\u683c:17420 * 320</p> <p>Batch_size:32</p> <p>1\ufe0f\u20e3 Encoder Embedding\u8f93\u5165 </p> <p>$X_{enc} = 32 \u00d7 96 \u00d7 320  $</p> <p>32\u4e3abatch\u5927\u5c0f\uff0c\u4e00\u4e2abatch\u670932\u4e2a\u6837\u672c\uff0c\u4e00\u4e2a\u6837\u672c\u4ee3\u886896\u4e2a\u65f6\u95f4\u70b9\u7684\u6570\u636e\u3002 320\u4e3a\u6bcf\u4e2a\u6570\u636e\u7684\u7ef4\u5ea6\uff0c\u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u70b9\u6570\u636e\uff08\u6bcf\u884c\uff09\u6709320\u5217\u3002</p> <p>$X_{mark} = 32 \u00d7 96 \u00d7 4 $ </p> <p>32 \u00d7 96\u540c\u4e0a\uff0c\u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u70b9\u7684\u6570\u636e\u90fd\u8981\u6709\u4e00\u4e2a\u4f4d\u7f6e\u7f16\u7801\uff0cXmark\u4e0eXenc\u6bcf\u884c\u4e00\u4e00\u5bf9\u5e94\u3002</p> <p>4\u4e3a\u65f6\u95f4\u6233\uff0c\u4f8b\u5982\u6211\u4eec\u7528\u5c0f\u65f6\u7ef4\u5ea6\u7684\u6570\u636e\uff0c\u90a3\u4e484\u5206\u522b\u4ee3\u8868\u5e74\u3001\u6708\u3001\u65e5\u3001\u5c0f\u65f6\uff0c</p> <p>2\ufe0f\u20e3 Decoder Embedding\u8f93\u5165\uff1a</p> <p>\\(X_{dec} = 32 \u00d7 72 \u00d7 320\\) </p> <p>\\(X_{mark} = 32 \u00d7 72 \u00d7 4\\) </p> <ul> <li>72=48+24\uff0c\u5176\u4e2d48\u4e3aEncoder96\u7684\u540e48\u4e2a\u65f6\u95f4\u70b9\u6570\u636e\uff0c\u7528\u8fd9\u4e9b\u771f\u5b9e\u503c\u6765\u5e26\u4e00\u5e26\u9884\u6d4b\u503c\uff0c24\u4e3a\u5f85\u9884\u6d4b\u503c\u3002</li> <li>48\u4e3a\u7eff\u8272\u90e8\u5206\uff0c24\u4e3a\u767d\u8272\u90e8\u5206\u586b\u51450\uff08mask\u673a\u5236\uff09</li> </ul> <p>3\ufe0f\u20e3 Embedding\u8f93\u5165\u8f93\u51fa\uff1a</p> <p>\u5c06\u7ef4\u5ea6\u4e3a\\(320\\)\u7684\u4e00\u4e2a\u65f6\u95f4\u70b9\u7684\u6570\u636e\u6295\u5f71\u6210\u7ef4\u5ea6\u4e3a512\u7684\u6570\u636e\u3002</p> <p>\u8f93\u5165\uff1a</p> <p>32 \u00d7 96/72 \u00d7 320</p> <p>32 \u00d7 96/72 \u00d7 4</p> <p>\u8f93\u51fa\uff1a</p> <p>32 \u00d7 96/72 \u00d7 512</p> <p>4\ufe0f\u20e3 ProbSparse Self-attention\u8f93\u5165\u8f93\u51fa</p> <p>\u8f93\u5165\uff1a</p> <p>32 \u00d7 8 \u00d7 96 \u00d7 64 (8 \u00d7 64 = 512\uff0c\u8fd9\u4e5f\u662f\u591a\u5934\u7684\u539f\u7406\uff0c\u53738\u4e2a\u5934)</p> <p>Active\u8f93\u51fa\uff1a</p> <p>32 \u00d7 8 \u00d7 25 \u00d7 64 \uff08\u53ea\u53d625\u4e2a\u6d3b\u8dc3q\uff09</p> <p>Active+Lazy\u8f93\u51fa\uff1a</p> <p>32 \u00d7 8 \u00d7 96 \u00d7 64 \uff08\u9664\u4e8625\u4e2a\u6d3b\u8dc3q\uff0c\u5176\u4f59q\u7528V\u5411\u91cf\u7684\u5e73\u5747\u6765\u4ee3\u66ff\uff09</p> <p>\u591a\u5934\u6ce8\u610f\u529b\u5408\u5e76\uff1a</p> <p>32 \u00d7 96 \u00d7 512</p> <p>Encoder\u8f93\u5165\u8f93\u51fa\uff1a</p> <p>\u591a\u4e2aEncoder\u548c\u84b8\u998f\u5c42\u7684\u7ec4\u5408</p> <p>\u8f93\u5165\uff1a</p> <p>32 \u00d7 96 \u00d7 512\uff08\u6765\u81ea\u4e0a\u9762embedding \u957f\u5ea6\u4e3a96\u7684\u90e8\u5206\uff09</p> <p>\u8f93\u51fa\uff1a</p> <p>32 \u00d7 51 \u00d7 512\uff08\u8fd9\u91cc\u768451\u5e94\u8be5\u662fconv1d\u5377\u79ef\u53d6\u6574\u5bfc\u81f4\u7684\uff0c\u56e0\u4e3a\u6e90\u7801\u8981\u81ea\u884c\u8c03\u6574\uff0c\u6240\u4ee5\u662f\u8fd9\u6837\u7684\uff09</p> <p>5\ufe0f\u20e3 Decoder\u8f93\u5165\u8f93\u51fa</p> <p>\u8f93\u5165\uff1a</p> <p>32 \u00d7 51 \u00d7 512 &amp; 32 \u00d7 72 \u00d7 512</p> <p>\uff0832 \u00d7 51 \u00d7 512\u662fEncoder\u8f93\u51fa\uff0c32 \u00d7 72 \u00d7 512\u662fDecoder Embedding\u540e\u7684\u8f93\u5165\uff09</p> <p>\u8f93\u51fa\uff1a</p> <p>32 \u00d7 72 \u00d7 512</p>"},{"location":"literature/TSP/4_Informer/#_3","title":"\u4f4d\u7f6e\u7f16\u7801","text":""},{"location":"literature/TSP/4_Informer/#_4","title":"\u5b9e\u9a8c\u90e8\u5206","text":"<p>\u65f6\u5e8f\u9884\u6d4b\u8bba\u6587\u7cbe\u8bfb\uff1a\u957f\u5e8f\u5217\u9884\u6d4b\u6a21\u578binformer\u4e0a</p> <p>\u672c\u6587\u6240\u7528\u6570\u636e\u96c6\uff1aETT h1\uff0cETT h2\uff0cETT m1\u3001weather</p> <p>\u5b9e\u9a8c\u90e8\u5206\uff1a</p> <ul> <li>\u5355\u53d8\u91cf \u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b</li> <li>\u591a\u53d8\u91cf ~ \uff08q \u7684\u7a00\u758f\u6027\u5047\u8bbe\u5728\u5f88\u591a\u6570\u636e\u96c6\u4e0a\u6210\u7acb\uff09</li> </ul> <p>https://arxiv.org/pdf/2012.07436</p> <p></p>"},{"location":"literature/TSP/5_Autoformer/","title":"2021\u3001Autoformer","text":""},{"location":"literature/TSP/5_Autoformer/#2021autoformer","title":"2021\u3001Autoformer","text":"2025-03-17 20:13:522025-09-28 12:54:06 <p> \u7ea6 336 \u4e2a\u5b57  17 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <ul> <li> \u6a21\u578b\u7ed3\u6784\u56fe</li> </ul>"},{"location":"literature/TSP/5_Autoformer/#_1","title":"\u4e3b\u51fd\u6570","text":""},{"location":"literature/TSP/5_Autoformer/#_2","title":"\u5e8f\u5217\u5206\u89e3\u6a21\u5757","text":"<p>\u5177\u4f53\u5730\u64cd\u4f5c\u901a\u8fc7\u7bad\u5934\u8bf4\u660e\uff0c\u65b9\u5757\u91cc\u8868\u793a\u5f62\u72b6\u7684\u53d8\u5316</p> <p> </p>"},{"location":"literature/TSP/5_Autoformer/#_3","title":"\u7f16\u7801\u5668\u6a21\u5757","text":""},{"location":"literature/TSP/5_Autoformer/#_4","title":"\u89e3\u7801\u5668\u6a21\u5757","text":""},{"location":"literature/TSP/5_Autoformer/#_5","title":"\u81ea\u76f8\u5173\u673a\u5236","text":""},{"location":"literature/TSP/5_Autoformer/#_6","title":"\u5f00\u59cb\u7406\u8bba\u8bb2\u89e3","text":"<p>\u5e8f\u5217\u5206\u89e3\u9884\u6d4b\u6a21\u578bAutoformer </p> <ul> <li>\u6587\u7ae0\u9898\u76ee\uff1aAutoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting</li> <li>\u6536\u5f55\u60c5\u51b5\uff1a 2021 NeurIPS </li> <li>\u4f5c\u8005\u56e2\u961f\uff1a\u6e05\u534e\u8f6f\u9662\u5434\u6d77\u65ed </li> <li>\u5f00\u6e90\u5730\u5740\uff1ahttps://github.com/thuml/Autoformer</li> <li>Autoformer:Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting</li> <li>https://openreview.net/pdf?id=I55UqU-M11y</li> <li>Autoformer: \u4e00\u79cd\u57fa\u4e8e\u81ea\u52a8\u76f8\u5173\u673a\u5236\u7684\u65f6\u5e8f\u9884\u6d4b\u65b0\u67b6\u6784</li> </ul> <p></p> <p></p> <p></p> <p></p>"},{"location":"literature/TSP/5_Autoformer/#_7","title":"\u95ee\u9898\u63cf\u8ff0","text":"<p>\u5e8f\u5217\u5206\u89e3\u9884\u6d4b\u6a21\u578b</p> <p></p> <p></p> <p> </p> <p></p> <p></p>"},{"location":"literature/TSP/5_Autoformer/#_8","title":"\u539f\u6587\u9605\u8bfb","text":"<p>https://blog.csdn.net/sinat_37574187/article/details/144396724</p> <p>\u672c\u6587\u805a\u7126\u7684\u4e24\u4e2a\u95ee\u9898\uff1a</p> <p>However, the forecasting task is extremely challenging under the long-term setting. </p> <p>First, it is unreliable to discover the temporal dependencies directly from the long-term time series because the dependencies can be obscured by entangled temporal patterns. </p> <p>Second, canonical Transformers with self-attention mechanisms are computationally prohibitive for long-term forecasting because of the quadratic complexity of sequence length.</p> <p>\uff081\uff09\u76f4\u63a5\u4ece\u957f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u53d1\u73b0\u65f6\u95f4\u6a21\u5f0f \u4e0d\u592a\u9760\u8c31\u3002\u56e0\u4e3a\u8ddd\u79bb\u592a\u957f\u4e86\u662f\u5176\u4e00\uff0c\u8fd8\u6709\u5c31\u662f \u65f6\u95f4\u6a21\u5f0f\u9519\u7efc\u590d\u6742</p> <p>\uff082\uff09\u8fd8\u662f Transformer \u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u592a\u9ad8\u4e86\u3002\u73b0\u5728\u4e00\u822c\u91c7\u7528\u7a00\u758f\u7684\u9010\u70b9\u8ba1\u7b97\uff0c\u4f46\u662f\uff0c\u635f\u5931\u4fe1\u606f\u4e86\u3002</p> <p>\u672c\u6587\u91c7\u7528\u5206\u89e3\u7684\u6982\u5ff5\u3002\u4f46\u662f\u5728\u4e4b\u524d\u7684\u7528\u5904\u4e2d\uff0c\u5206\u89e3\u4e3b\u8981\u662f\u9884\u5904\u7406\u7684\u6b65\u9aa4\uff0c\u56e0\u4e3a\u672a\u6765\u6570\u636e\u7684\u5206\u89e3\u662f\u89c2\u6d4b\u4e0d\u5230\u7684\u3002</p>"},{"location":"literature/TSP/6_UnetTSF/","title":"2024\u3001UnetTSF","text":""},{"location":"literature/TSP/6_UnetTSF/#2024unettsf","title":"2024\u3001UnetTSF","text":"2025-04-08 12:37:292025-09-28 12:54:06 <p> \u7ea6 1639 \u4e2a\u5b57  360 \u884c\u4ee3\u7801  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 13 \u5206\u949f</p> <p> </p> <p>https://arxiv.org/pdf/2401.03001</p> <p> </p>"},{"location":"literature/TSP/6_UnetTSF/#iii-proposed-method","title":"III. PROPOSED METHOD","text":"<p>\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\u662f\u5728\u7ed9\u5b9a\u957f\u5ea6\u4e3a \\(L\\) \u7684\u5386\u53f2\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u957f\u5ea6\u4e3a \\(T\\) \u7684\u672a\u6765\u6570\u636e\u3002\u8f93\u5165\u7684\u5386\u53f2\u6570\u636e \\(X = \\{x_1, x_2, x_3, \\ldots, x_L\\}\\)  \u5177\u6709\u56fa\u5b9a\u957f\u5ea6\u7684\u56de\u770b\u7a97\u53e3 L\uff0c\u6a21\u578b\u8f93\u51fa\u9884\u6d4b\u6570\u636e  \\(x = \\{x_{L+1}, x_{L+2}, \\ldots, x_{L+T}\\}\\) \uff0c\u5176\u4e2d  \\(x_i\\) \u8868\u793a\u5728\u65f6\u95f4  \\(t = i\\)  \u65f6\u7ef4\u5ea6\u4e3a \\(C\\) \u7684\u5411\u91cf\uff0c\\(C\\) \u8868\u793a\u8f93\u5165\u6570\u636e\u96c6\u4e2d\u7684\u901a\u9053\u6570\u3002\u6211\u4eec\u8bbe\u8ba1\u4e86 UnetTSF\uff0c\u4f7f\u7528 U-Net [27] \u67b6\u6784\uff0c\u5e76\u4e13\u95e8\u8bbe\u8ba1\u4e86\u9002\u5408\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684 FPN [12] \u548c\u591a\u6b65\u878d\u5408\u6a21\u5757\uff0c\u5982\u56fe 2 \u6240\u793a\u3002</p> <p>UNetTSF model\uff1a UnetTSF\u7531\u5168\u8fde\u63a5\u5c42\u548c\u6c60\u5316\u5c42\u7ec4\u6210\u3002\u6a21\u578b\u7684\u5de6\u4fa7\u4e3b\u8981\u7531\u65f6\u95f4\u5e8f\u5217\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc\uff08FPN\uff09\u6784\u6210\uff0c\u6c60\u5316\u51fd\u6570\u7528\u4e8e\u5f62\u6210\u8f93\u5165\u6570\u636e\u7684\u63cf\u8ff0\u6027\u7279\u5f81$ X = { X_1, X_2, X_3, ..., X_{\\text{stage} } } $  \u3002\u8fd9\u91cc\u7684\u201cstage\u201d\u8868\u793aUnet\u7f51\u7edc\u7684\u5c42\u6570\uff0c\u6a21\u578b\u7684\u53f3\u4fa7\u662f\u878d\u5408\u6a21\u5757\u3002\u5168\u8fde\u63a5\u5c42\u7528\u4e8e\u5c06\u4e0a\u5c42\u7279\u5f81\u4e0e\u5c40\u90e8\u5c42\u7279\u5f81\u878d\u5408\uff0c\u4ee5\u8f93\u51fa\u5f53\u524d\u5c42\u7684\u6700\u7ec8\u7279\u5f81\uff0c\u540c\u65f6\u4fdd\u6301\u7279\u5f81\u957f\u5ea6\u4e0d\u53d8\u3002</p> <p>Times series FPN \uff08\u65f6\u95f4\u5e8f\u5217\u7279\u5f81\u91d1\u5b57\u5854\u7f51\u7edc\uff09\uff1a\u6570\u636e\u5206\u89e3\u901a\u5e38\u88ab\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7528\u6765\u4ece\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u7279\u5f81\u3002\u901a\u5e38\uff0c\u6570\u636e\u88ab\u5206\u4e3a\u5b63\u8282\u6027\u3001\u5468\u671f\u6027\u3001\u8d8b\u52bf\u548c\u6ce2\u52a8\u9879\u3002Autoformer \u548c DLiner \u90fd\u4f7f\u7528\u5927\u89c4\u6a21\u81ea\u9002\u5e94\u5e73\u6ed1\u6838\u4ece\u539f\u59cb\u6570\u636e\u4e2d\u63d0\u53d6\u8d8b\u52bf\u9879\u3002\u4ece\u539f\u59cb\u6570\u636e\u4e2d\u51cf\u53bb\u8d8b\u52bf\u9879\u4f1a\u5f97\u5230\u5b63\u8282\u6027\u9879\uff0c\u8fd9\u53ef\u80fd\u4f1a\u5bfc\u81f4\u67d0\u4e9b\u7279\u5f81\u4e22\u5931\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u91c7\u7528\u591a\u5c42\u6b21\u63d0\u53d6\u65b9\u6cd5\u3002\u4f8b\u5982\uff0c\u5c06\u6570\u636e\u8bbe\u7f6e\u4e3a\u5206\u4e3a4\u5c42\uff08\\(\\text{stage = 4}\\)\uff09\uff0c\u4f7f\u7528\u5177\u6709 \\(\\text{kernel\\_size} = 3\\)\u3001\\(\\text{stride} = 2\\) \u548c \\(padding = 0\\) \u914d\u7f6e\u7684\u5e73\u5747\u6c60\u5316\uff08\\(\\text{avgpool}\\)\uff09\u63d0\u53d6\u8d8b\u52bf\u7279\u5f81\uff0c\u5c06\u539f\u59cb\u8f93\u5165\u6570\u636e\u8bbe\u4e3a \\(x\\) \uff0c\u5e76\u901a\u8fc7 \\(\\text{FPN}\\) \u6a21\u5757\u540e\uff0c\u5f62\u6210\u56db\u4e2a\u5c42\u6b21\u7684\u8f93\u5165\u6570\u636e\uff1a \\(X = [x_1, x_2, x_3, x_4]\\) \u3002 $$ x_1 = x $$</p> \\[ x_2 = \\text{AvgPool}(x_1) \\] \\[ x_3 = \\text{AvgPool}(x_2) \\] \\[ x_4 = \\text{AvgPool}(x_3) \\] \\[ \\text{len}(x_i) = \\left\\lfloor \\frac{x_{i-1} + 2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} + 1 \\right\\rfloor \\] <p>\u5982\u56fe2(b)\u6240\u793a\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684FPN\u7ed3\u6784\u53ef\u4ee5\u6709\u6548\u63d0\u53d6\u8d8b\u52bf\u7279\u5f81\u3002\u91d1\u5b57\u5854\u9876\u5c42\u7684\u8d8b\u52bf\u4fe1\u606f\u6bd4\u5e95\u5c42\u66f4\u96c6\u4e2d\uff0c\u800c\u5e95\u5c42\u7684\u5b63\u8282\u6027\u7279\u5f81\u66f4\u4e3a\u4e30\u5bcc\u3002</p> \u8bf4\u660e\uff1a\u91d1\u5b57\u5854\u9876\u5c42\u7684\u8d8b\u52bf\u4fe1\u606f\u6bd4\u5e95\u5c42\u66f4\u96c6\u4e2d\uff0c\u800c\u5e95\u5c42\u7684\u5b63\u8282\u6027\u7279\u5f81\u66f4\u4e3a\u4e30\u5bcc <p> \u9996\u5148\uff0c\u5173\u4e8e\u9876\u5c42\u548c\u5e95\u5c42\uff1a\u5e95\u5c42\u9760\u8fd1\u8f93\u5165\u7aef\uff0c\u5e8f\u5217\u957f\u5ea6\u957f\uff0c\u6240\u8c13\u7684\u5206\u8fa8\u7387\u9ad8 \u9876\u5c42\u9760\u8fd1\u8f93\u51fa\u7aef\uff0c\u5e8f\u5217\u957f\u5ea6\u77ed\uff0c\u6240\u8c13\u7684\u5206\u8fa8\u7387\u4f4e \u5176\u6b21\uff0c\u5173\u4e8e\u6c60\u5316\u64cd\u4f5c\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u4f7f\u7528\uff0c\u76f8\u5f53\u4e8e\u6bcf\u6b21\u4e22\u6389\u4e86\u8d8b\u52bf\u4fe1\u606f\uff0c\u6700\u9876\u5c42\u7684\u7279\u5f81\u6700\u62bd\u8c61\uff0c\u4fdd\u7559\u4e86\u5168\u5c40\u4fe1\u606f\u548c\u6ce2\u52a8\u4fe1\u606f \u9700\u8981\u6ce8\u610f\uff0c\u6c60\u5316\u662f\u6c60\u5316\u6389\u4e86\u957f\u671f\u8d8b\u52bf\u4fe1\u606f\uff0c\u5c24\u5176\u662f\u5927\u6838\u6c60\u5316\u63d0\u53d6 trend\uff0c\u6bd4\u5982 Autoformer - \u5e73\u5747\u6c60\u5316\uff1a\u4f1a\u5e73\u6ed1\u77ed\u671f\u6ce2\u52a8\uff0c\u90e8\u5206\u4fdd\u7559\u5b63\u8282\u6027\u6a21\u5f0f\u7684\u5927\u81f4\u5f62\u72b6\uff0c\u5c24\u5176\u662f\u5f53\u5b63\u8282\u5468\u671f\u8fdc\u5927\u4e8e\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u65f6 - \u6700\u5927\u6c60\u5316\u4f1a\u4fdd\u7559\u663e\u8457\u5cf0\u503c\uff0c\u8fd9\u4e9b\u5cf0\u503c\u901a\u5e38\u662f\u5b63\u8282\u6027\u6a21\u5f0f\u7684\u5173\u952e\u7279\u5f81 </p> <p>Multi stage fusion module\uff08\u591a\u9636\u6bb5\u878d\u5408\u6a21\u5757\uff09\uff1a\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684FPN\u6a21\u5757\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u591a\u5c3a\u5ea6\u7684\u65f6\u95f4\u7279\u5f81 \\(X\\)\u3002\u4e3a\u4e86\u5145\u5206\u5229\u7528\u8fd9\u4e9b\u7279\u5f81\uff0c\u4f7f\u7528\u591a\u4e2a\u5168\u8fde\u63a5\u9884\u6d4b\u6765\u83b7\u5f97 \\(Y = [y_1, y_2, y_3, y_4]\\)\u3002\\(y_i\\) \u7684\u957f\u5ea6\u8ba1\u7b97\u65b9\u6cd5\u4e0e \\(x\\) \u76f8\u540c\uff0c\u5e76\u4e14\u4f7f\u7528\u76f8\u540c\u7684\u6c60\u5316\u64cd\u4f5c\u6765\u8ba1\u7b97\u6bcf\u4e2a\u5c42\u7ea7\u4e0e \\(X\\) \u76f8\u540c\u7684\u957f\u5ea6\u3002\u878d\u5408\u6a21\u5757\u91c7\u7528 \\(y_i\\)  \u548c \\(y_{i-1}\\) \u8fdb\u884c\u62fc\u63a5\uff0c\u7136\u540e\u4f7f\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u6765\u8f93\u51fa \\(y_i^{'}\\)\uff0c\\(y_i^{'}\\) \u548c  \\(y_i\\) \u7684\u957f\u5ea6\u662f\u76f8\u540c\u7684\u3002</p> \\[ \\text{len}(y1) = \\text{len}(y) = T \\] \\[ y_{i-1}^{'} = \\text{Linear}(\\text{cat}(y_i^{'}, y_{i-1})) \\] \\[ \\text{len}(y_i) = \\left\\lfloor \\frac{y_{i-1} + 2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} + 1 \\right\\rfloor \\] <p>\u6e90\u7801\uff1ahttps://github.com/lichuustc/UnetTSF/tree/main/models</p> <p>\u600e\u4e48\u914d\u7f6e\uff1f</p> <ul> <li>\u5b98\u7f51\u4e0b\u8f7d\u4e0b\u6765\u6a21\u578b\u6587\u4ef6</li> <li>\u914d\u7f6e\u6587\u4ef6\u642c\u8fc7\u6765\uff0c\u5b8c\u4e8b\u3002</li> </ul> \u6a21\u578b\u6587\u4ef6\uff0c\u5df2\u914d\u7f6e\u597d <p> </p>Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom layers.RevIN import RevIN\nimport custom_repr\nclass moving_avg(nn.Module):\n    \"\"\"\n    Moving average block to highlight the trend of time series\n    \"\"\"\n    def __init__(self, kernel_size, stride):\n        super(moving_avg, self).__init__()\n        self.kernel_size = kernel_size\n        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n\n    def forward(self, x):\n        # padding on the both ends of time series\n        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n        x = torch.cat([front, x, end], dim=1)\n        x = self.avg(x.permute(0, 2, 1))\n        x = x.permute(0, 2, 1)\n        return x\n\n\nclass series_decomp(nn.Module):\n    \"\"\"\n    Series decomposition block\n    \"\"\"\n    def __init__(self, kernel_size):\n        super(series_decomp, self).__init__()\n        self.moving_avg = moving_avg(kernel_size, stride=1)\n\n    def forward(self, x):\n        moving_mean = self.moving_avg(x)\n        res = x - moving_mean\n        return res, moving_mean\n\nclass block_model(nn.Module):\n    \"\"\"\n    Decomposition-Linear\n    \"\"\"\n    def __init__(self, input_channels, input_len, out_len, individual):\n        super(block_model, self).__init__()\n        self.channels = input_channels\n        self.input_len = input_len\n        self.out_len = out_len\n        self.individual = individual\n\n        if self.individual:\n            self.Linear_channel = nn.ModuleList()\n\n            for i in range(self.channels):\n                self.Linear_channel.append(nn.Linear(self.input_len, self.out_len))\n        else:\n            self.Linear_channel = nn.Linear(self.input_len, self.out_len)\n        self.ln = nn.LayerNorm(out_len)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        # x: [Batch, Input length, Channel]\n        if self.individual:\n            output = torch.zeros([x.size(0),x.size(1),self.out_len],dtype=x.dtype).to(x.device)\n            for i in range(self.channels):\n                output[:,i,:] = self.Linear_channel[i](x[:,i,:])\n        else:\n            output = self.Linear_channel(x)\n        #output = self.ln(output)\n        #output = self.relu(output)\n        return output # [Batch, Channel, Output length]\n\n\nclass Model(nn.Module):\n    def __init__(self, configs):\n        super(Model, self).__init__()\n\n        self.input_channels = configs.enc_in\n        self.input_len = configs.seq_len\n        self.out_len = configs.pred_len\n        self.individual = configs.individual\n        # \u4e0b\u91c7\u6837\u8bbe\u5b9a\n        self.stage_num = configs.stage_num\n        self.stage_pool_kernel = configs.stage_pool_kernel\n        self.stage_pool_stride = configs.stage_pool_stride\n        self.stage_pool_padding = configs.stage_pool_padding\n\n        self.revin_layer = RevIN(self.input_channels, affine=True, subtract_last=False)\n\n        len_in = self.input_len\n        len_out = self.out_len\n        down_in = [len_in]\n        down_out = [len_out]\n        i = 0\n        while i &lt; self.stage_num - 1:\n            linear_in = int((len_in + 2 * self.stage_pool_padding - self.stage_pool_kernel)/self.stage_pool_stride + 1 )\n            linear_out = int((len_out + 2 * self.stage_pool_padding - self.stage_pool_kernel)/self.stage_pool_stride + 1 )\n            down_in.append(linear_in)\n            down_out.append(linear_out)\n            len_in = linear_in\n            len_out = linear_out\n            i = i + 1\n\n        # \u6700\u5927\u6c60\u5316\u5c42\n        self.Maxpools = nn.ModuleList() \n        # \u5de6\u8fb9\u7279\u5f81\u63d0\u53d6\u5c42\n        self.down_blocks = nn.ModuleList()\n        for in_len,out_len in zip(down_in,down_out):\n            self.down_blocks.append(block_model(self.input_channels, in_len, out_len, self.individual))\n            self.Maxpools.append(nn.AvgPool1d(kernel_size=self.stage_pool_kernel, stride=self.stage_pool_stride, padding=self.stage_pool_padding))\n\n        # \u53f3\u8fb9\u7279\u5f81\u878d\u5408\u5c42\n        self.up_blocks = nn.ModuleList()\n        len_down_out = len(down_out)\n        for i in range(len_down_out -1):\n            print(len_down_out, len_down_out - i -1, len_down_out - i - 2)\n            in_len = down_out[len_down_out - i - 1] + down_out[len_down_out - i - 2]\n            out_len = down_out[len_down_out - i - 2]\n            self.up_blocks.append(block_model(self.input_channels, in_len, out_len, self.individual))\n\n        #self.linear_out = nn.Linear(self.out_len * 2, self.out_len)\n\n    def forward(self, x):\n        x = self.revin_layer(x, 'norm')\n        x1 = x.permute(0,2,1)\n        e_out = []\n        i = 0\n        for down_block in self.down_blocks:\n            e_out.append(down_block(x1))\n            x1 = self.Maxpools[i](x1)\n            i = i+1\n\n        e_last = e_out[self.stage_num - 1]\n        for i in range(self.stage_num - 1):\n            e_last = torch.cat((e_out[self.stage_num - i -2], e_last), dim=2)\n            e_last = self.up_blocks[i](e_last)\n        e_last = e_last.permute(0,2,1)\n        e_last = self.revin_layer(e_last, 'denorm')\n        return e_last\n\nimport argparse\nimport os\nimport torch\nimport random\nimport numpy as np\n\nparser = argparse.ArgumentParser(description='Autoformer &amp; Transformer family for Time Series Forecasting')\n\n# random seed\nparser.add_argument('--random_seed', type=int, default=2021, help='random seed')\n\n# basic config\nparser.add_argument('--is_training', type=int, required=False, default=1, help='status')\nparser.add_argument('--model_id', type=str, required=False, default='test', help='model id')\nparser.add_argument('--model', type=str, required=False, default='Transformer',\n                    help='model name, options: [Autoformer, Informer, Transformer]')\n\n# data loader\nparser.add_argument('--data', type=str, required=False, default='ETTh1', help='dataset type')\nparser.add_argument('--root_path', type=str, default='./dataset/ETT/', help='root path of the data file')\nparser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\nparser.add_argument('--features', type=str, default='M',\n                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\nparser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\nparser.add_argument('--freq', type=str, default='h',\n                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\nparser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n\n# forecasting task\nparser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\nparser.add_argument('--label_len', type=int, default=48, help='start token length')\nparser.add_argument('--pred_len', type=int, default=720, help='prediction sequence length')\n\n#u_linear\nparser.add_argument('--stage_num', type=int, default=4, help='stage num')\nparser.add_argument('--stage_pool_kernel', type=int, default=3, help='AvgPool1d kernel_size')\nparser.add_argument('--stage_pool_stride', type=int, default=2, help='AvgPool1d stride')\nparser.add_argument('--stage_pool_padding', type=int, default=0, help='AvgPool1d padding')\n\n# DLinear\n#parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n\n# PatchTST\nparser.add_argument('--fc_dropout', type=float, default=0.05, help='fully connected dropout')\nparser.add_argument('--head_dropout', type=float, default=0.0, help='head dropout')\nparser.add_argument('--patch_len', type=int, default=16, help='patch length')\nparser.add_argument('--stride', type=int, default=8, help='stride')\nparser.add_argument('--padding_patch', default='end', help='None: None; end: padding on the end')\nparser.add_argument('--revin', type=int, default=1, help='RevIN; True 1 False 0')\nparser.add_argument('--affine', type=int, default=0, help='RevIN-affine; True 1 False 0')\nparser.add_argument('--subtract_last', type=int, default=0, help='0: subtract mean; 1: subtract last')\nparser.add_argument('--decomposition', type=int, default=0, help='decomposition; True 1 False 0')\nparser.add_argument('--kernel_size', type=int, default=25, help='decomposition-kernel')\nparser.add_argument('--individual', type=int, default=1, help='individual head; True 1 False 0')\n\n# Formers \nparser.add_argument('--embed_type', type=int, default=0, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\nparser.add_argument('--enc_in', type=int, default=7, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\nparser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\nparser.add_argument('--c_out', type=int, default=7, help='output size')\nparser.add_argument('--d_model', type=int, default=512, help='dimension of model')\nparser.add_argument('--n_heads', type=int, default=8, help='num of heads')\nparser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\nparser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\nparser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\nparser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\nparser.add_argument('--factor', type=int, default=1, help='attn factor')\nparser.add_argument('--distil', action='store_false',\n                    help='whether to use distilling in encoder, using this argument means not using distilling',\n                    default=True)\nparser.add_argument('--dropout', type=float, default=0.05, help='dropout')\nparser.add_argument('--embed', type=str, default='timeF',\n                    help='time features encoding, options:[timeF, fixed, learned]')\nparser.add_argument('--activation', type=str, default='gelu', help='activation')\nparser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\nparser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n\n#corr\nparser.add_argument('--corr_lower_limit', type=float, default=0.6, help='find corr ')\n\n# optimization\nparser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\nparser.add_argument('--itr', type=int, default=1, help='experiments times')\nparser.add_argument('--train_epochs', type=int, default=80, help='train epochs')\nparser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\nparser.add_argument('--patience', type=int, default=20, help='early stopping patience')\nparser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\nparser.add_argument('--des', type=str, default='test', help='exp description')\nparser.add_argument('--loss', type=str, default='mse', help='loss function')\nparser.add_argument('--lradj', type=str, default='type3', help='adjust learning rate')\nparser.add_argument('--pct_start', type=float, default=0.3, help='pct_start')\nparser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n\n# GPU\nparser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\nparser.add_argument('--gpu', type=int, default=0, help='gpu')\nparser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\nparser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\nparser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')\n\nargs = parser.parse_args()\n\n# random seed\nfix_seed = args.random_seed\nrandom.seed(fix_seed)\ntorch.manual_seed(fix_seed)\nnp.random.seed(fix_seed)\n\n\nargs.use_gpu =  True\n\nif args.use_gpu and args.use_multi_gpu:\n    args.dvices = args.devices.replace(' ', '')\n    device_ids = args.devices.split(',')\n    args.device_ids = [int(id_) for id_ in device_ids]\n    args.gpu = args.device_ids[0]\n\n# print('Args in experiment:')\n# print(args.seq_len)\n\n\nbatch_x = torch.randn(args.batch_size, args.seq_len, args.enc_in)\n# ETTh1 =&gt; 17420 , channels = 7,Frequence = 7\n\nmodel = Model(args).float()\n\noutputs = model(batch_x)\n</code></pre> <p></p> Python<pre><code>def forward(self, x):\n    x = self.revin_layer(x, 'norm')\n    x1 = x.permute(0,2,1)\n    e_out = []\n    i = 0\n    for down_block in self.down_blocks:\n        e_out.append(down_block(x1))\n        x1 = self.Maxpools[i](x1)\n        i = i+1\n\n    e_last = e_out[self.stage_num - 1]\n    for i in range(self.stage_num - 1):\n        e_last = torch.cat((e_out[self.stage_num - i -2], e_last), dim=2)\n        e_last = self.up_blocks[i](e_last)\n    e_last = e_last.permute(0,2,1)\n    e_last = self.revin_layer(e_last, 'denorm')\n    return e_last\n</code></pre> <p>\u590d\u8ff0\u5f62\u72b6\u53d8\u5316\uff1a</p> <ul> <li><code>pred_len  =720</code> </li> </ul> <p>\uff081\uff09\u4f20\u8fdb\u6765\u7684x \u5f62\u72b6 <code>args.batch_size, args.seq_len, args.enc_in =  [32,96,7]</code> </p> <p>\uff082\uff09\u53ef\u9006\u5b9e\u4f8b\u5f52\u4e00\u5316\uff0c\u8fd8\u662fx\uff0c\u5f62\u72b6 [32,96,7]</p> <p>\uff083\uff09permute \u8f6c\u6362\u7ef4\u5ea6\uff0c\u5f97\u5230 x1\uff0c\u5f62\u72b6[32,7,96]\uff0c\u4ece\u8fd9\u91cc\u5f00\u59cb\u6240\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5c01\u88c5\u6a21\u5f0f \u90fd\u662f \u7279\u5f81\u4f18\u5148\u3002</p> <p>\uff084\uff09\u8f93\u5165 x1.shape = [32,7,96]\uff0c\u5904\u7406 down_block(x1)\uff0c\u8f93\u51fa\u5f62\u72b6 [32, 7, 720]\uff0c\u8fd9\u4e2a\u8f93\u51fa\u5f62\u72b6\u5e76\u6ca1\u6709\u53c2\u4e0e\u540e\u7eed\u7684\u6c60\u5316\u5904\u7406\u3002\u800c\u662f\u5b58\u5230\u4e86 <code>e_out</code>    \u518d\u91cd\u590d\u4e00\u904d\u5c31\u662f\u5b9a\u4e49\u4e86 7 \u4e2a\u72ec\u7acb\u7684\u7ebf\u6027\u5c42\uff0c\u5206\u522b\u5c06 96 \u4e2a\u8f93\u5165\u5e8f\u5217 \u6620\u5c04\u5230 720 \u7684\u9884\u6d4b\u6b65\u957f\u3002</p> \u8865\u5145 \u5173\u4e8e  down_block(x1) <p> \u7ed3\u6784\u662f\uff1a\u591a\u4e2a\u5e76\u884c\u7ebf\u6027\u5c42 block_model(   (Linear_channel): ModuleList(     (0-6): 7 x Linear(in_features=96, out_features=720, bias=True)   )   (ln): LayerNorm((720,), eps=1e-05, elementwise_affine=True)   (relu): ReLU(inplace=True) ) \u2460 (0-6): 7 x Linear(in_features=96, out_features=720, bias=True)\uff0c\u8868\u793a\u6a21\u578b\u5305\u542b 7\u4e2a\u72ec\u7acb\u7684\u7ebf\u6027\u5c42\uff0c\u6bcf\u4e2a\u7ebf\u6027\u5c42\u4e13\u95e8\u5904\u7406\u4e00\u4e2a\u8f93\u5165\u901a\u9053\u7684\u6570\u636e \u2461 (0-6): \u8868\u793a\u7d22\u5f15\u8303\u56f4\uff0c\u4ece0\u52306\uff0c\u51717\u4e2a\u5143\u7d20 \u2462 7 x: \u8868\u793a\u67097\u4e2a\u76f8\u540c\u7c7b\u578b\u7684\u6a21\u5757 \u2463 Linear(in_features=96, out_features=720, bias=True): \u6bcf\u4e2a\u6a21\u5757\u90fd\u662f\u4e00\u4e2a\u7ebf\u6027\u5c42\uff0c\u8f93\u5165\u7279\u5f8196\uff0c\u8f93\u51fa\u7279\u5f81720 \u2464 \u5f53 individual=True \u65f6\uff08\u5728\u4ee3\u7801\u4e2d args.individual=1\uff09\uff0c\u6a21\u578b\u4e3a\u6bcf\u4e2a\u8f93\u5165\u901a\u9053\u521b\u5efa\u4e00\u4e2a\u72ec\u7acb\u7684\u7ebf\u6027\u5c42\u3002==\u300b\"\u901a\u9053\u72ec\u7acb\u5904\u7406\"\uff0c\u5e38\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b \u89e3\u91ca\uff1a\u76ee\u524d\u90fd\u5728\u7528\u7684\u901a\u9053\u72ec\u7acb \u2460 \u7279\u5316\u5904\u7406: \u6bcf\u4e2a\u901a\u9053(\u53d8\u91cf)\u53ef\u80fd\u6709\u4e0d\u540c\u7684\u6a21\u5f0f\u548c\u7279\u6027\uff0c\u72ec\u7acb\u5904\u7406\u53ef\u4ee5\u66f4\u597d\u5730\u6355\u6349\u8fd9\u4e9b\u5dee\u5f02 \u2461 \u907f\u514d\u7279\u5f81\u5e72\u6270: \u4e0d\u540c\u53d8\u91cf\u53ef\u80fd\u6709\u4e0d\u540c\u7684\u89c4\u6a21\u548c\u5206\u5e03\uff0c\u72ec\u7acb\u5904\u7406\u53ef\u4ee5\u907f\u514d\u53d8\u91cf\u95f4\u7684\u5e72\u6270 </p> <p>\uff085\uff09<code>x1 = self.Maxpools[i](x1)</code>  \u8f93\u5165  x1 \u5f62\u72b6  [32,7,96]\uff0c\u6700\u5927\u6c60\u5316\u4ee5\u540e\uff0c\u8f93\u51fa\u5f62\u72b6  <code>torch.Size([32, 7, 47])</code></p> <p>\u6211\u53c8\u7406\u6e05\u695a\u4e86\uff01\uff01\u8d76\u7d27\u8bb0\u4e0b\u6765\uff01</p> <p>\u5f00\u59cb\uff1a</p> Python<pre><code>x = self.revin_layer(x, 'norm')   # torch.Size([32, 96, 7])\nx1 = x.permute(0,2,1)  #  [32,7,96]\ne_out = []\ni = 0\n\u2460 for down_block in self.down_blocks:\n    e_out.append(down_block(x1))\n        x1 torch.Size([32, 7, 96])\n        down_block\u7684\u4f5c\u7528\u5c31\u662f \n        \u8f93\u5165\uff1a[Batch, Channel, Input_length]\n        \u8f93\u51fa\uff1a[Batch, Channel, Output_length]\n        down_block(x1) torch.Size([32, 7, 720])\n        e_out.append(torch.Size([32, 7, 720]))\n    x1 = self.Maxpools[i](x1)\n        self.Maxpools[0]( x1 torch.Size([32, 7, 96]))\n        \u8f93\u51fa x1.shape = torch.Size([32, 7, 47])\n        i=1\n        \u2461 for down_block in self.down_blocks:\n            e_out.append(down_block(x1))\n            x1.shape = torch.Size([32, 7, 47])\n            down_block(x1).shape = torch.Size([32, 7, 359])\n            x1 = self.Maxpools[i](x1)\n            x1.shape = torch.Size([32, 7, 47])\n            x1 = self.Maxpools[i](x1).shape = torch.Size([32, 7, 23])\n            i = i+1\n            i = 2\n            \u2462 for down_block in self.down_blocks:\n                e_out.append(down_block(x1))\n                x1.shape = torch.Size([32, 7, 23])\n                down_block(x1).shape = torch.Size([32, 7, 179])\n                x1 = self.Maxpools[i](x1)\n                x1.shape = torch.Size([32, 7, 23])\n                x1 = self.Maxpools[i](x1) = torch.Size([32, 7, 11])\n                i = 3\n                \u2463 for down_block in self.down_blocks:\n                    e_out.append(down_block(x1))\n                    x1 = torch.Size([32, 7, 11])\n                    down_block(x1) = torch.Size([32, 7, 89])\n                    x1 = self.Maxpools[i](x1)\n                    x1.shape = torch.Size([32, 7, 11])\n                    x1 = self.Maxpools[i](x1) = torch.Size([32, 7, 5])\n</code></pre> <p>\u5bf9\u4e8e\u8fd9\u91cc\u7684 down_block(x1) \u6765\u8bf4\uff0c</p> <p>\u5206\u522b\u63a5\u6536 </p> <ul> <li>x1 = torch.Size([32, 7, 96]) \u2192 down_block(x1) torch.Size([32, 7, 720])</li> <li>x1 = torch.Size([32, 7, 47]) \u2192 down_block(x1) = torch.Size([32, 7, 359])</li> <li>x1 = torch.Size([32, 7, 23]) \u2192 down_block(x1) = torch.Size([32, 7, 179])</li> <li>x1 = torch.Size([32, 7, 11]) \u2192 down_block(x1) = torch.Size([32, 7, 89])</li> </ul> <p>\u5c42\u95f4\u662f <code>x1 = *self*.Maxpools[i](x1)</code>   \u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u51cf\u534a</p> <p>\u5c42\u5185\u662f <code>down_block</code>\uff0c\u5c06\u8f93\u5165\u5e8f\u5217\u6620\u5c04\u5230\u8f93\u51fa\u5e8f\u5217\u5bf9\u5e94\u7684\u957f\u5ea6</p> <p>\u5173\u4e8e <code>e_out</code> </p> <ul> <li><code>e_out[0].shape = [32,7,720]</code></li> <li><code>e_out[1].shape = [32,7,359]</code></li> <li><code>e_out[2].shape = [32,7,179]</code></li> <li><code>e_out[3].shape = [32,7,89]</code></li> </ul> Python<pre><code>\ud83c\udf08e_last = e_out[self.stage_num - 1]\n\ud83d\udd35e_out[self.stage_num - 1] = e_out[3] = torch.Size([32, 7, 89])\n\ud83e\ude90for i in range(self.stage_num - 1):\n    \ud83c\udf08e_last = torch.cat((e_out[self.stage_num - i -2], e_last), \n                       dim=2)\n    \ud83d\udd34e_out[self.stage_num - i -2] = e_out[2] = torch.Size([32, 7, 179])\n    \ud83d\udd34e_last = e_out[3] = torch.Size([32, 7, 89])\n    \ud83d\udd34e_last = cat = torch.Size([32, 7, 268])\n    \ud83c\udf08e_last = self.up_blocks[i](e_last)\n    \ud83d\udd35e_last = torch.Size([32, 7, 268])\n    \ud83d\udd35e_last = self.up_blocks[i](e_last) = torch.Size([32, 7, 179])\n    \ud83e\ude90for i in range(self.stage_num - 1):\n        \ud83c\udf08e_last = torch.cat((e_out[self.stage_num - i -2], e_last), \n                           dim=2)\n        \ud83d\udd35e_out[self.stage_num - i -2] = e_out[1] = torch.Size([32, 7, 359])\n        \ud83d\udd35e_last.shape = e_out[2] = torch.Size([32, 7, 179])\n        \ud83d\udd35e_last = cat = torch.Size([32, 7, 538])\n        \ud83c\udf08e_last = self.up_blocks[i](e_last)\n        \ud83d\udd34e_last.shape = torch.Size([32, 7, 538])\n        \ud83d\udd34e_last = self.up_blocks[i](e_last).shape = torch.Size([32, 7, 359])\n        \ud83e\ude90for i in range(self.stage_num - 1):\n             \ud83c\udf08e_last = torch.cat((e_out[self.stage_num - i -2],\n                                 e_last),\n                                dim=2)\n\n             \ud83d\udd34e_out[self.stage_num - i -2] = e_out[0] =  torch.Size([32, 7, 720])\n             \ud83d\udd34e_last = torch.Size([32, 7, 359])\n             \ud83d\udd34e_last = cat = torch.Size([32, 7, 1079])\n             \ud83c\udf08e_last = self.up_blocks[i](e_last)\n            \ud83d\udd35e_last = torch.Size([32, 7, 1079])\n            \ud83d\udd35e_last = self.up_blocks[i](e_last) = torch.Size([32, 7, 720])  \n\ud83c\udf08e_last = e_last.permute(0,2,1)\n\ud83d\udd35\u8df3\u51fa for \u5faa\u73af\n\ud83d\udd35e_last = torch.Size([32, 7, 720])  \n\ud83d\udd35e_last = permute = torch.Size([32, 720, 7]) \n\ud83d\udd35e_last = self.revin_layer(e_last, 'denorm')\n\ud83d\udd35\u5f62\u72b6\u4e0d\u53d8\uff0c\u8fd4\u56de\u7ed3\u679c\uff0c\u6a21\u578b\u7ed3\u675f\n</code></pre> <p>\u56fe\u7247\uff1a</p> <p></p> <p>\u901a\u9053\u72ec\u7acb\u7684\u5efa\u6a21\u6b65\u9aa4</p>"},{"location":"literature/TSP/7_SCINet/","title":"2022\u3001SCINet","text":""},{"location":"literature/TSP/7_SCINet/#2022scinet","title":"2022\u3001SCINet","text":"2025-04-10 20:13:162025-09-28 12:54:06 <p> \u7ea6 13 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction</p>"},{"location":"literature/TSP/8_PatchTST/","title":"2023\u3001PatchTST","text":""},{"location":"literature/TSP/8_PatchTST/#2023patchtst","title":"2023\u3001PatchTST","text":"2025-04-10 20:13:162025-09-28 12:54:06 <p> \u7ea6 3 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>ICLR2023</p>"},{"location":"literature/TSP/9_Pyraformer/","title":"2022\u3001Pyraformer","text":""},{"location":"literature/TSP/9_Pyraformer/#2022pyraformer","title":"2022\u3001Pyraformer","text":"2025-04-10 20:13:162025-09-28 12:54:06 <p> \u7ea6 5358 \u4e2a\u5b57  6 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 27 \u5206\u949f</p> <p>ICLR2022  Oral \u8682\u8681\u96c6\u56e2\u3001\u4e0a\u6d77\u4ea4\u901a\u5927\u5b66</p> <p>\u539f\u6587\uff1aPyraformer: Low-complexity Pyramidal Attention for Long-range Time Series Modeling and Forecasting </p> <p>\u4ee3\u7801\uff1ahttps://github.com/ant-research/Pyraformer</p> <p>\u5173\u952e\u8bcd\uff1a</p> <ul> <li>\u6700\u5927\u4fe1\u53f7\u4f20\u9012\u8def\u5f84 &amp; \u590d\u6742\u5ea6</li> <li>Pyraformer \u6700\u5927\u4fe1\u53f7\u4f20\u9012\u8def\u5f84  O(1)\uff0c\u590d\u6742\u5ea6 O(L)</li> <li>C \u53c9\u6811</li> <li>\u81ea\u5df1\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5e93</li> <li> <p>\u5f15\u7406\u3001\u547d\u9898\uff0c\u7406\u8bba\u57fa\u7840\u6bd4\u8f83\u624e\u5b9e</p> </li> <li> <p> \u672c\u6587\u7f51\u7edc\u7ed3\u6784\u56fe</p> </li> </ul> <p></p> <ul> <li> <p> \u4ee3\u7801\u7ed3\u6784\u56fe\uff1a</p> </li> <li></li> </ul>"},{"location":"literature/TSP/9_Pyraformer/#_1","title":"\u6458\u8981","text":"<p>Accurate prediction of the future given the past based on time series data is of paramount importance, since it opens the door for decision making and risk management ahead of time. </p> <p>In practice, the challenge is to build a flexible but parsimonious model that can capture a wide range of temporal dependencies. </p> <p>\u57fa\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u6839\u636e\u8fc7\u53bb\u7684\u89c2\u6d4b\u6765\u51c6\u786e\u9884\u6d4b\u672a\u6765\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u4e3a\u63d0\u524d\u8fdb\u884c\u51b3\u7b56\u548c\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002</p> <p>\u5728\u5b9e\u8df5\u4e2d\uff0c\u6311\u6218\u5728\u4e8e\u6784\u5efa\u4e00\u4e2a\u7075\u6d3b\u4e14\u7b80\u7ea6\u7684\u6a21\u578b\uff0c\u80fd\u591f\u6355\u6349\u5e7f\u6cdb\u7684\u65f6\u5e8f\u4f9d\u8d56\u5173\u7cfb\u3002</p> <p>In this paper, we propose Pyraformer by exploring the multi-resolution representation of the time series. </p> <p>Specifically, we introduce the pyramidal attention module (PAM) in which the inter-scale tree structure summarizes features at different resolutions and the intra-scale neighboring connections model the temporal dependencies of different ranges.</p> <p>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u63a2\u7d22\u65f6\u95f4\u5e8f\u5217\u7684\u591a\u5206\u8fa8\u7387\u8868\u793a\u63d0\u51fa\u4e86Pyraformer\u3002</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5f15\u5165\u4e86**\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u6a21\u5757\uff08Pyramidal Attention Module, PAM\uff09**\uff0c\u5176\u4e2d\u8de8\u5c3a\u5ea6\u7684\u6811\u72b6\u7ed3\u6784\u80fd\u591f\u603b\u7ed3\u4e0d\u540c\u5206\u8fa8\u7387\u7684\u7279\u5f81\uff0c\u800c\u5185\u5c3a\u5ea6\u7684\u90bb\u8fd1\u8fde\u63a5\u5219\u80fd\u591f\u5bf9\u4e0d\u540c\u8303\u56f4\u7684\u65f6\u5e8f\u4f9d\u8d56\u5173\u7cfb\u8fdb\u884c\u5efa\u6a21\u3002</p> <p>\uff08\uff1f\uff09 Under mild conditions, the maximum length of the signal traversing path in Pyraformer is a constant (i.e., \\(O(1)\\)) with regard to the sequence length \\(L\\), while its time and space complexity scale linearly with \\(L\\). </p> <p>\u5728\u6e29\u548c\u7684\u6761\u4ef6\u4e0b\uff0cPyraformer\u4e2d\u4fe1\u53f7\u904d\u5386\u8def\u5f84\u7684\u6700\u5927\u957f\u5ea6\u4e0e\u5e8f\u5217\u957f\u5ea6\\(L\\)\u65e0\u5173\uff0c\u662f\u4e00\u4e2a\u5e38\u6570\uff08\u5373\\(O(1)\\)\uff09\uff0c\u800c\u5176\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u5219\u4e0eL\u5448\u7ebf\u6027\u5173\u7cfb\u3002</p> <p>Extensive experimental results show that Pyraformer typically achieves the highest prediction accuracy in both single-step and long-range multi-step forecasting tasks with the least amount of time and memory consumption, especially when the sequence is long1.</p> <p>\u5927\u91cf\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPyraformer\u901a\u5e38\u5728\u5355\u6b65\u9884\u6d4b\u548c\u957f\u8ddd\u79bb\u591a\u6b65\u9884\u6d4b\u4efb\u52a1\u4e2d\u5747\u80fd\u5b9e\u73b0\u6700\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4e14\u5728\u65f6\u95f4\u548c\u5185\u5b58\u6d88\u8017\u65b9\u9762\u8868\u73b0\u6700\u4e3a\u51fa\u8272\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u3002 </p> <p>\u6458\u8981\u603b\u7ed3\uff1a</p> <p>\u57fa\u4e8e\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u7684Transformer(Pyraformer)\uff0c\u80fd\u591f\u5728\u83b7\u53d6**\u957f\u671f\u4f9d\u8d56**\u548c**\u4f4e\u65f6\u95f4\u7a7a\u95f4\u590d\u6742\u5ea6\u95f4**\u83b7\u53d6\u5e73\u8861\u3002\u5bf9\u4e8e\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u6a21\u5757 (pyramidal attention module\uff0cPAM)\uff0c\u5176\u4e3b\u8981\u5305\u542b\u4e24\u90e8\u5206\uff1a</p> <ul> <li> <p>\u4f7f\u7528**\u5c3a\u5ea6\u95f4(inter-scale)**\u6811\u5f62\u7ed3\u6784\u6c47\u603b\u4e86\u4e0d\u540c\u65f6\u95f4\u5206\u8fa8\u7387\u4e0b\u7684\u7279\u5f81</p> </li> <li> <p>\u4f7f\u7528**\u5c3a\u5ea6\u5185(intra-scale)**\u76f8\u90bb\u8fde\u63a5\u5bf9\u4e0d\u540c\u8303\u56f4\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u8fdb\u884c\u5efa\u6a21</p> </li> </ul> <p>\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\uff0cPyraformer\u4e2d\u4fe1\u53f7\u904d\u5386\u8def\u5f84\u7684\u6700\u5927\u957f\u5ea6\u76f8\u5bf9\u4e8e\u5e8f\u5217\u957f\u5ea6\u662f\u4e00\u4e2a\u5e38\u6570(\u5373**O(1)**)\u3002</p>"},{"location":"literature/TSP/9_Pyraformer/#_2","title":"\u95ee\u9898\u5f15\u5165\uff1a\u590d\u6742\u5ea6&amp;\u6700\u5927\u4fe1\u53f7\u4f20\u9012\u8def\u5f84","text":"<ul> <li>\u957f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6311\u6218\uff1a\u56e0\u4e3a\u505a\u957f\u671f\u9884\u6d4b\u9700\u8981\u5e38\u7684\u7684\u5386\u53f2\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\uff0c\u56e0\u6b64\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u662f\u4f18\u5148\u8003\u8651\u9879\uff0c\u5176\u8d8a\u5c0f\u8d8a\u597d\u3002</li> <li>\u6700\u5927\u4fe1\u53f7\u4f20\u9012\u8def\u5f84\u7684\u5b9a\u4e49\uff1a\\(x_t\\)\u548c\\(x_{t+k}\\)\u540c\u65f6\u88ab\u8003\u8651\uff0c\u9700\u8981\u51e0\u6b65\uff08\u591a\u5c11\u4e2a\u8fed\u4ee3\uff09\u3010\u8bba\u6587\u4e2d\u79f0\u4e4b\u4e3a**longest signal traversing path**\u3011\uff0c\u5176\u8d8a\u5c0f\u8d8a\u597d</li> </ul> <ul> <li>RNN\u548cCNN\uff1a</li> <li>\u590d\u6742\u5ea6\u4f4e\uff0c\u4e3a\\(O(L)\\)</li> <li>longest signal traversing path \u4e3a\\(O(L)\\)\u3010RNN\u662f\u4e00\u4e2a\u65f6\u95f4\u7247\u4e00\u4e2a\u65f6\u95f4\u7247\u5730\u8fed\u4ee3\u8fc7\u53bb\u3011</li> <li> <p>\u5f88\u96be\u5b66\u5230\u5f88\u8fdc\u7684\u4e24\u4e2a\u65f6\u95f4\u7247\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb</p> </li> <li> <p>Transformer\uff1a</p> </li> <li>longest signal traversing path \u4e3a\\(O(1)\\)</li> <li>\u4f46\u662f\u590d\u6742\u5ea6\u4e3a\\(O(L^2)\\)</li> <li>\u4e0d\u80fd\u5904\u7406\u7279\u522b\u957f\u7684\u65f6\u95f4\u5e8f\u5217 </li> <li>\u8868\u4e2d\u4e0d\u540c\u6a21\u578b\u7528\u4e8e**\u5904\u7406\u5e8f\u5217\u6570\u636e\u7684\u7f51\u7edc\u7ed3\u6784**\u5982\u4e0b\uff1a</li> </ul> <p> </p>"},{"location":"literature/TSP/9_Pyraformer/#_3","title":"\u65b9\u6cd5","text":"<p>\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\u53ef\u4ee5\u8868\u8ff0\u4e3a\uff0c\u5728\u7ed9\u5b9a\u5148\u524d\u7684 \\(L\\) \u6b65\u89c2\u6d4b\u503c  \\(z_{t-L+1:t}\\) \u548c\u76f8\u5173\u534f\u53d8\u91cf  \\(x_{t-L+1:t+M}\\) \uff08\u4f8b\u5982\uff0c\u4e00\u5929\u4e2d\u7684\u5c0f\u65f6\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u672a\u6765\u7684  \\(M\\) \u6b65 \\(z_{t+1:t+M}\\) \u3002</p> <p>\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u6211\u4eec\u5728\u672c\u6587\u4e2d\u63d0\u51fa\u4e86**Pyraformer**\uff0c\u5176\u6574\u4f53\u67b6\u6784\u5728\u56fe2\u4e2d\u8fdb\u884c\u4e86\u603b\u7ed3\u3002</p> <p>\u5982\u56fe\u6240\u793a\uff0c\u6211\u4eec\u9996\u5148\u5c06\u89c2\u6d4b\u6570\u636e\u3001\u534f\u53d8\u91cf\u548c\u4f4d\u7f6e\u4fe1\u606f\u5206\u522b\u5d4c\u5165\uff0c\u7136\u540e\u4ee5\u4e0eInformer\uff08Zhou et al., 2021\uff09\u76f8\u540c\u7684\u65b9\u5f0f\u5c06\u5b83\u4eec\u7ec4\u5408\u5728\u4e00\u8d77\u3002</p> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4f7f\u7528**\u7c97\u5c3a\u5ea6\u6784\u5efa\u6a21\u5757\uff08CSCM\uff09\u6784\u5efa\u4e00\u4e2a\u591a\u5206\u8fa8\u7387 **C-ary**\u6811\uff0c\u5176\u4e2d\u5728\u8f83\u7c97\u5c3a\u5ea6\u4e0a\u7684\u8282\u70b9\u603b\u7ed3\u4e86\u76f8\u5e94\u8f83\u7ec6\u5c3a\u5ea6\u4e0a\u7684  **C  \u4e2a\u8282\u70b9\u7684\u4fe1\u606f\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u6355\u6349\u4e0d\u540c\u8303\u56f4\u7684\u65f6\u5e8f\u4f9d\u8d56\u5173\u7cfb\uff0c\u6211\u4eec\u901a\u8fc7\u5728\u91d1\u5b57\u5854\u56fe\u4e2d\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u4f20\u9012\u6d88\u606f\uff0c\u5f15\u5165\u4e86**\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u6a21\u5757\uff08PAM\uff09**\u3002</p> <p>\u6700\u540e\u6839\u636e\u4e0b\u6e38\u4efb\u52a1\uff0c\u6211\u4eec\u91c7\u7528\u4e0d\u540c\u7684\u7f51\u7edc\u7ed3\u6784\u6765\u8f93\u51fa\u6700\u7ec8\u9884\u6d4b\u3002\u5728\u540e\u7eed\u5185\u5bb9\u4e2d\uff0c\u6211\u4eec\u5c06\u8be6\u7ec6\u9610\u8ff0\u6240\u63d0\u51fa\u7684\u6a21\u578b\u7684\u6bcf\u4e2a\u90e8\u5206\u3002\u4e3a\u4e86\u4fbf\u4e8e\u8868\u8ff0\uff0c\u672c\u6587\u4e2d\u4f7f\u7528\u7684\u6240\u6709\u7b26\u53f7\u5728\u88684\u4e2d\u8fdb\u884c\u4e86\u603b\u7ed3\u3002</p>"},{"location":"literature/TSP/9_Pyraformer/#31-pyramidal-attention-module-pam","title":"3.1 PYRAMIDAL ATTENTION MODULE (PAM)","text":"<p>We begin with the introduction of the PAM, since it lies at the heart of Pyraformer.</p> <p>\u6211\u4eec\u9996\u5148\u4ecb\u7ecdPAM\uff0c\u56e0\u4e3a\u5b83\u662fPyraformer\u7684\u6838\u5fc3\u3002</p> <p>As demonstrated in Figure 1(d), we leverage a pyramidal graph to describe the temporal dependencies of the observed time series in a multiresolution fashion. </p> <p>\u5982\u56fe1(d)\u6240\u793a\uff0c\u6211\u4eec\u5229\u7528\u91d1\u5b57\u5854\u56fe\u4ee5\u591a\u5206\u8fa8\u7387\u65b9\u5f0f\u63cf\u8ff0\u89c2\u6d4b\u65f6\u95f4\u5e8f\u5217\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u3002</p> <p>Such a multi-resolution structure has proved itself an effective and efficient tool for long-range interaction modeling in the field of computer vision (Sun et al., 2019; Wang et al., 2021) and statistical signal processing (Choi et al., 2008; Yu et al., 2019). </p> <p>\u8fd9\u79cd\u591a\u5206\u8fa8\u7387\u7ed3\u6784\u5df2\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\uff08Sun et al., 2019; Wang et al., 2021\uff09\u548c\u7edf\u8ba1\u4fe1\u53f7\u5904\u7406\uff08Choi et al., 2008; Yu et al., 2019\uff09\u9886\u57df\u8bc1\u660e\u662f\u4e00\u79cd\u6709\u6548\u4e14\u9ad8\u6548\u7684\u957f\u8ddd\u79bb\u4ea4\u4e92\u5efa\u6a21\u5de5\u5177\u3002</p> <p>We can decompose the pyramidal graph into two parts: the inter-scale and the intra-scale connections. </p> <p>\u6211\u4eec\u53ef\u4ee5\u5c06\u91d1\u5b57\u5854\u56fe\u5206\u89e3\u4e3a\u4e24\u90e8\u5206\uff1a\u8de8\u5c3a\u5ea6\u548c\u5185\u5c3a\u5ea6\u8fde\u63a5\u3002</p> <p>The inter-scale connections form a C-ary tree, in which each parent has C children. </p> <p>\u8de8\u5c3a\u5ea6\u8fde\u63a5\u5f62\u6210\u4e00\u4e2a \\(\\text{C-ary}\\)\u6811\uff0c\u5176\u4e2d\u6bcf\u4e2a\u7236\u8282\u70b9\u6709  \\(C\\) \u4e2a\u5b50\u8282\u70b9\u3002</p> <p>For example, if we associate the finest scale of the pyramidal graph with hourly observations of the original time series, the nodes at coarser scales can be regarded as the daily, weekly, and even monthly features of the time series.</p> <p>\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u5c06\u91d1\u5b57\u5854\u56fe\u7684\u6700\u7ec6\u5c3a\u5ea6\u4e0e\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u7684\u6bcf\u5c0f\u65f6\u89c2\u6d4b\u503c\u76f8\u5173\u8054\uff0c\u90a3\u4e48\u8f83\u7c97\u5c3a\u5ea6\u4e0a\u7684\u8282\u70b9\u53ef\u4ee5\u88ab\u89c6\u4e3a\u65f6\u95f4\u5e8f\u5217\u7684\u65e5\u3001\u5468\u751a\u81f3\u6708\u7279\u5f81\u3002</p> <ul> <li>\u7ec6\u5c3a\u5ea6 \u5fae\u89c2\u4fe1\u606f\uff08\u6bcf\u5c0f\u65f6\u89c2\u6d4b\u503c\uff09</li> <li>\u7c97\u5c3a\u5ea6 \u5b8f\u89c2\u4fe1\u606f\uff08\u65e5\u3001\u5468\u751a\u81f3\u6708\u7279\u5f81\uff09</li> </ul> <p>As a consequence, the pyramidal graph offers a multi-resolution representation of the original time series.\u91d1\u5b57\u5854\u56fe\u63d0\u4f9b\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u7684\u591a\u5206\u8fa8\u7387\u8868\u793a</p> <p>Furthermore, it is easier to capture long-range dependencies (e.g., monthly dependence) in the coarser scales </p> <p>by simply connecting the neighboring nodes via the intra-scale connections.</p> <p>\u7c97\u5c3a\u5ea6\u66f4\u5bb9\u6613\u6355\u83b7\u957f\u671f\u4f9d\u8d56\uff0c\u901a\u8fc7\u5185\u5c3a\u5ea6\u8fde\u63a5\u7b80\u5355\u7684\u76f8\u90bb\u8282\u70b9</p> <p>In other words, the coarser scales are instrumental in describing long-range correlations in a manner that is graphically far more parsimonious than could be solely captured with a single, finest scale model. </p> <ul> <li>\u7c97\u5236\u5ea6\u63cf\u8ff0\u957f\u8ddd\u79bb\u76f8\u5173\u6027\u5f88\u91cd\u8981</li> <li>\u6bd4\u53ea\u4f7f\u7528\u5355\u4e00\u6700\u7ec6\u5c3a\u5ea6\u6240\u6355\u6349\u5230\u7684\u4fe1\u606f\u7b80\u6d01\u5f97\u591a</li> </ul> <p>Indeed, the original single-scale Transformer (see Figure 1(a)) adopts a full graph that connects every two nodes at the finest scale so as to model the long-range dependencies, leading to a computationally burdensome model with \\(O(L^2)\\) time and space complexity (Vaswani et al., 2017).</p> <p>In stark contrast, as illustrated below, the pyramidal graph in the proposed Pyraformer reduces the computational cost to \\(O(L)\\) without increasing the order of the maximum length of the signal traversing path.</p> <ul> <li>\u5b9e\u9645\u4e0a\uff0c\u539f\u59cb\u5355\u5c3a\u5ea6\u7684 Transformer \u91c7\u7528\u4e86\u4e00\u4e2a\u5b8c\u5168\u56fe\uff0c\u5c06\u6700\u7ec6\u5c3a\u5ea6\u7684\u6bcf\u4e24\u4e2a\u8282\u70b9\u8fde\u63a5\u8d77\u6765\uff0c\u4ee5\u5efa\u6a21\u957f\u671f\u4f9d\u8d56\uff0c\u4f46\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u90fd\u662f \\(O(L^2)\\) </li> <li>\u800c\u672c\u6587\u6240\u63d0\u51fa\u7684 Pyraformer \u4e2d\u91d1\u5b57\u5854\u56fe\u5c06\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u5230 \\(O(L)\\)  \uff0c\u800c\u4e0d\u589e\u52a0\u6700\u5927\u4fe1\u53f7\u4f20\u9012\u8def\u5f84\u7684\u957f\u5ea6\u3002</li> </ul> <p>Before delving into the PAM, we first introduce the original attention mechanism. Let X and Y denote the input and output of a single attention head respectively. </p> <ul> <li>\u9996\u5148\u4ecb\u7ecd\u539f\u59cb\u6ce8\u610f\u529b\u673a\u5236\uff0c</li> </ul> <p>\uff081\uff09\u8ba1\u7b97\u516c\u5f0f\uff1a </p> <ul> <li>\u7b26\u53f7\u8868\u793a\uff1a\\(X\\) \u548c \\(Y\\)\u5206\u522b\u8868\u793a\u5355\u4e2a\u6ce8\u610f\u529b\u5934\u7684\u8f93\u5165\u548c\u8f93\u51fa\u3002</li> </ul> <p>Note that multiple heads can be introduced to describe the temporal pattern from different perspectives.</p> <ul> <li>\u591a\u5934\u7684\u5f15\u5165\u53ef\u4ee5\u4ece\u4e0d\u540c\u7684\u65b9\u9762\u63cf\u8ff0\u65f6\u95f4\u6a21\u5f0f</li> </ul> <p>X is first linearly transformed into three distinct matrices, namely, the query \\(Q = XW_Q\\), the key \\(K = XW_K\\), and the value \\(V = XW_V\\) , where \\(W_Q\\), \\(W_K\\) , \\(WV \u2208 R^{L\u00d7D_K}\\) . </p> <p>For the \\(\\text{i-th}\\) row \\(q_i\\) in \\(Q\\), it can attend to any rows (i.e., keys) in \\(K\\). In other words, the corresponding output \\(y_i\\) can be expressed as:</p> <ul> <li> <p>\\(X\\)  \u9996\u5148\u88ab\u7ebf\u6027\u53d8\u6362\u4e3a\u4e09\u4e2a\u4e0d\u540c\u7684\u77e9\u9635\uff1a\u67e5\u8be2\u77e9\u9635  \\(Q = XW_Q\\)\uff0c\u952e\u77e9\u9635  \\(K = XW_K\\) \uff0c\u548c\u503c\u77e9\u9635 $V = XW_V $ \uff0c\u5176\u4e2d  \\(W_Q, W_K, W_V \\in \\mathbb{R}^{L \\times D_K}\\)\u3002</p> </li> <li> <p>\u5bf9\u4e8e\u67e5\u8be2\u77e9\u9635  \\(Q\\) \u4e2d\u7684\u7b2c  \\(i\\) \u884c  \\(q_i\\) \uff0c\u5b83\u53ef\u4ee5\u5173\u6ce8\u952e\u77e9\u9635  \\(K\\) \u4e2d\u7684\u4efb\u4f55\u884c\uff08\u5373\u952e\uff09\u3002</p> </li> <li> <p>\u8f93\u51fa  \\(y_i\\) \u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u516c\u5f0f\u8ba1\u7b97\uff1a</p> </li> </ul> <p>$$    y_i = \\sum_{\\ell=1}^{L} \\frac{\\exp(q_i k_\\ell^T / \\sqrt{D_K}) v_\\ell}{\\sum_{\\ell=1}^{L} \\exp(q_i k_\\ell^T / \\sqrt{D_K})}    $$</p> <ul> <li>\u5176\u4e2d\uff0c \\(k_\\ell^T\\) \u8868\u793a\u952e\u77e9\u9635  \\(K\\) \u4e2d\u7b2c  \\(\\ell\\) \u884c\u7684\u8f6c\u7f6e\u3002</li> </ul> <p>where \\(k^T_\\ell\\) denotes the transpose of row \\(l\\) in \\(K\\). </p> <p>\uff082\uff09\u65f6\u95f4\u590d\u6742\u5ea6&amp;\u7a7a\u95f4\u590d\u6742\u5ea6 </p> <p>We emphasize that the number of query-key dot products (Q-K pairs) that need to be calculated and stored dictates the time and space complexity of the attention mechanism. </p> <p>\u9700\u8981\u8ba1\u7b97\u548c\u5b58\u50a8\u7684\u67e5\u8be2-\u952e\u70b9\u79ef\u5bf9\u6570\uff08Q-K\u5bf9\uff09\u51b3\u5b9a\u4e86\u6ce8\u610f\u529b\u673a\u5236\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u3002</p> <p>Viewed another way, this number is proportional to the number of edges in the graph (see Figure 1(a)). </p> <p>\u4ece\u53e6\u4e00\u4e2a\u89d2\u5ea6\u6765\u770b\uff0c\u8fd9\u4e2a\u6570\u91cf\u4e0e\u56fe\u4e2d\u7684\u8fb9\u6570\u6210\u6b63\u6bd4\uff08\u89c1\u56fe1(a)\uff09\u3002</p> <p>Since all Q-K pairs are computed and stored in the full attention mechanism (1), the resulting time and space complexity is O(L2).</p> <p>\u7531\u4e8e\u5728\u5b8c\u6574\u7684\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u8ba1\u7b97\u548c\u5b58\u50a8\u4e86\u6240\u6709\u7684**Q-K**\u5bf9\uff0c\u56e0\u6b64\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(L^2)\\)\u3002</p> <p>\u603b\u7ed3\uff1a\u8fd9\u90e8\u5206\u8bb2\u89e3\u539f\u59cb\u6ce8\u610f\u529b\u673a\u5236\u7684\u57fa\u672c\u8ba1\u7b97\u8fc7\u7a0b\u548c\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u7279\u522b\u662f\u5982\u4f55\u901a\u8fc7\u67e5\u8be2\u3001\u952e\u548c\u503c\u77e9\u9635\u6765\u8ba1\u7b97\u6ce8\u610f\u529b\u8f93\u51fa\uff0c\u4ee5\u53ca\u8fd9\u79cd\u8ba1\u7b97\u65b9\u5f0f\u5bfc\u81f4\u7684\u9ad8\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6</p> <p>As opposed to the above full attention mechanism, every node only pays attention to a limited set of keys in the PAM, corresponding to the pyramidal graph in Figure 1d. </p> <p>\u4e0e\u4e0a\u8ff0\u5b8c\u6574\u7684\u6ce8\u610f\u529b\u673a\u5236\u4e0d\u540c\uff0cPAM\u4e2d\u7684\u6bcf\u4e2a\u8282\u70b9\u53ea\u5173\u6ce8\u4e00\u4e2a\u6709\u9650\u7684\u952e\u96c6\u5408\u3002</p> <p>Concretely, suppose that \\(n^{(s)}_\\ell\\)  denotes the \\(\\text{l-th}\\) node at scale \\(s\\), where \\(s = 1, \u00b7 \u00b7 \u00b7 , S\\) represents the bottom scale to the top scale sequentially. </p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u5047\u8bbe  \\(n_\\ell^{(s)}\\)  \u8868\u793a\u5c3a\u5ea6  \\(s\\) \u4e2d\u7684\u7b2c  \\(\\ell\\) \u4e2a\u8282\u70b9\uff0c\u5176\u4e2d  \\(s = 1, \\cdots, S\\) \uff0c \\(S\\) \u8868\u793a\u4ece\u5e95\u5c42\u5230\u9876\u5c42\u7684\u5c3a\u5ea6\u5e8f\u5217\u3002</p> <p>In general, each node in the graph can attend to a set of neighboring nodes \\(\\mathbb{N}^{(s) }_{\\ell}\\) at  three scales: the adjacent \\(A\\) nodes at the same scale including the node itself (denoted as \\(\\mathbb{A}_{\\ell}^{(s)}\\) ), </p> <p>the  \\(C\\) children it has in the \\(C\\text{-ary}\\) tree (denoted as \\(\\mathbb{C}^{(s)}_\\ell\\) ), and the parent of it in the \\(C\\text{-ary}\\) tree (denoted  \\(\\mathbb{P}^{(s)}_{\\ell}\\) ), that is,</p> <ul> <li>\u4e00\u822c\u6765\u8bf4\uff0c\u56fe\u4e2d\u7684\u6bcf\u4e2a\u8282\u70b9\u53ef\u4ee5\u5173\u6ce8\u4e09\u4e2a\u5c3a\u5ea6\u4e0a\u7684\u4e00\u7ec4\u90bb\u8fd1\u8282\u70b9 \\(N_\\ell^{(s)}\\) \uff1a\u540c\u5c3a\u5ea6\u7684\u76f8\u90bb\u8282\u70b9\uff08\u5305\u62ec\u8282\u70b9\u672c\u8eab\uff0c\u8bb0\u4e3a \\(A_\\ell^{(s)}\\) \uff09\uff0c\u5728  \\(C\\) -ary\u6811\u4e2d\u7684 \\(C\\) \u4e2a\u5b50\u8282\u70b9\uff08\u8bb0\u4e3a  \\(C_\\ell^{(s)}\\) \uff09\uff0c\u4ee5\u53ca\u5728  \\(C\\) -ary\u6811\u4e2d\u7684\u7236\u8282\u70b9\uff08\u8bb0\u4e3a \\(P_\\ell^{(s)}\\)\uff09\u3002</li> </ul> <p>\u90bb\u8fd1\u8282\u70b9\u7684\u5b9a\u4e49\uff1a</p> <ul> <li>\\(N_\\ell^{(s)} = A_\\ell^{(s)} \\cup C_\\ell^{(s)} \\cup P_\\ell^{(s)}\\) </li> <li>\\(A_\\ell^{(s)} = \\{n_j^{(s)} : |j - \\ell| \\leq \\frac{A-1}{2}, 1 \\leq j \\leq \\frac{L}{C^{s-1}}\\}\\) </li> <li>\\(C_\\ell^{(s)} = \\{n_{j}^{(s-1)} : (\\ell - 1)C &lt; j \\leq \\ell C\\} if ,s \\geq 2 ,else \\emptyset\\) </li> <li>\\(P_\\ell^{(s)} = \\{n_{j}^{(s+1)} : j = \\lceil \\frac{\\ell}{C} \\rceil\\}, if \\ s \\leq S - 1 ,else \\ \\emptyset\\) </li> </ul> <p>\u7b80\u5316\u540e\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\uff1a\u5728\u8282\u70b9  \\(n_\\ell^{(s)}\\) \u4e0a\u7684\u6ce8\u610f\u529b\u53ef\u4ee5\u7b80\u5316\u4e3a\uff1a $$ y_i = \\sum_{\\ell \\in N_\\ell^{(s)}} \\frac{\\exp(q_i k_\\ell^T / \\sqrt{d_K}) v_\\ell}{\\sum_{\\ell \\in N_i^{(s)}} \\exp(q_i k_\\ell^T / \\sqrt{d_K})} $$</p> <ul> <li>\u5176\u4e2d\uff0c \\(N_\\ell^{(s)}\\)  \u8868\u793a\u8282\u70b9  \\(n_\\ell^{(s)}\\)  \u5728\u4e09\u4e2a\u5c3a\u5ea6\u4e0a\u7684\u90bb\u8fd1\u8282\u70b9\u96c6\u5408\u3002</li> </ul> <p>We further denote the number of attention layers as N . Without loss of generality, we assume that L is divisible by \\(C^{S\u22121}\\). We can then have the following lemma (cf. Appendix B for the proof and Table 4 for the meanings of the notations).</p> <ul> <li> <p>PAM\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684\u7b80\u5316\uff1a\u9650\u5236\u6bcf\u4e2a\u8282\u70b9\u53ea\u5173\u6ce8\u4e00\u4e2a\u6709\u9650\u7684\u952e\u96c6\u5408\uff0c\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002</p> </li> <li> <p>\u6bcf\u4e2a\u8282\u70b9\u53ea\u5173\u6ce8\u540c\u5c3a\u5ea6\u7684\u76f8\u90bb\u8282\u70b9\u3001\u5b50\u8282\u70b9\u548c\u7236\u8282\u70b9\uff0c\u4ece\u800c\u7b80\u5316\u4e86\u6ce8\u610f\u529b\u8ba1\u7b97\u516c\u5f0f\u3002</p> </li> </ul> <p></p> <p>Lemma 1. Given A, C, L, N , and S that satisfy Equation (4), after N stacked attention layers, nodes at the coarsest scale can obtain a global receptive field.</p> <p>\u7ed9\u5b9a  \\(A\\) ,  \\(C\\) ,  \\(L\\) , \\(N\\), \u548c \\(S\\) \u6ee1\u8db3\u4e0b\u9762\u7684\u65b9\u7a0b (4)\uff0c\u90a3\u4e48\u5728\u7ecf\u8fc7  \\(N\\) \u5c42\u5806\u53e0\u7684\u6ce8\u610f\u529b\u5c42\u540e\uff0c\u6700\u7c97\u5c3a\u5ea6\u4e0a\u7684\u8282\u70b9\u53ef\u4ee5\u83b7\u5f97\u5168\u5c40\u611f\u53d7\u91ce\uff1a</p> <p>\u65b9\u7a0b\uff084\uff09 $$ \\frac{L}{C^{S-1}} - 1 \\leq \\frac{(A - 1)N}{2}. $$ \u7b26\u53f7\u8bf4\u660e\uff1a </p> <ul> <li>\\(A\\) \uff1a\u6bcf\u4e2a\u8282\u70b9\u5728\u540c\u5c3a\u5ea6\u4e0a\u7684\u76f8\u90bb\u8282\u70b9\u6570\uff08\u5305\u62ec\u8282\u70b9\u672c\u8eab\uff09</li> <li>\\(C\\)\uff1aC-ary\u6811\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u5b50\u8282\u70b9\u6570</li> <li>\\(L\\)\uff1a\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u7684\u957f\u5ea6</li> <li>\\(N\\) \uff1a\u5806\u53e0\u7684\u6ce8\u610f\u529b\u5c42\u6570</li> <li>\\(S\\)\uff1a\u5c3a\u5ea6\u6570\uff0c\u4ece\u6700\u7ec6\u5c3a\u5ea6\u5230\u6700\u7c97\u5c3a\u5ea6</li> </ul> <p>In addition, when the number of scales S is fixed, the following two propositions summarize the time and space complexity and the order of the maximum path length for the proposed pyramidal attention mechanism. </p> <p>We refer the readers to Appendix C and D for proof. </p> <ul> <li> <p>\u5f53\u5c3a\u5ea6\u6570 \\(S\\) \u56fa\u5b9a\u65f6\uff0c\u4ee5\u4e0b\u4e24\u4e2a\u547d\u9898\u603b\u7ed3\u4e86\u6240\u63d0\u51fa\u7684\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u673a\u5236\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4ee5\u53ca\u6700\u5927\u8def\u5f84\u957f\u5ea6\u7684\u9636\u6570\u3002</p> </li> <li> <p>\u5177\u4f53\u8bc1\u660e\u53ef\u4ee5\u5728\u9644\u5f55 C \u548c D \u4e2d\u627e\u5230\u3002</p> </li> </ul> <p>\u603b\u7ed3\uff1a</p> <ul> <li> <p>\u5f15\u7406\uff08Lemma 1\uff09\uff0c\u5b83\u63cf\u8ff0\u4e86\u5728\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u7ecf\u8fc7  N \u5c42\u5806\u53e0\u7684\u6ce8\u610f\u529b\u5c42\u540e\uff0c\u6700\u7c97\u5c3a\u5ea6\u4e0a\u7684\u8282\u70b9\u53ef\u4ee5\u83b7\u5f97\u5168\u5c40\u611f\u53d7\u91ce\uff08global receptive field\uff09</p> </li> <li> <p>\u516c\u5f0f \\(\\frac{L}{C^{S-1}} - 1 \\leq \\frac{(A - 1)N}{2}\\) \u8868\u793a\u5728\u7ecf\u8fc7 \\(N\\) \u5c42\u5806\u53e0\u7684\u6ce8\u610f\u529b\u5c42\u540e\uff0c\u6700\u7c97\u5c3a\u5ea6\u4e0a\u7684\u8282\u70b9\u53ef\u4ee5\u83b7\u5f97\u5168\u5c40\u611f\u53d7\u91ce\u7684\u6761\u4ef6\u3002</p> </li> </ul> <p>Proposition 1.  The time and space complexity for the pyramidal attention mechanism is \\(O(AL)\\) for given \\(A\\) and \\(L\\) and amounts to \\(O(L)\\) when \\(A\\) is a constant \\(w.r.t. L\\). </p> <p>\u4fdd\u8bc1\u590d\u6742\u5ea6 \\(O(L)\\) </p> <p>\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u673a\u5236\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a \\(O(AL)\\)\uff0c\u7ed9\u5b9a \\(A\\) \u548c \\(L\\)\uff0c\u5e76\u4e14\u5f53 \\(A\\) \u76f8\u5bf9\u4e8e  \\(L\\)\u662f\u5e38\u6570\u65f6\uff0c\u590d\u6742\u5ea6\u4e3a \\(O(L)\\)\u3002</p> <p>\u7b26\u53f7\u8bf4\u660e\uff1a</p> <ul> <li>\\(A\\) \uff1a\u6bcf\u4e2a\u8282\u70b9\u5728\u540c\u5c3a\u5ea6\u4e0a\u7684\u76f8\u90bb\u8282\u70b9\u6570\uff08\u5305\u62ec\u8282\u70b9\u672c\u8eab\uff09</li> <li>\\(L\\)\uff1a\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u7684\u957f\u5ea6\u3002</li> <li>\u8be5\u547d\u9898\u8868\u660e\uff0c\u5f53  \\(A\\) \u76f8\u5bf9\u4e8e  \\(L\\)  \u662f\u5e38\u6570\u65f6\uff0c\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u673a\u5236\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3b\u8981\u53d6\u51b3\u4e8e\u5e8f\u5217\u957f\u5ea6  \\(L\\) </li> </ul> <p>Proposition 2. Let the signal traversing path between two nodes in a graph denote the shortest path connecting them. Then the maximum length of signal traversing path between two arbitrary nodes in the pyramidal graph is \\(O(S + L/C^{S\u22121}/A)\\) for given \\(A, C, L,\\) and \\(S\\).</p> <p>\u4fdd\u8bc1\u6700\u5927\u4fe1\u53f7\u4f20\u9012\u8def\u5f84 \\(O(1)\\) </p> <p>\u8bbe\u56fe\u4e2d\u4e24\u4e2a\u8282\u70b9\u4e4b\u95f4\u7684\u4fe1\u53f7\u7a7f\u8d8a\u8def\u5f84\u8868\u793a\u8fde\u63a5\u5b83\u4eec\u7684\u6700\u77ed\u8def\u5f84\u3002</p> <p>\u5219\u5728\u7ed9\u5b9a  \\(A\\) ,  \\(C\\) ,  \\(L\\) , \u548c  \\(S\\)  \u7684\u60c5\u51b5\u4e0b\uff0c\u91d1\u5b57\u5854\u56fe\u4e2d\u4efb\u610f\u4e24\u4e2a\u8282\u70b9\u4e4b\u95f4\u7684\u4fe1\u53f7\u7a7f\u8d8a\u8def\u5f84\u7684\u6700\u5927\u957f\u5ea6\u4e3a \\(O(S + L/C^{S-1}/A)\\)\u3002</p> <p>Suppose that \\(A\\) and \\(S\\) are fixed and \\(C\\) satisfies Equation (5), the maximum path length is \\(O(1)\\) for time series with length \\(L\\).</p> <p>\u5047\u8bbe  \\(A\\)  \u548c  \\(S\\) \u662f\u56fa\u5b9a\u7684\uff0c\u5e76\u4e14  \\(C\\) \u6ee1\u8db3\u65b9\u7a0b (5)\uff0c\u5219\u5bf9\u4e8e\u957f\u5ea6\u4e3a  \\(L\\)  \u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u6700\u5927\u8def\u5f84\u957f\u5ea6\u4e3a  \\(O(1)\\)\u3002</p> <p>\u539f\u6587\u65b9\u7a0b\uff085\uff09</p> \\[ \\sqrt[S-1]{L} \\ \\geq C \\geq \\sqrt[S-1]{\\frac{L}{(A-1)N/2 + 1}} \\ . \\] <ul> <li>\u7b26\u53f7\u8bf4\u660e\uff1a</li> <li>\\(C\\) \uff1a \\(C\\) -ary\u6811\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u5b50\u8282\u70b9\u6570\u3002</li> <li>\\(S\\) \uff1a\u5c3a\u5ea6\u6570\uff0c\u4ece\u6700\u7ec6\u5c3a\u5ea6\u5230\u6700\u7c97\u5c3a\u5ea6\u3002</li> <li>\\(N\\) \uff1a\u5806\u53e0\u7684\u6ce8\u610f\u529b\u5c42\u6570\u3002</li> <li>\u65b9\u7a0b (5) \u7ed9\u51fa\u4e86  \\(C\\)  \u7684\u53d6\u503c\u8303\u56f4\uff0c\u786e\u4fdd\u5728 \\(A\\) \u548c  \\(S\\)  \u56fa\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u6700\u5927\u8def\u5f84\u957f\u5ea6\u4e3a  \\(O(1)\\) \u3002</li> </ul> <p>\u603b\u7ed3\uff1a</p> <ul> <li>\u8fd9\u4e24\u4e2a\u547d\u9898\u603b\u7ed3\u4e86\u91d1\u5b57\u5854\u6ce8\u610f\u529b\u673a\u5236\u5728\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4ee5\u53ca\u4fe1\u53f7\u7a7f\u8d8a\u8def\u5f84\u6700\u5927\u957f\u5ea6\u65b9\u9762\u7684\u7406\u8bba\u4fdd\u8bc1</li> <li>\u547d\u9898 1 \u8868\u660e\uff0c\u5f53  \\(A\\) \u76f8\u5bf9\u4e8e  \\(L\\)  \u662f\u5e38\u6570\u65f6\uff0c\u590d\u6742\u5ea6\u4e3b\u8981\u53d6\u51b3\u4e8e\u5e8f\u5217\u957f\u5ea6  \\(L\\) </li> <li>\u547d\u9898 2 \u5219\u7ed9\u51fa\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u91d1\u5b57\u5854\u56fe\u4e2d\u4efb\u610f\u4e24\u4e2a\u8282\u70b9\u4e4b\u95f4\u7684\u4fe1\u53f7\u7a7f\u8d8a\u8def\u5f84\u7684\u6700\u5927\u957f\u5ea6\u4e3a  \\(O(1)\\) </li> </ul> <p>In our experiments, we fix S and N , and A can only take 3 or 5, regardless of the sequence length L. </p> <p>\u5728\u6211\u4eec\u7684\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u56fa\u5b9a\u4e86  \\(S\\)  \u548c \\(N\\)\uff0c\u5e76\u4e14 \\(A\\) \u53ea\u80fd\u53d6\\(3\\)\u6216\\(5\\)\uff0c\u65e0\u8bba\u5e8f\u5217\u957f\u5ea6 \\(L\\) \u5982\u4f55\u3002</p> <p>\u53c2\u6570\u8bbe\u7f6e\uff1a - \\(S\\)   \u548c  \\(N\\)  \u662f\u56fa\u5b9a\u7684\u53c2\u6570\u3002 -  \\(A\\) ) \u53ef\u4ee5\u53d6\u503c\u4e3a3\u62165\uff0c\u4e0e\u5e8f\u5217\u957f\u5ea6  \\(L\\)  \u65e0\u5173\u3002</p> <p>Therefore, the proposed PAM achieves the complexity of \\(O(L)\\) with the maximum path length of \\(O(1)\\). </p> <p>\u56e0\u6b64\uff0c\u6240\u63d0\u51fa\u7684**PAM**\uff08\u5b9e\u73b0\u4e86 \\(O(L)\\)  \u7684\u590d\u6742\u5ea6\uff0c\u6700\u5927\u8def\u5f84\u957f\u5ea6\u4e3a \\(O(1)\\) </p> <p>Note that in the PAM, a node can attend to at most \\(A + C + 1\\) nodes. </p> <p>\u6ce8\u610f\uff0c\u5728**PAM**\u4e2d\uff0c\u4e00\u4e2a\u8282\u70b9\u6700\u591a\u53ef\u4ee5\u5173\u6ce8  \\(A + C + 1\\) \u4e2a\u8282\u70b9\u3002</p> <p>Unfortunately, such a sparse attention mechanism is not supported in the existing deep learning libraries, such as Pytorch and TensorFlow. </p> <p>\u4e0d\u5e78\u7684\u662f\uff0c\u8fd9\u79cd\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u5728\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93\u4e2d\uff08\u5982Pytorch\u548cTensorFlow\uff09\u5e76\u4e0d\u652f\u6301\u3002</p> <p>A naive implementation of the PAM that can fully exploit the tensor operation framework is to first compute the product between all Q-K pairs, i.e., \\(q_ik^T_{\\ell}\\ for \\ l =  1, \u00b7 \u00b7 \u00b7 , L,\\) and then mask out \\(l\\in \u0338 N^{(s) }_{\\ell}\\) . </p> <p>\u4e00\u79cd\u53ef\u4ee5\u5145\u5206\u5229\u7528\u5f20\u91cf\u64cd\u4f5c\u6846\u67b6\u7684**PAM**\u7684\u7b80\u5355\u5b9e\u73b0\u662f\u9996\u5148\u8ba1\u7b97\u6240\u6709**Q-K**\u5bf9\u7684\u4e58\u79ef\uff0c\u5373 $  q_i k_\\ell^T $ ( \\(\\ell = 1, \\cdots, L\\)  ) \uff0c\u7136\u540e\u5c4f\u853d\u6389   \\(\\ell \\notin \\mathbb{N}_\\ell^{(s)}\\)  \u3002</p> <p>However, the resulting time and space complexity of this  implementation is still \\(O(L^2)\\) .</p> <p>\u7136\u800c\uff0c\u8fd9\u79cd\u5b9e\u73b0\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4ecd\u7136\u662f  \\(O(L^2)\\)  \u3002</p> <p>Instead, we build a customized CUDA kernel specialized for the PAM using TVM (Chen et al., 2018), practically reducing the computational time and memory cost and making the proposed model amenable to long time series. Longer historical input is typically helpful for improving the prediction accuracy, as more information is provided, especially when long-range dependencies are considered.</p> <p>\u76f8\u53cd\uff0c\u6211\u4eec\u4f7f\u7528TVM\uff08Chen et al., 2018\uff09\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u95e8\u4e3aPAM\u5b9a\u5236\u7684CUDA\u5185\u6838\uff0c\u5b9e\u9645\u4e0a\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u548c\u5185\u5b58\u6210\u672c\uff0c\u4f7f\u6240\u63d0\u51fa\u7684\u6a21\u578b\u9002\u5408\u5904\u7406\u957f\u65f6\u5e8f\u6570\u636e\u3002\u66f4\u957f\u7684\u5386\u53f2\u8f93\u5165\u901a\u5e38\u6709\u52a9\u4e8e\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u56e0\u4e3a\u63d0\u4f9b\u4e86\u66f4\u591a\u4fe1\u606f\uff0c\u7279\u522b\u662f\u5f53\u8003\u8651\u957f\u8ddd\u79bb\u4f9d\u8d56\u65f6\u3002</p> <p>\u603b\u7ed3\uff1a</p> <ul> <li>\u590d\u6742\u5ea6\uff1a</li> <li>PAM\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a ( O(L) )\uff0c\u5176\u4e2d ( L ) \u662f\u5e8f\u5217\u957f\u5ea6\u3002</li> <li>\u6700\u5927\u8def\u5f84\u957f\u5ea6\u4e3a ( O(1) )\uff0c\u8fd9\u610f\u5473\u7740\u65e0\u8bba\u5e8f\u5217\u957f\u5ea6\u5982\u4f55\uff0c\u8def\u5f84\u957f\u5ea6\u90fd\u4fdd\u6301\u4e0d\u53d8\u3002</li> <li>\u5b9e\u73b0\u7ec6\u8282\uff1a</li> <li>\u4e00\u79cd\u7b80\u5355\u7684PAM\u5b9e\u73b0\u662f\u5148\u8ba1\u7b97\u6240\u6709Q-K\u5bf9\u7684\u4e58\u79ef\uff0c\u7136\u540e\u5c4f\u853d\u6389\u4e0d\u9700\u8981\u7684\u5143\u7d20\u3002\u8fd9\u79cd\u5b9e\u73b0\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4ecd\u7136\u662f \\(O(L^2)\\) \uff0c\u8fd9\u5bf9\u4e8e\u957f\u5e8f\u5217\u6765\u8bf4\u53ef\u80fd\u4e0d\u591f\u9ad8\u6548\u3002</li> <li>\u4e3a\u4e86\u4f18\u5316\uff0c\u4f5c\u8005\u4f7f\u7528TVM\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u95e8\u4e3aPAM\u5b9a\u5236\u7684CUDA\u5185\u6838\u3002\u8fd9\u79cd\u4f18\u5316\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u548c\u5185\u5b58\u6210\u672c\uff0c\u4f7f\u6a21\u578b\u66f4\u9002\u5408\u5904\u7406\u957f\u65f6\u5e8f\u6570\u636e\u3002</li> </ul>"},{"location":"literature/TSP/9_Pyraformer/#32-coarser-scale-construction-module-cscm","title":"3.2 COARSER-SCALE CONSTRUCTION MODULE (CSCM)","text":"<p>\u539f\u6587\u56fe 3 \u63cf\u8ff0\u7684\u8fd9\u4e2a\u6a21\u5757 </p> <p> </p> <p>CSCM targets at initializing the nodes at the coarser scales of the pyramidal graph, so as to facilitate the subsequent PAM to exchange information between these nodes. </p> <p>CSCM\u65e8\u5728\u521d\u59cb\u5316\u91d1\u5b57\u5854\u56fe\u7684\u8f83\u7c97\u7cd9\u5c3a\u5ea6\u4e0a\u7684\u8282\u70b9\uff0c\u4ee5\u4fbf\u4fc3\u8fdb\u968f\u540e\u7684PAM\u5728\u8fd9\u4e9b\u8282\u70b9\u4e4b\u95f4\u4ea4\u6362\u4fe1\u606f\u3002</p> <p>Specifically, the coarse-scale nodes are introduced scale by scale from bottom to top by performing convolutions on the corresponding children nodes \\(C_{\\ell}^{(s)}\\) .</p> <p>\u5177\u4f53\u6765\u8bf4\uff0c\u901a\u8fc7\u5728\u76f8\u5e94\u7684\u5b50\u8282\u70b9  \\(C_{\\ell}^{(s)}\\)  \u4e0a\u6267\u884c\u5377\u79ef\uff0c\u4ece\u5e95\u5c42\u5230\u9876\u5c42\u9010\u5c42\u5f15\u5165\u7c97\u7cd9\u5c3a\u5ea6\u7684\u8282\u70b9\u3002</p> <p>As demonstrated in Figure 3, several convolution layers with kernel  size C and stride C are sequentially applied to the embedded sequence in the dimension of time, yielding a sequence with length L/Cs at scale s. </p> <p>\u5982\u56fe3\u6240\u793a\uff0c\u51e0\u4e2a\u5177\u6709\u6838\u5927\u5c0f \\( C \\) \u548c\u6b65\u5e45 \\( C \\) \u7684\u5377\u79ef\u5c42\u4f9d\u6b21\u5e94\u7528\u4e8e\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u5d4c\u5165\u5e8f\u5217\uff0c\u4ea7\u751f\u957f\u5ea6\u4e3a \\( L/C^s \\) \u7684\u5e8f\u5217\u3002</p> <p>The resulting sequences at different scales form a C-ary tree. We concatenate these fine-to-coarse sequences before inputting them to the PAM. In order to reduce the amount of parameters and calculations, we reduce the dimension of each node by a fully connected layer before inputting the sequence into the stacked convolution layers and restore it after all convolutions. Such a bottleneck structure significantly reduces the number of parameters in the module and can guard against over-fitting.</p>"},{"location":"literature/TSP/9_Pyraformer/#_4","title":"\u56fe\u7247\u7ffb\u8bd1","text":"<p>\u5728\u5c3a\u5ea6 \\( s \\)\u3002\u4e0d\u540c\u5c3a\u5ea6\u4e0a\u7684\u5e8f\u5217\u7ed3\u679c\u5f62\u6210\u4e00\u4e2aC-ary\u6811\u3002\u6211\u4eec\u5728\u5c06\u5b83\u4eec\u8f93\u5165\u5230PAM\u4e4b\u524d\uff0c\u5c06\u8fd9\u4e9b\u4ece\u7ec6\u5230\u7c97\u7684\u5e8f\u5217\u8fde\u63a5\u8d77\u6765\u3002\u4e3a\u4e86\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u548c\u8ba1\u7b97\u91cf\uff0c\u6211\u4eec\u5728\u5c06\u5e8f\u5217\u8f93\u5165\u5230\u5806\u53e0\u7684\u5377\u79ef\u5c42\u4e4b\u524d\uff0c\u901a\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u51cf\u5c11\u6bcf\u4e2a\u8282\u70b9\u7684\u7ef4\u5ea6\uff0c\u5e76\u5728\u6240\u6709\u5377\u79ef\u4e4b\u540e\u6062\u590d\u5b83\u3002\u8fd9\u79cd\u74f6\u9888\u7ed3\u6784\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u5757\u4e2d\u7684\u53c2\u6570\u6570\u91cf\uff0c\u5e76\u53ef\u4ee5\u9632\u6b62\u8fc7\u62df\u5408\u3002</p>"},{"location":"literature/TSP/9_Pyraformer/#_5","title":"\u8bb2\u89e3","text":"<p>\u8fd9\u6bb5\u6587\u5b57\u63cf\u8ff0\u4e86CSCM\uff08\u53ef\u80fd\u662f\u67d0\u79cd\u6a21\u578b\u6216\u7b97\u6cd5\uff09\u5982\u4f55\u901a\u8fc7\u521d\u59cb\u5316\u91d1\u5b57\u5854\u56fe\u7684\u8f83\u7c97\u7cd9\u5c3a\u5ea6\u4e0a\u7684\u8282\u70b9\u6765\u4fc3\u8fdb\u4fe1\u606f\u4ea4\u6362\u3002\u4ee5\u4e0b\u662f\u5173\u952e\u70b9\u7684\u8be6\u7ec6\u89e3\u91ca\uff1a</p> <ol> <li> <p>\u521d\u59cb\u5316\u8282\u70b9\uff1a    - CSCM\u7684\u76ee\u6807\u662f\u5728\u91d1\u5b57\u5854\u56fe\u7684\u8f83\u7c97\u7cd9\u5c3a\u5ea6\u4e0a\u521d\u59cb\u5316\u8282\u70b9\uff0c\u4ee5\u4fbf\u4fc3\u8fdb\u540e\u7eed\u7684PAM\u5728\u8fd9\u4e9b\u8282\u70b9\u4e4b\u95f4\u4ea4\u6362\u4fe1\u606f\u3002</p> </li> <li> <p>\u5377\u79ef\u5c42\uff1a    - \u901a\u8fc7\u5728\u76f8\u5e94\u7684\u5b50\u8282\u70b9 \\( C_{\\ell}^{(s)} \\) \u4e0a\u6267\u884c\u5377\u79ef\uff0c\u4ece\u5e95\u5c42\u5230\u9876\u5c42\u9010\u5c42\u5f15\u5165\u7c97\u7cd9\u5c3a\u5ea6\u7684\u8282\u70b9\u3002    - \u51e0\u4e2a\u5177\u6709\u6838\u5927\u5c0f \\( C \\) \u548c\u6b65\u5e45 \\( C \\) \u7684\u5377\u79ef\u5c42\u4f9d\u6b21\u5e94\u7528\u4e8e\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u5d4c\u5165\u5e8f\u5217\uff0c\u4ea7\u751f\u957f\u5ea6\u4e3a \\( L/C^s \\) \u7684\u5e8f\u5217\u3002</p> </li> <li> <p>C-ary\u6811\uff1a    - \u4e0d\u540c\u5c3a\u5ea6\u4e0a\u7684\u5e8f\u5217\u7ed3\u679c\u5f62\u6210\u4e00\u4e2aC-ary\u6811\u3002    - \u5728\u5c06\u8fd9\u4e9b\u5e8f\u5217\u8f93\u5165\u5230PAM\u4e4b\u524d\uff0c\u5c06\u5b83\u4eec\u8fde\u63a5\u8d77\u6765\u3002</p> </li> <li> <p>\u51cf\u5c11\u53c2\u6570\u548c\u8ba1\u7b97\u91cf\uff1a    - \u4e3a\u4e86\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u548c\u8ba1\u7b97\u91cf\uff0c\u5728\u5c06\u5e8f\u5217\u8f93\u5165\u5230\u5806\u53e0\u7684\u5377\u79ef\u5c42\u4e4b\u524d\uff0c\u901a\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u51cf\u5c11\u6bcf\u4e2a\u8282\u70b9\u7684\u7ef4\u5ea6\uff0c\u5e76\u5728\u6240\u6709\u5377\u79ef\u4e4b\u540e\u6062\u590d\u5b83\u3002    - \u8fd9\u79cd\u74f6\u9888\u7ed3\u6784\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u5757\u4e2d\u7684\u53c2\u6570\u6570\u91cf\uff0c\u5e76\u53ef\u4ee5\u9632\u6b62\u8fc7\u62df\u5408\u3002</p> </li> </ol> <p>\u603b\u7ed3\u6765\u8bf4\uff0c\u8fd9\u6bb5\u6587\u5b57\u63cf\u8ff0\u4e86CSCM\u5982\u4f55\u901a\u8fc7\u521d\u59cb\u5316\u91d1\u5b57\u5854\u56fe\u7684\u8f83\u7c97\u7cd9\u5c3a\u5ea6\u4e0a\u7684\u8282\u70b9\u6765\u4fc3\u8fdb\u4fe1\u606f\u4ea4\u6362\uff0c\u5e76\u4f7f\u7528\u5377\u79ef\u5c42\u548c\u74f6\u9888\u7ed3\u6784\u6765\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u548c\u8ba1\u7b97\u91cf\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6548\u7387\u548c\u9632\u6b62\u8fc7\u62df\u5408\u3002</p>"},{"location":"logs/","title":"\u9996\u9875","text":"","tags":["logs"]},{"location":"logs/#_1","title":"\u6742","text":"2025-03-27 00:00:002025-09-28 12:54:06 <p>\u542c\u8bf4\u6bcf\u4e2ap\u4eba\u5fc5\u5907\u7684\u6742\uff0c\u7b11\uff09</p> <p></p>","tags":["logs"]},{"location":"logs/1_date/","title":"\u4e00\u4e9b\u65e5\u671f","text":""},{"location":"logs/1_date/#_1","title":"\u4e00\u4e9b\u65e5\u671f","text":"2025-03-21 14:12:102025-09-28 12:54:06 <p> \u7ea6 690 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p>"},{"location":"logs/1_date/#_2","title":"\u6bd5\u4e1a\u76f8\u5173","text":"<ul> <li>2024 \u5e74 11 \u6708 5 \u65e5 \u5173\u4e8e\u505a\u597d\u7814\u7a76\u751f\u5f00\u9898\u62a5\u544a\u5de5\u4f5c\u7684\u901a\u77e5 </li> <li>2024\u5e7412\u670813\u65e5 \u5f00\u9898\u62a5\u544a</li> <li>2024\u5e7412\u670816\u65e5 \u5f00\u9898\u7b54\u8fa9</li> <li>2024 \u5e74 12 \u6708 31 \u65e5 \u7814\u4e8c\u4e0a\u6700\u540e\u4e00\u6b21\u7ec4\u4f1a</li> <li>2025 \u5e74 3 \u6708 21 \u65e5 22 \u7ea7\u7814\u4e09\u5e08\u5144\u5e08\u59d0\u4e0a\u4f20\u9884\u7b54\u8fa9 ppt\u3001\u8bba\u6587</li> <li>2025 \u5e74 4 \u6708 8 \u65e5 \u5173\u4e8e\u505a\u597d2024-2025\u5b66\u5e74\u7814\u7a76\u751f\u4e2d\u671f\u8003\u6838\u7684\u901a\u77e5 </li> <li>2025 \u5e74 4 \u6708 11 \u65e5 22 \u7ea7\u5e08\u5144\u5e08\u59d0\u6c47\u62a5\u8bba\u6587\uff0c\u76f2\u5ba1\u5df2\u62bd</li> </ul>"},{"location":"logs/1_date/#_3","title":"\u788e","text":"<ul> <li>\u5170\u5dde\u5927\u5b66\u6570\u5b66\u4e0e\u7edf\u8ba1\u5b66\u9662</li> </ul> <ul> <li>2024 \u5e74 11 \u6708 6 \u65e5 \u6570\u5b66\u4e0e\u7edf\u8ba1\u5b66\u96622025\u5e74\u535a\u58eb\u7814\u7a76\u751f\u62db\u751f\u201c\u7533\u8bf7-\u8003\u6838\u201d\u5b9e\u65bd\u65b9\u6848 </li> </ul> <p>\u7b2c\u4e00\u6279\u6b21\u62a5\u540d\u65f6\u95f4\uff1a2024\u5e7411\u670815\u65e58:00-12\u670815\u65e518:00</p> <p>\u7b2c\u4e8c\u6279\u6b21\u62a5\u540d\u65f6\u95f4\uff1a\u5982\u7b2c\u4e00\u6279\u6b21\u62a5\u540d\u751f\u6e90\u4e0d\u8db3\uff0c\u5b66\u9662\u5c06\u4e8e2025\u5e743-5\u6708\u5f00\u542f\u7b2c\u4e8c\u6279\u6b21\u62a5\u540d\uff0c\u5177\u4f53\u65f6\u95f4\u53e6\u884c\u901a\u77e5\u3002</p> <ul> <li>2024 \u5e7412 \u6708 23 \u65e5 \u5170\u5dde\u5927\u5b66\u6570\u5b66\u4e0e\u7edf\u8ba1\u5b66\u96622025\u5e74\u535a\u58eb\u7814\u7a76\u751f\u7b2c\u4e00\u6279\u62db\u751f\u5f55\u53d6\u4e0e\u8003\u6838\u529e\u6cd5</li> <li>2024 \u5e74 12 \u6708 24 \u65e5 \u5170\u5dde\u5927\u5b66\u6570\u5b66\u4e0e\u7edf\u8ba1\u5b66\u96622025\u5e74\u535a\u58eb\u62db\u751f\u51c6\u8003\u8003\u751f\u540d\u5355\u516c\u793a </li> </ul> <p>future\uff1a</p> <ul> <li>2025 \u5e74 7 \u6708 7 \u65e5 \u4e2d\u671f\u8003\u6838</li> <li>2026 \u5e74 5 \u6708 \u6bd5\u4e1a\u8bba\u6587\u7b54\u8fa9</li> </ul>"},{"location":"logs/1_date/#_4","title":"\u597d\u4e45\u4e0d\u89c1","text":"<ul> <li>2025 \u5e74 1 \u6708 2 \u65e5 \ud83c\udfe0</li> <li>2025 \u5e74 1 \u67084 \u65e5 \u89c1\u670b\u53cb\ud83d\udc6c\ud83c\udffb</li> <li>2025 \u5e74 1 \u6708 18 \u65e5 \u5bb6\u5ead\u805a\u9910</li> <li>2025 \u5e74 1 \u670820 \u65e5 \u89c1\u53d1\u5c0f</li> </ul>"},{"location":"logs/1_date/#_5","title":"\u4e8b\u52a1\u65e5\u671f","text":"<ul> <li>\u4e2d\u56fd\u6559\u5e08\u8d44\u683c\u7f51</li> <li>\u4e2d\u56fd\u6559\u80b2\u8003\u8bd5\u7f51 </li> </ul> <ul> <li> <p>2025 \u5e74 1 \u6708 7 \u65e5 \u6559\u8d44\u9762\u8bd5\u6210\u7ee9</p> </li> <li> <p>2025 \u5e74 2 \u6708 21 \u65e5~2 \u6708 28 \u65e5 \u56db\u516d\u7ea7\u6210\u7ee9</p> </li> <li>2025 \u5e74 3 \u6708 \u6559\u5e08\u8d44\u683c\u8bc1\u8ba4\u8bc1\u3001\u4f53\u68c0</li> <li>2023 \u5e74 3 \u6708 7 \u65e5 2025\u5e74\u4e0a\u534a\u5e74\u5168\u56fd\u5927\u5b66\u82f1\u8bed\u56db\u3001\u516d\u7ea7\u8003\u8bd5\u62a5\u540d\u5de5\u4f5c\u542f\u52a8</li> <li>2025 \u5e74 3 \u6708 20 \u65e5  \u7518\u8083\u77012025\u5e74\u4e0a\u534a\u5e74\u6559\u5e08\u8d44\u683c\u8ba4\u5b9a\u516c\u544a</li> <li>2025 \u5e74 4 \u6708 14 \u65e5 2025\u5e74\u5404\u7701\u4efd\u6559\u5e08\u8d44\u683c\u8ba4\u5b9a\u516c\u544a\u6c47\u603b</li> <li>2025\u5e744\u670814\u65e59\uff1a00\uff0d4\u670825\u65e517\uff1a00 \u7b2c\u4e00\u6279\u4e2d\u5c0f\u5b66\u6559\u5e08\u8d44\u683c\u8ba4\u5b9a\u7f51\u62a5\u65f6\u95f4</li> <li>2025 \u5e746 \u6708 14 \u65e5 \u516d\u7ea7\u7b14\u8bd5</li> <li>2025\u5e746\u670816\u65e59\uff1a00\uff0d6\u670827\u65e517\uff1a00 \u7b2c\u4e8c\u6279\u4e2d\u5c0f\u5b66\u6559\u5e08\u8d44\u683c\u8ba4\u5b9a\u7f51\u62a5\u65f6\u95f4</li> </ul>"},{"location":"logs/1_date/#_6","title":"\u6cd5\u5b9a\u5f00\u5fc3\u65e5","text":"<ul> <li>2025 \u5e74 1 \u6708 28 \u65e5 \u65b0\u5e74\u5feb\u4e50</li> </ul>"},{"location":"logs/1_date/#_7","title":"\u5e73\u5e73\u6de1\u6de1\u7684\u5c0f\u65e5\u5b50","text":"<ul> <li>2025 \u5e74 3 \u6708 7 \u65e5\uff0c\u4eca\u5929\u5403\u4e86 3 \u4e2a\u5de7\u514b\u529b\u78b1\u6c34\u9762\u5305</li> <li>2025 \u5e74 3 \u6708 16 \u65e5\uff0c\u4eca\u5929\u751f\u65e5\uff0c\u8c22\u8c22 gaq\u3001myx</li> <li>2024 \u5e74 4 \u6708 14 \u65e5\uff0c\u665a\uff0c\u725b\u5976\u9e21\u86cb\u91aa\u7cdf\u597d\u597d\u559d</li> <li>2025 \u5e744 \u6708 15 \u65e5\uff0c\u665a\uff0czdc\uff0c\u5976\u6cb9\u6ce1\u8299\u597d\u597d\u5403</li> </ul>"},{"location":"logs/1_date/#_8","title":"\u6211\u79fb\u52a8","text":"<ul> <li>2024 \u5e74 12 \u6708 25 \u65e5~2024 \u5e74 12 \u6708 30 \u65e5 \u6210\u90fd</li> <li>2025 \u5e74 2 \u6708 6 \u65e5 \u7814\u4e8c\u4e0b\u8fd4\u6821</li> <li>2025 \u5e74 3 \u6708 8 \u65e5 \u56de\u5bb6</li> <li>2025 \u5e74 3 \u6708 13 \u65e5 \u8fd4\u6821</li> </ul>"},{"location":"logs/2_updatelog/","title":"\u66f4\u65b0\u65e5\u5fd7","text":""},{"location":"logs/2_updatelog/#_1","title":"\u66f4\u65b0\u65e5\u5fd7","text":"2025-03-28 09:31:382025-09-28 12:54:06 <p>Abstract</p> <p>\u8be5\u9875\u9762\u7279\u522b\u611f\u8c22:  TonyCrane/mkdocs-changelog-plugin</p>"},{"location":"logs/2_updatelog/#2025","title":"2025","text":"2025-09-28\u00b6 <p> \u4e0a\u4f20 pdf_note\u90e8\u5206</p> 2025-05-02\u00b6 <p> \u672c\u7ad9\u4e0d\u518d\u66f4\u65b0,\u8df3\u8f6c\u67e5\u770b\u6700\u65b0\u52a8\u6001</p> 2025-04-20\u00b6 <p> SENet Mamba \u91cd\u65b0\u7ec4\u7ec7\u6587\u4ef6\u7ed3\u6784</p> 2025-04-19\u00b6 <p> \u95e8\u63a7\u673a\u5236</p> 2025-04-18\u00b6 <p> python-CodeRepo</p> 2025-04-16\u00b6 <p> Git\u90e8\u5206</p> 2025-04-15\u00b6 <p> DLinear\u8bba\u6587</p> 2025-04-14\u00b6 <p> Fedformer\u3001Pyraformer \u9891\u57df\u65f6\u5e8f</p> <p> TimeMixer\u3001WITRAN \u8bba\u6587\u53ca\u4ee3\u7801</p> <p> \u6574\u7406\u4e86\u4e00\u4e2a\u81ea\u5df1\u590d\u73b0\u8fc7\u7684 TSF \u4ed3\u5e93</p> 2025-04-10\u00b6 <p> Autoformer\u3001SegRNN \u4ee3\u7801\u6570\u636e\u6d41\u52a8\u56fe\u3001\u6458\u51fa\u5e8f\u5217\u5206\u89e3\u6a21\u5757</p> 2025-04-08\u00b6 <p> UNetTSF</p> 2025-04-02\u00b6 <p> SegRNN \u518d\u63a2\uff0c\u5b9e\u9a8c\u90e8\u5206</p> <p> \u5220\u9664 pdf_note\u90e8\u5206</p> 2025-03-29\u00b6 <p> \u4fee\u6539\u9996\u9875\u6837\u5f0f\uff0c\u7f51\u7ad9\u5b57\u4f53\uff0cchangelog \u7c7b\u578b\u4fee\u6539\uff0c\u94fe\u63a5\u989c\u8272\u3001\u9f20\u6807\u60ac\u505c\u989c\u8272\u3001\u5361\u7247\u9634\u5f71\u989c\u8272\u4e0e\u4e3b\u9898\u8272\u9002\u914d</p> 2025-03-28\u00b6 <p> \u65b0\u589e\u66f4\u65b0\u65e5\u5fd7\u529f\u80fd</p> <p> \u663e\u793a\u7ad9\u70b9\u7edf\u8ba1\u3001\u66f4\u6362\u5916\u89c2\u3001\u8bbe\u8ba1\u9996\u9875</p> <p> \u65e5\u671f\u7684\u663e\u793a\u66f4\u6362\u63d2\u4ef6</p> 2025-03-27\u00b6 <p> \u590d\u5e73\u9762\u4e0e\u590d\u6307\u6570\u65cb\u8f6c</p>"},{"location":"logs/2_updatelog/#2024","title":"2024","text":"2024-11-14\u00b6 <p> hello world</p>"},{"location":"logs/3_test/","title":"\u529f\u80fd\u6d4b\u8bd5\u9875\u9762","text":""},{"location":"logs/3_test/#_1","title":"\u529f\u80fd\u6d4b\u8bd5\u9875\u9762","text":"2025-03-28 10:25:362025-09-28 12:54:06 <p> \u7ea6 36 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"logs/4_flink/","title":"\u66f4\u591a\u94fe\u63a5","text":"2025-03-28 17:28:522025-09-28 12:54:06 <ul> <li> <p> \u8fd9\u662f\u4e00\u4e2a\u5145\u6ee1\u611f\u6069\u7684\u9875\u9762\uff0c\u8c22\u8c22\u4f60\u4eec</p> <p><p>\u6d77\u7eb3\u767e\u5ddd\u51ed\u5ea6\u91cf\uff0c\u58c1\u7acb\u5343\u4ede\u4efb\u4e91\u7fd4</p></p> </li> </ul> <p>Abstract</p> <p>\u5355\u65b9\u9762\u6dfb\u52a0\u53cb\u94fe\uff0c\u90fd\u592a\u597d\u4f1a\u8bbe\u8ba1</p> <p>\u5de5\u5177\u94fe\u3001\u8d5b\u535a\u5bfc\u5e08\u3001\u5b66\u4e60\u94fe\u63a5\u3001\u670b\u53cb\u7b49</p> <p>\u672c\u9875\u9762\u6837\u5f0f\u7279\u522b\u611f\u8c22\uff1a\u9e64\u7fd4\u4e07\u91cc\u7684\u7b14\u8bb0\u672c</p>"},{"location":"logs/4_flink/#_2","title":"\u5de5\u5177\u94fe","text":"Latex \u8868\u683c\u3001\u56fe\u7247\u6392\u7248\u6a21\u7248 \u4e2d\u5c71\u5927\u5b66\u8001\u5e08\u7ef4\u62a4 \u79d1\u7814\u5236\u56fe\u5de5\u5177\u5206\u4eab b\u7ad9 up \u4e3b \u79d1\u7814\u7ed8\u56fe\u914d\u8272 \u77e5\u4e4e\uff1a\u6de1\u84dd\u3001\u6de1\u7ea2\u3001\u6de1\u9ec4\u3001\u6de1\u7eff \u4e0d\u849c\u5b50 \u7edf\u8ba1 pv\u3001uv ColorSpace \u751f\u6210\u5f88\u597d\u770b\u7684\u914d\u8272 <p>\ud83d\udea9 \u53cc\u62fc\u5165\u95e8</p> <p>\ud83d\udea9 \u53cc\u62fc\u7ec3\u4e60</p> <p>\ud83d\udea9 \u7528\u963f\u91cc\u4e91\u7684\u4e07\u7f51\u4e91\u865a\u62df\u4e3b\u673a\u642d\u5efa\u4e00\u4e2a\u81ea\u6709\u57df\u540d\u7684WordPress\u535a\u5ba2</p> <p>\ud83d\udea9 \u5076\u7136\u5237\u5230\u7684\u9006\u5929\u5927\u795e</p>"},{"location":"logs/4_flink/#mkdocs","title":"mkdocs","text":"\u6768\u5e0c\u6770\u7684\u4e2a\u4eba\u7f51\u7ad9 \u4e0d\u5fd8\u521d\u5fc3\uff0c\u5f00\u59cb mkdocs \u7684\u8d77\u70b9 Wcowin\u2019s Web \u8ddf\u7740\u5b66\u8fc7\u65f6\u95f4\u6233\u3001\u9875\u9762\u5d4c\u5165\u663e\u793a pdf MkDocs Material \u5b98\u65b9\u6587\u6863\uff0c\u4e0d\u5fc5\u591a\u8a00 \u9e64\u7fd4\u4e07\u91cc\u7684\u7b14\u8bb0\u672c \u9996\u9875\u5f88\u9177\uff0c\u6ca1\u5b66\u4f1a widcardw/my-notes \u5f88\u7b80\u6d01\u7684\u5728\u7ebf\u7b14\u8bb0\uff0c\u4e13\u6ce8\u5185\u5bb9\uff0c\u4e5f\u4f1a\u8ba9\u6211\u601d\u8003\u5efa\u7f51\u9875\u7684\u521d\u8877 Walker_V's Notebook \u8ddf\u7740\u5b66\u4e86\u4ee5\u5361\u7247\u5f62\u5f0f\u5d4c\u5165 pdf"},{"location":"logs/4_flink/#_3","title":"\ud83d\udcfa \u8d5b\u535a\u5bfc\u5e08","text":"\u6570\u5b66\u5bb6\u662f\u6211\u7406\u60f3 \u8ddf\u7740\u5b66\u8fc7 bert \u738b\u6728\u5934\u5b66\u79d1\u5b66 \u4ece\u7f16\u7801\u5668\u548c\u8bcd\u5d4c\u5165\u7406\u89e3 Transformer\uff0c\u7ebf\u6027\u4ee3\u6570\u672c\u8d28 Rayman\u5c0f\u4f55\u540c\u5b66 Diffusion\u3001VAE \u6a21\u578b\u516c\u5f0f\u63a8\u5bfc deep_thoughts \u5946\u4f6c\uff0c\u4f4d\u7f6e\u7f16\u7801\u3001\u5f52\u4e00\u5316\u3001\u5377\u79ef\u3001Transformer\u5168\u624b\u6413 RethinkFun \u591a\u6a21\u6001\u7cfb\u5217\uff1aCLIP\u3001MOCO"},{"location":"logs/4_flink/#_4","title":"\u535a\u5ba2","text":"wmanthor Transformer \u7cfb\u5217\u535a\u5ba2\u5f88\u597d"},{"location":"logs/4_flink/#_5","title":"\u670b\u53cb","text":"Just for Life. \u5927\u5b66\u5b66\u957f\uff0c\u5bf9\u722c\u5c71\u662f\u771f\u7231"},{"location":"logs/6_waline/","title":"\u7545\u6240\u6b32\u8a00","text":""},{"location":"logs/6_waline/#_1","title":"\u7545\u6240\u6b32\u8a00","text":"2025-03-30 11:31:152025-09-28 12:54:06 <p> \u7ea6 33 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <ul> <li> <p> \u6eb6 err's \u7559\u8a00\u677f</p> <p></p><p>\u53bb\u7559\u65e0\u610f\uff0c\u6f2b\u968f\u5929\u5916\u4e91\u5377\u4e91\u8212\u53cb\u597d\u8ba8\u8bba\uff0c\u7545\u6240\u6b32\u8a00</p><p></p> </li> </ul>"},{"location":"logs/7_backup/","title":"Backup","text":""},{"location":"logs/7_backup/#backup","title":"Backup","text":"2025-04-05 14:15:382025-09-28 12:54:06 <p> \u7ea6 17 \u4e2a\u5b57  225 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p>"},{"location":"logs/7_backup/#vscode","title":"vscode","text":""},{"location":"logs/7_backup/#launchjson","title":"launch.json","text":"Python<pre><code>{\n    // \u4f7f\u7528 IntelliSense \u4e86\u89e3\u76f8\u5173\u5c5e\u6027\u3002 \n    // \u60ac\u505c\u4ee5\u67e5\u770b\u73b0\u6709\u5c5e\u6027\u7684\u63cf\u8ff0\u3002\n    // \u6b32\u4e86\u89e3\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u8bbf\u95ee: https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n\n        {\n            \"name\": \"Python: run_longExp.py\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"program\": \"${workspaceFolder}/run_longExp.py\",\n            \"args\": [\n                \"--model_id\", \"illness_60_24\",\n                \"--is_training\", \"1\" ,\n                \"--model\", \"SegRNN\", \n                \"--data\", \"custom\",\n                \"--root_path\", \"./dataset/\",\n                \"--data_path\", \"national_illness.csv\",\n                \"--features\", \"M\",\n                \"--seq_len\", \"60\",\n                \"--pred_len\", \"24\",\n                \"--d_model\", \"512\",\n                \"--dropout\", \"0.0\",\n                \"--rnn_type\", \"gru\",\n                \"--dec_way\", \"pmf\",\n                \"--seg_len\", \"12\",\n                \"--loss\", \"mae\",\n                \"--des\", \"test\",\n                \"--itr\", \"1\",\n                \"--batch_size\" ,\"16\",\n                \"--train_epochs\", \"2\",\n                \"--num_workers\", \"0\",\n                \"--learning_rate\", \"0.001\",\n                \"--enc_in\", \"7\",\n                \"--revin\", \"1\"\n            ],\n            \"console\": \"integratedTerminal\",\n            \"justMyCode\": true,\n            \"cwd\": \"${workspaceFolder}\"\n        },\n\n\n\n        {\n            \"name\": \"[\u8fd9\u91cc\u66f4\u6362\u4e3a\u4efb\u610f\u540d\u79f0]\",\n            \"type\": \"python\",\n            \"request\": \"attach\",\n            \"connect\": {\n                \"host\": \"localhost\",\n                \"port\": 5998\n            }\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (type in script name)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${command:AskForScriptName}\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (select script from list of sh files)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${command:SelectScriptName}\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (hardcoded script name)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${workspaceFolder}/path/to/script.sh\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (simplest configuration)\",\n            \"program\": \"${file}\"\n        }\n    ]\n}\n</code></pre>"},{"location":"logs/7_backup/#sh","title":"sh","text":"Python<pre><code>model_name=SegRNN\n\nroot_path_name=./dataset/\ndata_path_name=national_illness.csv\nmodel_id_name=illness\ndata_name=custom\n\n\nseq_len=60\nfor pred_len in 24 36 48 60\ndo\n    python -m debugpy --listen 5998 --wait-for-client run_longExp.py \\\n      --is_training 1 \\\n      --root_path $root_path_name \\\n      --data_path $data_path_name \\\n      --model_id $model_id_name'_'$seq_len'_'$pred_len \\\n      --model $model_name \\\n      --data $data_name \\\n      --features M \\\n      --seq_len $seq_len \\\n      --pred_len $pred_len \\\n      --seg_len 12 \\\n      --enc_in 7 \\\n      --d_model 512 \\\n      --dropout 0 \\\n      --train_epochs 30 \\\n      --patience 10 \\\n      --rnn_type gru \\\n      --dec_way pmf \\\n      --channel_id 1 \\\n      --revin 1 \\\n      --itr 1 --batch_size 16 --learning_rate 0.001\ndone\n</code></pre>"},{"location":"logs/7_backup/#unettsf","title":"\u50bb\u74dc\u5f0f\u5b9e\u73b0UnetTSF","text":"UnetTSF \u4e0d\u6d89\u53ca for\u5faa\u73af Python<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport math\n\n\"UnetTSF: A Better Performance Linear Complexity Time Series Prediction Model\"\n\n\nclass block_model(nn.Module):\n    \"\"\"\n    Decomposition-Linear\n    \"\"\"\n    def __init__(self, input_channels, input_len, out_len):\n        super(block_model, self).__init__()\n        self.channels = input_channels\n        self.input_len = input_len\n        self.out_len = out_len\n\n        self.Linear_channel = nn.Linear(self.input_len, self.out_len)\n        self.ln = nn.LayerNorm(out_len)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        # (B,C,N,T) --&gt; (B,C,N,T)\n        output = self.Linear_channel(x)\n        return output\n\n\n\nclass Model(nn.Module):\n    def __init__(self, input_channels=64,out_channels=64, seq_len=720, pred_len=720):\n        super(Model, self).__init__()\n\n        self.input_channels = input_channels\n        self.out_channels = out_channels\n        self.input_len = seq_len\n        self.out_len = pred_len\n\n        # \u4e0b\u91c7\u6837\u8bbe\u5b9a\n        n1 = 1\n        # \u5e8f\u5217\u957f\u5ea6\u8981\u80fd\u591f\u88ab\u4e0b\u91c7\u6837\u500d\u6570\u6574\u9664\n        filters = [n1, n1 * 2, n1 * 4, n1 * 8]\n        # \u5f53\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u7b49\u4e8e40\u65f6\u5019, down_in=[40,20,10,5]; down_out=[40,20,10,5]\n        down_in = [int(self.input_len / filters[0]), int(self.input_len / filters[1]), int(self.input_len / filters[2]),int(self.input_len / filters[3])]\n        down_out = [int(self.out_len / filters[0]), int(self.out_len / filters[1]), int(self.out_len / filters[2]),int(self.out_len / filters[3])]\n\n        # \u6700\u5927\u6c60\u5316\u5c42\n        # out = (input+2*padding-kernelsize)/stride + 1  \u5728\u8fd9\u91cc\u914d\u7f6e\u4e00\u6837,\u56e0\u6b64\u7b80\u5316\u4e3a: out=(input+2-3)/2+1=(input+1)/2\n        self.Maxpool1 = nn.AvgPool2d(kernel_size=(1,3), stride=(1,2), padding=(0,1))\n        self.Maxpool2 = nn.AvgPool2d(kernel_size=(1,3), stride=(1,2), padding=(0,1))\n        self.Maxpool3 = nn.AvgPool2d(kernel_size=(1,3), stride=(1,2), padding=(0,1))\n        self.Maxpool4 = nn.AvgPool2d(kernel_size=(1,3), stride=(1,2), padding=(0,1))\n\n        # \u5de6\u8fb9\u7279\u5f81\u63d0\u53d6\u5c42\n        self.down_block1 = block_model(self.input_channels, down_in[0], down_out[0])\n        self.down_block2 = block_model(self.input_channels, down_in[1], down_out[1])\n        self.down_block3 = block_model(self.input_channels, down_in[2], down_out[2])\n        self.down_block4 = block_model(self.input_channels, down_in[3], down_out[3])\n\n        # \u53f3\u8fb9\u7279\u5f81\u878d\u5408\u5c42\n        self.up_block3 = block_model(self.input_channels, down_out[2] + down_out[3], down_out[2])\n        self.up_block2 = block_model(self.input_channels, down_out[1] + down_out[2], down_out[1])\n        self.up_block1 = block_model(self.input_channels, down_out[0] + down_out[1], down_out[0])\n\n        # \u8f93\u51fa\u6620\u5c04\n        self.linear_out = nn.Linear(self.input_channels, self.out_channels)\n\n    def forward(self, x):\n        # x: (N,T,C), \u4e0b\u9762\u7684\u6ce8\u91ca\u6211\u4eec\u6309\u716743\u884c\u63d0\u4f9b\u7684\u91c7\u7528\u7387\u6765\u8fdb\u884c\u8ba1\u7b97\n\n        x1 = x.permute(2,0,1)    # \u5bf9\u8f93\u5165x\u53d8\u6362\u7ef4\u5ea6,\u4fbf\u4e8e\u8ba1\u7b97:(N,T,C) --&gt; (C,N,T)\n        e1 = self.down_block1(x1)  # \u901a\u8fc7\u7ebf\u6027\u5c42\u6620\u5c04\u5230\u4e2d\u95f4\u7279\u5f81\u8868\u793aE1: (C,N,T) --&gt; (C,N,T)\n\n        x2 = self.Maxpool1(x1)    # \u5bf9\u8f93\u5165x1\u901a\u8fc7\u6c60\u5316\u64cd\u4f5c\u83b7\u5f97\u7b2c\u4e8c\u5c42\u7279\u5f81x2: (C,N,T)--&gt; (C,N,T/2)\n        e2 = self.down_block2(x2) # \u901a\u8fc7\u7ebf\u6027\u5c42\u6620\u5c04\u5230\u4e2d\u95f4\u7279\u5f81\u8868\u793aE2:(C,N,T/2)--&gt; (C,N,T/2)\n\n        x3 = self.Maxpool2(x2)     # \u5bf9\u8f93\u5165x2\u901a\u8fc7\u6c60\u5316\u64cd\u4f5c\u83b7\u5f97\u7b2c\u4e8c\u5c42\u7279\u5f81x3:(C,N,T/2)--&gt;(B,C,N,T/4)\n        e3 = self.down_block3(x3)  #\u901a\u8fc7\u7ebf\u6027\u5c42\u6620\u5c04\u5230\u4e2d\u95f4\u7279\u5f81\u8868\u793aE3:(B,C,N,T/4)--&gt;(B,C,N,T/4)\n\n        x4 = self.Maxpool3(x3)    #\u5bf9\u8f93\u5165x3\u901a\u8fc7\u6c60\u5316\u64cd\u4f5c\u83b7\u5f97\u7b2c\u4e8c\u5c42\u7279\u5f81x4:(B,C,N,T/4)--&gt;(B,C,N,T/8)\n        e4 = self.down_block4(x4) #\u901a\u8fc7\u7ebf\u6027\u5c42\u6620\u5c04\u5230\u4e2d\u95f4\u7279\u5f81\u8868\u793aE4:(B,C,N,T/8) --&gt; (B,C,N,T/8)\n\n\n        # \u7b2c\u56db\u5c42\u5411\u7b2c\u4e09\u5c42\u878d\u5408\n        d3 = torch.cat((e3, e4), dim=-1)  # \u5c06e3\u7279\u5f81\u56fe\u4e0ed4==E4\u7279\u5f81\u56fe\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u62fc\u63a5:  (B,C,N,T/4).concat(B,C,N,T/8) == (B,C,N,3T/8)\n        d3 = self.up_block3(d3) # \u5c06\u62fc\u63a5\u540e\u7684\u65f6\u95f4\u7ef4\u5ea6\u91cd\u65b0\u6620\u5c04\u5230\u5f53\u524d\u5c42\u672c\u8be5\u5177\u6709\u7684\u65f6\u95f4\u7ef4\u5ea6: (B,C,N,3T/8) --&gt; (B,C,N,T/4)\n\n        # \u7b2c\u4e09\u5c42\u5411\u7b2c\u4e8c\u5c42\u878d\u5408\n        d2 = torch.cat((e2, d3), dim=-1)  # \u5c06e2\u7279\u5f81\u56fe\u4e0ed3\u7279\u5f81\u56fe\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u62fc\u63a5: (B,C,N,T/2).concat(B,C,N,T/4) == (B,C,N,3T/4)\n        d2 = self.up_block2(d2)  # \u5c06\u62fc\u63a5\u540e\u7684\u65f6\u95f4\u7ef4\u5ea6\u91cd\u65b0\u6620\u5c04\u5230\u5f53\u524d\u5c42\u672c\u8be5\u5177\u6709\u7684\u65f6\u95f4\u7ef4\u5ea6:(B,C,N,3T/4)--&gt; (B,C,N,T/2)\n\n        # \u7b2c\u4e8c\u5c42\u5411\u7b2c\u4e00\u5c42\u878d\u5408\n        d1 = torch.cat((e1, d2), dim=-1)  # \u5c06e1\u7279\u5f81\u56fe\u4e0ed1\u7279\u5f81\u56fe\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u62fc\u63a5: (B,C,N,T).concat(B,C,N,T/2) == (B,C,N,3T/2)\n        out = self.up_block1(d1) # \u5c06\u62fc\u63a5\u540e\u7684\u65f6\u95f4\u7ef4\u5ea6\u91cd\u65b0\u6620\u5c04\u5230\u5f53\u524d\u5c42\u672c\u8be5\u5177\u6709\u7684\u65f6\u95f4\u7ef4\u5ea6:(B,C,N,3T/2)--&gt; (B,C,N,T)\n\n        out = self.linear_out(out.permute(1,2,0)) # \u5c06\u7b2c\u4e00\u5c42\u878d\u5408\u540e\u7684\u8868\u793a\u901a\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\u751f\u6210\u8f93\u51fa: (B,C 0 ,N 1,T 2 )--permute-&gt; (B,N 1,T 2,C 0)--linear-&gt;(B,N,T,C)\n\n        return out\n\nif __name__ == '__main__':\n    # (B,N,T,C)  T:\u5e8f\u5217\u7684\u957f\u5ea6,N:\u5e8f\u5217\u7684\u4e2a\u6570;  \u66f4\u6539\u8f93\u5165\u8bb0\u5f97\u628a104\u884c\u7684\u901a\u9053,\u8f93\u5165\u8f93\u51fa\u957f\u5ea6\u76f8\u5e94\u7684\u6539\u53d8; \u8f93\u5165\u7684\u5e8f\u5217\u957f\u5ea6\u8981\u88ab\u7b2c45\u884c\u7684\u4e0b\u91c7\u6837\u6bd4\u4f8b\u6574\u9664\u624d\u884c\u3002\n    X = torch.randn( 16, 720, 321)\n    Model = Model(input_channels=64,out_channels=64, seq_len=40, pred_len=40)\n    out = Model(X) # (B,N,T,C)--&gt;(B,N,T,C)\n    print(out.shape)\n</code></pre>"},{"location":"logs/diary/","title":"\u66f4\u65e9\u4ee5\u524d","text":""},{"location":"logs/diary/#_1","title":"\u66f4\u65e9\u4ee5\u524d","text":"2024-11-17 16:27:102025-09-28 12:54:06 <p> \u7ea6 3426 \u4e2a\u5b57  294 \u884c\u4ee3\u7801  11 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 21 \u5206\u949f</p> <p>\u4e50\u89c2 &amp; \u575a\u5f3a</p>"},{"location":"logs/diary/#2025-3-29","title":"2025-3-29","text":"<p>\u8c01\u61c2\u554a\uff0c\u8fd9\u4e00\u901a\u6298\u817e\uff0c\u754c\u9762\u6e05\u723d\u7684\u597d\u50cf\u4e0d\u662f\u6211\u7684\u4e00\u6837</p> <p>\u5ba1\u7f8e\u662f\u4e2a\u597d\u4e1c\u897f\u3002</p> <p>\u6709\u65f6\u5019\u5728\u5927\u4fee\u7684\u8fc7\u7a0b\u4e2d\uff0c\u672c\u6765\u60f3\u5c0f\u4fee\u7684\u5185\u5bb9\u53ef\u4ee5\u4e00\u5e76\u66f4\u6539\u3002</p> <p>\u80fd\u7528\uff0c\u5c31\u522b\u6539\u3002</p>"},{"location":"logs/diary/#2025-3-38","title":"2025-3-38","text":"<p>p\u4eba\u4e0d\u652f\u6301\u4e2d\u89c4\u4e2d\u77e9\uff0c\u770b\u4e86\u4e00\u4e9b mkdocs \u7684\u4f18\u79c0\u8bbe\u8ba1\uff0c\u5ffd\u7136\u89c9\u5f97\u8fd8\u80fd\u518d\u6298\u817e\u6298\u817e\u6211\u7684\u9875\u9762\u3002</p> <p><code>blog</code>\u529f\u80fd\u7684\u903b\u8f91\u5b9e\u5728\u634b\u4e0d\u901a\uff0c\u4e0d\u662f\u6211\u4e60\u60ef\u7684\u65b9\u5f0f\u3002<code>\u6362\u4e86changelog</code>\u7684\u63d2\u4ef6\uff0c\u8212\u9002\u591a\u4e86\u3002</p> <ul> <li> mkdocs \u7684\u5bfb\u5740\u903b\u8f91\u548c vscode \u7684\u627e\u5730\u5740\u903b\u8f91\uff0c\u4e0d\u4e00\u6837\uff0c\u73b0\u5728\u5c31\u662f vscode \u6216\u8005\u672c\u5730\u80fd\u627e\u5230\u7684\u5730\u5740\u5230\u4e86 mkdocs \u6216\u8005\u90e8\u7f72\u5230\u8fdc\u7a0b\u5c31\u627e\u4e0d\u5230\u4e86\u3002</li> </ul> YAML<pre><code># \uff08\u4fee\u6539\u524d\uff09\nsite_url: https://mydomain.org/mysite\n# \uff08\u4fee\u6539\u540e\uff09\nsite_url: https://mydomain.org\n</code></pre> <p>mkdocs \u7684\u597d\u5904\u5c31\u662f\u53ef\u4ee5\u76f4\u63a5\u6252\u522b\u4eba\u7684\u6e90\u7801\uff0c\u81ea\u5df1\u5165\u95e8\u6216\u8005\u8bbe\u8ba1\u8d77\u6765\u4f1a\u65b9\u4fbf\u3002</p>"},{"location":"logs/diary/#2025-3-27","title":"2025\u5e74 3 \u6708 27 \u65e5","text":"<p>\u7ec8\u4e8e\u5f00\u59cb\u7814\u7a76\u5f52\u6863\u529f\u80fd\u4e86\uff0c\u771f\u590d\u6742\u554a\u3002\u670d\u4e86\u3002\u770b\u89c1\u522b\u4eba\u5f04\u5f97\u597d\u770b\u7f51\u9875\uff0c\u592a\u559c\u6b22\u4e86\u3002\u5f97\u4ece\u7b80\u5355\u5230\u590d\u6742\uff0c\u6025\u4e0d\u6765\u3002</p> <ul> <li> (solved\uff1a<code>changelog</code>)\u5f52\u6863\uff0c\u903b\u8f91\u5173\u7cfb\u7406\u4e0d\u987a</li> <li> \u56fe\u5e8a\uff0c\u6e32\u67d3\u52a0\u5feb\u662f\u4e0d\u662f\u4e00\u5b9a\u9700\u8981\u56fe\u5e8a</li> </ul> <p>\u597d\u5947\uff0c\u65e0\u654c\u597d\u5947\uff0c\u662f\u600e\u4e48\u505a\u5230\u6e32\u67d3\u8fd9\u4e48\u5feb\u7684\uff0c7 \u79d2\u6e32\u67d3\u4e0d\u51fa\u6765\uff0c\u9ec4\u82b1\u83dc\u90fd\u51c9\u4e86\u3002\u4ee5\u540e\u518d\u770b\u5427\uff0c\u5e72\u6d3b\u3002\u662f\u592a\u597d\u770b\u4e86</p> <p>https://wcowin.work/about/geren/</p> <p>https://wcowin.work/Mkdocs-Wcowin/</p> <p>\u5ffd\u7136\u5728\u60f3\uff0c\u53ef\u4ee5 down \u4e0b\u6765\u6e90\u7801\u4e00\u70b9\u70b9\u5b66\u3002</p> <p>\u6ca1\u65f6\u95f4\u4e86\uff0c\u8fd9\u4e2a\u65f6\u95f4\u6233\u7f51\u9875\u6e32\u67d3\u662f\u771f\u6162\u554a</p> <p></p>"},{"location":"logs/diary/#2025-3-26","title":"2025 \u5e74 3 \u6708 26 \u65e5","text":"<p>\u4e00\u4e9b\u788e\u788e\u5ff5</p> <ul> <li>\u6a21\u957f-\u5e45\u89d2\u5f62\u5f0f</li> <li>\u5085\u91cc\u53f6\u7ea7\u6570\u7684\u4e09\u89d2\u51fd\u6570\u5f62\u5f0f\u3001\u8f85\u52a9\u89d2\u5f62\u5f0f\u3001\u590d\u6307\u6570\u5f62\u5f0f</li> </ul> <p>\u5085\u91cc\u53f6\u53d8\u6362\u5b66\u4e86\u51e0\u5929\uff0c\u4e0d\u8bb0\u5f97\u4e86\u3002\u4f46\u662f\u73b0\u5728\u770b\u660e\u767d\u7684\u4e1c\u897f\uff0c\u591f\u628a Autoformer \u4e2d\u7684\u5085\u91cc\u53f6\u53d8\u6362\u770b\u660e\u767d\u4e86\uff08\u5927\u6982\u3002\uff09</p> <p> </p> <p>\u4eca\u5929\u8fd8\u5b66\u4f1a\u4e86\u600e\u4e48\u628a jupyter notebook \u5d4c\u5165\u5230 mkdocs \u4e2d\u3002\u563f\u563f\uff0c\u6709\u70b9\u8fdb\u6b65\u55f7\u3002\u660e\u5929\u9700\u8981\u628a\u5085\u91cc\u53f6\u53d8\u6362\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53cc\u8fb9\u8c31\u3001\u5355\u8fb9\u8c31\u7684\u5bf9\u7167\uff0c\u4e0e\u4e0a\u9762\u90a3\u4e2a\u56fe\u4e2d python \u7a0b\u5e8f\u518d\u597d\u597d\u770b\u770b\u3002</p> <p>\u5f88\u6709\u5e2e\u52a9\u7684\u94fe\u63a5\uff0c\u8001\u5e08\u8bb2\u5f97\u5f88\u6210\u7cfb\u7edf\uff0c\u6bd4\u8f83\u9762\u5411\u5e94\u7528\uff1a\u6570\u5b57\u4fe1\u53f7\u5904\u7406 </p> <p></p>"},{"location":"logs/diary/#2025-3-25","title":"2025 \u5e74 3 \u6708 25 \u65e5","text":"<p>\u597d\u50cf\u4e00\u4e2a\u6361\u5783\u573e\u7684\uff0c\u8fd9\u6361\u70b9\u77e5\u8bc6\uff0c\u90a3\u513f\u6361\u70b9\u77e5\u8bc6\uff0c\u7136\u540e\u6574\u5408</p> <p>\u8d8a\u4eb2\u8fd1\u7684\u4eba\uff0c\u8d1f\u9762\u60c5\u7eea\u53cd\u800c\u66f4\u591a\uff0c\u8001\u8bdd\u8bf4\uff0c\u8ddd\u79bb\u4ea7\u751f\u7f8e</p> <p>\u8fd8\u662f\uff0c\u6211\u8fd8\u662f\u592a\u72ed\u9698\u4e86\u3002</p>"},{"location":"logs/diary/#2025-3-24","title":"2025 \u5e74 3 \u6708 24 \u65e5","text":"<p>\u5085\u91cc\u53f6\u7ea7\u6570\u4e03\u4e03\u516b\u516b\u4e86\u3002</p> <ul> <li> \u5085\u91cc\u53f6\u53d8\u6362</li> <li> DFT &amp; FFT</li> </ul>"},{"location":"logs/diary/#2025-3-22","title":"2025\u5e74 3 \u6708 22 \u65e5 \u5927\u9634\u5929","text":"<p>\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u8981\u4e0d\u4f60\u5e26\u6211\u8d70\u5427\uff0c\u4e5d\u654f\u4e86\uff0c\u4e00\u4e2a\u5934\u4e24\u4e2a\u5927\u3002</p> <p>\u4e00\u8d77\u5531\uff0c\u597d\u8fd0\u6765\uff0c\u6211\u4eec\u597d\u8fd0\u6765\ud83c\udfb5</p> <p>\u7ec8\u4e8e\uff0c\u5b8c\u6210\u4e86 Autoformer \u7684 Decoder \u90e8\u5206\uff0c\u7ec6\u8282\u633a\u591a\u7684</p> <p>\u4e24\u6b21\u6ce8\u610f\u529b+\u4e00\u6b21\u524d\u9988\u7f51</p> <p>DecoderLayer \u5185\u90e8\u6d41\u52a8\u7684\u662f\u5b63\u8282\u6210\u5206\uff0c\u8d8b\u52bf\u6210\u5206\u4fdd\u7559\uff0c\u7136\u540e\u76f8\u52a0\uff0c\u5e76\u4e14\u5728 DecoderLayer \u5185\u90e8\u5b8c\u6210\u7ef4\u5ea6\u8f6c\u6362\uff0c\u7528 kernel size=3\uff0c\u5bf9\u5e8f\u5217\u8fdb\u884c\u5e73\u6ed1\u3002</p> <p>\u800c\u5728\u6240\u6709\u7684 DecoderLayer \u6267\u884c\u5b8c\u4ee5\u540e\uff0c\u8fdb\u884c\u5b63\u8282\u6210\u5206\u7684\u7ef4\u5ea6\u8f6c\u5316\u8fd8\u539f\u4e3a\u539f\u59cb\u7ef4\u5ea6\uff0c\u7528\u7684\u662fnn.Linear\uff0c\u4fdd\u7559\u5c16\u9510\u90e8\u5206\u3002\u4f4e\u9891\u6210\u5206\u548c\u9ad8\u9891\u6210\u5206\u5728\u4e0d\u540c\u7684\u4f4d\u7f6e\u8fdb\u884c\u7ef4\u5ea6\u8fd8\u539f\uff0c\u56e0\u4e3a\u5b63\u8282\u6210\u5206\u9ad8\u9891\uff0c\u6240\u4ee5\u5728 Decoder \u7684\u8fc7\u7a0b\u4e2d\u5168\u90e8\u4fdd\u6301\u9ad8\u7ef4\u8868\u793a\uff0c\u4f46\u662f \u8d8b\u52bf\u6210\u5206\u5c31\u4e0d\u9700\u8981\u4e86</p> <p>\u6bcf\u6b21\u6ce8\u610f\u529b\uff0c\u524d\u9988\u7f51\u7684\u64cd\u4f5c\u4ee5\u540e\uff0c\u7d27\u8ddf\u7740\u5c31\u662f\u6b8b\u5dee\u8fde\u63a5\u3002</p> <p>Autoformer \u7684\u521b\u65b0\u5728\u4e8e\uff0c\u6bcf\u6b21\u6ce8\u610f\u529b\u548c\u524d\u9988\u7f51\u4e4b\u540e\uff0c\u90fd\u8fdb\u884c\u4e86\u5e8f\u5217\u5206\u89e3\uff0c\u5728 Encoder \u4e2d\u4e22\u5f03\u8d8b\u52bf\u5206\u91cf\uff0c\u5728 Decoder \u4e2d\u4fdd\u5b58\u8d8b\u52bf\u5206\u91cf\u9010\u5c42\u7d2f\u52a0\u3002</p> <p>\u8fd8\u6709\u5faa\u73af\u586b\u5145\u3002\u8fd8\u6709\u53cc\u5411\u8df3\u8f6c\u7684\u951a\u70b9\u8bbe\u7f6e\u3002</p> Markdown<pre><code>[](#\u8df3\u5230)&lt;a id=\"\u8fd4\u56de\"&gt;&lt;/a&gt;\n\n[](#\u8fd4\u56de)&lt;a id=\"\u8df3\u5230\"&gt;&lt;/a&gt;\n</code></pre> <ul> <li> <p> \u63a5\u4e0b\u6765\u5f00\u59cb\u770b\u6ce8\u610f\u529b\u673a\u5236\u662f\u600e\u4e48\u5b9e\u73b0\u7684\uff0c\u65b0\u5f00\u4e00\u4e2a\u6587\u6863\u3002</p> </li> <li> <p> \u5e76\u4e14\u628a\u6587\u6863\u5212\u5206\u5212\u5206\u6807\u9898\u628a\uff08\u7b11\uff09</p> </li> </ul> <p>\u6211\u77e5\u9053\u6211\u54ea\u91cc\u522b\u626d\u4e86\uff0c\u662f\u56e0\u4e3a\u6ca1\u6709\u66f4\u597d\u7684\u9009\u62e9\uff0c\u6240\u4ee5\u662f\u6211\u3002\u53ea\u662f\u4e00\u79cd\u6ca1\u6709\u5b89\u5168\u611f\u7684\u5173\u7cfb\u3002\u7b97\u4e86\uff0c\u7410\u788e\uff0c\u4e0d\u7ba1\uff0c\u9664\u4e86\u73b0\u5728\u7684\u81ea\u5df1\uff0c\u90fd\u662f\u865a\u65e0</p>"},{"location":"logs/diary/#2025-3-19","title":"2025\u5e74 3 \u6708 19 \u65e5","text":"<p>\u597d\u4e86\u597d\u4e86\uff0c\u5e72\u6d3b\u4e86\uff0c\u770b Autoformer</p> <ul> <li> mkdocs \u9875\u9762\u5d4c\u5165 pdf</li> <li> mkdocs &amp; mermaid</li> </ul> <p>mkdocs  yml \u914d\u7f6e\u6587\u4ef6\uff0c\u4eca\u5929\u4fee\u6539\u4e86\u914d\u7f6e\u6587\u4ef6\uff0c\u9875\u9762\u5d4c\u5165\u672c\u5730 pdf</p> <p>\u8fd9\u4e2a\u76f8\u5f53\u4e8e\u5907\u4efd\u3002</p> <p>\u8fd9\u91cc\u7684\u914d\u7f6e\u7f29\u8fdb\uff0c\u975e\u5e38\u5bb9\u6613\u62a5\u9519\uff0cAI \u81ea\u52a8\u7ed9\u9519\u8f93\u51fa\u7684\u5168\u6587\u672c\u5185\u5bb9\u4f1a\u6709\u5220\u51cf\uff0c\u7ec6\u5fc3\u70b9\u5427\u3002</p> Old mkdocs.yml <p> </p>YAML<pre><code>site_name: My Docs\nsite_name: \u6eb6err\nsite_url: https://mydomain.org/mysite\n# edit_uri: edit/main/docs/\n# - \u5efa\u7ad9\uff1a241114 \n\nedit_uri: https://github.com/dearRongerr/Rongerr.github.io/edit/main/docs\nnav:\n# \u4e3a\u4e86\u5c06\u9875\u9762\u94fe\u63a5\u5230\u67d0\u4e2a\u90e8\u5206\uff0c\n# \u8bf7\u5728\u76f8\u5e94\u7684\u6587\u4ef6\u5939\u4e2d\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a index.md \u7684\u65b0\u6587\u6863\uff0c\n# \u5e76\u5c06\u5176\u6dfb\u52a0\u5230\u5bfc\u822a\u90e8\u5206\u7684\u5f00\u5934\n  - \u4fbf\u7b7e:   \n    - sticks/mkdocs_learn.md\n    - sticks/markdwon_learn.md\n    - sticks/latex.md\n    - sticks/GitHub.md\n    - sticks/MacOS.md\n    - sticks/shell.md\n    - sticks/linux.md\n    - sticks/screen.md\n    - sticks/docker.md  \n    - sticks/writting.md\n    - sticks/1_github_v1.md\n    - sticks/2_python.md\n    - sticks/3_vscode.md\n  - \u9762\u8bd5:\n    - \u9898\u76ee:\n      - bagu/questions/1_questions.md\n    - \u529b\u6263:\n      - bagu/leetcode/index.md\n      - bagu/leetcode/1.md\n      - bagu/leetcode/2.md\n    - \u6df1\u5ea6\u5b66\u4e60: \n      - bagu/deeplearning/index.md\n      - bagu/deeplearning/transformer.md\n      - bagu/deeplearning/former1.md\n      - bagu/deeplearning/former2.md \n      - bagu/deeplearning/pytorch_shape_function.md\n      - bagu/deeplearning/1.md\n    - \u673a\u5668\u5b66\u4e60: \n      - bagu/machinelearning/kmeans.md\n      - bagu/machinelearning/2.md\n  - \u6349\u4e2a\u866b:\n    - Error/github.md\n    - Error/latex.md \n    - Error/python.md \n    - Error/macos.md\n    - Error/docker.md      \n  - \u7b14\u8bb0:\n    - learning/3_ViT.md\n    - learning/1_clip.md\n    - learning/2_MOCO.md\n    - learning/2.md\n    - learning/1.md\n    - learning/vit.md\n    - learning/swintransformer.md\n    - learning/pe.md\n    - learning/convs.md\n    - learning/3.md\n    - learning/4_GAN.md\n    - learning/5_Bert.md\n    - learning/6_Diffusion.md\n    - learning/6_Diffusion1.md\n    - learning/7_Clip.md\n    - learning/8_WeightNorm.md\n    - learning/9_cGAN.md \n    - learning/10_ResNet.md\n    - learning/11_excelcsvtensor.md \n    - learning/12_KLdivergence.md\n    - learning/13_RNN.md\n    - learning/14_LSTM.md\n    - learning/15_ContrastiveLearning.md\n    - learning/16_YOLO.md\n    - learning/17_DETR.md\n    - learning/18_DINO.md\n    - learning/19_GPT.md  \n    - learning/20_distill.md\n    - learning/21_FastRCNN.md\n    - learning/22_DilatedConv.md    \n  - \u6587\u732e:\n    - literature/index.md\n    - \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b: \n      - literature/TSP/index.md\n      - literature/TSP/0_note.md\n      - literature/TSP/1_SegRNN.md  \n      - literature/TSP/2_DLinear.md\n      - literature/TSP/3_TimesNet.md\n      - literature/TSP/4_Informer.md\n      - literature/TSP/5_Autoformer.md\n    - \u76ee\u6807\u8ba1\u6570:\n        - literature/ObejectCounting/index.md\n        - literature/ObejectCounting/rank1 CountGD.md\n        - literature/ObejectCounting/rank2 GeCo.md\n        - literature/ObejectCounting/rank3 DAVE.md\n        - literature/ObejectCounting/rank4 CACViT.md\n        - literature/ObejectCounting/rank5 SSD.md\n        - literature/ObejectCounting/rank6 LOCA.md\n        - literature/ObejectCounting/rank7 SemAug_CountTR.md\n        - literature/ObejectCounting/rank8 CounTR.md\n        - literature/ObejectCounting/rank9 SemAug_SAFECount.md\n        - literature/ObejectCounting/rank10 SPDCN.md\n        - literature/ObejectCounting/rank11 GCA_SUN.md\n        - literature/ObejectCounting/rank12 SAFECount.md\n        - literature/ObejectCounting/rank13 BMNet.md\n        - literature/ObejectCounting/rank14 LaoNet.md\n        - literature/ObejectCounting/rank15 CounTX.md\n        - literature/ObejectCounting/rank16 Counting_DETR.md\n        - literature/ObejectCounting/rank17 RCC.md\n        - literature/ObejectCounting/rank18 Omnicount.md\n        - literature/ObejectCounting/rank19 FamNet.md\n    - \u590d\u73b0&amp;\u4ee3\u7801: \n      - literature/Reproduction/index.md\n      - literature/Reproduction/DAVE.md     \n      - literature/Reproduction/1.md\n      - literature/Reproduction/2.md\n      - literature/Reproduction/3.md\n      - literature/Reproduction/4.md\n      - literature/Reproduction/5_SegRNN_index.md\n      - literature/Reproduction/5_SegRNN_v1.md\n      - literature/Reproduction/5_SegRNN_v2.md\n      - literature/Reproduction/6_AutoFormer.md\n    - \u76ee\u6807\u68c0\u6d4b:\n      - literature/ObjectDetection/2.md\n      - literature/ObjectDetection/index.md\n      - literature/ObjectDetection/1.md\n      - literature/ObjectDetection/3.md\n      - literature/ObjectDetection/4.md\n\n    - \u591a\u6a21\u6001:\n      - literature/MultiModal/index.md\n      - literature/MultiModal/1.md\n  - \u6742:\n    - logs/index.md     \n    - logs/diary.md      \n\ntheme:\n  name: material\n  features:\n    - toc.follow\n    # \u7ed9\u6bcf\u4e2a Tab \u6dfb\u52a0\u4e00\u4e2a index.md\uff0c\u4e14\u5728\u70b9\u51fb Tab \u65f6\u6253\u5f00\n    # https://squidfunk.github.io/mkdocs-material/setup/setting-up-navigation/#section-index-pages-with-section-index-pages\n    # - navigation.indexes  \n    # \u8fd4\u56de\u9876\u90e8\u7684\u6309\u94ae\uff0c\u5728\u4e0a\u6ed1\u65f6\u51fa\u73b0\n    # https://squidfunk.github.io/mkdocs-material/setup/setting-up-navigation/#back-to-top-button\n    - navigation.top  \n    # \u641c\u7d22\u8f93\u5165\u4e00\u4e9b\u5b57\u6bcd\u65f6\u63a8\u8350\u8865\u5168\u6574\u4e2a\u5355\u8bcd\n    # https://squidfunk.github.io/mkdocs-material/setup/setting-up-site-search/#search-suggestions\n    - search.suggest\n    # \u641c\u7d22\u7684\u5173\u952e\u8bcd\u6587\u7ae0\u52a0\u5165\u9ad8\u4eae\n    # https://squidfunk.github.io/mkdocs-material/setup/setting-up-site-search/#search-highlighting\n    - search.highlight\n    # \u53ef\u4ee5\u901a\u8fc7\u6309\u94ae\u590d\u5236\u4ee3\u7801\n    # https://squidfunk.github.io/mkdocs-material/reference/code-blocks/#code-copy-button\n    - content.code.copy\n    # [\u70b9\u51fb\u6309\u94ae\u8df3\u8f6c\u81f3 GitHub \u4fee\u6539 Markdown \u6e90\u6587\u4ef6]\n    # https://squidfunk.github.io/mkdocs-material/setup/adding-a-git-repository/#code-actions\n    # - content.action.edit # \u4e0d\u8981\uff0c\u6539\u4e86\u4f1a\u6709\u4e0d\u540c\u6b65\u7684\u95ee\u9898\n    # - navigation.footer # \u9875\u811a\u53ef\u4ee5\u5305\u542b\u6307\u5411\u5f53\u524d\u9875\u9762\u7684\u4e0a\u4e00\u9875\u548c\u4e0b\u4e00\u9875\u7684\u94fe\u63a5\n    - navigation.tabs  # \u8bbe\u7f6e\u5bfc\u822a\n    - navigation.tabs.sticky # \u7c98\u6027\u5bfc\u822a\n    - navigation.sections # \u4e0d\u77e5\u9053\u662f\u5565 \u52a0\u4e0a\u8bd5\u4e00\u4e0b  \n    # \u529f\u80fd\u6807\u5fd7 navigation.tabs \u548c navigation.sections \u53ef\u4ee5\u76f8\u4e92\u7ec4\u5408\u3002\n    # \u5982\u679c\u542f\u7528\u4e86\u4e24\u4e2a\u529f\u80fd\u6807\u5fd7\uff0c\u5219\u4f1a\u4e3a\u7ea7\u522b 2 \u5bfc\u822a\u9879\u5448\u73b0\u90e8\u5206\u3002\n    - navigation.expand  # \u4e0b\u62c9\u7684\u5bfc\u822a\u9ed8\u8ba4\u5c55\u5f00\n    - navigation.indexes # \u7d22\u5f15\u9875\n  palette: \n    # Palette toggle for light mode \u8bbe\u7f6e\u767d\u5929\u6a21\u5f0f\n    - scheme: default\n      primary: light blue  # \u8bbe\u7f6e\u6a2a\u5e45\u989c\u8272\n      accent: light blue  # \u8bbe\u7f6e\u9f20\u6807\u60ac\u505c\u989c\u8272\n      toggle:\n        icon: material/brightness-7 \n        name: Switch to dark mode\n\n    # Palette toggle for dark mode  \u8bbe\u7f6e\u591c\u95f4\u6a21\u5f0f\n    - scheme: slate\n      toggle:\n        icon: material/brightness-4\n        name: Switch to light mode\n# repo_url: https://github.com/squidfunk/mkdocs-material # \u6dfb\u52a0github\u4ed3\u5e93\uff0c\u8ddftheme\u662f\u540c\u4e00\u4e2a\u7ea7\u522b\n# repo_url: https://github.com/dearRongerr\n# repo_name: squidfunk/mkdocs-material # \u8bbe\u7f6e\u5b58\u50a8\u5e93\u7684\u540d\u79f0  \u5c31\u4f1a\u51fa\u73b0\u4e86 mkdocs-material\u8fd9\u4e2a\u4ed3\u5e93\uff0c\u5e76\u81ea\u52a8\u8bfb\u53d6\u4e00\u4e9b\u5f00\u6e90\u4ed3\u5e93\u7684\u57fa\u672c\u4fe1\u606f\n# repo_name: dearRongerr's github\n# copyright: dearRongerr | 24.11.14 \nmarkdown_extensions:\n  - pymdownx.pathconverter:\n    base_path: 'docs/pdf_files' # \u8bbe\u7f6e\u57fa\u7840\u8def\u5f84\u4e3a\u4f60\u7684 PDF \u6587\u4ef6\u6240\u5728\u76ee\u5f55\n    absolute: false # \u5c06\u8def\u5f84\u8f6c\u6362\u4e3a\u7edd\u5bf9\u8def\u5f84\n    tags: 'a script img link object embed' # \u9700\u8981\u8f6c\u6362\u8def\u5f84\u7684 HTML \u6807\u7b7e\n  - abbr\n  - pymdownx.tasklist:\n      custom_checkbox: true\n  - admonition\n  - attr_list\n  - def_list\n  - footnotes\n  - md_in_html\n  - toc:\n      permalink: true\n  - pymdownx.arithmatex:\n      generic: true\n  - pymdownx.betterem:\n      smart_enable: all\n  - pymdownx.caret\n  - pymdownx.details\n  # - pymdownx.emoji:\n  #     emoji_generator: !!python/name:material.extensions.emoji.to_svg\n  #     emoji_index: !!python/name:material.extensions.emoji.twemoji\n  - pymdownx.highlight:\n      anchor_linenums: true\n      line_spans: __span\n      pygments_lang_class: true\n  - pymdownx.inlinehilite\n  - pymdownx.keys\n  - pymdownx.caret\n  - pymdownx.mark\n  - pymdownx.tilde\n  # [\u6570\u5b66\u516c\u5f0f\u652f\u6301]\n  # https://squidfunk.github.io/mkdocs-material/reference/math/#katex\n  - pymdownx.arithmatex:\n      generic: true\n  # [\u56fe\u7247\u529f\u80fd\u652f\u6301]\n  # https://squidfunk.github.io/mkdocs-material/reference/images/\n  # \u7ed9 Markdown \u56fe\u7247\u8bed\u6cd5\u540e\u9762\u6dfb\u52a0 `{width=\"300\"}` \u8bbe\u7f6e\u5927\u5c0f\n  - attr_list\n  - md_in_html\n  # [\u7ed9\u6807\u9898\u6dfb\u52a0\u94fe\u63a5]\n  # https://squidfunk.github.io/mkdocs-material/setup/extensions/python-markdown/#+toc.permalink\n  - toc:\n      permalink: true # \u56fa\u5b9a\u6807\u9898\u4f4d\u7f6e\u4e3a\u5f53\u524d\u4f4d\u7f6e\n  # [\u4ee3\u7801\u8bed\u6cd5\u9ad8\u4eae]\n  # https://squidfunk.github.io/mkdocs-material/reference/code-blocks/#code-blocks\n  # https://squidfunk.github.io/mkdocs-material/setup/extensions/python-markdown-extensions/#highlight\n  - pymdownx.highlight:\n      # \u663e\u793a\u884c\u53f7\n      linenums: true\n      # # \u663e\u793a\u7f16\u7a0b\u8bed\u8a00\u540d\u79f0\n      # auto_title: true\n      # https://squidfunk.github.io/mkdocs-material/setup/extensions/python-markdown-extensions/#+pymdownx.highlight.line_spans\n      line_spans: __span\n      # https://squidfunk.github.io/mkdocs-material/setup/extensions/python-markdown-extensions/#+pymdownx.highlight.pygments_lang_class\n      pygments_lang_class: true\n  - pymdownx.inlinehilite\n  - pymdownx.snippets\n  - pymdownx.superfences\n  # [Markdown \u63d0\u793a]\n  # https://squidfunk.github.io/mkdocs-material/reference/admonitions/\n  - admonition\n  - pymdownx.details\n  # [Markdown footnote \u8bed\u6cd5\u652f\u6301]\n  # https://squidfunk.github.io/mkdocs-material/reference/footnotes/\n  - footnotes\n\nextra_javascript:\n  # [\u6570\u5b66\u516c\u5f0f\u652f\u6301]\n  # https://squidfunk.github.io/mkdocs-material/reference/math/#katex\n  - mkdocs/javascripts/katex.js\n  - https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js\n  - https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js\nextra_css:\n  # [\u6570\u5b66\u516c\u5f0f\u652f\u6301]\n  # https://squidfunk.github.io/mkdocs-material/reference/math/#katex\n  - https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css\n  # [\u81ea\u5b9a\u4e49 css]\n  # \u4e0d\u4f7f\u7528\u5e95\u90e8\u7684\u7ffb\u9875\n  - mkdocs/css/no-footer.css\n  # \u65e0\u5e8f\u5217\u8868\u7b26\u53f7\u81ea\u5b9a\u4e49\n  - mkdocs/css/unordered-list-symbols.css\n  # \u6807\u9898\u81ea\u52a8\u7f16\u53f7\nextra:\n  generator: false\n\nplugins:\n  - search\n  # \u663e\u793a\u521b\u5efa\u65e5\u671f\u3001\u4fee\u6539\u65e5\u671f\n  # https://squidfunk.github.io/mkdocs-material/setup/adding-a-git-repository/#code-actions\n  - git-revision-date-localized:\n      enable_creation_date: true\n      type: timeago #\u65f6\u95f4\u7c7b\u578b\n      # type: date #\u65e5\u671f\u7c7b\u578b\n      custom_format: \"%d. %B %Y\"  # \u65f6\u95f4\u683c\u5f0f\n      fallback_to_build_date: false #\u8bb8\u56de\u9000\u5230git \u4e0d\u53ef\u7528\u65f6mkdocs build\u6267\u884c\u7684\u65f6\u95f4\n      locale: zh #\u9996\u9009\u8bed\u8a00\n      # exclude:  #\u6392\u9664\u7684\u9875\u9762\n      #     - index.md\n      enabled: true #\u662f\u5426\u542f\u7528\n      # strict: true      \n</code></pre> <p></p>"},{"location":"logs/diary/#2025-3-14","title":"2025 \u5e74 3 \u6708 14 \u65e5","text":"<p>\u771f\u597d\u554a\uff0c\u771f\u597d\u554a\uff0cSegRNN \u7684\u4ee3\u7801\u770b\u5b8c\u4e86\uff0c\u4e0b\u9762\u8fd8\u6709\u4e00\u4e9b\u7ec6\u8282\u90e8\u5206\uff0c\u6a21\u578b\u7684\u635f\u5931\u4ec0\u4e48\u7684\uff0c\u4e3b\u4f53\u90e8\u5206\u90fd\u770b\u597d\u4e86\u3002\u4e0b\u9762\u4e00\u6b65\uff0c\u5c31\u662f\u5b8c\u5168\u8dd1\u5b8c\u8bba\u6587\uff0c\u770b\u770b\u5b9e\u9a8c\u7ed3\u679c\uff0c\u5305\u62ec\u6d88\u878d\u5b9e\u9a8c\u7684\u90e8\u5206\u3002\u987a\u7740\u5b9e\u9a8c\uff1a</p> <p></p> <p>\u628a\u8fd9\u8fb9\u7684\u51e0\u4e2a\u6a21\u578b\u90fd\u8dd1\u901a\uff0c\u603b\u800c\u8a00\u4e4b\uff0c\u5c31\u662f\u6536\u5c3e\u5de5\u4f5c\uff0c\u590d\u73b0\u8bba\u6587\u4e2d\u7684\u6240\u6709\u7ed3\u679c\u3002</p> <p>\u628a\u8fd9\u4e2a\u9879\u76ee\u5b8c\u5168\u770b\u597d\u4e86\uff0c\u540e\u9762\u4e5f\u90fd\u597d\u8bf4\uff0c\u56e0\u4e3a\u65f6\u95f4\u5e8f\u5217\u7684\u4ee3\u7801\u786e\u5b9e\u5f88\u591a\u4e00\u6837\u7684\u3002</p> <p>\u4eca\u5929\u5ffd\u7136\u610f\u8bc6\u5230\uff0c\u6ca1\u5fc5\u8981\u7279\u522b\u5173\u6ce8\u7c7b\u5728\u54ea\u4e2a\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\uff0c\u77e5\u9053\u8c03\u7528\u7684\u54ea\u4e2a\u7c7b\u548c\u7c7b\u5b9e\u73b0\u7684\u529f\u80fd\u66f4\u91cd\u8981\u3002</p> <p>\u65f6\u95f4\u5e8f\u5217\u4e2d\u6b8b\u5dee\u8fde\u63a5\u3002</p> <p>\u5b8c\u5168\u5f04\u660e\u767d\u4e00\u4e2a\u4ee3\u7801\u4e5f\u633a\u96be\u7684\uff0c\u8fd8\u6709\u5f88\u591a\u5c0f\u70b9\u4e0d\u660e\u767d\u3002</p>"},{"location":"logs/diary/#2025-3-13","title":"2025\u5e74 3 \u6708 13 \u65e5","text":"<p>\u6211\u60f3\u6211\u4f1a\u4e00\u76f4\u575a\u5f3a\uff0c\u5c31\u50cf\u6211\u7237\u7237\u4e00\u6837\u3002\u6211\u4f1a\u4e00\u76f4\u4e00\u76f4\u60f3\u5ff5\u8fd9\u4e2a\u5014\u5f3a\u4e0d\u670d\u8f93\u7684\u8001\u5934\u513f\u3002\u7238\u7238\u5988\u5988\u6559\u4f1a\u7684\u6211\u7684\u662f\u6148\u60b2\uff0c\u6c38\u8fdc\u6e29\u548c\u3002\u90a3\u4e48\u6211\u7237\u7237\u8eab\u4f53\u529b\u884c\u7684\u662f \u5014\u5f3a\u3002okay\uff0c\u52a0\u6cb9\u3002</p>"},{"location":"logs/diary/#2025-3-7","title":"2025 \u5e74 3 \u6708 7 \u65e5","text":"<p>(1) \u6539\u8fd9\u4e2a\u4ec0\u4e48\u6307\u7eb9\u7684\u9519\u8bef\u3002\u539f\u56e0\uff1a\u6ca1\u6709\u9000\u51fa debug \u76f4\u63a5\u65ad\u7f51\uff0c\u5c31\u4f1a\u62a5\u9519 <code>git remote -v</code>\uff0c\u5220\u4e86 github \u672c\u5730\u4ed3\u5e93</p> <p>\uff082\uff09git push \u5fd8\u4e86\u660e\u660e\u662f\u5565\u4e86 <code>git push -u origin main</code></p> <p>\u66f4\u65b0\uff1a</p> <p>\u8c01\u7684\u4ee3\u7801\u53c8\u62a5\u9519\u5566\uff1f\u8036\uff0c\u662f\u6211</p> <p></p> <p>\u66f4\u65b0\uff1a</p> <p>\u521a\u521a\u53c8\u56e0\u4e3a\u65ad\u7f51\uff0c\u5bfc\u81f4\u9519\u8bef\u4e86\u3002\u5c31\u662f\u8bf4\u8fd8\u662f\u6b63\u5e38\u7684\u5427\u65ad\u5f00\u8fde\u63a5\u548c\u9000\u51fa\u5427\uff0c\u5df2\u7ecf\u5403\u8fc7\u4e24\u6b21\u4e8f\u4e86\uff0c\u4e5f\u8bb8\u662f\u56e0\u4e3a\u8fd9\u6b21\u628a\u91cd\u5b9a\u5411\u5220\u9664\u4e86\uff0c\u6240\u4ee5\u6ca1\u6709\u62a5\u8fdb\u7a0b\u7684\u9519\u8bef\uff0c\u53ea\u662f\u62a5\u4e86\u7aef\u53e3\u88ab\u76d1\u542c\u7684\u9519\u8bef</p> Text Only<pre><code>| tee\n</code></pre> Text Only<pre><code>&gt;\n</code></pre> <p>\u7559\u5b58\u6b63\u786e\u7684 shell \u8c03\u7528 python \u811a\u672c\uff1a</p> Text Only<pre><code>model_name=SegRNN\n\nroot_path_name=./dataset/\ndata_path_name=national_illness.csv\nmodel_id_name=illness\ndata_name=custom\n\n\nseq_len=60\nfor pred_len in 24 36 48 60\ndo\n    python -m debugpy --listen 5998 --wait-for-client run_longExp.py \\\n      --is_training 1 \\\n      --root_path $root_path_name \\\n      --data_path $data_path_name \\\n      --model_id $model_id_name'_'$seq_len'_'$pred_len \\\n      --model $model_name \\\n      --data $data_name \\\n      --features M \\\n      --seq_len $seq_len \\\n      --pred_len $pred_len \\\n      --seg_len 12 \\\n      --enc_in 7 \\\n      --d_model 512 \\\n      --dropout 0 \\\n      --train_epochs 30 \\\n      --patience 10 \\\n      --rnn_type gru \\\n      --dec_way pmf \\\n      --channel_id 1 \\\n      --revin 1 \\\n      --itr 1 --batch_size 16 --learning_rate 0.001 | tee logs/LongForecasting/$model_name'_'$model_id_name'_'$seq_len'_'$pred_len.log\ndone\n</code></pre> <p>\u4ee5\u53ca launch.json\u7684\u914d\u7f6e\uff1a</p> Text Only<pre><code>{\n    // \u4f7f\u7528 IntelliSense \u4e86\u89e3\u76f8\u5173\u5c5e\u6027\u3002 \n    // \u60ac\u505c\u4ee5\u67e5\u770b\u73b0\u6709\u5c5e\u6027\u7684\u63cf\u8ff0\u3002\n    // \u6b32\u4e86\u89e3\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u8bbf\u95ee: https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"[\u8fd9\u91cc\u66f4\u6362\u4e3a\u4efb\u610f\u540d\u79f0]\",\n            \"type\": \"python\",\n            \"request\": \"attach\",\n            \"connect\": {\n                \"host\": \"localhost\",\n                \"port\": 5998\n            }\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (type in script name)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${command:AskForScriptName}\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (select script from list of sh files)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${command:SelectScriptName}\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (hardcoded script name)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${workspaceFolder}/path/to/script.sh\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (simplest configuration)\",\n            \"program\": \"${file}\"\n        }\n    ]\n}\n</code></pre> <p>\u4ee5\u53ca\u6700\u540e\u522b\u5fd8\u4e86\u6b63\u5e38\u6253\u65ad\u70b9</p>"},{"location":"logs/diary/#2025-3-6","title":"2025 \u5e74 3 \u6708 6 \u65e5","text":"<p>\u4eba\u9ebb\u4e86\uff0c\u8c22\u8c22\uff0c\u8c03\u4ee3\u7801\u90fd\u61c2\u5f97\u4e00\u5f20\u56fe\uff1a\u7a0b\u5e8f\u80fd\u8dd1\u5c31\u522b\u52a8\uff0c\u53ef\u60dc\u6211\u6253\u4e86\u90a3\u4e48\u591a\u8d85\u7ea7\u7528\u5fc3\u7684\u8bb0\u5f55\u70b9\uff0c\u4e0d\u8bf4\u4e86\uff0c\u91cd\u65b0\u8c03\u4ee3\u7801\u4e86\u3002\u7b97\u4e86\uff0c\u4e5f\u6709\u6536\u83b7\u7684</p> <p>\u770b\u660e\u767d\u7684\u5730\u65b9\u90fd\u53d8\u6210\u8bb0\u5f55\u70b9\uff0c\u6709\u6536\u83b7\u7684</p> <p>\u611f\u8c22\u81ea\u5df1\u662f\u4e2a\u8001\u5197\u4f59\u7684\u4eba\u4e86\uff0c\u5168\u90e8\u590d\u5236\u4fdd\u5b58\u4e86\u4e00\u4efd\uff0c\u8fd8\u6709\u6551\u3002\u4eca\u5929\u5b66\u4e60\u53c2\u6570 <code>--wait-for-client</code> \u548c <code>--itr 1 --batch_size 16 --learning_rate 0.001 | tee logs/LongForecasting/$model_name'_'$model_id_name'_'$seq_len'_'$pred_len.log</code></p> <p><code>| tee</code>\u53c2\u6570</p> <p>\u5d29\u6e83\u7684\u65f6\u5019\uff0c\u53ea\u6068\u81ea\u5df1\u6ca1\u641e\u4e2a\u7248\u672c\u5e93\u56de\u9000\u72b6\u6001\u4e86\u3002\u7b97\u4e86\uff0c\u4e0d\u4f1a\uff0c\u518d\u8bf4\u3002</p> <p>\u5e94\u8be5\u662f\u4e2d\u65ad\u518d\u52a0\u4e0a\u91cd\u5b9a\u5411\u7684\u95ee\u9898\u3002</p> Text Only<pre><code>model_name=SegRNN\n\nroot_path_name=./dataset/\ndata_path_name=national_illness.csv\nmodel_id_name=illness\ndata_name=custom\n\n\nseq_len=60\nfor pred_len in 24 36 48 60\ndo\n    python -m debugpy --listen 5998 --wait-for-client run_longExp.py \\\n      --is_training 1 \\\n      --root_path $root_path_name \\\n      --data_path $data_path_name \\\n      --model_id $model_id_name'_'$seq_len'_'$pred_len \\\n      --model $model_name \\\n      --data $data_name \\\n      --features M \\\n      --seq_len $seq_len \\\n      --pred_len $pred_len \\\n      --seg_len 12 \\\n      --enc_in 7 \\\n      --d_model 512 \\\n      --dropout 0 \\\n      --train_epochs 30 \\\n      --patience 10 \\\n      --rnn_type gru \\\n      --dec_way pmf \\\n      --channel_id 1 \\\n      --revin 1 \\\n      --itr 1 --batch_size 16 --learning_rate 0.001 | tee logs/LongForecasting/$model_name'_'$model_id_name'_'$seq_len'_'$pred_len.log\ndone\n</code></pre>"},{"location":"logs/diary/#2025-3-5","title":"2025\u5e74 3 \u6708 5 \u65e5","text":"<p>\u5927\u6982\u5c31\u662f\u5b58\u4e00\u4e9b\u6d3b\u7740\u7684\u75d5\u8ff9\uff1b\u6211\u80fd\u6bcf\u5929\u8bf4 100 \u53e5\u4e27\u6c14\u8bdd\uff0c\u7136\u540e\u7b2c\u4e8c\u5929\u4f9d\u65e7\u6d3b\u529b\u6ee1\u6ee1\u3002\u56e0\u4e3a\u662f\u81ea\u5df1\u7684\u9009\u62e9\uff0c\u4e3a\u81ea\u5df1\u7684\u9009\u62e9\u7edd\u5bf9\u7684\u8d1f\u8d23\u3002\u505a\u4e0d\u4e0b\u53bb\u6362\u5c31\u662f\u4e86\u3002Okay\uff0cDone\u3002</p>"},{"location":"logs/diary/#2025-3-1","title":"2025 \u5e74 3 \u6708 1 \u65e5","text":"<p>3 \u6708\uff0c\u52a0\u6cb9\u52a0\u6cb9</p> <p>\u65b0\u6280\u80fd\uff1avscode \u4e2d\uff0cshell \u8c03\u7528 python \u6587\u4ef6\uff0c\u600e\u4e48\u8c03\u8bd5\uff0c\u5c5e\u5b9e\u5de7\u5408\uff0c\u5fc3\u5e73\u6c14\u548c\u7684\u5206\u6790\uff0c\u95ee\u9898\u63d0\u51fa\u6765\u5c31\u662f\u80fd\u89e3\u51b3</p> <p>yepyep</p> <p></p>"},{"location":"logs/diary/#2025-2-28","title":"2025 \u5e74 2 \u6708 28 \u65e5","text":"<p>\u5bc4\u4e86\uff0c\u8dd1\u4e0d\u52a8\uff0c\u6362\u6362\u5427</p> <p>\u590d\u4e60\u590d\u4e60\uff0c\u547d\u4ee4\u603b\u4e5f\u4e0d\u7528 \u8be5\u5fd8\u4e86</p> <p></p>"},{"location":"logs/diary/#2025-2-27","title":"2025 \u5e74 2 \u6708 27 \u65e5","text":"<p>\u5173\u4e8e docker\u8111\u5b50\u91cc\u5927\u6982\u6709\u4e00\u6574\u5957\u6d41\u7a0b\u4e86</p> <p>\u6253\u7b97\u4f7f\u7528 docker \u5c01\u88c5\u4ee3\u7801\uff0c\u589e\u52a0\u53ef\u79fb\u690d\u6027\uff0c\u597d\u5fc3\u7684\u540c\u95e8\u613f\u610f\u5e2e\u6211\u8dd1\uff0c\u5177\u4f53\u5730\u505a\u6cd5\uff1a</p> <ul> <li>docker pull\u62c9\u53d6\u4e00\u4e2a\u5b98\u65b9\u7684\u955c\u50cf</li> <li>docker ps \u67e5\u770b\u955c\u50cf</li> <li>docker tag \u91cd\u547d\u540d\uff0c\u955c\u50cf\u540d:\u6807\u7b7e</li> <li>docker \u538b\u7f29\u6210 tar \u6587\u4ef6\uff0c\u547d\u4ee4\u5fd8\u4e86\uff0cdocker save </li> <li>\u4e0a\u4f20 tar \u6587\u4ef6\u5230\u670d\u52a1\u5668</li> <li>docker -i \u8def\u5f84 load \u52a0\u8f7d\u955c\u50cf</li> <li>docker ps\u67e5\u770b</li> <li>\u6709\u4e86\u7684\u8bdd\uff0cdocker run\uff0c\u542f\u52a8\u4e00\u4e2a\u5bb9\u5668\uff0c\u56e0\u4e3a\u6211\u4e3b\u8981\u60f3\u628a\u81ea\u5df1\u7684\u9879\u76ee\u6587\u4ef6\u5c01\u88c5\u5230\u5bb9\u5668\u4e2d\uff0c\u518d\u6253\u5305\u6210tar\u6587\u4ef6\u4e5f\u597d\uff0c\u518d\u5206\u4eab\u5230\u793e\u533a\u4e5f\u597d</li> <li>\u5927\u6982\u9700\u8981\u76ee\u5f55\u6302\u8f7d\uff0c\u628a\u672c\u5730\u7684\u6587\u4ef6\u6302\u8f7d\u5230\u5bb9\u5668\u5185\u7684\u67d0\u4e2a\u6587\u4ef6\uff0c\u800c\u4e0d\u662f\u5377\u6620\u5c04\uff0c\u56e0\u4e3a\u8981\u4ee5\u5916\u90e8\u7684\u6587\u4ef6\u4e3a\u51c6</li> <li>\u53ef\u80fd\u4f1a\u9047\u5230\u7684\u9519\u8bef\uff0c\u5e93\u4e0d\u591f\uff0c\u90a3\u5c31 pip \u5b89\u88c5\u3002</li> </ul>"},{"location":"logs/diary/#2025-2-26","title":"2025\u5e74 2 \u6708 26 \u65e5","text":"<p>\u6700\u8fd1\u8fd9\u51e0\u5929\u628a git \u7684\u76f8\u5173\u5185\u5bb9\uff0c\u6700\u7b80\u5355\u7684\u7cfb\u7edf\u7684\u8fc7\u4e86\u4e00\u904d\uff0c\u672c\u5730\u4ed3\u5e93\u548c\u8fdc\u7a0b\u4ed3\u5e93\u662f\u4e24\u4e2a\u6982\u5ff5\uff0c\u77e5\u8bc6\u7684\u7406\u89e3\u786e\u5b9e\u66f4\u52a0\u6df1\u523b\u4e86\uff0cgit remote -v\u67e5\u770b\u672c\u5730\u4ed3\u5e93\u8fde\u63a5\u7684\u8fdc\u7a0b\u4ed3\u5e93\u7684\u5730\u5740\u548c\u522b\u540d\uff0c\u672c\u5730\u4ed3\u5e93\u7684\u4fee\u6539\uff0cgit staus\u67e5\u770b\u672c\u5730\u4ed3\u5e93\u7684\u72b6\u6001\uff0c\u7136\u540e\u4e00\u5957\u7ec4\u5408\u62f3\uff0cgit add.\uff0cgit commit -m\"\u63d0\u4ea4\u4fe1\u606f\"\uff0cgit push \u63a8\u9001\u5230\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u7b2c\u4e00\u6b21\u5728\u547d\u4ee4\u884c\u6267\u884c\uff0c\u6ca1\u6709\u4ece vscode \u4e2d\u50bb\u74dc\u5f0f\u64cd\u4f5c\u4e86\ud83e\udee3\u4e5f\u8bb8\u8fd9\u4e2a\u4e16\u754c\u4e0d\u7f3a\u77e5\u9053\u7684\u4eba\uff0c\u7f3a\u638c\u63e1\u7684\u4eba\u3002okay\uff0c\u7ee7\u7eed\u5b66\u4e60</p> <p></p> <p></p> <p> </p> <p>\ud83d\udc95\ud83c\udf08\ud83d\udc3e \u4f46\u884c\u597d\u4e8b\uff0c\u4e0d\u95ee\u524d\u7a0b</p> <p>\ud83e\ude90\ud83d\udcab \u6361\u5783\u573e\u7684\u4eba\u4e0d\u4f1a\u5ac9\u5992\u5f00\u5b9d\u9a6c\u8f66\u7684\u4eba\uff0c\u4f46\u4f1a\u5ac9\u5992\u5783\u573e\u6bd4\u5b83\u6361\u5f97\u591a\u7684\u4eba</p> <p>\ud83c\udf3a\ud83d\udc0b\u2728 \u9762\u671d\u5927\u6d77\uff0c\u6625\u6696\u82b1\u5f00</p>"},{"location":"logs/diary/#241219","title":"241219","text":"<p>\uff08241219\uff09\u4e00\u6574\u4e2a\u5927\u6446\u70c2\uff0c\u4f60\u52aa\u529b\u5427\uff0c\u6211\u5f00\u5fc3\u5c31\u597d\u4e86\u3002\u751f\u547d\u4e4b\u6811\u5373\u5c06\u67af\u840e\uff0c\u7075\u9b42\u9a6c\u4e0a\u7a92\u606f\uff0c\u6211\u88c5\u4e0d\u53bb\u4e0b\u4e86</p> <ul> <li>241115 \u5c0f\u7ea2\u4e66\u4e0a\u53d1\u4e86\u4e2a\u8d34\uff0c\u7fa4\u8d77\u5632\u4e4b\uff1a\u522b\u9a82\u4e86\u522b\u9a82\u4e86\uff0c\u6211\u9519\u4e86</li> <li>241117 \u6765\u4e86</li> <li>241118 \u6765\u54af</li> <li> \u6587\u732e\u9605\u8bfb\u7b14\u8bb0</li> <li> \u597d\u6d88\u606f\uff1a\u6587\u7ae0\u65f6\u95f4\u6233\u6539\u5bf9\u4e86</li> <li>241119 \u5f00\u5de5\uff0c\u6162\u6162\u6765\u4e5f\u633a\u597d\u7684\uff0c\u662f\u7684</li> <li>241125 \u5e72\u6d3b</li> <li>241126 \u6765\u4e86</li> <li>241127 \u6765\u4e86</li> <li>241128 \u661f\u671f\u56db \u6765\u4e86 \u6674\u5929</li> <li>241129 \u661f\u671f\u4e94 \u6765\u4e86 \u9634\u5929</li> </ul> <p>\u2b50\ufe0f Week 1</p>"},{"location":"logs/diary/#2024121","title":"2024\u5e7412\u67081\u65e5 \u661f\u671f\u65e5 \u4f11","text":""},{"location":"logs/diary/#2024122","title":"2024\u5e7412\u67082\u65e5 \u661f\u671f\u4e00 \u6765\u4e86 \u6674\u5929","text":"<ul> <li> \u67e5\uff1a\u5f52\u4e00\u5316</li> <li> \u6539\uff1a\u5f52\u4e00\u5316\u3001\u6587\u732e\u9605\u8bfb COUNTGD\u3001COUNTR</li> <li> \u589e\uff1aGAN</li> </ul> <p>8h9min</p>"},{"location":"logs/diary/#2024123","title":"2024\u5e7412\u67083\u65e5 \u661f\u671f\u4e8c \u6765\u4e86 \u6674\u5929","text":"<ul> <li> \u6539\uff1aGAN</li> </ul> <p>6h34min</p>"},{"location":"logs/diary/#2024124","title":"2024\u5e7412\u67084\u65e5 \u661f\u671f\u4e09 \u6765\u4e86 \u6674\u5929","text":"<ul> <li> \u6539\uff1aGAN\uff08DONE\uff09</li> <li> \u6539\uff1aViT\uff08DONE\uff09</li> <li> \u589e\uff1aBert</li> <li> \u589e\uff1avision transformer\u4ee3\u7801\uff08DONE\uff09</li> <li> \u589e\uff1aclip</li> </ul> <p>10h45min</p>"},{"location":"logs/diary/#2024125","title":"2024\u5e7412\u67085\u65e5 \u661f\u671f\u56db \u6674\u5929 \u6765\u4e86","text":"<ul> <li> \u6539\uff1aWeightNorm</li> </ul> <p>2h21min</p> <p>2024\u5e7412\u67086\u65e5 \u661f\u671f\u4e94 \u6559\u8d44\u9762\u8bd5</p> <p>2024\u5e7412\u67087\u65e5 \u661f\u671f\u516d \u6559\u8d44\u9762\u8bd5</p>"},{"location":"logs/diary/#2024128","title":"2024\u5e7412\u67088\u65e5 \u661f\u671f\u65e5 \u9634\u5929 \u6765\u4e86","text":"<ul> <li> \u6539\uff1aWeightNorm</li> <li> \u589e\uff1aGAN\u7684\u53d8\u4f53\uff1a\u6700\u5c0f\u4e8c\u4e58GAN</li> </ul> <p>3h45min</p> <p>\u2b50Week2</p>"},{"location":"logs/diary/#2024129","title":"2024\u5e7412\u67089\u65e5 \u661f\u671f\u4e00 \u9634\u5929 \u6765\u4e86","text":"<ul> <li> \u6539\uff1aGAN\u53d8\u4f53\uff1acGAN\uff08DONE\uff09</li> <li> \u589e\uff1apytorch\u8bfb\u53d6csv\u3001excel\u6587\u4ef6\u8f6c\u6362\u6210tensor</li> <li> \u589e\uff1aResNet\u9879\u76ee\u5b9e\u6218</li> <li> \u6539\uff1aDiffusion models</li> </ul> <p>8h59min</p>"},{"location":"logs/diary/#20241210","title":"2024\u5e7412\u670810\u65e5 \u661f\u671f\u4e8c \u4e0b\u96ea \u6765\u4e86","text":"<ul> <li> \u67e5\uff1aGAN\u53d8\u4f53</li> <li> \u6539\uff1aDDPM</li> <li> \u589e\uff1aKL\u6563\u5ea6\uff08DONE\uff09</li> </ul> <p>6h44min</p>"},{"location":"logs/diary/#20241211","title":"2024\u5e7412\u670811\u65e5 \u661f\u671f\u4e09 \u9634\u5929 \u6765\u4e86 \u51b2\uff01","text":"<ul> <li> \u6539\uff1aDDPM\u63a8\u5bfc</li> </ul>"},{"location":"logs/diary/#20241212","title":"2024\u5e7412\u670812\u65e5 \u661f\u671f\u56db \u9634\u5929 \u6765\u4e86","text":"<ul> <li> \u589e\uff1alatex\u6349\u866b</li> </ul>"},{"location":"logs/diary/#20241213","title":"2024\u5e7412\u670813\u65e5 \u661f\u671f\u4e94 \u6674\u5929 \u6765\u4e86","text":"<ul> <li> \u6539\uff1alatex\u6349\u866b</li> </ul> <p>\u2b50Week3</p>"},{"location":"logs/diary/#20241219","title":"2024\u5e7412\u670819\u65e5 \u661f\u671f\u56db \u9634\u5929 \u6765\u4e86","text":"<ul> <li> \u6539\uff1a\u6269\u6563\u6a21\u578b\u63a8\u5bfc</li> </ul>"},{"location":"logs/diary/#20241220","title":"2024\u5e7412\u670820\u65e5 \u661f\u671f\u4e94 \u65e9\u4e0a\u597d","text":"<ul> <li> \u6539\uff1aVAE\u63a8\u5bfc</li> <li> \u589e\uff1aRNN</li> </ul>"},{"location":"logs/diary/#2024-12-21","title":"2024 \u5e74 12 \u6708 21 \u65e5 \u661f\u671f\u516d \u4e0a\u5348\u597d","text":"<ul> <li> \u589e\uff1a\u5c0f\u8bb2\u5802\uff08ViT\u3001CLIP\uff09\u3001YOLO\u3001DETR\u3001DINO\u3001\u5bf9\u6bd4\u5b66\u4e60\u3001GPT</li> <li> \u67e5\uff1aRNN\uff08DONE\uff09</li> </ul> <p>\u8fd1\u671f\u9ed8\u5ff5\uff1a\u300c\u6c38\u8fdc\u6446\u8131\u53d7\u5bb3\u8005\u53d9\u4e8b\u300d</p> <p>\u505c\u6b62\u5411\u4e16\u754c\u63cf\u8ff0\u6211\u7684\u76d1\u72f1</p> <p>\u66f4\u91cd\u8981\u7684\u662f\uff1a\u505c\u6b62\u5411\u81ea\u5df1\u63cf\u8ff0</p> <p>\u66f4\u91cd\u8981\u7684\u662f\uff1a\u73b0\u5728\u4ece\u76d1\u72f1\u91cc\u7ad9\u8d77\u8eab\uff0c\u8d70\u51fa\u53bb</p> <p>\u56e0\u4e3a\u76d1\u72f1\u6ca1\u6709\u4e0a\u9501\uff0c\u4e5f\u6ca1\u6709\u95e8</p> <p>\u6700\u540e\uff0c\u6839\u672c\u6ca1\u6709\u76d1\u72f1</p> <p>\u6c38\u8fdc\u4e0d\u8981\u8bd5\u56fe\u5c06\u81ea\u5df1\u6253\u9020\u6210\u4e00\u4e2a\u53d7\u5bb3\u8005\u6765\u83b7\u5f97\u522b\u4eba\u7684\u7406\u89e3\u548c\u7231\uff0c\u4e0d\u8981\u89c9\u5f97\u4e16\u754c\u5bf9\u4f60\u4e0d\u516c\uff0c\u4e0d\u8981\u89c9\u5f97\u8c01\u5bf9\u4e0d\u8d77\u4f60</p> <p>\u628a\u81ea\u5df1\u5f53\u6210\u53d7\u5bb3\u8005\uff0c\u5c31\u6c38\u8fdc\u8981\u627e\u51f6\u624b\uff1b</p> <p>\u628a\u81ea\u5df1\u5f53\u6210\u524d\u8fdb\u8005\uff0c\u5c31\u6c38\u8fdc\u5728\u627e\u52a9\u624b</p>"},{"location":"logs/diary/#2024-12-22","title":"2024 \u5e74 12 \u6708 22 \u65e5 \u661f\u671f\u65e5  \u4e0a\u5348\u597d \u6674\u5929","text":"<ul> <li> \u67e5\uff1aLSTM</li> <li> \u6539\uff1aMOCO</li> </ul> <p>\u2b50Week4</p>"},{"location":"logs/diary/#2024-12-23","title":"2024 \u5e74 12 \u6708 23 \u65e5 \u661f\u671f\u4e00  \u4e2d\u5348\u597d \u9634\u5929","text":"<ul> <li> \u67e5\uff1aLSTM</li> </ul>"},{"location":"logs/diary/#2025-1-21-2216","title":"2025 \u5e74 1 \u6708 21 \u65e5 \u661f\u671f\u4e8c 22:16","text":"<p>\u6b64\u65f6\u6b64\u523b\u6211\u7ec8\u4e8e\u662f\u56de\u5230\u4e86\u5bb6\uff0c\u82e5\u662f\u6390\u6307\u4e00\u7b97\uff0c\u4e5f\u662f\u8fc7\u53bb\u4e00\u4e2a\u6708\u4e86\u3002</p>"},{"location":"logs/diary/#2025-2-20-2100","title":"2025 \u5e74 2 \u6708 20 \u65e5 \u661f\u671f\u56db 21.00","text":"<p>\u4eca\u5929\u5fc3\u60c5\u4e0d\u9519\uff0c\u6211\u8fd9\u4e2a\u7535\u8111\u7684\u5feb\u6377\u952e\u8bbe\u8ba1\u7684\u592a\u8212\u670d\u4e86</p> <p>option+1 typora</p> <p>option2 edge \u6d4f\u89c8\u5668</p> <p>option3 vscode</p> <p>option5 \u7f51\u6613\u4e91</p> <p>option7 safari</p> <p>command7 google</p> <p>option9 wps</p> <p>^1 \u684c\u9762</p> <p>\u684c\u9762 1 ssh vscode</p> <p>\u684c\u9762 2 vscode \u4ee3\u7801\u5b66\u4e60</p> <p>option `\u622a\u56fe\uff0coptionT \u8d34\u56fe</p> <p>...\u5f88\u987a\u6ed1</p> <p>\u4eca\u5929\u5728\u8dd1\u4ee3\u7801</p> <p></p> <p>option0 \u8bbe\u7f6e</p> <p>command0 \u8bbf\u8fbe</p>"},{"location":"logs/1_0_diary/","title":"\ud83e\udee8 \u65e5\u8bb0","text":""},{"location":"logs/1_0_diary/#_1","title":"\ud83e\udee8 \u65e5\u8bb0","text":"2025-03-29 12:25:012025-09-28 12:54:06 <p> \u7ea6 57 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u6982\u8981</p> <p>\u65e5\u8bb0\u3001\u788e\u788e\u5ff5</p> <p>\u6709\u4e9b\u4eba\u5750\u7740\uff0c\u5176\u5b9e\u8111\u5b50\u91cc\u5404\u79cd\u60f3\u6cd5\u4e00\u76f4\u7ffb\u817e\u5435\u67b6\ud83d\ude02</p> <p>\u770b\u56fe\u6807\uff0c\u6296\u4e00\u6296 \ud83e\udee8 \uff0c\u8111\u5b50\u91cc\u5c31\u6e05\u6e05\u723d\u723d</p> <p>\u6765\u8fd9\u91cc\u770b\u4e00\u4e2a\u4e0d\u77e5\u540d\u7684\u8dcc\u8dcc\u649e\u649e \ud83e\udd23</p>"},{"location":"logs/1_0_diary/2025/03/","title":"3 \u6708","text":""},{"location":"logs/1_0_diary/2025/03/#3","title":"3 \u6708","text":"2025-03-29 17:45:372025-09-28 12:54:06 <p> \u7ea6 993 \u4e2a\u5b57  20 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 5 \u5206\u949f</p>"},{"location":"logs/1_0_diary/2025/03/#2025-03-29-saturday","title":"2025-03-29 Saturday","text":"<ul> <li>2025 \u5e74 \u7b2c 13 \u5468\uff0c\u786e\u5b9e\u4e00\u76f4\u60f3\u5199\u4e2a\u53ef\u4ee5\u5b58\u6863\u7684 blog \u8fd9\u4e2a\u903b\u8f91\u592a\u4e0d\u8212\u670d\u4e86\uff0c\u4e0d\u5f04\u4e86\u3002</li> <li>\u4ee5\u524d\u89c9\u5f97 markdown + mkdocs \u5c31\u591f\u4e86  \u8fd9\u4e24\u5929\u4e00\u76f4\u6e32\u67d3\u7f51\u9875\uff0c\u5ffd\u7136\u89c9\u5f97\u8fd8\u662f\u5f97\u4e00\u70b9 html\uff0c\u8c01\u80fd\u60f3\u5230\u51e0\u5e74\u524d\u81ea\u5df1\u5b66\u4e86\u534a\u540a\u5b50\u7684 html \u5c45\u7136\u8fd8\u80fd\u7528\u5230\ud83d\ude02\u3002\u8fd9\u6837\u7f51\u9875\u5b9a\u5236\u5316\u66f4\u9ad8\uff0c\u52a0\u4e0a\u4e00\u4e9b css \u548c javasript \u786e\u5b9e\u597d\u770b\ud83d\ude06\u3002</li> <li>\u4e3a\u5565\u6211\u7684\u5168\u7ad9\u81ea\u52a8\u5728\u65b0\u6807\u7b7e\u9875\u6253\u5f00\uff0c\u6ca1\u6548\u679c  <code>pip install mkdocs-open-in-new-tab</code></li> <li>\u56fe\u7247\u7684\u547c\u5438\u611f\u592a\u8212\u9002\u4e86\uff0c \u884c\u4e86\uff0c\u5f00\u59cb\u56fe\u5e8a\uff0c\u6682\u65f6\u4e0d\u6298\u817e\u5916\u89c2\u4e86\u3002</li> <li>\u7f51\u7ad9\u4f18\u5316\uff0caction\uff01</li> <li>\u7cfb\u7edf\u65f6\u95f4\u7c98\u8d34\u5de5\u5177 get\uff01</li> <li>\u5982\u65e0\u5fc5\u8981\uff0c\u52ff\u589e\u5b9e\u4f53</li> <li>\u5176\u5b9e\u4eca\u5929\u5bf9 git pages\u6709\u4e86\u66f4\u8fdb\u4e00\u6b65\u7684\u7406\u89e3\uff0c\u5b83\u662f\u901a\u8fc7\u5168\u7403\u5185\u5bb9\u5206\u53d1\u7cfb\u7edf\uff1f\u8fdb\u884c\u5185\u5bb9\u5206\u53d1\u7684\uff0c\u6240\u4ee5\u54cd\u5e94\u901f\u5ea6\u8fd8\u53ef\u4ee5\uff0c\u4f46\u6211\u7684\u95ee\u9898\u662f\u56fe\u7247\u592a\u591a\u4e86\u3002</li> </ul> <ul> <li>\u5177\u4f53\u7684\u89e3\u51b3\u65b9\u6cd5\u4e5f\u53ef\u4ee5\u5f00\u59cb\u6709\u4e86\u70b9\u8f6e\u5ed3\uff1a</li> </ul> <ul> <li>\u2460\uff08\u5df2\u4fee\u6539\uff09png \u56fe\u7247\u683c\u5f0f\u53d8\u6210 webp</li> <li>\u2461\u61d2\u52a0\u8f7d\uff08\u6709 js\uff0c\u4e5f\u53ef\u4ee5\u5728 markdown \u4e2d\u76f4\u63a5\u8fdb\u884c\u8bbe\u7f6e\uff09</li> <li>\u2462\u6258\u7ba1\uff0cTypora \u53ef\u4ee5\u76f4\u63a5\u8fdb\u884c\u6258\u7ba1\u8f6c\u6362 url\uff08\u5f97\u82b1\u94b1\uff0c\u5148\u6682\u65f6\u518d\u8bf4\uff0c\u56e0\u4e3a\u6211\u662f\u81ea\u5df1\u7ed9\u81ea\u5df1\u770b\u7684\u66f4\u591a\u4e00\u4e9b  \u89e3\u51b3\u65b9\u6cd5\uff1a<code>Typora+PicGo+\u963f\u91cc\u4e91OSS</code> \uff0cPicGo\u5df2\u4e0b\u8f7d\u3002\uff09</li> </ul> <ul> <li>\u6240\u4ee5\u8fd9\u91cc\u5c31\u540e\u9762\u518d\u8bf4\u3002</li> </ul>"},{"location":"logs/1_0_diary/2025/03/#2025-03-30-sunday","title":"2025-03-30 Sunday","text":"<ul> <li>08:49:50 \u8fd8\u662f\u5f97\u9759\u6001\u7f51\u9875\u6258\u7ba1\u3001\u56fe\u5e8a</li> </ul> Text Only<pre><code>++ctrl+alt+del+shift+command++\n</code></pre> <p>Ctrl+Alt+Del+Shift+Cmd</p> <p>\u5feb\u6377\u952e </p> Alt+Cmd  + T \u63d2\u5165\u8868\u683c Shift+Ctrl  +D \u63d2\u5165\u5f53\u524d\u65e5\u671f 2025-03-30 Sunday Shift+Ctrl  +T \u63d2\u5165\u5f53\u524d\u65f6\u95f4 09:23:04 <p>\u200b     </p> <p>\u5173\u4e8e\u5982\u4f55\u5728 mac \u4e0a\u8fdb\u884c\u63d2\u5165\u65e5\u671f\u548c\u65f6\u95f4\u7684\u505a\u6cd5</p> <ul> <li> <p>\u805a\u7126\u641c\u7d22\uff1a\u8f93\u5165\u81ea\u52a8\u64cd\u4f5c</p> </li> <li> <p>\u6253\u5f00\u81ea\u52a8\u641c\u7d22\uff0c\u9009\u62e9 \u5feb\u901f\u64cd\u4f5c\uff0c\u9009\u62e9\u5b9e\u7528\u5de5\u5177\uff0c\u53cc\u51fb\u9009\u62e9 shell \u811a\u672c</p> </li> <li> <p>\u8f93\u5165 <code>date +\"%Y-%m-%d %H:%M:%S %A\"</code></p> </li> <li> <p>shell \u811a\u672c\u4e2d\uff0c\u9700\u8981\u989d\u5916\u6ce8\u610f\u7684\u8bbe\u7f6e\u662f\uff0c\u8f93\u5165\u90e8\u5206\u9009\u62e9 <code>\u65e0\u8f93\u5165</code> \uff0c\u8f93\u51fa\u9009\u62e9<code>\u66ff\u6362\u6587\u672c</code> \uff0c\u70b9\u51fb\u8fd0\u884c\uff0c\u7a0b\u5e8f\u8fd0\u884c\uff0c\u70b9\u51fb\u7ed3\u679c\uff0c\u67e5\u770b\u7ed3\u679c</p> </li> <li> <p>\u4fdd\u5b58\u5feb\u901f\u64cd\u4f5c\u540d\u79f0 <code>\u65e5\u671f\u5feb\u6377\u952e</code></p> </li> <li> <p>\u6253\u5f00\u7cfb\u7edf\u8bbe\u7f6e\uff0c\u952e\u76d8\uff0c\u5feb\u6377\u952e\uff0c\u670d\u52a1\uff0c\u6587\u672c\uff0c\u9009\u62e9\u627e\u5230 <code>\u65e5\u671f\u5feb\u6377\u952e</code>\uff0c\u6ca1\u6709\u53ef\u4ee5\u7a0d\u7b49\u4e00\u4e0b\uff0c\u5f55\u5165\u5feb\u6377\u952e\u5373\u53ef\u3002</p> </li> </ul> <p>\u66f4\u65b0 mkdocs \u7684\u4f7f\u7528</p> <p>\uff081\uff09\u4ee3\u7801\u5757\u884c\u5185\u9ad8\u4eae</p> Text Only<pre><code>``` py hl_lines=\"2 3\" title=\"bubble_sort.py\"\ndef bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n```\n</code></pre> <p>\u6548\u679c\uff1a</p> bubble_sort.py<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre> <p>(2) \u65e0\u5e8f\u5217\u8868</p> Text Only<pre><code>- Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur\n  accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh\n  lacinia sed. Aenean in finibus diam.\n\n    * Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis.\n    * Nam vulputate tincidunt fringilla.\n    * Nullam dignissim ultrices urna non auctor.\n</code></pre> <ul> <li> <p>Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur   accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh   lacinia sed. Aenean in finibus diam.</p> <ul> <li>Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis.</li> <li>Nam vulputate tincidunt fringilla.</li> <li>Nullam dignissim ultrices urna non auctor.</li> </ul> </li> </ul> <p>\u4efb\u52a1\u5217\u8868</p> Text Only<pre><code>- [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit\n- [ ] Vestibulum convallis sit amet nisi a tincidunt\n    * [x] In hac habitasse platea dictumst\n    * [x] In scelerisque nibh non dolor mollis congue sed et metus\n    * [ ] Praesent sed risus massa\n- [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque\n</code></pre> <ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Vestibulum convallis sit amet nisi a tincidunt<ul> <li> In hac habitasse platea dictumst</li> <li> In scelerisque nibh non dolor mollis congue sed et metus</li> <li> Praesent sed risus massa</li> </ul> </li> <li> Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque</li> </ul> <p>\uff083\uff09\u5173\u4e8e \u6298\u53e0\u6846\u7684\u4f7f\u7528</p> <p>Typora \u81ea\u5e26\u7684 </p> <p>Tip</p> <p>Caution</p> <p>Note</p> <p>\u200b    </p> <p>Important</p> <p>Html </p> \u6298\u53e0\u6458\u8981 <p>     \u597d\u591a\u5185\u5bb9     \u597d\u591a\u5185\u5bb9     \u597d\u591a\u5185\u5bb9     \u597d\u591a\u5185\u5bb9     \u597d\u591a\u5185\u5bb9 </p> <ul> <li> <p>11:50:52 \u56fe\u5e8a\uff0c\u8981\u4e0d\u7136\u4f53\u9a8c\u611f\u592a\u5dee\u4e86\u3002</p> </li> <li> <p> 14:33:07 \u56fe\u5e8aget</p> </li> </ul> <ul> <li>\u53c2\u8003\u94fe\u63a5\uff1aTypora+Github+PicGO</li> <li>\u6b65\u9aa4\uff1a</li> <li>Github \u4e0a\u65b0\u5efa\u4e00\u4e2a\u4ed3\u5e93\uff0c\u547d\u540d\u4e3a\u4e0e\u56fe\u7247\u6709\u5173\u7684\uff0c\u6bd4\u5982 PicGO</li> <li>\u5efa\u597d\u4ed3\u5e93\u4ee5\u540e\uff0c\u751f\u6210\u4e2a\u4eba token\uff0c\u9009\u62e9 classic\uff0c\u4e24\u6b21\u90fd\u9009\u62e9 classic\uff0c\u7ee7\u7eed\u8bbe\u7f6e\u4e00\u4e2a\u4e0e\u56fe\u7247\u6709\u5173\u7684\u540d\u79f0\uff0c\u4e0b\u9762\u590d\u9009\u6846\uff0c\u52fe\u9009\u6240\u6709\u4e0e repo \u6709\u5173\u7684\u5185\u5bb9\uff0c\u63a5\u7740\u751f\u6210 token\uff0c\u590d\u5236\u5e76\u4fdd\u5b58\u597d\uff0c\u540e\u9762\u5c31\u770b\u4e0d\u5230\u4e86</li> <li>\u56de\u5230 PicGo\u914d\u7f6e\uff0cmac \u7528\u6237\u7ec8\u7aef\u8f93\u5165 <code>uname -m</code> \u67e5\u770b\u82af\u7247\uff0c\u6211\u7684 arm86\uff0c\u6240\u4ee5\u9009\u62e9 arm86 \u7248\u672c\uff0cPicGo \u914d\u7f6e\u65f6\u95f4\u6233\u91cd\u547d\u540d\uff0c\u56fe\u5e8a\u8bbe\u7f6e\u9009\u62e9 Github\uff0c\u63a5\u7740\u8f93\u5165\u4ed3\u5e93\u540d\uff0cmain \u5206\u652f\uff0c\u7ed1\u5b9a\u5feb\u6377\u952e ++ctrl/command+shift++ ++P++</li> <li>\u56de\u5230 typora \u914d\u7f6e\uff0c\u56fe\u5e8a\u914d\u7f6e\uff0c\u9009\u62e9 PicGo\uff0c\u5b9e\u73b0\u5728 typora \u4e2d\u7c98\u8d34\u56fe\u7247\u65f6\u81ea\u52a8\u751f\u6210\u56fe\u7247\u94fe\u63a5</li> </ul> <ul> <li>\u56fe\u5e8a\u95ee\u9898\uff0cgithub \u9700\u8981\u9b54\u6cd5\uff0c\u963f\u91cc\u4e91\u5b58\u50a8 40G \u4e5f\u4e0d\u5230 10 \u5757\u94b1</li> <li>png \u683c\u5f0f\u592a\u5927\u4e86\uff0c\u60f3\u5b89\u88c5 compress\u63d2\u4ef6\u548c\u8f6c\u683c\u5f0f\u63d2\u4ef6\uff0c\u63d2\u4ef6\u5e02\u573a\u6709\u95ee\u9898\u3002</li> </ul>"},{"location":"logs/1_0_diary/2025/04/","title":"4\u6708","text":""},{"location":"logs/1_0_diary/2025/04/#4","title":"4\u6708","text":"2025-03-29 17:45:372025-09-28 12:54:06 <p> \u7ea6 3944 \u4e2a\u5b57  179 \u884c\u4ee3\u7801  1 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 22 \u5206\u949f</p>"},{"location":"logs/1_0_diary/2025/04/#2025-04-20-sunday","title":"2025-04-20 Sunday","text":"<p>\u641c\u72d7\u4e2d\u6587\u8f93\u5165,\u82f1\u6587\u6807\u70b9,\u6ca1\u6709\u987f\u53f7.</p> <p>\u7b11,\u8fd9 mamba \u5c31\u975e\u7528\u4e0d\u53ef\u5417... \u73af\u5883\u597d\u96be\u88c5...</p> <p>docker\u4e0d\u7528,\u5168\u5fd8\u4e86</p> <p>\u55ef,\u670d\u52a1\u5668\u7684\u95ee\u9898,\u4e00\u5b9a\u662f\u7684,\u5df2\u7ecf\u8bd5\u8fc7\u5f88\u591a\u4e86</p> <p>\u8bf4\u5b9e\u8bdd,\u6211\u4e5f\u662f\u6e10\u6e10\u5730\u610f\u8bc6\u5230,\u6211\u4ee5\u524d\u5230\u5e95\u6709\u591a\u50bb....\u867d\u7136\u5f88\u65e9\u5c31\u77e5\u9053\u5982\u679c\u6211\u4e5f\u660e\u767d\u4e86\u6211\u5230\u5e95\u54ea\u91cc\u4e0d\u4e00\u6837\u4e86,\u6211\u5c31\u4e0d\u662f\u6211\u4e86,\u4f46\u65e2\u7136\u5230\u4e86\u8fd9\u4e2a\u9636\u6bb5\u90a3\u4e48\u53d1\u751f\u4ec0\u4e48\u4e5f\u662f\u81ea\u7136\u800c\u7136\u7684,</p> <p>\u6574\u6d3b,Hugo,\u5b9e\u5728\u53d7\u4e0d\u4e86\u4e86,\u592a\u6162\u4e86.</p> <p>Hugo:this</p> <p>\u4e00\u3001\u4f7f\u7528hugo\u521b\u5efa\u4e2a\u4eba\u7ad9\u70b9</p> <p>\u6709\u4e00\u5929\u8d85\u8fc7\u9650\u5236\u4e86\u5c31\u8d70\u54af~</p> <p>\u9700\u8981\u5b9e\u73b0\u5f04\u660e\u767d\u7684\u95ee\u9898:</p> <p>(1)gitpages 1GB \u7684\u9650\u5236</p> <p>(2)github+PicGO\u9650\u5236/\u56fe\u5e8a</p> <p>(3)\u56fe\u7247\u7684\u7ba1\u7406</p>"},{"location":"logs/1_0_diary/2025/04/#2025-04-19-saturday","title":"2025-04-19 Saturday","text":"<p>\u6211\u679c\u7136\u8fd8\u662f\u4e00\u4e2a\u4e0d\u559c\u6b22\u4efb\u4f55\u9ebb\u70e6\u7684\u4eba\uff0c\u5361\u7247\u53cb\u94fe \u597d\u96be\u63d2\u5165</p>"},{"location":"logs/1_0_diary/2025/04/#2025-04-18-friday","title":"2025-04-18 Friday","text":"<p>\u5165\u95e8\u8fd8\u662f\u592a\u91cd\u8981\u4e86\uff0c\u65f6\u5e8f\u7684\u4ee3\u7801\u5927\u5bb6\u597d\u9075\u5b88\u89c4\u8303\u3002</p>"},{"location":"logs/1_0_diary/2025/04/#2025-04-16-wednesday","title":"2025-04-16 Wednesday","text":"<p>\u6765\u8bfb\u4ee3\u7801\u4e86 \u4f60\u662f\u8fdc\u7a0b\u670d\u52a1\u5668\uff0c\u4f60\u4e3a\u4ec0\u4e48\u5361\u554a\uff1f\u554a\uff1f</p> Python<pre><code>self.original_block = block_model(channels, in_len, out_len, individual)\n</code></pre> <p>\u8fd9\u4e2a\u5904\u7406\u8fd8\u662f\u5f88\u5355\u7eaf\u7684\uff0c\u5982\u679c\u662f\u5c31\u662f\u5c06\u539f\u59cb 96 \u4e2a\u65f6\u95f4\u6b65\u6620\u5c04\u5230 96 \u7ef4\u7684\u7279\u5f81\u7a7a\u95f4\uff0c\u5982\u679c\u662f\u901a\u9053\u72ec\u7acb\u7684\uff0c\u5c31\u662f 7 \u4e2a\u72ec\u7acb\u7684\u7ebf\u6027\u5c42 <code>nn.Linear(96,96)</code>  \u5982\u679c\u4e0d\u662f\u901a\u9053\u72ec\u7acb\u7684\uff0c\u5c31\u662f\u5171\u4eab\u53c2\u6570\u7684\u7ebf\u6027\u5c42\u3002\u8fd9\u91cc\u662f\u57fa\u4e8e\u901a\u9053\u72ec\u7acb\u5047\u8bbe\u7684\u5efa\u6a21\u3002</p> Python<pre><code>self.decomposer = TrendCyclicDecomposition(kernel_size=trend_kernel)\n</code></pre> <p>\u505a\u5b8c\u539f\u59cb\u7684\u7279\u5f81\u7684\u975e\u7ebf\u6027\u53d8\u6362\u4ee5\u540e\uff0c\u8fdb\u884c\u8d8b\u52bf\u5206\u89e3\uff0c\u5c06\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u5206\u4e3a\u4f4e\u9891\u4fe1\u53f7\u548c\u9ad8\u9891\u4fe1\u53f7\uff1a</p> Python<pre><code>def __init__(self, kernel_size=25):\n    super(TrendCyclicDecomposition, self).__init__()\n    self.kernel_size = kernel_size\n    self.avg = nn.AvgPool1d(\n        kernel_size=kernel_size, \n        stride=1, \n        padding=(kernel_size-1)//2\n    )\n</code></pre> <p>\u8fd9\u91cc\u7684\u5904\u7406\u4e5f\u662f\u6bd4\u8f83\u5355\u7eaf\u7684\uff0c\u5c31\u662f\u901a\u8fc7\u4e00\u4e2a kernel size=25 \u7684\u5377\u79ef\u6838\u8fdb\u884c\u8d8b\u52bf\u5206\u89e3\u3002\u5c31\u4e0d\u628a\u6b8b\u5dee\u5206\u51fa\u6765\u4e86\uff0c\u56e0\u4e3a\u90a3\u662f\u7eaf\u968f\u673a\u90e8\u5206\uff0c\u5f88\u96be\u9884\u6d4b\u3002</p> <p>\u5f53\u4f60\u5fc3\u70e6\u610f\u4e71\u65f6\uff0c\u5c31\u9010\u884c\u7406\u4ee3\u7801\uff0c\u987a\u903b\u8f91\u3002</p> <p><code>x = self.revin_layer(x, 'norm')</code></p> <p>\u9996\u5148 \u53ef\u9006\u5b9e\u4f8b\u5f52\u4e00\u5316\uff0c\u4e00\u822c\u6765\u8bf4\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4f20\u8d77\u6765\u7684\u683c\u5f0f\u662f \u65f6\u95f4\u6b65\u4f18\u5148\uff0c\u4f46\u662f\u53c8\u4e00\u822c\u6765\u8bf4\uff0c\u6211\u4eec\u662f\u5bf9\u65f6\u95f4\u6b65\u8fdb\u884c\u64cd\u4f5c\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u628a\u6570\u636e\u683c\u5f0f\u6539\u6210\u901a\u9053\u4f18\u5148\u4e86</p> Python<pre><code>x1 = x.permute(0,2,1)\n</code></pre> <p>\u6240\u4ee5\u5c31\u662f\u8fd9\u6765\u7684 permute \u4e86\uff0c\u53d8\u6210 NCT \u6216\u8005 BDS\uff0c\u770b\u4e2a\u4eba\u4e60\u60ef\u5427</p> <p>N\uff1abatch\u3001C \u7279\u5f81\u6570\uff08\u8fd9\u4e2a\u8bb0\u53f7\u662f\u7c7b\u6bd4\u56fe\u7247\u7684\u901a\u9053 Channel\uff09\u3001T \u4e00\u4e2a\u65f6\u95f4\u6b65</p> <p>B\uff1abatchsize\u3001D \u4e00\u4e2a\u65f6\u95f4\u6b65\u7279\u5f81\u6570\u3001S \u8f93\u5165\u65f6\u95f4\u6b65 SequenceLength</p> <p>\u5176\u5b9e\u5173\u4e8e\u539f\u59cb TSFUnet\uff0c\u6ca1\u5565\u597d\u8bf4\u7684\uff0c\u786e\u5b9e\u5f88\u7b80\u5355\uff0c\u901a\u9053\u72ec\u7acb\u7684\u7b56\u7565\uff0c\u5982\u679c\u8bbe\u7f6e individual=1\uff0c\u5c31\u6709 C \u4e2a \u72ec\u7acb\u7684\u7ebf\u6027\u5c42\u5206\u522b\u8bad\u7ec3\uff0c\u53ef\u4ee5\u4fdd\u8bc1\u5404\u4e2a\u7279\u5f81\u4e4b\u95f4\u4e0d\u53d7\u5e72\u6270\uff0c\u5982\u679c\u4e0d\u662f individual \u7684\uff0c\u90a3\u4e48\u5c31\u5171\u4eab\u53c2\u6570\u7684 Linear \u5c42\u4e00\u8d77\u8bad\u7ec3\u3002\u7136\u540e\u5c31\u4e00\u4e2a\u4e0b\u91c7\u6837\uff0c\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\uff0c\u4e0b\u91c7\u6837\u7684\u90e8\u5206\u63a5\u7740\u4e0b\u91c7\u6837\uff0c\u7136\u540e\u7ee7\u7eed\u7ebf\u6027\u53d8\u6362\uff0c\u7ebf\u6027\u53d8\u6362\u7684\u90e8\u5206\u7b49\u7740\uff0c\u7b49\u7740\u4e0b\u91c7\u6837\u7ed3\u675f\u4e86\uff0c\u548c\u4f4e\u5206\u8fa8\u7387\u7684\u7ebf\u6027\u53d8\u6362 cat\uff0c\u518d\u7ecf\u8fc7\u4e00\u4e2a Linear \u5c42\uff0c\u5f97\u5230\u4f4e\u5c42\u7684\u7ebf\u6027\u53d8\u6362\u7ef4\u5ea6\uff0c\u5c31\u8fd9\u6837\uff0c\u76f4\u5230\u8fd8\u539f\u4e3a\u539f\u59cb\u7ef4\u5ea6\uff0c\u601d\u60f3\u7b80\u5355\u7684\u548c SegRNN \u4e00\u6837\uff0c\u6536\u655b\u4e5f\u5f88\u5feb\u3002\u590d\u6742\u7684\u771f\u4e0d\u4e00\u5b9a\u597d\u3002</p> Python<pre><code>        for down_block in self.down_blocks:\n            e_out.append(down_block(x1))\n            x1 = self.Maxpools[i](x1)\n            i = i+1\n</code></pre> <p>\u63a5\u4e0b\u6765\u5c31\u662f\u4e00\u4e2a downblocks</p> <p>\u4e00\u4e2a downblock \u7684\u6784\u6210\uff1a</p> Python<pre><code>EnhancedUNetBlock(\n  (original_block): block_model(\n    (Linear_channel): Linear(in_features=96, out_features=192, bias=True)\n    (ln): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n    (relu): ReLU(inplace=True)\n  )\n  (decomposer): TrendCyclicDecomposition(\n    (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(12,))\n  )\n  (freq_decomposer): FrequencyDecomposer(\n    (wavelet_decomposers): ModuleList(\n      (0): SimpleWaveletDecomposition(\n        (low_pass): Sequential(\n          (0): ReflectionPad1d((2, 1))\n          (1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n          (2): GELU()\n          (3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        )\n        (high_pass): Sequential(\n          (0): ReflectionPad1d((2, 1))\n          (1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n          (2): GELU()\n          (3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        )\n      )\n      (1): SimpleWaveletDecomposition(\n        (low_pass): Sequential(\n          (0): ReflectionPad1d((2, 1))\n          (1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n          (2): GELU()\n          (3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        )\n        (high_pass): Sequential(\n          (0): ReflectionPad1d((2, 1))\n          (1): Conv1d(7, 7, kernel_size=(4,), stride=(1,), groups=7)\n          (2): GELU()\n          (3): InstanceNorm1d(7, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        )\n      )\n    )\n  )\n  (freq_processors): ModuleList(\n    (0): block_model(\n      (Linear_channel): Linear(in_features=192, out_features=192, bias=True)\n      (ln): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      (relu): ReLU(inplace=True)\n    )\n    (1): block_model(\n      (Linear_channel): Linear(in_features=192, out_features=192, bias=True)\n      (ln): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): block_model(\n      (Linear_channel): Linear(in_features=192, out_features=192, bias=True)\n      (ln): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (freq_fusion): FrequencyFusion()\n  (low_freq_enhancer): LowFrequencyEnhancer(\n    (time_norm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n    (time_attention): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=7, out_features=7, bias=True)\n    )\n    (temporal_conv): Sequential(\n      (0): Conv1d(7, 7, kernel_size=(3,), stride=(1,), padding=(1,), groups=7)\n      (1): GELU()\n      (2): Conv1d(7, 7, kernel_size=(1,), stride=(1,))\n      (3): Dropout(p=0.1, inplace=False)\n    )\n    (kan_processor): M_KAN(\n      (channel_mixer): Sequential(\n        (0): ChebyKANLayer(\n          (fc1): ChebyKANLinear()\n        )\n      )\n      (conv): BasicConv(\n        (conv): Conv1d(7, 7, kernel_size=(3,), stride=(1,), padding=(1,), groups=7, bias=False)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n    )\n  )\n)\n</code></pre> <p>\u522b\u6015\uff0c\u770b\u770b init \u90e8\u5206\uff1a</p> Python<pre><code>        for in_len, out_len in zip(down_in, down_out):\n            self.down_blocks.append(\n                EnhancedUNetBlock(\n                    self.input_channels, \n                    in_len, \n                    out_len, \n                    self.individual,\n                    trend_kernel=min(25, in_len//4*2+1),  # \u786e\u4fdd\u5947\u6570\n                    n_freq_bands=3,\n                    use_wavelet=self.use_wavelet\n                )\n            )\n</code></pre> <p>\u597d\u4e86\uff0c\u5f00\u59cb\u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\u4e86</p> Python<pre><code>base_output = self.original_block(x)\n</code></pre> <p>\u8f93\u5165 96\uff0c\u8f93\u5165 192\uff0cC=7</p> Text Only<pre><code>\u6a21\u578b\u53c2\u6570\u6570\u91cf: 402249\n\u8f93\u5165\u5f62\u72b6: torch.Size([16, 96, 7])\n</code></pre> <p>\u89c1\u9762\u5c31\u662f\u4e00\u4e2a\u7ebf\u6027\u5c42\uff1a</p> Python<pre><code>block_model(\n  (Linear_channel): Linear(in_features=96, out_features=192, bias=True)\n  (ln): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n  (relu): ReLU(inplace=True)\n)\n</code></pre> <p>\u8fd9\u4e2a\u7ebf\u6027\u53d8\u6362\u662f \u539f\u59cb Sequence\u2192predict Length \u7684\uff08\u539f\u59cb Unet \u4e5f\u662f\u8fd9\u6837\u5904\u7406\u7684</p> Python<pre><code>self.individual\n</code></pre> <p>\u56e0\u4e3a\u8fd9\u91cc\u662f False\uff0c\u6240\u4ee5\u5c31\u662f\u5171\u4eab\u53c2\u6570\u7684\u7ebf\u6027\u5c42\u3002</p> <p>\u8c03\u8bd5\u7684\u65f6\u5019\uff0c\u9009\u62e9\u8c03\u7528 launch.json\u8c03\u8bd5\uff0c\u8fd9\u6837 <code>\"justMyCode\": true</code>, \u8bbe\u7f6e\u5c31\u4f1a\u751f\u6548\u4e86\uff0c\u6b65\u8fdb\u4e0d\u4f1a\u8fdb\u5165\u5185\u90e8\u51fd\u6570</p> <p>\u8d70\uff0c\u6211\u4eec\u53bb \u8fd9\u4e2a\u51fd\u6570\u5185\u90e8</p> Python<pre><code>base_output = self.original_block(x)\n</code></pre> <p>\u5b83\u7684 init\uff1a</p> Python<pre><code>self.original_block = block_model(channels, in_len, out_len, individual)\n</code></pre> <p>\u521d\u59cb\u5316\u9700\u8981\u7684\u53c2\u6570\uff1a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u7279\u5f81\u3001SequenceLength\u3001predictLength\u3001\u8fd8\u6709\u662f\u5426\u901a\u9053\u72ec\u7acb\uff0c\u8fdb\u53bb\u770b forward</p> Python<pre><code>def forward(self, x):\n    # x: [Batch, Input length, Channel]\n    if self.individual:\n        output = torch.zeros([x.size(0),x.size(1),self.out_len],dtype=x.dtype).to(x.device)\n        for i in range(self.channels):\n            output[:,i,:] = self.Linear_channel[i](x[:,i,:])\n    else:\n        output = self.Linear_channel(x)\n    #output = self.ln(output)\n    #output = self.relu(output)\n    return output # [Batch, Channel, Output length]\n</code></pre> <p>\u786e\u5b9e\u662f\u628a\uff0c\u5982\u679c\u662f individual=true\uff0c\u5c31\u4f1a\u5355\u72ec\u4e3a\u6bcf\u4e2a\u901a\u9053\u5efa\u7acb\u7ebf\u6027\u5c42\uff1b\u5982\u679c individual=False\uff0c\u5c31\u4f1a\u7528\u5171\u4eab\u7684\u7ebf\u6027\u5c42\uff08\u8fd9\u4e2a\u4f5c\u8005\u5e94\u8be5\u4e5f\u505a\u4e86\u633a\u591a\u5c1d\u8bd5\u7684\uff0c\u4ee3\u7801\u7248\u672c\u633a\u591a\u7684 hhh\uff0c\u4e5f\u633a\u4e0d\u5bb9\u6613\u7684\uff0c\u5bb3\uff0c\u54ea\u4e2a\u505a\u5b9e\u9a8c\u7684\u60c5\u7eea\u7a33\u5b9a\u5462</p> <p>\u8fd9\u91cc\u8fd8\u6709\u81ea\u5b9a\u4e49\u51fd\u6570\uff0c\u5f97\u6252</p> Python<pre><code>self.Linear_channel\n</code></pre>"},{"location":"logs/1_0_diary/2025/04/#2025-04-15-tuesday","title":"2025-04-15 Tuesday","text":"<p>TSB \u7ed9\u4e86 docker \u8fd0\u884c\uff0c\u4f46\u662f\u5fd8\u4e86 docker \u600e\u4e48\u7528\uff0c\uff08\u6211\u8fd9\u8be5\u6b7b\u7684\u8bb0\u6027\uff0c\u4e00\u70b9\u90fd\u4e0d\u8bb0\u5f97\u4e86\uff0c\u4e8f\u6211\u4e0a\u4e2a\u6708\u8fd8\u7814\u7a76\u4e86\u4e00\u4e2a\u661f\u671f\u3002</p> <ul> <li> <p>docker run</p> </li> <li> <p>docker build</p> </li> <li> <p>docker image</p> </li> </ul> <p>\u60f3\u8bbe\u8ba1\u5b9e\u9a8c\u4e86\uff0c\u8bba\u6587\u770b\u5f97\u4eba\u5934\u5927</p> <ul> <li> DLinear(\u4ee3\u7801\u8fd8\u6ca1\u770b) </li> </ul>"},{"location":"logs/1_0_diary/2025/04/#2025-04-14-monday","title":"2025-04-14 Monday","text":"<ul> <li> iTransformer </li> <li> WITRAN(\u592a\u6709\u529f\u529b\u4e86\uff0c\u516c\u5f0f)(\u4ee3\u7801\u6ca1\u770b\u5b8c)</li> <li> PatchTST</li> <li> TimesNet</li> </ul> <p>\u7075\u5149\u4e4d\u73b0\uff0c\u5173\u4e8e\u53ec\u56de\u7387\u4e3a\u4ec0\u4e48\u53ef\u4ee5\u662f 1 \u7684\u76f4\u89c2\u89e3\u91ca\uff0c\u5982\u679c 100 \u4e2a\u6837\u672c\uff0c99 \u4e2a\u6b63\u4f8b\uff0c1 \u4e2a\u8d1f\u4f8b\uff0c\u4f46\u662f\u9884\u6d4b\u7684\u65f6\u5019\u628a\u6240\u6709\u7684\u6837\u672c\u7684\u90fd\u9884\u6d4b\u4e3a\u6b63\u4f8b\uff0c\u6b63\u786e\u7387 99%\uff0c\u53ec\u56de\u7387=1\u3002\u7528\u4f8b\u5b50\u6e05\u6670\u660e\u4e86\u3002</p>"},{"location":"logs/1_0_diary/2025/04/#2025-04-02-wednesday","title":"2025-04-02 Wednesday","text":"<p>\u52a0\u6cb9\u3002</p> <p>\u88c2\u5f00\uff0c\u4e0d\u77e5\u9053\u5e72\u5565</p> <p>\u6211\u8be5\u600e\u4e48\u505a\uff0c\u4ece\u54ea\u513f\u5f00\u59cb\u3002</p> <p>\u9996\u5148\uff0c\u6211\u5df2\u7ecf\u5bf9 Electricity \u6570\u636e\u96c6\u8fdb\u884c\u4e86 \u805a\u7c7b\uff0c\u805a\u6210\u56db\u7c7b\uff0c\u6548\u679c\u6bd4\u8f83\u597d\uff0c\u540c\u65f6\u7528\u4e3b\u6210\u5206\u5206\u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u964d\u7ef4\u53ef\u89c6\u5316\u3002\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u4e5f\u8981\u6d4b\u8bd5\u539f\u8bba\u6587\u7684\u7ed3\u679c\uff0c\u6240\u4ee5\u6211\u5e94\u8be5\u590d\u73b0\u51fa\u8bba\u6587\u7684\u7ed3\u679c\u3002\u73b0\u5728 SegRNN \u7684\u4ee3\u7801\u770b\u660e\u767d\u4e86\uff0c\u6211\u5df2\u7ecf\u8dd1\u4e86\u5f88\u591a SegRNN \u7684\u4ee3\u7801\uff0c\u73b0\u5728\u770b\uff0c\u590d\u73b0\u51fa\u6765\u7684\u8bba\u6587\u7ed3\u679c\uff0c\u7136\u540e\u518d SegRNN \u7684\u57fa\u7840\u4e0a\u6539\u3002</p> <p>\u95ee\u9898 1\uff1aSegRNN \u7684\u4f5c\u8005\u90fd\u505a\u4e86\u54ea\u4e9b\u5b9e\u9a8c\uff1f\u7528\u4e86\u4ec0\u4e48\u6570\u636e\u96c6\uff1f\u7528\u4e86\u4ec0\u4e48\u5bf9\u6bd4\u6a21\u578b\uff1f</p> <p>table1\uff0c\u6570\u636e\u96c6\u6982\u8ff0\uff1a</p> <p>\u88682\uff1a\u672c\u6587\u505a\u7684\u6240\u6709\u5bf9\u6bd4\u5b9e\u9a8c\uff1a</p> <p> </p> <p>\u6211\u73b0\u5728\uff0c\u9700\u8981\u590d\u73b0\u539f\u8bba\u6587\u7684\u7ed3\u679c\u3002</p>"},{"location":"logs/1_0_diary/2025/04/#2025-04-04-friday","title":"2025-04-04 Friday","text":""},{"location":"logs/1_0_diary/2025/04/#_1","title":"\u6587\u732e\u9605\u8bfb","text":"<p>Long time series forecasting aims to utilize historical information to forecast future states over extended horizons. Traditional RNN-based series forecasting methods struggle to effectively address long-term dependencies and gradient issues in long time series problems. Recently, SegRNN has emerged as a leading RNN-based model tailored for long-term series forecasting, demonstrating state-of-the-art performance while maintaining a streamlined architecture through innovative segmentation and parallel decoding techniques. Nevertheless, SegRNN has several limitations: its fixed segmentation disrupts data continuity and fails to effectively leverage information across different segments, the segmentation strategy employed by SegRNN does not fundamentally address the issue of information loss within the recurrent structure. To address these issues, we propose the ISMRNN method with three key enhancements: we introduce an implicit segmentation structure to decompose the time series and map it to segmented hidden states, resulting in denser information exchange during the segmentation phase. Additionally, we incorporate residual structures in the encoding layer to mitigate information loss within the recurrent structure. To extract information more effectively, we further integrate the Mamba architecture to enhance time series information extraction. Experiments on several real-world long time series forecasting datasets demonstrate that our model surpasses the performance of current state-of-the-art models.</p> <p>\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65e8\u5728\u5229\u7528\u5386\u53f2\u4fe1\u606f\u6765\u9884\u6d4b\u672a\u6765\u5728\u8f83\u957f\u65f6\u95f4\u8303\u56f4\u5185\u7684\u72b6\u6001\u3002\u4f20\u7edf\u7684\u57fa\u4e8eRNN\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5728\u5904\u7406\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u95ee\u9898\u65f6\uff0c\u96be\u4ee5\u6709\u6548\u89e3\u51b3\u957f\u671f\u4f9d\u8d56\u6027\u548c\u68af\u5ea6\u95ee\u9898\u3002\u6700\u8fd1\uff0cSegRNN\u4f5c\u4e3a\u4e00\u79cd\u9488\u5bf9\u957f\u671f\u5e8f\u5217\u9884\u6d4b\u7684\u9886\u5148RNN\u6a21\u578b\u51fa\u73b0\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5206\u6bb5\u548c\u5e76\u884c\u89e3\u7801\u6280\u672f\uff0c\u4ee5\u7cbe\u7b80\u7684\u67b6\u6784\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u7136\u800c\uff0cSegRNN\u5b58\u5728\u51e0\u4e2a\u5c40\u9650\u6027\uff1a\u5176\u56fa\u5b9a\u7684\u5206\u6bb5\u65b9\u5f0f\u7834\u574f\u4e86\u6570\u636e\u7684\u8fde\u7eed\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u4e0d\u540c\u5206\u6bb5\u4e4b\u95f4\u7684\u4fe1\u606f\uff0cSegRNN\u91c7\u7528\u7684\u5206\u6bb5\u7b56\u7565\u4e5f\u672a\u80fd\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u5faa\u73af\u7ed3\u6784\u4e2d\u7684\u4fe1\u606f\u4e22\u5931\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86ISMRNN\u65b9\u6cd5\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u589e\u5f3a\u70b9\uff1a\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u9690\u5f0f\u5206\u6bb5\u7ed3\u6784\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u5e76\u6620\u5c04\u5230\u5206\u6bb5\u9690\u85cf\u72b6\u6001\uff0c\u5728\u5206\u6bb5\u9636\u6bb5\u5b9e\u73b0\u4e86\u66f4\u5bc6\u96c6\u7684\u4fe1\u606f\u4ea4\u6362\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5728\u7f16\u7801\u5c42\u4e2d\u5f15\u5165\u6b8b\u5dee\u7ed3\u6784\uff0c\u4ee5\u51cf\u8f7b\u5faa\u73af\u7ed3\u6784\u4e2d\u7684\u4fe1\u606f\u4e22\u5931\u3002\u4e3a\u4e86\u66f4\u6709\u6548\u5730\u63d0\u53d6\u4fe1\u606f\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u6574\u5408\u4e86Mamba\u67b6\u6784\u6765\u589e\u5f3a\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\u63d0\u53d6\u3002\u5728\u51e0\u4e2a\u771f\u5b9e\u4e16\u754c\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u6027\u80fd\u3002</p> <p>In this work, we propose a novel model named ISMRNN to address the issues associated with SegRNN. Specifically, ISMRNN introduces an implicit segmentation structure that decomposes and maps the time series into encoded vectors through two linear transformations. This method facilitates more continuous processing during segmentation and enhances the utilization of information between different segments. Additionally, ISMRNN incorporates a residual structure with a linear layer, allowing some information to bypass the recurrent encoding structure, thus reducing information loss within the recurrent framework. Furthermore, we employ the Mamba structure[Gu and Dao, 2023] for preprocessing the time series, which aids in capturing long-term dependencies more effectively. The main contributions of ISMRNN can be summarized as follows:  </p> <p>\u2022 Utilizing implicit segmentation for denser information exchange during the segmentation phase. </p> <p>\u2022 Incorporating the Mamba structure to improve information preprocessing.  </p> <p>\u2022 The residual structure reduces information loss within the recurrent structure.</p> <p>\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a ISMRNN \u7684\u65b0\u578b\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u4e0e SegRNN \u76f8\u5173\u7684\u95ee\u9898\u3002\u5177\u4f53\u6765\u8bf4\uff0cISMRNN \u5f15\u5165\u4e86\u4e00\u79cd\u9690\u5f0f\u5206\u6bb5\u7ed3\u6784\uff0c\u901a\u8fc7\u4e24\u6b21\u7ebf\u6027\u53d8\u6362\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u5e76\u6620\u5c04\u4e3a\u7f16\u7801\u5411\u91cf\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u5206\u6bb5\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u4e86\u66f4\u8fde\u7eed\u7684\u5904\u7406\uff0c\u5e76\u589e\u5f3a\u4e86\u4e0d\u540c\u5206\u6bb5\u4e4b\u95f4\u4fe1\u606f\u7684\u5229\u7528\u3002\u6b64\u5916\uff0cISMRNN \u5728\u7f16\u7801\u7ed3\u6784\u4e2d\u5f15\u5165\u4e86\u5e26\u6709\u7ebf\u6027\u5c42\u7684\u6b8b\u5dee\u7ed3\u6784\uff0c\u4f7f\u5f97\u90e8\u5206\u4fe1\u606f\u80fd\u591f\u7ed5\u8fc7\u5faa\u73af\u7f16\u7801\u7ed3\u6784\uff0c\u4ece\u800c\u51cf\u5c11\u5faa\u73af\u6846\u67b6\u5185\u7684\u4fe1\u606f\u4e22\u5931\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u91c7\u7528 Mamba \u7ed3\u6784 [Gu and Dao, 2023] \u5bf9\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u9884\u5904\u7406\uff0c\u8fd9\u6709\u52a9\u4e8e\u66f4\u6709\u6548\u5730\u6355\u6349\u957f\u671f\u4f9d\u8d56\u6027\u3002ISMRNN \u7684\u4e3b\u8981\u8d21\u732e\u53ef\u4ee5\u603b\u7ed3\u5982\u4e0b\uff1a - \u5229\u7528\u9690\u5f0f\u5206\u6bb5\uff0c\u5728\u5206\u6bb5\u9636\u6bb5\u5b9e\u73b0\u66f4\u5bc6\u96c6\u7684\u4fe1\u606f\u4ea4\u6362\u3002 - \u5f15\u5165 Mamba \u7ed3\u6784\u4ee5\u6539\u8fdb\u4fe1\u606f\u9884\u5904\u7406\u3002 - \u6b8b\u5dee\u7ed3\u6784\u51cf\u5c11\u4e86\u5faa\u73af\u7ed3\u6784\u5185\u7684\u4fe1\u606f\u4e22\u5931\u3002</p> <p>\u8f93\u5165\uff1a</p> <p>x.shape=torch.Size([16, 720, 321])  batchSize SequenceLength FeatureDim</p> <p>reshape </p> <p>x.reshape(-1, self.seg_num_x, self.seg_len) \u2192 [16\u00d7321=5136, 15,48]</p> <p>self.valueEmbedding </p> Python<pre><code># build model\nself.valueEmbedding = nn.Sequential(\n    nn.Linear(self.seg_len, self.d_model),\n    nn.ReLU()\n)\n\nSequential(\n  (0): Linear(in_features=48, out_features=512, bias=True)\n  (1): ReLU()\n)\n</code></pre> <p>\u2192 [5136, 15,512]</p>"},{"location":"logs/1_0_diary/2025/04/#2025-04-05-saturday","title":"2025-04-05 Saturday","text":"<p>time Unet forward \u63a5\u6536 x\uff0c\u8f93\u5165 x \u7684\u5f62\u72b6\u662f(32,720,7)\uff0c</p> <p><code>x = self.revin_layer(x, 'norm')</code> \u8fdb\u884c\u53ef\u9006\u5b9e\u4f8b\u5f52\u4e00\u5316 \uff0c\u5f62\u72b6\u4e0d\u53d8(32,720,7)</p> <p><code>x1 = x.permute(0,2,1)</code> \u63a5\u4e0b\u6765\u4ea4\u6362\u7ef4\u5ea6\uff0c\u5f62\u72b6\u7531(32,720,7)\u53d8\u4e3a(32,7,720)</p> Python<pre><code>i = 0\nfor down_block in self.down_blocks:\n    e_out.append(down_block(x1))\n    x1 = self.Maxpools[i](x1)\n    i = i+1\n</code></pre> <p>self.down_blocks </p> Text Only<pre><code>ModuleList(\n  (0): block_model(\n    (Linear_channel): ModuleList(\n      (0-6): 7 x Linear(in_features=720, out_features=720, bias=True)\n    )\n    (ln): LayerNorm((720,), eps=1e-05, elementwise_affine=True)\n    (relu): ReLU(inplace=True)\n  )\n  (1): block_model(\n    (Linear_channel): ModuleList(\n      (0-6): 7 x Linear(in_features=359, out_features=359, bias=True)\n    )\n    (ln): LayerNorm((359,), eps=1e-05, elementwise_affine=True)\n    (relu): ReLU(inplace=True)\n  )\n  (2): block_model(\n    (Linear_channel): ModuleList(\n      (0-6): 7 x Linear(in_features=179, out_features=179, bias=True)\n    )\n    (ln): LayerNorm((179,), eps=1e-05, elementwise_affine=True)\n    (relu): ReLU(inplace=True)\n  )\n  (3): block_model(\n    (Linear_channel): ModuleList(\n      (0-6): 7 x Linear(in_features=89, out_features=89, bias=True)\n    )\n    (ln): LayerNorm((89,), eps=1e-05, elementwise_affine=True)\n    (relu): ReLU(inplace=True)\n  )\n)\n</code></pre> <p>self.Maxpools </p> Python<pre><code>ModuleList(\n  (0-3): 4 x AvgPool1d(kernel_size=(3,), stride=(2,), padding=(0,))\n)\n</code></pre> <p>\u7b2c1\u6b21\u5faa\u73af </p> <p>\u8f93\u5165 x1 \u5f62\u72b6: [32, 7, 720]</p> <p><code>down_block(x1)</code> \u8f93\u51fa\u5f62\u72b6: [32, 7, 720]</p> <p><code>Maxpools[0](x1)</code> \u8f93\u51fa\u5f62\u72b6: [32, 7, 359]</p> <p>\u6c60\u5316\u53c2\u6570: kernel_size=3, stride=2, padding=0</p> <p>\u8ba1\u7b97: <code>(720 + 2*0 - 3)/2 + 1 = 359</code></p> <p>\u7b2c2\u6b21\u5faa\u73af</p> <p>\u8f93\u5165 x1 \u5f62\u72b6: [32, 7, 359]</p> <p>down_block(x1) \u8f93\u51fa\u5f62\u72b6: [32, 7, 359]</p> <p><code>Maxpools[1](x1)</code> \u8f93\u51fa\u5f62\u72b6: [32, 7, 179] \u8ba1\u7b97: <code>(359 + 2*0 - 3)/2 + 1 = 179</code></p> <p>\u7b2c3\u6b21\u5faa\u73af </p> <p>\u8f93\u5165 x1 \u5f62\u72b6: [32, 7, 179]</p> <p><code>down_block(x1)</code> \u8f93\u51fa\u5f62\u72b6: [32, 7, 179]</p> <p><code>Maxpools[2](x1)</code> \u8f93\u51fa\u5f62\u72b6: [32, 7, 89]</p> <p>\u8ba1\u7b97: <code>(179 + 2*0 - 3)/2 + 1 = 89</code></p> <p>\u7b2c4\u6b21\u5faa\u73af </p> <p>\u8f93\u5165 x1 \u5f62\u72b6: [32, 7, 89]</p> <p>down_block(x1) \u8f93\u51fa\u5f62\u72b6: [32, 7, 89] <code>Maxpools[3](x1)</code>\u8f93\u51fa\u5f62\u72b6: [32, 7, 44]</p> <p>\u8ba1\u7b97: (89 + 2*0 - 3)/2 + 1 = 44</p> <p>\u5faa\u73af\u7ed3\u675f\u540e\uff0c<code>e_out</code> \u5217\u8868\u5305\u542b<code>4</code>\u4e2a\u5f20\u91cf\uff0c\u5bf9\u5e94<code>4</code>\u4e2a\u5c3a\u5ea6\u7684\u7279\u5f81\uff1a</p> <p>e_out[0]: [32, 7, 720] (\u539f\u59cb\u5c3a\u5ea6)</p> <p>e_out[1]: [32, 7, 359] (\u7b2c\u4e00\u6b21\u4e0b\u91c7\u6837)</p> <p>e_out[2]: [32, 7, 179] (\u7b2c\u4e8c\u6b21\u4e0b\u91c7\u6837)</p> <p>e_out[3]: [32, 7, 89] (\u7b2c\u4e09\u6b21\u4e0b\u91c7\u6837)</p> <ul> <li>\u968f\u7740\u5c42\u6b21\u52a0\u6df1\uff0c\u65f6\u95f4\u7ef4\u5ea6\u9010\u6e10\u51cf\u5c0f\uff0c\u6bcf\u5c42\u6355\u83b7\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u7684\u7279\u5f81</li> <li><code>down_block</code> \u64cd\u4f5c\u4e0d\u6539\u53d8\u901a\u9053\u7ef4\u5ea6\u548c\u6279\u6b21\u7ef4\u5ea6\uff0c\u53ea\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u6620\u5c04</li> <li>\u6bcf\u6b21\u6c60\u5316\u64cd\u4f5c\u4f1a\u4f7f\u65f6\u95f4\u7ef4\u5ea6\u5927\u7ea6\u51cf\u534a (\u53d6\u51b3\u4e8e\u7cbe\u786e\u7684\u6c60\u5316\u53c2\u6570)</li> </ul> <p>(cv\u4e2d\uff0c\u901a\u8fc7\u5377\u79ef\u901a\u9053\u6570\u7ffb\u500d\uff0c\u5c3a\u5ea6\u4e0d\u53d8\uff1b\u6c60\u5316\u6210\u901a\u9053\u6570\u4e0d\u53d8\uff0c\u5c3a\u5ea6\u51cf\u534a)</p> <p><code>e_last = e_out[self.stage_num - 1]</code> \u5176\u4e2d <code>self.stage_num=4</code>\uff0c\u83b7\u53d6\u7b2c\u4e09\u6b21\u4e0b\u91c7\u6837\u5c42\u8f93\u51fa[32, 7, 89] \uff0c\u4e5f\u5c31\u662f <code>e_last.shape = [32, 7, 89]</code> </p> \u600e\u4e48\u4ece\u8bba\u6587\u4e2d\u6252\u6a21\u5757\uff1f <p>     \uff081\uff09\u627e\u5230\u539f\u8bba\u6587\uff0c\u63d0\u51fa\u7684\u6a21\u5757\uff0c\u7ed9\u51fa\u7684\u4ee3\u7801     \uff082\uff09\u51c6\u5907\u81ea\u5df1\u7684\u6d4b\u8bd5\u6587\u4ef6     \u5206\u6790\uff0c\u539f\u6a21\u5757\u7684 init\u3001forward \u5206\u522b\u9700\u8981\u4ec0\u4e48\u53c2\u6570\uff0c\u5f62\u72b6\u7684\u542b\u4e49     \u5206\u6790\uff0c\u81ea\u5df1\u4e3a\u4ec0\u4e48\u9700\u8981\u8fd9\u4e2a\u6a21\u5757\u3002\u81ea\u5df1\u7684\u6570\u636e\u662f\u4ec0\u4e48\u5f62\u72b6\u7684\uff0c\u5c06\u81ea\u5df1\u7684\u6570\u636e\u7ef4\u5ea6\u62ff\u51fa\u6765\uff0c\u5206\u6790\u548c\u539f\u6a21\u5757\u7684\u7ef4\u5ea6\u5bf9\u9f50\u3002\u6d4b\u8bd5\u5bf9\u8c61\u662f\u81ea\u5df1\u6240\u9700\u8981\u7684\u6570\u636e\u3002\u6d4b\u8bd5\u6210\u529f\u3002 </p> Python<pre><code>e_last = e_out[self.stage_num - 1]\nfor i in range(self.stage_num - 1):\n    e_last = torch.cat((e_out[self.stage_num - i - 2], e_last), dim=2)\n    e_last = self.up_blocks[i](e_last)\ne_last = e_last.permute(0,2,1)\ne_last = self.revin_layer(e_last, 'denorm')\nreturn e_last\n</code></pre> <p>\u521d\u59cb\u6761\u4ef6\uff1a</p> <ul> <li>stage_num = 4 (\u9ed8\u8ba4\u8bbe\u7f6e)</li> <li>e_out \u5305\u542b4\u4e2a\u4e0d\u540c\u5c3a\u5ea6\u7684\u7279\u5f81\u56fe:</li> <li>e_out[0]: [32, 7, 720]</li> <li>e_out[1]: [32, 7, 359]</li> <li>e_out[2]: [32, 7, 179]</li> <li>e_out[3]: [32, 7, 89]</li> </ul> <p>\u7b2c1\u6b21\u5faa\u73af (i=0) </p> <p>e_last \u521d\u59cb\u503c\u4e3a e_out[3]: [32, 7, 89]</p> <p><code>e_last = torch.cat((e_out[self.stage_num - i -2], e_last), dim=2)</code></p> <p>\u8ba1\u7b97 <code>self.stage_num - i - 2 = 4 - 0 - 2 = 2</code></p>  \u8bf4\u660e\uff1a\u62fc\u63a5 e_out[2] \u548c e_last: [32, 7, 179] \u548c [32, 7, 89]   <p> \u6765\uff0c\u8bfb\uff0c [32, 7, 179] \uff0c32 \u4e2a 7\uff0c7 \u4e2a 179\uff0c\u73b0\u5728\u62fc\u63a5\u6cbf\u7740 dim=2\uff0c\u73b0\u5728\u662f 32 \u4e2a 7\uff0c7 \u4e2a 179+89 </p> <p>\u6cbf dim=2 (\u65f6\u95f4\u7ef4\u5ea6) \u62fc\u63a5\uff0c\u5f97\u5230 [32, 7, 179+89] = [32, 7, 268]</p> <p>\u901a\u8fc7 up_blocks[0] \u6620\u5c04\uff0c\u8f93\u51fa\u5f62\u72b6\u53d8\u4e3a [32, 7, 179]</p> \u8bf4\u660e\uff1aself.up_blocks <p> </p>Python<pre><code>    ModuleList(\n      (0): block_model(\n        (Linear_channel): ModuleList(\n          (0-6): 7 x Linear(in_features=268, out_features=179, bias=True)\n        )\n        (ln): LayerNorm((179,), eps=1e-05, elementwise_affine=True)\n        (relu): ReLU(inplace=True)\n      )\n      (1): block_model(\n        (Linear_channel): ModuleList(\n          (0-6): 7 x Linear(in_features=538, out_features=359, bias=True)\n        )\n        (ln): LayerNorm((359,), eps=1e-05, elementwise_affine=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): block_model(\n        (Linear_channel): ModuleList(\n          (0-6): 7 x Linear(in_features=1079, out_features=720, bias=True)\n        )\n        (ln): LayerNorm((720,), eps=1e-05, elementwise_affine=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n</code></pre> <p></p> <p>\u7b2c2\u6b21\u5faa\u73af (i=1)</p> <p>e_last \u5f53\u524d\u503c: [32, 7, 179]  </p> <p><code>e_last = torch.cat((e_out[self.stage_num - i -2], e_last), dim=2)</code></p> <p>\u8ba1\u7b97 <code>self.stage_num - i - 2 = 4 - 1 - 2 = 1</code></p> <p>\u62fc\u63a5 <code>e_out[1]</code> \u548c <code>e_last</code>: [32, 7, 359] \u548c [32, 7, 179]</p> <p>\u6cbf dim=2 \u62fc\u63a5\uff0c\u5f97\u5230 [32, 7, 359+179] = [32, 7, 538]</p> <p>\u901a\u8fc7 up_blocks[1] \u6620\u5c04\uff0c\u8f93\u51fa\u5f62\u72b6\u53d8\u4e3a [32, 7, 359]</p> <p>\u7b2c3\u6b21\u5faa\u73af (i=2)</p> <p>e_last \u5f53\u524d\u503c: [32, 7, 359]</p> <p>\u8ba1\u7b97 self.stage_num - i - 2 = 4 - 2 - 2 = 0</p> <p>\u62fc\u63a5 e_out[0] \u548c e_last: [32, 7, 720] \u548c [32, 7, 359]</p> <p>\u6cbf dim=2 \u62fc\u63a5\uff0c\u5f97\u5230 [32, 7, 720+359] = [32, 7, 1079]</p> <p>\u901a\u8fc7 up_blocks[2] \u6620\u5c04\uff0c\u8f93\u51fa\u5f62\u72b6\u53d8\u4e3a [32, 7, 720]</p> <p><code>e_last = e_last.permute(0,2,1)</code></p> <p>\u8c03\u6574\u7ef4\u5ea6: e_last.permute(0,2,1) \u5c06 [32, 7, 720] \u53d8\u4e3a [32, 720, 7]</p> <p>\u5e94\u7528\u9006\u5f52\u4e00\u5316: <code>revin_layer(e_last, 'denorm')</code> \u5f62\u72b6\u4e0d\u53d8\uff0c\u4ecd\u4e3a <code>[32, 720, 7]</code></p> <p>\u8fd4\u56de\u6700\u7ec8\u8f93\u51fa: \u5f62\u72b6\u4e3a <code>[32, 720, 7]</code></p> <p>\u8f93\u5165 BSC\uff0c</p> <p>\u53ef\u9006\u5b9e\u4f8b\u5f52\u4e00\u5316 BSC</p> <p>permute BCS</p> <p>1.1 <code>\u805a\u5408\u4fe1\u606f</code></p> <p>maxPool BC \\(\\frac{S}{2}\\)</p> <p>AvgPool BC \\(\\frac{S}{2}\\)</p> <p>Add(MaxPool + AvgPool)  BC  \\(\\frac{S}{2}\\)</p> <p>\u4fdd\u5b58Pool \u540e\u7684 BC  \\(\\frac{S}{2}\\)</p> <p>Linear  BC  \\(\\frac{S}{2}\\)</p> <p>\ud83d\udfe2 1.2 <code>Seg</code>  \u7ec6\u7c92\u5ea6\u63d0\u53d6\u4fe1\u606f\uff0c\u6b8b\u5dee\u8fde\u63a5</p> <p>\u76f4\u63a5\u5bf9\u8f93\u5165 BCS \u5206\u6210 2 \u6bb5\uff0c\u5f62\u72b6\u4e3a BC\u00d72\u00d7 \\(\\frac{S}{2}\\)</p> <p>\u7ecf\u8fc7 GRU \u63d0\u53d6\u6700\u540e\u4e00\u5c42\u9690\u542b\u5c42\u72b6\u6001 \uff0c\u5f62\u72b6\u4e3a 1\u00d7BC\u00d7 \\(\\frac{S}{2}\\)  \uff081\u8868\u793a num_layers  \u5355\u5c42 GRU\uff09</p> <p>\ud83d\udfe2 \u878d\u5408\u4fe1\u606f</p>"},{"location":"logs/1_0_diary/2025/04/#2025-04-07-monday","title":"2025-04-07 Monday","text":"<p>\u89e3\u7801\u9636\u6bb5\uff1a</p> <p><code>decoder_input_4 = x_AddNorm4.permute(0, 2, 1)</code> </p> <p>\u8f93\u5165\u5f62\u72b6 [B,S/8,d_model] \u7ecf\u8fc7 permute [B,d_model,S/8]</p> <p>\u7b2c\u4e00\u9636\u6bb5\uff1a\u4f7f\u75281/8\u5206\u8fa8\u7387\u7279\u5f81\u9884\u6d4b\u603b\u9884\u6d4b\u957f\u5ea6\u7684\u524d1/8\u90e8\u5206</p> <p>\u9996\u5148\u62ff\u5230\u6700\u540e\u4e00\u4e2a\u5386\u53f2\u65f6\u95f4\u70b9  <code>last_state_4 = decoder_input_4[:, :, -1]</code></p> <p>\u7ef4\u5ea6 <code>[B,d_model]</code></p> <p>\u63a5\u4e0b\u6765\u9884\u6d4b\uff0c\u6295\u5f71\uff08\u5728\u60f3\u4f1a\u4e0d\u4f1a\u7528 GRU \u6548\u679c\u66f4\u597d\u4e00\u4e9b\uff09</p> <p><code>pred_4 = *self*.predictor_4(last_state_4)</code></p> <p>\u76f4\u63a5\u4ece <code>[B,d_model]</code>  \u6295\u5f71\u5230 <code>[B,pred_len/4*enc_in]</code></p> <p>\u63a5\u4e0b\u6765 reshape \u6210\u6b63\u5e38\u7684\u5f62\u72b6\uff1a<code>[B,enc_in,pred_len/4]</code></p> <p>\u4e0b\u9762\u5f00\u59cb\u5411\u4e0a\u878d\u5408\uff0c\u4f7f\u7528 <code>x_fused3</code>  \u878d\u5408\u4e86 <code>seq_len/8</code>  \u548c <code>seq_len/4</code> \u7684\u4fe1\u606f</p> <p>\u5f62\u72b6\u662f <code>[B,S/4,d_model]</code></p> <p>permute \u7ef4\u5ea6\u8f6c\u6362\u4e3a <code>[B,d_model,S/4]</code></p> <p>\u63a5\u4e0b\u6765\u8fdb\u884c\u6e10\u8fdb\u5f0f\u7684\u89e3\u7801\u7ed3\u6784\uff0c\u878d\u5408\u4e0a\u4e00\u5c42\u7684\u89e3\u7801\uff0c\u521b\u5efa\u6e10\u8fdb\u5f0f \u81ea\u56de\u5f52\u7684\u89e3\u7801\u7ed3\u6784</p> <p>\u62ff\u5230 <code>x_fused3</code> \u5f62\u72b6 <code>[B,S/4,d_model]</code></p> <p><code>permute</code>  \u5f62\u72b6\u53d8\u4e3a <code>[B,d_model,S/4]</code></p> <p>\u878d\u5408\u4e0a\u4e00\u5c42\u89e3\u7801 <code>pred_len/8</code> \u7684\u8f93\u51fa  <code>pred_4</code> \u5f62\u72b6 <code>[B,enc_in,pred_len_4]</code></p> <p>\u4e3a\u4e86\u53ef\u4ee5\u878d\u5408\uff0c\u9996\u5148\u7ef4\u5ea6\u8981\u5bf9\u9f50\uff0c\u6240\u4ee5\u5bf9   <code>pred_4</code>  \u7684 <code>enc_in</code> \u7ef4\u5ea6\u8fdb\u884c\u6295\u5f71\uff0c\u6295\u5f71\u5230 <code>d_model</code> \u7ef4\u5ea6 \u5f62\u72b6\u53d8\u4e3a   <code>[B,d_model,pred_len_4]</code></p> <p>\u63a5\u4e0b\u6765\uff0c\u5c31\u53ef\u4ee5 concat \u4e86\uff0c <code>[B,d_model,S/4]</code> concat     <code>[B,d_model,pred_len/4]</code>\u53d8\u6210   <code>[B,d_model,S/4]</code> </p> <p>\u5176\u5b9e\u8fd9\u91cc\u662f\u4e24\u4e2a\u4e0d\u5bf9\u9f50\uff0c\u9884\u6d4b\u7684\u957f\u5ea6\u548c\u7ef4\u5ea6\u90fd\u4e0d\u5bf9\u9f50\u3002</p> <p>\u53ef\u8fd8\u662f\u60f3\u8bbe\u8ba1\u4e00\u4e2a\u6e10\u8fdb\u89e3\u7801\uff0c\u6e10\u8fdb\u89e3\u7801\u4e0d\u597d\u5f04\uff0c\u56e0\u4e3a\u7ef4\u5ea6\u548c\u957f\u5ea6\u90fd\u4e0d\u5bf9\u9f50\u3002</p> <p>\u81ea\u5e95\u5411\u4e0a\u7684\u878d\u5408\u548c\u89e3\u7801\u3002</p>"},{"location":"logs/1_0_diary/2025/04/#2025-04-13-sunday","title":"2025-04-13 Sunday","text":"<ul> <li> TimeMixer\uff08\u7ebf\u6027\u7cfb\u6a21\u578b\uff09</li> <li> Pyraformer \uff08\u6709\u8bc1\u660e\uff09</li> <li> Fedformer\uff08\u8bbe\u8ba1\u9891\u57df\u7684\u90fd\u6709\u70b9\u8003\u9a8c\u6570\u5b66\u529f\u5e95\uff0c\u5c0f\u6ce2\u53d8\u6362\u786e\u5b9e\u4e0d\u660e\u767d\uff09</li> </ul>"},{"location":"logs/1_0_diary/2025/05/","title":"5 \u6708","text":""},{"location":"logs/1_0_diary/2025/05/#5","title":"5 \u6708","text":"2025-03-29 17:45:372025-09-28 12:54:06 <p> \u7ea6 2 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"logs/1_0_diary/2025/06/","title":"6 \u6708","text":""},{"location":"logs/1_0_diary/2025/06/#6","title":"6 \u6708","text":"2025-03-29 17:45:372025-09-28 12:54:06 <p> \u7ea6 2 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"logs/1_0_diary/2025/07/","title":"7 \u6708","text":""},{"location":"logs/1_0_diary/2025/07/#7","title":"7 \u6708","text":"2025-03-29 17:45:372025-09-28 12:54:06 <p> \u7ea6 2 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"logs/1_0_diary/2025/08/","title":"8 \u6708","text":""},{"location":"logs/1_0_diary/2025/08/#8","title":"8 \u6708","text":"2025-03-29 17:45:372025-09-28 12:54:06 <p> \u7ea6 2 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"logs/1_0_diary/2025/09/","title":"9 \u6708","text":""},{"location":"logs/1_0_diary/2025/09/#9","title":"9 \u6708","text":"2025-03-29 17:45:372025-09-28 12:54:06 <p> \u7ea6 2 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"logs/1_0_diary/2025/0_Question/","title":"\u95ee\u9898\u6e05\u5355","text":""},{"location":"logs/1_0_diary/2025/0_Question/#_1","title":"\u95ee\u9898\u6e05\u5355","text":"2025-04-08 12:37:292025-09-28 12:54:06 <p> \u7ea6 32 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u5141\u8bb8\u81ea\u5df1\u6709\u95ee\u9898\uff0c\u95ee\u9898\u7684\u7b54\u6848\u968f\u7740\u65f6\u95f4\u9010\u6e10\u660e\u4e86\uff0c\u91cd\u8981\u7684\u662f\u7801\u653e\u6e05\u695a</p>"},{"location":"logs/1_0_diary/2025/10/","title":"10 \u6708","text":""},{"location":"logs/1_0_diary/2025/10/#10","title":"10 \u6708","text":"2025-03-29 17:45:372025-09-28 12:54:06 <p> \u7ea6 2 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p>"},{"location":"sticks/1_github_v0/","title":"git init","text":""},{"location":"sticks/1_github_v0/#git-init","title":"git init","text":"2025-04-16 23:10:442025-09-28 12:54:07 <p> \u7ea6 50 \u4e2a\u5b57  94 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u521d\u59cb\u5316\u672c\u5730\u4ed3\u5e93\u3001\u540e\u9762\u63a8\u9001\u8fdc\u7a0b</p> <p>\u7b2c\u4e00\u6b65\uff1a</p> Bash<pre><code>git init\ngit add .\ngit commit -m \"Initial commit\"\n# \u53ef\u80fd\u9700\u8981\ngit config user.name \"dearRongerr\"\ngit config user.email \"1939472345@qq.com\"\n</code></pre> <p>\u7b2c\u4e8c\u6b65\uff1a\u91cd\u8981\uff09\u7f16\u5199 <code>.gitignore</code> </p> Bash<pre><code># Python\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# \u865a\u62df\u73af\u5883\nvenv/\nenv/\nENV/\n.env\n.venv\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# \u6570\u636e\u6587\u4ef6 (\u6839\u636e\u9700\u8981\u53d6\u6d88\u6ce8\u91ca)\n*.csv\n*.xls\n*.xlsx\n*.parquet\n*.feather\n*.pickle\n*.pkl\n\n# \u7f16\u8bd1\u548c\u7f13\u5b58\n__pycache__/\n*.py[cod]\n*$py.class\n\n# \u65e5\u5fd7\u6587\u4ef6\n*.log\nlogs/\n\n# OS\u751f\u6210\u7684\u6587\u4ef6\n.DS_Store\n.DS_Store?\n._*\n.Spotlight-V100\n.Trashes\nehthumbs.db\nThumbs.db\n\n# IDE\u76f8\u5173\u6587\u4ef6\n.idea/\n.vscode/\n*.swp\n*.swo\n*~\n\n# \u6a21\u578b\u6587\u4ef6\u548c\u68c0\u67e5\u70b9 (\u6839\u636e\u9700\u8981\u53d6\u6d88\u6ce8\u91ca)\n# *.h5\n# *.pkl\n# *.pt\n# *.pth\n# checkpoints/\n# models/\n\n# \u56fe\u50cf\u548c\u5927\u578b\u5a92\u4f53\u6587\u4ef6 (\u6839\u636e\u9700\u8981\u53d6\u6d88\u6ce8\u91ca)\n# *.png\n# *.jpg\n# *.jpeg\n# *.gif\n# *.mp4\n# *.mov\n\n# \u73af\u5883\u914d\u7f6e\u6587\u4ef6\n.env\n.env.local\nconfig.ini\n</code></pre> <p>\u5c24\u5176\u6ce8\u610f \uff1a</p> <p>\uff081\uff09\u5982\u679c\u5df2\u7ecf\u63d0\u4ea4\u4e86 <code>.DS_Store</code> \uff0c\u8bf7\u6267\u884c\uff1a</p> Bash<pre><code>git rm --cached **/.DS_Store\n</code></pre> <p>\uff082\uff09\u63a5\u7740\u518d\u6b21\u63d0\u4ea4</p>"},{"location":"sticks/1_github_v1/","title":"Git(clone\u4ee5\u540e)","text":""},{"location":"sticks/1_github_v1/#gitclone","title":"Git(clone\u4ee5\u540e)","text":"2025-02-28 10:36:422025-09-28 12:54:07 <p> \u7ea6 36 \u4e2a\u5b57  27 \u884c\u4ee3\u7801  2 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p>"},{"location":"sticks/1_github_v1/#fork-clone","title":"fork &amp; clone","text":"<p>link</p> <p>\u3010Git\u7248\u672c\u63a7\u5236\u3011GitHub\u4e0afork\u9879\u76ee\u548cclone\u9879\u76ee\u7684\u533a\u522b</p>"},{"location":"sticks/1_github_v1/#ssh-clone","title":"SSH clone","text":"Bash<pre><code>git clone git@github.com:\u539f\u4f5c\u8005/\u539f\u4ed3\u5e93.git\n</code></pre> <p>\u4e4b\u540e\uff1a</p> Bash<pre><code># \u8fdb\u5165\u9879\u76ee\u76ee\u5f55\ncd \u539f\u4ed3\u5e93\n\n# \u67e5\u770b\u5f53\u524d\u8fdc\u7a0b\u4ed3\u5e93\ngit remote -v\n# \u663e\u793a\u7ed3\u679c\u901a\u5e38\u4e3a\uff1a\n# origin   git@github.com:\u539f\u4f5c\u8005/\u539f\u4ed3\u5e93.git (fetch)\n# origin   git@github.com:\u539f\u4f5c\u8005/\u539f\u4ed3\u5e93.git (push)\n\n# \u79fb\u9664\u539f\u59cb\u7684\u8fdc\u7a0b\u4ed3\u5e93\u5f15\u7528\ngit remote rm origin\n\n# \u6dfb\u52a0\u4f60\u81ea\u5df1\u7684\u4ed3\u5e93\u4f5c\u4e3a\u65b0\u7684 origin (\u53ef\u4ee5\u4f7f\u7528SSH\u6216HTTPS)\ngit remote add origin git@github.com:\u4f60\u7684\u7528\u6237\u540d/\u4f60\u7684\u4ed3\u5e93.git\n# \u6216\ngit remote add origin https://github.com/\u4f60\u7684\u7528\u6237\u540d/\u4f60\u7684\u4ed3\u5e93.git\n\n# \u6dfb\u52a0\u539f\u4f5c\u8005\u7684\u4ed3\u5e93\u4f5c\u4e3a upstream (\u65b9\u4fbf\u65e5\u540e\u540c\u6b65\u66f4\u65b0)\ngit remote add upstream git@github.com:\u539f\u4f5c\u8005/\u539f\u4ed3\u5e93.git\n</code></pre> <p>\u63d0\u4ea4\u914d\u7f6e\u4e2a\u4eba\u4fe1\u606f\uff1a</p> Bash<pre><code>cd \u4f60\u7684\u9879\u76ee\n# \u5171\u4eab\u670d\u52a1\u5668\u4e0a\u5de5\u4f5c\uff0c\u672c\u5730\u914d\u7f6e\uff0c\u907f\u514d\u5f71\u54cd\u5176\u4ed6\u9879\u76ee\ngit config user.name \"dearRongerr\"\ngit config user.email \"1939472345@qq.com\"\n# \u4e2a\u4eba\u5b9e\u9a8c\uff0c\u5168\u5c40\u914d\u7f6e\ngit config --global user.name \"dearRongerr\"\ngit config --global user.email \"1939472345@qq.com\"\n</code></pre>"},{"location":"sticks/1_github_v2/","title":"git\u5206\u652f\u4e0e\u529f\u80fd\u6d4b\u8bd5","text":""},{"location":"sticks/1_github_v2/#git","title":"git\u5206\u652f\u4e0e\u529f\u80fd\u6d4b\u8bd5","text":"2025-04-16 23:10:442025-09-28 12:54:07 <p> \u7ea6 208 \u4e2a\u5b57  90 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p>"},{"location":"sticks/1_github_v2/#function-main","title":"function\u5206\u652f\u5408\u5e76\u5230 main \u5206\u652f","text":"<p>\u573a\u666f\u63cf\u8ff0\uff1amain \u5206\u652f\u4fdd\u5b58\u5f53\u524d\u6700\u597d\u6700\u65b0\u7684\u72b6\u6001</p> <p>function\u5206\u652f\u6d4b\u8bd5\uff0c\u6d4b\u8bd5\u6210\u529f\u5408\u5e76\u5230\u4e3b\u5206\u652f</p> <p>\uff081\uff09\u4ece\u5f53\u524dmain\u4f4d\u7f6e\u521b\u5efafunction\u5206\u652f</p> Bash<pre><code>git checkout -b function\n</code></pre> <p>\uff082\uff09\u9a8c\u8bc1\u5206\u652f\u72b6\u6001</p> Bash<pre><code># \u786e\u8ba4main\u5206\u652f\u6b63\u786e\u6307\u5411\"\u6dfb\u52a0\u5c0f\u6ce2\u53d8\u6362\"\u63d0\u4ea4\ngit checkout main\ngit log -1 --oneline  # \u5e94\u663e\u793a\"\u6dfb\u52a0\u5c0f\u6ce2\u53d8\u6362\"\n\n# \u786e\u8ba4function\u5206\u652f\u4e0emain\u4e00\u81f4\ngit checkout function\ngit log -1 --oneline  # \u4e5f\u5e94\u663e\u793a\"\u6dfb\u52a0\u5c0f\u6ce2\u53d8\u6362\"\n</code></pre> <p>\uff083\uff09\u540e\u7eed\u5728 function \u5206\u652f\u4e0a\u5de5\u4f5c\uff1a</p> Bash<pre><code># \u5728function\u5206\u652f\u4e0a\u8fdb\u884c\u6240\u6709\u5f00\u53d1\u5de5\u4f5c\ngit checkout function\n\n# \u4fee\u6539\u4ee3\u7801\n# ...\n\n# \u63d0\u4ea4\u66f4\u6539\ngit add .\ngit commit -m \"\u5728function\u5206\u652f\u4e0a\u7684\u6539\u8fdb\"\n\n# \u5982\u679c\u6539\u8fdb\u6210\u529f\uff0c\u53ef\u4ee5\u5c06function\u5408\u5e76\u5230main\ngit checkout main\ngit merge function\n\n# \u5982\u679c\u9700\u8981\u7ee7\u7eed\u5728function\u4e0a\u5f00\u53d1\u65b0\u529f\u80fd\ngit checkout function\n# \u7ee7\u7eed\u5f00\u53d1...\n</code></pre>"},{"location":"sticks/1_github_v2/#_1","title":"\u56de\u9000\u63d0\u4ea4\u3001\u4fee\u6539\u5934\u6307\u9488","text":"<p>\u573a\u666f\u63cf\u8ff0\uff1a\u4fee\u6539main \u5934\u6307\u9488\uff0c\u6307\u5411\u4e4b\u524d\u7684\u67d0\u6b21\u63d0\u4ea4</p> <p>\uff081\uff09\u67e5\u770b\u60f3\u8981\u56de\u9000\u63d0\u4ea4\u7684\u54c8\u5e0c\u503c</p> Bash<pre><code>git log --oneline\n</code></pre> <p>\uff082\uff09\u5c06main\u5206\u652f\u6307\u5411\u8be5\u63d0\u4ea4</p> Bash<pre><code>git checkout main\n# \u901a\u8fc7\u54c8\u5e0c\u503c\u56de\u9000\ngit reset --hard &lt;\u63d0\u4ea4\u54c8\u5e0c\u503c&gt;\n# \u901a\u8fc7\u5f15\u7528\u56de\u9000\uff1a\u6307\u5411 \u5f53\u524dHEAD\u7684\u524d\u4e00\u4e2a\u63d0\u4ea4\ngit reset --hard HEAD~1\n</code></pre> <p>\u573a\u666f\uff1a\u5b8c\u6574\u7684\u5de5\u4f5c\u6d41</p>"},{"location":"sticks/1_github_v2/#git_1","title":"\u4fdd\u7559\u529f\u80fd\u5206\u652f\u7684\u5b8c\u6574Git\u5de5\u4f5c\u6d41","text":"<p>\uff081\uff09\u521b\u5efafunction \u5206\u652f</p> Bash<pre><code># \u786e\u8ba4main\u5206\u652f\u4f4d\u4e8e\"\u6dfb\u52a0\u5c0f\u6ce2\u53d8\u6362\"\u63d0\u4ea4\ngit checkout main\n\n# \u521b\u5efa\u5e76\u5207\u6362\u5230function\u5206\u652f\ngit checkout -b function\n</code></pre> <p>\uff082\uff09\u5728function\u5206\u652f\u4e0a\u8fdb\u884c\u5b9e\u9a8c</p> Bash<pre><code># \u786e\u4fdd\u5728function\u5206\u652f\u4e0a\ngit checkout function\n\n# \u4fee\u6539\u4ee3\u7801\uff08\u4f8b\u5982\u8c03\u6574etth1_u.sh\u4e2d\u7684\u53c2\u6570\uff09\nnano scripts/etth1_u.sh\n# \u4fee\u6539dropout\u53c2\u6570\u6216\u6dfb\u52a0\u65b0\u529f\u80fd\n\n# \u63d0\u4ea4\u66f4\u6539\ngit add scripts/etth1_u.sh\ngit commit -m \"\u5b9e\u9a8c: \u8c03\u6574dropout\u53c2\u6570\u4e3a0.3\"\n</code></pre> <p>\uff083\uff09\u5982\u679c\u5b9e\u9a8c\u7ed3\u679c\u826f\u597d\uff0c\u5408\u5e76\u5230main\u5206\u652f</p> Bash<pre><code># \u5207\u6362\u5230main\u5206\u652f\ngit checkout main\n\n# \u5408\u5e76function\u5206\u652f\uff08\u4f7f\u7528--no-ff\u4fdd\u7559\u5408\u5e76\u5386\u53f2\uff09\ngit merge --no-ff function -m \"\u5408\u5e76improved-dropout\u5b9e\u9a8c: \u6027\u80fd\u63d0\u534710%\"\n\n# \u53ef\u9009: \u4e3a\u6b64\u7248\u672c\u6dfb\u52a0\u6807\u7b7e\ngit tag -a v1.1 -m \"ETTh1\u6570\u636e\u96c6\u4e0a\u7684\u6539\u8fdb\u7248\u672c: MSE\u964d\u4f4e\u52300.xxx\"\n</code></pre> <p>\uff084\uff09\u7ee7\u7eed\u5728function\u5206\u652f\u4e0a\u8fdb\u884c\u65b0\u5b9e\u9a8c</p> Bash<pre><code># \u5207\u6362\u56defunction\u5206\u652f\ngit checkout function\n\n# \u53ef\u9009: \u5c06function\u91cd\u7f6e\u5230\u4e0emain\u4e00\u81f4\uff08\u5982\u679c\u60f3\u57fa\u4e8e\u6700\u65b0main\u5f00\u59cb\uff09\ngit reset --hard main  \n\n# \u8fdb\u884c\u65b0\u7684\u4fee\u6539.....\n# \u4f8b\u5982\u6dfb\u52a0\u65b0\u7684\u6b63\u5219\u5316\u5c42\n\n# \u63d0\u4ea4\u65b0\u5b9e\u9a8c\ngit add models/Time_Unet.py\ngit commit -m \"\u5b9e\u9a8c: \u6dfb\u52a0dropout\u5230\u9ad8\u9891\u5904\u7406\u90e8\u5206\"\n\n# \u8fd0\u884c\u65b0\u5b9e\u9a8c\nbash scripts/etth1_u.sh\n</code></pre> <p>\uff085\uff09 \u6709\u7528\u7684\u8f85\u52a9\u547d\u4ee4</p> Bash<pre><code># \u67e5\u770b\u5f53\u524d\u72b6\u6001\ngit status\n\n# \u663e\u793a\u63d0\u4ea4\u4fe1\u606f\ngit log\n\n# \u5982\u679c\u60f3\u653e\u5f03\u5f53\u524d\u5b9e\u9a8c\ngit checkout function\ngit reset --hard main\n\n# \u5982\u679c\u60f3\u521b\u5efa\u65b0\u7684\u5b9e\u9a8c\u5206\u652f\ngit checkout main\ngit checkout -b new-experiment\n</code></pre> <p>\u591a\u5206\u652f\u5b9e\u9a8c</p> Bash<pre><code># \u4ecemain\u521b\u5efa\u591a\u4e2a\u5b9e\u9a8c\u5206\u652f\ngit checkout main\ngit checkout -b exp-regularization\ngit checkout main\ngit checkout -b exp-architecture\n\n# \u5728\u4e0d\u540c\u5206\u652f\u6d4b\u8bd5\u4e0d\u540c\u601d\u8def\n# ...\n</code></pre>"},{"location":"sticks/1_github_v3/","title":"(\u9010\u6b65\u7cfb\u5217) git","text":""},{"location":"sticks/1_github_v3/#git","title":"(\u9010\u6b65\u7cfb\u5217) git","text":"2025-04-20 14:04:312025-09-28 12:54:07 <p> \u7ea6 123 \u4e2a\u5b57  94 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 2 \u5206\u949f</p> <ul> <li>\u672c\u5730 git init</li> <li> <p>\u91cd\u8981!\u7f16\u5199 <code>.gitignore</code>  ,\u5c24\u5176\u662f <code>.DS...</code> (\u89c1\u6807\u9898,\u590d\u5236\u5373\u53ef)</p> </li> <li> <p>git add</p> </li> <li>git commit -m\"first init\"</li> <li>[option]</li> </ul> Bash<pre><code># \u53ef\u80fd\u9700\u8981\ngit config user.name \"dearRongerr\"\ngit config user.email \"1939472345@qq.com\"\n</code></pre> <ul> <li>\u8fde\u63a5\u8fdc\u7a0b</li> </ul> Bash<pre><code>git remote add origin https://github.com/dearRongerr/Rongerr.github.io.git\ngit branch -M main \n</code></pre> <p><code>git branch -M main</code> </p> <p>\u5f3a\u5236\u91cd\u547d\u540d\u8fdc\u7a0b\u5206\u652f\u4e3a:main</p> <ul> <li>\u63a8\u9001</li> </ul> Bash<pre><code>git push -u origin main\n</code></pre>"},{"location":"sticks/1_github_v3/#add","title":"ADD","text":"<ul> <li>\u66f4\u6539\u8fdc\u7a0b\u8fde\u63a5</li> <li>\u8bef\u63d0\u4ea4 / <code>.gitignore</code> </li> </ul>"},{"location":"sticks/1_github_v3/#_1","title":"\ud83d\udea9 \u66f4\u6539\u8fdc\u7a0b\u8fde\u63a5","text":"Text Only<pre><code># \u67e5\u770b\u5f53\u524d\u8fde\u63a5\ngit remote -v\n# \u66f4\u6539\ngit remote set-url origin https://github.com/dearRongerr/NewRepo.git\n</code></pre>"},{"location":"sticks/1_github_v3/#ds_store","title":"\ud83d\udea9 \u5982\u679c\u5df2\u7ecf\u63d0\u4ea4\u4e86 <code>.DS_Store</code> \uff0c\u6267\u884c","text":"Bash<pre><code>git rm --cached **/.DS_Store\n</code></pre>"},{"location":"sticks/1_github_v3/#_2","title":"\ud83d\udea9 \u67e5\u770b\u8fdc\u7a0b\u5206\u652f","text":"Bash<pre><code>git remote -v\n</code></pre>"},{"location":"sticks/1_github_v3/#_3","title":"\u51e0\u70b9\u8bf4\u660e","text":"<p>\u2460 \u4e00\u5b9a\u662f\u672c\u5730\u548c\u8fdc\u7a0b\u4ed3\u5e93\u72b6\u6001\u4e00\u6837</p>"},{"location":"sticks/1_github_v3/#gitignore","title":".gitignore","text":"Bash<pre><code># Python\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# \u865a\u62df\u73af\u5883\nvenv/\nenv/\nENV/\n.env\n.venv\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# \u6570\u636e\u6587\u4ef6 (\u6839\u636e\u9700\u8981\u53d6\u6d88\u6ce8\u91ca)\n*.csv\n*.xls\n*.xlsx\n*.parquet\n*.feather\n*.pickle\n*.pkl\n\n# \u7f16\u8bd1\u548c\u7f13\u5b58\n__pycache__/\n*.py[cod]\n*$py.class\n\n# \u65e5\u5fd7\u6587\u4ef6\n*.log\nlogs/\n\n# OS\u751f\u6210\u7684\u6587\u4ef6\n.DS_Store\n.DS_Store?\n._*\n.Spotlight-V100\n.Trashes\nehthumbs.db\nThumbs.db\n\n# IDE\u76f8\u5173\u6587\u4ef6\n.idea/\n.vscode/\n*.swp\n*.swo\n*~\n\n# \u6a21\u578b\u6587\u4ef6\u548c\u68c0\u67e5\u70b9 (\u6839\u636e\u9700\u8981\u53d6\u6d88\u6ce8\u91ca)\n# *.h5\n# *.pkl\n# *.pt\n# *.pth\n# checkpoints/\n# models/\n\n# \u56fe\u50cf\u548c\u5927\u578b\u5a92\u4f53\u6587\u4ef6 (\u6839\u636e\u9700\u8981\u53d6\u6d88\u6ce8\u91ca)\n# *.png\n# *.jpg\n# *.jpeg\n# *.gif\n# *.mp4\n# *.mov\n\n# \u73af\u5883\u914d\u7f6e\u6587\u4ef6\n.env\n.env.local\nconfig.ini\n</code></pre>"},{"location":"sticks/3_vscode/","title":"VSCode","text":""},{"location":"sticks/3_vscode/#vscode","title":"VSCode","text":"2025-03-04 21:01:002025-09-28 12:54:07 <p> \u7ea6 1482 \u4e2a\u5b57  2 \u884c\u4ee3\u7801  7 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 7 \u5206\u949f</p>"},{"location":"sticks/3_vscode/#vscode_1","title":"vscode \u6ce8\u91ca\u5173\u952e\u5b57\u9ad8\u4eae","text":"<ul> <li>\u3010\u53c2\u770b\u3011</li> </ul> <p>vscode\u8bbe\u7f6e\u5173\u952e\u5b57\u9ad8\u4eae</p> <p></p> <p><code>command+shift+p</code>\u6253\u5f00\u547d\u4ee4\u7a97\u53e3\uff0c\u641c\u7d22<code>Highlight Toggle Current</code>\u547d\u4ee4\uff0c\u6b64\u547d\u4ee4\u53ef\u9ad8\u4eae\u9009\u4e2d\u7684\u5355\u8bcd</p> Text Only<pre><code>Highlight Toggle Current\n</code></pre> <p>\u5373\u53ef\u8bbe\u7f6e\uff1a</p> <p></p> <p></p> <p>\u6548\u679c\uff1a</p> <p></p> <ul> <li>command + \uff0c \u641c\u7d22 highlight\u4ee3\u7801\u7f16\u8f91\u5668\u4f4d\u7f6e\uff0c\u4e00\u6837\u6253\u5f00</li> </ul>"},{"location":"sticks/3_vscode/#vscode-shell-python","title":"vscode \u8c03\u8bd5 shell \u8c03\u7528\u7684 python \u6587\u4ef6","text":"<p>vscode \u4e2d\u5982\u4f55Debug\u7528Bash\u811a\u672c\u8fd0\u884c\u7684Python\u4ee3\u7801</p> <p>\u4f7f\u7528VSCode\u5bf9\u4e00\u4e2a\u7528Shell\u811a\u672c\u542f\u52a8\u7684Python\u7a0b\u5e8f\u8fdb\u884cDebug</p> <p>\u4f7f\u7528VSCode\u8c03\u8bd5\u5e26\u53c2\u6570\u7684Python\u811a\u672c</p> <p>\uff081\uff09\u6fc0\u6d3bpython \u8fd0\u884c\u76f8\u5e94\u7684\u865a\u62df\u73af\u5883</p> <p>\uff082\uff09\u5b89\u88c5 <code>debugpy</code> \u5e93</p> Text Only<pre><code>pip install debugpy\n</code></pre> <p>\uff083\uff09\u67e5\u770b\u53ef\u7528\u7aef\u53e3\uff1a</p> Text Only<pre><code>for port in {5000..6000}; do\n    (echo &gt; /dev/tcp/localhost/$port) &gt;/dev/null 2&gt;&amp;1 || echo \"$port is free\"\ndone\n</code></pre> <p>\u67e5\u770b5000-6000\u4e4b\u95f4\u7684\u53ef\u7528\u7aef\u53e3\uff0c\u7528\u7684 <code>5999</code></p> <p>\uff084\uff09launch.json \u914d\u7f6e</p> <p>\u5728VSCode\u6309<code>Command+Shift+P</code>, \u8f93\u5165<code>Debug: Add Configuration</code> \u65b0\u5efa\u4e00\u4e2alaunch.json\uff08\u6216\u8005\u76f4\u63a5\u6253\u5f00launch.json)\u7f16\u8f91\u4ee5\u4e0b\u5185\u5bb9\u5e76\u4fdd\u5b58</p> Text Only<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"[\u8fd9\u91cc\u66f4\u6362\u4e3a\u4efb\u610f\u540d\u79f0]\",\n            \"type\": \"python\",\n            \"request\": \"attach\",\n            \"connect\": {\n                \"host\": \"localhost\",\n                \"port\": 5999\n            }\n        }\n    ]\n}\n</code></pre> <p>\uff085\uff09Shell \u4f7f\u7528Shell \u542f\u52a8Python\uff0c\u5bf9\u539f\u6765\u7684Shell\u8fdb\u884c\u7f16\u8f91\uff0c \u4f8b\u5982\u539f\u6765\u7684Shell\u662f\uff1a</p> Text Only<pre><code>python [NAME].py --arg1 \"arg\" --arg2 \"123\" \n</code></pre> <p>\u53ea\u9700\u8981\u5728<code>python</code>\u548c<code>[NAME].py</code>\u4e4b\u95f4\u52a0\u5165 <code>-m debugpy --listen [\u7aef\u53e3\u53f7]</code></p> <p>\u5373\uff1a</p> Text Only<pre><code>python -m debugpy --listen 5999 [NAME].py --arg1 \"arg\" --arg2 \"123\" \n</code></pre> <p>\uff086\uff09\u8fd0\u884c</p> <p>\u5728\u8fd0\u884c\u7684 python \u7684\u6587\u4ef6\u4e2d\uff0c\u6253\u4e0a\u76f8\u5e94\u7684\u65ad\u70b9\uff0c\u7136\u540e\u8fd0\u884c shell \u6587\u4ef6</p> Text Only<pre><code>sh your_shell_path/shell_name.sh\n</code></pre> <p>\u5373\u53ef\u6fc0\u6d3b vscode \u7684\u76f8\u5e94\u8c03\u8bd5</p> <p></p> <p>\u4e00\u4e9b\u4e0d\u592a\u61c2\u7684\u8bbe\u7f6e\uff1a</p> <ul> <li> <p>\u5e94\u7528\u5e02\u573a\u6269\u5c55\uff1aBash Debug</p> </li> <li> <p><code>launch.json</code>\u7684\u914d\u7f6e\uff1a\u70b9\u51fb <code>\u6dfb\u52a0\u914d\u7f6e</code>\uff0c\u65b0\u589e 3 \u4e2a\uff1a</p> </li> </ul> <p>\uff081\uff09Bash-Debug (type in script name)</p> <p>\uff082\uff09Bash-Debug (hardcoded script name)</p> <p>\uff083\uff09Bash-Debug (simplest configuration)</p> Text Only<pre><code>{\n    // \u4f7f\u7528 IntelliSense \u4e86\u89e3\u76f8\u5173\u5c5e\u6027\u3002 \n    // \u60ac\u505c\u4ee5\u67e5\u770b\u73b0\u6709\u5c5e\u6027\u7684\u63cf\u8ff0\u3002\n    // \u6b32\u4e86\u89e3\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u8bbf\u95ee: https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"[\u8fd9\u91cc\u66f4\u6362\u4e3a\u4efb\u610f\u540d\u79f0]\",\n            \"type\": \"python\",\n            \"request\": \"attach\",\n            \"connect\": {\n                \"host\": \"localhost\",\n                \"port\": 5999\n            }\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (type in script name)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${command:AskForScriptName}\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (select script from list of sh files)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${command:SelectScriptName}\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (hardcoded script name)\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"program\": \"${workspaceFolder}/path/to/script.sh\",\n            \"args\": []\n        },\n        {\n            \"type\": \"bashdb\",\n            \"request\": \"launch\",\n            \"name\": \"Bash-Debug (simplest configuration)\",\n            \"program\": \"${file}\"\n        }\n    ]\n}\n</code></pre>"},{"location":"sticks/3_vscode/#_1","title":"\u8c03\u8bd5\u4e0d\u663e\u793a\u5f20\u91cf\u5f62\u72b6\u95ee\u9898","text":"<p>\u3010\u53c2\u770b\u3011\u5728 VS Code \u4e2d\u8c03\u8bd5 Tensor \u5f62\u72b6\u4e0d\u663e\u793a\u7684\u95ee\u9898\u53ca\u89e3\u51b3\u65b9\u6848</p> <p></p> <p>\u7b2c\u4e00\u6b65\uff1a\u65b0\u5efapy\u6587\u4ef6\uff0c\u6587\u4ef6\u540d</p> Bash<pre><code>custom_repr.py\n</code></pre> <p>\u7b2c\u4e8c\u6b65\uff1a\u6587\u4ef6\u4e2d\u7684\u5185\u5bb9\uff0c\u590d\u5236\uff1a</p> <p>\u7b2c\u4e09\u6b65\uff1a\u5728\u6700\u5f00\u59cb\u7684\u6587\u4ef6\u5f00\u5934\uff1a</p> Python<pre><code>import custom_repr\n</code></pre> <p>\u590d\u5236\u8fd9\u91cc </p> Text Only<pre><code>import torch\nimport pandas as pd\n\n# -------------------- \u81ea\u5b9a\u4e49\u5305\u88c5\u7c7b --------------------\n\nclass CustomBool:\n    def __init__(self, value):\n        self.value = bool(value)\n\n    def __repr__(self):\n        return f'{{bool}} {self.value}'\n\nclass CustomInt:\n    def __init__(self, value):\n        self.value = int(value)\n\n    def __repr__(self):\n        return f'{{int}} {self.value}'\n\nclass CustomStr:\n    def __init__(self, value):\n        self.value = str(value)\n\n    def __repr__(self):\n        return f'{{str}} {self.value}'\n\n# \u81ea\u5b9a\u4e49 list \u548c dict \u5b50\u7c7b\nclass CustomList(list):\n    def __repr__(self):\n        return f'{{list: {len(self)}}} {super().__repr__()}'\n\nclass CustomDict(dict):\n    def __repr__(self):\n        return f'{{dict: {len(self)}}} {super().__repr__()}'\n\n# \u81ea\u5b9a\u4e49 Tensor \u7684 __repr__ (Torch)\noriginal_tensor_repr = torch.Tensor.__repr__\ndef custom_tensor_repr(self):\n    return f'{{Tensor: {tuple(self.shape)}}} {original_tensor_repr(self)}'\ntorch.Tensor.__repr__ = custom_tensor_repr\n\n# \u81ea\u5b9a\u4e49 DataFrame \u7684 __repr__ (Pandas)\noriginal_dataframe_repr = pd.DataFrame.__repr__\ndef custom_dataframe_repr(self):\n    return f'{{DataFrame: {self.shape}}} {original_dataframe_repr(self)}'\npd.DataFrame.__repr__ = custom_dataframe_repr\n\n# \u81ea\u5b9a\u4e49 DataLoader \u7684\u7c7b\nclass DataLoader:\n    def __init__(self, data_size):\n        self.data_size = data_size\n\n    def __len__(self):\n        return self.data_size\n\n    def __repr__(self):\n        return f'{{DataLoader: {len(self)}}} DataLoader object'\n\n# -------------------- __main__ \u51fd\u6570 --------------------\ndef main():\n    # \u4f7f\u7528\u81ea\u5b9a\u4e49\u7c7b\u578b\u4ee3\u66ff\u539f\u751f\u7c7b\u578b\n    my_list = CustomList([1, 2, 3, 4, 5, 6])\n    my_dict = CustomDict({'a': 1, 'b': 2, 'c': 3})\n    my_bool = CustomBool(True)\n    my_int = CustomInt(42)\n    my_str = CustomStr(\"hello\")\n\n    # \u6d4b\u8bd5 Tensor\n    my_tensor = torch.randn(100, 512)\n\n    # \u6d4b\u8bd5 DataFrame\n    my_dataframe = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n\n    # \u6d4b\u8bd5 DataLoader\n    my_dataloader = DataLoader(220)\n\n    # \u8f93\u51fa\u5185\u5bb9\n    print(my_list)        # {list: 6} [1, 2, 3, 4, 5, 6]\n    print(my_dict)        # {dict: 3} {'a': 1, 'b': 2, 'c': 3}\n    print(my_bool)        # {bool} True\n    print(my_int)         # {int} 42\n    print(my_str)         # {str} 'hello'\n    print(my_tensor)      # {Tensor: (100, 512)} tensor([...])\n    print(my_dataframe)   # {DataFrame: (3, 3)}    A  B  C\n    print(my_dataloader)  # {DataLoader: 220} DataLoader object\n\n# \u5982\u679c\u662f\u76f4\u63a5\u8fd0\u884c\u6587\u4ef6\uff0c\u5219\u8c03\u7528 main \u51fd\u6570\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"sticks/3_vscode/#debug-add-configuration","title":"Debug: Add Configuration","text":"<p>launch.json \u914d\u7f6e</p> <p>\u5728VSCode\u6309<code>Command+Shift+P</code>, \u8f93\u5165<code>Debug: Add Configuration</code> \u65b0\u5efa\u4e00\u4e2alaunch.json\uff08\u6216\u8005\u76f4\u63a5\u6253\u5f00launch.json)\u7f16\u8f91\u4ee5\u4e0b\u5185\u5bb9\u5e76\u4fdd\u5b58</p> <ul> <li> \u60f3\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u8fd8\u662f vscode \u8c03\u8bd5\u5e26\u53c2\u6570\u7684 python \u6587\u4ef6\u3002</li> </ul> <p>\u53e6\u5916\u4e00\u79cd\u65b9\u6cd5\uff0c\u4f60\u628a\u81ea\u5df1\u7684 shell \u811a\u672c\u7ed9 gpt\uff0c\u8ba9\u5b83\u7ed9\u4f60\u5199\u4e00\u4e2a \u914d\u7f6e\uff0c\u7136\u540e\u52a0\u5230<code>launch.json</code>\u4e2d\u5c31\u884c\u4e86 \uff08\u6709\u70b9\u5185\u4e2a\u867d\u7136\uff0c\u7b97\u4e86\uff0c\u80fd\u5e72\u6d3b\u5c31\u884c\uff09\uff1a</p> Text Only<pre><code>       {\n            \"name\": \"Python: run_longExp.py\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"program\": \"${workspaceFolder}/run_longExp.py\",\n            \"args\": [\n                \"--model_id\", \"illness_60_24\",\n                \"--is_training\", \"1\" \n                \"--model\", \"SegRNN\", \n                \"--data\", \"custom\",\n                \"--root_path\", \"./dataset/\",\n                \"--data_path\", \"national_illness.csv\",\n                \"--features\", \"M\",\n                \"--seq_len\", \"60\",\n                \"--pred_len\", \"24\",\n                \"--d_model\", \"512\",\n                \"--dropout\", \"0.0\",\n                \"--rnn_type\", \"gru\",\n                \"--dec_way\", \"pmf\",\n                \"--seg_len\", \"12\",\n                \"--loss\", \"mae\",\n                \"--des\", \"test\",\n                \"--itr\", \"1\",\n                \"--train_epochs\", \"2\",\n                \"--num_workers\", \"0\"\n            ],\n            \"console\": \"integratedTerminal\",\n            \"justMyCode\": true,\n            \"cwd\": \"${workspaceFolder}\"\n        },\n</code></pre> <p>\u5173\u4e8e\u8fd9\u4e2a\u6709\u51e0\u70b9\u60f3\u8bf4\u7684\uff1a</p> <ul> <li>\u4f7f\u7528\u542f\u52a8\u6a21\u5f0f\u800c\u4e0d\u662f\u9644\u52a0\u6a21\u5f0f</li> <li>\u8fd9\u79cd\u8c03\u8bd5\u53eb\u505a \u4ee5\u542f\u52a8\u6a21\u5f0f \u8c03\u8bd5\uff0c\u800c\u4e0d\u662f\u9644\u52a0\u6a21\u5f0f\u8c03\u8bd5\uff0c\u533a\u522b\u5728 <code>\"request\": \"launch\"</code>\uff0c<code>\"request\": \"launch\"</code> </li> </ul> <p>\u8fd9\u79cd\u7684\u597d\u5904\uff1a</p> <p>\u6700\u7b80\u5355\u7684\u8c03\u8bd5\u65b9\u6cd5\u662f\u4f7f\u7528\"\u542f\u52a8\"\u6a21\u5f0f\uff0c\u6309\u7167\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ol> <li>\u4f7f\u7528\u65b9\u6848\u4e00\u4e2d\u7684\u914d\u7f6e\u66ff\u6362\u6216\u6dfb\u52a0\u5230<code>launch.json</code>\u6587\u4ef6\u4e2d</li> <li>\u5728VS Code\u5de6\u4fa7\u7684<code>\"\u8fd0\u884c\u548c\u8c03\u8bd5\"</code>\u9762\u677f\u4e2d==\u9009\u62e9==\u521a\u521a\u521b\u5efa\u7684<code>\"Python: run_longExp.py\"</code>\u914d\u7f6e</li> <li>\u8bbe\u7f6e\u65ad\u70b9\u5e76\u70b9\u51fb\u7eff\u8272\u7684\u8fd0\u884c\u6309\u94ae\u5f00\u59cb\u8c03\u8bd5</li> </ol> <p>\ud83d\udfe2 \u4e0d\u9700\u8981\u624b\u52a8\u542f\u52a8\u8c03\u8bd5\u670d\u52a1\u5668</p> <ul> <li>\u4e00\u4e9b\u53c2\u6570\u89e3\u91ca\uff1a</li> </ul> Text Only<pre><code>{\n    \"name\": \"Python: run_longExp.py\",  // \u8c03\u8bd5\u914d\u7f6e\u7684\u540d\u79f0\uff0c\u4f1a\u663e\u793a\u5728VSCode\u8c03\u8bd5\u4e0b\u62c9\u83dc\u5355\u4e2d\n    \"type\": \"python\",                  // \u6307\u5b9a\u8c03\u8bd5\u5668\u7c7b\u578b\u4e3aPython\n    \"request\": \"launch\",               // \u4f7f\u7528\"\u542f\u52a8\"\u6a21\u5f0f\u800c\u975e\"\u9644\u52a0\"\u6a21\u5f0f\n    \"program\": \"${workspaceFolder}/run_longExp.py\", // \u8981\u8fd0\u884c\u7684Python\u811a\u672c\u8def\u5f84\n    \"args\": [                          // \u4f20\u9012\u7ed9\u811a\u672c\u7684\u547d\u4ee4\u884c\u53c2\u6570\n        \"--model_id\", \"illness_60_24\", // \u6a21\u578bID\u53c2\u6570\n        \"--is_training\", \"1\"           // \u8bad\u7ec3\u6a21\u5f0f\u6807\u5fd7\n        \"--model\", \"SegRNN\",           // \u4f7f\u7528\u7684\u6a21\u578b\n        // ...\u66f4\u591a\u53c2\u6570\n    ],\n    \"console\": \"integratedTerminal\",   // \u4f7f\u7528VSCode\u5185\u7f6e\u7ec8\u7aef\u663e\u793a\u8f93\u51fa\n    \"justMyCode\": true,                // \u53ea\u8c03\u8bd5\u60a8\u7684\u4ee3\u7801\uff0c\u8df3\u8fc7\u5e93\u4ee3\u7801\n    \"cwd\": \"${workspaceFolder}\"        // \u8bbe\u7f6e\u5de5\u4f5c\u76ee\u5f55\u4e3a\u9879\u76ee\u6839\u76ee\u5f55\n}\n</code></pre>"},{"location":"sticks/3_vscode/#vscode_2","title":"vscode \u8c03\u8bd5\u76f8\u5173","text":"<p>\uff081\uff09\u8bb0\u5f55\u70b9</p> <ul> <li>\u8fd0\u884c\u4f46\u662f\u4e0d\u505c\u6b62</li> <li><code>{args.model_name}</code>  \u5927\u62ec\u53f7\u5305\u8d77\u6765\u7684\u5185\u5bb9\u4f1a\u81ea\u52a8\u66ff\u6362\u4e3a python \u6587\u4ef6\u4e2d\u7684\u5185\u5bb9</li> </ul> <p>\uff082\uff09\u7981\u7528\u65ad\u70b9</p> <p>case\uff1a\u6709\u65f6\u5019\u65ad\u70b9\u592a\u591a\u4e86\uff0c\u4e00\u70b9\u70b9\u4ece\u5934\u5f00\u59cb\u4e00\u6b65\u6b65\u770b\uff0c\u524d\u9762\u7684\u65ad\u70b9\u660e\u767d\u4e86\uff0c\u5c31\u4e0d\u7528\u770b\u4e86\uff0c\u4f46\u53c8\u4e0d\u60f3\u5220\u9664\u65f6</p> <p></p>"},{"location":"sticks/4_mkdocs/","title":"mkdocs \u5e38\u7528\u547d\u4ee4","text":""},{"location":"sticks/4_mkdocs/#mkdocs","title":"mkdocs \u5e38\u7528\u547d\u4ee4","text":"2025-04-02 15:40:002025-09-28 12:54:07 <p> \u7ea6 87 \u4e2a\u5b57  33 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>https://squidfunk.github.io/mkdocs-material/reference/admonitions/</p>"},{"location":"sticks/4_mkdocs/#_1","title":"\u6298\u53e0\u6846","text":""},{"location":"sticks/4_mkdocs/#_2","title":"\u6587\u672c\u6298\u53e0\u6846","text":"HTML<pre><code>&lt;details&gt;\n&lt;summary&gt;\u8bf4\u660e&lt;/summary&gt;\n&lt;p&gt;\n\u4f60\u60f3\u6298\u53e0\u7684\u4e00\u5927\u6bb5\u5185\u5bb9\n&lt;/p&gt;\n&lt;/details&gt;\n</code></pre> \u5185\u5bb9\u6982\u8981 <p> \u4f60\u60f3\u6298\u53e0\u7684\u4e00\u5927\u6bb5\u5185\u5bb9 </p>"},{"location":"sticks/4_mkdocs/#_3","title":"\u4ee3\u7801\u6298\u53e0\u6846","text":"Markdown<pre><code>&lt;details&gt;\n&lt;summary&gt;\u8bf4\u660e\uff1a&lt;/summary&gt;\n&lt;p&gt;\n```python\n```\n&lt;/p&gt;\n&lt;/details&gt;\n</code></pre> <p>\u6548\u679c\uff1a</p> \u8bf4\u660e\uff1a <p> </p>Python<pre><code>\n</code></pre> <p></p> Old mkdocs.yml <p> </p>YAML<pre><code>\n</code></pre> <p></p>"},{"location":"sticks/4_mkdocs/#_4","title":"\u63cf\u8ff0\u6846","text":"Markdown<pre><code>!!! note\n    This is a note.\n</code></pre> <p>Note</p> <p>This is a note.</p> Markdown<pre><code>??? question \"What is the meaning of life, the universe, and everything?\"\n</code></pre> What is the meaning of life, the universe, and everything? Markdown<pre><code>!!! abstract\n    you can use \n    - note\n    - abstract\n    - info\n    - tip\n    - success\n    - question\n    - warning\n    - failure\n    - danger\n    - bug\n    - example\n    - quote\n</code></pre> Markdown<pre><code>!!! note \"note \u6807\u9898\"\n\n    Lorem \n</code></pre> <p>note \u6807\u9898</p> <p>Lorem </p> Text Only<pre><code>??? note \"\u6298\u53e0 note\"\n\n    Lorem \n</code></pre> \u6298\u53e0 note <p>Lorem </p> Text Only<pre><code>???+ note \"\u9ed8\u8ba4\u5c55\u5f00 note\"\n\n    Lorem \n</code></pre> \u9ed8\u8ba4\u5c55\u5f00 note <p>Lorem </p>"},{"location":"sticks/5_preReproduction/","title":"(\u9010\u6b65\u7cfb\u5217)\u590d\u73b0\u4e4b\u524d","text":""},{"location":"sticks/5_preReproduction/#_1","title":"(\u9010\u6b65\u7cfb\u5217)\u590d\u73b0\u4e4b\u524d","text":"2025-04-13 10:17:212025-09-28 12:54:07 <p> \u7ea6 400 \u4e2a\u5b57  247 \u884c\u4ee3\u7801  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 5 \u5206\u949f</p> <ul> <li>git clone</li> <li> <p>\u4e0b\u8f7d\u6570\u636e\u96c6</p> </li> <li> <p>conda activate\u3001readme\u3001python \u7248\u672c</p> </li> </ul>"},{"location":"sticks/5_preReproduction/#y","title":"\u81ea\u52a8\u786e\u8ba4 y","text":"Bash<pre><code># \u521b\u5efa\u65b0\u7684conda\u73af\u5883\uff08\u81ea\u52a8\u786e\u8ba4\u6240\u6709\u63d0\u793a\uff09\nconda create -n mamba python==3.8 -y\n\n# \u6fc0\u6d3b\u73af\u5883\nconda activate mamba\n\n# \u5b89\u88c5\u517c\u5bb9\u7248\u672c\u7684PyTorch\uff08\u81ea\u52a8\u786e\u8ba4\u6240\u6709\u63d0\u793a\uff09\nconda install pytorch==2.0.0 torchvision torchaudio pytorch-cuda==11.8 -c pytorch -c nvidia -y\n\n### \u7a33\u5b9a\u5b89\u88c5\u65b9\u6cd5# \n# 1. \u901a\u8fc7\u6b64\u547d\u4ee4\u884c\u67e5\u770b\u5b89\u88c5\u7684\u662f\u54ea\u4e2awheel\u6587\u4ef6:\npip install mamba-ssm --no-cache-dir --verbose\n# 2. \u590d\u5236\u7ed9\u5b9a\u7684.wheel\u94fe\u63a5\u5230\u6d4f\u89c8\u5668,\u76f4\u63a5\u4e0b\u8f7d\n# 3. \u7136\u540e\u5728\u5bf9\u5e94\u7684\u73af\u5883\u4e2d\u76f4\u63a5\npip install mamba_ssm-2.2.2+cu118torch2.0cxx11abiFALSE-cp38-cp38-linux_x86_64.whl\n</code></pre>"},{"location":"sticks/5_preReproduction/#_2","title":"\u5b89\u88c5\\\u6fc0\u6d3b","text":"Python<pre><code>conda create -n dave python==3.8\nconda activate dave\nconda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=11.8 -c pytorch -c nvidia\nconda install numpy\nconda install scikit-image\nconda install scikit-learn\nconda install tqdm\nconda install pycocotools\n</code></pre>"},{"location":"sticks/5_preReproduction/#_3","title":"\u8fdb\u5165\\\u9000\u51fa","text":"Python<pre><code># To activate this environment, use               \n#     $ conda activate Autoformer\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n</code></pre>"},{"location":"sticks/5_preReproduction/#requirements","title":"requirements \u5b89\u88c5","text":"Python<pre><code>conda create -n SegRNN python=3.8\nconda activate SegRNN\npip install -r requirements.txt\n</code></pre>"},{"location":"sticks/5_preReproduction/#_4","title":"\u67e5\u770b\u865a\u62df\u73af\u5883\u5217\u8868:","text":"Python<pre><code>conda env list\nconda actiavte \u73af\u5883\u540d\nconda deactivate\n</code></pre>"},{"location":"sticks/5_preReproduction/#_5","title":"\u672c\u5730\u5b89\u88c5:","text":"<p>(1)wheel</p> <ul> <li>\u4e0b\u8f7d(\u8fd9\u79cd\u60c5\u51b5\u53d1\u751f\u5728\u6211\u5b89\u88c5 mamba \u7684\u65f6\u5019,\u4e0b\u8f7d\u65f6,\u4f1a\u663e\u793a\u6b63\u5728\u4e0b\u8f7d\u54ea\u4e2a wheel \u6587\u4ef6,\u76f4\u63a5\u5c06\u6b63\u5728\u4e0b\u8f7d\u7684 url\u94fe\u63a5\u590d\u5236\u5230\u6d4f\u89c8\u5668,\u4f1a\u81ea\u52a8\u4e0b\u8f7d)</li> <li>\u8fdb\u5165\u5230\u6709 wheel \u6587\u4ef6\u7684\u6587\u4ef6\u5939,\u8bb0\u5f97\u4fdd\u8bc1\u5728python\u865a\u62df\u73af\u5883\u4e2d,\u7136\u540e,pip install \u5373\u53ef</li> </ul> Bash<pre><code>pip install mamba_ssm-2.2.2+cu118torch2.0cxx11abiFALSE-cp38-cp38-linux_x86_64.whl\n</code></pre> <ul> <li> (2) git\u5b89\u88c5</li> </ul> Python<pre><code># \u6fc0\u6d3b\u60a8\u7684\u73af\u5883\nconda activate mamba\n\n# \u5378\u8f7d\u73b0\u6709\u7248\u672c\npip uninstall -y mamba-ssm\n\n# \u514b\u9686\u4ed3\u5e93\ngit clone https://github.com/state-spaces/mamba.git\ncd mamba\n\n# \u5b89\u88c5\npip install -e .\n</code></pre> <p>\u6267\u884c pip install -e . \u65f6\uff0cpip \u4f1a\u5728\u5f53\u524d\u76ee\u5f55\u67e5\u627e setup.py \u6587\u4ef6,\u6267\u884c\u8be5\u6587\u4ef6\u4e2d\u7684\u5b89\u88c5\u6307\u4ee4 </p> <ul> <li>\u8c03\u8bd5 sh \u6587\u4ef6</li> </ul> <p>\u8fd9\u91cc\u8981\u5b89\u88c5 python \u5e93\uff1a</p> Python<pre><code>pip install debugpy\n</code></pre> <p>\u4fee\u6539 sh \u6587\u4ef6\uff1a</p> Bash<pre><code>python -u run_longExp.py\n# \u9700\u8981\u624b\u52a8\u70b9\u51fb \u8c03\u8bd5\uff0c\u5f00\u59cb\u8fd0\u884c\npython -m debugpy --listen 5998 --wait-for-client run_longExp.py \n# \u53ef\u4ee5\u79fb\u9664 --wait-for-client \u53c2\u6570\uff0c\u8ba9\u7a0b\u5e8f\u4e0d\u5fc5\u7b49\u5f85\u5ba2\u6237\u7aef\u8fde\u63a5\u5c31\u5f00\u59cb\u8fd0\u884c\npython -m debugpy --listen 5998 run_longExp.py \\\n</code></pre> <p>\u4fee\u6539\u914d\u7f6e\u6587\u4ef6  <code>\"configurations\"</code> </p> JSON<pre><code>        {\n            \"name\": \"[\u8fd9\u91cc\u66f4\u6362\u4e3a\u4efb\u610f\u540d\u79f0]\",\n            \"type\": \"debugpy\",\n            \"justMyCode\": true,\n            \"request\": \"attach\",\n            \"connect\": {\n                \"host\": \"localhost\",\n                \"port\": 5998\n            }\n        },\n</code></pre> <ul> <li>\u65b0\u5efapython \u6587\u4ef6\uff0c\u8c03\u8bd5\u663e\u793a\u5f62\u72b6  </li> </ul> <p>\u5bfc\u5165</p> Python<pre><code>import custom_repr\n</code></pre>   custom_repr.py  Python<pre><code>import torch\nimport pandas as pd\nimport custom_repr\n# -------------------- \u81ea\u5b9a\u4e49\u5305\u88c5\u7c7b --------------------\n\nclass CustomBool:\n    def __init__(self, value):\n        self.value = bool(value)\n\n    def __repr__(self):\n        return f'{{bool}} {self.value}'\n\nclass CustomInt:\n    def __init__(self, value):\n        self.value = int(value)\n\n    def __repr__(self):\n        return f'{{int}} {self.value}'\n\nclass CustomStr:\n    def __init__(self, value):\n        self.value = str(value)\n\n    def __repr__(self):\n        return f'{{str}} {self.value}'\n\n# \u81ea\u5b9a\u4e49 list \u548c dict \u5b50\u7c7b\nclass CustomList(list):\n    def __repr__(self):\n        return f'{{list: {len(self)}}} {super().__repr__()}'\n\nclass CustomDict(dict):\n    def __repr__(self):\n        return f'{{dict: {len(self)}}} {super().__repr__()}'\n\n# \u81ea\u5b9a\u4e49 Tensor \u7684 __repr__ (Torch)\noriginal_tensor_repr = torch.Tensor.__repr__\ndef custom_tensor_repr(self):\n    return f'{{Tensor: {tuple(self.shape)}}} {original_tensor_repr(self)}'\ntorch.Tensor.__repr__ = custom_tensor_repr\n\n# \u81ea\u5b9a\u4e49 DataFrame \u7684 __repr__ (Pandas)\noriginal_dataframe_repr = pd.DataFrame.__repr__\ndef custom_dataframe_repr(self):\n    return f'{{DataFrame: {self.shape}}} {original_dataframe_repr(self)}'\npd.DataFrame.__repr__ = custom_dataframe_repr\n\n# \u81ea\u5b9a\u4e49 DataLoader \u7684\u7c7b\nclass DataLoader:\n    def __init__(self, data_size):\n        self.data_size = data_size\n\n    def __len__(self):\n        return self.data_size\n\n    def __repr__(self):\n        return f'{{DataLoader: {len(self)}}} DataLoader object'\n\n# -------------------- __main__ \u51fd\u6570 --------------------\ndef main():\n    # \u4f7f\u7528\u81ea\u5b9a\u4e49\u7c7b\u578b\u4ee3\u66ff\u539f\u751f\u7c7b\u578b\n    my_list = CustomList([1, 2, 3, 4, 5, 6])\n    my_dict = CustomDict({'a': 1, 'b': 2, 'c': 3})\n    my_bool = CustomBool(True)\n    my_int = CustomInt(42)\n    my_str = CustomStr(\"hello\")\n\n    # \u6d4b\u8bd5 Tensor\n    my_tensor = torch.randn(100, 512)\n\n    # \u6d4b\u8bd5 DataFrame\n    my_dataframe = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n\n    # \u6d4b\u8bd5 DataLoader\n    my_dataloader = DataLoader(220)\n\n    # \u8f93\u51fa\u5185\u5bb9\n    print(my_list)        # {list: 6} [1, 2, 3, 4, 5, 6]\n    print(my_dict)        # {dict: 3} {'a': 1, 'b': 2, 'c': 3}\n    print(my_bool)        # {bool} True\n    print(my_int)         # {int} 42\n    print(my_str)         # {str} 'hello'\n    print(my_tensor)      # {Tensor: (100, 512)} tensor([...])\n    print(my_dataframe)   # {DataFrame: (3, 3)}    A  B  C\n    print(my_dataloader)  # {DataLoader: 220} DataLoader object\n\n# \u5982\u679c\u662f\u76f4\u63a5\u8fd0\u884c\u6587\u4ef6\uff0c\u5219\u8c03\u7528 main \u51fd\u6570\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p></p> <ul> <li>\u5220\u9664 .git\u6587\u4ef6</li> </ul> Python<pre><code>rm -rf .git\n</code></pre> <ul> <li>\u53ef\u9009\uff09 \u7531\u4e8e\u662f fork \u6765\u7684\u4ee3\u7801\uff0c\u4f1a\u4fdd\u7559\u539f\u6709\u4f5c\u8005\u7684\u7248\u672c\u63a7\u5236\u8bb0\u5f55</li> </ul> <p>\u62e5\u6709\u4e00\u4e2a\u5e72\u51c0\u7684\u4ed3\u5e93\uff0c\u5e76\u4e14\u4e0d\u4f1a\u663e\u793a\u539f\u4f5c\u8005\u7684\u7248\u672c\u8bb0\u5f55\uff0c\u540c\u65f6\u53ef\u4ee5\u9009\u62e9\u5730\u662f\u5426\u4ece\u539f\u4ed3\u5e93\u83b7\u53d6\u66f4\u65b0\u3002</p> <p>\uff081\uff09\u5f7b\u5e95\u6e05\u9664\u9879\u76ee\u7684\u6240\u6709\u4e4b\u524d\u7684\u63d0\u4ea4\u5386\u53f2</p> <p>\u5b8c\u5168\u91cd\u65b0\u5f00\u59cb\uff0c\u521b\u5efa\u5168\u65b0\u7684\u4ed3\u5e93 </p> Bash<pre><code># 1. \u5907\u4efd\u5f53\u524d\u4ee3\u7801\ncp -r UnetTSF UnetTSF_backup\n\n# 2. \u5220\u9664\u65e7\u7684 Git \u76ee\u5f55\nrm -rf UnetTSF/.git\n\n# 3. \u521d\u59cb\u5316\u65b0\u7684 Git \u4ed3\u5e93\ncd UnetTSF\ngit init\n\n# 4. \u6dfb\u52a0\u6240\u6709\u6587\u4ef6\u5e76\u63d0\u4ea4\ngit add .\ngit commit -m \"Initial commit: Forked from original repo with modifications\"\n</code></pre> <p>\u4e0e\u6211\u81ea\u5df1\u7684\u8fdc\u7a0b\u4ed3\u5e93\u5173\u8054 </p> Python<pre><code># \u6dfb\u52a0\u4f60\u81ea\u5df1\u7684\u8fdc\u7a0b\u4ed3\u5e93\ngit remote add origin https://github.com/\u4f60\u7684\u7528\u6237\u540d/\u4ed3\u5e93\u540d.git\ngit remote add origin https://github.com/dearRongerr/TSF_Reproduction.git\n# \u63a8\u9001\u4ee3\u7801\ngit push -u origin main  \n</code></pre> <p>\u5982\u679c\u8fd8\u60f3\u4ece\u539f\u59cb\u4ed3\u5e93\u83b7\u53d6\u66f4\u65b0\uff0c\u4fdd\u7559\u539f\u59cb\u4ed3\u5e93\u4f5c\u4e3a\u4e0a\u6e38 </p> Bash<pre><code># \u6dfb\u52a0\u539f\u59cb\u4ed3\u5e93\u4f5c\u4e3a\u4e0a\u6e38\ngit remote add upstream https://github.com/\u539f\u4f5c\u8005/\u539f\u4ed3\u5e93.git\n\n# \u83b7\u53d6\u4e0a\u6e38\u66f4\u65b0\uff08\u5f53\u9700\u8981\u65f6\uff09\ngit fetch upstream\ngit merge upstream/master  # \u6216\u8005 main\n</code></pre> <p>\uff082\uff09\u4fdd\u7559\u5b8c\u6574\u5386\u53f2\u8bb0\u5f55\uff1a\u6240\u6709\u4e4b\u524d\u7684\u63d0\u4ea4\u5386\u53f2\u90fd\u4f1a\u4fdd\u7559 </p> Bash<pre><code># \u67e5\u770b\u5f53\u524d\u8fdc\u7a0b\u4ed3\u5e93\ngit remote -v\n# \u663e\u793a\u7ed3\u679c\u901a\u5e38\u4e3a\uff1a\n# origin   https://github.com/\u539f\u4f5c\u8005/\u539f\u4ed3\u5e93.git (fetch)\n# origin   https://github.com/\u539f\u4f5c\u8005/\u539f\u4ed3\u5e93.git (push)\n\n# \u79fb\u9664\u539f\u59cb\u7684\u8fdc\u7a0b\u4ed3\u5e93\u5f15\u7528\ngit remote rm origin\n\n# \u6dfb\u52a0\u4f60\u81ea\u5df1\u7684\u4ed3\u5e93\u4f5c\u4e3a\u65b0\u7684 origin\ngit remote add origin https://github.com/\u4f60\u7684\u7528\u6237\u540d/\u4f60\u7684\u4ed3\u5e93.git\n\n# \u6dfb\u52a0\u539f\u4f5c\u8005\u7684\u4ed3\u5e93\u4f5c\u4e3a upstream (\u65b9\u4fbf\u65e5\u540e\u540c\u6b65\u66f4\u65b0)\ngit remote add upstream https://github.com/\u539f\u4f5c\u8005/\u539f\u4ed3\u5e93.git\n</code></pre> <p>\u66f4\u65b0 .gitignore \u6587\u4ef6 </p> Bash<pre><code># Python \u7f13\u5b58\u6587\u4ef6\n__pycache__/\n*.py[cod]\n*$py.class\n.pytest_cache/\n.coverage\nhtmlcov/\n\n# \u865a\u62df\u73af\u5883\nvenv/\nenv/\nENV/\n\n# \u5206\u5e03\u5f0f\u8bad\u7ec3\n*.out\n*.err\n*.log\n\n# \u6a21\u578b\u68c0\u67e5\u70b9\u548c\u7ed3\u679c\ncheckpoints/\nresults/\n*.pth\n*.pt\n*.bin\n*.h5\n\n# \u4e34\u65f6\u6587\u4ef6\n.ipynb_checkpoints\n.DS_Store\n.idea/\n.vscode/\n\n# \u6570\u636e\u6587\u4ef6 (\u6839\u636e\u9700\u8981\u8c03\u6574)\n*.csv\n*.tsv\n*.pkl\n*.npy\n</code></pre>"},{"location":"sticks/5_preReproduction/#_6","title":"\u6a21\u578b\u4fee\u6539\u4e0e\u7248\u672c\u63a7\u5236","text":"Python<pre><code># \u8fdb\u884c\u591a\u6b21\u63d0\u4ea4\u5f00\u53d1\u4e00\u4e2a\u7279\u6027\ngit commit -m \"\u521d\u59cb\u5316\u591a\u5c3a\u5ea6\u5377\u79ef\u7ed3\u6784\"\ngit commit -m \"\u6dfb\u52a0\u81ea\u6ce8\u610f\u529b\u673a\u5236\"\ngit commit -m \"\u4f18\u5316\u7279\u5f81\u878d\u5408\u65b9\u6cd5\"\ngit commit -m \"\u5b8c\u6210\u591a\u5c3a\u5ea6\u65f6\u95f4\u5377\u79ef\u4e0e\u6ce8\u610f\u529b\u673a\u5236\"\n\n# \u7279\u6027\u5b8c\u6210\u540e\uff0c\u6253\u4e00\u4e2a\u6807\u7b7e\ngit tag -a feature-multiscale-complete -m \"\u591a\u5c3a\u5ea6\u65f6\u95f4\u5377\u79ef\u4e0e\u6ce8\u610f\u529b\u673a\u5236\u5b8c\u6574\u5b9e\u73b0\"\n\n# \u8fd0\u884c\u5b9e\u9a8c\u540e\uff0c\u6807\u8bb0\u7ed3\u679c\ngit tag -a exp-etth1-96h-mae0.412 -m \"ETTh1\u6570\u636e\u96c696\u5c0f\u65f6\u9884\u6d4b\u6700\u4f73\u7ed3\u679c\"\n</code></pre> <p>\u63d0\u4ea4&amp;\u6253\u6807\u7b7e</p> <p>\u6807\u7b7e\u662f\u5bf9\u63d0\u4ea4\u7684\u5f15\u7528\uff0c\u6240\u4ee5\u5fc5\u987b\u5148\u6709\u63d0\u4ea4\u624d\u80fd\u6253\u6807\u7b7e</p> Bash<pre><code># \u9996\u5148\u63d0\u4ea4\u4ee3\u7801\ngit add models/Time_Unet.py\ngit commit -m \"\u5b8c\u6210\u591a\u5c3a\u5ea6\u65f6\u95f4\u5377\u79ef\u4e0e\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\"\n\n# \u7136\u540e\u5728\u8fd9\u4e2a\u63d0\u4ea4\u4e0a\u6253\u6807\u7b7e\ngit tag -a v0.1-multiscale -m \"\u591a\u5c3a\u5ea6\u65f6\u95f4\u5377\u79ef\u7279\u6027\u5b8c\u6210\"\n</code></pre>"},{"location":"sticks/6_0_docker/","title":"(\u9010\u6b65\u7cfb\u5217)docker","text":""},{"location":"sticks/6_0_docker/#docker","title":"(\u9010\u6b65\u7cfb\u5217)docker","text":"2025-04-20 14:04:312025-09-28 12:54:07 <p> \u7ea6 65 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>\u573a\u666f\u63cf\u8ff0:</p> <p>\u672c\u5730\u62c9\u53d6,\u670d\u52a1\u5668\u8fd0\u884c,\u6302\u8f7d\u76ee\u5f55</p> <p>\u5927\u4f53\u601d\u8def\u662f:</p> <ul> <li>\u5148\u627e\u76ee\u6807\u955c\u50cf</li> <li>\u672c\u5730 pull</li> <li>\u672c\u5730\u6253\u5305\u6210 tar \u5305?</li> <li>\u4e0a\u4f20\u670d\u52a1\u5668</li> <li>\u670d\u52a1\u5668 load?</li> </ul> <p>(1)\u627e\u955c\u50cf:</p> <ul> <li>[dockerhub]</li> </ul> <p>\u627e\u5230\u7b26\u5408\u8981\u6c42\u7684</p> <p>(2)</p>"},{"location":"sticks/7_vercel/","title":"gitpages+vercel \u9759\u6001\u7f51\u9875\u6258\u7ba1","text":""},{"location":"sticks/7_vercel/#gitpagesvercel","title":"gitpages+vercel \u9759\u6001\u7f51\u9875\u6258\u7ba1","text":"2025-05-02 19:25:402025-09-28 12:54:07 <p> \u7ea6 26 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4\u4e0d\u5230 1 \u5206\u949f</p> <p>vercel\u5b98\u7f51:https://vercel.com/</p> <p>start by:this</p> <p>\u5982\u4f55\u5c06MKdocs\u90e8\u7f72\u5230Vercel\uff1f</p> <p>\u9a6c\u4e0a\u8d85 1GB\ud83e\udd72\u5bb3</p>"},{"location":"sticks/GitHub/","title":"Git\u5b66\u4e60","text":""},{"location":"sticks/GitHub/#git","title":"Git\u5b66\u4e60","text":"2024-12-19 18:20:132025-09-28 12:54:07 <p> \u7ea6 2722 \u4e2a\u5b57  13 \u884c\u4ee3\u7801  110 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 14 \u5206\u949f</p> <p>\u65b0\u5efa\u4ed3\u5e93\uff1a</p> Python<pre><code>echo \"# Rongerr.github.io\" &gt;&gt; README.md\ngit init\ngit add README.md\ngit commit -m \"first commit\"\ngit branch -M main\ngit remote add origin https://github.com/dearRongerr/Rongerr.github.io.git\ngit push -u origin main\n</code></pre> <p>\u5411\u5df2\u6709\u4ed3\u5e93\u63a8\u9001</p> Python<pre><code>git remote add origin https://github.com/dearRongerr/Rongerr.github.io.git\ngit branch -M main\ngit push -u origin main\n</code></pre>"},{"location":"sticks/GitHub/#_1","title":"\u65b0\u5efa\u4ed3\u5e93","text":"<p>1\u3001\u67e5\u770b git \u7248\u672c</p> <p></p> <p>2\u3001\u521d\u59cb\u5316\u4ed3\u5e93\uff08\u65b0\u5efa\u4ed3\u5e93\uff09</p> <p></p> <p>3\u3001\u5220\u9664\u4e86 <code>.git</code> \u4e5f\u5c31\u662f\u5220\u9664\u4e86\u4ed3\u5e93</p> <p></p> <p>4\u3001git init \u6307\u5b9a\u53c2\u6570\uff0c\u8868\u793a\u5728\u54ea\u513f\u521d\u59cb\u5316\u4e00\u4e2a\u65b0\u7684\u4ed3\u5e93</p> <p></p> <p>\u6ce8\u610f\u770b\u7eff\u8272\u7684\u5206\u652f\uff08\u600e\u4e48\u90a3\u4e48\u4e11\uff0c\u7b97\u4e86\uff0c\u65e0\u6240\u8c13\uff09</p> <p>5 <code>git clone</code> \u65b0\u5efa\u4ed3\u5e93</p> <p></p> <p>\u6709 <code>.git</code> \u6587\u4ef6\uff0c\u5c31\u662f\u4e00\u4e2a\u8fdc\u7a0b\u4ed3\u5e93</p>"},{"location":"sticks/GitHub/#_2","title":"\u5de5\u4f5c\u533a\u57df\u548c\u6587\u4ef6\u72b6\u6001","text":"<p>link</p> <p></p>"},{"location":"sticks/GitHub/#_3","title":"\u6dfb\u52a0\u548c\u63d0\u4ea4\u6587\u4ef6","text":"<ul> <li>git \u652f\u6301\u4f7f\u7528\u901a\u914d\u7b26\uff0c\u5c06\u6587\u4ef6\u6dfb\u52a0\u5230\u6682\u5b58\u533a</li> </ul> <ul> <li><code>git add .</code>  \u63d0\u4ea4\u5f53\u524d\u6587\u4ef6\u5939\u4e0b\u7684\u6240\u6709\u6587\u4ef6</li> </ul>"},{"location":"sticks/GitHub/#_4","title":"\u67e5\u770b\u63d0\u4ea4\u8bb0\u5f55","text":"<p>git log\uff1a\u67e5\u770b\u590d\u6742\u7684\u63d0\u4ea4\u8bb0\u5f55</p> <p>git log --oneline \uff1a\u67e5\u770b\u7b80\u6d01\u7684\u63d0\u4ea4\u8bb0\u5f55</p> <p></p> <p></p> <p>\u6bcf\u6b21\u63d0\u4ea4\u90fd\u6709\u4e00\u4e2a <code>id</code> \u53f7</p> <p>\u7b2c\u4e09\u4e2a\u63d0\u4ea4\u65f6\uff0c\u76f4\u63a5\u8f93\u5165\u7684 <code>git commit</code>\uff0c\u4f1a\u8fdb\u5165 <code>vim</code> \u63d0\u793a\u8f93\u5165\u63d0\u4ea4\u4fe1\u606f</p> <p>\u6309\u952e\u76d8 <code>i</code>  \u8fdb\u5165\u7f16\u8f91\u6a21\u5f0f</p> <p>\u7f16\u8f91\u5b8c\u4ee5\u540e\uff0c\u6309\u952e\u76d8 <code>esc</code>\uff0c\u56de\u5230\u547d\u4ee4\u884c\u6a21\u5f0f\uff0c</p> <p>\u7136\u540e\u8f93\u5165<code>:wq</code> \u4fdd\u5b58\u7f16\u8f91\u7684\u5185\u5bb9</p>"},{"location":"sticks/GitHub/#_5","title":"\u914d\u7f6e\u4f5c\u8005\u4fe1\u606f","text":"<ul> <li>Author \u7684\u4fe1\u606f\uff0c\u5305\u62ec username \u548c\u90ae\u7bb1\u662f\u901a\u8fc7 <code>git config</code> \u914d\u7f6e\u7684\uff1a</li> </ul> <p>\u8fd9\u91cc\uff0c\u56e0\u4e3a\u7528\u6237\u540d\u4e2d\u95f4\u6709\u7a7a\u683c\uff0c\u6240\u4ee5\u4f7f\u7528\u53cc\u5f15\u53f7\u62ec\u8d77\u6765</p> <p>\u914d\u7f6e\u5b8c\u7528\u6237\u540d\u53ef\u4ee5\u914d\u7f6e\u90ae\u7bb1\uff1a</p> <p></p> <p>\u56e0\u4e3a\u90ae\u7bb1\u4e2d\u95f4\u6ca1\u6709\u7a7a\u683c \uff0c\u6240\u4ee5\u53ef\u4ee5\u7701\u7565\u6389\u53cc\u5f15\u53f7</p> <p></p>"},{"location":"sticks/GitHub/#git-reset","title":"git reset","text":"<p>\u56de\u9000\u7248\u672c</p> <p></p> <p>\u5de5\u4f5c\u533a \u300b\u300b\u6682\u5b58\u533a\u300b\u300b\u672c\u5730\u4ed3\u5e93\uff08\u771f\u6b63\u63d0\u4ea4\u4fdd\u5b58\u8d77\u6765\uff09</p> <p>\u793a\u4f8b\uff1a</p> <p></p> <p>\u67e5\u770b\u5de5\u4f5c\u533a\u7684\u5185\u5bb9\uff1a<code>ls</code></p> <p>\u67e5\u770b\u6682\u5b58\u533a\u7684\u5185\u5bb9\uff1a<code>git ls-files</code></p> <p>\u4e09\u4e2a\u6587\u4ef6\uff0c\u4e09\u6b21\u63d0\u4ea4</p> <p></p> <p></p> <p></p> <ul> <li>git reset --soft  ##\u56de\u9000\u7684\u7248\u672c id##</li> </ul> <p>\u00d7\uff1a</p> <p></p> <p></p> <p>\u221a</p> <p></p> <p>git log --oneline:</p> <p></p> <p>\u5934\u6307\u9488\u7684\u4f4d\u7f6e\u4e5f\u53d8\u4e86</p> <ul> <li>git reset --hard HEAD^ (hard reset \u56de\u9000\u5230\u4e0a\u4e00\u4e2a\u7248\u672c)</li> </ul> <p></p> <p></p> <p>hard \u6a21\u5f0f\uff0c\u5de5\u4f5c\u533a\u6587\u4ef6\u88ab\u5220\u4e86\uff0c\u6682\u5b58\u533a\u6587\u4ef6\u4e5f\u88ab\u5220\u4e86\uff0c\u63d0\u4ea4\u5386\u53f2\u4e5f\u53ea\u5269\u4e0b\u4e00\u4e2a\u4e86</p> <p></p> <p>\u5f53\u4f7f\u7528 hard \u53c2\u6570\u56de\u9000\u5230\u4e0a\u4e00\u4e2a\u7248\u672c\u7684\u65f6\u5019\uff0c\u5de5\u4f5c\u533a\u548c\u6682\u5b58\u533a\u7684\u5185\u5bb9\u90fd\u4f1a\u88ab\u6e05\u7a7a</p> <ul> <li>\u9ed8\u8ba4 mixed \u6a21\u5f0f</li> </ul> <p></p> <p>git add \u5230\u6682\u5b58\u533a</p> <p>git commit \u5230\u4ed3\u5e93</p> <p>git reset --soft \u64a4\u9500 git commit \u64cd\u4f5c\uff08\u56de\u5230\u6682\u5b58\u533a\uff09</p> <p>git reset --hard \u5220\u9664\u5de5\u4f5c\u533a\u548c\u6682\u5b58\u533a\uff08\u5de5\u4f5c\u533a\u4e5f\u6ca1\u4e86\uff09</p> <p>git reset --mixed \u4fdd\u5b58\u5de5\u4f5c\u533a\uff0c\u5220\u9664\u6682\u5b58\u533a\uff08\u56de\u5230\u5de5\u4f5c\u533a\uff09</p>"},{"location":"sticks/GitHub/#git-reflog","title":"\u8bef\u64cd\u4f5c git reflog","text":"<p>git \u4fdd\u5b58\u6240\u6709\u64cd\u4f5c\uff0c\u4f7f\u7528 git reflog \u67e5\u770b\u6240\u6709\u64cd\u4f5c\u5bf9\u5e94\u7684\u7248\u672c\u53f7</p> <p></p> <p>\u56de\u5230\u5bf9\u5e94\u7684\u7248\u672c\uff1a</p> <p></p> <p>git log --oneline\u67e5\u770b\u5f53\u524d\u6240\u5904\u7684\u7248\u672c</p> <p></p> <p></p>"},{"location":"sticks/GitHub/#git-diff","title":"git diff","text":"<p>\u67e5\u770b\u5dee\u5f02</p>"},{"location":"sticks/GitHub/#git-rm","title":"git rm","text":"<p>\u5220\u9664\u6587\u4ef6</p> <p>\uff081\uff09\u67e5\u770b\u672c\u5730\u4ed3\u5e93\u4e2d\u7684\u5185\u5bb9</p> <p></p> <p>\uff082\uff09\u5220\u9664\u6587\u4ef6 1</p> <p></p> <p>\uff083\uff09\u67e5\u770b\u4ed3\u5e93\u72b6\u6001\uff0c\u663e\u793a\u6587\u4ef6 1 \u5df2\u7ecf\u88ab\u5220\u9664\u4e86</p> <p></p> <p>\uff084\uff09\u8fd9\u91cc\u6d89\u53ca\u5230\u4e00\u4e2a\u95ee\u9898\uff0c\u672c\u5730\u5de5\u4f5c\u533a\u7684\u6587\u4ef6\u5df2\u7ecf\u88ab\u5220\u9664\u4e86\uff0c\u4f46\u662f\u6682\u5b58\u533a\u7684\u6587\u4ef6\u8fd8\u6ca1\u6709\u5220\u9664</p> <ul> <li>\u8fd9\u91cc\u4e5f\u662f\u63d0\u793a\uff0c\u9700\u8981\u66f4\u65b0\u6682\u5b58\u533a</li> </ul> <p></p> <ul> <li>git ls-files \u67e5\u770b\u6682\u5b58\u533a\u7684\u5185\u5bb9</li> </ul> <p></p> <ul> <li>\u56e0\u6b64\u6267\u884c git add \u64cd\u4f5c\uff0c\u544a\u8bc9 git\uff0c\u6211\u4eec\u5df2\u7ecf\u5220\u9664\u4e86\u6587\u4ef6 1</li> </ul> <p>\u53ef\u4ee5\u6267\u884c <code>git add .</code>  \u6216\u8005\u6267\u884c <code>git add file1.txt</code></p> <p>\u518d\u6b21\u67e5\u770b\u6682\u5b58\u533a\u7684\u5185\u5bb9</p> <p></p> <p></p> <ul> <li> <p>\u603b\u7ed3\uff1a\u8fd9\u79cd\u4ece\u672c\u5730\u5220\u9664\u6587\u4ef6\uff0c\u518d\u544a\u8bc9\u6682\u5b58\u533a\u5df2\u7ecf\u5220\u9664\u4e86\u6587\u4ef6\u7684\u505a\u6cd5\u5341\u5206\u590d\u6742\uff0c\u56e0\u6b64 git rm \u547d\u4ee4</p> </li> <li> <p>\u5220\u9664\u6587\u4ef6 2\uff0c\u67e5\u770b\u6682\u5b58\u533a\uff0c\u5de5\u4f5c\u533a\uff0cgit status</p> </li> </ul> <p></p> <p></p> <p></p> <p>\u603b\u7ed3\uff0c\u53ea\u9700\u8981\u6267\u884c\u4e00\u6b21 git rm \u547d\u4ee4\uff0cgit \u5c31\u80fd\u628a\u6587\u4ef6\u4ece\u5de5\u4f5c\u533a\u548c\u6682\u5b58\u533a\u540c\u65f6\u5220\u9664</p> <ul> <li>\u6700\u540e\u6267\u884c\u63d0\u4ea4\uff0c\u4ece\u7248\u672c\u5e93\u4e2d\u4e5f\u5220\u9664\u6389</li> </ul> <p></p> <ul> <li>\u603b\u7ed3\uff1a</li> </ul> <p></p>"},{"location":"sticks/GitHub/#gitignore","title":".gitignore","text":"<p>\u544a\u8bc9 git \u4e0d\u5e94\u8be5\u6dfb\u52a0\u5230\u7248\u672c\u5e93\u4e2d\u7684\u6587\u4ef6</p> <p>\u5de5\u4f5c\u533a\u300b\u300b\u6682\u5b58\u533a\u300b\u300b\u7248\u672c\u5e93</p> <p></p> <ul> <li>\u73b0\u6709\u4e24\u4e2a\u65e5\u5fd7\u6587\u4ef6\uff0caccess.log  \u3001 other_access.log</li> </ul> <p>\u5c06access.log\u6dfb\u52a0\u5230 .gitignore\u6587\u4ef6</p> <p></p> <ul> <li>git status \u67e5\u770b\u72b6\u6001</li> </ul> <p></p> <p>\u5df2\u7ecf\u770b\u4e0d\u5230 access.log \u6587\u4ef6\u4e86\uff0c\u63a5\u4e0b\u6765\u6267\u884c\uff0c\u6dfb\u52a0\u5230\u6682\u5b58\u533a\uff0c\u63d0\u4ea4\u5230\u7248\u672c\u5e93\uff0c</p> <p></p> <ul> <li><code>.gitignore</code>\u4e2d\u5199 <code>\"*.log\"</code>\uff0c\u901a\u914d\u7b26\u5ffd\u7565\u6389\u6240\u6709 .log\u6587\u4ef6</li> <li>\u9700\u8981\u6ce8\u610f\u7684\u4e00\u70b9\u662f\uff0c<code>.gitignore</code>\u5ffd\u7565\u6389\u7684\u6587\u4ef6\u662f \u8fd8\u6ca1\u6709\u88ab\u6dfb\u52a0\u5230\u7248\u672c\u5e93\u4e2d\u7684\u6587\u4ef6\uff0c\u90a3\u6b64\u65f6\uff0c\u5982\u679c\u60f3\u628a\u5df2\u7ecf\u4e0a\u4f20\u5230\u7248\u672c\u5e93\u4e2d\u7684 log \u6587\u4ef6\uff0c\u4ece\u7248\u672c\u5e93\u4e2d\u5220\u9664\uff0c\u5374\u4e0d\u4ece\u672c\u5730\u5220\u9664\u5e94\u8be5\u600e\u4e48\u529e\u5462\uff1f</li> </ul> <p>\uff081\uff09\u4f7f\u7528 <code>git rm --cached other.log</code>\uff0c\u5c06\u60f3\u8981\u5ffd\u7565\u7684\u65e5\u5fd7\u6587\u4ef6\u4ece\u6682\u5b58\u533a\u5220\u9664</p> <p></p> <p>\uff082\uff09\u67e5\u770b\u5de5\u4f5c\u533a\u6587\u4ef6\uff0c\u65e5\u5fd7\u6587\u4ef6\u8fd8\u5728\uff0c\u6b64\u65f6\u518d\u63d0\u4ea4\u5230\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u518d\u4fee\u6539 <code>other.log</code>\u6587\u4ef6\uff0c\u6b64\u65f6 <code>git status</code> \u67e5\u770b\u4ed3\u5e93\u72b6\u6001\uff0c\u4ed3\u5e93\u4e5f\u662f\u6ca1\u6709\u4efb\u4f55\u53d8\u5316\u7684\u3002</p> <ul> <li>git\u4e0d\u4f1a\u8ffd\u8e2a\u7a7a\u6587\u4ef6\u5939</li> </ul> <p></p> <ul> <li>\u5728\u7a7a\u6587\u4ef6\u5939\u4e0b\u65b0\u5efa\u4e00\u4e2a\u6587\u4ef6\uff0cgit status \u67e5\u770b\u6587\u4ef6\u72b6\u6001\uff0c\u663e\u793a\u6587\u4ef6\u88ab\u8ffd\u8e2a\u5230\u4e86</li> </ul> <p></p> <ul> <li>linux\u547d\u4ee4</li> </ul> <p></p> <ul> <li><code>vi .gitignore</code> \u6587\u4ef6\uff0c\u5c06 <code>temp/</code>\u6587\u4ef6\u5939\u6dfb\u52a0\u5230<code>.gitignore</code>\u4e2d\uff0cgit \u4f1a\u5ffd\u7565\u6389\u6574\u4e2a\u6587\u4ef6\u5939</li> </ul> <p></p> <ul> <li>git status -s \u67e5\u770b\u4ed3\u5e93\u72b6\u6001\uff0c\u7b80\u7565\u663e\u793a</li> </ul> <p></p> <p>\u663e\u793a gitignore \u6587\u4ef6\u88ab\u4fee\u6539\u8fc7</p> <ul> <li>git commit -am</li> </ul> <p></p> <p>\uff081\uff09\u6587\u4ef6**a.txt\u5904\u4e8e\u5df2\u8ddf\u8e2a**\uff0c\u4f46\u672a\u6682\u5b58\u72b6\u6001\u3002\u8fd9\u65f6\uff0c\u5982\u679c\u4f7f\u7528**git commit -m\u662f\u65e0\u6cd5\u63d0\u4ea4\u6700\u65b0\u7248\u672c\u7684a.txt\u7684**\uff0c\u63d0\u4ea4\u7684\u53ea\u662f\u6700\u5f00\u59cb\u7a7a\u5185\u5bb9\u7684\u65e7\u7248\u672ca.txt</p> <p>\uff082\uff09\u8981\u63d0\u4ea4**\u65b0\u7248\u672ca.txt**\uff0c\u5373\u5185\u5bb9\u4e3a**'a'\u7684a.txt**\uff0c\u5219\u9700\u8981\u4f7f\u7528**git add a.txt**\uff0c\u5c06\u65b0\u7248\u672c\u7684a.txt\u653e\u5230staged\u6682\u5b58\u533a\uff0c\u7136\u540e\u624d\u80fd\u4f7f\u7528git commit -m\u8fdb\u884c\u63d0\u4ea4</p> <p>\uff083\uff09\u800c\u5982\u679c\u4f7f\u7528**git commit -am**\uff0c\u5219\u53ef\u4ee5\u7701\u7565**git add a.txt**\u8fd9\u4e00\u6b65\uff0c\u56e0\u4e3a**git commit -am\u53ef\u4ee5\u63d0\u4ea4\u8ddf\u8e2a\u8fc7\u7684\u6587\u4ef6**\uff0c\u800ca.txt\u4e00\u5f00\u59cb\u5df2\u7ecf\u88ab\u8ddf\u8e2a\u8fc7\u4e86</p>"},{"location":"sticks/GitHub/#ssh","title":"SSH\u914d\u7f6e\u548c\u514b\u9686\u4ed3\u5e93","text":"<ul> <li>\u65b0\u5efa\u8fdc\u7a0b\u4ed3\u5e93</li> </ul> <ul> <li>\u6dfb\u5199\u4ed3\u5e93\u540d\u79f0</li> </ul> <p>\u53ef\u9009\uff1a\u9879\u76ee\u63cf\u8ff0\u3001\u662f\u5426\u6dfb\u52a0 gitignore \u6587\u4ef6\uff0creadme\u6587\u4ef6</p> <p>\uff081\uff09\u5982\u679c\u672c\u5730\u6ca1\u6709\u4ed3\u5e93\uff0c\u6267\u884c\u5982\u4e0b\u547d\u4ee4\uff0c\u5728\u672c\u5730\u521b\u5efa\u4ed3\u5e93\u5e76\u548c\u8fdc\u7a0b\u4ed3\u5e93\u5173\u8054\u8d77\u6765</p> <p></p> <p>\uff082\uff09\u5982\u679c\u672c\u5730\u6709\u4ed3\u5e93</p> <p></p> <ul> <li>\u8fdc\u7a0b\u5730\u5740\u7684\u4e24\u79cd\u65b9\u5f0f\uff1a</li> </ul> <p></p> <p>\uff081\uff09HTTPS\uff0c\u5728\u628a\u672c\u5730\u4ed3\u5e93\u7684\u4ee3\u7801 push \u5230\u8fdc\u7a0b\u4ed3\u5e93\u7684\u65f6\u5019\uff0c\u9700\u8981\u9a8c\u8bc1\u7528\u6237\u540d\u548c\u5bc6\u7801</p> <p>\uff082\uff09SSH\uff0cgit \u5f00\u5934\u7684\u662f SSH \u534f\u8bae\uff0c\u8fd9\u79cd\u65b9\u5f0f\u5728\u63a8\u9001\u7684\u65f6\u5019\uff0c\u4e0d\u9700\u8981\u9a8c\u8bc1\u7528\u6237\u540d\u548c\u5bc6\u7801\uff0c\u4f46\u662f\u9700\u8981\u5728 github \u4e0a\u6dfb\u52a0SSH\u516c\u94a5\u7684\u914d\u7f6e\uff08\u63a8\u8350\uff09</p> <ul> <li>\u914d\u7f6e SSH\u79d8\u94a5</li> </ul> <p>\uff081\uff09\u672c\u5730  \u4f7f\u7528 SHH \u514b\u9686 \u8fdc\u7a0b\u4ed3\u5e93</p> Bash<pre><code>git clone git@github.com:dearRongerr/remote_repo.git\n</code></pre> <p></p> <p>\u62a5\u9519\u662f\u56e0\u4e3a\u6ca1\u6709\u914d\u7f6e SSH \u79d8\u94a5\u5bfc\u81f4\u7684\uff0c\u4f7f\u7528 SSH \u7684\u65b9\u5f0f\u5fc5\u987b\u914d\u7f6e SSH \u7684\u79d8\u94a5</p> <p>\uff082\uff09\u56de\u5230\u6839\u76ee\u5f55\uff0c\u8fdb\u5165 .ssh\u76ee\u5f55</p> <p></p> <p>\uff083\uff09\u4f7f\u7528 ssh key generate \u751f\u6210\u79d8\u94a5\uff0c-t \u8868\u793a\u6307\u5b9a\u534f\u8bae\u4e3aRSA\uff0c-b \u6307\u5b9a\u751f\u6210\u5927\u5c0f\u4e3a 4096 </p> Batchfile<pre><code>ssh-keygen -t rsa -b 4096\n</code></pre> <p></p> <p>\uff084\uff09\u4f1a\u63d0\u793a\u8f93\u5165\u79d8\u94a5\u540d\u79f0 </p> <p></p> <p>\ud83d\udfe2 \u5982\u679c\u662f\u7b2c\u4e00\u6b21\u751f\u6210\u79d8\u94a5\uff0c\u90a3\u4e48\u76f4\u63a5\u56de\u8f66\uff0c\u5c31\u4f1a\u751f\u6210\u4e00\u4e2a <code>id_rsa</code> \u5bc6\u94a5\u6587\u4ef6</p> <p>\ud83d\udfe2 \u5982\u679c\u4e4b\u524d\u5df2\u7ecf\u751f\u6210\u8fc7\u4e86\uff0c\u9700\u8981\u91cd\u65b0\u547d\u540d\u4e00\u4e2a\u6587\u4ef6\uff0c\u5426\u5219\u4f1a\u8986\u76d6\u6389\u4e4b\u524d\u7684\u5bc6\u94a5\u6587\u4ef6\uff0c\u5e76\u4e14\u64cd\u4f5c\u4e0d\u53ef\u9006</p> <p>\u8fd9\u91cc\u91cd\u65b0\u547d\u540d\u4e86\u4e00\u4e2a\u540d\u4e3a test \u7684\u6587\u4ef6\u540d\uff0c\u56de\u8f66\u786e\u5b9a\u8f93\u5165\uff0c\u540e\u9762\u8f93\u5165\u5bc6\u7801\uff0c\u751f\u6210\u79d8\u94a5</p> <p>\ud83d\udfe2 \u5982\u679c\u4e0d\u8bbe\u7f6e\u5bc6\u7801\uff0c\u5c31\u76f4\u63a5\u56de\u8f66\u4e0d\u8f93\u5165\u5bc6\u7801\u5373\u53ef</p> <p></p> <p>\uff084\uff09\u67e5\u770b\u672c\u5730\u76ee\u5f55</p> <p></p> <p></p> <p>\u4e00\u4e2a test\uff0c\u79c1\u94a5\u6587\u4ef6\uff0c\u8c01\u8981\u4e5f\u4e0d\u7ed9</p> <p>\u4e00\u4e2a test.pub\uff0c\u516c\u94a5\u6587\u4ef6\uff0c\u4e0a\u4f20\u5230github</p> <p>(5) \u6253\u5f00\u516c\u94a5\u6587\u4ef6\uff0c\u590d\u5236\u516c\u94a5\u6587\u4ef6\u7684\u5185\u5bb9</p> <p></p> <p> </p> <p></p> <p>vi\u6253\u5f00\u516c\u94a5\u6587\u4ef6\uff0c\u590d\u5236\u5185\u5bb9</p> <p>\uff086\uff09\u56de\u5230 github--&gt;setting--&gt;SSH and GPG keys --&gt;New SSH key--&gt;\u7c98\u8d34\u516c\u94a5\u5185\u5bb9\u5230\u8f93\u5165\u6846\u4e2d\uff0c\u6807\u9898\u8f93\u5165\u4efb\u610f\u540d\u5b57\u5373\u53ef--&gt;Add SSH Key </p> <p></p> <p></p> <p></p> <p></p> <p>\uff087\uff09</p> <ul> <li>\u5982\u679c\u5728\u751f\u6210\u79d8\u94a5\u6587\u4ef6\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u7684\u662f\u9ed8\u8ba4\u540d\u79f0\uff0c\u90a3\u4e48\u79d8\u94a5\u914d\u7f6e\u5c31\u5df2\u7ecf\u7ed3\u675f\u4e86</li> <li>\u7531\u4e8e\u6f14\u793a\u4e2d\u751f\u6210\u5bc6\u94a5\u6587\u4ef6\u65f6\uff0c\u547d\u540d\u4e86 test\u5bc6\u94a5\u6587\u4ef6\uff0c\u6240\u4ee5\u9700\u8981\u518d\u6b21\u914d\u7f6e\uff1a</li> </ul> <p>\u521b\u5efa congifg\u6587\u4ef6\uff0c\u5e76\u628a\u4e0b\u9762\u7684 5 \u884c\u6dfb\u52a0\u5230 config \u6587\u4ef6\u4e2d<code>tail -5 config</code> \uff0c\u786e\u4fdd\u5728\u8bbf\u95eegithub.com \u7684\u65f6\u5019\uff0c\u6307\u5b9a\u4f7f\u7528SSH \u4e0b\u7684 test \u79d8\u94a5</p> Bash<pre><code>tail -5 config\n</code></pre> <p></p> <p>\ud83d\udd34 \u6211\u90a3\u5947\u5947\u602a\u602a\u7684\u9519\u8bef</p> <p>\u95ee\u9898\u63cf\u8ff0\uff1a</p> <p>\u751f\u6210\u5bc6\u94a5\u65f6\uff0c\u60f3\u751f\u6210 test.pub \u7684\u5bc6\u7801\uff0c\u6267\u884c <code>tail -5 config</code> \u53bb\u627e test.pub\u79d8\u94a5\uff0c\u7ed3\u679c\u51fa\u73b0\u4e86\u6211\u4e0d\u8ba4\u8bc6\u7684\u4ee3\u7801</p> <p>\u60f3\u7740\uff0c\u4e5f\u8bb8\u662f\u56e0\u4e3a\u6211\u4ece\u6765\u6ca1\u6709\u751f\u6210\u8fc7\u79d8\u94a5\uff0c\u6240\u4ee5\u6267\u884c\u751f\u6210\u5bc6\u94a5\u6587\u6863\u65f6\uff0c\u76f4\u63a5\u4e00\u8def\u56de\u8f66\u3002</p> <p>\ud83d\udfe2 \u4f7f\u7528\u9ed8\u8ba4\u79d8\u94a5\u914d\u7f6e\u6210\u529f\u4e86\u3002</p> <p></p> <p>\u4f7f\u7528\u9ed8\u8ba4\u79d8\u94a5\uff0c\u4e0d\u9700\u8981\u6267\u884c <code>tail -5 config</code></p> <p></p> <p>(8) \u4ee5\u4e0a\u914d\u7f6e\u5b8c\u6210\uff0c\u56de\u5230\u672c\u5730\u4ed3\u5e93\uff0c\u6267\u884c git clone \u547d\u4ee4\uff0c\u4f1a\u63d0\u793a\u8f93\u5165\u5bc6\u7801\uff0c\u4e5f\u5c31\u662f\u751f\u6210 ssh \u79d8\u94a5\u65f6\uff0c\u8f93\u5165\u7684\u5bc6\u7801\uff0c\u5982\u679c\u6ca1\u6709\u8f93\u5165\u5bc6\u7801\uff0c\u76f4\u63a5\u56de\u8f66\u5373\u53ef</p> <p></p> <p>\uff089\uff09ls \u67e5\u770b\u672c\u5730\uff0c\u53d1\u73b0\u591a\u4e86 <code>remote-repo</code>\uff0c\u8868\u660e\u5c06\u8fd9\u4e2a\u4ed3\u5e93\u514b\u9686\u5230\u4e86\u672c\u5730</p> <p></p> <p>\uff0810\uff09\u8fdb\u5165\u76ee\u5f55\u91cc\u9762\uff0c\u591a\u4e86 main \u5206\u652f\uff0c\u8868\u793a\u8fd9\u662f\u4e00\u4e2a\u4ed3\u5e93</p> <p></p> <p></p> <p>\uff0811\uff09\u672c\u5730\u4e0e\u8fdc\u7a0b\u4ed3\u5e93\u4ea4\u4e92\u6f14\u793a\uff1a</p> <p></p> <p></p> <p>\u672c\u5730\u4ed3\u5e93\u548c\u8fdc\u7a0b\u4ed3\u5e93\u7684\u4ea4\u4e92\u9700\u8981\u4f7f\u7528 push \u548c pull \u64cd\u4f5c</p> <ul> <li>\u4f7f\u7528 push \u547d\u4ee4\u628a\u672c\u5730\u4ed3\u5e93\u7684\u4fee\u6539\u5185\u5bb9\u63a8\u9001\u7ed9\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u5237\u65b0\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u663e\u793a\u65b0\u5efa\u7684 hello.txt \u63a8\u9001\u5230\u8fdc\u7a0b\u4ed3\u5e93\u3002</li> </ul> <p></p> <p></p>"},{"location":"sticks/GitHub/#_6","title":"\u5173\u8054\u672c\u5730\u4ed3\u5e93\u548c\u8fdc\u7a0b\u4ed3\u5e93","text":"<p>\u5c06\u672c\u5730\u4ed3\u5e93\uff0c\u653e\u5230\u8fdc\u7a0b\u4ed3\u5e93</p> <p>\uff081\uff09github \u4e0a\u521b\u5efa\u65b0\u4ed3\u5e93</p> <p></p> <p>\uff082\uff09\u5c06\u672c\u5730 <code>my-repo</code>\u4ed3\u5e93\u548c\u8fdc\u7a0b <code>first-repo</code>\u4ed3\u5e93\u5173\u8054\u8d77\u6765\uff0c\u590d\u5236 <code>first-repo</code>\u4e2d\u7684\u63d0\u793a\u547d\u4ee4\u5373\u53ef</p> <p></p> <p>\ud83d\udce2 \u9700\u8981\u8fdb\u5165\u672c\u5730 <code>my-repo</code> \u4ed3\u5e93\uff0c\u6267\u884c <code>git remote</code> \u64cd\u4f5c\u3002</p> <p></p> <p></p> <p>\uff083\uff09<code>git remote -v</code> \u67e5\u770b\u5f53\u524d\u4ed3\u5e93\u6240\u5bf9\u5e94\u7684\u8fdc\u7a0b\u4ed3\u5e93\u7684\u522b\u540d\u548c\u5730\u5740</p> <p> </p> <p>\u663e\u793a\u4e3a \uff08\u8fdc\u7a0b\u4ed3\u5e93\u7684\u522b\u540d\uff09origin \u548c\u5730\u5740</p> <p></p> <p>\uff084\uff09 \u7b2c\u4e8c\u884c\uff0c<code>git branch -M main</code>  \u6307\u5b9a==\uff08\u672c\u5730\uff09\u5206\u652f\u7684\u540d\u79f0\u4e3a main\uff0c\u8fd9\u91cc\u9ed8\u8ba4\u7684\uff08\u672c\u5730\u5206\u652f\uff09==\u540d\u79f0\u5c31\u662f main\uff0c\u56e0\u6b64\u53ef\u4ee5\u7701\u7565\u6267\u884c\u8fd9\u884c\u547d\u4ee4 </p> <p></p> <p>\uff085\uff09\u7b2c\u4e09\u884c\uff0c<code>git push -u origin main</code> \u5c06\u672c\u5730\u7684 main \u5206\u652f\u548c\u8fdc\u7a0b origin\u4ed3\u5e93\u7684main \u5206\u652f\u5173\u8054\u8d77\u6765</p> <p>\u5173\u4e8e <code>git push -u origin main</code>\u547d\u4ee4</p> <p>\u547d\u4ee4\u5168\u79f0\uff1a<code>git push -u origin main:main</code></p> <p>\u5c06\u672c\u5730\u4ed3\u5e93\u548c\u522b\u540d\u4e3a origin \u7684\u8fdc\u7a0b\u4ed3\u5e93\u5173\u8054\u8d77\u6765</p> <p>main:main \u672c\u5730\u4ed3\u5e93\u7684 main \u5206\u652f\u63a8\u9001\u7ed9\u8fdc\u7a0b\u4ed3\u5e93\u7684 main \u5206\u652f\uff0c\u56e0\u4e3a\u672c\u5730\u5206\u652f\u7684\u540d\u79f0\u548c\u8fdc\u7a0b\u5206\u652f\u7684\u540d\u79f0\u76f8\u540c\uff0c\u56e0\u6b64\u53ef\u4ee5\u7701\u7565\u53ea\u4f7f\u7528\u4e00\u4e2a main</p> <p>\u6267\u884c\u5b8c git push \u64cd\u4f5c\uff0c\u663e\u793a\u672c\u5730\u4ed3\u5e93\u7684\u5185\u5bb9\u63a8\u9001\u5230\u4e86\u8fdc\u7a0b\u4ed3\u5e93</p> <p></p> <p></p> <p></p>"},{"location":"sticks/GitHub/#_7","title":"\u62c9\u53d6\u8fdc\u7a0b\u4ed3\u5e93\u7684\u4fee\u6539\u5408\u5e76\u5230\u672c\u5730\u4ed3\u5e93","text":"<p>\uff081\uff09\u8fdc\u7a0b\u4ed3\u5e93\u4fee\u6539\uff0c\u6dfb\u52a0 readme \u6587\u4ef6--&gt;\u70b9\u51fbadd a readme--&gt;\u7f16\u8f91\u5185\u5bb9--&gt;\u70b9\u51fb\u63d0\u4ea4\u6309\u94ae--&gt;\u5237\u65b0\u9875\u9762--&gt;\u770b\u5230\u6587\u4ef6\u6dfb\u52a0\u5230\u8fdc\u7a0b\u4ed3\u5e93\u91cc\u9762\u4e86</p> <p></p> <p></p> <p></p> <p></p> <p>\uff082\uff09\u95ee\u9898\u63cf\u8ff0\uff1a</p> <p>\u8fdc\u7a0b\u4ed3\u5e93\u6709\u4e86\u4e00\u4e2a\u65b0\u7684\u6587\u4ef6\uff0c\u4f46\u662f\u672c\u5730\u8fd8\u6ca1\u6709\u8fd9\u4e2a\u6587\u4ef6</p> <p>\u4f7f\u7528 pull \u62c9\u53d6\u8fdc\u7a0b\u4ed3\u5e93\u4e2d\u4fee\u6539\u7684\u5185\u5bb9</p> <p></p> <p>\u547d\u4ee4\u89e3\u91ca\uff1a\u8fdc\u7a0b\u4ed3\u5e93\uff08origin\uff09\u7684 main \u5206\u652f\uff0c\u62c9\u53d6\u5230\u672c\u5730\u3002</p> <p>\ud83d\udfe2 \u7701\u7565\u8fdc\u7a0b\u4ed3\u5e93\u540d\u548c\u5206\u652f\u540d\uff0c\u76f4\u63a5\u4f7f\u7528 <code>git pull</code> \u547d\u4ee4\uff0c\u90a3\u4e48\u5c06\u9ed8\u8ba4\u62c9\u53d6\u4ed3\u5e93\u522b\u540d\u4e3a <code>origin</code>\u7684 <code>main</code> \u5206\u652f\uff0c\u4f5c\u7528\u5c31\u662f\u5c06\u8fdc\u7a0b\u4ed3\u5e93\u7684\u6307\u5b9a\u5206\u652f\u62c9\u53d6\u5230\u672c\u5730\u518d\u8fdb\u884c\u5408\u5e76\uff1bls \u53c2\u770b\u672c\u5730\u4ed3\u5e93\u6587\u4ef6\uff0creadme \u6587\u4ef6\u62c9\u53d6\u8fc7\u6765\u4e86\u3002</p> <p></p> <p></p> <p></p> <p>\u6682\u5b58\u533a\u7684\u6587\u4ef6\uff1a <code>git ls-files</code></p> <p></p> <p>git pull\uff0cls\u67e5\u770b\u6587\u4ef6\u5217\u8868</p> <p></p> <p>readme \u62c9\u53d6\u4e0b\u6765\u3002</p> <p>2025 \u5e74 2 \u6708 26 \u65e5\uff0c\u544a\u4e00\u6bb5\u843d\uff0c\u611f\u8c22\u3002\u5206\u652f\u6ca1\u5b66\u3002\u7528\u5230\u4e86\u518d\u8bf4\u3002</p> <p>summary\uff1a\u672c\u5730\u4ed3\u5e93\u548c\u8fdc\u7a0b\u4ed3\u5e93\u3001\u8fde\u63a5</p>"},{"location":"sticks/MacOS/","title":"MacOS","text":""},{"location":"sticks/MacOS/#macos","title":"MacOS","text":"2024-12-19 22:26:512025-09-28 12:54:07 <p> \u7ea6 169 \u4e2a\u5b57  3 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p>"},{"location":"sticks/MacOS/#_1","title":"\u7ec8\u7aef\u547d\u4ee4","text":"<ul> <li><code>cd ..</code>  \u8fd4\u56de\u4e0a\u7ea7\u6587\u4ef6</li> <li><code>ls</code>  \u663e\u793a\u5f53\u524d\u76ee\u5f55\u6587\u4ef6</li> <li><code>ls -a</code> \u663e\u793a\u5f53\u524d\u76ee\u5f55\u7684\u6240\u6709\u6587\u4ef6\uff0c\u5305\u62ec\u9690\u85cf\u6587\u4ef6</li> </ul> <p>macOS \u7ec8\u7aef\u547d\u4ee4</p> <ul> <li> <p>\u663e\u793a\u6587\u4ef6\u6811</p> </li> <li> <p>\u6253\u5f00mac\u7ec8\u7aef</p> <ul> <li> <p>\u8f93\u5165 brew install tree</p> </li> <li> <p>\u4f7f\u7528\uff1a</p> </li> </ul> <p><code>tree</code> \u663e\u793a\u6587\u4ef6\u6811</p> <p><code>tree -a</code> \u663e\u793a\u6240\u6709\u6587\u4ef6\u6811\uff0c\u5305\u542b\u9690\u85cf\u6587\u4ef6</p> </li> <li> <p>vim\uff1f</p> </li> </ul> <p>\u90fd\u662f\u7ec8\u7aef</p> <p></p> <ul> <li>bash \u548c zsh\uff1f</li> </ul>"},{"location":"sticks/MacOS/#_2","title":"\u914d\u7f6e\u7ec8\u7aef","text":"<p>\u6548\u679c\u5c55\u793a\uff1a</p> <p></p> <p>\u3010\u6559\u7a0b\u3011\u5b89\u88c5 iterm2 \u6253\u9020\u6f02\u4eae\u4e14\u9ad8\u6027\u80fd\u7684 mac \u7ec8\u7aef</p> <p>\u5de5\u5177\uff1aIterm2 + oh my zsh + powerlevel10k</p> <p>Oh My Zsh \u548c Powerlevel10k\uff1a\u5929\u4f5c\u4e4b\u5408 | Linux \u4e2d\u56fd</p> <p>iTerm2\u5b89\u88c5\u914d\u7f6e\u4f7f\u7528\u6307\u5357\u2014\u2014\u4fdd\u59c6\u7ea7</p> <p>ZSH\u4e3b\u9898agnoster\u914d\u7f6e\u4fdd\u59c6\u7ea7\u6d41\u7a0b\u6559\u5b66</p> <p>\u5b89\u88c5Mac\u795e\u5668 brew\u3010\uff1f\u3011\uff1a\u7f51\u5740 https://brew.sh</p> <p></p>"},{"location":"sticks/docker/","title":"Docker","text":""},{"location":"sticks/docker/#docker","title":"Docker","text":"2025-02-26 16:43:322025-09-28 12:54:07 <p> \u7ea6 9747 \u4e2a\u5b57  54 \u884c\u4ee3\u7801  143 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 49 \u5206\u949f</p> <p>\u5360\u4f4d\uff1adocker hub</p> <p> </p> <p>\u5c0f\u767d\u5165\u95e8\uff1a\u5982\u4f55\u5728docker\u4e2d\u8fd0\u884cpython\u7a0b\u5e8f</p> <p>\u5982\u4f55\u901a\u8fc7 Docker \u90e8\u7f72\u6df1\u5ea6\u5b66\u4e60\u9879\u76ee\u73af\u5883\uff1f</p>"},{"location":"sticks/docker/#_1","title":"\u4f7f\u7528\u5bb9\u5668\u8dd1\u4ee3\u7801","text":"<p>1\ufe0f\u20e3 \u521b\u5efa\u4e00\u4e2a\u672c\u5730Ubuntu\u7cfb\u7edf\u548cdocker\u5bb9\u5668\u5171\u4eab\u7684\u6587\u4ef6\u5939</p> Bash<pre><code>sudo mkdir /loacal_data\n</code></pre> <p>2\ufe0f\u20e3 \u5c06\u4ee3\u7801\u6587\u4ef6\u590d\u5236\u5230Ubuntu\u7cfb\u7edf\u7684<code>/loacal_data</code>\u76ee\u5f55\u4e0b\uff0c\u8fd9\u6837\u8be5\u76ee\u5f55\u5c31\u548c\u5bb9\u5668\u5185\u90e8\u7684<code>/container_data</code>\u76ee\u5f55\u8fde\u901a\u4e86</p> Bash<pre><code>sudo docker run -v /local_data:/container_data -itd image_name:v1 bash\n</code></pre> <p>3\ufe0f\u20e3 \u67e5\u770b\u6b64\u65f6\u6b63\u5728\u8fd0\u884c\u7684\u5bb9\u5668</p> Bash<pre><code>sudo docker ps \n</code></pre> <p>\u8be5\u5bb9\u5668\u5c31\u662f\u6211\u4eec\u521a\u521a\u6240\u521b\u5efa\u7684\u7528\u4e8e\u672c\u5730\u6d4b\u8bd5\u4ee3\u7801\u7684\u5bb9\u5668</p> <p>4\ufe0f\u20e3 \u7528<code>docker attach</code>\u8fdb\u5165\u5bb9\u5668</p> Bash<pre><code>sudo docker attach 500ad76de1cf\n</code></pre> <p>5\ufe0f\u20e3 \u4e4b\u540e\u7684\u6b65\u9aa4\u5c31\u662f\u4e0e\u5728\u672c\u5730\u7cfb\u7edf\u547d\u4ee4\u884c\u7684\u64cd\u4f5c\u4e00\u6837\uff0c\u8fdb\u5165\u4ee3\u7801\u7684\u6587\u4ef6\u5939\uff0c\u7528<code>python</code>\u547d\u4ee4\u6267\u884c\u4ee3\u7801</p>"},{"location":"sticks/docker/#_2","title":"\u672c\u5730\u62c9\u53d6\u955c\u50cf\u4e0a\u4f20\u670d\u52a1\u5668","text":"<p>\u6b65\u9aa4</p> <p>\ud83d\udfe2 \u7b2c\u4e00\u6b65\uff1a\u62c9\u53d6\u8fdc\u7a0b\u955c\u50cf\uff0cdocker pull</p> Bash<pre><code>docker pull pytorch/pytorch:2.6.0-cuda11.8-cudnn9-devel\n</code></pre> <p> </p> <p></p> <p>\ud83d\udfe2 \u7b2c\u4e8c\u6b65\uff0c\u6807\u8bb0\u955c\u50cf\uff0c\u4e3a pull \u4e0b\u6765\u7684\u955c\u50cf\uff0c\u6253\u6807\u7b7e\uff0c\u63a8\u9001\u5230==\u670d\u52a1\u5668\u4e0a\u7684\u540d\u79f0:\u7248\u672c\u53f7==</p> Bash<pre><code>docker tag 8d8f916f1de0 geco_image:v1\n</code></pre> <p></p> <p>\ud83d\udfe2 \u7b2c\u4e09\u6b65\uff1a\u5c06\u672c\u5730\u7684 docker \u955c\u50cf\u4fdd\u5b58\u4e3a tar \u6587\u4ef6\uff0c\u5c31\u7528\u521a\u521a tag \u7684\u522b\u540d:\u6807\u7b7e\uff0c\u8fd9\u6837\u5230\u670d\u52a1\u5546\u5c31\u662f\u5bf9\u5e94\u7684\u540d\u79f0\u548c\u6807\u7b7e</p> Bash<pre><code>docker save -o \u955c\u50cftar\u6587\u4ef6\u540d\u79f0.tar geco_image:v1\n</code></pre> <p></p> <p>\ud83d\udfe2 \u7b2c\u56db\u6b65\uff1a\u4f20\u8f93\u955c\u50cf\uff0c\u5c06\u4fdd\u5b58\u7684tar\u6587\u4ef6\u4f20\u8f93\u5230\u8fdc\u7a0b\u670d\u52a1\u4e0a\uff0cFileZilla \u5373\u53ef</p> <p></p> <p>\ud83d\udfe2 \u7b2c\u4e94\u6b65\uff1a\u5728\u8fdc\u7a0b\u670d\u52a1\u4e0a\u52a0\u8f7d\u955c\u50cf</p> Bash<pre><code>docker load -i \u955c\u50cftar\u6587\u4ef6\u540d\u79f0.tar\n</code></pre> <p></p> <ul> <li>\u5728\u670d\u52a1\u5668\u7aef\u542f\u52a8 docker</li> </ul> <p><code>docker run -it #####image_id#####</code></p> <p></p> <p>docker run -it \u955c\u50cf\uff0crun\u8d77\u6765\u5c31\u662f\u5bb9\u5668\uff08\u6216\u8005\u53eb\u5e94\u7528\uff09\uff0c\u662f\u53ef\u4ee5\u4fee\u6539\u7684\u3002</p>"},{"location":"sticks/docker/#docker_1","title":"docker \u914d\u7f6e\u52a0\u901f\u963f\u91cc\u4e91\u955c\u50cf\u6e90","text":""},{"location":"sticks/docker/#_3","title":"\u4e00\u4e9b\u547d\u4ee4","text":"<ul> <li> <p>docker images</p> </li> <li> <p>\u67e5\u770b\u5df2\u7ecf\u6709\u7684 docker</p> </li> <li> <p>docker pull  ###</p> </li> <li> <p>docker pull asappinc/python-38-cuda118</p> </li> <li> <p>\u62c9\u53d6\u8fdc\u7a0b docker</p> </li> <li> <p>\u5220\u9664\u672c\u5730\u62c9\u53d6\u8fc7\u6765\u7684 docker\uff1a</p> </li> <li> <p>docker \u5b89\u88c5\u6210\u529f\u6ca1   docker help</p> </li> </ul>"},{"location":"sticks/docker/#docker-tag","title":"docker tag","text":"Bash<pre><code>docker tag SOURCE[\u672c\u5730]_IMAGE[:TAG] TARGET_IMAGE[\u670d\u52a1\u5668][:TAG]\n</code></pre> <p>tag\u7684\u4f5c\u7528\uff1a</p> <ul> <li><code>SOURCE_IMAGE[:TAG]</code>\uff1a\u6e90\u955c\u50cf\u7684\u540d\u79f0\u548c\u53ef\u9009\u7684\u6807\u7b7e\u3002\u5982\u679c\u672a\u6307\u5b9a\u6807\u7b7e\uff0c\u9ed8\u8ba4\u4e3a <code>latest</code>\u3002</li> <li><code>TARGET_IMAGE[:TAG]</code>\uff1a\u76ee\u6807\u955c\u50cf\u7684\u540d\u79f0\u548c\u53ef\u9009\u7684\u6807\u7b7e\u3002</li> <li>\u5047\u8bbe\u4f60\u6709\u4e00\u4e2a\u540d\u4e3a <code>my-image</code> \u7684\u955c\u50cf\uff0c\u5e76\u4e14\u4f60\u60f3\u4e3a\u5b83\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u6807\u7b7e <code>v1.0</code>\uff0c\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a<code>docker tag my-image my-image:v1.0</code></li> <li>\u8fd9\u5c06\u4e3a <code>my-image</code> \u955c\u50cf\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u6807\u7b7e <code>v1.0</code>\u3002\u4f60\u53ef\u4ee5\u4f7f\u7528 <code>docker images</code> \u547d\u4ee4\u67e5\u770b\u955c\u50cf\u548c\u6807\u7b7e\uff1a<code>docker images</code></li> <li>\u8f93\u51fa\u793a\u4f8b\uff1a</li> </ul> <p>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE my-image            latest              d1e3f1e4f1e4        2 days ago          500MB my-image            v1.0                d1e3f1e4f1e4        2 days ago          500MB</p> <ul> <li>\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff1a</li> </ul> <p>\u4e24\u4e2a\u955c\u50cf\u7684 ID \u4e00\u6837\u662f\u56e0\u4e3a\u5b83\u4eec\u5b9e\u9645\u4e0a\u662f\u540c\u4e00\u4e2a\u955c\u50cf\uff0c\u53ea\u662f\u88ab\u6253\u4e0a\u4e86\u4e0d\u540c\u7684\u6807\u7b7e\u3002\u8fd9\u610f\u5473\u7740\u4f60\u53ef\u4ee5\u901a\u8fc7\u4efb\u610f\u4e00\u4e2a\u6807\u7b7e\u6765\u5f15\u7528\u8fd9\u4e2a\u955c\u50cf\uff0c\u5e76\u4e14\u5220\u9664\u5176\u4e2d\u4e00\u4e2a\u6807\u7b7e\u4e0d\u4f1a\u5f71\u54cd\u955c\u50cf\u7684\u5b9e\u9645\u6570\u636e\u3002</p> <p>\u5f53\u4f60\u5220\u9664\u4e00\u4e2a\u955c\u50cf\u6807\u7b7e\u65f6\uff0c\u5b9e\u9645\u4e0a\u53ea\u662f\u5220\u9664\u4e86\u8fd9\u4e2a\u6807\u7b7e\uff0c\u800c\u955c\u50cf\u672c\u8eab\u4ecd\u7136\u5b58\u5728\uff0c\u76f4\u5230\u6240\u6709\u5f15\u7528\u5b83\u7684\u6807\u7b7e\u90fd\u88ab\u5220\u9664\u3002</p>"},{"location":"sticks/docker/#docker-load","title":"docker load","text":"<p><code>docker load -i \u955c\u50cftar\u6587\u4ef6\u540d\u79f0.tar</code> </p> <ul> <li> <p>\u52a0\u8f7d\u5b8c\u6210\u540e\uff0c\u4f7f\u7528 <code>docker images</code> \u5373\u53ef\u67e5\u770b \u52a0\u8f7d\u5230\u7684\u955c\u50cf</p> </li> <li> <p>\u8be5\u547d\u4ee4\u7528\u4e8e\u4ece\u4e00\u4e2a tar \u6587\u4ef6\u4e2d\u52a0\u8f7d Docker \u955c\u50cf\uff1a</p> </li> </ul> Bash<pre><code>docker load -i \u955c\u50cftar\u6587\u4ef6\u540d\u79f0.tar\n</code></pre> <ul> <li><code>docker load</code>\uff1a\u8fd9\u662f Docker \u7684\u4e00\u4e2a\u547d\u4ee4\uff0c\u7528\u4e8e\u4ece\u4e00\u4e2a tar \u6587\u4ef6\u4e2d\u52a0\u8f7d\u955c\u50cf\u3002</li> <li><code>-i</code>\uff1a\u8fd9\u662f <code>--input</code> \u7684\u7f29\u5199\uff0c\u6307\u5b9a\u8f93\u5165\u6587\u4ef6\u3002</li> <li><code>\u955c\u50cftar\u6587\u4ef6\u540d\u79f0.tar</code>\uff1a\u8fd9\u662f\u5305\u542b Docker \u955c\u50cf\u7684 tar \u6587\u4ef6\u7684\u540d\u79f0\u3002</li> </ul> <p></p>"},{"location":"sticks/docker/#dockerfile","title":"dockerfile","text":"<p>\u67e5\u770b\u5b98\u65b9\u6e90\uff0c\u4ee5python\u4e3a\u4f8b</p> <p></p>"},{"location":"sticks/docker/#docker_2","title":"\u7cfb\u7edf\u5b66\u4e60docker","text":""},{"location":"sticks/docker/#docker_3","title":"\u5b89\u88c5docker","text":"<ul> <li>docker\u7684\u5b89\u88c5\u547d\u4ee4\uff1a\u53c2\u7167docker\u5b98\u7f51\u8bbf\u95eedocker.com</li> <li>\u70b9\u51fb\uff1a\u5f00\u53d1\u8005--&gt;\u6587\u6863--&gt;manuals\u624b\u518c(\u5305\u542bhow to install\u3001\u5982\u4f55\u5b89\u88c5)--&gt;docker\u5f15\u64ce docker engine --&gt;  install\u5b89\u88c5--&gt;\u9009\u62e9\u6211\u4eec\u7cfb\u7edf\u7684\u7248\u672c\uff08\u5982 CentOS\uff09--&gt; \u53c2\u7167\u6b65\u9aa4\uff0c \u76f4\u63a5\u590d\u5236\u547d\u4ee4</li> <li>\u7b2c\u4e00\u6b65\uff0c\u79fb\u9664\u7cfb\u7edf\u91cc\u8fb9\u7684\u65e7\u7248\u672c</li> </ul> <ul> <li>\u7b2c\u4e8c\u6b65\uff1a\u914d\u7f6edocker\u7684\u4e0b\u8f7d\u6e90</li> </ul> <p>\u5b89\u88c5 yum-utils \u5de5\u5177\u7c7b\uff0c\u7528\u8fd9\u4e2a\u5de5\u5177\u7c7b\u914d\u7f6edocker\u7684\u4e0b\u8f7d\u5730\u5740\u6e90 \u56e0\u4e3a\u8fd9\u91cc\u7684docker\u4e0b\u8f7d\u5730\u5740\u662f\u8fde\u63a5docker\u5b98\u7f51\u7684\uff0c\u4e0b\u8f7d\u8d77\u6765\u6bd4\u8f83\u6162</p> <p></p> <p>\u53c2\u7167\u5982\u4e0b\uff1a</p> <p></p> <p>\u628adocker\u7684\u4e0b\u8f7d\u6e90\u914d\u7f6e\u6210\u963f\u91cc\u4e91\u7684\u5730\u5740</p> <ul> <li>\u7b2c\u4e09\u6b65\uff0c\u5b89\u88c5docker\u5f15\u64ce\uff1a</li> </ul> <p></p> <p>\u5305\u542b</p> <p>\uff081\uff09docker-ce\uff1adocker\u5f15\u64ce</p> <p>\uff082\uff09docker-ce-cli\uff1adocker\u5f15\u64ce\u7684\u547d\u4ee4\u884c\u7a0b\u5e8f\uff0c\u547d\u4ee4\u884c\u53ef\u4ee5\u7ed9docker\u7684demon\u540e\u53f0\u8fdb\u7a0b\u53bb\u53d1\u9001\u547d\u4ee4</p> <p>\uff083\uff09container.io\uff1adocker\u7684\u8fd0\u884c\u65f6\u5bb9\u5668\u73af\u5883</p> <p>\uff084\uff09\u4ee5\u53cadocker\u7528\u6765\u6784\u5efa\u955c\u50cf\u7684\u63d2\u4ef6\u5de5\u5177</p> <p>\uff085\uff09\u8fd8\u6709docker compose\uff1a\u505a\u6279\u91cf</p> <p></p> <p>\u8f93\u5165Y\u786e\u8ba4\u4e0b\u8f7d\u5b89\u88c5</p> <ul> <li>\u7b2c\u56db\u6b65\uff1a\u542f\u52a8docker</li> </ul> <p></p> <p>\u8f93\u5165system control start docker sudo \u8868\u793a \u4f7f\u7528\u8d85\u7ea7\u7ba1\u7406\u5458\u6743\u9650\uff0c\u4f7f\u7528\u7684\u662froot\u7684\u8bdd\uff0c\u53ef\u4ee5\u76f4\u63a5\u7c98\u8d34\u547d\u4ee4\u56de\u8f66\uff0c\u5b8c\u6210 docker\u542f\u52a8</p> <p></p> <p>\u8fd0\u884cdocker\u547d\u4ee4\uff0c<code>docker ps</code>\uff0c\u67e5\u770b\u6b63\u5728\u8fd0\u884c\u4e2d\u7684\u5e94\u7528</p> <p>\u6ce8\u610f\uff1a\u8fd9\u4e2a\u547d\u4ee4\u542f\u52a8docker\u53ea\u662f\u5f53\u524d\u542f\u52a8\uff0c\u5982\u679c\u5173\u673a\uff0c\u4e0b\u6b21\u8fd8\u5f97\u7528\u8fd9\u4e2a\u547d\u4ee4\u542f\u52a8docker\uff0c \u6240\u4ee5\u989d\u5916\u52a0\u4e00\u4e2a\u53ebsystem control enable docker</p> <p></p> <p>\u8ba9docker\u5f00\u673a\u4e5f\u542f\u52a8\uff0c\u81f3\u6b64docker\u5b89\u88c5\u5b8c\u6210</p> <p>\u8865\u5145\u914d\u7f6e\uff1a </p> <p></p> <p>docker\u5df2\u7ecf\u542f\u52a8\u5b89\u88c5\u5b8c\u6210\u4ee5\u540e\uff0c\u53ef\u4ee5\u914d\u7f6edocker\u7684\u52a0\u901f</p> <p>\u56e0\u4e3adocker\u53bb\u4e0b\u8f7d\u955c\u50cf\uff0c \u9ed8\u8ba4\u4ecedocker hub\u5b98\u7f51\u4e0b\u8f7d\uff0c\u800c\u8fde\u63a5\u56fd\u5916\u6bd4\u8f83\u6162\uff0c\u6240\u4ee5\u4e00\u822c\u914d\u7f6e\u56fd\u5185\u955c\u50cf\u6e90\u5730\u5740</p> <p>\u547d\u4ee4\u884c\u793a\u4f8b\u5982\u4e0b\uff1a</p> <p></p> <p>\u914d\u7f6e\u597d\u52a0\u901f\u6e90\u5730\u5740\u4ee5\u540e\uff0c\u91cd\u542fdocker\u7684\u540e\u53f0\u8fdb\u7a0b\u4ee5\u53ca\u91cd\u542fdocker</p> <p>\u6ce8\u610f\u8fd9\u91cc\u7684\u914d\u7f6e\u539f\u7406\uff0c\u662fdocker\u540e\u53f0\u8fdb\u7a0b\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u5728etc/docker/demon.json\u4e2d\uff0c\u7ed9\u8fd9\u4e2ajson\u4e2d\u914d\u7f6e\u4e86\u4e00\u4e2a\u9009\u9879\uff1aregistry - mirrors\u6307\u5411\u56fd\u5185\u955c\u50cf\u6e90\uff0c\u76f8\u5f53\u4e8e\u4fee\u6539\u4e86docker\u7684\u914d\u7f6e\u6587\u4ef6</p> <p>\u5168\u90e8\u914d\u7f6e\u6210\u529f\u4ee5\u540e\u518d\u6b21\u9a8c\u8bc1\uff0c\u5982\u679cdocker ps \u7b49 docker \u547d\u4ee4\u53ef\u4ee5\u8fd0\u884c\u8bc1\u660e\u6ca1\u6709\u95ee\u9898</p>"},{"location":"sticks/docker/#docker_4","title":"docker \u547d\u4ee4","text":"<p>\u95ee\u9898\u63cf\u8ff0\uff1a </p> <p></p> <p>\u7528docker\u542f\u52a8\u4e00\u4e2anginx\u5e94\u7528\uff0c\u5e76\u4e14\u5c06nginx\u7684\u9ed8\u8ba4\u9996\u9875\u6539\u6210\u81ea\u5df1\u7684\u9875\u9762\uff0c\u8fd9\u6837\u522b\u4eba\u6765\u8bbf\u95ee\u8fd9\u4e2anginx\uff0c\u5c31\u80fd\u770b\u5230\u4f60\u81ea\u5df1\u7684\u9875\u9762\uff0c\u5e76\u4e14\u5c06\u6539\u597d\u7684\u5e94\u7528\u53d1\u5e03\u51fa\u53bb\uff0c\u53d1\u5e03\u5230\u5e94\u7528\u5e02\u573a\uff0c\u8ba9\u6240\u6709\u4eba\u90fd\u80fd\u4ece\u5e02\u573a\u91cc\u8fb9\u4e0b\u8f7d\u8fd9\u4e2a\u5e94\u7528\uff0c\u76f4\u63a5\u8fd0\u884c</p> <p>\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <p></p> <ul> <li>\u7b2c\u4e00\u6b65\u53bb\u5e94\u7528\u5e02\u573a\u4e0b\u8f7dNGINX\u8f6f\u4ef6\u955c\u50cf</li> <li>\u7136\u540edocker\u4f7f\u7528\u8fd9\u4e2a\u955c\u50cf\u542f\u52a8\u4e00\u4e2a\u5e94\u7528\u5bb9\u5668</li> <li>\u63a5\u4e0b\u6765\u4fee\u6539\u5bb9\u5668\u91cc\u7684\u9ed8\u8ba4\u9875\u9762\uff0c\u628a\u5b83\u6539\u6210\u81ea\u5df1\u7684\u9875\u9762</li> <li>\u6700\u540e\u628a\u4fee\u6539\u7684\u6574\u4e2a\u8f6f\u4ef6\uff0c\u4fdd\u5b58\u4e00\u4e2a\u65b0\u7684\u955c\u50cf\uff0c\u628a\u8fd9\u4e2a\u955c\u50cf\u53d1\u5e03\u5230\u5e94\u7528\u5e02\u573a\u91cc\u8fb9\uff0c\u8ba9\u522b\u4eba\u53ef\u4ee5\u4e0b\u8f7d</li> </ul> <p>\u7b2c\u4e00\u6b65\uff0c\u4e0b\u8f7d\u955c\u50cf\uff1a</p> <p></p> <p>\u8ddf\u955c\u50cf\u76f8\u5173\u7684\u547d\u4ee4 - \u68c0\u7d22\uff0c\u4f7f\u7528docker search\u5148\u627e\u4e00\u4e0b\u6709\u6ca1\u6709\u8fd9\u4e2a\u955c\u50cf - \u518d\u5229\u7528docker pull\u628a\u8fd9\u4e2a\u955c\u50cf\u4e0b\u8f7d\u8fc7\u6765 - \u4f7f\u7528docker images\uff0c\u67e5\u770b\u5df2\u7ecf\u4e0b\u8f7d\u6765\u7684\u6240\u6709\u955c\u50cf\u5217\u8868 - \u4f7f\u7528docker rmi\uff0cremove image\u7684\u7f29\u5199\uff0c\u5220\u9664\u67d0\u4e00\u4e2a\u955c\u50cf</p> <p>\ud83d\udfe2 \u5148\u6765\u7528docker search\u6765\u641c\u4e00\u4e0b\u6709\u6ca1\u6709nginx\u955c\u50cf</p> <p></p> <ul> <li>\u6253\u5370\u4e00\u4e2a\u5217\u8868</li> <li>name\uff1a\u955c\u50cf\u7684\u540d\u5b57</li> <li>description\uff1a\u5bf9\u8fd9\u4e2a\u955c\u50cf\u7684\u63cf\u8ff0</li> <li>stars\uff1a\u8fd9\u4e2a\u955c\u50cf\u6709\u591a\u5c11\u7684star</li> <li>official\uff1a\u8fd9\u4e2a\u955c\u50cf\u662f\u4e0d\u662f\u5b98\u65b9\u53d1\u5e03\u7684\u955c\u50cf\uff0c\u5982\u679cOK\u4ee3\u8868\u8fd9\u662f\u5b98\u65b9\u955c\u50cf\uff0c\u5426\u5219\u5c31\u662f\u7b2c\u4e09\u65b9\u5236\u4f5c\u7684\u955c\u50cf</li> </ul> <p></p> <ul> <li> <p>\u663e\u793a \u6709\u4e00\u4e2aNGINX\uff0c\u76f4\u63a5\u8fdb\u884c\u4e0b\u8f7d </p> </li> <li> <p>\u4f7f\u7528docker pull\u547d\u4ee4\u76f4\u63a5\u5199\u955c\u50cf\u540d\u56de\u8f66\uff0c\u955c\u50cf\u8fdb\u5165\u4e0b\u8f7d\u6d41\u7a0b\uff0c\u4e0b\u8f7d\u5b8c\u6210\u4ee5\u540e\uff0c\u4f7f\u7528docker images\u68c0\u67e5\u4e00\u4e0b</p> </li> </ul> <p></p> <ul> <li>\u663e\u793a \u7cfb\u7edf\u91cc\u73b0\u5728\u6709\u4e00\u4e2a\u955c\u50cf</li> <li>\u6253\u5370\u7684\u5217\u8868\uff1a</li> </ul> <p>1\ufe0f\u20e3 repository\uff1a\u4ee3\u8868\u955c\u50cf\u7684\u540d\u5b57</p> <p>2\ufe0f\u20e3 TAG \u662f\u955c\u50cf\u7684\u6807\u7b7e\uff0c\u4e00\u822c\u4ee3\u8868\u955c\u50cf\u7684\u7248\u672c\uff0clatest\u4ee3\u8868\u6700\u65b0\u7248\u672c</p> <p>3\ufe0f\u20e3 image id\u4ee3\u8868\u955c\u50cf\u7684\u552f\u4e00id</p> <p>4\ufe0f\u20e3 created \uff1a\u955c\u50cf\u662f\u591a\u5c11\u5929\u524d\u521b\u5efa\u51fa\u6765\u7684</p> <p>5\ufe0f\u20e3 size\uff1a \u955c\u50cf\u7684\u5927\u5c0f</p> <p>\ud83d\udce2 \u8fd9\u91cc\u6f14\u793a\u4e0b\u8f7d\u7684\u955c\u50cfNGINX\uff0c\u662f\u6700\u65b0\u7248\u7684\uff0c \u90a3\u5982\u679c\u8981\u4e0b\u8f7d\u6307\u5b9a\u7248\u672c\u7684\u5462\uff1f</p> <ul> <li> <p>\u955c\u50cf\u7684\u5b8c\u6574\u540d\uff0c\u5176\u5b9e\u662f\u955c\u50cf\u540d\u5192\u53f7\u52a0\u6807\u7b7e</p> </li> <li> <p>\u6240\u4ee5docker pull \u4e0b\u8f7dnginx\uff0c\u5176\u5b9e\u7b49\u4e8edocker put nginx\u52a0\u4e0a\u5b83\u7684\u6807\u7b7e\uff0c\u4e5f\u5c31\u662f\u7248\u672clatest\uff0c\u4e0b\u8f7d\u6700\u65b0\u7248\u672c</p> </li> <li> <p>\u5982\u679c\u8981\u4e0b\u8f7d\u6307\u5b9a\u7248\u672c\uff0c\u90a3\u6b64\u65f6\u5c31\u4e0d\u63a8\u8350docker search\u641c\u7d22\u955c\u50cf\uff0c\u800c\u662f\u53bbdocker hub\u7f51\u7ad9\u81ea\u5df1\u6765\u641c\u7d22\u955c\u50cf\uff0c\u5728\u8fd9\u4e2a\u7f51\u7ad9\u91cc\u6709\u5b8c\u6574\u7684\u7248\u672c\u5217\u8868\uff0c\u770b\u4e0a\u54ea\u4e2a\u53bb\u4e0b\u8f7d\u54ea\u4e2a</p> </li> </ul> <p></p> <p>\u641c\u7d22\u60f3\u8981\u7684\u955c\u50cf\uff0c\u8f93\u5165NGINX\u56de\u8f66\uff0c\u6709NGINX\u955c\u50cf \u6ce8\u610f\u52a0\u4e86\u8fd9\u4e24\u4e2a\u6807\u5fd7\u7684\u90fd\u662f\u5b98\u65b9\u955c\u50cf</p> <p></p> <p>\u70b9\u8fdb\u6765\uff0c\u6bcf\u4e00\u4e2a\u955c\u50cf\u90fd\u6709\u8bf4\u660e\uff0c\u5305\u62ec\u8fd9\u4e2a\u955c\u50cf\u5982\u4f55\u542f\u52a8\uff0c\u4e5f\u63d0\u4f9b\u4e86docker run\u547d\u4ee4</p> <p></p> <p></p> <p>\u53c2\u8003\u6bcf\u4e00\u4e2a\u955c\u50cf\u7684\u8bf4\u660e\uff0c\u5982\u679c\u60f3\u8981\u4e0b\u8f7d\u5176\u4ed6\u7248\u672c\u7684nginx\uff0c\u70b9\u51fb TAGS \u91cc</p> <p></p> <ul> <li>\u6bcf\u4e00\u4e2atag\u90fd\u662f\u4e00\u79cd\u7248\u672c\uff0c\u6bd4\u59821.26</li> </ul> <p></p> <p>\u4e0b\u8f7d\u5b83\uff0c\u76f4\u63a5\u590d\u5236\u547d\u4ee4\u5230\u6211\u4eec\u7684\u547d\u4ee4\u884c\uff0c\u91cd\u65b0\u4e0b\u8f7ddocker pull\uff0c\u5192\u53f7\u6307\u5b9a\u4e86\u955c\u50cf\u7248\u672c</p> <p></p> <p>\u4e0b\u8f7d\u5b8c\u4ee5\u540e\uff0c\u4f7f\u7528<code>docker images</code>\uff0c\u5b8c\u6574\u5199\u6cd5\u662fimage ls\uff0c\u5217\u51fa\u6240\u6709\u7684\u955c\u50cf\u5217\u8868</p> <p></p> <p>\u770b\u5230\u6709nginx1.26.0\u955c\u50cf \uff0c\u8fd8\u6709nginx lastest \u955c\u50cf \ud83d\udfe2 \u5982\u679c\u60f3\u8981\u5220\u9664\u67d0\u4e00\u4e2a\u955c\u50cf\uff0c\u53ef\u4ee5\u4f7f\u7528docker rmi\uff0c\u5c31\u662fremove image\uff0c\u5199\u955c\u50cf\u7684\u540d\u52a0\u4e0a\u5b8c\u6574\u6807\u7b7e</p> <p></p> <ul> <li> <p>\u6bd4\u5982\u8981\u5220latest\uff0c\u5c31\u5199latest <code>docker rmi nginx\uff1alatest</code></p> </li> <li> <p>\u6216\u8005\uff0c\u6bcf\u4e00\u4e2a\u955c\u50cf\u6709\u5b83\u7684\u552f\u4e00id\u4e5f\u53ef\u4ee5\u7528\u5b83\u7684\u552f\u4e00id \uff0c\u6765\u8fdb\u884c\u5220\u9664</p> </li> <li>\u955c\u50cf\u5c31\u88ab\u5220\u9664\u4e86</li> <li>\u518d\u6765\u68c0\u67e5docker images\uff0c\u5217\u8868\u91cc\u8fb9\u53ea\u6709NGINX1.2.6.0</li> </ul> <p></p>"},{"location":"sticks/docker/#_4","title":"\u542f\u52a8\u5bb9\u5668","text":"<p>\u7b2c\u4e00\u6b65\uff0c\u4e0b\u8f7dnginx\u955c\u50cf \u7b2c\u4e8c\u6b65\uff0c\u542f\u52a8\u5bb9\u5668\uff0c\u6bcf\u4e00\u4e2a\u5bb9\u5668\u90fd\u4ee3\u8868\u4e00\u4e2a\u8fd0\u884c\u4e2d\u7684\u5e94\u7528</p> <p>\ud83d\udfe2 \u8ddf\u5bb9\u5668\u76f8\u5173\u7684\u547d\u4ee4  </p> <ul> <li> <p>\u8fd0\u884c\u4f7f\u7528docker run  </p> </li> <li> <p>\u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684\u5bb9\u5668 docker ps  </p> </li> <li> <p>\u505c\u6b62stop   </p> </li> <li> <p>\u542f\u52a8start  </p> </li> <li> <p>\u91cd\u542frestart  </p> </li> <li> <p>\u67e5\u770b\u5bb9\u5668\u7684\u72b6\u6001\uff0c\u6bd4\u5982CPU\u5185\u5b58\u5360\u7528\uff0c\u4f7f\u7528docker states  </p> </li> <li> <p>\u67e5\u770b\u5bb9\u5668\u7684\u65e5\u5fd7\uff0c\u4e5f\u5c31\u662f\u5e94\u7528\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u65e5\u5fd7\uff0c\u4f7f\u7528docker logs  </p> </li> <li> <p>\u8fdb\u5165\u5bb9\u5668\u5185\u90e8\u8fdb\u884c\u4fee\u6539\uff0c\u4f7f\u7528docker exec  </p> </li> <li> <p>\u5220\u9664\u4e00\u4e2a\u5bb9\u5668\uff0c\u4f7f\u7528docker rm  </p> </li> </ul> <p>\ud83d\udce2 \u5176\u4e2ddocker run\u548cdocker exec \u8fd9\u4e24\u4e2a\u547d\u4ee4\uff0c\u6bd4\u8f83\u590d\u6742  </p> <p>\u9996\u5148\u7b2c\u4e00\u4e2adocker run</p> <p>\u5f53\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2anginx\u955c\u50cf\u4ee5\u540e\uff0c\u60f3\u8981\u542f\u52a8\u8fd9\u4e2a\u5e94\u7528</p> <p>\u7b2c\u4e00\u6b65\u662fdocker run\uff0c\u542f\u52a8\u4e00\u4e2a\u5e94\u7528</p> <p></p> <ul> <li>docker run --help \u67e5\u770b\u8fd9\u4e2a\u547d\u4ee4\u600e\u4e48\u7528</li> </ul> <p></p> <p>\u7528\u6cd5usage\u662fdocker run <code>options</code>\uff0coptions\u5c31\u662f\u53c2\u6570\u9879</p> <p>\u542f\u52a8\u4e00\u4e2a\u5bb9\u5668\u80fd\u52a0\u7684\u53c2\u6570\u9879\uff1a</p> <p></p> <ul> <li> <p>image\u4ee3\u8868\u955c\u50cf</p> </li> <li> <p>\u4e2d\u62ec\u53f7\u4ee3\u8868 \u53ef\u9009\u53c2\u6570</p> </li> <li>\u540e\u8fb9[command] [ARG...] \u7ffb\u8bd1\u8fc7\u6765\u662f \uff1a\u547d\u4ee4\u548c\u53c2\u6570\u3002\u8868\u793a\u5982\u679c\u542f\u52a8\u8fd9\u4e2a\u955c\u50cf\uff0c\u8981\u4f7f\u7528\u4ec0\u4e48\u6837\u7684\u542f\u52a8\u547d\u4ee4\uff0c\u53ef\u4ee5\u81ea\u5df1\u5b9a\u4e49\uff0c\u4f46\u4e00\u822c\u955c\u50cf\u540e\u8fb9\u7684\u547d\u4ee4\u548c\u53c2\u6570\uff0c\u4e0d\u7528\u5199\uff0c\u56e0\u4e3a\u6bcf\u4e00\u4e2a\u955c\u50cf\u6709\u5b83\u81ea\u5df1\u7684\u542f\u52a8\u547d\u4ee4\u548c\u53c2\u6570\uff0c\u8fd9\u662f\u955c\u50cf\u91cc\u8fb9\u9ed8\u8ba4\u5e26\u597d\u7684\uff0c\u9664\u975e\u6211\u4eec\u8981\u6539\u53d8\u955c\u50cf\u7684\u9ed8\u8ba4\u542f\u52a8\u884c\u4e3a\uff0c\u5426\u5219\u90fd\u4e0d\u7528\u7ba1</li> <li>\u4f7f\u7528\u5c31\u662f\uff1a</li> </ul> <p>1\ufe0f\u20e3 \u76f4\u63a5\u4f7f\u7528docker run\u52a0\u4e0a \u955c\u50cf\u540d\uff0c\u5c31\u53ef\u4ee5\u7528\u8fd9\u4e2a\u955c\u50cf\u542f\u52a8\u4e00\u4e2a\u5e94\u7528</p> <p>2\ufe0f\u20e3 \u5982\u679c\u8981\u52a0\u5165\u4e00\u4e9b\u53c2\u6570\u8bbe\u7f6e\uff0c\u90a3\u5c31\u7ed9run\u548cimage\u4e2d\u95f4\u52a0\u4e0a\u53c2\u6570\u8bbe\u7f6e\u9879</p> <p>\u73b0\u5728\u76f4\u63a5\u4f7f\u7528<code>docker run nginx</code></p> <p>\u4f46\u5982\u679c\u4e0d\u5199\u955c\u50cf\u7684\u7248\u672c\u53f7\uff0c\u5c31\u4f1a\u4f7f\u7528\u6700\u65b0\u955c\u50cf\uff0c\u5982\u679c\u7b2c\u4e00\u6b21\u542f\u52a8\u6ca1\u6709\u8fd9\u4e2a\u955c\u50cf\uff0c\u4f1a\u81ea\u52a8\u4e0b\u8f7d\uff0c\u542f\u52a8\u963b\u585e\u4e86\u63a7\u5236\u53f0\uff0c\u6b64\u65f6\u4e0d\u53ef\u4ee5\u9000\u51fa\u63a7\u5236\u53f0\uff0c\u4e00\u505c\uff0c\u5e94\u7528\u8ddf\u7740\u4e5f\u5c31\u505c\u4e86</p> <p></p> <p>\u590d\u5236\u4e00\u4e2a\u89c6\u56fe\uff0c\u5728\u8fd9\u4e2a\u4f1a\u8bdd\u4e2d\u7528\u7b2c\u4e8c\u4e2a\u547d\u4ee4\uff1adocker ps\uff0c\u53ef\u4ee5\u67e5\u770b\u8fd0\u884c\u4e2d\u7684\u5e94\u7528</p> <p></p> <p>\u770b\u5230\u6709\u4e00\u4e2anginx\u5728\u8fd0\u884c</p> <p>\u5b8c\u6574\u6253\u5370\u53c2\u6570\u89e3\u91ca\uff1a</p> <ul> <li>container id \u4ee3\u8868\u6b63\u5728\u8fd0\u884c\u7684\u5e94\u7528\u7684\u552f\u4e00id</li> <li>image \u4f7f\u7528\u54ea\u4e2a\u955c\u50cf\u8fd0\u884c\u7684\uff0c\u6ca1\u5e26tag\u6807\u7b7e\uff0c\u8bf4\u660e\u662f\u4f7f\u7528\u6700\u65b0\u955c\u50cf</li> <li>command \u4ee3\u8868\u8fd9\u4e2a\u5bb9\u5668\u81ea\u5df1\u7684\u542f\u52a8\u547d\u4ee4\uff0c\u4e0d\u7528\u7ba1</li> <li>create\u4ee3\u8868 \u662f\u591a\u957f\u65f6\u95f4\u4e4b\u524d\u542f\u52a8\u7684</li> <li>status \u542f\u52a8\u72b6\u6001\uff0cup \u4ee3\u8868\u4e0a\u7ebf\u6210\u529f\u4e86</li> <li> <p>ports \u4ee3\u8868\u8fd9\u4e2a\u5e94\u7528\u5360\u7528\u7684\u7aef\u53e3\u662f 80 \u7aef\u53e3</p> </li> <li> <p>names\u4ee3\u8868\u5e94\u7528\u5bb9\u5668\u7684\u540d\u5b57\uff0c\u4f1a\u7ed9\u4e00\u4e2a\u968f\u673a\u540d\u5b57</p> </li> </ul> <p>\u25b6\ufe0f \u6b64\u65f6\u628a\u8fd9\u4e2a\u5e94\u7528\u63a7\u5236\u53f0 CTRL C \u4e2d\u65ad\u6389\uff0c\u4f1a\u53d1\u73b0\u8fd9\u4e2a\u5e94\u7528\u505c\u4e86</p> <ul> <li>\u518d\u4f7f\u7528docker ps \u6765\u68c0\u67e5\uff0c\u5c31\u6ca1\u6709\u8fd0\u884c\u4e2d\u7684\u8fd9\u4e2a\u5e94\u7528\u4e86</li> </ul> <p></p> <p>\u6ce8\u610fdocker ps  \u67e5\u770b\u6240\u6709\u8fd0\u884c\u4e2d\u7684\u5bb9\u5668</p> <ul> <li>\u505c\u4e86\u7684\uff0c\u53ef\u4ee5\u4f7f\u7528<code>docker ps -a</code> \u5c31\u53ef\u4ee5\u67e5\u770b\u6240\u6709\u7684\u5bb9\u5668\uff0c\u5305\u62ec\u505c\u6b62\u4e86\u7684</li> </ul> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u8fd9\u4e2a\u5bb9\u5668\u4e4b\u524d\u662f\u8fd0\u884c\u7684\uff0c\u73b0\u5728<code>status</code>\u72b6\u6001\u662f<code>exist</code>\u5df2\u7ecf\u9000\u51fa\u4e86</p> <p>\u25b6\ufe0f \u9000\u51fa\u7684\u5bb9\u5668\u5982\u679c\u518d\u60f3\u542f\u52a8\u600e\u4e48\u505a\u5462\uff1f</p> <ul> <li> <p>\u4f7f\u7528 docker start\uff0c\u76f8\u5f53\u4e8e\u628a\u8fd9\u4e2a\u5bb9\u5668\u91cd\u65b0\u542f\u52a8</p> </li> <li> <p>docker start \u5199\u5bb9\u5668\u7684\u540d\u5b57\u3001\u5bb9\u5668\u7684id\u3001id\u4e5f\u53ef\u4ee5\u53ea\u5199\u4e09\u4f4d\uff0c\u80fd\u8ddf\u5176\u4ed6\u4eba\u533a\u5206\u5c31\u884c</p> </li> </ul> <p></p> <p>\u4ee5\u4e0a\uff0c\u4ee3\u8868\u628a\u5b83\u542f\u52a8\u8d77\u6765\u4e86</p> <p>docker ps \u67e5\u770b\uff0c\u8fd9\u4e2a\u5e94\u7528<code>up</code>\uff0c\u8868\u793a\u542f\u52a8\u8d77\u6765\u4e86</p> <p>\u25b6\ufe0f \u542f\u52a8\u7684\u5e94\u7528\u5982\u679c\u60f3\u505c\u6389\uff0c\u53ef\u4ee5\u4f7f\u7528<code>docker stop</code>\u547d\u4ee4\uff0c\u628a\u8fd9\u4e2a\u5e94\u7528\u505c\u6389\uff0c\u53ef\u4ee5\u4f7f\u7528\u5b83\u7684\u5e94\u7528\u540d</p> <p></p> <p>docker ps\u67e5\u770b\u8fd0\u884c\u4e2d\u7684\u5e94\u7528\u5c31\u6ca1\u6709\u4e86</p> <p>\u60f3\u8981\u770b\u5230\u5b83\u5c31ps -a</p> <p></p> <p>\u770b\u5230\u4e03\u79d2\u524d\u9000\u51fa</p> <p>\u25b6\ufe0f docker restart</p> <p>\u65e0\u8bba\u8fd9\u4e2a\u5bb9\u5668\u662f\u8fd0\u884c\u4e2d\u8fd8\u662f\u505c\u6b62\u4e86\uff0c\u90fd\u53ef\u4ee5\u4f7f\u7528restart\u91cd\u542f\u4e00\u4e0b</p> <p></p> <p>docker ps \uff0c\u770b\u4e00\u4e0b\uff0c\u53c8\u91cd\u65b0<code>up</code>\u4e0a\u7ebf\u4e86</p> <p>\u25b6\ufe0f <code>docker states</code> </p> <p>\u67e5\u770b\u8fd9\u4e2a\u5e94\u7528CPU\u5185\u5b58\u7b49\u5360\u7528\u60c5\u51b5</p> <p></p> <p>\u6253\u5370592\u5bb9\u5668\uff0cCPU\u5185\u5b58\u5305\u62ec\u7f51\u7edcIO\u6574\u4e2a\u60c5\u51b5\uff0c\u800c\u4e14\u662f\u6bcf\u79d2\u53d8\u5316\u7684\uff0c\u8fd9\u4e00\u5757\u6ca1\u6709\u53d8\u5316\u7684\u539f\u56e0\u662f\u56e0\u4e3a\u8fd9\u4e2a\u5bb9\u5668\u73b0\u5728\u6ca1\u6709\u5904\u7406\u4efb\u4f55\u8bf7\u6c42\uff0c\u6240\u4ee5\u6574\u4e2a\u8d44\u6e90\u7684\u5360\u7528\u6ca1\u6709\u53d8\u5316</p> <p>\u25b6\ufe0f <code>docker logs 592</code></p> <p></p> <p>\u5bb9\u5668\u5728\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4f1a\u4ea7\u751f\u5927\u91cf\u65e5\u5fd7\uff0c\u6709\u65f6\u8981\u7528\u65e5\u5fd7\u6392\u9519\u7b49</p> <p>\u5c31\u53ef\u4ee5\u4f7f\u7528docker logs\u67e5\u770b\u5bb9\u5668\u65e5\u5fd7</p> <p></p> <p>\ud83d\udfe2 \u5220\u9664\u5bb9\u5668</p> <p>run \u8d77\u6765\u7684\u955c\u50cf \u53eb\u505a \u5bb9\u5668\u3002\u60f3\u8981\u5220\u9664\u4e00\u4e2a\u5bb9\u5668\uff0c\u5fc5\u987b\u5148stop\u505c\u4e86\uff0c\u624d\u80fd\u5220\u9664\uff1b\u4e5f\u53ef\u4ee5\u4f7f\u7528false remove\u5f3a\u5236\u5220\u9664</p> <p></p> <p>\ud83d\udfe2 \u5f3a\u5236\u5220\u9664\u7684\u5199\u6cd5\uff1a</p> <p></p> <p>\u8fd9\u6837\u8fd0\u884c\u4e2d\u7684\u5bb9\u5668\u4e5f\u80fd\u5220\u9664</p> <p>\ud83d\udfe2\u68c0\u67e5\uff1adocker ps\uff1bdocker ps -a</p> <p></p> <p>\u90fd\u6ca1\u6709</p>"},{"location":"sticks/docker/#docker-run","title":"docker run \u540e\u53f0\u542f\u52a8","text":"<p>\u95ee\u9898\u63cf\u8ff0\uff1a\u76f4\u63a5\u4f7f\u7528 <code>docker run image</code>\u4f1a\u5c06\u63a7\u5236\u53f0\u963b\u6b7b\uff0c\u5e76\u4e14\u4e0d\u80fd\u8bbf\u95ee\u7aef\u53e3\uff0c\u60f3\u8981\u540e\u53f0\u542f\u52a8\uff0c\u5e76\u4e14\u8bbe\u7f6e\u53ef\u4ee5\u8bbf\u95ee\u7684\u7aef\u53e3</p> <p>\ud83d\udfe2 docker rm -f container_id/name \u5f3a\u5236\u5220\u9664\u542f\u52a8\u7684\u5bb9\u5668\uff08run \u8d77\u6765\u7684 image\uff09</p> <p>\ud83d\udfe2docker rmi image:tag \u5220\u9664\u955c\u50cf</p> <p>\ud83d\udfe2 \u6700\u7b80\u5355\u7684 docker run image\uff08\u9ed8\u8ba4\u542f\u52a8\u6700\u65b0\u7684 image\uff0cdocker ps \u67e5\u770b\u8be5\u955c\u50cf\u7684\u5bb9\u5668 id\uff09</p> <p>\ud83d\udfe2docker run -d\uff08\u540e\u53f0\u542f\u52a8\uff09 --name my_image_container(\u7ed9\u542f\u52a8\u7684\u955c\u50cf\u8d77\u4e00\u4e2a\u5bb9\u5668\u540d\uff0c\u5982\u679c\u4e0d\u7ed9\u540d\u5b57\uff0c\u4f1a\u8d77\u4e00\u4e2a\u968f\u673a\u540d\u5b57)  image</p> <p></p> <p>\uff081\uff09\u8fd9\u6837\u542f\u52a8\u4ee5\u540e\uff0c\u5bb9\u5668\u72b6\u6001\u662f UP\uff0c\u5e76\u4e14\u540d\u5b57\u662f\u6307\u5b9a\u7684\u540d\u5b57</p> <p>\uff082\uff09\u5e76\u4e14\u542f\u52a8\u662f\u540e\u53f0\u542f\u52a8\uff0c\u8fd4\u56de\u7684\u662f\u5bb9\u5668\u7684\u5b8c\u6574 id</p> <p>\u95ee\u9898\u63cf\u8ff0\uff1a\u6b64\u65f6\u4f9d\u7136\u4e0d\u80fd\u8bbf\u95ee\u7aef\u53e3</p> <p>\u539f\u56e0\u5206\u6790\uff1a</p> <p>\u539f\u56e0\u5728\u4e8e\u542f\u52a8\u7684\u8fd9\u4e2a\u5bb9\u5668\uff0c\u662f\u8fd0\u884c\u5728\u81ea\u5df1\u7684\u73af\u5883\u5185</p> <p>\u5177\u4f53\u89e3\u91ca\uff1a</p> <p>\u5f53docker run\u542f\u52a8\u4e00\u4e2a\u5bb9\u5668\uff0c\u9996\u5148\u662f\u672c\u5730\u7684\u4e3b\u673a\u5b89\u88c5\u4e86docker\uff0c\u6bcf\u4e00\u4e2a\u5bb9\u5668\u5176\u5b9e\u5728\u81ea\u5df1\u7684\u73af\u5883\u5185\u8fd0\u884c\uff0c\u662f\u9694\u79bb\u7684\uff1b\u6bcf\u4e00\u4e2a\u5bb9\u5668\u5b83\u90fd\u62e5\u6709\u81ea\u5df1\u5b8c\u6574\u7684\u6587\u4ef6\u7cfb\u7edf\u3001\u540d\u79f0\u7a7a\u95f4\u3001CPU\u5185\u5b58\u8fdb\u7a0b\u7b49\u8fd9\u4e9b\u64cd\u4f5c\uff1b\u5982\u679cdocker run\u542f\u52a8\u4e86\u4e00\u4e2anginx\uff0c\u5176\u5b9enginx\u5c31\u5b89\u88c5\u5230\u4e86\u8fd9\u4e2a\u5bb9\u5668\u4e2d\uff0c\u4e5f\u5c31\u662f\u5c0f\u578bLINUX\u7cfb\u7edf\u91cc\u8fb9\u8dd1\u7684\u4e00\u4e2a\u8f6f\u4ef6\uff0c\u800c\u8fd9\u4e2anginx\u5360\u7528\u7684\u662f80\u7aef\u53e3\uff0c\u4e5f\u5c31\u662f\u5982\u679c\u4f60\u60f3\u8981\u8bbf\u95eenginx\uff0c\u9664\u975e\u662f\u6765\u5230\u8fd9\u4e2a\u5c0fLINUX\u7cfb\u7edf\u91cc\u8fb9\uff0c\u8bbf\u95ee\u5c0f\u7cfb\u7edf\u768480 \u7aef\u53e3\uff0c\u5c31\u53ef\u4ee5\u8bbf\u95ee\u5230nginx</p> <p>\u4f46\u662f\u73b0\u5728\u60f3\u8981\u8bbf\u95ee\u7684\u662f\u5916\u90e8\u4e3b\u673a\u7684\u4e00\u4e2a\u7aef\u53e3\uff0c\u5c31\u53bb\u8bbf\u95ee\u5230nginx\uff0c\u6bd4\u5982\u60f3\u8981\u8bbf\u95ee\u5916\u90e8\u4e3b\u673a\u768488 \u7aef\u53e3\uff0c\u6700\u7ec8\u8bbf\u95ee\u5230nginx\uff0c\u90a3\u4e48\u5c31\u53ef\u4ee5\u6765\u505a\u4e00\u4e2a\u64cd\u4f5c\u53eb\u7aef\u53e3\u6620\u5c04</p> <p></p> <p>\u4f7f\u7528 <code>-p</code> \u8fd9\u4e2a\u53c2\u6570\u5199\u4e00\u4e2a<code>\u5916\u90e8\u7aef\u53e3:\u5185\u90e8\u7aef\u53e3</code>\u5c31\u4ee3\u8868\u8bbf\u95ee\u4e3b\u673a\u5916\u90e8\u768488\u7aef\u53e3\u5c31\u7b49\u4e8e\u8bbf\u95ee\u5bb9\u5668\u5185\u90e8\u7684<code>80</code> \u7aef\u53e3\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u53eb\u7aef\u53e3\u6620\u5c04\uff0c<code>p</code>\u5c31\u662f<code>port</code>\u7684\u7b80\u5199</p> <p>\ud83d\udfe2 \u7aef\u53e3\u6620\u5c04 </p> <p><code>docker run -d \u540e\u53f0\u542f\u52a8 --name \u5bb9\u5668\u540d -p \u672c\u5730 80 \u7aef\u53e3:\u5bb9\u5668\u5185 80 \u7aef\u53e3 \u955c\u50cf\u540d nginx</code></p> <p></p> <p>\u6b64\u65f6\uff0cdocker ps\uff0c\u67e5\u770b\u5bb9\u5668\u72b6\u6001</p> <p></p> <p>\u8ddf\u4e4b\u524d\u7684\u6253\u5370\u6709\u6240\u533a\u522b\uff1a\u5728PORTS\u7aef\u53e3\u8fd9\u4e00\u5757\uff0c<code>0.0.0.0:80</code> \u4ee3\u8868\u4efb\u4f55<code>IP</code>\u8bbf\u95ee<code>80</code>\u7aef\u53e3\u5c31\u662f\u5bb9\u5668\u5185\u90e8\u7684<code>80</code>\u7aef\u53e3</p> <p>\u6b64\u65f6\uff0c\u6d4f\u89c8\u5668\u4e0a\u91cd\u65b0\u5237\u65b0</p> <p></p> <p>nginx\u7684\u9ed8\u8ba4\u9875\u9762\u5c31\u5c55\u793a\u51fa\u6765\u4e86\u3002 03:19 \u6240\u4ee5\u975e\u5e38\u91cd\u8981\u7684\u4e00\u4e2a\u70b9 03:21 \u5c31\u662f\u5982\u679c\u6211\u4eec\u4f7f\u7528docker\u542f\u52a8\u4e00\u4e2a\u5bb9\u5668 03:24 \u60f3\u8981\u8ba9\u5916\u8fb9\u968f\u65f6\u80fd\u8bbf\u95ee 03:26 \u4e00\u5b9a\u8981\u4e3a\u8fd9\u4e2a\u5bb9\u5668\u66b4\u9732\u7aef\u53e3 03:29 \u4e5f\u5c31\u662f\u6765\u505a\u7aef\u53e3\u6620\u5c04</p> <p>\u95ee\u9898\u63cf\u8ff0\uff1a<code>\u672c\u673a 88 \u7aef\u53e3</code>\u6620\u5c04\u5230<code>\u5bb9\u5668 80 \u7aef\u53e3</code>\uff0c\u4e24\u4e2a\u7aef\u53e3\uff0c<code>\u672c\u673a 88 \u7aef\u53e3</code>\u53ef\u4ee5\u91cd\u590d\u5417\uff1f<code>\u5bb9\u5668 80 \u7aef\u53e3</code>\u53ef\u4ee5\u91cd\u590d\u5417\uff1f</p> <p>\u590d\u8ff0\u95ee\u9898\uff1a\u5982\u679c\u542f\u52a8\u4e00\u4e2a\u65b0\u7684\u5bb9\u5668\uff0c\u65b0\u7684\u5bb9\u5668\u5185\u90e8\u4e5f\u7528<code>80 \u7aef\u53e3</code>\uff0c\u5916\u90e8\u7aef\u53e3\u6620\u5c04\u5230 <code>88 \u7aef\u53e3</code>\u53ef\u4ee5\u5417\uff1f</p> <p>\ud83d\udfe2 \u7b54\uff1a<code>\u672c\u673a 88 \u7aef\u53e3</code>\u4e0d\u53ef\u4ee5\u91cd\u590d\uff0c<code>\u5bb9\u5668\u5185\u90e880\u7aef\u53e3</code>\u53ef\u4ee5\u91cd\u590d\uff0c\u4e5f\u5c31\u662f\u540c\u4e00\u4e2a\u955c\u50cf\uff0c\u542f\u52a8\u7684\u5bb9\u5668 A \u53ef\u4ee5\u662f <code>80 \u7aef\u53e3</code>\uff0c\u5bb9\u5668 B \u4e5f\u53ef\u4ee5\u662f <code>80 \u7aef\u53e3</code></p> <p>\u7406\u7531\uff1a \u56e0\u4e3a88 \u7aef\u53e3\u662f\u5360\u5230\u6211\u4eec\u81ea\u5df1\u4e3b\u673a\u4e0a\u7684\u540c\u4e00\u53f0\u673a\u5668\uff0c\u540c\u4e00\u4e2a\u7aef\u53e3\u53ea\u80fd\u5f00\u4e00\u4e2a \u800c80 \u7aef\u53e3\u53ef\u4ee5\u91cd\u590d\u7684\uff0c\u56e0\u4e3a\u8fd9\u4e2a80\u662f\u5bb9\u5668\u768480 \u7aef\u53e3\uff0c\u5bb9\u5668 A \u53ef\u4ee5\u662f <code>80 \u7aef\u53e3</code>\uff0c\u5bb9\u5668 B \u4e5f\u53ef\u4ee5\u662f <code>80 \u7aef\u53e3</code>\uff0c\u56e0\u4e3a \u5bb9\u5668\u4e4b\u95f4\u662f\u9694\u79bb\u7684\uff0c\u53ea\u662f\u5728\u505a\u7aef\u53e3\u6620\u5c04\u7684\u65f6\u5019\uff0c\u6ce8\u610f\u9632\u6b62\u51b2\u7a81\u5373\u53ef\u3002\u6bcf\u4e00\u4e2a\u5bb9\u5668\u90fd\u53ef\u4ee5\u8ba4\u4e3a\u662f\u4e00\u4e2a\u72ec\u7acb\u7684LINUX\u670d\u52a1\u5668\u3002</p>"},{"location":"sticks/docker/#_5","title":"\u4fee\u6539\u5bb9\u5668","text":"<p>\u95ee\u9898\u63cf\u8ff0\uff1a</p> <p></p> <p>\u9ed8\u8ba4\u662fnginx\u6b22\u8fce\u9875\uff0c\u60f3\u8981\u628a\u5b83\u6539\u6210\u81ea\u5df1\u7684\u6b22\u8fce\u9875\u9762\u3002\u600e\u4e48\u4fee\u6539\u5462\uff1f</p> <p>\ud83d\udfe2 \u9700\u8981\u7528\u5230\u7684\u547d\u4ee4\uff1adockr exec \u547d\u4ee4</p> <p>\u4f7f\u7528dockr exec\u547d\u4ee4\uff0c\u8fdb\u5165\u5230\u88c5\u4e86ngnix\u7684\u8fd9\u4e2a\u5bb9\u5668\u91cc\u8fb9\uff0c\u5728\u8fd9\u4e2a\u5bb9\u5668\u91cc\u8fb9\u6709\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\u53ebuser/share/nginx/html\uff0cngnix\u7684\u9ed8\u8ba4\u9875\u5728\u8fd9\u5b58\u7740\u3002</p> <p>\u95ee\u9898\u63cf\u8ff0\uff1a\u600e\u4e48\u77e5\u9053\u4fee\u6539\u7684\u6587\u6863\u5728\u54ea\u91cc\uff1f</p> <p></p> <p>\u600e\u4e48\u77e5\u9053\u4fee\u6539\u7684\u6587\u6863\u5728\u54ea\u91cc\uff1f</p> <p>\u9605\u8bfb\u5b98\u65b9\u6587\u6863\uff0cdocker hub\uff0c\u4e0b\u8f7d ngnix \u955c\u50cf\u7684\u65f6\u5019\uff0c\u955c\u50cf\u7684\u4ecb\u7ecd\u9875 Overview\uff0c\u4f1a\u8bf4\u660e \u9759\u6001\u9875\u9762\u4f4d\u7f6e\u5728\u54ea\u3002</p> <p></p> <p></p> <p>\u56de\u5230\u6211\u4eec\u7684\u95ee\u9898\uff1a\u5982\u679c\u6211\u4eec\u60f3\u8981\u4fee\u6539ngnix\u9ed8\u8ba4\u9875\uff0c\u56e0\u4e3angnix\u662f\u88c5\u5230\u5bb9\u5668\u91cc\u8fb9\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u8fdb\u5165\u5230\u8fd9\u4e2a\u5bb9\u5668\u91cc\u8fb9\u7684ngnix\u5b58\u9875\u9762\u7684\u4f4d\u7f6e\u8fdb\u884c\u4fee\u6539</p> <p>\u5177\u4f53\u6b65\u9aa4\uff1a</p> <p>\uff081\uff09\u6253\u5f00\u7ec8\u7aef\uff0c\u8fdb\u5165\u5bb9\u5668\uff0c\u4f7f\u7528<code>docker exec -it mynginx /bin/bash</code></p> Bash<pre><code>docker exec -it mynginx /bin/bash\n</code></pre> <p><code>it</code> \u8868\u793a\u4ee5\u4ea4\u4e92\u6a21\u5f0f\uff0c\u76f8\u5f53\u4e8e\u8fdb\u884c\u4ea4\u4e92\uff0c\u8fdb\u884c\u547d\u4ee4\u7684\u53d1\u9001\uff0c\u4ee5\u4ea4\u4e92\u6a21\u5f0f\u8fdb\u5165\u5230\u54ea\u91cc\u5462\uff1f\u5c31\u5199\u5bb9\u5668\u540d\uff0c\u5bb9\u5668\u540d\u53eb<code>mynginx</code>\uff08\u6216\u8005\u5199 id \u4e5f\u662f\u53ef\u4ee5\u7684\uff09</p> <p>\u540e\u8fb9\u518d\u52a0\u4e0a\uff0c\u56e0\u4e3a\u8981\u8fdb\u884c\u4ea4\u4e92\uff0c\u90a3\u4e48\u4f7f\u7528\u54ea\u79cd\u65b9\u5f0f\u8fdb\u884c\u4ea4\u4e92\uff1f\u4f7f\u7528\u63a7\u5236\u53f0\u4ea4\u4e92\uff0c\u6240\u4ee5\u540e\u9762\u63a5 <code>/bin/bash</code> </p> <p></p> <p>\ud83d\udfe2\uff082\uff09\u89c2\u5bdf\u533a\u522b\u3002\u539f\u6765\u662f root@VM...... \u53d8\u6210 root@2d83bd....  \u8868\u793a\u73b0\u5728\u5df2\u7ecf\u8fdb\u884c\u5230\u4e86 ngnix \u5bb9\u5668\u5185\u90e8</p> Bash<pre><code>ls /\n</code></pre> <p><code>ls /</code> \u5217\u51fa\u76ee\u5f55\u7ed3\u6784</p> <p></p> <p>\u63a7\u5236\u53f0\u8f93\u51fa\u4e5f\u662f\u4e00\u4e2a LINUX\u7cfb\u7edf\u7684\u76ee\u5f55\u7ed3\u6784\uff0c\u4e5f\u5c31\u662f\u8bf4\u5bb9\u5668\u6709\u81ea\u5df1\u7684\u6587\u4ef6\u7cfb\u7edf\uff0c\u5e26\u4e86nginx\u5b8c\u6574\u7684\u8fd0\u884c\u73af\u5883</p> <p>\u800cnginx\u9875\u9762\u7684\u4f4d\u7f6e\u5728<code>usr/share/nginx/html/</code> \uff0c\u8fdb\u5165\u8be5\u6587\u4ef6</p> <p> </p> <p><code>ls</code> \u53ef\u4ee5\u770b\u5230\u6709\u4e00\u4e2aindex\u9875\u9762\uff0c\u53ef\u4ee5\u4fee\u6539</p> <p></p> <p><code>vi index.html</code> \u56de\u8f66</p> <p></p> <p>\u5bb9\u5668\u4e3a\u4e86\u4fdd\u6301\u8f7b\u91cf\u7ea7\uff0c\u5185\u90e8\u7684\u8fd9\u4e2aLINUX\u7cfb\u7edf\u6ca1\u6709 <code>vi</code> \u547d\u4ee4\uff0c\u5982\u679c\u60f3\u8981\u4fee\u6539\u9875\u9762\u4f7f\u7528 <code>echo</code> \u65b9\u5f0f\u3002\u5982\u56fe\u6240\u793a\u5373\u53ef\u3002</p> <p>\u518d\u6b21\u6765\u8bbf\u95ee\uff0c\u5237\u65b0\u6d4f\u89c8\u5668\uff0c\u5c55\u793a\u65b0\u7684\u9875\u9762</p> <p></p> <p>\u95ee\u9898\u63cf\u8ff0\uff1a\u6bcf\u6b21\u60f3\u8981\u4fee\u6539\u5bb9\u5668\u5185\u90e8\u7684\u4e1c\u897f\uff0c\u8fd8\u8981\u4f7f\u7528docker exec\u8fdb\u5165\u5230\u5185\u90e8\u518d\u8fdb\u884c\u4fee\u6539\uff0c\u6709\u70b9\u9ebb\u70e6\uff0c\u6bd4\u8f83\u7b80\u5355\u7684\u65b9\u5f0f\uff1f</p> <p>\ud83d\udfe2 \u4f7f\u7528<code>docker</code> \u7684\u5b58\u50a8\u628a\u5185\u90e8\u7684\u4e00\u4e2a\u6587\u4ef6\u5939\uff0c\u76f4\u63a5\u6620\u5c04\u5230\u5916\u90e8\u4e3b\u673a\u7684\u4e00\u4e2a\u4f4d\u7f6e\u4ee5\u540e\uff0c \u5728\u4e3b\u673a\u4f4d\u7f6e\u6539\uff0c\u5185\u90e8\u4e5f\u4f1a\u53d1\u751f\u53d8\u5316\uff08\u5177\u4f53\u65b9\u5f0f\uff0c\u8e72\u4e00\u4e2a\uff09</p> <p>\uff083\uff09\u4fee\u6539\u5b8c\u6210\u4ee5\u540e\uff0cexit \u9000\u51fa\u5bb9\u5668\uff0c\u91cd\u65b0\u56de\u5230\u672c\u5730\u673a\u5668\u7684\u4e3b\u63a7\u5236\u754c\u9762</p> <p></p> <p>\u4ee5\u4e0a\u6574\u4e2a\u8fc7\u7a0b\u5b9e\u73b0\u4e86\uff0c\u672c\u5730\u4e3b\u673a\u8bbf\u95ee 80 \u7aef\u53e3\u53ef\u4ee5\u8bbf\u95ee\u5230\u5df2\u7ecf\u4fee\u6539\u597d\u7684\u9875\u9762\u3002</p>"},{"location":"sticks/docker/#_6","title":"\u4fdd\u5b58\u955c\u50cf","text":"<p>\ud83d\udd34 \u95ee\u9898\u63cf\u8ff0 \uff1a\u628a\u5236\u4f5c\u597d\u7684\u8fd9\u4e2a\u8f6f\u4ef6\uff0c\u80fd\u9ed8\u8ba4\u9996\u9875\u8fd4\u56dehello docker\u7684\u8f6f\u4ef6\uff0c\u53d1\u5e03\u5230\u5e94\u7528\u5e02\u573a\uff0c\u8ba9\u522b\u4eba\u4e0b\u8f7d\u8fd9\u4e2a\u8f6f\u4ef6\uff0c\u9ed8\u8ba4\u8bbf\u95ee\u4e5f\u80fd\u5c55\u793ahello docker</p> <p></p> <p>\u7b2c\u56db\u6b65\uff0c\u4fdd\u5b58\u955c\u50cf\u3002</p> <p>\u4e4b\u524d\u542f\u52a8\u4e86\u5bb9\u5668\u5185\u90e8\u7684\u9875\u9762\uff0c\u4e5f\u4fee\u6539\u4e86\uff0c\u73b0\u5728\u5e0c\u671b\u628a\u8fd9\u4e2a\u8fd0\u884c\u4e2d\u7684\u8f6f\u4ef6\uff0c\u6253\u5305\u6210\u4e00\u4e2a\u955c\u50cf\u4fdd\u5b58\u8d77\u6765\uff0c\u6700\u7ec8\u53ef\u4ee5\u5206\u4eab\u5230\u793e\u533a</p> <p>\u9700\u8981\u7528\u5230\u7684\u547d\u4ee4\u5982\u4e0b\uff1a</p> <p></p> <ul> <li>\u63d0\u4ea4\uff1adocker commit</li> <li>\u4fdd\u5b58\uff1adocker save</li> <li>\u52a0\u8f7d\uff1adocker load</li> </ul>"},{"location":"sticks/docker/#docker-commit","title":"docker commit","text":"<p>\u67e5\u770b docker commit \u7684\u529f\u80fd\uff1a</p> Bash<pre><code>docker commit --help\n</code></pre> <p>\u67e5\u770b\u6587\u6863\u63cf\u8ff0\uff1a</p> <p></p> <p>docker commit\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2anew image\u65b0\u955c\u50cf\uff0c\u4ece\u4e00\u4e2a\u5bb9\u5668\u7684\u6539\u53d8\u91cc\u8fb9\u3002</p> <p>\u4e5f\u5c31\u662f\u5229\u7528commit\u547d\u4ee4\uff0c\u53ef\u4ee5\u628a\u6574\u4e2a\u5bb9\u5668\u4ee5\u53ca\u5b83\u7684\u6240\u6709\u53d8\u5316\uff0c\u6253\u5305\u6210\u4e00\u4e2a\u65b0\u7684\u955c\u50cf</p> <p>\u53c2\u6570\u8bf4\u660e\uff1a</p> <ul> <li> <p><code>-a</code> \u6307\u5b9a\u4f5c\u8005</p> </li> <li> <p><code>-c</code>  \u6709\u54ea\u4e9b\u6539\u53d8\u7684\u5217\u8868</p> </li> <li> <p><code>-m</code> \u6b64\u6b21\u63d0\u4ea4\u4e86\u7684\u4fe1\u606f</p> </li> <li> <p><code>-p</code>  \u6253\u5305\u671f\u95f4\u52a0\u4e0a <code>-p</code> \u53ef\u4ee5\u6682\u505c\u5bb9\u5668\u7684\u8fd0\u884c</p> </li> </ul> <p>\u7528\u6cd5\uff1a</p> Bash<pre><code>Usage:  docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]\n</code></pre> <p>docker commit + \u90a3\u4e00\u5806\u53ef\u9009\u53c2\u6570 + \u5bb9\u5668   +  \u955c\u50cf : \u6807\u7b7e </p> <p>\u6f14\u793a\uff1a</p> Bash<pre><code>docker commit -m\"update index.html\" mynginx mynginx:v1.0\n</code></pre> <p></p> <p>\u8fd0\u884c\u6210\u529f\uff0c\u68c0\u67e5docker images\uff0c\u6240\u6709\u955c\u50cf\u5217\u8868</p> <p></p>"},{"location":"sticks/docker/#docker-save","title":"docker save","text":"<p>\u6253\u5305\u6587\u4ef6</p> Bash<pre><code>docker save --help\n</code></pre> <p>\u67e5\u770b\u5e2e\u52a9\u6587\u6863 &amp; \u547d\u4ee4\u529f\u80fd\uff1a</p> <p></p> <p>\u5177\u4f53\u4f7f\u7528\u5b9e\u4f8b\uff1a</p> <p></p> <p>docker save\uff0c\u52a0\u4e0a\u955c\u50cf\uff0c\u5148\u6765\u5199<code>docker save</code>\uff0c\u8981\u4fdd\u5b58\u7684\u955c\u50cf\u662f<code>myngnix</code>\uff0c\u6807\u7b7e <code>v1.0</code></p> <p>\u955c\u50cf\u4e2d\u95f4\u53ef\u4ee5\u52a0\u4e00\u4e9b\u53c2\u6570\uff0c\u5373 <code>save</code>\u8ddf<code>image</code>\u4e2d\u95f4\u52a0 <code>options</code></p> <p><code>option</code>\u91cc\u8fb9\u53ef\u4ee5\u6307\u5b9a <code>-o</code> \u5c31\u662f\u5c06\u8fd9\u4e2a\u955c\u50cf\u8f93\u51fa\u6210\u4e00\u4e2a <code>.tar</code> \u538b\u7f29\u6587\u4ef6\uff0c\u8fd9\u4e2a\u538b\u7f29\u5305\u6587\u4ef6\uff0c\u53ef\u4ee5\u968f\u4fbf\u8d77\u540d\uff0c\u8fd9\u91cc\u4e5f\u53eb <code>myngnix.tar</code></p> <p></p> <p>\u8fd9\u4e2a\u5305\uff0c\u53ef\u4ee5\u653e\u5230U\u76d8\u4f20\u8f93\u7ed9\u522b\u4eba\uff0c\u522b\u4eba\u5c31\u80fd\u4f7f\u7528\u4e86</p> <p>\ud83d\udd34 \u95ee\u9898\u63cf\u8ff0\uff1a\u522b\u4eba\u600e\u4e48\u4f7f\u7528\uff1f</p>"},{"location":"sticks/docker/#docker-load_1","title":"docker load","text":"<p>\u8865\u5145 \u540c\u65f6\u5220\u9664\u591a\u4e2a\u955c\u50cf\u547d\u4ee4\uff1a</p> Bash<pre><code>docker rmi imageID1 imageID2 imageID3\n</code></pre> <p>\u5220\u9664\u5bb9\u5668\uff1a</p> Bash<pre><code>docker rm -f container_id\n</code></pre> <p>\ud83d\udd35 \u573a\u666f\u63cf\u8ff0\uff1a\u522b\u4eba\u62f7\u8d1d\u4e86 <code>mynginx.tar</code> \uff0c\u90a3\u4e48\u5bf9\u65b9\u600e\u4e48\u542f\u52a8\u4e00\u6a21\u4e00\u6837\u7684\u5e94\u7528\u5462\uff1f\uff08\u5982\u4f55\u628a\u4ece\u522b\u4eba\u90a3\u91cc\u62f7\u8d1d\u6765\u7684\u955c\u50cf\uff0c\u8fd0\u884c\u51fa\u4e00\u6837\u7684\u5bb9\u5668\uff08\u5e94\u7528\uff09\uff1f\uff09</p> <p>\u5b89\u88c5 docker \u7684\u673a\u5668\u4e0a\uff0c\u6839\u76ee\u5f55\u53ea\u6709  <code>mynginx.tar</code></p> <p></p> <p>\u6b64\u65f6\u4f7f\u7528\uff0cdocker load\uff0c\u5177\u4f53\u600e\u4e48\u4f7f\u7528\uff0c\u5148\u67e5\u5e2e\u52a9\u6587\u6863</p> <p></p> <p>\u53c2\u6570\u89e3\u8bfb\uff1a</p> <ul> <li><code>-i</code> \u6307\u5b9a\u538b\u7f29\u5305\u4f4d\u7f6e\uff0c\u4f1a\u81ea\u52a8\u5c06\u538b\u7f29\u5305\u8bfb\u53d6\u8fdb\u6765</li> </ul> <p></p> <p><code>docker images</code> \u68c0\u67e5</p> <p></p> <p>\ud83d\udfe2 \u6709\u4e86\u955c\u50cf\uff08only read\uff09\u4ee5\u540e\uff0c\u4f7f\u7528docker run\u547d\u4ee4\u542f\u52a8\u5bb9\u5668\uff08\u5b9e\u4f8b\u5316\u7684\u955c\u50cf\uff09\uff0c</p> <p>docker run myngnix:v1.0  (\u955c\u50cf\u540d:\u7248\u672c\u53f7)</p> <p>\u4e2d\u95f4\u52a0\u53ef\u8bfb\u53c2\u6570\uff1a</p> <p><code>-d</code> \u540e\u53f0\u542f\u52a8\uff1b<code>--name</code> \u5bb9\u5668\u540d\u79f0\uff1b<code>-p 80:80</code> \u7aef\u53e3\u6620\u5c04</p> <p></p> <p>\u8fd4\u56de\u5b8c\u6574\u7684\u5bb9\u5668\u540d\u3002</p> <p><code>docker ps</code> \u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684\u5bb9\u5668\uff1b\u5237\u65b0\u6d4f\u89c8\u5668\uff0c\u8bbf\u95ee\u672c\u5730 80 \u7aef\u53e3\uff0c\u5c31\u662f\u6539\u8fc7\u7684\u9875\u9762\uff0c\u8fd0\u884c\u4e86\u4e00\u6a21\u4e00\u6837\u7684\u5e94\u7528\u3002</p> <p></p> <p>\u603b\u7ed3\uff1a</p> <ul> <li>docker commit\uff1a\u5bb9\u5668\u63d0\u4ea4\u4e3a\u955c\u50cf</li> <li>docker save\uff1a\u955c\u50cf\u6253\u5305\u6210\u53ef\u79fb\u690d\u7684 tar \u6587\u4ef6</li> <li>docker load\uff1a\u52a0\u8f7d\u955c\u50cf\u6587\u4ef6</li> <li>docker run\uff1a\u542f\u52a8\u955c\u50cf\uff0c\u5b9e\u4f8b\u5316\u955c\u50cf\uff0c\u542f\u52a8\u5e94\u7528\uff0c\u5b9e\u4f8b\u5316\u6210\u4e00\u4e2a\u5bb9\u5668</li> <li>[TODO] \u8fd8\u5f97\u8865\uff0c\u600e\u4e48\u672c\u5730\u4fee\u6539\u548c\u955c\u50cf\u4fee\u6539...</li> </ul> <p>\ud83d\udd35 \u573a\u666f\u63cf\u8ff0\uff1a\u628a\u955c\u50cf\u4fdd\u5b58\u6210\u4e00\u4e2a\u6587\u4ef6\u7684\u65b9\u5f0f\uff0c\u65b9\u4fbf\u5229\u7528\u6587\u4ef6\u4f20\u8f93\u7684\u624b\u6bb5\u8fdb\u884c\u4f20\u8f93\uff0c\u53e6\u5916\u4e00\u79cd\u65b9\u5f0f\uff0c\u628a\u955c\u50cf\u63a8\u9001\u7ed9\u793e\u533a\uff0c\u76f4\u63a5\u4f7f\u7528docker pull \u8fdb\u884c\u4e0b\u8f7d</p>"},{"location":"sticks/docker/#docker-push","title":"docker push","text":"<p>\u5206\u4eab\u793e\u533a</p> <p></p> <p>\u6700\u540e\u4e00\u6b65\uff0c\u5206\u4eab\u793e\u533a\uff0c\u628a\u955c\u50cf <code>mynginx:v1.0</code>  \u5206\u4eab\u5230\u5b98\u65b9\u7684docker hub \u4ed3\u5e93</p> <p>\u9700\u8981\u7528\u5230\u7684 3 \u4e2a\u547d\u4ee4\uff1a</p> <ul> <li>docker login\uff1a\u9996\u5148\u767b\u5f55\u5230 docker hub</li> <li>docker tag\uff1adocker hub \u8981\u6c42\u7ed9\u955c\u50cf\u91cd\u65b0\u8d77\u4e00\u4e2a\u540d\u5b57</li> <li>docker push\uff1a\u6700\u540e\u5c06\u955c\u50cf\u63a8\u9001\u4e0a\u53bb</li> </ul> <p>\ud83d\udfe2 docker login</p> <ul> <li>\u67e5\u770b\u7528\u6237\u540d</li> </ul> <p></p> <p>\ud83d\udfe2 <code>docker login</code>\uff0c\u6309\u7167\u63d0\u793a \u8f93\u5165<code>\u7528\u6237\u540d</code>\u548c<code>\u5bc6\u7801</code></p> <p></p> <p>\u5982\u679c\u60f3\u8981\u63a8\u9001\u5230\u7f51\u9875\u7aef\uff0c\u5728\u7f51\u9875\u7aef\u767b\u5f55\u4ee5\u540e\uff0c\u5ba2\u6237\u7aef\uff08\u4e5f\u5c31\u662f\u7ec8\u7aef\uff09\u4e5f\u9700\u8981\u767b\u5f55\uff0c\u76f4\u63a5\u8f93\u5165 <code>docker login</code>\uff0c\u6309\u7167\u63d0\u793a\u8f93\u5165 <code>\u7528\u6237\u540d</code>\u548c<code>\u5bc6\u7801</code>\u5373\u53ef\u3002</p> <p></p> <p>\ud83d\udfe2 \u767b\u5f55\u6210\u529f\u4ee5\u540e\uff0c\u60f3\u8981\u63a8\u9001 <code>mynginx</code> \u955c\u50cf\uff0c\u63a5\u4e0b\u6765\uff0c\u4f7f\u7528 <code>docker tag</code> \u5bf9\u8fd9\u4e2a\u955c\u50cf\u8fdb\u884c\u6539\u540d</p> <p>\u7406\u7531\uff1a\u56e0\u4e3adocker hub\u4e3a\u4e86\u533a\u5206\u8fd9\u4e9b\u955c\u50cf\uff0c\u6bcf\u4e00\u4e2a\u955c\u50cf\u7684\u540d\u5b57\u90fd\u662f\u5b83\u7684\u7528\u6237\u540d\u540e\u8fb9\u518d\u52a0\u955c\u50cf\uff0c\u76f8\u5f53\u4e8e\u6211\u4eec\u672c\u5730\u7684\u8fd9\u4e2a\u955c\u50cf\u7f3a\u5c11\u4e86\u7528\u6237\u540d</p> <p>\u5177\u4f53\u7684 docker tag \u600e\u4e48\u5904\u7406\uff1f</p> Bash<pre><code>docker tag --help\n</code></pre> <p>Usage \u663e\u793a\uff0cdocker tag \u4f60\u539f\u6765\u7684\u955c\u50cf\u548ctarget\u65b0\u7684\u76ee\u6807\u955c\u50cf</p> <p>\ud83d\udfe2 </p> Bash<pre><code>docker tag mynginx:v1.0 leifengyang/mynginx:v1.0\n</code></pre> <p></p> <p>\u6267\u884c\u5b8c\u6539\u540d\u64cd\u4f5c\u4ee5\u540e\uff0c<code>docker images</code> \u68c0\u67e5</p> <p></p> <p>\u62e5\u6709\u4e86\u4e00\u4e2a\u65b0\u955c\u50cf <code>leifengyang/mynginx:v1.0</code> \uff0c\u867d\u7136\u955c\u50cf\u540d\u8ddf\u6807\u7b7e\u8ddf\u4e0a\u4e00\u4e2a\u4e0d\u4e00\u6837</p> <p>\u4f46\u662f\u90fd\u662f\u540c\u4e00\u4e2a\u955c\u50cf\uff0c\u6240\u4ee5\u955c\u50cfid\u662f\u4e00\u6837\u7684\uff0c\u6709\u4e86\u8fd9\u4e2a\u65b0\u955c\u50cf\u4ee5\u540e\uff0c\u4f7f\u7528<code>docker push</code>\u628a\u5b83\u63a8\u9001\u4e0a\u53bb</p> <p>\ud83d\udfe2 docker push</p> <p>\ud83d\udce2 \u9700\u8981\u6ce8\u610f\u7684\u662f \u6b64\u65f6\u7684\u63a8\u9001\u4e0d\u80fd\u4f7f\u7528 image ID\uff0c\u56e0\u4e3a\u8fd9\u4e24\u4e2a\u955c\u50cfid\u90fd\u4e00\u6837\uff0c\u6ca1\u6cd5\u533a\u5206\uff0c\u76f4\u63a5\u5199\u955c\u50cf\u52a0\u6807\u7b7e\u56de\u8f66\uff0c\u8fdb\u884c\u955c\u50cf\u63a8\u9001\uff0c\u8fde\u5411\u7684\u662fdocker hub\uff0c\u4f1a\u6bd4\u8f83\u6162\u4e00\u70b9</p> Bash<pre><code>docker push leifengyang/mynginx:v1.0\n</code></pre> <p></p> <p>\u6574\u4e2a\u63a8\u9001\u5b8c\u4ee5\u540e\uff0c\u8fd9\u4e00\u5757\u51fa\u73b0\u6253\u5370\uff0c\u6765\u5230\u4e2a\u4eba\u4e3b\u9875\uff0c\u5237\u65b0 Repositories\uff0c\u5c31\u662f\u4e2a\u4eba\u7684\u955c\u50cf\u4ed3\u5e93\uff0c\u800c\u4e14\u662f\u4e00\u4e2apublic\u955c\u50cf\uff0c\u6240\u6709\u4eba\u90fd\u53ef\u4ee5\u8bbf\u95ee\u3002</p> <p></p> <p>\u70b9\u8fdb\u8fd9\u4e2a\u955c\u50cf\uff0c\u4e5f\u80fd\u770b\u5230\u8fd9\u4e2a\u955c\u50cf\uff0c\u63a8\u4e86\u4e00\u4e2a\u6807\u7b7e\u53ebv1.0</p> <p></p> <p>\u53ef\u4ee5\u4e3a\u8fd9\u4e2a\u955c\u50cf\u53bb\u6765\u7f16\u5199\u4e00\u4e2a\u8bf4\u660e\u4e66</p> <p></p> <p>\u70b9\u51fb <code>Add overview</code> \uff0c\u652f\u6301markdown\u8bed\u6cd5</p> <p></p> <p>\u955c\u50cf\u7279\u6027\uff1a\u4fee\u6539\u4e86NGINX\u9ed8\u8ba4\u9875\uff0c\u8fd4\u56dehello docker</p> <p>\u542f\u52a8\u547d\u4ee4\uff1a\u6765\u544a\u8bc9\u522b\u4eba\u600e\u4e48\u7528\u8fd9\u4e2a\u955c\u50cf</p> <p>docker run -d \u4ee5\u540e\u53f0\u65b9\u5f0f\u542f\u52a8 -p\u7aef\u53e3 \u66b4\u9732\u5916\u90e8\u768480\u8bbf\u95ee\u5bb9\u5668\u768480 --name mynginx</p> <p>\u7136\u540e\u4f7f\u7528\u8fd9\u4e2a\u955c\u50cf\uff0c\u5168\u79f0+\u6807\u7b7e <code>leifengyang/mynginx:v1.0</code></p> <p>\u70b9\u51fb\u66f4\u65b0\uff0c\u5c31\u4e3a\u8fd9\u4e2a\u955c\u50cf\u5199\u4e86\u4e00\u4e2a\u8bf4\u660e\u4e66</p> <p>\u6709\u4e86\u8fd9\u4e2a\u8bf4\u660e\u4e66\u4ee5\u540e\u5462\uff0c\u522b\u4eba\u53bbdocker hub\u53bb\u6765\u641c\u4f60\u7684\u8fd9\u4e2a\u955c\u50cf\uff0c\u7136\u540e\u6839\u636e\u63cf\u8ff0\u542f\u52a8\u955c\u50cf\u3002</p> <p></p> <p>\ud83d\udce2 \u63a8\u8350\u5c06\u955c\u50cf\u5206\u4eab\u5230\u793e\u533a\u65f6\uff0c\u9664\u4e86\u4e0a\u4f20\u6307\u5b9a\u7248\u672c\u7684\uff0c\u8fd8\u4e0a\u4f20\u4e00\u4e2a\u6700\u65b0\u7248\u672c\u7684\uff0c\u65b9\u4fbf\u76f4\u63a5 docker pull</p> <p>\ud83d\udfe2 \u5177\u4f53\u7684\u64cd\u4f5c\uff0c\u4f7f\u7528 docker tag \u6539\u540d\u5373\u53ef</p> Bash<pre><code>docker tag mynginx:v1.0 leifengyang/mynginx:latest\n</code></pre> <p>\ud83d\udfe2 docker images\u68c0\u67e5\uff0c\u53d1\u73b0\u6709\u4e86 <code>leifengyang/mynginx:latest</code> \u7684\u6700\u65b0\u955c\u50cf\uff0c\u8fd9\u4e2a 3 \u4e2a\u955c\u50cf\u7684 id \u90fd\u662f\u4e00\u6837</p> <p>\ud83d\udfe2 \u4f7f\u7528 docker push \u63a8\u9001\u6700\u65b0\u955c\u50cf\uff0c\u8fd9\u6837\u522b\u4eba\u62c9\u53d6\u955c\u50cf\u5373\u4f7f\u4e0d\u5199\u7248\u672c\u53f7\u4e5f\u4e0d\u4f1a\u62a5\u9519\u3002</p> Bash<pre><code>docker push leifengyang/mynginx:latest\n</code></pre> <p></p> <p></p> <p>\u6574\u4e2a\u63a8\u9001\u5b8c\u6210\uff0c\u5237\u65b0\u81ea\u5df1\u7684\u4ed3\u5e93\uff0c\u6709\u6700\u65b0\u53d1\u5e03\u7684\u7248\u672c\u8fd8\u6709\u6307\u5b9a\u7684\u7248\u672c</p>"},{"location":"sticks/docker/#docker_5","title":"\u603b\u7ed3 docker \u7684\u5e38\u7528\u547d\u4ee4","text":"<p>\u5c24\u5176\u662f docker run \u8fd0\u884c\u4e00\u4e2a\u5bb9\u5668</p> <p></p>"},{"location":"sticks/docker/#_7","title":"\u8865\u5145\u7aef\u53e3\u6620\u5c04","text":"<p>\ud83d\udd35 \u60c5\u51b5\u63cf\u8ff0\uff1a\u73b0\u5728\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u8fd0\u884c\u4e2d\u7684 docker \u5bb9\u5668\uff0c\u5360\u7528\u7684 80 \u7aef\u53e3\uff0c\u73b0\u5728\u5728\u542f\u52a8\u4e00\u4e2a docker \u5bb9\u5668\uff0c\u955c\u50cf\u4ecd\u7136\u662f mynginx:v1.0\uff0c\u8fd9\u6b21\u5360\u7528\u5916\u90e8\u4e3b\u673a\u7684 88 \u7aef\u53e3\uff0c\u76f8\u5f53\u4e8e\u5bb9\u5668\u5185\u90e8\u7684 80 \u7aef\u53e3</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cdocker run -d \u540e\u53f0\u542f\u52a8\uff0c-p \u7aef\u53e3\u6620\u5c04\u672c\u5730 88 \u7aef\u53e3\u5230\u5bb9\u5668\u5185 80 \u7aef\u53e3\uff0c--name app02\u6b64\u65f6 \u5bb9\u5668\u540d\u7edd\u5bf9\u4e0d\u53ef\u4ee5\u8ddf\u4e4b\u524d\u7684\u5bb9\u5668\u540d\u91cd\u590d\uff0c\u542f\u52a8\u7684\u955c\u50cf\u8fd8\u662f mynginx:v1.0</p> <p>\ud83d\udfe2 \u542f\u52a8\u4e00\u4e2a\u5bb9\u5668\uff0c-d \u540e\u53f0\u542f\u52a8\uff0c-p \u672c\u5730 88 \u7aef\u53e3\u6620\u5c04\u5bb9\u5668\u5185\u90e8 80 \u7aef\u53e3\uff0c\u540d\u5b57\u53eb\u505a app02\uff0c\u4ece\u955c\u50cf mynginx \u4e2d\u542f\u52a8\uff0c\u6807\u7b7e\u540d\u4e3a v1.0</p> Bash<pre><code>docker run -d -p 88:80 --name app02 mynginx:v1.0\n</code></pre> <p></p>"},{"location":"sticks/docker/#docker_6","title":"docker \u5b58\u50a8","text":"<p>\ud83d\udd34 \u95ee\u9898\u63cf\u8ff0\uff1a</p> <p>\uff081\uff09\u5982\u679c\u60f3\u8981\u4fee\u6539nginx\u7684\u9ed8\u8ba4\u9875\u9762\uff0c\u9700\u8981\u77e5\u9053\u5728\u5bb9\u5668\u5185\u90e8/usr/share/nginx/html\u8fd9\u4e2a\u4f4d\u7f6e\u4e0b\u5b58\u4e86 nginx \u7684\u9ed8\u8ba4\u9875\uff0c\u60f3\u8981\u4fee\u6539\u8fd9\u4e2a\u9875\u9762\uff0c\u9700\u8981\u4f7f\u7528docker exec\uff0c\u8fdb\u5165\u5230\u5bb9\u5668\u5185\u90e8\u8fdb\u884c\u4fee\u6539</p> <p>\uff082\uff09\u56e0\u4e3a\u5bb9\u5668\u6709\u81ea\u5df1\u7684\u6587\u4ef6\u7cfb\u7edf\u8fd0\u884c\u5728\u81ea\u5df1\u7684\u8fdb\u7a0b\u5185\uff0c\u90a3\u6570\u636e\u81ea\u7136\u4e5f\u5b58\u5230\u81ea\u5df1\u7684\u5bb9\u5668\u5185\u90e8\uff0c\u67d0\u4e00\u5929\u5047\u5982\u8fd9\u4e2a\u5bb9\u5668\u70b8\u4e86\u6216\u8005\u8bef\u5220\u9664\uff0c\u518d\u91cd\u65b0\u542f\u52a8\u4e00\u4e2a\uff0c\u5c31\u76f8\u5f53\u4e8e\u542f\u52a8\u4e86\u4e00\u4e2a\u65b0\u5bb9\u5668\uff0c\u539f\u6765\u5bb9\u5668\u91cc\u8fb9\u7684\u6570\u636e\u4e5f\u4f1a\u4e22\u5931</p> <p>\u4ee5\u4e0a\u63cf\u8ff0\u4e86\u4e24\u79cd\u60c5\u51b5 \u2460 \u4fee\u6539\u4e0d\u5bb9\u6613 \u2461 \u5bb9\u6613\u4e22\u5931</p> <p></p> <p>\ud83d\udce2  \u8865\u5145\u6279\u91cf\u5220\u9664\u7684\u6240\u6709\u5bb9\u5668\u7684\u6280\u5de7</p> <ul> <li>\u5220\u9664\u4e00\u4e2a\u5bb9\u5668\uff1a <code>docker rm containerID</code></li> <li>\ud83d\udfe2 \u7b2c\u4e00\u6b65 \uff1a\u62ff\u5230\u6240\u6709\u5bb9\u5668 ID</li> </ul> Bash<pre><code>docker ps -aq\n</code></pre> <p></p> <p><code>docker ps -a</code> \u62ff\u5230\u6240\u6709\u5bb9\u5668</p> <p><code>docker ps --help</code> </p> <p></p> <p>-a  \u663e\u793a\u6240\u6709\u5bb9\u5668</p> <p>-q \u663e\u793a\u6240\u6709\u5bb9\u5668 ID</p> <ul> <li>\ud83d\udfe2 \u7b2c\u4e8c\u6b65\uff0c\u6279\u91cf\u5220\u9664\u6240\u6709\u5bb9\u5668  <code>-f</code> \u8868\u793a\u5f3a\u5236\u5220\u9664</li> </ul> Bash<pre><code>docker rm -f $(docker ps -aq)\n</code></pre> <p></p> <p>\u73b0\u5728\u6f14\u793a\u5728\u4e0d\u6302\u5728\u76ee\u5f55\u7684\u60c5\u51b5\u4e0b\u600e\u4e48\u4fee\u6539\u9ed8\u8ba4\u9875\u9762 </p> <p>\ud83d\udfe2 \u7b2c\u4e00\u6b65\u542f\u52a8\u5bb9\u5668\uff0c\u5982\u679c\u6ca1\u6709\u955c\u50cf\uff0c\u90a3\u4e48 docker \u4f1a\u81ea\u52a8\u4e0b\u8f7d\u6700\u65b0\u7684\u955c\u50cf\u5e76\u542f\u52a8\u5bb9\u5668\uff1a</p> Bash<pre><code>docker run -d -p 80:80 --name app01 nginx\n</code></pre> <p>\ud83d\udfe2 \u7b2c\u4e8c\u6b65\uff0c\u67e5\u770b\u6b63\u5728\u8fd0\u884c\u7684\u5bb9\u5668</p> Bash<pre><code>docker ps\n</code></pre> <p>\ud83d\udfe2 \u7b2c\u4e09\u6b65\uff0c\u7ec8\u7aef\u8fdb\u5165\u5bb9\u5668\u5185\u90e8  <code>-it</code> \u4ee5\u4ea4\u4e92\u6a21\u5f0f\u542f\u52a8 <code>bash</code> \u7ec8\u7aef</p> Docker<pre><code>docker exec -it 35f bash\n</code></pre> <p>\ud83d\udfe2 \u7b2c\u56db\u6b65\uff0c\u8fdb\u5165\u5230\u60f3\u8981\u4fee\u6539\u7684\u5bb9\u5668\u5185\u90e8\u7684\u6587\u4ef6\uff0c\u9605\u8bfb\u5b98\u65b9\u955c\u50cf\u6587\u6863\uff0c\u627e\u5230\u76ee\u6807\u76ee\u5f55</p> Bash<pre><code>cd /usr/share/nginx/html/\n</code></pre> <p>\ud83d\udfe2 \u7b2c\u4e94\u6b65\uff0c\u6253\u5370\u8be5\u76ee\u5f55\u4e0b\u7684\u6587\u4ef6</p> Bash<pre><code>ls\n</code></pre> <p>\ud83d\udfe2 \u7b2c\u516d\u6b65\uff0c\u4fee\u6539\u76ee\u6807\u6587\u4ef6\uff0c\u5237\u65b0\u9875\u9762\uff0c\u5b8c\u6210\u4fee\u6539</p> Bash<pre><code>echo 11111 &gt; index.html\n</code></pre> <p></p> <p>\u8fd9\u6837\u4fee\u6539\u7684\u6b65\u9aa4\u5df2\u7ecf\u5f88\u7e41\u7410\u4e86\uff0c\u800c\u4e14\u5982\u679c\u60f3\u8981\u7f16\u8f91\u4e00\u4e2a\u6587\u4ef6\uff0cdocker \u5185\u90e8\u90fd\u4e0d\u652f\u6301\u7f16\u8f91\u547d\u4ee4 </p> <p></p> <p>\ud83d\udd34\u4ee5\u4e0a\u60c5\u51b5\u90fd\u8bf4\u660e\u4e86\u5bb9\u5668\u5185\u90e8\u7684\u6240\u6709\u6570\u636e\u7ba1\u7406\u8d77\u6765\u662f\u975e\u5e38\u4e0d\u5bb9\u6613\u7684</p> <p>\u6f14\u793a\u53e6\u4e00\u79cd\u60c5\u51b5\uff0c\u4e0d\u5c0f\u5fc3\u8bef\u5220\u9664\u5bb9\u5668\uff0c\u5982\u679c\u4ee5\u76f8\u540c\u7684\u547d\u4ee4\u518d\u6b21\u542f\u52a8\u5bb9\u5668\uff0c\u6b64\u65f6\u5bb9\u5668\u53d8\u6210\u4e86\u4e00\u4e2a\u65b0\u7684\u5bb9\u5668\uff0c\u521a\u521a\u7684\u4fee\u6539\u4e5f\u4e0d\u4f5c\u6570\u4e86</p> <p>\u5177\u4f53\u64cd\u4f5c\uff1a</p> <p>\ud83d\udfe2 \u7b2c\u4e00\u6b65 \u5220\u9664\u5bb9\u5668</p> Bash<pre><code>docker rm -f 35f\n</code></pre> <p>\ud83d\udfe2 \u7b2c\u4e8c\u6b65\uff0c\u4ee5\u76f8\u540c\u7684\u547d\u4ee4\u91cd\u65b0\u542f\u52a8\u4e00\u4e2a\u5bb9\u5668</p> Bash<pre><code>docker run -d -p 80:80 --name app01 nginx\n</code></pre> <p>\u6b64\u65f6\uff0c\u5237\u65b0\u9875\u9762\uff0c\u53c8\u53d8\u56de\u4e86\u9ed8\u8ba4\u9875\u9762</p> <p></p> <p>\u8bf4\u660e\uff1a\u5bb9\u5668\u53ea\u8981\u4e00\u542f\u52a8\uff0c\u76f8\u5f53\u4e8e\u542f\u52a8\u4e00\u4e2a\u81ea\u5df1\u7684\u7a7a\u95f4\u3001\u6587\u4ef6\u7cfb\u7edf\u548c\u8fdb\u7a0b\u3002\u5bb9\u5668\u4e00\u65e6\u9500\u6bc1\u5b83\u7684\u6240\u6709\u7684\u6587\u4ef6\u3001\u7cfb\u7edf\u5185\u5bb9\u5168\u90e8\u9500\u6bc1\uff0c\u8fd9\u6837\u5c31\u4ea7\u751f\u4e86\u6570\u636e\u4e22\u5931\u95ee\u9898</p> <p>\u603b\u4e4b\u76ee\u5f55\u6302\u8f7d\u53ef\u4ee5\u89e3\u51b3\u7684\u4e24\u4e2a\u95ee\u9898</p> <p>\u2460 \u5bb9\u5668\u5185\u90e8\u7684\u6587\u4ef6\u4fee\u6539\u4e0d\u5bb9\u6613</p> <p>\u2461 \u6570\u636e\u4e22\u5931\u95ee\u9898</p>"},{"location":"sticks/docker/#_8","title":"\u76ee\u5f55\u6302\u8f7d","text":"<p>\u4ec0\u4e48\u662f\u76ee\u5f55\u6302\u8f7d\uff1f</p> <p>\uff081\uff09docker\u5141\u8bb8\u5728\u81ea\u5df1\u7684\u673a\u5668\u4e2d\u4e13\u95e8\u5f00\u8f9f\u4e00\u4e2a\u76ee\u5f55\uff0c\u6bd4\u5982\u4e0a\u56fe\u4e2d\u6f14\u793a\u7684 <code>/app/nghtml</code>\uff0c\u7136\u540e\u544a\u8bc9docker\uff0c\u8fd9\u4e2a\u76ee\u5f55\u5bf9\u5e94\u5bb9\u5668\u5185\u90e8\u7684\u76ee\u5f55 <code>/usr/share/nginx/html</code> </p> <p>\uff082\uff09\u672c\u5730\u76ee\u5f55\u548c\u5bb9\u5668\u7684\u76ee\u5f55 \u76f8\u5f53\u4e8e\u5f62\u6210\u4e86\u5173\u8054\u5173\u7cfb</p> <p>\uff083\uff09\u5728\u5916\u90e8\u7684\u76ee\u5f55\u8fdb\u884c\u6240\u6709\u7684\u5185\u5bb9\u4fee\u6539\uff0c\u5185\u90e8\u4e5f\u770b\u5f97\u89c1\uff1b\u5185\u90e8\u53d1\u751f\u4e86\u4efb\u4f55\u53d8\u5316\uff0c\u5916\u8fb9\u4e5f\u770b\u5f97\u89c1\uff0c\u56e0\u4e3a\u4e24\u4e2a\u76ee\u5f55\u662f\u4e00\u4e2a\u6302\u8f7d</p> <p>\u7c7b\u6bd4\u73b0\u5b9e\uff0c\u5c31\u662f\u7535\u8111\u4e0a\u63d2\u4e2a U \u76d8\uff0c\uff08\u5bb9\u5668\u5185\u7684\uff09\u8fd9\u4e2a\u76ee\u5f55\u5176\u5b9e\u5c31\u662f\u4e00\u4e2aU\u76d8\uff0c\u628aU\u76d8\u63d2\u5165\u7535\u8111\uff0c\u90a3\u4e48\u7535\u8111\u4e0a\u7684\u67d0\u4e00\u4e2a\u4f4d\u7f6e\uff0c\u5c31\u4f1a\u663e\u793aU\u76d8\u91cc\u8fb9\u7684\u5185\u5bb9\uff0cU\u76d8\u91cc\u8fb9\u6539\u4e86\uff0c\u7535\u8111\u91cc\u8fb9\u770b\u5f97\u89c1\uff0c\u7535\u8111\u91cc\u8fb9\u7ed9U\u76d8\u91cc\u8fb9\u4e5f\u53ef\u4ee5\u5199\u4e1c\u897f\uff0c\u7535\u8111\u91cc\u8fb9\u6539\u4e86\uff0cU\u76d8\u91cc\u8fb9\u4e5f\u6539\u4e86</p> <p>\u4ee5\u4e0a\u5c31\u662f \u6302\u8f7d\u7684\u7406\u89e3 </p> <p>\u600e\u4e48\u4f7f\u7528\u6302\u8f7d\uff1f</p> Bash<pre><code>docker run -d -p 80:80 -v /app/nghtml:/usr/share/nginx/html --name app01 nginx\n</code></pre> <p>\u4f9d\u7136\u662f docker run\uff0c\u52a0\u4e00\u4e2a -v \u53c2\u6570 \u672c\u5730\u76ee\u5f55:\u5bb9\u5668\u5185\u76ee\u5f55</p> <p>docker run -d\u540e\u53f0\u542f\u52a8\uff0c-p\u7aef\u53e3\u6620\u5c04\uff0c\u672c\u5730 80 \u7aef\u53e3\u6620\u5c04\u5bb9\u5668\u5185 80 \u7aef\u53e3\uff0c-v \u672c\u5730 /app/nghtml\u6302\u8f7d\u5230 /usr/share/nginx/html\u76ee\u5f55\u3002\u5982\u679c\u540d--name app01\uff0c\u542f\u52a8\u7684\u955c\u50cf nginx</p> <p>\u203b docker run </p> <p></p> <p>\u5173\u4e8e\u76ee\u5f55\u6302\u8f7d\u7684\u8bf4\u660e</p> Batchfile<pre><code>docker run -d -p 80:80 -v /app/nghtml:/usr/share/nginx/html --name app01 nginx\n</code></pre> <p></p> <p>\uff081\uff09\u76ee\u5f55\u6302\u8f7d\u542f\u52a8\u4e00\u4e2a\u5bb9\u5668\u4ee5\u540e\uff0cdocker ps \u67e5\u770b\u5bb9\u5668\u72b6\u6001\uff0c\u542f\u52a8\u6210\u529f\u6ca1\u95ee\u9898\uff0cstaus\u662fup\u7684\uff1b</p> <p>\uff082\uff09\u800c\u4e14\u5916\u90e8\u4e00\u5f00\u59cb\u5e76\u6ca1\u6709\u521b\u5efa\u8fd9\u4e2a\u76ee\u5f55\uff0cdocker\u8fd8\u4f1a\u81ea\u52a8\u521b\u5efa</p> <p>\uff083\uff09<code>ls</code> \u8bbf\u95eeLINUX\u4e3b\u673a\u7684app\u4e0b\u8fb9\u6709\u6ca1\u6709\u4e1c\u897f\uff0c\u786e\u5b9e\u6709\u4e00\u4e2a <code>nginx</code> \u76ee\u5f55</p> <p></p> <p>\u5bf9\u4e8e\u5bbf\u4e3b\u673a\u6765\u8bf4\uff0c\u5b83\u662f\u65b0\u5efa\u7684\u4e00\u4e2a\u7a7a\u76ee\u5f55\uff0c \u6b64\u65f6\u518d\u6765\u8bbf\u95ee\u8fd9\u4e2anginx\uff0c\u6765\u5230\u6d4f\u89c8\u5668\u5237\u65b0</p> <p></p> <p>\u663e\u793a\uff0cnginx \u8fd4\u56de403\u62d2\u7edd\u8bbf\u95ee\uff0c\u56e0\u4e3a\u73b0\u5728nginx\u7684\u9ed8\u8ba4\u9875\uff0c\u8981==\u4ee5\u5916\u8fb9\u7684\u6587\u4ef6\u5939\u4e3a\u51c6==</p> <p>\u800c\u6211\u4eec\u5bbf\u4e3b\u673a\u6587\u4ef6\u5939\u6ca1\u6709\u9ed8\u8ba4\u9875\uff0c\u6240\u4ee5\u5185\u90e8\u4e5f\u8ba4\u4e3a\u6ca1\u6709\u6570\u636e\u3002</p> <p>\uff084\uff09\u6b64\u65f6\u5982\u679c\u60f3\u8981\u8bbf\u95ee\u5185\u5bb9\uff0c\u5c31\u5728\u5916\u90e8\u51c6\u5907\u4e00\u4e2a\u9875\u9762</p> <p></p> <p>\u73b0\u5728\u5728\u5bbf\u4e3b\u673a\u6587\u4ef6\u5939\u5185\u65b0\u5efa\u4e00\u4e2a index.html\uff0c\u5e76\u4e14\u6dfb\u52a0 2222</p> Bash<pre><code>echo 22222&gt;index.html\n</code></pre> <p>\u5728\u5bbf\u4e3b\u673a nginx \u91cc\u9762\u653e\u4e86\u4e00\u4e2a index.html\uff0c\u76f8\u5f53\u4e8e\u5728\u5bb9\u5668\u5185\u90e8\u653e\u4e86\u4e00\u4e2a\u4e00\u6837\u7684\uff0c\u6b64\u65f6\u518d\u5237\u65b0\u9875\u9762\uff0c\u770b\u5230\u9ed8\u8ba4\u9875\u6539\u53d8\u4e86\u3002</p> <p>\u597d\u5904\uff1a</p> <p>\u4fee\u6539\u6570\u636e\u4f1a\u975e\u5e38\u5bb9\u6613\uff0c\u4e0d\u7528\u62c5\u5fc3\u6570\u636e\u4e22\u5931\uff0c\u5982\u679c docker ps \u8bef\u5220\u9664\u4e86\u5bb9\u5668\uff0c\u5916\u90e8\u7684\u8fd9\u4e2a\u6587\u4ef6\u5939\u8fd8\u5728\uff0c\u800c\u5982\u679c\u542f\u52a8\u7684\u65f6\u5019\u7528\u76f8\u540c\u7684\u547d\u4ee4\uff0c\u4f9d\u7136\u8bbf\u95ee 80 \u7aef\u53e3\uff0c\u5185\u5bb9\u4e00\u6a21\u4e00\u6837\u3002</p> <p>\ud83d\udfe2 \u8bef\u5220\u9664\u4e86\u5bb9\u5668</p> <p></p> <p>\ud83d\udfe2 \u5916\u90e8\u7684\u6587\u4ef6\u5939\u8fd8\u5728 <code>pwd</code> print working directory \u6253\u5370\u5f53\u524d\u6b63\u5728\u5de5\u4f5c\u7684\u76ee\u5f55</p> Bash<pre><code>pwd\n</code></pre> <p></p> <p>\ud83d\udfe2 \u542f\u52a8\u7684\u65f6\u5019\u7528\u76f8\u540c\u7684\u547d\u4ee4\uff0c\u8fd8\u662f\u8ba9\u5916\u90e8\u7684\u8fd9\u4e2a <code>/app/nghtml</code> \u6587\u4ef6\u5939\u6302\u8f7d\u5230\u5185\u90e8 <code>/usr/share/nginx/html</code> </p> Bash<pre><code>docker run -d -p 80:80 -v /app/nghtml:/usr/share/nginx/html --name app01 nginx\n</code></pre> <p></p> <p>\u6b64\u65f6\uff0c\u542f\u52a8\u7684nginx\u5bb9\u5668\u5185\u90e8\u7684\u5185\u5bb9\u5c31\u4f1a\u8ddf\u5916\u8fb9\u4fdd\u6301\u4e00\u81f4\uff0c\u56de\u8f66\uff0c\u542f\u52a8\u7684\u65b0\u5bb9\u5668docker ps \u4f9d\u7136\u8bbf\u95ee80\u7aef\u53e3\uff0c\u5237\u65b0\u5185\u5bb9\u4e00\u6a21\u4e00\u6837</p> <p></p> <p>\u5982\u679c\u8fdb\u5230\u5bb9\u5668\u5185\u90e8\uff0c\u5728\u5185\u90e8\u8fdb\u884c\u6587\u4ef6\u4fee\u6539\uff0c\u5916\u90e8\u4e5f\u662f\u770b\u5f97\u89c1\u7684</p> <p>\u6f14\u793a\u8fc7\u7a0b\uff1a</p> <p>\ud83d\udfe2 \u8fdb\u5165\u5230 <code>9d1</code> <code>bash</code> \u63a7\u5236\u53f0</p> Bash<pre><code>docker exec -it 9d1 bash\n</code></pre> <p>\ud83d\udfe2 cd\u5230 \u5185\u90e8\u76ee\u5f55</p> Bash<pre><code>cd /usr/share/nginx/html\n</code></pre> <p>\ud83d\udfe2 ls \u67e5\u770b\u76ee\u5f55\u4e2d\u7684\u6587\u4ef6\u5217\u8868</p> Bash<pre><code>ls\n</code></pre> <p>\ud83d\udfe2 \u67e5\u770b\u6587\u4ef6\u5185\u5bb9</p> Bash<pre><code>cat index.html\n</code></pre> <p>\ud83d\udfe2 \u8ffd\u52a0 3333 \u5230 index.html</p> Bash<pre><code>echo 333333 &gt;&gt; index.html\n</code></pre> <p>\ud83d\udfe2 \u67e5\u770b index.html \u4e2d\u7684\u66f4\u6539\u662f\u5426\u6709\u6548</p> Bash<pre><code>cat index.html\n</code></pre> <p>\ud83d\udfe2  \u9000\u51fa \u5bb9\u5668\uff0c\u63a7\u5236\u53f0\u8f93\u5165  <code>exit</code></p> <p>\ud83d\udfe2 docker ps \u67e5\u770b\u8be5\u5bb9\u5668\u6b63\u5728\u8fd0\u884c\uff0c\u4f46\u662f\u6211\u4eec\u628a\u5bb9\u5668\u5185\u5bb9\u6539\u4e86\uff0c\u73b0\u5728\u770b\u5bb9\u5668\u5916\u90e8\u7684\u5185\u5bb9\u662f\u4e0d\u662f\u548c\u5bb9\u5668\u5185\u90e8\u7684\u4fdd\u6301\u4e00\u81f4</p> <p></p> <p>\u73b0\u5728\u770b\u5bb9\u5668\u5916\u90e8\u7684\u5185\u5bb9\u662f\u4e0d\u662f\u548c\u5bb9\u5668\u5185\u90e8\u7684\u4fdd\u6301\u4e00\u81f4</p> <p>\u5177\u4f53\u64cd\u4f5c\u4e3a</p> <p>\ud83d\udfe2 \u6253\u5370\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55 <code>pwd</code></p> <p>\ud83d\udfe2  \u67e5\u770b\u76ee\u5f55\u4e2d\u7684\u6587\u4ef6  <code>ls</code></p> <p>\ud83d\udfe2 \u67e5\u770b\u6587\u4ef6\u4e2d\u7684\u5185\u5bb9  <code>cat index.html</code></p> <p></p> <p>\u5185\u5bb9\u548c\u5bb9\u5668\u5185\u7684\u6587\u4ef6\u4fdd\u6301\u4e00\u81f4\uff0c\u5916\u90e8\u7684\u76ee\u5f55\u6302\u8f7d\u5230\u5bb9\u5668\u5185\u90e8\u7684\u4e00\u4e2a\u4f4d\u7f6e</p> <p>\u603b\u7ed3\uff0c\u76ee\u5f55\u6302\u8f7d\uff0c\u4f7f\u7528 -v \u7684\u65b9\u5f0f\uff0c\u5c06\u5916\u90e8\u7684\u6587\u4ef6\u6302\u8f7d\u5230\u5bb9\u5668\u5185\u7684\u6587\u4ef6</p>"},{"location":"sticks/docker/#_9","title":"\u76ee\u5f55\u6302\u8f7d&amp;\u5377\u6620\u5c04","text":"<p>\u53c2\u8003</p> <p>\u76ee\u5f55\u6302\u8f7d\u4f1a\u628a \u5bb9\u5668\u5185\u76f8\u5e94\u7684\u6587\u4ef6\u6e05\u7a7a\uff0c\u7136\u540e\u5c06\u5bbf\u4e3b\u673aor\u4e3b\u673aor \u672c\u673a\u7684\u6587\u4ef6\uff0c\u590d\u5236\u5230\u5bb9\u5668\u5185\u5bf9\u5e94\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u5bbf\u4e3b\u673a\u6587\u4ef6\u5939\u5185\u90e8\u662f\u7a7a\u7684\uff0c\u90a3\u4e48\u5bb9\u5668\u5185\u4e5f\u662f\u7a7a\u7684</p> <p>\ud83d\udd35 \u5982\u679c\u662f\u5bb9\u5668\u542f\u52a8\u7684\u5fc5\u8981 config \u914d\u7f6e\u6587\u4ef6\u6302\u8f7d\u4e86\uff0c\u90a3\u4e48\u5bb9\u5668\u5c31\u4f1a\u542f\u52a8\u5931\u8d25\uff0c\u56e0\u4e3a\u76ee\u5f55\u6302\u8f7d\u4f1a\u6e05\u7a7a \u5bb9\u5668\u5185\u76ee\u5f55\uff0c\u89e3\u51b3\u529e\u6cd5\u5c31\u662f\uff1a</p> <p>\ud83d\udfe2 \u5377\u6620\u5c04</p> <p></p>"},{"location":"sticks/docker/#_10","title":"\u5377\u6620\u5c04","text":"<p>\ud83d\udd34 \u95ee\u9898\u63cf\u8ff0\uff1a</p> <p>\u4e4b\u524d\u542f\u52a8\u7684nginx\u5bb9\u5668\uff0c\u60f3\u4fee\u6539\u5b83\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u5b83\u7684\u914d\u7f6e\u6587\u4ef6\u5728\u5bb9\u5668\u5185\u90e8\u7684\u4f4d\u7f6e\u53eb<code>etc/nginx/</code> \u4e5f\u5c31\u662f <code>nginx.conf</code></p> <p></p> <p>\u5177\u4f53\u6765\u8bf4\uff0c</p> <p>\uff081\uff09\u9996\u5148 docker exec -it \u4ee5\u4ea4\u4e92\u6a21\u5f0f\u542f\u52a8\u5bb9\u5668 9d1\u7684 bash \u63a7\u5236\u53f0</p> <p>\uff082\uff09\u5728\u5bb9\u5668\u5185\u90e8\uff0c\u8fdb\u5165 etc/nginx\u6587\u4ef6\u5939</p> <p>\uff083\uff09ls \u770b\u5230\u6587\u4ef6 nginx.conf</p> <p>\ud83d\udd34 \u4e5f\u5c31\u662f\u8bf4\u5728\u5bb9\u5668\u5185\u90e8\uff0c\u6709nginx\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u5982\u679c\u60f3\u8981\u4fee\u6539\u8fd9\u4e2a\u914d\u7f6e\u6587\u4ef6\uff0c\u6309\u7167\u76ee\u5f55\u6302\u8f7d\u7684\u65b9\u5f0f\u5c31\u662f\uff0c\u5728\u5916\u90e8\u7684\u4f4d\u7f6e <code>/app/ngconf</code> \u6302\u8f7d\u5185\u90e8\u76ee\u5f55 <code>/etc/nginx</code>\uff0c\u5e0c\u671b\u5b9e\u73b0\u7684\u6548\u679c\u662f \uff1a\u5728\u5916\u90e8\u8fdb\u884c\u7684\u4fee\u6539\uff0c\u5185\u90e8\u4e5f\u53d1\u751f\u53d8\u5316</p> <p>\u90a3\u8fd9\u6837\u505a\u53ef\u4e0d\u53ef\u4ee5\u5462\uff1f</p> <p>\ud83d\udfe2  \u9000\u51fa\u8fd9\u4e2a\u5bb9\u5668\uff0c\u91cd\u65b0\u542f\u52a8\uff0c\u8fdb\u884c\u6d4b\u8bd5\uff0c\u540c\u65f6\u6302\u8f7d\u4e24\u4e2a\u76ee\u5f55\uff0c\u5199\u4e24\u4e2a -v</p> Bash<pre><code>docker run -d -p 88:80 -v /app/nghtml:/usr/share/nginx/html -v /app/ngconf:/etc/nginx --name app02 nginx\n</code></pre> <p>\u540e\u53f0\u542f\u52a8\uff0c\u7aef\u53e3\u6620\u5c04\uff0c\u4e4b\u524d 80 \u7aef\u53e3\u5df2\u7ecf\u5360\u7528\u4e86\uff0c\u6240\u4ee5\u672c\u673a 88 \u7aef\u53e3\u6620\u5c04\u5bb9\u5668\u5185\u90e8 80 \u7aef\u53e3\uff0c\u5148\u6302\u5219\u9875\u9762\u76ee\u5f55 <code>-v /app/nghtml:/usr/share/nginx/html</code> \uff0c\u518d\u6302\u8f7d\u914d\u7f6e\u6587\u4ef6\u76ee\u5f55  <code>-v /app/ngconf:/etc/nginx</code>  \uff0c\u540d\u5b57\u53eb app02 \uff0c\u542f\u52a8\u7684\u955c\u50cf\u662f nginx</p> <p>\ud83d\udfe2 docker ps \u67e5\u770b\u6587\u4ef6\u72b6\u6001\uff0c\u53d1\u73b0\u8fd0\u884c\u4e2d\u7684\u5bb9\u5668\u5e76\u6ca1\u6709app02\uff0cdocker ps -a\u67e5\u770b\u6240\u6709\u5bb9\u5668\uff0c\u663e\u793a app02 \u662f\u9000\u51fa\u72b6\u6001\uff1a</p> <p></p> <p>\u90a3\u9000\u51fa\u7684\u539f\u56e0\u662f\u4ec0\u4e48\u5462\uff0c\u68c0\u67e5 app02 \u7684\u65e5\u5fd7\uff1a</p> Bash<pre><code>docker logs app02\n</code></pre> <p></p> <p>\u6700\u540e\u4e00\u884c\u663e\u793a\uff0c/etc/nginx/nginx.conf \u6ca1\u6709\u8fd9\u6837\u7684\u6587\u4ef6</p> <p>\u89e3\u91ca\uff1a\u56e0\u4e3a\u5982\u679c\u4f7f\u7528\u76ee\u5f55\u6302\u8f7d\u7684\u8bdd\uff0c\u4f1a\u9ed8\u8ba4\u5148\u5728\u5bb9\u5668\u5916\u8fb9\u521b\u5efa\u4e00\u4e2a\u7a7a\u6587\u4ef6\u5939\uff0c\u53eb\u505a <code>ngconfig</code>\uff0c\u800c\u8fd9\u4e2a\u7a7a\u6587\u4ef6\u5939\u91cc\u8fb9\u4ec0\u4e48\u90fd\u6ca1\u6709\uff0c\u90a3\u518d\u6765\u6302\u8f7d\u5230\u5bb9\u5668\u5185\u90e8\u7684<code>/etc/nginx/</code>\u4e0b\uff0c\u76f8\u5f53\u4e8e\u5bb9\u5668\u5185\u90e8\u76ee\u5f55\u5185\u4ec0\u4e48\u90fd\u6ca1\u6709\uff0c\u4f46\u662f\u5bb9\u5668\u542f\u52a8\uff0c\u53c8\u8981\u4f7f\u7528\u9ed8\u8ba4\u7684 <code>/etc/nginx/</code> \u4e0b\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u6240\u4ee5\u5bb9\u5668\u62a5\u9519\u5bfc\u81f4\u6ca1\u6709\u542f\u52a8</p> <p>\u4e5f\u5c31\u662f\u6302\u8f7d\u914d\u7f6e\u6587\u4ef6\u662f\u4e0d\u53ef\u4ee5\u7684\uff0c\u9664\u975e\u63d0\u524d\u628a\u914d\u7f6e\u6587\u4ef6\u653e\u5230\u672c\u673a\u6302\u8f7d\u7684\u76ee\u5f55\u4e0b\uff0c\u56e0\u4e3a\u9ed8\u8ba4\u4ee5\u5916\u8fb9\u7684\u6302\u8f7d\u76ee\u5f55\u4e3a\u51c6\uff0c\u800c\u5bb9\u5668\u521a\u542f\u52a8\u672c\u673a\u6302\u8f7d\u76ee\u5f55\u662f\u7a7a\u76ee\u5f55\uff0c\u90a3\u5bb9\u5668\u5185\u90e8\u5c31\u662f\u7a7a\u76ee\u5f55</p> <p>\ud83d\udd34 \u6709\u6ca1\u6709\u4e00\u79cd\u65b9\u5f0f\u80fd\u8ba9\u5bb9\u5668\u542f\u52a8\u7684\u65f6\u5019\uff0c\u867d\u7136\u5728\u672c\u673a\u76ee\u5f55\u6765\u6302\u8f7d\u5bb9\u5668\u5185\u90e8\u76ee\u5f55\uff0c\u4f46\u662f\u5bb9\u5668\u5185\u90e8\u76ee\u5f55\u6709\u4ec0\u4e48\u5185\u5bb9\uff0c\u80fd\u8ba9\u672c\u673a\u6302\u8f7d\u7684\u76ee\u5f55\u8ddf\u5bb9\u5668\u5185\u90e8\u76ee\u5f55\u7684\u5185\u5bb9\u4fdd\u6301\u4e00\u81f4 \uff0c\u5916\u90e8\u76ee\u5f55\u521d\u59cb\u5316\u5c31\u6709\u5bb9\u5668\u5185\u90e8\u7684\u5185\u5bb9\uff1f</p> <p>\u89e3\u51b3\u65b9\u5f0f \uff1a \u5377\u6620\u5c04</p> <p>\ud83d\udd34 \u600e\u4e48\u4f7f\u7528\u5377\u6620\u5c04\uff1f</p> <p></p> <p>\u5377\u6620\u5c04\u7684\u5199\u6cd5\uff1a-v</p> <p>case1\uff1a\u5982\u679c\u662f\u76ee\u5f55\u6302\u8f7d\uff0c\u9700\u8981\u5199\u4e3b\u673a\u8981\u6302\u8f7d\u7684\u76ee\u5f55\u4f4d\u7f6e</p> <p>case2\uff1a\u800c\u5982\u679c\u662f\u5377\u6620\u5c04\uff0c\u5199\u7684\u662f\u79f0\u4e3a<code>\u5377\u540d</code> \uff0c\u6240\u8c13\u7684\u5377\u5176\u5b9e\u6307\u7684\u5c31\u662f\u4e00\u4e2a\u5b58\u50a8\uff0c\u6309\u7167\u5377\u5f62\u5f0f\u7684\u5199\u6cd5\uff0c\u53ea\u9700\u8981\u8d77\u4e00\u4e2a\u5377\u540d</p> <p>\u5377\u540d\u8ddf\u8def\u5f84\u7684\u533a\u522b\uff0c\u5c31\u662f\u4e0d\u4ee5\u70b9\u6760\uff08<code>./</code>\uff09\u6216\u8005\u6760(<code>/</code>)\u8fd9\u4e9b\u8def\u5f84\u5f00\u59cb\uff0c\u5c31\u662f\u4e00\u4e2a\u5377</p> <p>\u8fd9\u4e2a\u5377docker\u4f1a\u81ea\u52a8\u7ed9\u5377\u521b\u5efa\u4e00\u4e2a\u5b58\u50a8\u4f4d\u7f6e\uff0c\u53bb\u628a\u5bb9\u5668\u5185\u90e8\u7684\u8fd9\u91cc\u9762\u5185\u5bb9\uff0c\u5373\u4f7f\u5728\u5bb9\u5668\u521d\u59cb\u542f\u52a8\u7684\u65f6\u5019\u5c31\u8ddf\u5185\u90e8\u7684\u8fd9\u4e2a\u5185\u5bb9\u4fdd\u6301\u5b8c\u5168\u4e00\u81f4</p> <p>\u6f14\u793a\uff1a</p> <p>\ud83d\udfe2 \u542f\u52a8\u7b2c\u4e09\u4e2a\u5bb9\u5668\uff1a</p> Bash<pre><code>docker run -d -p 99:80 -v /app/nghtml:/usr/share/nginx/html -v ngconf:/etc/nginx --name app03 nginx\n</code></pre> <p></p> <p>\u91cd\u65b0\u542f\u52a8\u4e00\u4e2a\u5bb9\u5668\uff0c\u8fd8\u662f\u7528\u4e4b\u524d\u7684\u547d\u4ee4\uff0c\u6765\u7a0d\u52a0\u4fee\u6539\uff0c\u5bb9\u5668\u540d app03\uff0c88 \u7aef\u53e3\u88ab app02 \u5360\u7528\u4e86\uff0c\u6240\u4ee5\u8fd9\u91cc\u7aef\u53e3\u6620\u5c04\u672c\u673a\u7aef\u53e3\u5199 99 \uff0c\u8fd8\u6709 -v \u7684\u65f6\u5019\uff0c\u76f4\u63a5\u53eb ngconf  \uff08\u53eb\u505a\u5377\u540d\uff09\u6211\u542f\u52a8\u4e00\u4e2aapp</p> <p></p> <p>docker ps \u67e5\u770b\u72b6\u6001\uff0capp03 \u6210\u529f\u542f\u52a8\u4e86\u3002 </p> <p>\u8fd9\u4e2a docker run \u5373\u4f7f\u7528\u4e86\u76ee\u5f55\u6302\u8f7d\uff0c\u53c8\u4f7f\u7528\u4e86\u5377\u6620\u5c04\uff0c</p> <p>\ud83d\udd34 \u95ee\u9898\uff1a\u5982\u679c\u60f3\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff0c\u90a3\u600e\u4e48\u5728\u672c\u673a\u53bb\u627e\u6587\u4ef6\u5b58\u50a8\u4f4d\u7f6e\uff1f</p> <p>\ud83d\udfe2 \u7b54\uff1a\u5377\u7684\u4f4d\u7f6e \uff0cdocker\u7edf\u4e00\u653e\u5728\u4e86\u8fd9\u4e2a\u76ee\u5f55\u4e0b\uff1a</p> <p><code>/var/lib/docker/volumes/&lt;volume-nanme&gt;</code></p> <p></p> <p>\u5b9e\u64cd\uff1a</p> <p>\uff081\uff09\u8fdb\u5165\u672c\u673a volumes \u6587\u4ef6\u5939\u4e0b\u3002\u53ef\u4ee5\u770b\u5230 ngconf \u5377</p> <p></p> <p>\uff082\uff09cd \u8fdb\u5165\u5377 </p> Bash<pre><code>cd ngconf/\n</code></pre> <p></p> <p>\u2460 <code>ls</code> \u67e5\u770b\u76ee\u5f55\u5185\u5bb9\uff0c\u53ea\u6709\u4e00\u4e2a <code>-data</code> \u6587\u4ef6\u5939</p> <p>\u2461 <code>cd _data</code></p> <p>\u2462 <code>ls</code> \u67e5\u770b \u76ee\u5f55\u5185\u5bb9</p> <p></p> <p>\u4e5f\u5c31\u662f\u8bf4\u660e \u539f\u6765\u5bb9\u5668\u5185\u90e8  <code>/etc/nginx</code> \u4e2d\u7684\u6240\u6709\u5185\u5bb9 \u90fd\u88ab\u5b8c\u5168\u7684\u653e\u5230\u4e86 <code>\u5377</code>\u4e0b\u9762</p> <p>\uff081\uff09\u672c\u673a\u4fee\u6539 nginx.conf \u6587\u4ef6</p> <p>\uff082\uff09\u8fdb\u5165\u5bb9\u5668\u5185\u90e8</p> <p>\uff083\uff09cd \u8fdb\u6587\u4ef6\u5939</p> <p>\uff084\uff09ls \u663e\u793a\u76ee\u5f55\u5185\u5bb9</p> <p>\uff085\uff09cat \u663e\u793a\u6587\u4ef6\u5185\u5bb9\uff0c\u521a\u521a\u672c\u673a\u4fee\u6539\u7684\u5185\u5bb9\uff0c\u5bb9\u5668\u5185\u90e8\u4e5f\u88ab\u4fee\u6539\u4e86</p> <p></p> <p>\u603b\u7ed3\uff1a\u4ee5\u4e0a\u6f14\u793a\u4e86\u5377\u6620\u5c04\u5b58\u50a8\u7684\u4e24\u79cd\u65b9\u5f0f</p> <ul> <li>\u4e00\u79cd\u76ee\u5f55\u6302\u8f7d</li> <li>\u4e00\u79cd\u662f\u5377\u6620\u5c04</li> <li>\u76ee\u5f55\u6302\u8f7d\uff0c\u521d\u59cb\u542f\u52a8\u5916\u8fb9\u7684\u76ee\u5f55\u662f\u7a7a\u7684\uff0c\u91cc\u8fb9\u4e5f\u662f\u7a7a\u7684\uff0c </li> <li>\u5377\u6620\u5c04\uff0c\u521d\u59cb\u542f\u52a8\uff0c\u5bb9\u5668\u5916\u8fb9\uff08\u4e5f\u5c31\u662f\u672c\u673a\u76ee\u5f55\uff09\u7684\u76ee\u5f55\u8981\u4ee5\u5185\u90e8\u7684\u4e3a\u51c6\uff0c\u542f\u52a8\u8d77\u6765\u4e86\u4ee5\u540e\uff0c\u5bb9\u5668\u91cc\u5916\u968f\u4fbf\u4fee\u6539\uff0c\u5bb9\u5668\u5185\u5916\u90fd\u80fd\u770b\u5230</li> </ul> <p>\u5173\u4e8e docker \u7684\u5377\u547d\u4ee4\uff1a</p> <p>\ud83d\udfe2 <code>docker volume ls</code> \u5217\u51fa\u672c\u673a\u6240\u6709\u5377\uff0c\u53ef\u4ee5\u770b\u5230 <code>ngconf</code>\uff0c\u521a\u521a\u521b\u5efa\u7684\u5377</p> <p>\u8865\u5145 <code>cd ~</code> \u8868\u793a\u8fdb\u5165\u6839\u76ee\u5f55\uff1bpwd  <code>print working ddirectory</code></p> Bash<pre><code>docker volume ls\n</code></pre> <p></p> <p>\ud83d\udfe2 \u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u5377\uff1adocker create + \u5377\u540d</p> Bash<pre><code>docker create haha\n</code></pre> <p></p> <ul> <li>\u6700\u7ec8\u6240\u6709\u7684\u5377\u4e2d\u7684\u5185\u5bb9\u90fd\u4f1a\u653e\u5230 <code>/var/lib/docker/vlolumes/\u4f60\u8d77\u7684\u5377\u540d</code>\u7684 <code>_data</code>\u6587\u4ef6\u5939\u4e0b\uff0c\u5173\u4e8e\u8fd9\u4e2a\u8def\u5f84\u4e5f\u53ef\u4ee5\u4e0d\u7528\u8bb0\uff1a</li> </ul> <p>\ud83d\udfe2 \u67e5\u770b\u5377\u5c5e\u6027\uff1a</p> Bash<pre><code>docker volume inspect ngconf\n</code></pre> <p></p> <p>docker\u4f1a\u6253\u5370\u8fd9\u4e2a\u5377\u771f\u6b63\u6240\u5728\u7684\u4f4d\u7f6e\u662f\u5728\u54ea\uff0c\u4ee5\u53ca\u5b83\u7684\u521b\u5efa\u65f6\u95f4\u7b49\u7b49</p> <p>\ud83d\udce2  \u53e6\u5916\u6ce8\u610f\u7684\u4e00\u70b9\uff0c\u5982\u679c\u5220\u9664\u5bb9\u5668\uff0c\u5377\u548c\u6302\u8f7d\u7684\u672c\u5730\u76ee\u5f55\u4e0d\u4f1a\u88ab\u5220\u9664</p> <p>\u4e0b\u6b21\u518d\u542f\u52a8\u5bb9\u5668\uff0c\u4f7f\u7528\u76f8\u540c\u7684\u5377\u6216\u8005\u76f8\u540c\u7684\u76ee\u5f55\uff0c\u5b83\u4eec\u7684\u6570\u636e\u4f9d\u7136\u90fd\u662f\u5728\u7684</p> <p></p> <p>\u5982\u56fe\uff0c\u5220\u9664app03\uff0c</p> Bash<pre><code>docker rm -f app03\ndocker volume ls\n</code></pre> <p><code>ngconf</code>\u4f9d\u7136\u5728</p> <p>\u5982\u679c\u4e0b\u6b21\u518d\u542f\u52a8\u5bb9\u5668\uff0c\u4f9d\u7136\u662f\u4f7f\u7528\u5377\u6620\u5c04\u7684\u65b9\u5f0f\uff0c\u76f8\u5f53\u4e8e\u4ee5\u524d<code>nginx</code>\u7684\u6240\u6709\u914d\u7f6e\u90fd\u88ab\u4fdd\u7559</p> <p>\u591f\u7528\u4e86\uff0c\u611f\u8c22</p>"},{"location":"sticks/latex/","title":"LaTex","text":""},{"location":"sticks/latex/#latex","title":"LaTex","text":"2024-12-19 18:20:132025-09-28 12:54:08 <p> \u7ea6 503 \u4e2a\u5b57  307 \u884c\u4ee3\u7801  5 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 6 \u5206\u949f</p> <p>latex\u5bfc\u5165\u5305</p> TeX<pre><code>\\usepackage{caption}\n\\usepackage{amsmath}\n\\usepackage{amssymb}\n</code></pre> <ul> <li>caption</li> <li>\u5bf9\u9f50</li> <li>\\mathbb</li> </ul>"},{"location":"sticks/latex/#_1","title":"\u516c\u5f0f\u5bf9\u9f50\u4e00\u4e2a\u7f16\u53f7","text":"TeX<pre><code>\\begin{align}\n\\begin{split}\n\\omega&amp;=\\sum\\limits_{i=1}^{m}(\\hat{\\alpha_i}-\\alpha)x_i\\\\\n0&amp;=\\sum\\limits_{i=1}^{m}(\\hat{\\alpha_i}-\\alpha_i) \\\\\nC&amp;= \\alpha_i + \\mu_i \\\\\nC &amp;= \\hat{\\alpha}_i + \\hat{\\mu}_i \n\\end{split}\n\\end{align}\n</code></pre>"},{"location":"sticks/latex/#_2","title":"\u591a\u884c\u516c\u5f0f\u5bf9\u9f50","text":""},{"location":"sticks/latex/#_3","title":"\u7f57\u9a6c\u5b57\u6bcd","text":"<p>\\(\\var\\)</p> <p>\\(\\varepsilon\\)</p> <p>\\(\\epsilon\\)</p> <p>\\(\\Phi\\)</p> <p>\\(\\phi\\)</p> <p>\\(\\lambda_{j}\\neq0\\)</p> <p>\\(\\infty\\)</p> <p>\\(\\psi\\)</p> <p>\u52a0\u6a2a\u7ebf \\(\\overline{\\psi_{j}}\\)</p> <p>\\(x^{\\prime}\\)</p> <p>\\(\\kappa\\)</p> <p>\u6b63\u8d1f\u53f7 \\(\\pm\\)</p> <p>\\(\\tilde{c}\\)\u6ce2\u6d6a\u7ebf</p>"},{"location":"sticks/latex/#_4","title":"\u504f\u5bfc","text":"<p>\u5728LaTeX\u4e2d\u8f93\u5165\u504f\u5bfc\u6570\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528<code>\\frac</code>\u547d\u4ee4\u548c<code>\\partial</code>\u7b26\u53f7\u3002\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b\uff0c\u6f14\u793a\u5982\u4f55\u8f93\u5165\u4e00\u4e2a\u5173\u4e8e\u53d8\u91cfx\u7684\u504f\u5bfc\u6570\uff1a</p> TeX<pre><code>\\documentclass{article}\n\\begin{document}\n\n\u504f\u5bfc\u6570\u793a\u4f8b\uff1a$\\frac{\\partial f}{\\partial x}$\n\n\\end{document}\n</code></pre> <p>\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c<code>\\frac{\\partial f}{\\partial x}</code>\u8868\u793a\u51fd\u6570f\u5173\u4e8e\u53d8\u91cfx\u7684\u504f\u5bfc\u6570\u3002\u4f60\u53ef\u4ee5\u6839\u636e\u9700\u8981\u4fee\u6539\u53d8\u91cf\u548c\u51fd\u6570\u540d\u3002</p>"},{"location":"sticks/latex/#_5","title":"\u516c\u793a\u7f16\u53f7\u53ca\u5f15\u7528","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u5e26\u6709\u7f16\u53f7\u7684\u516c\u5f0f\uff1a</p> TeX<pre><code>\\begin{equation}\n\n\\label{eq:emc}\n    E=mc^2\n\\end{equation}\n</code></pre> <p>\u5728\u6587\u672c\u4e2d\u5f15\u7528\u516c\u5f0f \\ref{eq:emc}\uff0c\u8fd9\u662f\u7231\u56e0\u65af\u5766\u7684\u8d28\u80fd\u65b9\u7a0b\u3002</p>"},{"location":"sticks/latex/#_6","title":"\u5b9a\u4e49","text":"TeX<pre><code>\\begin{definition}\n\n\uff08\u71b5\uff09\u5206\u7c7b\u51b3\u7b56\u6811\u6a21\u578b\u662f\u4e00\u79cd\u63cf\u8ff0\u5bf9\u5b9e\u4f8b\u8fdb\u884c\u5206\u7c7b\u7684\u6811\u5f62\u7ed3\u6784\u3002\u51b3\u7b56\u6811\u7531\u7ed3\u70b9\uff08node\uff09\u548c\u6709\u5411\u8fb9\uff08directed node\uff09\u7ec4\u6210\u3002\u7ed3\u70b9\u6709\u4e24\u79cd\u7c7b\u578b\uff1a\u5185\u90e8\u7ed3\u70b9\uff08internal node\uff09\u548c\u53f6\u7ed3\u70b9\uff08leaf node\uff09\u3002\u5185\u90e8\u7ed3\u70b9\u8868\u793a\u4e00\u4e2a\u7279\u5f81\u6216\u5c5e\u6027\uff0c\u53f6\u7ed3\u70b9\u8868\u793a\u4e00\u4e2a\u7c7b\u3002\n\\end{definition}\n</code></pre>"},{"location":"sticks/latex/#_7","title":"\u63d2\u5165\u56fe\u7247","text":"TeX<pre><code>\\begin{center}\n    \\includegraphics[width=0.5\\textwidth]{figure/\u51b3\u7b56\u6811\u6a21\u578b1.png}\n    \\captionof{figure}{\u51b3\u7b56\u6811\u6a21\u578b}\n    \\label{fig:example}\n\\end{center}\n</code></pre> <p>\u5982\u56fe<code>\\ref{fig:label_name}</code>\u6240\u793a</p> TeX<pre><code>\\begin{center}\n    \\includegraphics[width=0.8\\linewidth]{figure/image3.png}\n    \\captionof{figure}{\u652f\u6301\u5411\u91cf\u56de\u5f52\u7684\u51e0\u4f55\u62bd\u8c61} \n    \\label{fig:\u652f\u6301\u5411\u91cf\u56de\u5f52\u7684\u51e0\u4f55\u62bd\u8c61}\n\\end{center}\n</code></pre> TeX<pre><code>\\begin{center}\n    \\includegraphics[width=0.8\\textwidth]{figure/E1.png}\n\\end{center}\n</code></pre> TeX<pre><code>\\begin{center}\n    \\includegraphics[width=1\\linewidth]{figure/image2.png}\n    \\captionof{figure}{\u652f\u6301\u5411\u91cf\u56de\u5f52}  \n\\end{center}\n</code></pre>"},{"location":"sticks/latex/#_8","title":"\u5f53\u524d\u4f4d\u7f6e\u4e09\u7ebf\u8868","text":"TeX<pre><code>\\begin{table}[h] % \u4f7f\u7528 [h] \u9009\u9879\u5c06\u8868\u683c\u653e\u7f6e\u5728\u5f53\u524d\u4f4d\u7f6e\n  \\centering\n  \\caption{\u5386\u53f2\u53ca\u5b9e\u65f6\u8def\u51b5\u4fe1\u606f}\n  \\begin{tabular}{ccc}\n    \\hline\n    \u5b57\u6bb5\u540d\u79f0 &amp; \u5b57\u6bb5\u542b\u4e49 \\\\\n    \\hline\n    link &amp; \u6570\u636e2  \\\\\n    label &amp; \u6570\u636e5 \\\\\n    current_slice_id &amp; \u6570\u636e5 \\\\\n    future_slice_id &amp; \u6570\u636e5 \\\\\n    recent_feature &amp; \u6570\u636e5 \\\\\n    history_feature &amp; \u6570\u636e5 \\\\\n    \\hline\n  \\end{tabular}\n\\end{table}\n</code></pre> TeX<pre><code>\u5728\u6587\u672c\u4e2d\u63d2\u5165\u4e00\u4e2a\u4e09\u7ebf\u8868\u5982\u4e0b\u6240\u793a\uff1a\n\n\\begin{center}\n  \\captionof{table}{\u8fd9\u662f\u4e00\u4e2a\u4e09\u7ebf\u8868\u7684\u4f8b\u5b50}\n  \\begin{tabular}{ccc}\n    \\toprule\n    \u52171 &amp; \u52172 &amp; \u52173 \\\\\n    \\midrule\n    \u6570\u636e1 &amp; \u6570\u636e2 &amp; \u6570\u636e3 \\\\\n    \u6570\u636e4 &amp; \u6570\u636e5 &amp; \u6570\u636e6 \\\\\n    \\bottomrule\n  \\end{tabular}\n\\end{center}\n\n\u5728\u8868\u683c\u4e4b\u540e\u7684\u6587\u672c\u7ee7\u7eed\u3002\n</code></pre> TeX<pre><code>\\begin{table}[h]\n    \\caption{\u6570\u636e\u96c6\u793a\u4f8b} \n    \\centering\n    \\begin{tabular}{ccc}\n        \\toprule\n        \\textbf{\u5e8f\u53f7} &amp; \\textbf{Date} &amp; \\textbf{Number of Passengers}\\\\\n        \\midrule\n        1 &amp; 1949/1/1 &amp; 112 \\\\\n        2 &amp; 1949/2/1 &amp; 118 \\\\\n            3 &amp; 1949/3/1 &amp; 132 \\\\\n            4 &amp; 1949/4/1 &amp; 129 \\\\\n            5 &amp; 1949/5/1 &amp; 121 \\\\\n            ... &amp; ... &amp; ... \\\\\n            144 &amp; 1960/11/1 &amp; 390 \\\\\n            145 &amp; 1949/12/1 &amp; 432 \\\\\n        \\bottomrule\n    \\end{tabular}\n\\end{table}\n</code></pre>"},{"location":"sticks/latex/#latex_1","title":"latex \u5355\u5143\u683c\u5185\u6362\u884c","text":"TeX<pre><code>\\begin{table}\n  \\centering\n  \\caption{\u4e09\u7ebf\u8868\u6bb5\u5185\u5206\u884c}\n  \\begin{tabular}{ccc}\n    \\toprule\n    \u52171 &amp; \u52172 &amp; \u52173 \\\\\n    \\midrule\n    \u6570\u636e1 &amp; \u6570\u636e2 &amp; \\begin{tabular}[t]{@{}c@{}}\u6570\u636e3 \\\\ \u884c2\\end{tabular} \\\\\n    \u6570\u636e4 &amp; \\begin{tabular}[t]{@{}c@{}}\u6570\u636e5 \\\\ \u884c1\\end{tabular} &amp; \u6570\u636e6 \\\\\n    \\bottomrule\n  \\end{tabular}\n\\end{table}\n</code></pre>"},{"location":"sticks/latex/#_9","title":"\u8ba1\u6570\u5217\u8868","text":"TeX<pre><code>\\begin{enumerate}\n    \\item \u51b3\u7b56\u6811\u8c03\u53c2\u526a\u679d\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u8bc6\u522b.\n    \\item \u968f\u673a\u68ee\u6797\u5b9e\u73b0\u624b\u5199\u6570\u5b57\u8bc6\u522b.\n        \\item \u8865\u5145\u5b9e\u9a8c.\n\\end{enumerate}\n</code></pre>"},{"location":"sticks/latex/#_10","title":"\u4e0d\u8ba1\u6570\u5217\u8868","text":"TeX<pre><code>\\begin{itemize}\n    \\item \n\\end{itemize}\n\n# \n</code></pre>"},{"location":"sticks/latex/#_11","title":"\u8868\u683c\u6a21\u7248","text":"TeX<pre><code>\\begin{table}\n    \\caption{\u8fd9\u662f\u4e00\u4e2a\u4e09\u7ebf\u8868.}  \n    \\centering\n    \\begin{tabular}{ccc}\n        \\toprule\n        \\textbf{Treatments} &amp; \\textbf{Response 1} &amp; \\textbf{Response 2}\\\\\n        \\midrule\n        Treatment 1 &amp; 0.0003262 &amp; 0.562 \\\\\n        Treatment 2 &amp; 0.0015681 &amp; 0.910 \\\\\n        \\bottomrule\n    \\end{tabular}\n\\end{table}\n</code></pre>"},{"location":"sticks/latex/#_12","title":"\u4ee3\u7801","text":"TeX<pre><code>\\begin{lstlisting}[caption = cs\u4ee3\u7801\u8868\u6d4b\u8bd5]\n\n\n\\end{lstlisting}\n\n\\begin{lstlisting}\n\n\n\\end{lstlisting}\n</code></pre>"},{"location":"sticks/latex/#_13","title":"\u6c42\u548c\u53f7\u6b63\u4e0a\u6b63\u4e0b","text":"TeX<pre><code>$\\sum\\limits_{n=0}^{\\infty}2^{n} = -1$\n</code></pre> <p>\\(\\sum\\limits_{n=0}^{\\infty}2^{n} = -1\\)</p>"},{"location":"sticks/latex/#_14","title":"\u4ee3\u7801 \u7b49\u5bbd\u5b57\u4f53","text":"<p>\u5728LaTeX\u4e2d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528<code>\\texttt{}</code>\u547d\u4ee4\u6765\u663e\u793a\u7b49\u5bbd\u5b57\u4f53\u6587\u672c\uff0c\u4ee5\u7a81\u51fa\u4ee3\u7801\u6216\u5e93\u7684\u540d\u79f0\u3002\u5bf9\u4e8e\"Scikit-learn\u5e93<code>\\texttt{Scikit-learn}</code>\u5e93</p>"},{"location":"sticks/latex/#_15","title":"\u5b66\u672f\u578b\u8bba\u6587\u5e38\u7528\u7684\u5b9a\u7406\u7c7b\u73af\u5883\u7684\u5b9a\u4e49","text":"TeX<pre><code>%===================  \u5b9a\u7406\u7c7b\u73af\u5883\u5b9a\u4e49 ===================\n\\newtheorem{example}{\u4f8b}              % \u6574\u4f53\u7f16\u53f7\n\\newtheorem{algorithm}{\u7b97\u6cd5}\n\\newtheorem{theorem}{\u5b9a\u7406}[section]            % \u6309 section \u7f16\u53f7\n\\newtheorem{definition}[theorem]{\u5b9a\u4e49}\n\\newtheorem{axiom}[theorem]{\u516c\u7406}\n\\newtheorem{property}[theorem]{\u6027\u8d28}\n\\newtheorem{proposition}[theorem]{\u547d\u9898}\n\\newtheorem{lemma}[theorem]{\u5f15\u7406}\n\\newtheorem{corollary}[theorem]{\u63a8\u8bba}\n\\newtheorem{remark}[theorem]{\u6ce8\u89e3}\n\\newtheorem{condition}[theorem]{\u6761\u4ef6}\n\\newtheorem{conclusion}[theorem]{\u7ed3\u8bba}\n\\newtheorem{assumption}[theorem]{\u5047\u8bbe}\n\\usepackage{amsmath}\n\\numberwithin{equation}{section} % \u6309 section \u7f16\u53f7\n</code></pre>"},{"location":"sticks/latex/#_16","title":"\u7b97\u6cd5\u683c\u5f0f\u5f15\u7528","text":"TeX<pre><code>\\begin{algorithm}\n\n\\label{alg:example}\n\\end{algorithm}\n\n\u5f15\u7528\u7b97\u6cd5\uff1a\u7b97\u6cd5~\\ref{alg:example} \u5c55\u793a\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b\u7b97\u6cd5\u3002\n\n#\u63d2\u5165\u94fe\u63a5\n\\href{https://example.com}{bagging nearest neighbor classifiers}\n</code></pre>"},{"location":"sticks/latex/#_17","title":"\u5f15\u7528\u53c2\u8003\u6587\u732e","text":"TeX<pre><code>\\cite\n</code></pre>"},{"location":"sticks/latex/#latex_2","title":"latex \u6b63\u4f53\u3001\u82b1\u4f53","text":"<p>\u82b1\u4f53\u5b57\u6bcd\u8981\u8c03\u5305</p> TeX<pre><code>\\usepackage{amsthm,amsmath,amssymb}\n\\usepackage{mathrsfs}\n</code></pre> <p><code>\\mathrm{R}</code>\\(\\mathrm{R}\\)</p> <p><code>\\rm{R}</code> \\(\\rm{R}\\)</p> <p><code>\\mathbb{R}</code> \\(\\mathbb{R}\\)</p> <p><code>\\mathcal{R}</code> \\(\\mathcal{R}\\)</p> <p><code>\\mathscr{R}</code> \\(\\mathscr{R}\\)</p>"},{"location":"sticks/latex/#latex_3","title":"latex \u5b57\u6bcd\u7684\u6b63\u4e0a\u65b9\u6253\u4e24\u4e2a\u70b9","text":"<p>\\(\\ddot x\\)</p> <p><code>\\ddot x</code> </p>"},{"location":"sticks/latex/#_18","title":"\u5b9a\u4e49","text":"TeX<pre><code>\\begin{definition}{Oracle\u65b9\u6cd5}\n\n\\label{def:example}\n\n\u200b    \u8fd9\u662f\u4e00\u4e2a\u5b9a\u4e49\u3002\n\\end{definition}\n\n\u5728\u5b9a\u4e49~\\ref{def:example} \u4e2d\u6211\u4eec\u53ef\u4ee5\u770b\u5230...\n</code></pre>"},{"location":"sticks/latex/#_19","title":"\u5f15\u7528","text":"<ul> <li>\u56fe\u7247</li> <li>\u516c\u5f0f</li> <li>\u53c2\u8003\u6587\u732e</li> <li>\u9644\u5f55</li> <li>\u8868\u683c</li> <li>\u5b9a\u4e49</li> <li>\u5b9a\u7406</li> </ul> TeX<pre><code>\\begin{theorem}\n\n\\label{thm:example}    \n\n\u8fd9\u662f\u4e00\u4e2a\u5b9a\u7406\u3002\n\n \\end{theorem} \n\n\u5728\u5b9a\u7406~\\ref{thm:example} \u4e2d\u6211\u4eec\u53ef\u4ee5\u770b\u5230...\n</code></pre>"},{"location":"sticks/latex/#_20","title":"\u6253\u6ce2\u6d6a\u7ebf","text":"<p>\\(\\widetilde{{\\beta}}=A\\boldsymbol{y}\\)</p> TeX<pre><code>\\widetilde{{\\beta}}=A\\boldsymbol{y}\n</code></pre>"},{"location":"sticks/latex/#_21","title":"\u5c0f\u4e8e\u7b49\u4e8e\u5927\u4e8e\u7b49\u4e8e","text":"TeX<pre><code>\\begin{aligned}1\\leqslant j\\leqslant p\\end{aligned}\n</code></pre> <p>\\(\\begin{aligned}1\\leqslant j\\leqslant p\\end{aligned}\\)</p>"},{"location":"sticks/latex/#_22","title":"\u5927\u5e3d\u5b50","text":"<p>\\(\\widehat{\\mathcal{M}_d}\\)</p> TeX<pre><code>$\\widehat{\\mathcal{M}_d}$\n</code></pre>"},{"location":"sticks/latex/#_23","title":"\u516c\u5f0f\u6c34\u5e73\u5bf9\u9f50 \u53bb\u6389\u516c\u5f0f\u7f16\u53f7","text":"TeX<pre><code>\\begin{flalign}\n&amp;\\ \u516c\u5f0f\u5185\u5bb91  &amp;\n&amp;\\ \u516c\u5f0f\u5185\u5bb92  &amp;\n&amp;\\ \u516c\u5f0f\u5185\u5bb93  &amp;\n\\nonumber\n\\end{flalign}\n</code></pre> \\[ \\begin{flalign} &amp;\\ \u516c\u5f0f\u5185\u5bb91  &amp; &amp;\\ \u516c\u5f0f\u5185\u5bb92  &amp; &amp;\\ \u516c\u5f0f\u5185\u5bb93  &amp; \\nonumber \\end{flalign} \\]"},{"location":"sticks/latex/#_24","title":"\u6253\u62ec\u53f7","text":""},{"location":"sticks/latex/#_25","title":"\u5b57\u4f53\u52a0\u989c\u8272","text":"TeX<pre><code>\u9996\u5148\uff0c\u5728\u6700\u524d\u9762\u7684\u5bfc\u8a00\u533a\u8f93\u5165\u547d\u4ee4 **\\usepackage{color}**\uff0c\u7136\u540e\uff0c\u5728\u9700\u8981\u52a0\u6ce8\u989c\u8272\u7684\u5904\u8f93\u5165**{\\color{red}{I love you}}**\uff0c\u6700\u5916\u9762\u7684\u5927\u62ec\u53f7\u662f\u53ea\u5bf9\u201cI love you\u201d\u52a0\u6ce8\u7ea2\u8272\uff0c\u5982\u679c\u6ca1\u6709\u8fd9\u4e2a\u5927\u62ec\u53f7\u7684\u8bdd\uff0c\u90a3\u4f1a\u5bf9\u540e\u9762\u6240\u6709\u7684\u6587\u672c\u52a0\u989c\u8272\u3002\u5982\u679c\u8981\u5bf9\u516c\u5f0f\u52a0\u6ce8\u989c\u8272\uff0c\u53ea\u9700\u8981\u5c06\u6587\u5b57\u201cI love you\u201d\u6362\u6210\u516c\u5f0f\u7684\u547d\u4ee4\u5c31\u53ef\u4ee5\u4e86\uff0c\u5982\uff1a\u8981\u5bf9\u516c\u5f0f*A*\uff08*x*\uff09\u52a0\u989c\u8272\uff0c\u8f93\u5165{\\color{red}{$*A*\uff08*x*\uff09$}}\u5c31\u53ef\u4ee5\u4e86\u3002\n</code></pre>"},{"location":"sticks/latex/#_26","title":"\u4e09\u7ebf\u8868","text":"TeX<pre><code>\\begin{table}\n    \\caption{\u8fd9\u662f\u4e00\u4e2a\u4e09\u7ebf\u8868.}  \n    \\centering\n    \\begin{tabular}{ccc}\n        \\toprule\n        \\textbf{Treatments} &amp; \\textbf{Response 1} &amp; \\textbf{Response 2}\\\\\n        \\midrule\n        Treatment 1 &amp; 0.0003262 &amp; 0.562 \\\\\n        Treatment 2 &amp; 0.0015681 &amp; 0.910 \\\\\n        \\bottomrule\n    \\end{tabular}\n\\end{table}\n</code></pre> TeX<pre><code>\\begin{table}[!htp]\n    \\centering\n    % PLCR\u5df2\u7ecf\u5b9a\u4e49\n    \\caption{\u67d0\u6821\u5b66\u751f\u8eab\u9ad8\u4f53\u91cd\u6837\u672c.}\n    \\label{tab2:heightweight}   \n    \\begin{tabular}{lccc}\n        \\toprule\n        \u5e8f\u53f7&amp;\u5e74\u9f84&amp;\u8eab\u9ad8&amp;\u4f53\u91cd\\\\\n        \\midrule\n        1&amp;14&amp;156&amp;42\\\\\n        2&amp;16&amp;158&amp;45\\\\\n        3&amp;14&amp;162&amp;48\\\\\n        4&amp;15&amp;163&amp;50\\\\\n        \\cmidrule{2-4}\n        \u5e73\u5747&amp;15&amp;159.75&amp;46.25\\\\\n        \\bottomrule\n    \\end{tabular}\n\\end{table}\n</code></pre>"},{"location":"sticks/latex/#latex-2","title":"latex\u7a7a 2 \u884c","text":"<p>\\vspace{2ex}</p>"},{"location":"sticks/latex/#latex-beamer","title":"latex beamer \u884c\u95f4\u8ddd","text":"<p>\\linespread{2}</p>"},{"location":"sticks/latex/#latex_4","title":"latex \u591a\u884c\u516c\u5f0f","text":"TeX<pre><code>\\begin{equation}\n\\left\\{\n             \\begin{array}{lr}\n             x=\\dfrac{3\\pi}{2}(1+2t)\\cos(\\dfrac{3\\pi}{2}(1+2t)), &amp;  \\\\\n             y=s, &amp; 0\\leq s\\leq L,|t|\\leq1.\\\\\n             z=\\dfrac{3\\pi}{2}(1+2t)\\sin(\\dfrac{3\\pi}{2}(1+2t)), &amp;  \n             \\end{array}\n\\right.\n\\end{equation}\n</code></pre> TeX<pre><code>\\begin{equation}\n\\begin{aligned}\n\\begin{split}\n&amp; \\min_{ \\omega,b} \\quad\\frac{1}{2}|| \\omega||^2 + C \\sum \\limits_{i=1}^m(\\xi_i + \\hat\\xi_i)\\\\\n&amp; st.  \\left\\{ \\begin{array}{ll} f(x_i)- y_i \\leq \\epsilon + \\xi_i \\\\ y_i-f(x_i)\\leq \\epsilon + \\hat{\\xi}_i \\\\ \\xi_i &gt;0,\\hat{\\xi}_i&gt;0 \\end{array}  \\quad \\quad i=1,2,3,...,m \\right.\n\\end{split}\n\\end{aligned}   \n\\end{equation}\n\n\n\\begin{equation}\n\\begin{aligned}\n\\begin{split}\n\n\\end{split}\n\\end{aligned}   \n\\end{equation}\n</code></pre>"},{"location":"sticks/latex/#beamer","title":"beamer \u4e00\u70b9\u4e00\u70b9\u7684\u51fa\u6765\u7684\u52a8\u753b","text":"TeX<pre><code>\\subsection{\u4f5c\u8005\u5728\u8fd9\u7bc7\u7efc\u8ff0\u4e2d\u5177\u4f53\u8bb2\u4e86\u4ec0\u4e48\uff1f }\n\\begin{frame}{Frame Title}\n    The main issues and contributions of this paper are as follows:\n\\begin{itemize}[&lt;+-&gt;]\n\\item Contribution 1: ...... ;\n\\item Contribution 2: ...... ;\n\\item Contribution 3: ...... ;\n\\end{itemize}  \n\\end{frame}\n</code></pre>"},{"location":"sticks/latex/#beamer_1","title":"beamer \u7b97\u6cd5\u8de8\u9875","text":"TeX<pre><code>\\begin{frame}[allowframebreaks]\n</code></pre> TeX<pre><code>\\documentclass{beamer}\n\\usefonttheme{serif}\n\\usetheme{Warsaw}\n%%=====================================================================================\n%\u7b97\u6cd5\u5b8f\u5305\n\\usepackage{algorithm,algpseudocode}\n\\makeatletter\n\\newenvironment{breakablealgorithm}\n{\n        \\begin{center}\n            \\refstepcounter{algorithm}% New algorithm\n            \\hrule height.8pt depth0pt \\kern2pt% \\@fs@pre for \\@fs@ruled\n            \\renewcommand{\\caption}[2][\\relax]{% Make a new \\caption\n                %{\\raggedright\\textbf{\\textbf{\u7b97\u6cd5}~\\thealgorithm} ##2\\par}%\n               {\\raggedright\\textbf{\\ALG@name~\\thealgorithm} ##2\\par}%\n                \\ifx\\relax##1\\relax % #1 is \\relax\n                \\addcontentsline{loa}{algorithm}{\\protect\\numberline{\\thealgorithm}##2}%\n                \\else % #1 is not \\relax\n                \\addcontentsline{loa}{algorithm}{\\protect\\numberline{\\thealgorithm}##1}%\n                \\fi\n                \\kern2pt\\hrule\\kern2pt\n            }\n        }{\n        \\kern2pt\\hrule\\relax %\\@fs@post% for \\@fs@ruled\n    \\end{center}\n}\n\\makeatother\n%===========================================================================================\n\\newcommand{\\rr}{\\tilde{r}_{0}}\n\\begin{document}\n%%=====================================================\n\\begin{frame}[allowframebreaks]\n\\begin{breakablealgorithm}\n\\caption{Your Algorithm}%\u7b97\u6cd5\u6807\u9898\n    \\begin{algorithmic}[1]%\u4e00\u884c\u4e00\u4e2a\u6807\u884c\u53f7\n     ******************************\n     ******************************\n     ******************************\n%%*\u4e3a\u7b97\u6cd5\u5177\u4f53\u5185\u5bb9\n    \\end{algorithmic}\n\\end{breakablealgorithm}\n\\end{frame}\n\n\\end{document}\n</code></pre>"},{"location":"sticks/latex/#beamer-169","title":"beamer 16:9","text":"TeX<pre><code>\\documentclass[aspectratio=169]{beamer}\n</code></pre>"},{"location":"sticks/latex/#_27","title":"\u884c\u95f4\u8ddd","text":"TeX<pre><code>\\linespread{1.5}%\u4fee\u6539\u884c\u8ddd\n</code></pre>"},{"location":"sticks/latex/#_28","title":"\u6700\u540e\u4e00\u9875\u81f4\u8c22 \u5927\u5199 \u5728\u4e2d\u95f4","text":"TeX<pre><code>\\begin{frame}\n\\Huge{\\centerline{TheEnd}}\n\\end{frame}\n</code></pre>"},{"location":"sticks/linux/","title":"linux","text":""},{"location":"sticks/linux/#linux","title":"linux","text":"2025-02-10 13:36:152025-09-28 12:54:08 <p> \u7ea6 494 \u4e2a\u5b57  43 \u884c\u4ee3\u7801  19 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p> <p>\u53c2\u8003</p>"},{"location":"sticks/linux/#linux_1","title":"\u5b89\u88c5\u548c\u914d\u7f6e Linux \u7cfb\u7edf","text":""},{"location":"sticks/linux/#_1","title":"\u865a\u62df\u673a\u5b89\u88c5","text":"<p>mac \u63a8\u8350\uff1a</p> <p></p>"},{"location":"sticks/linux/#docker","title":"docker \u5b89\u88c5","text":"<p>\u57fa\u4e8e Alpine Linux \u955c\u50cf</p> Bash<pre><code>docker pull alpine\n</code></pre> <p></p> <p>\u4ea4\u4e92\u6a21\u5f0f\u542f\u52a8\u955c\u50cf\uff0csh\uff1f</p> <p>-it\uff1aInteractive\uff1bTerminal</p> <p>sh\uff1a\u5bb9\u5668\u542f\u52a8\u540e\u662f\u4e00\u4e2a\u662f shell \u6a21\u5f0f\u7684\u989d\u4ea4\u4e92</p> Bash<pre><code>docker run -it alpine sh\n</code></pre>"},{"location":"sticks/linux/#_2","title":"\u4e91\u670d\u52a1\u5668","text":"<p>\u6536\u8d39</p> <p></p>"},{"location":"sticks/linux/#macmultipass","title":"mac\u4e0a\u4f7f\u7528multipass \u5b89\u88c5\u865a\u62df\u673a\u7cfb\u7edf","text":"<p>\ud83d\udfe2 \u5b98\u7f51\u4e0b\u8f7d\u955c\u50cf\uff0c\u7136\u540e\u6309\u63d0\u793a\u70b9\u5373\u53ef</p> <p>multipass\u5b98\u65b9</p> <p></p> <p></p> <ul> <li> \u62a5\u9519\uff1a</li> </ul> <p></p> <p>\u89e3\u51b3\uff1a\u9000\u51fa docker desk</p> <p></p> <p>\u5b89\u88c5\u5b8c\u6210\u4e4b\u540e\uff0c\u6253\u5f00\u547d\u4ee4\u884c\u7ec8\u7aef\uff0c\u6267\u884c\u4e00\u4e2a<code>multipass launch</code> \u547d\u4ee4\uff0c\u5b89\u88c5 <code>ubuntu</code></p> <p><code>name</code>\u8868\u793a\u865a\u62df\u673a\u7684\u540d\u5b57\uff0c\u53c2\u6570\u5206\u522b\u8868\u793a\u5206\u914d\u7ed9\u865a\u62df\u673a\u7684CPU\u6838\u5fc3\u6570\u3001\u5185\u5b58\u3001\u78c1\u76d8\u7684\u5927\u5c0f</p> <p>\u56de\u8f66\u4e4b\u540e\u5c31\u4f1a\u5f00\u59cb\u4e0b\u8f7d <code>ubuntu</code> \u7684\u955c\u50cf\u6587\u4ef6\uff0c\u8010\u5fc3\u7b49\u5f85</p> <p>\u4e0b\u8f7d\u5b8c\u6210\u4e4b\u540e\uff0c\u4f7f\u7528 <code>multipass list</code> \u547d\u4ee4\uff0c\u67e5\u770b\u4e00\u4e0b\u5f53\u524d\u7684\u865a\u62df\u673a\u5217\u8868\uff0c\u53ef\u4ee5\u770b\u521a\u521a\u521b\u5efa\u7684\u865a\u62df\u673a\uff0c\u5df2\u7ecf\u5728\u5217\u8868\u4e2d\u4e86</p> <p>\u63a5\u4e0b\u6765\uff0c\u4f7f\u7528<code>multipass shell ubuntu</code>\u8fdb\u5165\u5230\u8fd9\u4e2a\u865a\u62df\u673a\u4e2d\uff0c<code>ubuntu</code>\u662f\u8fd9\u4e2a\u865a\u62df\u673a\u7684\u540d\u5b57\uff0c\u5728\u8fd9\u4e2a\u865a\u62df\u673a\u4e2d\uff0c\u53ef\u4ee5\u5b89\u88c5\u548c\u914d\u7f6e\u81ea\u5df1\u9700\u8981\u7684\u73af\u5883\u3002</p> <p>\ud83d\udfe2 \u547d\u4ee4\u884c\u6267\u884c\uff0c\u5b89\u88c5\u547d\u4ee4</p> Text Only<pre><code>multipass launch --name ubuntu --cpus 4 --memory 8G --disk 10G\n</code></pre> <p>\u2460</p> <p></p> <p>\u2461 \u5c55\u793a\u7cfb\u7edf\u5185\u5b89\u88c5\u7684\u865a\u62df\u673a\u5217\u8868</p> Text Only<pre><code>multipass list\n</code></pre> <p></p> <p>\u2462 \u542f\u52a8\u865a\u62df\u673a\uff0c\u540d\u79f0\u4e3a ubuntu\uff0cshell \u65b9\u5f0f\u542f\u52a8</p> Text Only<pre><code>multipass shell ubuntu\n</code></pre> <p></p> <p>\u2463 \u9000\u51fa</p> Text Only<pre><code>exit\n</code></pre>"},{"location":"sticks/linux/#multipass","title":"multipass \u5e38\u7528\u547d\u4ee4","text":""},{"location":"sticks/linux/#vi-vim","title":"vi \u3001vim","text":"<p>vim \uff1avi \u7684 improve \u7248</p> <p>\u542f\u52a8 vi\uff1a\u8fde\u63a5\u5230 linux \u7cfb\u7edf\u4ee5\u540e\uff0c\u547d\u4ee4\u884c\u8f93\u5165 vi --&gt; esc --&gt; :q \u9000\u51fa</p> <p>\u53ef\u4ee5\u770b\u5230 vim \u7684\u7248\u672c\u53f7\u548c\u5e2e\u52a9\u4fe1\u606f</p> <p></p>"},{"location":"sticks/linux/#vim","title":"vim \u7684\u4e09\u79cd\u6a21\u5f0f","text":"<p><code>i</code> \u63d2\u5165\u6a21\u5f0f</p> <p><code>:wq</code>  \u4fdd\u5b58\u5e76\u9000\u51fa</p> <p><code>esc</code> \u56de\u5230\u547d\u4ee4\u6a21\u5f0f</p>"},{"location":"sticks/linux/#linux_2","title":"linux \u5e38\u7528\u547d\u4ee4","text":"<p>\u957f\u5217\u8868\u3001\u9006\u5e8f\u3001\u6309\u4fee\u6539\u65f6\u95f4\u663e\u793a</p> <p>print working directory</p> <p>change mod\u4fee\u6539\u6743\u9650\uff08+ \u52a0\u6743\u9650 - \u51cf\u6743\u9650\uff09</p> Bash<pre><code>ls\n\nls -ltr\n\nll\n\nls-a\n\ncd\n\ncd..\n\ncd ../..\n\ncat hello.txt\n\necho \"\u547d\u4ee4\u884c\u4f1a\u663e\u793a\u7684\u5185\u5bb9\"\n\necho \"\u6587\u4ef6\u4e2d\u6dfb\u52a0\u5185\u5bb9\"&gt; hello.txt\n\npwd\n\nrm hello.txt\n\nclear\n\nchmod +x hello.sh\n\nchmod +rw hello.txt\n\nchmod -x hello.txt\n\nchmod ug+x hello.sh\n\ncd /\n\nmkdir folder\n\nmkdir -p folder1/folder2/folder3\n\ndu\n</code></pre> <p></p> <p>\u67e5\u770b\u76ee\u5f55\u7ed3\u6784\uff1a<code>du</code> \u3001 <code>tree</code></p> <p>\ud83d\udfe2 <code>du</code> \u547d\u4ee4</p> <p>\u628a\u5f53\u524d\u76ee\u5f55\u4e0b\u7684\u6240\u6709\u6587\u4ef6\u548c\u76ee\u5f55\u7684\u5927\u5c0f\u90fd\u5217\u51fa\u6765\uff0c\u770b\u5230\u76ee\u5f55\u7684\u7ed3\u6784</p> <p>\u5de6\u8fb9\u7684\u6570\u5b57\u8868\u793a\u7684\u662f\u6587\u4ef6\u6216\u8005\u76ee\u5f55\u7684\u5927\u5c0f</p> <p></p> <p>\ud83d\udfe2 \u5305\u7ba1\u7406\u5668\u5b89\u88c5 tree</p> Text Only<pre><code>sudo apt install tree\n\ntree\n</code></pre> <p></p> <p></p>"},{"location":"sticks/markdwon_learn/","title":"markdown","text":""},{"location":"sticks/markdwon_learn/#markdown","title":"markdown","text":"2024-11-18 20:53:472025-09-28 12:54:08 <p> \u7ea6 510 \u4e2a\u5b57  61 \u884c\u4ee3\u7801  5 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 3 \u5206\u949f</p>"},{"location":"sticks/markdwon_learn/#mermaid","title":"\u753b\u56fe mermaid","text":"<p>mermaid \u5b98\u7f51 </p> <pre><code>---\ntitle: Animal example\n---\nclassDiagram\n    note \"From Duck till Zebra\"\n    Animal &lt;|-- Duck\n    note for Duck \"can fly\\ncan swim\\ncan dive\\ncan help in debugging\"\n    Animal &lt;|-- Fish\n    Animal &lt;|-- Zebra\n    Animal : +int age\n    Animal : +String gender\n    Animal: +isMammal()\n    Animal: +mate()\n    class Duck{\n        +String beakColor\n        +swim()\n        +quack()\n    }\n    class Fish{\n        -int sizeInFeet\n        -canEat()\n    }\n    class Zebra{\n        +bool is_wild\n        +run()\n    }\n\n</code></pre> <pre><code>quadrantChart\n    title Reach and engagement of campaigns\n    x-axis Low Reach --&gt; High Reach\n    y-axis Low Engagement --&gt; High Engagement\n    quadrant-1 We should expand\n    quadrant-2 Need to promote\n    quadrant-3 Re-evaluate\n    quadrant-4 May be improved\n    Campaign A: [0.3, 0.6]\n    Campaign B: [0.45, 0.23]\n    Campaign C: [0.57, 0.69]\n    Campaign D: [0.78, 0.34]\n    Campaign E: [0.40, 0.34]\n    Campaign F: [0.35, 0.78]\n\n</code></pre> <p>mermaid\u5728\u7ebf\u9884\u89c8\u5de5\u5177 \u5982\u56fe\u6240\u793a\u3002</p> <ul> <li> mkdocs\u4e0d\u89e3\u6790mermaid\uff08\u5df2\u89e3\u51b3 \u89c1 <code>mkdocs learn</code>\uff09</li> </ul> <p></p>"},{"location":"sticks/markdwon_learn/#_1","title":"\u951a\u70b9\u8bbe\u7f6e","text":"<p>\u4ece\u54ea\u513f\u8df3\uff1a</p> Markdown<pre><code>[\u8bf4\u660e\u6587\u5b57](#jump)\n</code></pre> <p>\u8df3\u5230\u54ea\u91cc\uff1a</p> Markdown<pre><code>&lt;span id = \"jump\"&gt;\u8df3\u8f6c\u5230\u7684\u4f4d\u7f6e&lt;/span&gt;\n</code></pre> <p>\u951a\u70b9 m2</p> <p>\u4e3b\u8981\u8fd8\u662f \u4e24\u79cd\u60c5\u51b5</p> <ul> <li>\u4e00\u79cd\u662f \u914d\u5408a \u6807\u7b7e  <code>&lt;a name=\"\u4f60\u8d77\u540d\u5b57\"&gt;</code> \u4f7f\u7528</li> <li>\u4e00\u79cd\u662f \u914d\u5408 span \u6807\u7b7e <code>&lt;span id=\"\u4f60\u53c8\u8d77\u4e86\u7684\u4e00\u4e2a\u540d\u5b57\"&gt;</code></li> <li>\u7136\u540e <code>&lt;/</code> \u4f1a\u81ea\u52a8\u8865\u5168</li> </ul> <p>\u6f14\u793a\u793a\u4f8b\uff1a</p> <ul> <li>a \u6807\u7b7e + name</li> </ul> Markdown<pre><code># \u76ee\u5f55\n- [\u8df3\u8f6c\u5230\u90e8\u52061](#section-1)\n- [\u8df3\u8f6c\u5230\u90e8\u52062](#section-2)\n\n&lt;a name=\"section-1\"&gt;&lt;/a&gt;\n## \u90e8\u52061\n\u8fd9\u91cc\u662f\u90e8\u52061\u7684\u5185\u5bb9\u3002\n\n&lt;a name=\"section-2\"&gt;&lt;/a&gt;\n## \u90e8\u52062\n\u8fd9\u91cc\u662f\u90e8\u52062\u7684\u5185\u5bb9\u3002\n</code></pre> <p>a \u6807\u7b7e \u951a\u70b9\u6f14\u793a </p> <ul> <li>\u8df3\u8f6c\u5230\u90e8\u52061</li> </ul> <p>\u90e8\u52061</p> <ul> <li>span \u6807\u7b7e +  id</li> </ul> Markdown<pre><code># \u76ee\u5f55\n- [\u8df3\u8f6c\u5230\u90e8\u52061](#section1)\n- [\u8df3\u8f6c\u5230\u90e8\u52062](#section2)\n\n&lt;span id=\"section1\"&gt;&lt;/span&gt;\n## \u90e8\u52061\n\u8fd9\u91cc\u662f\u90e8\u52061\u7684\u5185\u5bb9\u3002\n\n&lt;span id=\"section2\"&gt;&lt;/span&gt;\n## \u90e8\u52062\n\u8fd9\u91cc\u662f\u90e8\u52062\u7684\u5185\u5bb9\u3002\n</code></pre> <p>span \u6807\u7b7e \u951a\u70b9\u6f14\u793a</p> <ul> <li>\u8df3\u8f6c\u5230\u90e8\u52062</li> </ul> <p>span \u6807\u7b7e +  id  ||\u90e8\u5206 2 </p> <p>\u770b\u51fa\u533a\u522b\u6765\u4e86\u5417\uff1f </p> <p>a \u6807\u7b7e+name\uff0c\u4ece\u54ea\u513f\u8df3\uff0c\u8df3\u5230\u54ea\u513f\u90fd\u6709\u53d8\u8272</p> <p></p> <p>span \u6807\u7b7e+id\uff0c\u4ece\u54ea\u513f\u8df3\u6709\u53d8\u8272\uff0c\u8df3\u5230\u54ea\u513f\u6ca1\u6709\u53d8\u8272</p> <p></p> <p>\u4e92\u8df3\uff0c\u5c31\uff1a</p> Markdown<pre><code>&lt;span id=\"\u8fd4\u56de\u7406\u89e3\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\"&gt;[\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236](#\u8df3\u5230\u7406\u89e3\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236)&lt;/span&gt;\n</code></pre> <p></p> Markdown<pre><code>[&lt;span id=\"\u8df3\u5230\u7406\u89e3\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\"&gt;\u7406\u89e3\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236&lt;/span&gt;](#\u8fd4\u56de\u7406\u89e3\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236) \n</code></pre> <p></p> <p>\ud83c\udff7 span \u6807\u7b7e</p> Markdown<pre><code>&lt;span id=\"\u6587\u5b571\"&gt;[\u6587\u5b571](#\u6587\u5b572)&lt;/span&gt;\n\u8fd9\u91cc\u662f\u6587\u5b571\u7684\u5185\u5bb9\u3002\u70b9\u51fb\u4e0a\u65b9\u7684\u201c\u6587\u5b571\u201d\u53ef\u4ee5\u8df3\u8f6c\u5230\u6587\u5b572\u3002\n\n&lt;span id=\"\u6587\u5b572\"&gt;[\u6587\u5b572](#\u6587\u5b571)&lt;/span&gt;\n\u8fd9\u91cc\u662f\u6587\u5b572\u7684\u5185\u5bb9\u3002\u70b9\u51fb\u4e0a\u65b9\u7684\u201c\u6587\u5b572\u201d\u53ef\u4ee5\u8df3\u8f6c\u5230\u6587\u5b571\u3002\n</code></pre> <p>\ud83c\udff7 a \u6807\u7b7e</p> Markdown<pre><code>[\u6587\u5b571](#\u6587\u5b572) &lt;a id=\"\u6587\u5b571\"&gt;&lt;/a&gt;\n\u8fd9\u91cc\u662f\u6587\u5b571\u7684\u5185\u5bb9\u3002\u70b9\u51fb\u4e0a\u65b9\u7684\u201c\u6587\u5b571\u201d\u53ef\u4ee5\u8df3\u8f6c\u5230\u6587\u5b572\u3002\n\n[\u6587\u5b572](#\u6587\u5b571) &lt;a id=\"\u6587\u5b572\"&gt;&lt;/a&gt;\n\u8fd9\u91cc\u662f\u6587\u5b572\u7684\u5185\u5bb9\u3002\u70b9\u51fb\u4e0a\u65b9\u7684\u201c\u6587\u5b572\u201d\u53ef\u4ee5\u8df3\u8f6c\u5230\u6587\u5b571\u3002\n</code></pre>"},{"location":"sticks/markdwon_learn/#_2","title":"\u7bad\u5934\u4e0a\u5199\u5b57","text":"Markdown<pre><code>X \\stackrel{F}{\\rightarrow} Y\n</code></pre> <p>\\(X \\stackrel{F}{\\rightarrow} Y\\)</p>"},{"location":"sticks/markdwon_learn/#_3","title":"\u7bad\u5934\u4e0a\u52a0\u5b57\u7b26","text":"Markdown<pre><code>$\\vec{a}$  \u5411\u91cf\n$\\overline{a}$ \u5e73\u5747\u503c\n$\\widehat{a}$ (\u7ebf\u6027\u56de\u5f52\uff0c\u76f4\u7ebf\u65b9\u7a0b) \u5c16\n$\\widetilde{a}$ \n$\\dot{a}$   \u4e00\u9636\u5bfc\u6570\n$\\ddot{a}$  \u4e8c\u9636\u5bfc\u6570\n</code></pre> <p>\\(\\vec{a}\\)  \u5411\u91cf \\(\\overline{a}\\) \u5e73\u5747\u503c \\(\\widehat{a}\\) (\u7ebf\u6027\u56de\u5f52\uff0c\u76f4\u7ebf\u65b9\u7a0b) \u5c16 \\(\\widetilde{a}\\) \\(\\dot{a}\\)   \u4e00\u9636\u5bfc\u6570 \\(\\ddot{a}\\)  \u4e8c\u9636\u5bfc\u6570</p>"},{"location":"sticks/markdwon_learn/#markdown_1","title":"markdown\u591a\u884c\u5927\u62ec\u53f7","text":""},{"location":"sticks/markdwon_learn/#_4","title":"\u5c45\u4e2d\u5bf9\u9f50\u7684\u5927\u62ec\u53f7","text":"\\[ f(i)= \\left\\{\\begin{matrix} 1,i\\in Q \\\\ -1,i\\notin Q \\end{matrix}\\right. \\] Markdown<pre><code>$$\nf(i)=\n\\left\\{\\begin{matrix}\n1,i\\in Q \\\\\n-1,i\\notin Q\n\\end{matrix}\\right.\n$$\n</code></pre>"},{"location":"sticks/markdwon_learn/#_5","title":"\u6807\u51c6\u5927\u62ec\u53f7","text":"<p>\u5de6\u5bf9\u9f50\u7684\u5927\u62ec\u53f7</p> Markdown<pre><code>$$\n\\begin{cases}\nx+y=5 \\\\\n2x+3y=12\n\\end{cases}\n$$\n</code></pre> \\[ \\begin{cases} x+y=5 \\\\ 2x+3y=12 \\end{cases} \\]"},{"location":"sticks/markdwon_learn/#_6","title":"\u6ce2\u6d6a\u53f7","text":"Text Only<pre><code>$\\sim$\n</code></pre> <p>\\(\\sim\\)</p> <p>\u6b63\u6bd4\u4e8e\u7b26\u53f7</p> Text Only<pre><code>$\\propto$\n</code></pre> <p>\\(\\propto\\)</p> <p>\u79ef\u5206\u7b26\u53f7</p> Text Only<pre><code>\\int\n</code></pre> <p>\\(\\int\\)</p> <p>\u4efb\u610f</p> Text Only<pre><code>${\\forall}$\n</code></pre> <p>\\({\\forall}\\)</p> <p>\u5b58\u5728</p> Text Only<pre><code>${\\exists}$\n</code></pre> <p>\\({\\exists}\\)</p> <p>\u7b49\u4ef7\u4e8e</p> Text Only<pre><code>$\\iff$\n</code></pre> <p>\\(\\iff\\)</p> Text Only<pre><code>$\\partial$\n</code></pre> <p>\\(\\partial\\)</p> Text Only<pre><code>\\mathbf{I}\n</code></pre> <p>\\(\\mathbf{I}\\) \u52a0\u7c97\u9ed1\u4f53\u8868\u793a\u5411\u91cf</p> Text Only<pre><code>$\\pi$\n</code></pre> <p>\\(\\pi\\)</p> Text Only<pre><code>$\\prod$\n$\\cdot$\n$\\times$\n$\\circ$\n$\\odot$\n</code></pre> <p>\\(\\prod\\)</p> <p>\\(\\cdot\\)</p> <p>\\(\\times\\)</p> <p>\\(\\circ\\)</p> <p>\\(\\odot\\)</p>"},{"location":"sticks/markdwon_learn/#_7","title":"\u6b63\u8d1f\u53f7","text":"Markdown<pre><code>x = \\pm 5\n</code></pre> <p>\\(x = \\pm 5\\) </p>"},{"location":"sticks/markdwon_learn/#_8","title":"\u5e0c\u814a\u5b57\u6bcd","text":"<ul> <li>\u963f\u5c14\u6cd5\uff08\\(\\alpha\\) \uff09\uff1a<code>$\\alpha$</code></li> <li>\u8d1d\u5854\uff08\\(\\beta\\)\uff09\uff1a<code>$\\beta$</code></li> <li>\u4f3d\u739b\uff08\\(\\gamma\\)\uff09\uff1a<code>$\\gamma$</code></li> <li>\u5fb7\u5c14\u5854\uff08\\(\\delta\\)\uff09\uff1a<code>$\\delta$</code></li> <li>\u827e\u666e\u897f\u9686\uff08\\(\\epsilon\\)\uff09\uff1a<code>$\\epsilon$</code></li> <li>\u6cfd\u5854\uff08\\(\\zeta\\)\uff09\uff1a<code>$\\zeta$</code></li> <li>\u4f0a\u5854\uff08\\(\\eta\\)\uff09\uff1a<code>$\\eta$</code></li> <li>\u897f\u5854\uff08\\(\\theta\\)\uff09\uff1a<code>$\\theta$</code></li> <li>\u827e\u6b27\u5854\uff08\\(\\iota\\)\uff09\uff1a<code>$\\iota$</code></li> <li>\u5361\u5e15\uff08\\(\\kappa\\)\uff09\uff1a<code>$\\kappa$</code></li> <li>\u62c9\u59c6\u8fbe\uff08\\(\\lambda\\)\uff09\uff1a<code>$\\lambda$</code></li> <li>\u7f2a\uff08\\(\\mu\\)\uff09\uff1a<code>$\\mu$</code></li> <li>\u7ebd\uff08\\(\\nu\\)\uff09\uff1a<code>$\\nu$</code></li> <li>\u514b\u897f\uff08\\(\\xi\\)\uff09\uff1a<code>$\\xi$</code></li> <li>\u6d3e\uff08\\(\\pi\\)\uff09\uff1a<code>$\\pi$</code></li> <li>\u67d4\uff08\\(\\rho\\)\uff09\uff1a<code>$\\rho$</code></li> <li>\u897f\u683c\u739b\uff08\\(\\sigma\\)\uff09\uff1a<code>$\\sigma$</code></li> <li>\u9676\uff08\\(\\tau\\)\uff09\uff1a<code>$\\tau$</code></li> <li>\u5b87\u666e\u897f\u9686\uff08\\(\\upsilon\\)\uff09\uff1a<code>$\\upsilon$</code></li> <li>\u6590\uff08\\(\\phi\\)\uff09\uff1a<code>$\\phi$</code></li> <li>\u51ef\uff08\\(\\chi\\)\uff09\uff1a<code>$\\chi$</code></li> <li>\u666e\u8d5b\uff08\\(\\psi\\)\uff09\uff1a<code>$\\psi$</code></li> <li>\u6b27\u7c73\u4f3d\uff08\\(\\omega\\)\uff09\uff1a<code>$\\omega$</code></li> </ul> <p>\u5927\u5199\u5e0c\u814a\u5b57\u6bcd\uff1a</p> <ul> <li>\u5927\u4f3d\u739b\uff08\\(\\Gamma\\)\uff09\uff1a<code>$\\Gamma$</code></li> <li>\u5927\u5fb7\u5c14\u5854\uff08\\(\\Delta\\)\uff09\uff1a<code>$\\Delta$</code></li> <li>\u5927\u897f\u5854\uff08\\(\\Theta\\)\uff09\uff1a<code>$\\Theta$</code></li> <li>\u5927\u62c9\u59c6\u8fbe\uff08\\(\\Lambda\\)\uff09\uff1a<code>$\\Lambda$</code></li> <li>\u5927\u514b\u897f\uff08\\(\\Xi\\)\uff09\uff1a<code>$\\Xi$</code></li> <li>\u5927\u6d3e\uff08\\(\\Pi\\)\uff09\uff1a<code>$\\Pi$</code></li> <li>\u5927\u897f\u683c\u739b\uff08\\(\\Sigma\\)\uff09\uff1a<code>$\\Sigma$</code></li> <li>\u5927\u5b87\u666e\u897f\u9686\uff08\\(\\Upsilon\\)\uff09\uff1a<code>$\\Upsilon$</code></li> <li>\u5927\u6590\uff08\\(\\Phi\\)\uff09\uff1a<code>$\\Phi$</code></li> <li>\u5927\u666e\u8d5b\uff08\\(\\Psi\\)\uff09\uff1a<code>$\\Psi$</code></li> <li>\u5927\u6b27\u7c73\u4f3d\uff08\\(\\Omega\\)\uff09\uff1a<code>$\\Omega$</code></li> </ul>"},{"location":"sticks/markdwon_learn/#_9","title":"\u591a\u884c\u5927\u62ec\u53f7\u516c\u5f0f","text":"Markdown<pre><code> $$ st.  \\left\\{ \\begin{array}{lr} 0 \\\\ 1 \\end{array}\\right.  $$\n</code></pre> <p>$$ st.  \\left{ \\begin{array}{lr} 0 \\ 1 \\end{array}\\right.  $$</p>"},{"location":"sticks/markdwon_learn/#_10","title":"\u4e0d\u7b49\u4e8e","text":"Markdown<pre><code>\\ne\n</code></pre> <p>\\(\\ne\\)</p>"},{"location":"sticks/mkdocs_learn/","title":"MkDocs","text":""},{"location":"sticks/mkdocs_learn/#mkdocs","title":"MkDocs","text":"2024-11-15 14:10:142025-09-28 12:54:08 <p> \u7ea6 1988 \u4e2a\u5b57  130 \u884c\u4ee3\u7801  14 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 12 \u5206\u949f</p>"},{"location":"sticks/mkdocs_learn/#_1","title":"\u5b66\u4e60\u94fe\u63a5","text":"<p>\u597d\u770b\u7684\u9875\u9762\u8bbe\u8ba1\uff1a</p> Mkdocs-Wcowin\u4e2d\u6587\u4e3b\u9898 Wcowin\uff0c\u7ecf\u5e38\u53bb\u7ffb\u7684\u9875\u9762\ud83d\ude02  mkdocs-changelog-plugin  \u998b\u4e86\u597d\u4e45\uff0c\u7ec8\u4e8e\u8bbe\u7f6e\u5566 \u9e64\u7fd4\u4e07\u91cc\u7684\u7b14\u8bb0\u672c  \u5e26\u4f6c\uff0c\u4f1a\u5199\u63d2\u4ef6\uff0ccss  \u5b98\u65b9 Material for MkDocs  \u5b98\u65b9\u6587\u6863  <ul> <li> \u6587\u7ae0\u6807\u9898\u4e0b\u663e\u793a\u7edf\u8ba1</li> <li> \u5361\u7247\u663e\u793a\u67e5\u770b pdf</li> <li> \u6298\u53e0\u6846</li> <li> \u5f52\u6863\u529f\u80fd\uff08\u63d2\u4ef6\uff1a<code>changelog</code>\uff09</li> <li> <p> \u4f18\u5316\u6e32\u67d3\u901f\u5ea6</p> </li> <li> <p> \u5706\u89d2\u8bbe\u8ba1\uff08\u641c\u7d22\u6846\u5706\u89d2\u3001\u56fe\u7247\u56db\u89d2\u53d8\u5706\u89d2\uff09<code>custom.css</code></p> </li> <li> <p> \u5185\u5d4c pdf\u5e76\u663e\u793a</p> </li> <li> \u672c\u7ad9\u8bbf\u95ee\u91cf\u3001\u672c\u7ad9\u8fd0\u884c\u65f6\u95f4</li> <li> <p> \u53cb\u60c5\u94fe\u63a5\uff0c\u663e\u793a\u5361\u7247\u6837\u5f0f</p> </li> <li> <p> \u65e5\u671f\u6811\uff0c\u6211\u5728\u60f3\uff0cmkdocs \u597d\u50cf\u6ca1\u6709\u7ffb\u9875\u529f\u80fd\u3002\u5c31\u5f88\u597d\u5947\u65f6\u5149\u8f74\u529f\u80fd\u3002 \u65e0\u4f24\u5927\u96c5\uff0c\u4e0d\u597d\u5947\u5566</p> </li> <li> <p>\u72ec\u7acb\u57df\u540d\u80fd\u52a0\u5feb\u8bbf\u95ee\u901f\u5ea6\u5417</p> </li> <li> <p> \u67e5\u770b\u7f51\u9875\u6e90\u4ee3\u7801\u53ef\u4ee5\u6709\uff08\u81ea\u5df1\u53bb github \u7ffb\u628a\uff09</p> </li> <li> <p> \u9996\u9875\u8981\u6539\uff0c\u6682\u65f6\u5148\u8fd9\u6837\u7684\u9996\u9875\u5427\u3002\u6ca1\u6709\u8ba9\u6211\u89c9\u5f97\u5fc5\u987b\u6539\u7684\u5fc5\u8981\u3002</p> </li> <li> <p>\u56fe\u5e8a\u56fe\u5e8a</p> </li> <li> <p> \u66f4\u65b0\u65e5\u5fd7\uff0c\u914d\u8272\u5df2\u4fee\u6539\uff0c\u81ea\u5b9a\u4e49\u7c7b\u578b</p> </li> <li> <p> \u7f51\u9875\u80cc\u666f\uff08copy \u522b\u4eba\u7684 css \u6837\u5f0f\ud83d\ude07 \u8c22\u8c22\u5404\u4f4d\u4e92\u8054\u7f51\u8001\u5e08\uff09</p> </li> <li> <p> \u56fe\u6807\u53d8\u6210\u82a6\u82c7</p> </li> <li> <p> index tab</p> </li> <li> <p> \u7f51\u9875\u80a4\u8272</p> </li> <li> <p>\u5173\u4e8e\u76ee\u5f55\u6210\u8868\u683c\uff0cindex \u9875\u7684\u603b\u7ed3\uff0c\u9875\u5185\u94fe\u63a5\uff1f</p> </li> <li> <p>\u6807\u7b7e\u600e\u4e48\u73a9\uff1f  \u5982\u65e0\u5fc5\u8981\uff0c\u52ff\u589e\u5b9e\u4f53\uff0c\u5bf9\u6211\u6765\u8bf4\uff0c\u786e\u5b9e\u3002</p> </li> </ul>"},{"location":"sticks/mkdocs_learn/#todo","title":"TODO","text":"<p>\u5f52\u6863\u529f\u80fd</p> <ul> <li>\u6298\u53e0\u5bfc\u822a\u3001\u76ee\u5f55\uff0c\u6587\u6863\u5185\u5bb9\u5360\u6700\u591a\u7bc7\u5e45\uff1a \u82b1\u4e66 </li> </ul> <p>\u611f\u89c9 mkdocs \u7684\u903b\u8f91\uff0c\u5373\u4f7f\u9690\u85cf\u4e86\u5bfc\u822a\u9875\u548c\u76ee\u5f55\u9875\uff0c\u4f9d\u7136\u4e0d\u80fd\u4f7f\u5185\u5bb9\u627e\u5230\u6700\u591a\u7684\u7bc7\u5e45\u3002\u4f30\u8ba1\u5f97\u81ea\u5b9a\u4e49\u3002</p> <p>\u4ee5\u540e\u770b\u5230\u4e86\u597d\u7684\u8bbe\u8ba1\uff0c\u4f1a\u518d\u6539\u3002</p> <p></p> <ul> <li> \uff08solved\uff1a<code>mkdocs-jupyter</code>\uff09mknotebooks \u4ee3\u7801\u80cc\u666f\u6d45\u7d2b\u8272\uff0c\u62a5\u770b\uff0c\u80af\u5b9a\u80fd\u6539\u3002\u82b1\u4e66 </li> <li> <p> \u7f51\u9875\u6e32\u67d3\u901f\u5ea6\u592a\u6162\u4e86</p> </li> <li> <p>\u5f53\u5f00\u59cb\u7528 \u5143\u6570\u636e\u548c html \u6807\u7b7e\u4ee5\u540e\uff0c\u5176\u5b9e typora \u4e5f\u6ca1\u90a3\u4e48\u9999\u4e86\uff0c\u56e0\u4e3a\u6709\u4e9b html \u8bc6\u522b\u4e0d\u4e86\u3002</p> </li> <li> <p>\u8fd8\u6709\u4e00\u4e9b\u989c\u8272\u7684\u4fee\u6539\uff0c\u53cb\u94fe\u5361\u7247\u9634\u5f71\u548c\u5b57\u4f53\u989c\u8272</p> </li> </ul>"},{"location":"sticks/mkdocs_learn/#begin","title":"begin","text":"<p>\u4e3b\u9898\u914d\u7f6e\uff1aMaterial for MkDocs</p> <p>\u672c\u5730\u8c03\u8bd5\uff1a</p> Text Only<pre><code>(base) .. mkdocs-site % mkdocs -h\nUsage: mkdocs [OPTIONS] COMMAND [ARGS]...\n\n  MkDocs - Project documentation with Markdown.\n\nOptions:\n  -V, --version         Show the version and exit.\n  -q, --quiet           Silence warnings\n  -v, --verbose         Enable verbose output\n  --color / --no-color  Force enable or disable color and wrapping for the output. Default is auto-\n                        detect.\n  -h, --help            Show this message and exit.\n\nCommands:\n  build      Build the MkDocs documentation.\n  get-deps   Show required PyPI packages inferred from plugins in mkdocs.yml.\n  gh-deploy  Deploy your documentation to GitHub Pages.\n  new        Create a new MkDocs project.\n  serve      Run the builtin development server.\n</code></pre> <p>\u53c2\u8003\u6a21\u7248\u6e90\u7801</p> <p>\u53c2\u8003\u6a21\u7248\u5c55\u793a</p> <p>\u5b98\u65b9\u6587\u6863\uff1amkdocs\u914d\u7f6e </p> <p>mkdocs\u5165\u95e8\u6559\u7a0b</p>"},{"location":"sticks/mkdocs_learn/#_2","title":"\u6587\u4ef6\u7ec4\u7ec7\u5f62\u5f0f","text":"Bash<pre><code>(base) ... docs % tree\n.\n\u251c\u2500\u2500 Error  # \u6587\u4ef6\u5939\n\u2502   \u2514\u2500\u2500 \u62a5\u9519.md   # markdown\u6587\u4ef6\n\u251c\u2500\u2500 Leecode\n\u2502   \u2514\u2500\u2500 \u529b\u6263.md\n\u251c\u2500\u2500 home\n\u2502   \u251c\u2500\u2500 page-1.md\n\u2502   \u2514\u2500\u2500 page-2.md\n\u251c\u2500\u2500 index.md\n\u251c\u2500\u2500 mkdocs\n\u2502   \u251c\u2500\u2500 css\n\u2502   \u2502   \u251c\u2500\u2500 no-footer.css\n\u2502   \u2502   \u2514\u2500\u2500 unordered-list-symbols.css\n\u2502   \u2514\u2500\u2500 javascripts\n\u2502       \u2514\u2500\u2500 katex.js\n\u2514\u2500\u2500 \u4fbf\u7b7e  # \u6587\u4ef6\u5939\n  \u251c\u2500\u2500 TODO  # \u56fe\u5e8a\n  \u2502   \u251c\u2500\u2500 1.png\n  \u2502   \u2514\u2500\u2500 image-20241115095446260.png\n  \u251c\u2500\u2500 TODO.md #markdown\u6587\u4ef6\n  \u251c\u2500\u2500 mkdocs_learn\n  \u2502   \u2514\u2500\u2500 image-20241115100605111-1636372-1636377.png\n  \u251c\u2500\u2500 mkdocs_learn.md\n  \u2514\u2500\u2500 \u5907\u5fd8.md\n\n10 directories, 14 files\n</code></pre> <p>\u524d\u6bb5\u4e0e\u540e\u7aef\u7684\u5bf9\u5e94</p> <p> </p>"},{"location":"sticks/mkdocs_learn/#_3","title":"\u6dfb\u52a0\u9875\u9762\u521b\u5efa\u65f6\u95f4\u3001\u6700\u540e\u4e00\u6b21\u4fee\u6539\u65f6\u95f4","text":"<p>\u5b98\u65b9\u6587\u6863\u94fe\u63a5 </p> <p> </p> <p>\u65b9\u6cd5 2\uff1a\u66f4\u6362\u65f6\u95f4\u6233\u663e\u793a\u5de5\u5177mkdocs-document-dates</p> <p>\u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5 python \u4f9d\u8d56\u5e93</p> Python<pre><code>pip install mkdocs-document-dates\n</code></pre> <p>\u7b2c\u4e8c\u6b65\uff1a\u4fee\u6539\u914d\u7f6e\u6587\u4ef6<code>.yml</code></p> YAML<pre><code>plugins:\n  - document-dates\n</code></pre> <p>\u81ea\u5b9a\u4e49\u914d\u7f6e\uff1a</p> YAML<pre><code>plugins:\n  - document-dates:\n      type: date               # \u65e5\u671f\u7c7b\u578b\uff1a date | datetime | timeago\uff0c\u9ed8\u8ba4 date\n      locale: zh               # \u672c\u5730\u5316\u8bed\u8a00\uff1a zh zh_tw en es fr de ar ja ko ru \uff0c\u9ed8\u8ba4\uff1aen\n      date_format: '%Y-%m-%d'  # \u65e5\u671f\u683c\u5f0f\n      time_format: '%H:%M:%S'  # \u65f6\u95f4\u683c\u5f0f\uff08\u4ec5\u5728 type=datetime \u65f6\u6709\u6548\uff09\n      position: bottom         # \u663e\u793a\u4f4d\u7f6e\uff1atop\uff08\u6807\u9898\u540e\uff09 | bottom\uff08\u6587\u6863\u672b\u5c3e\uff09\uff0c\u9ed8\u8ba4 bottom\n      exclude:                 # \u6392\u9664\u7684\u6587\u4ef6\u6a21\u5f0f\u5217\u8868\n        - temp.md              # \u6392\u9664\u7279\u5b9a\u6587\u4ef6\n        - private/*            # \u6392\u9664 private \u76ee\u5f55\u4e0b\u7684\u6240\u6709\u6587\u4ef6\uff0c\u5305\u62ec\u5b50\u76ee\u5f55\n        - drafts/*.md          # \u6392\u9664\u5f53\u524d\u76ee\u5f55 drafts \u4e0b\u7684\u6240\u6709 markdown \u6587\u4ef6\uff0c\u4e0d\u5305\u62ec\u5b50\u76ee\u5f55\n</code></pre> <p>\u7b2c\u4e09\u6b65\uff1a\u4fee\u6539\u5de5\u4f5c\u6d41\u6587\u4ef6</p> YAML<pre><code>...\n\n    - run: pip install mkdocs-document-dates\n    - run: mkdocs gh-deploy --force\n</code></pre>"},{"location":"sticks/mkdocs_learn/#_4","title":"\u5199\u4f5c","text":"<p>\u66f4\u591a\u5199\u4f5c</p> Text Only<pre><code>!!! note\n    This is a note.\n</code></pre> Text Only<pre><code>!!! tip\n    This is a tip.\n</code></pre> Text Only<pre><code>!!! warning\n    This is a warning.\n</code></pre> Text Only<pre><code>!!! danger\n    This is a danger.\n</code></pre> Text Only<pre><code>!!! success\n    This is a success.\n</code></pre> Text Only<pre><code>!!! info\n    This is a info.\n</code></pre> Markdown<pre><code>!!! quote\n    This is a quote.\n</code></pre> Markdown<pre><code>??? question \"What is the meaning of life, the universe, and everything?\"\n</code></pre> <p>Note</p> <p>This is a note.</p> <p>Tip</p> <p>This is a tip.</p> <p>Warning</p> <p>This is a warning.</p> <p>Danger</p> <p>This is a danger.</p> <p>Success</p> <p>This is a success.</p> <p>Info</p> <p>This is a info.</p> <p>Quote</p> <p>This is a quote.</p> What is the meaning of life, the universe, and everything?"},{"location":"sticks/mkdocs_learn/#mkdocs_1","title":"mkdocs\u547d\u4ee4","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul> <p>Project layout</p> Text Only<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"sticks/mkdocs_learn/#_5","title":"\u4e00\u4e9b\u4fee\u6539","text":"<ul> <li>\u672c\u5730\u6587\u4ef6\u548c\u5728\u7ebf\u6587\u4ef6\u7684\u5b58\u50a8\u95ee\u9898\uff0c\u4e0a\u4f20\u4e0a\u53bb\u7684\u672c\u5730\u600e\u4e48\u7ba1\u7406\uff0c\u53c8\u4e0d\u80fd\u5b8c\u5168\u5728\u7ebf</li> </ul> <p>\u7b49\u4f60\u5199\u5f97\u591a\u5230\u5360\u7528\u672c\u5730\u592a\u591a\u7a7a\u95f4\u518d\u8bf4\u5427\uff0c\u7b11\uff09</p> <ul> <li>\u56fe\u5e8a &amp; typora&amp; vscode&amp;github</li> </ul> <p>typora \u53ef\u4ee5\u81ea\u52a8\u521b\u5efa\u56fe\u5e8a\u6587\u4ef6\u5939</p> <ul> <li>mkdocs material \u5185\u5bb9\u5dee\u53c2\u8003</li> <li>\u65f6\u95f4\u6233\u663e\u793a\u6709\u95ee\u9898 github actions error</li> <li>\u7248\u672c\u4fee\u6539</li> </ul> <p>\u5b98\u65b9\u94fe\u63a5</p> <p>\u7248\u672c\u63a7\u5236\u793a\u4f8b</p> <p>\u7248\u672c\u63a7\u5236\u6e90\u7801</p> <p>\u597d\u590d\u6742\uff0c\u518d\u8bf4\u5427</p> <ul> <li>\u6587\u6863\u6807\u9898\u52a0\u7f16\u53f7\uff08\u53ef\u4ee5\u4f46\u6ca1\u5fc5\u8981\uff0c\u65b0\u5efaCSS\u6587\u4ef6\uff0c\u7136\u540e\u5728yml\u914d\u7f6e\u6587\u4ef6\u4e2d\u5f15\u7528</li> <li>mkdocs\u7684\u6587\u4ef6\u7ec4\u7ec7\u7ed3\u6784</li> </ul> <p>docs/\u6587\u4ef6\u5939\uff08\u5bfc\u822a\u680f\uff09/\uff08\u8d77\u4e2a\u522b\u540d\uff09/\u6587\u4ef6\u5939/\u6587\u4ef6\u5939/md\u6587\u4ef6</p> <p>docs/\u6587\u4ef6\u5939\uff08\u5bfc\u822a\u680f\uff09/\u6587\u4ef6\u5939\uff08\u5de6\u4fa7\u680f\u4e0b\u62c9\u6761\uff09/md\u6587\u4ef6</p> <p>docs/\u6587\u4ef6\u5939\uff08\u5bfc\u822a\u6a2a\u680f\uff09/md\u6587\u4ef6\uff08\u5de6\u4fa7\u680f\uff09/\u4e00\u7ea7\u6807\u9898\uff08\u6807\u9898\u5904\uff09/\u4e8c\u7ea7\u6807\u9898\uff08\u76ee\u5f55\u4ece\u4e8c\u7ea7\u6807\u9898\u5f00\u59cb\u663e\u793a\uff09</p> <p>\u4e00\u7ea7\u6807\u9898\u76f4\u63a5\u4f1a\u663e\u793a\u5728\u5de6\u4fa7\u680f\uff0c\u6216\u8005\u5728yml\u6587\u4ef6\u4e2d\u8d77\u522b\u540d</p> <ul> <li>\u82f1\u6587\u6587\u672c \u4e24\u7aef\u5bf9\u9f50(\u4ee5\u540e\u518d\u8bf4\u5427\uff0c\u4eba\u5bb6\u90fd\u6ca1\u5f04\uff0c\u6211\u4e5f\u4e0d\u6298\u817e\u4e86)</li> <li>\u8fd9\u4e2a\u4e3b\u9898\u8d85\u597d\u770b\uff0c\u6709\u7a7a\u6298\u817e\u4e00\u4e0b</li> <li>git push origin main\u6bcf\u6b21push\u5c31\u4f1a\u628a\u6240\u6709\u6587\u4ef6\u7684\u65f6\u95f4\u5168\u90e8\u66f4\u6539\u4e86</li> </ul> <p>\u6539\u5bf9\u4e86\uff01\u91cd\u65b0\u628a\u6574\u4e2a \u5de5\u4f5c\u6d41\u6587\u4ef6\u590d\u5236\u4e86\u522b\u4eba\u7684\u4e00\u4efd\u3002</p> <ul> <li>\u6587\u4ef6\u7ed3\u6784\u53d8\u4e86\uff0c\u8bb0\u5f97\u4fee\u6539yml\u7684\u8def\u5f84</li> </ul>"},{"location":"sticks/mkdocs_learn/#pdf","title":"\u5d4c\u5165 pdf \u6587\u6863\u5e76\u663e\u793a","text":"<p>\u5982\u4f55\u5728github\u9875\u9762\u4e0amkdocs\u751f\u6210\u7684\u7f51\u7ad9\u4e2d\u5d4c\u5165\u672c\u5730pdf\u6587\u4ef6\uff1f</p> <p></p> <p>\uff081\uff09\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff1a </p> YAML<pre><code>markdown_extensions:\n  - pymdownx.pathconverter:\n      base_path: 'docs/pdf_files' # \u8bbe\u7f6e\u57fa\u7840\u8def\u5f84\u4e3a\u4f60\u7684 PDF \u6587\u4ef6\u6240\u5728\u76ee\u5f55\n      absolute: false # \u5c06\u8def\u5f84\u4e0d\u8f6c\u6362\u4e3a\u7edd\u5bf9\u8def\u5f84\n      tags: 'a script img link object embed' # \u9700\u8981\u8f6c\u6362\u8def\u5f84\u7684 HTML \u6807\u7b7e\n</code></pre> <p>\uff082\uff09\u65b0\u5efa markdown \u6587\u4ef6\uff0c\u5d4c\u5165 pdf \u94fe\u63a5\u5373\u53ef\uff0c\u6ce8\u610f\u8def\u5f84\u7684\u914d\u7f6e\uff0c\u5d4c\u5165\u94fe\u63a5\u7684\u65b9\u6cd5\u548c\u5d4c\u5165\u5916\u94fe\u7684\u903b\u8f91\u662f\u4e00\u6837\u7684\uff0c\u53ea\u662f\u8fd9\u91cc\u8bbe\u7f6e\u7684\u672c\u5730\u7684\uff08\u6307\u7684\u662f \u73b0\u5728 \u5de5\u4f5c\u7684\u8def\u5f84\uff09\u76f8\u5bf9\u8def\u5f84</p> Markdown<pre><code># \ud83d\udcd2\n\u8fd9\u91cc\u90fd\u662f\u4e00\u4e9b\u4e4b\u524d\u7684\u7b14\u8bb0\uff0c\u9646\u9646\u7eed\u7eed\u7684\u642c\u5230\u8fd9\u91cc\u3002\n\n## \u81a8\u80c0\u5377\u79ef\n\n[\u70b9\u51fb\u8fd9\u91cc\u67e5\u770b PDF \u6587\u4ef6](../pdf_files/1_dilatedConv.pdf)\n</code></pre> <p>\u6211\u6700\u5f00\u59cb\u7684\u62a5\u9519\u662f\uff0c\u8def\u5f84\u9519\u4e86\uff1b\u8fd8\u6709 <code>absolute: false</code> \u8fd9\u91cc\u8bbe\u7f6e\u6210 false</p>"},{"location":"sticks/mkdocs_learn/#mkdocs-mermaid","title":"mkdocs &amp; mermaid","text":"<p>\u9879\u76ee\u5730\u5740\uff1ahttps://github.com/fralau/mkdocs-mermaid2-plugin</p> <p>\u53e6\u9644 \uff1aMermaid \u5728\u7ebf\u7f16\u8f91\u5668 </p> <p>\u53ef\u4ee5\u6b63\u786e\u89e3\u6790\uff1a </p> <p></p> <p>\u7b2c\u4e00\u6b65\uff1a\u7ec8\u7aef\u5b89\u88c5</p> Python<pre><code>pip install mkdocs-mermaid2-plugin\n</code></pre> <p>\u7b2c\u4e8c\u6b65\uff1a\u66f4\u65b0\u914d\u7f6e\u6587\u4ef6\uff1a</p> YAML<pre><code>plugins:\n    - search\n    - mermaid2\n</code></pre> <p>\u7b2c\u4e09\u6b65\uff1a\u4fee\u6539\u4e00\u4e0b\u4e3b\u9898</p> YAML<pre><code>  - pymdownx.superfences:\n      custom_fences:\n        - name: mermaid\n          class: mermaid\n          format: !!python/name:mermaid2.fence_mermaid_custom\n</code></pre> <p>\u9700\u8981\u6ce8\u610f\u7684\u95ee\u9898\uff1a\u4e0a\u9762\u7684\u7f29\u8fdb\uff0c\u975e\u5e38\u5bb9\u6613\u62a5\u9519\uff0cAI \u81ea\u52a8\u7ed9\u8f93\u51fa\u7684\u5168\u6587\u672c\u5185\u5bb9\u4f1a\u6709\u5220\u51cf\uff0c\u7ec6\u5fc3\u70b9\u5427\u3002</p> <p>\u5177\u4f53\u7684\u4f4d\u7f6e\uff1a</p> <p></p> <p>\u793a\u4f8b\u4ee3\u7801 <code>```mermaid</code></p> Text Only<pre><code>graph TD\n    classDef component fill:#e2f0cb,stroke:#333,stroke-width:1px\n    classDef operation fill:#ffd6cc,stroke:#333,stroke-width:1px\n\n    %% \u7c7b\u5c42\u6b21\u7ed3\u6784\n    ClassA[ClassA]:::component\n    ClassB[ClassB]:::component\n\n    %% \u521d\u59cb\u5316\u5173\u7cfb\n    subgraph \u521d\u59cb\u5316\u8fc7\u7a0b\n    I_B[\u521b\u5efaClassB\u5b9e\u4f8b]:::operation --&gt; I_A[\u521b\u5efaClassA\u5b9e\u4f8b]:::operation\n    end\n\n    %% \u65b9\u6cd5\u8c03\u7528\u5173\u7cfb\n    ClassA -- \"\u8c03\u7528\" --&gt; ClassB\n    ClassA.method_a -- \"\u8c03\u7528\" --&gt; ClassB.method_b\n</code></pre> <p>\u6b63\u786e\u89e3\u6790\u51fa\u7684\u6548\u679c</p> <pre><code>graph TD\n    classDef component fill:#e2f0cb,stroke:#333,stroke-width:1px\n    classDef operation fill:#ffd6cc,stroke:#333,stroke-width:1px\n\n    %% \u7c7b\u5c42\u6b21\u7ed3\u6784\n    ClassA[ClassA]:::component\n    ClassB[ClassB]:::component\n\n    %% \u521d\u59cb\u5316\u5173\u7cfb\n    subgraph \u521d\u59cb\u5316\u8fc7\u7a0b\n    I_B[\u521b\u5efaClassB\u5b9e\u4f8b]:::operation --&gt; I_A[\u521b\u5efaClassA\u5b9e\u4f8b]:::operation\n    end\n\n    %% \u65b9\u6cd5\u8c03\u7528\u5173\u7cfb\n    ClassA -- \"\u8c03\u7528\" --&gt; ClassB\n    ClassA.method_a -- \"\u8c03\u7528\" --&gt; ClassB.method_b\n</code></pre>"},{"location":"sticks/mkdocs_learn/#mermaid","title":"\u8fdc\u7a0b\u4ed3\u5e93\u6e32\u67d3 mermaid","text":"<p>\u672c\u5730 localhost \u80fd\u591f\u6e32\u67d3 mermaid\uff0c\u63d0\u4ea4\u5230\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u5de5\u4f5c\u6d41\u6587\u4ef6\u603b\u662f\u62a5\u9519</p> <p></p> <p>\u89e3\u51b3\uff1a\u4fee\u6539\u5de5\u4f5c\u6d41\u6587\u4ef6\uff0c\u5b89\u88c5 mermaid\u3002</p> <p></p>"},{"location":"sticks/mkdocs_learn/#mkdocs-jupyter-notebook","title":"mkdocs &amp;jupyter notebook","text":"<p>(1) </p> <p>mknotebooks</p> <p>mknotebooks \u9879\u76ee\u5e38\u89c1\u95ee\u9898\u89e3\u51b3\u65b9\u6848</p> <p>\u7b2c\u4e00\u6b65\uff1a</p> Bash<pre><code>pip3 install mknotebooks\n</code></pre> <p>\u7b2c\u4e8c\u6b65\uff0c\u4fee\u6539\u914d\u7f6e\u6587\u4ef6</p> YAML<pre><code># mkdocs.yml\nnav:\n  - your_notebook.ipynb\n\nplugins:\n  - mknotebooks\n</code></pre> <p>\u5373\u53ef\u6210\u529f\uff0c\u5b9e\u73b0 jupyter notebook \u5d4c\u5165\u5230 mkdocs \u7684\u7f51\u9875\u4e2d</p> <p>\u4e0d\u548b\u597d\u770b\u4e5f\u662f\u5c0a\u561f</p> <p></p> <p>(2) mkdocs-jupyter</p> <p>mkdocs-jupyter</p> <p>\u7b2c\u4e00\u6b65\uff1a</p> Bash<pre><code>pip install mkdocs-jupyter\n</code></pre> <p>\u7b2c\u4e8c\u6b65\uff1a\u4fee\u6539\u5bfc\u822a\u680f\u548c\u914d\u7f6e\u6587\u4ef6</p> Python<pre><code>nav:\n    - Home: index.md\n    - Notebook page: notebook.ipynb\n    - Python file: python_script.py\nplugins:\n    - mkdocs-jupyter\n</code></pre> <p>\u6362\u4e86\uff0c\u5f88\u597d\u770b</p> <p> </p> <p>\u7b2c\u4e09\u6b65\uff1a\u90e8\u7f72\u5230\u8fdc\u7a0b\uff0c\u8fd8\u9700\u8981\u4fee\u6539\u5de5\u4f5c\u6d41\u6587\u4ef6\uff1a</p> YAML<pre><code>- run: pip install mkdocs-jupyter\n</code></pre> <p> </p>"},{"location":"sticks/mkdocs_learn/#pdf_1","title":"\u5d4c\u5165 pdf \u76f4\u63a5\u663e\u793a","text":"<p>\u7ec8\u4e8e\u663e\u793a\u6210\u529f\u4e86\uff0c\u8fd9\u4e2a mkdocs \u7684\u627e\u8def\u5f84\u7684\u903b\u8f91\u6211\u5c5e\u5b9e\u4e0d\u7406\u89e3</p> <p></p> <p>\u6211\u7684\u5904\u7406\uff1a</p> <p>\u6587\u4ef6\u7ed3\u6784\uff1a</p> Bash<pre><code>.\n\u251c\u2500\u2500 1_0_fourier.md\n\u251c\u2500\u2500 1_1_fourier.md\n\u251c\u2500\u2500 1_2_signal.md\n\u251c\u2500\u2500 1_3_complexExp.md\n\u251c\u2500\u2500 1_4_signal.md\n\u251c\u2500\u2500 1_FFT.md\n\u251c\u2500\u2500 2_FFT.md\n\u251c\u2500\u2500 5_3_DTFS.pdf\n\u251c\u2500\u2500 5_4_DTFT.pdf\n</code></pre> <p>\u9700\u6c42\uff1a</p> <p>\u5728 <code>1_4_signal.md</code> \u4e2d\u5d4c\u5165 <code>5_3_DTFS.pdf</code></p> <p>\u65b9\u6cd5\uff1a</p> HTML<pre><code>&lt;iframe src=\"../pdf_files/5_3_DTFS.pdf\" width=\"100%\" height=\"800px\" style=\"border: 1px solid #ccc; overflow: auto;\"&gt; &lt;/iframe&gt;\n</code></pre> <p>\u662f\u5728\u4e0d\u660e\u767d\uff0c\u8fd9\u91cc\u627e\u5730\u5740\u7684\u8def\u5f84\uff0c\u90a3\u5c31\u590d\u5236\u4e24\u4efd <code>5_3_DTFS.pdf</code> \u5427\u3002</p>"},{"location":"sticks/mkdocs_learn/#_6","title":"\u5f52\u6863","text":""},{"location":"sticks/mkdocs_learn/#mkdocs-statistics","title":"mkdocs-statistics","text":"Python<pre><code>pip install mkdocs-statistics-plugin\n</code></pre> <p>\u914d\u7f6e\u94fe\u63a5\u53c2\u7167\uff1ahttps://github.com/TonyCrane/mkdocs-statistics-plugin</p>"},{"location":"sticks/mkdocs_learn/#_7","title":"\u914d\u7f6e\u5f15\u7528\u8def\u5f84","text":"<p>\u672c\u5730 vscode \u4e2d\uff1adocs/pdf_files/1_0_dilatedConv.pdf</p> <p>mkdocs serve\uff1a127.0.0.1.8000/Rongerr.github.io/pdf_files/1_0_dilatedConv.pdf</p> <p>\u8fdc\u7a0b\u4ed3\u5e93\u7684\u8def\u5f84\uff1ahttps://dearrongerr.github.io/Rongerr.github.io/pdf_files/1_0_dilatedConv.pdf</p> <p>html \u4e2d a \u6807\u7b7e\u627e\u7684\u5730\u5740\uff1a\u8bbe\u7f6e\u662f <code>&lt;a class=\"down-button\" target=\"_blank\" href=\"/pdf_files/1_0_dilatedConv.pdf\" markdown=\"1\"&gt;:fontawesome-solid-download: \u4e0b\u8f7d&lt;/a&gt;</code>\uff0c\u5b9e\u9645\u627e\u5230\u7684\u662f \uff1a127.0.0.1.8000/pdf_files/1_0_dilatedConv.pdf</p> <p>html \u4e2d a \u6807\u7b7e\u8bbe\u7f6e\u7684\u8def\u5f84\u8def\u5f84\uff1a<code>&lt;a class=\"down-button\" target=\"_blank\" href=\"../pdf_files/1_0_dilatedConv.pdf\" markdown=\"1\"&gt;:fontawesome-solid-download: \u4e0b\u8f7d&lt;/a&gt;</code>\uff0c\u5b9e\u9645\u627e\u5230\u7684\u662f\uff1a127.0.0.1.8000/Rongerr.github.io/logs/pdf_files/1_0_dilatedConv.pdf</p> <p>\u89e3\u51b3\u65b9\u6cd5\uff1a</p> <p>\u573a\u666f\u63cf\u8ff0\uff1a</p> <p>pwd\uff1a<code>docs/logs/3_test.md</code></p> <p>\u8981\u5f15\u7528\u7684\u6587\u4ef6\u8def\u5f84\uff1a<code>docs/pdf_files/1_0_dilatedConv.pdf</code></p> <p>\uff08\u6b63\u786e\u8bbe\u7f6e\u5f15\u7528\u8def\u5f84\uff09 \u4f7f\u7528<code>[]()</code> \u627e\u8def\u5f84\u8bbe\u7f6e\u94fe\u63a5\u65f6\uff0c\u6d4b\u8bd5\u6b63\u786e\u8df3\u8f6c \u70b9\u51fb\u8df3\u8f6c  \uff0c\u8def\u5f84\u8bbe\u7f6e</p> <p><code>[\u70b9\u51fb\u8df3\u8f6c](../pdf_files/1_0_dilatedConv.pdf)</code> </p> <p>\ud83d\udfe2 mkdocs serve \u4e2d\u89e3\u6790\u7684\u8def\u5f84\u4e3a\uff1a\ud83d\udc47 \uff0c\u5e76\u4e14\u53ef\u4ee5\u6b63\u5e38\u6253\u5f00</p> <p><code>127.0.0.1.8000/Rongerr.github.io/pdf_files/1_0_dilatedConv.pdf</code></p> <p>\u56e0\u4e3a\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u8bbe\u7f6e\u7684\u8def\u5f84 <code>site_url</code> \uff1a</p> YAML<pre><code>site_url: https://dearrongerr.github.io/Rongerr.github.io\n</code></pre> <p>\ud83d\udfe2 \u90e8\u7f72\u5230\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u4e0a\u4f20 gitpages\uff0c\u8fd9\u8def\u5f84\u88ab\u89e3\u6790\u4e3a\uff1a</p> <p><code>https://dearrongerr.github.io/Rongerr.github.io/pdf_files/1_0_dilatedConv.pdf</code></p> <p>\uff08<code>a</code>\u6807\u7b7e\u4e2d\u6b63\u786e\u8bbe\u7f6e\u5f15\u7528\u8def\u5f84\uff09 \u4f46\u662f a \u6807\u7b7e\u4e2d\uff0c\u5982\u679c\u60f3\u6b63\u786e\u7684\u5f15\u7528\uff0c\u8def\u5f84\u8981\u88ab\u8bbe\u7f6e\u4e3a \u6d4b\u8bd5\u70b9\u51fb\u6b63\u786e\u8df3\u8f6c\uff1a</p> HTML<pre><code>href=\"/Rongerr.github.io/pdf_files/1_0_dilatedConv.pdf\" \n</code></pre> <p>\uff08<code>iframe</code> \u6807\u7b7e\u4e2d src \u8bbe\u7f6e\u8def\u5f84\u540c\u7406\uff09 </p> HTML<pre><code>&lt;iframe src=\"/Rongerr.github.io/pdf_files/5_3_DTFS.pdf\" width=\"100%\" height=\"800px\" style=\"border: 1px solid #ccc; overflow: auto;\"&gt; &lt;/iframe&gt;\n</code></pre> <p>\u90fd\u80fd\u5728\u672c\u5730\u548c\u8fdc\u7a0b\u6b63\u786e\u5f15\u7528\u5230\u6587\u4ef6\u3002</p> <p>\u603b\u7ed3\uff1a </p> <ul> <li>html \u89e3\u6790\u8def\u5f84\uff1a\u52a0<code>/Rongerr.github.io/pdf_files/</code></li> <li>\u672c\u5730\u5f15\u7528\u8def\u5f84\u76f4\u63a5\uff1a<code>../pdf_files/</code></li> </ul>"},{"location":"sticks/mkdocs_learn/#_8","title":"\u6682\u5b58","text":"Text Only<pre><code>docs/assets/images/icons/pdf.svg\n\n```html \n\n  &lt;a class=\"view-button\" target=\"_blank\" href=\"/Rongerr.github.io/pdf_files/1_0_dilatedConv.pdf\" markdown=\"1\"&gt;:fontawesome-solid-eye: \u67e5\u770b&lt;/a&gt;\n\n```\n</code></pre>"},{"location":"sticks/mkdocs_learn/#pdf_2","title":"\u53ef\u6298\u53e0\u7684\u6846\u3001\u5361\u7247\u5c55\u793a\u5d4c\u5165\u7684pdf\u6587\u4ef6","text":"<ul> <li> <p> \u53ef\u6298\u53e0\u7684\u4e0b\u62c9\u6846</p> </li> <li> <p> \u5361\u7247\u5c55\u793a\u5d4c\u5165\u7684pdf\u6587\u4ef6</p> </li> </ul> Info <ul> <li>Author: Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, Bryan Hooi<ul> <li>Conference: ICLR 2024</li> <li>arXiv: 2306.13063</li> </ul> </li> </ul> \u8bba\u6587 1.15 MB / 29 P / 2025-02-25 \u67e5\u770b"},{"location":"sticks/mkdocs_learn/#html","title":"html \u6298\u53e0\u6846 \u9ed8\u8ba4\u6298\u53e0","text":"HTML<pre><code>&lt;details&gt;\n&lt;summary&gt;\u5185\u5bb9\u6982\u8981&lt;/summary&gt;\n&lt;p&gt;\n\u4f60\u60f3\u6298\u53e0\u7684\u4e00\u5927\u6bb5\u5185\u5bb9\n&lt;/p&gt;\n&lt;/details&gt;\n</code></pre> <p>\u663e\u793a\u6548\u679c\uff1a</p> \u5185\u5bb9\u6982\u8981 <p> \u4f60\u60f3\u6298\u53e0\u7684\u4e00\u5927\u6bb5\u5185\u5bb9 </p>"},{"location":"sticks/screen/","title":"screen","text":""},{"location":"sticks/screen/#screen","title":"screen","text":"2025-02-27 17:03:142025-09-28 12:54:08 <p> \u7ea6 211 \u4e2a\u5b57  3 \u884c\u4ee3\u7801  6 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>\u540e\u53f0\u8dd1\u4ee3\u7801</p> <p>link1</p> <p>link2</p> <p>\u4ece\u7ec8\u7aef\u5f00\u59cb\uff1a</p> <ul> <li>\u65b0\u5efa\u7a97\u53e3</li> </ul> Text Only<pre><code>screen -S screenName_runcode\n</code></pre> <ul> <li>\u914d\u7f6e\u597d\u81ea\u5df1 Python \u73af\u5883</li> </ul> <p>\u8fdb\u5165\u8981\u8fd0\u884c\u7684\u9879\u76ee\u6587\u4ef6\uff0c\u6fc0\u6d3b\u81ea\u5df1\u7684\u865a\u62df\u73af\u5883</p> <p></p> <p>\u5f00\u59cb\u8fd0\u884c\u81ea\u5df1\u7684\u9879\u76ee</p> <p>\u5f53\u81ea\u5df1\u7684 python \u6587\u4ef6\u5f00\u59cb\u8bad\u7ec3</p> <p></p> <ul> <li>\u600e\u4e48\u6837\u9000\u51fa\u7a97\u53e3\uff0c\u4f46\u662f\u4ee3\u7801\u4f9d\u7136\u53ef\u4ee5\u5728\u540e\u53f0\u8fd0\u884c\uff1f</li> </ul> <p>\u6309\u4f4f\u952e\u76d8 ctrl+a+d \u9000\u51fa\u7a97\u53e3\uff08mac\uff1acommand\uff1f\uff09</p> <p>\u7136\u540e\u5c31\u53ef\u4ee5 \u7ec8\u7aef\u8f93\u51fa <code>exit</code> \u9000\u51fa ssh \u8fde\u63a5\uff0c\u6216\u8005 <code>\u00d7</code> \u6389\u7a97\u53e3</p> <p></p> <ul> <li>\u5fd9\u5b8c\u4e86\u81ea\u5df1\u7684\u4e8b\uff0c\u600e\u4e48\u518d\u6b21\u91cd\u65b0\u8fdb\u5165\u7a97\u53e3\uff0c\u67e5\u770b\u7a0b\u5e8f\uff1f</li> </ul> <p>(1) \u7ec8\u7aef\u8f93\u5165</p> Text Only<pre><code>screen -ls\n</code></pre> <p></p> <p>(2) \u67e5\u770b\u5f53\u524d\u7684\u7a97\u53e3</p> <p>\u4e4b\u524d\u547d\u540d\u4e3a <code>code</code> \u7684\u7a97\u53e3\uff0c\u5bf9\u5e94 <code>3600.code</code></p> <p></p> <p>(3)\u7ec8\u7aef\u8f93\u5165 <code>screen -r 3600</code> \u7136\u540e\u56de\u8f66</p> Text Only<pre><code>screen -r 3600\n</code></pre> <p>\u53ef\u4ee5\u770b\u5230\u8fdb\u5165\u7a97\u53e3\u4e86\uff0c\u5e76\u4e14\u4ecd\u7136\u5728\u8bad\u7ec3</p> <p>\u4ee5\u4e0a\u4fdd\u8bc1\u4e86\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u7535\u8111\u53ef\u4ee5\u5173\u673a\uff0c\u4f11\u7720\uff0c\u65ad\u5f00ssh</p> <p></p>"},{"location":"sticks/shell/","title":"Shell","text":""},{"location":"sticks/shell/#shell","title":"Shell","text":"2025-03-04 21:01:002025-09-28 12:54:08 <p> \u7ea6 260 \u4e2a\u5b57  8 \u5f20\u56fe\u7247  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p> <p>mac \u4f7f\u7528 shell</p> <p>\u53c2\u8003</p> <p>\uff081\uff09\u8fdb\u5165 ubuntu \u7cfb\u7edf</p> Text Only<pre><code>multipass shell ubuntu\n</code></pre> <p>\uff082\uff09cat\u547d\u4ee4\u67e5\u770b\u4e00\u4e0b\uff0cetc\u76ee\u5f55\u4e0b\u7684shells\u8fd9\u4e2a\u6587\u4ef6\uff0c\u8fd9\u4e2a\u6587\u4ef6\u8bb0\u5f55\u4e86\u7cfb\u7edf\u4e2d\u6240\u6709\u7684shell\u7248\u672c</p> Text Only<pre><code>cat /etc/shells\n</code></pre> <p>\u67e5\u770b\u7cfb\u7edf\u4e2d\u6240\u6709\u7684 bash\u7248\u672c</p> <p></p> <p>\u67e5\u770b\u73af\u5883\u53d8\u91cf\u3001\u7cfb\u7edf\u7684\u67e5\u627e\u8def\u5f84\uff08\u7cfb\u7edf\u4f1a\u5728\u8fd9\u4e9b\u8def\u5f84\u4e2d\u67e5\u627e\u5404\u79cd\u547d\u4ee4\u7684\u6267\u884c\u6587\u4ef6\uff09\u3001shell\u73af\u5883\u53d8\u91cf\u5c31\u662f\u7528\u6765\u5b58\u50a8\u5f53\u524d\u7cfb\u7edf\u9ed8\u8ba4\u4f7f\u7528\u7684shell\u7684\u8def\u5f84\u7684\u3001<code>$0</code> \u67e5\u770b\u5f53\u524d\u6b63\u5728\u6267\u884c\u7684\u811a\u672c\u7684\u540d\u79f0</p> <p></p> <p>\u5207\u6362 shell</p> <p></p> <p>\uff083\uff09shell \u57fa\u7840</p> <p>\u2460 \u65b0\u5efa</p> <p></p> <p>\u2461 \u811a\u672c\u6587\u4ef6\u7684\u7b2c\u4e00\u884c\uff1a\u7cfb\u7edf\u81ea\u52a8\u8c03\u7528bash\u6765\u89e3\u91ca\u6267\u884c</p> <p></p> <p></p> <p>\u2462 \u8fd0\u884c\u4e00\u4e2a\u811a\u672c\u6587\u4ef6\u7684\u4f8b\u5b50</p> <p>\u811a\u672c\u6587\u4ef6\u4e2d\u7684\u5185\u5bb9</p> <p></p> <p>\ud83d\udd35 :wq\u4fdd\u5b58\u5e76\u9000\u51fa\uff0c\u56de\u5230\u547d\u4ee4\u884c</p> <p>\ud83d\udd35 \u5728 linux \u4e2d\u6267\u884c\u811a\u672c\u6587\u4ef6\uff0c\u8981\u7ed9\u8fd9\u4e2a\u6587\u4ef6\u6dfb\u52a0\u6267\u884c\u6743\u9650\uff0ca+x \u7ed9\u6240\u6709\u7528\u6237\u6dfb\u52a0\u6267\u884c\u6743\u9650</p> <p>\u4e4b\u540e\u6267\u884c\uff1a\u6267\u884c\u7684\u65b9\u5f0f\u662f\u5728\u547d\u4ee4\u884c\u4e2d\u8f93\u5165  <code>./</code> \uff0c\u7136\u540e\u52a0\u4e0a\u811a\u672c\u6587\u4ef6\u7684\u540d\u79f0\u5c31\u53ef\u4ee5\u4e86</p> <p></p>"},{"location":"sticks/writting/","title":"\u5199\u4f5c","text":""},{"location":"sticks/writting/#_1","title":"\u5199\u4f5c","text":"2025-02-27 17:03:142025-09-28 12:54:08 <p> \u7ea6 127 \u4e2a\u5b57  \u9884\u8ba1\u9605\u8bfb\u65f6\u95f4 1 \u5206\u949f</p>"},{"location":"sticks/writting/#_2","title":"\u8bba\u6587\u5e38\u89c1\u683c\u5f0f\u4fee\u6539\u5efa\u8bae","text":"<ul> <li> \u53c2\u8003\u6587\u732e\u7684\u5f15\u7528\u683c\u5f0f\uff1a</li> </ul> <p>\u4f5c\u8005\u540d\uff0c\u6587\u7ae0\u540d\uff0c\u671f\u520a\u540d\uff0c\u53d1\u8868\u5e74\u4efd\uff0c\u5377\u53f7\uff08\u671f\u53f7\uff09\uff0c\u8d77\u6b62\u9875\u7801. Wu, C.L.; Chau, K.W.; Li, Y.S. Methods to improve neural network performance in daily flows prediction. J. Hydrol. 2009, 372, 80\u201393. </p> <p>\u5982\u679c\u662f\u4e66\uff0c\u8981\u5199\u6210\uff1a\u4f5c\u8005\u540d\uff0c\u4e66\u540d\uff0c\u51fa\u7248\u793e\u7684\u540d\u79f0\uff0c\u51fa\u7248\u5e74\u4efd\u3002  \u4f8b\u5982\uff1aVapnik, V. Statistical Learning Theory; Wiley: New York, NY, USA, 1998.</p> <ul> <li> \u6587\u732e\u7efc\u8ff0\u90e8\u5206\uff1a</li> </ul> <p>\u53e6\u5916\uff0c\u6587\u732e\u7efc\u8ff0\u90e8\u5206\uff0c\u5f15\u7528\u7684\u65f6\u5019\u628a\u4f5c\u8005\u7b49\u540e\u9762\u7684\u4eba\u53bb\u6389</p>"}]}