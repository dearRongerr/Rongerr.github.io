
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mydomain.org/mysite/learning/vit/">
      
      
        <link rel="prev" href="../1/">
      
      
        <link rel="next" href="../swintransformer/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.8">
    
    
      
        <title>vision Transformer的原理与难点源码实现 - 溶err</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/timeago.css">
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css">
    
      <link rel="stylesheet" href="../../mkdocs/css/no-footer.css">
    
      <link rel="stylesheet" href="../../mkdocs/css/unordered-list-symbols.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#vision-transformer" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="溶err" class="md-header__button md-logo" aria-label="溶err" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            溶err
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              vision Transformer的原理与难点源码实现
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="light-blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../sticks/mkdocs_learn/" class="md-tabs__link">
          
  
    
  
  便签

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../bagu/questions/1_questions/" class="md-tabs__link">
          
  
    
  
  面试

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../Error/github/" class="md-tabs__link">
          
  
    
  
  捉个虫

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../3_ViT/" class="md-tabs__link">
          
  
    
  
  笔记

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../literature/" class="md-tabs__link">
          
  
    
  
  文献

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../logs/" class="md-tabs__link">
          
  
    
  
  杂

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="溶err" class="md-nav__button md-logo" aria-label="溶err" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    溶err
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    便签
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            便签
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/mkdocs_learn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MkDocs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/markdwon_learn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    markdown
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/latex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LaTex
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/GitHub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GitHub
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/MacOS/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MacOS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/shell/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shell
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/linux/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linux
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/screen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    screen
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/writting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    写作
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/1_github_v1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    github v1.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/2_python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/3_vscode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VSCode
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    面试
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            面试
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    题目
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            题目
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/questions/1_questions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面试问题
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../bagu/leetcode/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    力扣
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            力扣
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/leetcode/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1 两数之和
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/leetcode/2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2 两数相加
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../bagu/deeplearning/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    深度学习
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            深度学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手撕Transformer代码
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/former1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/former2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/pytorch_shape_function/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pytorch的维度变换函数
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    visionTransformer代码
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    机器学习
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            机器学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/machinelearning/kmeans/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手撕kmeans
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/machinelearning/2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手撕反向传播
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    捉个虫
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            捉个虫
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/github/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    github
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/latex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latex
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/macos/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    macOS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    docker
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    笔记
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_ViT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ViT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CLIP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2_MOCO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MOCO
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图解LayerNorm &amp; BatchNorm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5种归一化方法
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    vision Transformer的原理与难点源码实现
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    vision Transformer的原理与难点源码实现
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      1 怎么从Transformer应用到图像识别
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1 怎么从Transformer应用到图像识别">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-encoder" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 encoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.1 encoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-mhsa-fnn" class="md-nav__link">
    <span class="md-ellipsis">
      1.1.1 MHSA做的是 空间融合；FNN 做的是 通道融合
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-decoder" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 decoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 归纳偏置
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.3 归纳偏置">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131-transformernlpcnn-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      1.3.1 Transformer在nlp中，为什么会比CNN RNN效果要好呢
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      1.4 Transformer的使用类型
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-vit" class="md-nav__link">
    <span class="md-ellipsis">
      2 vit 框架
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 vit 框架">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-patch" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 patch的构建
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-cls-token" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 CLS token
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-position-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Position embedding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-transformer-encoder" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 Transformer encoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25-classification-head" class="md-nav__link">
    <span class="md-ellipsis">
      2.5 classification head
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3 原论文
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 原论文">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 摘要
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 模型图
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4 代码实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 代码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-patch" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 切分 patch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.1 切分 patch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#411-naivetorchunfold" class="md-nav__link">
    <span class="md-ellipsis">
      4.1.1 naive版本：torch.unfold()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#412-convflatten-output" class="md-nav__link">
    <span class="md-ellipsis">
      4.1.2 conv版本：flatten output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#413" class="md-nav__link">
    <span class="md-ellipsis">
      4.1.3 验证结果一样
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#414-patch" class="md-nav__link">
    <span class="md-ellipsis">
      4.1.4 patch 构建的全部代码
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-cls-token" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 CLS token
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-position-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 Position embedding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-transformer-encoder" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 Transformer Encoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45-classification-head" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 classification head
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      总结
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../swintransformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SwinTransformer 学习笔记
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4种位置编码
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../convs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    卷积
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    李沐 目标检测部分
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4_GAN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GAN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5_Bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BERT从零详细解读
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6_Diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6_Diffusion1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VDM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7_Clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Clip
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../8_WeightNorm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    WeightNorm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9_cGAN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GAN 变体
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10_ResNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    项目实战：ResNet果蔬分类
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_excelcsvtensor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础：excel\csv文件→tensor
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12_KLdivergence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KL divergence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13_RNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14_LSTM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LSTM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_ContrastiveLearning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对比学习
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16_YOLO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    YOLO
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17_DETR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DETR
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18_DINO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DINO
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19_GPT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20_distill/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    知识蒸馏
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21_FastRCNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    21 FastRCNN
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    文献
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            文献
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/TSP/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    时间序列预测
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            时间序列预测
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/0_note/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NOTE
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/1_SegRNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SegRNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/2_DLinear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DLinear
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/3_TimesNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TimesNet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/4_Informer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Informer
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/ObejectCounting/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    目标计数
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            目标计数
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank1%20CountGD/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank1 CountGD
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank2%20GeCo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank2 GeCo
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank3%20DAVE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank3 DAVE
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank4%20CACViT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank4 CACViT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank5%20SSD/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank5 SSD
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank6%20LOCA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank6 LOCA
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank7%20SemAug_CountTR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank7 SemAug CountTR
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank8%20CounTR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank8 CounTR
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank9%20SemAug_SAFECount/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank9 SemAug SAFECount
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank10%20SPDCN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank10 SPDCN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank11%20GCA_SUN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank11 GCA SUN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank12%20SAFECount/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank12 SAFECount
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank13%20BMNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank13 BMNet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank14%20LaoNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank14 LaoNet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank15%20CounTX/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank15 CounTX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank16%20Counting_DETR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank16 Counting DETR
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank17%20RCC/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank17 RCC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank18%20Omnicount/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank18 Omnicount
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank19%20FamNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank19 FamNet
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/Reproduction/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    复现&代码
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            复现&代码
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/Reproduction/DAVE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DAVE复现
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/Reproduction/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一些模块
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/Reproduction/2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    特征融合方式
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/Reproduction/3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一些感悟
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/Reproduction/4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    预训练权重
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/Reproduction/5_SegRNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    复现SegRNN
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/ObjectDetection/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    目标检测
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            目标检测
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObjectDetection/2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目标检测基础知识
    
  </span>
  

      </a>
    </li>
  

              
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObjectDetection/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DETR论文系列
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObjectDetection/3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    （DETR）End-to-End Object Detection with Transformer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObjectDetection/4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/MultiModal/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    多模态
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_6" id="__nav_5_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            多模态
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/MultiModal/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../logs/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    杂
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            杂
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../logs/diary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    乐观 &amp; 坚强
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      1 怎么从Transformer应用到图像识别
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1 怎么从Transformer应用到图像识别">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-encoder" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 encoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.1 encoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-mhsa-fnn" class="md-nav__link">
    <span class="md-ellipsis">
      1.1.1 MHSA做的是 空间融合；FNN 做的是 通道融合
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-decoder" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 decoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 归纳偏置
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.3 归纳偏置">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131-transformernlpcnn-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      1.3.1 Transformer在nlp中，为什么会比CNN RNN效果要好呢
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      1.4 Transformer的使用类型
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-vit" class="md-nav__link">
    <span class="md-ellipsis">
      2 vit 框架
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 vit 框架">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-patch" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 patch的构建
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-cls-token" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 CLS token
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-position-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Position embedding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-transformer-encoder" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 Transformer encoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25-classification-head" class="md-nav__link">
    <span class="md-ellipsis">
      2.5 classification head
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3 原论文
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 原论文">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 摘要
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 模型图
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4 代码实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 代码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-patch" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 切分 patch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.1 切分 patch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#411-naivetorchunfold" class="md-nav__link">
    <span class="md-ellipsis">
      4.1.1 naive版本：torch.unfold()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#412-convflatten-output" class="md-nav__link">
    <span class="md-ellipsis">
      4.1.2 conv版本：flatten output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#413" class="md-nav__link">
    <span class="md-ellipsis">
      4.1.3 验证结果一样
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#414-patch" class="md-nav__link">
    <span class="md-ellipsis">
      4.1.4 patch 构建的全部代码
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-cls-token" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 CLS token
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-position-embedding" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 Position embedding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-transformer-encoder" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 Transformer Encoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45-classification-head" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 classification head
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      总结
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="vision-transformer">vision Transformer的原理与难点源码实现<a class="headerlink" href="#vision-transformer" title="Permanent link">&para;</a></h1>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled/><span class="task-list-indicator"></span></label> 霹雳吧啦z</li>
</ul>
<p><a href="https://b23.tv/2vhsYYz">【28、Vision Transformer(ViT)模型原理及PyTorch逐行实现-哔哩哔哩】</a></p>
<h2 id="1-transformer">1 怎么从Transformer应用到图像识别<a class="headerlink" href="#1-transformer" title="Permanent link">&para;</a></h2>
<h3 id="11-encoder">1.1 encoder<a class="headerlink" href="#11-encoder" title="Permanent link">&para;</a></h3>
<p>首先从Transformer开始，首先Transformer是一个sequence to sequence 的框架，它包含 encoder和decoder两个部分，无论是encoder 还是 decoder，核心的建模模块 是由multihead self Attention和feed forward Neural network 这两个部分 构成的。</p>
<p><img alt="image-20241204083719339" src="../images/image-20241204083719339.png" /></p>
<h4 id="111-mhsa-fnn">1.1.1 MHSA做的是 空间融合；FNN 做的是 通道融合<a class="headerlink" href="#111-mhsa-fnn" title="Permanent link">&para;</a></h4>
<p>那具体来看，encoder 部分 就是将我们的源序列送入到 multihead self Attention和FNN 这两个模块里，这两个模块构成一层，那么encoder呢，一般有6层，这样的6层 堆叠起来，那我们需要注意一下 这两个模块的作用是不一样的[重点]，**那首先 multihead self Attention做的事 是对各个位置上的 embedding 进行一个融合，所以我们可以理解为 它做的是 空间融合部分，而FNN呢，是position-wise的，也就是说 对每个位置上单独进行 仿射变换，那我们可以理解为FNN 做的是 通道融合，**所以FNN和MHA 干的是 两个 不同的角度；</p>
<p>MHSA做的是 空间融合；FNN 做的是 通道融合；两个的作用是不一样的；</p>
<h3 id="12-decoder">1.2 decoder<a class="headerlink" href="#12-decoder" title="Permanent link">&para;</a></h3>
<p><img alt="image-20241204083707171" src="../images/image-20241204083707171.png" /></p>
<p>然后decoder部分 也是一个类似的结构，并且 encoder和decoder 是通过 cross-Attention 进行一个交互，来相互传递信息的</p>
<h3 id="13">1.3 归纳偏置<a class="headerlink" href="#13" title="Permanent link">&para;</a></h3>
<p><img alt="image-20241204082946003" src="../images/image-20241204082946003.png" /></p>
<p>这样的结构 就构成了一个Transformer，相比于传统的CNN RNN的区别在于，Transformer 没有局部建模的假设，也没有时间依赖性的假设，是一种全局的假设，对序列计算一个表征，但是它引入了 一个归纳偏置：position embedding，就是说 还是注入了位置信息；</p>
<h4 id="131-transformernlpcnn-rnn">1.3.1 Transformer在nlp中，为什么会比CNN RNN效果要好呢<a class="headerlink" href="#131-transformernlpcnn-rnn" title="Permanent link">&para;</a></h4>
<p>换个角度来说，Transformer在nlp中，为什么会比CNN RNN效果要好呢？就是因为Transformer，所引入的归纳偏置 是比较少的，如果真的要算归纳偏置的话，那么就是引入了 position embedding，而其它位置就可以说 没有引入 先验假设和 归纳偏置的；</p>
<p>对于这样一个模型，它学习上界 是比较好的；也就是说 它的performance是比较高的，唯一的缺陷就说 数据量的要求和引入的归纳偏置 是成 反比的，换句话说 就是我们引入了越多的归纳偏置，也就是说 我们人为地注入了 人类的经验性 知识 就可以帮助这个模型 更好的去学习；</p>
<p>一旦归纳偏置 引入的比较少，我们就期望这个模型从大量的数据中，归纳出 模型自己的 经验来做 这个任务。所以Transformer的优点是，上限很高，缺点就是 对数据量的要求比较高；</p>
<p>再次 强调 归纳偏置。归纳偏置就是 我们人类 用归纳法 所总结出的经验，然后我们把经验 代入到 模型的构建之中，那什么是归纳？就是 发现 很多事物 之间的 共性。</p>
<p>举例子，猫会叫、狗会叫、鸭会叫、鸡会叫，那我们 总结出 动物都会叫，这个就是一个 归纳法；</p>
<p>相对的 还有一个方法 是 演绎法；演绎法 比方说，下雨天要带伞，明天要下雨，所以明天需要带伞。这个就是演绎法。这是归纳和演绎的区别。</p>
<p>这里所说的归纳偏置，就是将人类所总结的经验，代入到 我们设计的模型的 过程之中。</p>
<p>上面是讲的Transformer模型的结构 以及 优缺点。回答了 如何评价Transformer的问题</p>
<p>以上：</p>
<ul>
<li>归纳偏置  &amp; 数据量</li>
<li>MHSA &amp; FFN</li>
</ul>
<h3 id="14-transformer">1.4 Transformer的使用类型<a class="headerlink" href="#14-transformer" title="Permanent link">&para;</a></h3>
<p><img alt="image-20241204083637280" src="../images/image-20241204083637280.png" /></p>
<p>Transformer的变体有，只使用Transformer的encoder，比如说我们常说的bert，bert为什么叫 双向的呢？就是在bert中 预训练 是采用的两个loss 一个是MLM，还有一个是NSP，就是它是去预测的被掩码的位置上的，没有和GPT一样，用的自回归的方式 进行语言建模，是只使用encoder的方式。</p>
<p>好处是速度很快，不需要做 自回归的 递推。另外一种 使用 场景是 decoder only，比如GPT系列，传统的自回归的 语言建模，包括自回归生成 以及一些 流式的任务，一般 我们只会用到 Transformer decoder的部分，这是第二种场景；</p>
<p>那第三种场景呢，就是Transformer原始论文的场景，就是像机器翻译、语言识别等，就是从一个序列空间 到 另外一个序列空间的转换，我们就会用到完整的Transformer的encoder和decoder这样一个结构；这三种使用场景 都很常用。并且呢 各自有各自的特点。想学自己看论文。</p>
<p>今天讲的vision Transformer是encoder only的结构，再次强调ViT只用到了 encoder only的部分，于是我们就不用考虑自回归、下三角的掩码矩阵等等；</p>
<h2 id="2-vit">2 vit 框架<a class="headerlink" href="#2-vit" title="Permanent link">&para;</a></h2>
<p>并且vit又是一个分类任务，更简单了，最后只需要预测一个概率，就可以了。相比于生成任务 是要简单很多的。</p>
<p>首先 vit的框架：</p>
<p><img alt="image-20241204083649066" src="../images/image-20241204083649066.png" /></p>
<p>vit的思想 就是想把 Transformer模型应用到 图像识别任务上，但是直接将Transformer 应用到图像识别任务上，面临的困难就是：Transformer在nlp当中 是以字为单位，就是一句话中 word的数量还是比较少的；但是如果我们 直接将Transformer 应用到一张图片上的话，那图片的基本单位 就是一个个像素点，然后每个图像的像素点 是非常非常多的，少则几百，大则 几千 几万 都有。所以我们把Transformer 直接应用到图像点上的话，第一个就是说 计算量 非常大，第二个 就是对图像而言，它的单个像素点不像在一个句子中  单个字所包含的信息量。在一句话中，单个字 所包含的信息量 还是 非常丰富的。</p>
<p>但是对一张图像当中的 某个像素点 并不包含 什么信息量；对于图像来说 信息量还是主要聚焦在 一小块区域中；就是说 很多个像素点 所构成的区域 构成的信息量 才会比较丰富；</p>
<p>如果单独看一个像素点的话 可能没有什么信息量；</p>
<p>以上是 图像 相比于 文本句子的区别，</p>
<p>所以为了将Transformer应用到 图像领域中 从这两个角度出发 就不能把 Transformer 从像素点层面 一个个个去算 自注意力。那么一个很简单 很直接的想法 就是把 很多个像素点 组成一个块，然后把图像分成很多个块，然后呢 把一个个图像块 去当做一个token，然后送入到Transformer中，这是一个很直接的想法。这个是输入特征部分。</p>
<h3 id="21-patch">2.1 patch的构建<a class="headerlink" href="#21-patch" title="Permanent link">&para;</a></h3>
<p>对于这个块 有两种角度 理解。</p>
<p><img alt="image-20241204083502361" src="../images/image-20241204083502361.png" /></p>
<p>第一种角度，通过DNN的角度理解，也就是说 首先把 图片 切割成 很多个块，也就是image to patch的过程。然后 我们再对 很多个patch 经过一个仿射变换，得到一个新的向量，叫做embedding，也就是 patch to embedding，这是从DNN的角度理解</p>
<p><img alt="image-20241204083558103" src="../images/image-20241204083558103.png" /></p>
<p>那另外一个角度，我们也可以理解为 我们把 图片 得到 embedding的过程 ，也可以理解为卷积网络，也就是说 我们会用一个二维的卷积 在图像上 应用一个卷积，并且说卷积 kernel size等于stride的，然后我们再把得到的卷积图拉直一下，就得到我们一个个的token embedding</p>
<p>这是我们从 两种角度 去看 image to embedding的过程</p>
<h3 id="22-cls-token">2.2  CLS token<a class="headerlink" href="#22-cls-token" title="Permanent link">&para;</a></h3>
<p><img alt="image-20241204083820807" src="../images/image-20241204083820807.png" /></p>
<p>接下来 为了去做分类任务，vit是借鉴了bert中的一个 class token的占位符，关于这个class token，大家也有不同的争议，比如为什么要有一个 class token，以及class token 既然 充当了 query的作用，那为什么 其他 位置上的 量 又可以对它去计算一个 注意力的权重，总之 这里有很多争议。但是bert论文中 也做了对比，用了class token的效果 是比 直接Pooling的效果 要好的。</p>
<h3 id="23-position-embedding">2.3 Position embedding<a class="headerlink" href="#23-position-embedding" title="Permanent link">&para;</a></h3>
<p><img alt="image-20241204083853239" src="../images/image-20241204083853239.png" /></p>
<p>另外 在vit中 同样引入了 position embedding，这里对比了好几种 embedding，最后使用了 可训练的一维embedding，效果会比较好一点</p>
<h3 id="24-transformer-encoder">2.4 Transformer encoder<a class="headerlink" href="#24-transformer-encoder" title="Permanent link">&para;</a></h3>
<p><img alt="image-20241204083959455" src="../images/image-20241204083959455.png" /></p>
<p>另外，vit是主要用了Transformer encoder的一个模块， 并没有使用到 decoder，是比较简单的。</p>
<h3 id="25-classification-head">2.5 classification head<a class="headerlink" href="#25-classification-head" title="Permanent link">&para;</a></h3>
<p><img alt="image-20241204084022804" src="../images/image-20241204084022804.png" /></p>
<p>最后 我们通过class token这个位置上的  状态量 拿出来，然后就可以去做 分类任务。这就是vit的一个全局的结构。接下来 我们来看 具体论文</p>
<h2 id="3">3 原论文<a class="headerlink" href="#3" title="Permanent link">&para;</a></h2>
<p><img alt="image-20241204084045018" src="../images/image-20241204084045018.png" /></p>
<p>论文的标题：一图胜16×16的字，改编自 一图胜千言；</p>
<p><strong><u>AN IMAGE IS WORTH 16×16 WORDS</u></strong></p>
<p>标题的意思就是说 如果把 一个图像的每个像素点看成 一个单词的话 其实我们可以把16×16 像素点 当成一张图 就够了 。我们不需要把16×16个像素点 拿出来 单独进行建模；而是可以把它们 直接看成一个整体。再变成一个embedding 进行建模，这样的效果会更好。</p>
<p><u><strong>TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</strong></u></p>
<p>下面一行 就是说 Transformer 应用到 图像识别，所以在本文中 主要是把transformer应用到 图像识别，cv领域 总共 有三大任务：识别、检测、分割；本文中 只讲到了 识别。后面还有论文把transformer用到cv，不仅会讲到image recognition还会讲到 检测和分割</p>
<h3 id="31">3.1 摘要<a class="headerlink" href="#31" title="Permanent link">&para;</a></h3>
<p>首先 摘要部分：</p>
<p><img alt="image-20241204084132218" src="../images/image-20241204084132218.png" /></p>
<p>尽管transformer已经成为nlp任务的标配；但是它在cv这个领域的潜力还没有被挖掘</p>
<p>那么在计算机视觉中，注意力机制要么应用到卷积网络中，要么直接替代卷积网络的某一部分；</p>
<p>在本文中，作者展示了CNN不是必须的，我们可以把简单的transformer模型直接应用到图像块上，就可以在图像分类任务上 表现得很好；但是这个很好是有成本的；当我们首先将这个vit模型在大量的数据上 做预训练，然后再把它迁移到 中等大小 或者 小的数据集上，vit就可以取得 相比于卷积网络 一样 甚至 更好的效果。</p>
<p>跟之前讲的transformer有异曲同工之妙，因为transformer的归纳偏置 是比较少的。就是说并没有把我们人类总结的一些经验 注入到transformer模型之中，所以单纯让transformer依赖数据去学习到这些经验 是一个比较漫长的过程，所以我们必须需要大量的数据量 大量的数据集 才可以让transformer vit取得比较好的效果，完全是 数据驱动的；</p>
<h3 id="32">3.2 模型图<a class="headerlink" href="#32" title="Permanent link">&para;</a></h3>
<p>introduction直接跳过，直接看模型图：</p>
<p><img alt="image-20241204085428355" src="../images/image-20241204085428355.png" /></p>
<p>vit的结构就是 图1所示；首先看decription；</p>
<p>首先把图片分成很多个固定大小的 块。然后在用线性网络 将这些块 形成一个嵌入表征，然后再在表征上 加入位置编码；然后再把这一系列的向量 送入到标准的transformer encoder之中，模型就用这么一句话 描述完了。然后为了去做 分类任务，就是像bert中一样，增加了一个 额外的classification token位置，就是对序列 新增了一个位置；</p>
<p>可以理解为 这个位置 就是起一个 query的作用。就是它会去收集 使得这个模型 能做好 分类任务的信息。最后呢 我们将最后一层的 位置信息 拿出来 做一个线性映射，映射到 类别的概率分布上，然后就可以了。这个模型是比较简单的 如果非常了解transformer模型的话。vit是没有难度的（代码 演示实例）</p>
<p>接下来 看左图，右图看过 很多遍了</p>
<p><img alt="image-20241204085557482" src="../images/image-20241204085557482.png" /></p>
<ul>
<li>
<p>首先将一副图片 分成很多个 块；需要注意的是 每个块的大小是不变的；图像的大小 可能会变化 但是 每个块的大小 是不会 发生变化的</p>
</li>
<li>
<p>在同一个模型中 块的大小 不会发生变化；</p>
</li>
<li>
<p>换句话说，如果图片大一点，那反应在 序列长度上 长一点；</p>
</li>
<li>将一个图片分成很多块，像卷积中 平移的顺序一样，先左到右，把图片拉直，拉成一个序列的形状；</li>
<li>然后再把 每个块的像素，像素点的值 归一化；就是说之前就已经 做好 归一化了 归一化到0-1之间。</li>
<li>然后再把块里的 值 通过线性变换 映射到 模型的维度，或者说 我们得到了patch embedding；</li>
<li>有了patch embedding以后，为了做分类任务，需要在序列的开头 增加一个 可训练的embedding，这个embedding是随机初始化的 embedding。那这样 就构成了 一个长度+1的序列。</li>
<li>然后我们再增加position embedding，就是位置编码，那这样 加完 后的 序列表征 就可以直接 送入到 transformer encoder中，然后我们在encoder 最后一层中，取出 新加的 也就是多余位置上的 输出状态 经过一个MLP，得到类别的概率分布，就可以用交叉熵 去算出 分类loss，就完成了 一个vit模型的搭建；</li>
</ul>
<h2 id="4">4 代码实现<a class="headerlink" href="#4" title="Permanent link">&para;</a></h2>
<p>接下来 代码 实现这个过程，实现的重点：</p>
<h3 id="41-patch">4.1 切分 patch<a class="headerlink" href="#41-patch" title="Permanent link">&para;</a></h3>
<ul>
<li>Image2embedding</li>
</ul>
<p>也就是说 实现的重点 在transformer之前的部分；因为transformer encoder的代码 pytorch 已经包装起来了。而且 之前 也已经详细讲过</p>
<p><u>所有的所有 都是为了 代码 嗯 别忘了 开始的目的</u></p>
<p>特点：实现 功能为主 ，不是跑模型；围绕例子 实现 过程；</p>
<p>首先 导入库：</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-0-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span></code></pre></div></td></tr></table></div>
<p>,来看一下，首先第一部分 要做什么，我们需要将 一幅 图片变成embedding，第一步我们要做这个事情，我们可以首先 定义一个函数</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-1-1"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb</span><span class="p">():</span>
</span><span id="__span-1-2">  <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
<p><img alt="image-20241204090121585" src="../images/image-20241204090121585.png" /></p>
<p>之前在 思维导图里 讲了 这个 image2emb这个过程 可以从两个角度 去理解，一个角度 是DNN的角度，我们把image手动 切成 一个个块，再把每个块 变成 embedding</p>
<p>第二个角度就是说 直接从 二维卷积的 角度去理解，就是 直接对图片做 二维卷积 ，然后把卷积后的结果 拉直一下，构成embedding</p>
<p>所以vit结构 第一层 其实就是一个卷积；那 写两个函数 实现它</p>
<p>第一个函数 叫navie,很直接的实现；</p>
<p>第二个函数取名为conv，我们以卷积的角度，来实现</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-2-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-2-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-2-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-2-4">
</span><span id="__span-2-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">():</span>
</span><span id="__span-2-6">    <span class="k">pass</span>
</span><span id="__span-2-7">
</span><span id="__span-2-8"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">():</span>
</span><span id="__span-2-9">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="411-naivetorchunfold">4.1.1 naive版本：torch.unfold()<a class="headerlink" href="#411-naivetorchunfold" title="Permanent link">&para;</a></h4>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-3-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-3-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-3-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-3-4">
</span><span id="__span-3-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-3-6">    <span class="c1"># image shape:bs  × channel × height × width</span>
</span><span id="__span-3-7">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-3-8">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">patch</span> <span class="o">@</span> <span class="n">weight</span>
</span><span id="__span-3-9">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-3-10"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">():</span>
</span><span id="__span-3-11">    <span class="k">pass</span>
</span><span id="__span-3-12">
</span><span id="__span-3-13"><span class="c1"># test code for image2emb</span>
</span><span id="__span-3-14"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-3-15"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-3-16"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-3-17">
</span><span id="__span-3-18"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-3-19"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span><span id="__span-3-20"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span>
</span><span id="__span-3-21">
</span><span id="__span-3-22"><span class="n">patch_embedding_naive</span> <span class="o">=</span> <span class="n">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">)</span>
</span><span id="__span-3-23"><span class="nb">print</span><span class="p">(</span><span class="n">patch_embedding_naive</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>注释：</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-4-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-4-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-4-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-4-4">
</span><span id="__span-4-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-4-6">    <span class="c1"># image shape:bs  × channel × height × width = 1,3,8,8</span>
</span><span id="__span-4-7">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-4-8">    <span class="c1"># patchshape = torch.Size([1, 48, 4])   patch_size = 4</span>
</span><span id="__span-4-9">    <span class="c1"># 1：batchsize</span>
</span><span id="__span-4-10">    <span class="c1"># 48 = 3*4*4（卷积覆盖的input region）</span>
</span><span id="__span-4-11">    <span class="c1"># 4：1,3,8,8的输入图片用 1344的卷积核卷积，得到4个input region</span>
</span><span id="__span-4-12">    <span class="c1"># transpose(-1,-2) → 1,4,48  </span>
</span><span id="__span-4-13">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">patch</span> <span class="o">@</span> <span class="n">weight</span>
</span><span id="__span-4-14">    <span class="c1"># 1,4,48 @ 48,8 = 4 × 8</span>
</span><span id="__span-4-15">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-4-16"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">():</span>
</span><span id="__span-4-17">    <span class="k">pass</span>
</span><span id="__span-4-18">
</span><span id="__span-4-19"><span class="c1"># test code for image2emb</span>
</span><span id="__span-4-20"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-4-21"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-4-22"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-4-23">
</span><span id="__span-4-24"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-4-25"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span><span id="__span-4-26"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span>
</span><span id="__span-4-27">
</span><span id="__span-4-28"><span class="n">patch_embedding_naive</span> <span class="o">=</span> <span class="n">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">)</span>
</span><span id="__span-4-29"><span class="nb">print</span><span class="p">(</span><span class="n">patch_embedding_naive</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<hr />
<p>以下是代码的怎么写出来的详解，可跳：</p>
<p>首先 我们来实现 navie的版本</p>
<p>那么既然是 image2embedding，我们需要的第一个参数 就是image的张量，第二个参数 就是 块的大小，首先将image分成很多很多的块，每个块 肯定是 方形的 边长是多少，那我们 传入的是就是 <code>patch_size</code> 也就是 块的边长，那还有就是 我们既然要得到embedding，首先得到块，块里面的所有像素点，我们会对它做一个 线性变换，线性变换的话 需要一个weight，这个 变换的权重矩阵</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-5-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-5-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-5-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-5-4">
</span><span id="__span-5-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">wieght</span><span class="p">):</span>
</span><span id="__span-5-6">    <span class="k">pass</span>
</span><span id="__span-5-7">
</span><span id="__span-5-8"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">():</span>
</span><span id="__span-5-9">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
<p>这里的image size一般是跟 卷积中类似，它的格式 就是 batch size×channel×height×width，这个是image的shape，在二维卷积中 也是这样格式</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-6-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-6-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-6-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-6-4">
</span><span id="__span-6-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-6-6">    <span class="c1"># image shape:bs  × channel × height × width</span>
</span><span id="__span-6-7">    <span class="k">pass</span>
</span><span id="__span-6-8"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">():</span>
</span><span id="__span-6-9">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
<p>首先第一步 我们要对 图像分块，那这个图片分块 其实就是 类似之前卷积讲过的</p>
<p><img alt="image-20241204090349426" src="../images/image-20241204090349426.png" /></p>
<p>我们有两种角度 理解卷积，第一种 角度 是把每次 滑动相乘的区域 拎出来，其实就是image2patch，只是 这里的stride 刚好 等于 kernel size</p>
<p>另外一种角度 就是我们对kernel 进行 填充，把kernel 填充成 跟 input feature map一样大小的，然后 推出了 转置卷积</p>
<p>所以这里 就是 第一种角度，我们可以通过image2patch，将每一步 卷积的区域 拿出来 构成一个个patch，那这里 不写for 循环 拿patch</p>
<p>之前 也讲过 在pytorch 中，有一个api叫做<code>pytorch nn functional unfold</code>这个api</p>
<p><img alt="image-20241204090421337" src="../images/image-20241204090421337.png" /></p>
<p>这个api做的事情，就是拿出卷积的区域</p>
<p><img alt="image-20241204090451722" src="../images/image-20241204090451722.png" /></p>
<p>，简单来讲 就是 拿出 卷积的区域，你看它需要的参数 也非常的卷积</p>
<p><img alt="image-20241204090520011" src="../images/image-20241204090520011.png" /></p>
<p>有input、kernel size、dilation，padding、stride</p>
<p>其实就是说 根据input 卷积的参数 就能将 每一次 滑动的 区域的输入 单独的 拿出来</p>
<p>这里 就是 image2patch的过程</p>
<p>这里 我们直接去调用</p>
<p>那也就是说 刚好有这些参数，就可以直接去调用</p>
<p>我们已经 import 简写成F了，所以就写F.unfold,input其实就是 image，刚好是满足这个格式的，第二个参数 就是kernel size参数，kernel size 其实就是 patch size，第三个呢 其实就是dilation，dilation这里我们不需要考虑，因为 我们并没有 空洞，padding也不用考虑，也没有做填充，最后一个stride我们需要考虑，我们的stride并不是1，因为 我们这里的图像分块 是没有交叠的，结构图中可以看到 ，每个块与块之间 是没有交叠的，这就是一种特殊的卷积 stride=kernel size，通过F.unfold函数 就能把 图像分块，结果定义为patch</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-7-1">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-8-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-8-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-8-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-8-4">
</span><span id="__span-8-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-8-6">    <span class="c1"># image shape:bs  × channel × height × width</span>
</span><span id="__span-8-7">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span>
</span><span id="__span-8-8">    <span class="k">pass</span>
</span><span id="__span-8-9"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">():</span>
</span><span id="__span-8-10">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
<p>这个 就是 调用pytorch F.unfold这个函数 将图片 进行分块，原理就是 将图片看成 kernel size=stride的卷积就好了，然后就可以把每一次 每一步 输入的区域 单独拿出来，放到patch中</p>
<p>当然 这个patch是什么形状呢？我们可以先来 测试一下，需要先 测试一下 这个函数 来看一下 patch的形状。</p>
<p>为了 测试 我们需要 先 定义一些常量，比如说 我们需要定义 batch size、input channel、图片的高度 以及 图片的宽度</p>
<p>假设 我们设置batch size=1，channel=3，宽度和高度写个8和8</p>
<p>同时我们还需要 定义 patch size，这里 我们可以定义4，也就是说 我们是4×4为一个 patch</p>
<p>那还有 我们需要得到 一个 embedding，所以我们还需要有一个 patch embedding dim，其实就是transformer中的 model dim，我们可以 定义为8</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-9-1"><span class="c1"># test code for image2emb</span>
</span><span id="__span-9-2"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-9-3"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-9-4"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span></code></pre></div></td></tr></table></div>
<p>在定义好了这些量以后，我们可以来测试这些函数了</p>
<p>首先 我们需要生成 图片</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-10-1"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>还需要 weight，weight怎么样定义呢？</p>
<p>weight 其实就是 patch2embedding过程的乘法矩阵，也就是说 我们将patch的大小 映射成model dim这个大小，所以weight 是一个 二维的张量</p>
<p>张量的第一个形状，先暂时设为None，第二个形状 其实 就是 model dim，是一个 这样的 乘法矩阵 </p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-11-1"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>那第一个维度呢？第一个维度 其实就是 patch的大小，按照论文的意思 patch的大小 是什么呢？patch的大小 其实就是patch的边长，边长的平方刚好是 面积，然后再乘以 通道数目，也就是说 如果图片 有 三个通道的话，每个patch 其实是 包含 三个 通道的，所以这里 我们需要算出一个量</p>
<p>patch_depth 也就是 patch的深度，它应该就是 patch size再乘以 patch size再乘以 ic 输入的通道数目，那这里 我们就可以把 weight的矩阵 给写出来，也就是 patch_depth</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-12-1"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-12-2"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-13-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-13-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-13-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-13-4">
</span><span id="__span-13-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-13-6">    <span class="c1"># image shape:bs  × channel × height × width</span>
</span><span id="__span-13-7">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span>
</span><span id="__span-13-8">    <span class="k">pass</span>
</span><span id="__span-13-9"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">():</span>
</span><span id="__span-13-10">    <span class="k">pass</span>
</span><span id="__span-13-11">
</span><span id="__span-13-12"><span class="c1"># test code for image2emb</span>
</span><span id="__span-13-13"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-13-14"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-13-15"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-13-16">
</span><span id="__span-13-17"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-13-18"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span><span id="__span-13-19"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>这就是 weight 矩阵，有了weight 有了image，patch_size 我们就可以 调用这个函数image2emb_navie</p>
<p>然后 我们首先打印一下 里面的patch的形状</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-14-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-14-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-14-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-14-4">
</span><span id="__span-14-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-14-6">    <span class="c1"># image shape:bs  × channel × height × width</span>
</span><span id="__span-14-7">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span>
</span><span id="__span-14-8">    <span class="nb">print</span><span class="p">(</span><span class="n">patch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="__span-14-9"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">():</span>
</span><span id="__span-14-10">    <span class="k">pass</span>
</span><span id="__span-14-11">
</span><span id="__span-14-12"><span class="c1"># test code for image2emb</span>
</span><span id="__span-14-13"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-14-14"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-14-15"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-14-16">
</span><span id="__span-14-17"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-14-18"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span><span id="__span-14-19"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span>
</span><span id="__span-14-20">
</span><span id="__span-14-21"><span class="n">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>输出：torch.Size([1, 48, 4])</p>
<p>结果解读：patch的形状是1×48×4 知道为什么 是 这3个数字吗</p>
<p>首先 4很好理解 因为 图像是 8×8的 这样一个 面积，然后 patch size是4×4，那一个8×8的图片，以4×4为一个块的话，刚好是 4块；就构成了4块；</p>
<p>这里的4 其实就是 块的数目，就是 图片 分块以后 块的数目</p>
<p>然后 48怎么来的呢？48其实就是  patch size×patch size ×input channel 就是 4×4×3=48,把每个卷积都拉直了，为了更便于理解 我们可以增加一个transpose，就是把最后一维和倒数第二维 交换一下，再运行</p>
<p><img alt="image-20241204202226767" src="../images/image-20241204202226767.png" /></p>
<p>1是batch size；4是patch的数目；48是每个patch所包含的像素点的数目</p>
<p>得到patch以后，打印weight形状</p>
<p><img alt="image-20241204202305823" src="../images/image-20241204202305823.png" /></p>
<p>weight形状 刚好是48×8，所以我们把patch跟weight 进行一个矩阵相乘，就可以得到patch embedding，用@符号，然后返回patch embedding，然后把得到patch embedding naive，然后打印patch embedding naive的形状</p>
<p><img alt="image-20241204202335847" src="../images/image-20241204202335847.png" /></p>
<p>这样 就完成了 第一个函数的测试 把这个3×8×8的图片，变成了 embedding的形式，embedding的大小是4×8；也就是一张图片被分成了4块 并且每一块 变成了长度为8的向量，来表示这个块</p>
<p>以上是所有naive的实现步骤</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-15-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-15-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-15-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-15-4">
</span><span id="__span-15-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-15-6">    <span class="c1"># image shape:bs  × channel × height × width</span>
</span><span id="__span-15-7">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-15-8">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">patch</span> <span class="o">@</span> <span class="n">weight</span>
</span><span id="__span-15-9">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-15-10"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">():</span>
</span><span id="__span-15-11">    <span class="k">pass</span>
</span><span id="__span-15-12">
</span><span id="__span-15-13"><span class="c1"># test code for image2emb</span>
</span><span id="__span-15-14"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-15-15"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-15-16"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-15-17">
</span><span id="__span-15-18"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-15-19"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span><span id="__span-15-20"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span>
</span><span id="__span-15-21">
</span><span id="__span-15-22"><span class="n">patch_embedding_naive</span> <span class="o">=</span> <span class="n">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">)</span>
</span><span id="__span-15-23"><span class="nb">print</span><span class="p">(</span><span class="n">patch_embedding_naive</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<hr />
<h4 id="412-convflatten-output">4.1.2 conv版本：flatten output<a class="headerlink" href="#412-convflatten-output" title="Permanent link">&para;</a></h4>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-16-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-16-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-16-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-16-4">
</span><span id="__span-16-5"><span class="c1"># step1 convert image to embedding vector sequence</span>
</span><span id="__span-16-6"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-16-7">    <span class="c1"># image shape:bs  × channel × height × width</span>
</span><span id="__span-16-8">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-16-9">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">patch</span> <span class="o">@</span> <span class="n">weight</span>
</span><span id="__span-16-10">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-16-11"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="p">):</span>
</span><span id="__span-16-12">    <span class="n">conv_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span> <span class="c1"># bs*oc*oh*ow</span>
</span><span id="__span-16-13">    <span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="p">,</span><span class="n">ow</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-16-14">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="o">*</span><span class="n">ow</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-16-15">
</span><span id="__span-16-16">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-16-17">
</span><span id="__span-16-18"><span class="c1"># test code for image2emb</span>
</span><span id="__span-16-19"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-16-20"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-16-21"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-16-22">
</span><span id="__span-16-23"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-16-24"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span><span id="__span-16-25"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span> <span class="c1"># model_dim是输出通道数目，patch depth是卷积核的面积乘以输入通道数</span>
</span><span id="__span-16-26">
</span><span id="__span-16-27"><span class="c1"># 分块方法得到embedding</span>
</span><span id="__span-16-28"><span class="n">patch_embedding_naive</span> <span class="o">=</span> <span class="n">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">)</span>
</span><span id="__span-16-29"><span class="n">kernel</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">patch_size</span><span class="p">))</span>
</span><span id="__span-16-30">
</span><span id="__span-16-31"><span class="c1"># 二维卷积方法得到embedding</span>
</span><span id="__span-16-32"><span class="n">patch_embedding_conv</span> <span class="o">=</span> <span class="n">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">patch_size</span><span class="p">)</span>
</span><span id="__span-16-33">
</span><span id="__span-16-34"><span class="nb">print</span><span class="p">(</span><span class="n">patch_embedding_naive</span><span class="p">)</span>
</span><span id="__span-16-35"><span class="nb">print</span><span class="p">(</span><span class="n">patch_embedding_conv</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>注释：</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-17-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-17-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-17-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-17-4">
</span><span id="__span-17-5"><span class="c1"># step1 convert image to embedding vector sequence</span>
</span><span id="__span-17-6"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-17-7">    <span class="c1"># image shape:bs  × channel × height × width = 1,3,8,8</span>
</span><span id="__span-17-8">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-17-9">    <span class="c1"># patchshape = torch.Size([1, 48, 4])   patch_size = 4</span>
</span><span id="__span-17-10">    <span class="c1"># 1：batchsize</span>
</span><span id="__span-17-11">    <span class="c1"># 48 = 3*4*4（卷积覆盖的input region）</span>
</span><span id="__span-17-12">    <span class="c1"># 4：1,3,8,8的输入图片用 1344的卷积核卷积，得到4个input region</span>
</span><span id="__span-17-13">    <span class="c1"># transpose(-1,-2) → 1,4,48  </span>
</span><span id="__span-17-14">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">patch</span> <span class="o">@</span> <span class="n">weight</span>
</span><span id="__span-17-15">    <span class="c1"># 1,4,48 @ 48,8 = 1× 4 × 8</span>
</span><span id="__span-17-16">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-17-17">
</span><span id="__span-17-18"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="p">):</span>
</span><span id="__span-17-19">    <span class="c1"># image = bs,ic,image_h,image_w = 1,3,8,8 </span>
</span><span id="__span-17-20">    <span class="c1"># kernel = 8 × 3 × 4 × 4</span>
</span><span id="__span-17-21">    <span class="c1"># stride = patch_size = 4 </span>
</span><span id="__span-17-22">    <span class="n">conv_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span> <span class="c1"># bs*oc*oh*ow</span>
</span><span id="__span-17-23">    <span class="c1"># (h-k+2p+s)/s = (8-4+4)/4  = 2</span>
</span><span id="__span-17-24">    <span class="c1"># conv_output = 8 × 1 × 2 × 2</span>
</span><span id="__span-17-25">    <span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="p">,</span><span class="n">ow</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-17-26">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="o">*</span><span class="n">ow</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-17-27">    <span class="c1"># conv_output = 1 × 8 × 2 × 2</span>
</span><span id="__span-17-28">    <span class="c1"># reshape ： 1 × 8 × 4</span>
</span><span id="__span-17-29">    <span class="c1"># transpose(-1,-2)  1 × 4 × 8</span>
</span><span id="__span-17-30">    <span class="c1">#（输入图片 划分成 4个patch，每个patch由原来的 48个像素表示，降维成8维表示）</span>
</span><span id="__span-17-31">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-17-32">
</span><span id="__span-17-33"><span class="c1"># test code for image2emb</span>
</span><span id="__span-17-34"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-17-35"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-17-36"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-17-37">
</span><span id="__span-17-38"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-17-39"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span><span id="__span-17-40"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span> <span class="c1"># model_dim是输出通道数目，patch depth是卷积核的面积乘以输入通道数</span>
</span><span id="__span-17-41">
</span><span id="__span-17-42"><span class="c1"># 分块方法得到embedding</span>
</span><span id="__span-17-43"><span class="n">patch_embedding_naive</span> <span class="o">=</span> <span class="n">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">)</span>
</span><span id="__span-17-44">
</span><span id="__span-17-45"><span class="c1"># conv版本：</span>
</span><span id="__span-17-46"><span class="n">kernel</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">patch_size</span><span class="p">))</span>
</span><span id="__span-17-47"><span class="c1"># weight = 48 × 8</span>
</span><span id="__span-17-48"><span class="c1"># transpose(0,1) : 8 × 48</span>
</span><span id="__span-17-49"><span class="c1"># reshape :8 × 3 × 4 × 4</span>
</span><span id="__span-17-50">
</span><span id="__span-17-51"><span class="c1"># 二维卷积方法得到embedding</span>
</span><span id="__span-17-52"><span class="n">patch_embedding_conv</span> <span class="o">=</span> <span class="n">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">patch_size</span><span class="p">)</span>
</span><span id="__span-17-53"><span class="c1"># image = bs,ic,image_h,image_w = 1,3,8,8 </span>
</span><span id="__span-17-54"><span class="c1"># kernel = 8 × 3 × 4 × 4</span>
</span><span id="__span-17-55"><span class="c1"># patch_size = 4</span>
</span><span id="__span-17-56">
</span><span id="__span-17-57"><span class="nb">print</span><span class="p">(</span><span class="n">patch_embedding_naive</span><span class="p">)</span>
</span><span id="__span-17-58"><span class="nb">print</span><span class="p">(</span><span class="n">patch_embedding_conv</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<hr />
<p>代码详解：</p>
<p>接下来 用卷积实现 conv的版本</p>
<p>既然是卷积 就需要对传入的参数改一下，第一个参数 还是 image，第二个参数是kernel，第三个参数 需要 stride，这样我们定义好了 卷积的三要素 </p>
<p>首先定义F.conv2d第一个参数 image，第二个参数 kernel，stride步长设置为stride，这样得到了conv_output,这样做了一个卷积，等下 会讲解 这个得到的和是什么</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-18-1"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="p">):</span>
</span><span id="__span-18-2">    <span class="n">conv_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
</span><span id="__span-18-3">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
<p>这样操作的话  卷积输出的大小是什么呢？</p>
<p>卷积输出的大小是 batch_size×output channel×output height×output width  </p>
<p>最终 我们要得到 patch embedding，其实我们卷积后的宽度和高度，我们会把它拉成一个序列，看框架图：</p>
<p><img alt="image-20241204202538969" src="../images/image-20241204202538969.png" /></p>
<p>就是说 将 output feature map拉直，拉直的就是output height×output width的部分，也就是说 可以对conv output进行一个reshape，reshape成bs×oc×（oh×ow）再transpose一下，把序列长度这一维 放到中间，这样得到 patch embedding，最后 返回 patch embedding</p>
<p>这个过程，首先将 image2embedding的过程 首先看出二维卷积，卷积的结果是一个batch size×通道数再✖️高度✖️宽度，因为我们这里模仿nlp中 把图片变成序列，于是我们可以把特征图 高度和宽度浓缩成一起，就是拉直的意思，然后再把通道数和嵌入位置 交换一下维度，通道数 就是 patch size，oh×ow就是sequence的长度</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-19-1"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="p">):</span>
</span><span id="__span-19-2">    <span class="n">conv_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span> <span class="c1"># bs*oc*oh*ow</span>
</span><span id="__span-19-3">    <span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="p">,</span><span class="n">ow</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-19-4">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="o">*</span><span class="n">ow</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-19-5">
</span><span id="__span-19-6">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span></code></pre></div></td></tr></table></div>
<p>接下来最关键的就是 定义好kernel，那kernel怎么定义呢？kernel就是weight，只不过要把形状变一变。</p>
<p><img alt="image-20241204202723536" src="../images/image-20241204202723536.png" /></p>
<p>首先 上面这个weight的形状是 patch depth×model dim，其实可以怎么理解呢？model dim就变成了oc，所以model dim就是输出通道数目 </p>
<p>patch depth就是卷积核的面积×输入通道数</p>
<p>kernel的形状按照二维卷积的形式，oc×ic×kh×kw 输出通道数、输入通道数、kernel卷积核的高度和宽度，所以把kernel  reshape成oc×ic×kh×kw 这种形状；</p>
<p>首先将kernel转置一下，通道数放到最前<code>kernel.transpose(0,1)</code></p>
<p>然后再reshape一下，那reshape成什么形状呢？按照<code>oc×ic×kh×kw</code>的数据格式，</p>
<p><img alt="image-20241204202816198" src="../images/image-20241204202816198.png" /></p>
<p>oc不知道大小，用-1表示，ic前面定义了，接下来kh×kw，kh、kw就是patch size，这里有个笔误</p>
<p><img alt="image-20241204202838959" src="../images/image-20241204202838959.png" /></p>
<p>kernel=weight.transpose</p>
<p>weight的形状：<code>patch_depth × model_dim</code>、<code>patch depth=patch size×patch size×ic</code>、<code>model dim=oc</code></p>
<p>所以我们的做法 首先交换0、1维度 把输出通道数放到前面，然后做reshape操作，然后把kernel代入函数当中，做image2emb，首先传入的是image，然后是kernel，然后这里的stride就是patch size，结果传给<code>patch embedding conv</code></p>
<p><img alt="image-20241204202912609" src="../images/image-20241204202912609.png" /></p>
<p>其中，patch embedding naive是分块方法得到patch embedding</p>
<p>patch embedding conv是二维卷积的方法得到patch embedding</p>
<h4 id="413">4.1.3 验证结果一样<a class="headerlink" href="#413" title="Permanent link">&para;</a></h4>
<p>打印查看结果 结果基本上是一样的</p>
<p><img alt="image-20241204202948374" src="../images/image-20241204202948374.png" /></p>
<h4 id="414-patch">4.1.4 patch 构建的全部代码<a class="headerlink" href="#414-patch" title="Permanent link">&para;</a></h4>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-20-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-20-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-20-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-20-4">
</span><span id="__span-20-5"><span class="c1"># step1 convert image to embedding vector sequence</span>
</span><span id="__span-20-6"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-20-7">    <span class="c1"># image shape:bs  × channel × height × width</span>
</span><span id="__span-20-8">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-20-9">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">patch</span> <span class="o">@</span> <span class="n">weight</span>
</span><span id="__span-20-10">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-20-11"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="p">):</span>
</span><span id="__span-20-12">    <span class="n">conv_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span> <span class="c1"># bs*oc*oh*ow</span>
</span><span id="__span-20-13">    <span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="p">,</span><span class="n">ow</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-20-14">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="o">*</span><span class="n">ow</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-20-15">
</span><span id="__span-20-16">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-20-17">
</span><span id="__span-20-18"><span class="c1"># test code for image2emb</span>
</span><span id="__span-20-19"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-20-20"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-20-21"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-20-22">
</span><span id="__span-20-23"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-20-24"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span><span id="__span-20-25"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span> <span class="c1"># model_dim是输出通道数目，patch depth是卷积核的面积乘以输入通道数</span>
</span><span id="__span-20-26">
</span><span id="__span-20-27"><span class="c1"># 分块方法得到embedding</span>
</span><span id="__span-20-28"><span class="n">patch_embedding_naive</span> <span class="o">=</span> <span class="n">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">)</span>
</span><span id="__span-20-29"><span class="n">kernel</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">patch_size</span><span class="p">))</span>
</span><span id="__span-20-30">
</span><span id="__span-20-31"><span class="c1"># 二维卷积方法得到embedding</span>
</span><span id="__span-20-32"><span class="n">patch_embedding_conv</span> <span class="o">=</span> <span class="n">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">patch_size</span><span class="p">)</span>
</span><span id="__span-20-33">
</span><span id="__span-20-34">
</span><span id="__span-20-35"><span class="nb">print</span><span class="p">(</span><span class="n">patch_embedding_naive</span><span class="p">)</span>
</span><span id="__span-20-36"><span class="nb">print</span><span class="p">(</span><span class="n">patch_embedding_conv</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>总结：这两种方法其实是一种方法，如果按照原文的意思，可以理解为原文首先是分成块，用一个矩阵进行相乘，我们可以把这个过程看成二维卷积的过程；就是说把矩阵转置成kernel的形状，然后以kernel size等于stride的卷积 来对二维图形进行卷积，卷积过后，把卷积输出的特征图，通道看成embedding的大小，卷积特征图的高度和宽度的二维形式拉直，拉成一维序列长度，印证了我们的角度，从CNN的角度理解，做一个二维卷积，再把输出的特征图拉直，就可以得到一维的embedding序列</p>
<p><img alt="image-20241204203030118" src="../images/image-20241204203030118.png" /></p>
<p>以上是第一步 由图片得到embedding：convert image to embedding vector sequence</p>
<h3 id="42-cls-token">4.2 CLS token<a class="headerlink" href="#42-cls-token" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-21-1"><span class="c1"># step2 prepend CLS token embedding</span>
</span><span id="__span-21-2"><span class="c1"># patch_embedding_conv = 1 × 4 × 8</span>
</span><span id="__span-21-3"><span class="c1"># cls_token_embedding = 1 × 1 × 8</span>
</span><span id="__span-21-4">
</span><span id="__span-21-5"><span class="n">cls_token_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">model_dim</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-21-6"><span class="c1"># token_embedding</span>
</span><span id="__span-21-7"><span class="c1"># 第一个位置 是 cls token，cls token的嵌入维度是 8</span>
</span><span id="__span-21-8"><span class="c1"># 所以 dim = 1</span>
</span><span id="__span-21-9"><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">cls_token_embedding</span><span class="p">,</span><span class="n">patch_embedding_conv</span><span class="p">],</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>第二步加上个 cls  token；classification token，这是模仿bert模型中，</p>
<p><img alt="image-20241204212608638" src="../images/image-20241204212608638.png" /></p>
<p>需要在序列开始 加入一个可学习的 embedding，可以理解为 query，up主也有疑问，既然是query 为什么要加可学习的embedding为什么也可以加position embedding，为什么其他位置也可以对它计算注意力机制  ；总之这里面还有很多难以解决的问题</p>
<p>根据原文的意思，CLS是随机初始化的，我们可以用一个随机初始化的张量：<code>cls_token_embeddding torch.randn()</code>形状是 batch size，长度显然是1，大小是model dim，需要增加一个参数<code>requires_grad=True</code>因为是可训练的</p>
<p><img alt="image-20241204212309325" src="../images/image-20241204212309325.png" /></p>
<p>以上增加了cls_token_embedding</p>
<p><img alt="image-20241204212407145" src="../images/image-20241204212407145.png" /></p>
<p>接下来将 naive或者conv给拼起来，调用torch.cat函数进行拼接，把cls embedding放在第一个位置，patch embedding放在第二个位置上，接下来考虑在哪个维度上进行拼接 ，这个dim传0还是1还是2，因为有三个维度，因为我们在位置上拼接，不是batch size不是通道，而是在位置上拼接，所以dimension传入1，也就是中间的维度，这样我们得到了token embedding</p>
<p>token embedding=patch embedding+cls token，也就是我们增加的分类字符</p>
<p><img alt="image-20241204212652501" src="../images/image-20241204212652501.png" /></p>
<h3 id="43-position-embedding">4.3 Position embedding<a class="headerlink" href="#43-position-embedding" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-22-1"><span class="c1"># step3 add position embedding</span>
</span><span id="__span-22-2"><span class="n">positon_embedding_table</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">max_num_token</span><span class="p">,</span><span class="n">model_dim</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-22-3"><span class="n">seq_len</span> <span class="o">=</span> <span class="n">token_embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-22-4"><span class="n">positon_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">positon_embedding_table</span><span class="p">[:</span><span class="n">seq_len</span><span class="p">],[</span><span class="n">token_embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span><span id="__span-22-5"><span class="n">token_embedding</span> <span class="o">+=</span> <span class="n">positon_embedding</span>
</span></code></pre></div></td></tr></table></div>
<p>注释：</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-23-1"><span class="c1"># step3 add position embedding</span>
</span><span id="__span-23-2"><span class="c1"># max_num_token = 16</span>
</span><span id="__span-23-3"><span class="c1"># model_dim = 8</span>
</span><span id="__span-23-4"><span class="c1"># positon_embedding_table = 16,8</span>
</span><span id="__span-23-5"><span class="n">positon_embedding_table</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">max_num_token</span><span class="p">,</span><span class="n">model_dim</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-23-6">
</span><span id="__span-23-7"><span class="c1"># token_embedding = 1,5,8 (bs,5个位置(1个cls token、4个单词),model_dim = 8)</span>
</span><span id="__span-23-8"><span class="c1"># seq_len = 5</span>
</span><span id="__span-23-9"><span class="n">seq_len</span> <span class="o">=</span> <span class="n">token_embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-23-10">
</span><span id="__span-23-11"><span class="n">positon_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">positon_embedding_table</span><span class="p">[:</span><span class="n">seq_len</span><span class="p">],[</span><span class="n">token_embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span><span id="__span-23-12"><span class="c1"># positon_embedding_table[:seq_len] = positon_embedding_table[:5] 取前5个8维</span>
</span><span id="__span-23-13"><span class="c1"># [:5] 表示 对 第一维 索引</span>
</span><span id="__span-23-14"><span class="c1"># positon_embedding_table[:seq_len] = 5,8</span>
</span><span id="__span-23-15"><span class="c1"># [token_embedding.shape[0],1,1] = [1,1,1]</span>
</span><span id="__span-23-16"><span class="c1"># positon_embedding = 1,5,8</span>
</span><span id="__span-23-17"><span class="n">token_embedding</span> <span class="o">+=</span> <span class="n">positon_embedding</span>
</span><span id="__span-23-18"><span class="c1"># token_embedding = 1,5,8</span>
</span></code></pre></div></td></tr></table></div>
<p>接下来 我们还需要增加position embedding</p>
<p>文章中 作者对比了很多种position emebedding，效果都差不多，最终采用的是一个 随机的 可学习的 emebedding</p>
<p>首先 定义一个 embedding table，关于 embedding table，之前讲过很多次，首先table的形状，是单词的数目×嵌入的维度；位置的数目×模型维度，所以我们还需要定义一个量 max_num_token,就是token的最大数目 max_num_token=16,同样设置 requires grad=True 是一个可训练的</p>
<p><img alt="image-20241204213510635" src="../images/image-20241204213510635.png" /></p>
<p>在设置好了 position embedding table以后，可以将table取出来，table取出来，就可以依赖于序列的长度，所以首先 我们得到sequence length,应该就是得到token embedding</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-24-1"><span class="n">seq_len</span> <span class="o">=</span> <span class="n">token_embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
<p>其实在图像中，同一个数据集，图像大小一般是固定的，就是说一般是相同的，就说在图像中，所以对于mask比nlp中 就会少一点；但今天还是不讲mask了，今天忽略mask。</p>
<p>首先得到sequence length，就可以根据sequence length，从position embedding table中取出位置编码，取出前sequence length个，取出来以后 还是一个二维的张量，我们还需要对其进行一个复制，复制成一个三维的，主要还是复制成 batch size这个数目, 就是token_embedding.shape[0],复制这么多份，因为这里是batch这个格式，那后面这个位置 或者说通道 都不用复制，这样得到 position embedding，</p>
<p><img alt="image-20241204213832840" src="../images/image-20241204213832840.png" /></p>
<p>最后position embedding 再和 token embedding相加；</p>
<p><img alt="image-20241204213902130" src="../images/image-20241204213902130.png" /></p>
<p>这样实现了position embedding加入到token embedding之中，完成了第三步</p>
<h3 id="44-transformer-encoder">4.4  Transformer Encoder<a class="headerlink" href="#44-transformer-encoder" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-25-1"><span class="c1"># step4 Pass embedding to Transformer Encoder</span>
</span><span id="__span-25-2"><span class="c1"># d_model = model_dim = 8</span>
</span><span id="__span-25-3"><span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">model_dim</span><span class="p">,</span><span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</span><span id="__span-25-4"><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</span><span id="__span-25-5"><span class="c1"># token_embedding = 1,5,8(可以理解为 5个词，每个词 嵌入 8个维度)</span>
</span><span id="__span-25-6"><span class="n">encoder_output</span> <span class="o">=</span> <span class="n">transformer_encoder</span><span class="p">(</span><span class="n">token_embedding</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>接下来 第四步，按照论文中的图，第四步比较简单了，直接将embedding送到transformer encoder，这部分比较简单</p>
<p><img alt="image-20241204215231425" src="../images/image-20241204215231425.png" /></p>
<p>我们需要来看一下 pytorch的transformer encoder的api</p>
<p><img alt="image-20241204215311458" src="../images/image-20241204215311458.png" /></p>
<p>，而不去写 一个具体的代码</p>
<p><img alt="image-20241204215332462" src="../images/image-20241204215332462.png" /></p>
<p>这里pytorch已经把transformer 完整的实现了分为encoder、decoder、encoderLayer、decoderLayer之类的；我们可以看到例子</p>
<p><img alt="image-20241204215515783" src="../images/image-20241204215515783.png" /></p>
<p>首先 实例化一个 encoderLayer,encoderLayer实际上就是MHA+FFN构成的；然后再把layer这个对象，送到 encoder中，并且定义好 num_layers,得到encoder对象；</p>
<p>第四步 把 embedding送入到 transformer中，</p>
<p>复制例子，把d_model=512改成 d_model=model_dim</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-26-1"><span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">model_dim</span><span class="p">,</span><span class="n">n_head</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>把 encoder layer送入到 encoder中，实例化一个 nn.TransformerEncoder,都仿照例子，第一个参数是encoder_layer,第二个参数是 num_layers,这样就得到了 transformer_encoder</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-27-1"><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>transformer_encoder直接以 token_embedding作为输入就好了,忽略 mask,得到 encoder output</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-28-1"><span class="n">encoder_output</span> <span class="o">=</span> <span class="n">transformer_encoder</span><span class="p">(</span><span class="n">token_embedding</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="45-classification-head">4.5 classification head<a class="headerlink" href="#45-classification-head" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-29-1"><span class="c1"># step5 do classification</span>
</span><span id="__span-29-2"><span class="n">cls_token_output</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,:]</span>
</span><span id="__span-29-3"><span class="n">linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model_dim</span><span class="p">,</span><span class="n">num_classes</span><span class="p">)</span>
</span><span id="__span-29-4"><span class="n">logits</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="p">(</span><span class="n">cls_token_output</span><span class="p">)</span>
</span><span id="__span-29-5"><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="__span-29-6"><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span><span class="n">label</span><span class="p">)</span>
</span><span id="__span-29-7"><span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>第五步，</p>
<p><img alt="image-20241204220113749" src="../images/image-20241204220113749.png" /></p>
<p>取出 class token这个位置上的 特征输出，然后把它映射到类别上面，得到概率分布，跟标签 计算 交叉熵，进行模型的 训练</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-30-1"><span class="c1"># step5 do classification</span>
</span></code></pre></div></td></tr></table></div>
<p>首先 将第一个位置的 状态 取出来，定义 cls_token_output,因为 encoder output是 三维的，那么 第一维是batch size不用管；第二维是位置 写个0，表示第一个；第三维是 通道数目 也不用管</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-31-1"><span class="n">cls_token_output</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,:]</span>
</span></code></pre></div></td></tr></table></div>
<p>这样得到了 第一个位置上 的 encoder 的输出；我们将其 映射到类别上；所以 我们需要 再定义一个 常量 叫num_classes，这是类别数目</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-32-1"><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
</span></code></pre></div></td></tr></table></div>
<p>再实例化 一个nn.Linear()层，也就是pytorch中的nn.Linear()层，输入的通道数 是 model_dim,因为 transformer的输出就是 model_dim  就是大小，输出的特征数 就是 num_classes;这是为了 分类之前 对 encoder output 做一个 映射，得到 linear_layer</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-33-1"><span class="n">linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model_dim</span><span class="p">,</span><span class="n">num_classes</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>然后这个 linear_layer进行 调用一下，以class token output 作为输入，这样得到 logits，</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-34-1"><span class="n">logits</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="p">(</span><span class="n">cls_token_output</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>logits是没有过softmax的，接下来 因为 在 loss function中是会调用softmax的</p>
<p>现在 我们实例化一个 loss function，nn.CrossEntropyLoss()这个函数用得比较多 不用查了</p>
<div class="language-text highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-35-1"> loss_fn = nn.CrossEntropyLoss()
</span></code></pre></div></td></tr></table></div>
<p>当然 这个 loss_fn，是以logits和Label作为 输入</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-36-1"><span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span><span class="n">label</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>得到loss</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-37-1"><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span><span class="n">label</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>接下来 定义  Label 这个标签，Label 是一个整型的标签，torch.randint()生成0——10以内的张量，大小是 batch size这个维度，这样 我们生成了Label</p>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-38-1"><span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,(</span><span class="n">bs</span><span class="p">,))</span>
</span></code></pre></div></td></tr></table></div>
<p>这样 我们 生成了 label，我们把 label，传入到loss function中，计算 loss，最后打印loss，接下来 测试</p>
<h2 id="_1">总结<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-39-1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-39-2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-39-3"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span id="__span-39-4">
</span><span id="__span-39-5"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">):</span>
</span><span id="__span-39-6">    <span class="c1"># image shape:bs  × channel × height × width</span>
</span><span id="__span-39-7">    <span class="n">patch</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-39-8">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">patch</span> <span class="o">@</span> <span class="n">weight</span>
</span><span id="__span-39-9">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-39-10"><span class="k">def</span><span class="w"> </span><span class="nf">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="p">):</span>
</span><span id="__span-39-11">    <span class="n">conv_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span> <span class="c1"># bs*oc*oh*ow</span>
</span><span id="__span-39-12">    <span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="p">,</span><span class="n">ow</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-39-13">    <span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">conv_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="n">oh</span><span class="o">*</span><span class="n">ow</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-39-14">
</span><span id="__span-39-15">    <span class="k">return</span> <span class="n">patch_embedding</span>
</span><span id="__span-39-16">
</span><span id="__span-39-17"><span class="c1"># test code for image2emb</span>
</span><span id="__span-39-18"><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span>
</span><span id="__span-39-19"><span class="n">patch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-39-20"><span class="n">model_dim</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-39-21"><span class="n">max_num_token</span> <span class="o">=</span> <span class="mi">16</span>
</span><span id="__span-39-22"><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
</span><span id="__span-39-23"><span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,(</span><span class="n">bs</span><span class="p">,))</span>
</span><span id="__span-39-24">
</span><span id="__span-39-25"><span class="n">patch_depth</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">*</span> <span class="n">ic</span>
</span><span id="__span-39-26"><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">image_h</span><span class="p">,</span><span class="n">image_w</span><span class="p">)</span>
</span><span id="__span-39-27"><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">patch_depth</span><span class="p">,</span><span class="n">model_dim</span><span class="p">)</span> <span class="c1"># model_dim是输出通道数目，patch depth是卷积核的面积乘以输入通道数</span>
</span><span id="__span-39-28">
</span><span id="__span-39-29"><span class="n">patch_embedding_naive</span> <span class="o">=</span> <span class="n">image2emb_navie</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">weight</span><span class="p">)</span>  <span class="c1"># 分块方法得到embedding</span>
</span><span id="__span-39-30"><span class="n">kernel</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">patch_size</span><span class="p">,</span><span class="n">patch_size</span><span class="p">))</span>   <span class="c1"># oc*ic*kh*kw</span>
</span><span id="__span-39-31">
</span><span id="__span-39-32"><span class="n">patch_embedding_conv</span> <span class="o">=</span> <span class="n">image2emb_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">patch_size</span><span class="p">)</span> <span class="c1"># 二维卷积方法得到embedding</span>
</span><span id="__span-39-33">
</span><span id="__span-39-34"><span class="c1"># print(patch_embedding_naive)</span>
</span><span id="__span-39-35"><span class="c1"># print(patch_embedding_conv)</span>
</span><span id="__span-39-36">
</span><span id="__span-39-37"><span class="c1"># step2 prepend CLS token embedding</span>
</span><span id="__span-39-38"><span class="n">cls_token_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">model_dim</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-39-39"><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">cls_token_embedding</span><span class="p">,</span><span class="n">patch_embedding_conv</span><span class="p">],</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-39-40">
</span><span id="__span-39-41"><span class="c1"># step3 add position embedding</span>
</span><span id="__span-39-42"><span class="n">positon_embedding_table</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">max_num_token</span><span class="p">,</span><span class="n">model_dim</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-39-43"><span class="n">seq_len</span> <span class="o">=</span> <span class="n">token_embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-39-44"><span class="n">positon_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">positon_embedding_table</span><span class="p">[:</span><span class="n">seq_len</span><span class="p">],[</span><span class="n">token_embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span><span id="__span-39-45"><span class="n">token_embedding</span> <span class="o">+=</span> <span class="n">positon_embedding</span>
</span><span id="__span-39-46">
</span><span id="__span-39-47"><span class="c1"># step4 Pass embedding to Transformer Encoder</span>
</span><span id="__span-39-48"><span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">model_dim</span><span class="p">,</span><span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</span><span id="__span-39-49"><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</span><span id="__span-39-50"><span class="n">encoder_output</span> <span class="o">=</span> <span class="n">transformer_encoder</span><span class="p">(</span><span class="n">token_embedding</span><span class="p">)</span>
</span><span id="__span-39-51">
</span><span id="__span-39-52"><span class="c1"># step5 do classification</span>
</span><span id="__span-39-53"><span class="n">cls_token_output</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,:]</span>
</span><span id="__span-39-54"><span class="n">linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model_dim</span><span class="p">,</span><span class="n">num_classes</span><span class="p">)</span>
</span><span id="__span-39-55"><span class="n">logits</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="p">(</span><span class="n">cls_token_output</span><span class="p">)</span>
</span><span id="__span-39-56"><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="__span-39-57"><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span><span class="n">label</span><span class="p">)</span>
</span><span id="__span-39-58"><span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>以上实现了 整个 vit，从输入 到 loss，全部实现了；其中image2embedding的过程用两种方式实现了</p>
<p>这两种方式，是在 开始的时候 展开，还是在 卷积过后 再展开，两个不同的角度；</p>
<p>然后需要在序列之前 加入cls token；</p>
<p>第三步 对token embedding 加入 position embedding；按照论文的意思就是增加一个 可训练的embedding</p>
<p>第四步 将 embedding传入到encoder中</p>
<p>第五步 就是class token 那个位置上的output，做一个变换，得到 要分类的概率分布，最后通过 交叉熵，来算出 分类 loss；</p>
<p>总体上就是 这样的过程；所以vit模型 不管是 模型上 还是 代码实现 上 都比较简单；想法也很简单 但是，训练成本很高，需要很多 图片数据 进行预训练，才能取得 跟CNN一样的效果；之后也有很多工作 将 transformer应用到 检测、分割领域 ；现在 只是 讲了 识别的领域；vit作者也提到了 目前只是用到了 识别领域，后面比较火的 swintransformer，一方面降低vit模型的计算量，另一方面 vit更加模仿了CNN的结构，来去 不断对 patch 这个维度 进行降维，然后也会对patch 的 weight 进行变动，swintransformer不仅在 图像识别上，在检测上 在 分割上 都取得了 比较好的效果。</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="2024年12月4日 14:16:24"><span class="timeago" datetime="2024-12-04T14:16:24+00:00" locale="zh"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="2024年12月4日 14:16:24">2024-12-04</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="2024年11月15日 11:19:11"><span class="timeago" datetime="2024-11-15T11:19:11+00:00" locale="zh"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="2024年11月15日 11:19:11">2024-11-15</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["toc.follow", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../js/timeago.min.js"></script>
      
        <script src="../../js/timeago_mkdocs_material.js"></script>
      
        <script src="../../mkdocs/javascripts/katex.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>