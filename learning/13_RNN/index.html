
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mydomain.org/mysite/learning/13_RNN/">
      
      
        <link rel="prev" href="../12_KLdivergence/">
      
      
        <link rel="next" href="../14_LSTM/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>RNN - 溶err</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/timeago.css">
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css">
    
      <link rel="stylesheet" href="../../mkdocs/css/no-footer.css">
    
      <link rel="stylesheet" href="../../mkdocs/css/unordered-list-symbols.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#rnn" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="溶err" class="md-header__button md-logo" aria-label="溶err" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            溶err
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              RNN
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="light-blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../sticks/mkdocs_learn/" class="md-tabs__link">
          
  
    
  
  便签

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../bagu/questions/1_questions/" class="md-tabs__link">
          
  
    
  
  面试

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../Error/github/" class="md-tabs__link">
          
  
    
  
  捉个虫

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../0_pdfNotes/" class="md-tabs__link">
          
  
    
  
  笔记

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../literature/" class="md-tabs__link">
          
  
    
  
  文献

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../Reproduction/" class="md-tabs__link">
          
  
    
  
  复现&代码

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../Statistics/" class="md-tabs__link">
          
  
    
  
  统计学

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../logs/" class="md-tabs__link">
          
  
    
  
  杂

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="溶err" class="md-nav__button md-logo" aria-label="溶err" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    溶err
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    便签
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            便签
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/mkdocs_learn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MkDocs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/markdwon_learn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    markdown
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/latex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LaTex
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/GitHub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GitHub
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/MacOS/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MacOS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/shell/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shell
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/linux/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linux
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/screen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    screen
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/writting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    写作
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/1_github_v1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    github v1.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/2_python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sticks/3_vscode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VSCode
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    面试
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            面试
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    题目
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            题目
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/questions/1_questions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面试问题
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../bagu/leetcode/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    力扣
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            力扣
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/leetcode/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1 两数之和
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/leetcode/2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2 两数相加
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../bagu/deeplearning/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    深度学习
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            深度学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手撕Transformer代码
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/former1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/former2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/pytorch_shape_function/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pytorch的维度变换函数
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/deeplearning/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    visionTransformer代码
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    机器学习
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            机器学习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/machinelearning/kmeans/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手撕kmeans
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bagu/machinelearning/2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手撕反向传播
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    捉个虫
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            捉个虫
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/github/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    github
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/latex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latex
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/macos/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    macOS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Error/docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    docker
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    笔记
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../0_pdfNotes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    📒
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_ViT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ViT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CLIP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2_MOCO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MOCO
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图解LayerNorm &amp; BatchNorm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5种归一化方法
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vision Transformer的原理与难点源码实现
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../swintransformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SwinTransformer 学习笔记
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4种位置编码
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../convs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    卷积
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    李沐 目标检测部分
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4_GAN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GAN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5_Bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BERT从零详细解读
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6_Diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6_Diffusion1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VDM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7_Clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    空
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../8_WeightNorm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    WeightNorm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9_cGAN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GAN 变体
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10_ResNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    项目实战：ResNet果蔬分类
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_excelcsvtensor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础：excel\csv文件→tensor
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12_KLdivergence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KL divergence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    RNN
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    RNN
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#k1" class="md-nav__link">
    <span class="md-ellipsis">
      k1 记忆单元分类
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k2" class="md-nav__link">
    <span class="md-ellipsis">
      k2 模型的分类
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k3" class="md-nav__link">
    <span class="md-ellipsis">
      k3 语音识别模型性能比较
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k4" class="md-nav__link">
    <span class="md-ellipsis">
      k4 循环神经网络的优缺点
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k5-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      k5 RNN 的应用场景
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k6-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      k6 RNN框图
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchnnrnn" class="md-nav__link">
    <span class="md-ellipsis">
      torch.nn.RNN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      代码示例
    </span>
  </a>
  
    <nav class="md-nav" aria-label="代码示例">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      1 单层单向 RNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      2 双向、单层RNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-rnn-api" class="md-nav__link">
    <span class="md-ellipsis">
      3 RNN api 代码汇总
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-rnnrnn" class="md-nav__link">
    <span class="md-ellipsis">
      4 单向RNN&amp;双向RNN 从矩阵运算的角度实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchtile" class="md-nav__link">
    <span class="md-ellipsis">
      torch.tile函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5 验证
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5 验证">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn_1" class="md-nav__link">
    <span class="md-ellipsis">
      自定义 RNN代码
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      6 验证双向RNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6 验证双向RNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn_2" class="md-nav__link">
    <span class="md-ellipsis">
      自定义双向 RNN代码
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      汇总所有代码
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14_LSTM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LSTM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_ContrastiveLearning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对比学习
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16_YOLO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    YOLO
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17_DETR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DETR
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18_DINO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DINO
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19_GPT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20_distill/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    知识蒸馏
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21_FastRCNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    21 FastRCNN
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    文献
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            文献
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/TSP/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    时间序列预测
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            时间序列预测
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/0_note/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NOTE
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/1_SegRNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023、SegRNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/2_DLinear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2022、DLinear
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/3_TimesNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023、TimesNet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/4_Informer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2021、 Informer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/TSP/5_Autoformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2021、Autoformer
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/ObejectCounting/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    目标计数
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            目标计数
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank1%20CountGD/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank1 CountGD
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank2%20GeCo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank2 GeCo
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank3%20DAVE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank3 DAVE
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank4%20CACViT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank4 CACViT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank5%20SSD/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank5 SSD
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank6%20LOCA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank6 LOCA
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank7%20SemAug_CountTR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank7 SemAug CountTR
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank8%20CounTR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank8 CounTR
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank9%20SemAug_SAFECount/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank9 SemAug SAFECount
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank10%20SPDCN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank10 SPDCN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank11%20GCA_SUN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank11 GCA SUN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank12%20SAFECount/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank12 SAFECount
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank13%20BMNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank13 BMNet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank14%20LaoNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank14 LaoNet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank15%20CounTX/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank15 CounTX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank16%20Counting_DETR/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank16 Counting DETR
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank17%20RCC/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank17 RCC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank18%20Omnicount/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank18 Omnicount
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObejectCounting/rank19%20FamNet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rank19 FamNet
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/ObjectDetection/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    目标检测
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            目标检测
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObjectDetection/2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    目标检测基础知识
    
  </span>
  

      </a>
    </li>
  

              
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObjectDetection/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DETR论文系列
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObjectDetection/3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    （DETR）End-to-End Object Detection with Transformer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/ObjectDetection/4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../literature/MultiModal/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    多模态
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            多模态
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../literature/MultiModal/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../Reproduction/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    复现&代码
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            复现&代码
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/7_summary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    汇总复现调用图
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/DAVE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DAVE复现
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/5_SegRNN_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SegRNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/5_SegRNN_v1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    复现SegRNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/5_SegRNN_v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    （补充）复现 SegRNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/5_SegRNN_v3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (手写笔记)SegRNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/6_AutoFormer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autoformer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/6_AutoFormer_v1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (续) Autoformer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../Reproduction/CodeRepo/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    一些代码
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_10" id="__nav_6_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_10">
            <span class="md-nav__icon md-icon"></span>
            一些代码
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一些模块
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    特征融合方式
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一些感悟
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    预训练权重
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/CodeRepo/1_MultiHeadAttention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    多头注意力机制形状变化
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Reproduction/CodeRepo/2_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从现实生活的角度看 Transformer
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../Statistics/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    统计学
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7" id="__nav_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            统计学
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Statistics/1_FFT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fourier级数
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Statistics/2_FFT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fourier基础知识
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Statistics/1_0_fourier/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    复平面旋转&amp;DFT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Statistics/1_1_fourier/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    直观理解傅里叶变换
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Statistics/1_2_signal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    信号的合成与分解
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../logs/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    杂
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_8" id="__nav_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            杂
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../logs/diary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    乐观 &amp; 坚强
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../logs/1_date/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一些日期
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#k1" class="md-nav__link">
    <span class="md-ellipsis">
      k1 记忆单元分类
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k2" class="md-nav__link">
    <span class="md-ellipsis">
      k2 模型的分类
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k3" class="md-nav__link">
    <span class="md-ellipsis">
      k3 语音识别模型性能比较
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k4" class="md-nav__link">
    <span class="md-ellipsis">
      k4 循环神经网络的优缺点
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k5-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      k5 RNN 的应用场景
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k6-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      k6 RNN框图
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchnnrnn" class="md-nav__link">
    <span class="md-ellipsis">
      torch.nn.RNN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      代码示例
    </span>
  </a>
  
    <nav class="md-nav" aria-label="代码示例">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      1 单层单向 RNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      2 双向、单层RNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-rnn-api" class="md-nav__link">
    <span class="md-ellipsis">
      3 RNN api 代码汇总
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-rnnrnn" class="md-nav__link">
    <span class="md-ellipsis">
      4 单向RNN&amp;双向RNN 从矩阵运算的角度实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchtile" class="md-nav__link">
    <span class="md-ellipsis">
      torch.tile函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5 验证
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5 验证">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn_1" class="md-nav__link">
    <span class="md-ellipsis">
      自定义 RNN代码
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      6 验证双向RNN
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6 验证双向RNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn_2" class="md-nav__link">
    <span class="md-ellipsis">
      自定义双向 RNN代码
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      汇总所有代码
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="rnn">RNN<a class="headerlink" href="#rnn" title="Permanent link">&para;</a></h1>
<p>ref：<a href="https://www.bilibili.com/video/BV13i4y1R7jB/?share_source=copy_web&amp;vd_source=5cbbeafd6fa2338b041c25f100ea6483">【29、PyTorch RNN的原理及其手写复现】</a></p>
<p><img alt="image-20241220115043569" src="../images/image-20241220115043569.png" /></p>
<p>topic：</p>
<p>（1）不同类型的RNN的图示以及应用场景的图示</p>
<p>（2）介绍pytorch中RNN的api的使用</p>
<p>（3）通过代码验证 RNN 内部是如何计算的，通过代码来 验证 pytorch的RNN的api 并对比结果</p>
<h2 id="k1">k1 记忆单元分类<a class="headerlink" href="#k1" title="Permanent link">&para;</a></h2>
<p><img alt="image-20241220115210956" src="../images/image-20241220115210956.png" /></p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 什么是记忆单元？</li>
</ul>
<p>记忆单元就是 存储的 过去的历史信息</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 什么是循环神经网络？</li>
</ul>
<p>所谓循环神经网络 就是说，在对序列进行建模的时候，在算每一时刻的表征的时候，一般考虑过去的 历史信息。这个历史信息 就是通过 记忆单元 保存的。然后每个时刻 我们都会从 记忆单元中 获取 过去的 历史信息，然后辅助当前时刻 做预测。</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 记忆单元分类</li>
</ul>
<p>关于记忆单元 一般有三类</p>
<ol>
<li>RNN</li>
<li>LSTM</li>
<li>GRU </li>
</ol>
<blockquote>
<p>一类 比如说 RNN，比如说 Simple RNN，简单的RNN 结构，等下实现的也是 简单的RNN结构</p>
<p>另外两种是 GRU和LSTM，这两种网络的记忆性会更强一点；计算复杂度也会更高一点；使用频率也会更高一点，就是说 现在很多的实际应用中，我们基本使用的是LSTM或者GRU；但是它们都是RNN的一个变体，所以RNN是基础；</p>
</blockquote>
<h2 id="k2">k2 模型的分类<a class="headerlink" href="#k2" title="Permanent link">&para;</a></h2>
<p><img alt="image-20241220115515504" src="../images/image-20241220115515504.png" /></p>
<p>（1）单向循环</p>
<blockquote>
<p>循环神经网络也可分为单向循环，所谓单向循环就是，当前时刻的预测 只跟 过去有关，从左到右 递归的计算。</p>
</blockquote>
<p>（2）双向循环</p>
<blockquote>
<p>双向循环，双向循环就是说 不只有 从左到右的 也有 从右到左的，就是说有两条链，另外一条链，在计算当前时刻的预测的时候 会考虑 未来信息。</p>
</blockquote>
<p>（3）多个单向 、 多个双向</p>
<blockquote>
<p>这个就是双向循环；那还可以把 多个单向 或者说 多个双向 叠加起来，也就是deep RNN 深度循环神经网络</p>
</blockquote>
<p><img alt="image-20241220115718028" src="../images/image-20241220115718028.png" /></p>
<p>（1）单向的循环神经网络</p>
<p><img alt="image-20241220115802397" src="../images/image-20241220115802397.png" /></p>
<p>可以分为三层：</p>
<ol>
<li>最下面一层是 input layer，也就是输入层；</li>
<li>中间是隐含层；</li>
<li>最后是输出层；</li>
</ol>
<blockquote>
<p>下面的输入层每一个神经元 可以看做 每一个时刻；</p>
<p>也就是说 每一个时刻 不仅跟当前时刻的输入有关，还跟上一时刻的记忆单元有关；</p>
<p>并且在单向循环神经网络 中 始终是 从左到右的；</p>
<p>就是说当前时刻的预测 只跟 过去的记忆单元 有关，跟未来的 是无关的；</p>
</blockquote>
<p>（2）双向的循环神经网络</p>
<p><img alt="image-20241220120003057" src="../images/image-20241220120003057.png" /></p>
<ol>
<li>有两条链</li>
<li>分为4个部分：  <strong>input layer、output layer、forward layer、backward layer</strong></li>
<li><strong>（forward layer）</strong>  forward layer是从左到右的循环 ，意思就是说 在 forward layer的输出中，它的输出不仅跟当前输入有关 也跟过去的记忆单元有关；</li>
<li><strong>（backward layer）</strong>  backward layer当中，它的当前时刻的输出 不仅跟当前时刻的输入有关，还跟未来时刻的记忆单元有关，所以是 从右到左的 递归运算的。</li>
<li>**（将forward和backward结合）**起来有什么好处呢？ 就是说 既能看到过去 又能看到未来</li>
</ol>
<h2 id="k3">k3 语音识别模型性能比较<a class="headerlink" href="#k3" title="Permanent link">&para;</a></h2>
<p><img alt="image-20241220120329113" src="../images/image-20241220120329113.png" /></p>
<blockquote>
<p>这张表格 来自某篇论文，这张表格 很好的 展示了 RNN、LSTM、 双向 单向、MLP、以及是否delay等 在参数数量相等的情况下 在语音识别上的表现；可以看到 第二列 第三列 分别是训练误差和测试误差；
</p>
</blockquote>
<p>通过表格 可以看到 不同的模型在 语音识别 这种 序列建模，序列分类这个任务上的表现</p>
<p><img alt="image-20241220123407253" src="../images/image-20241220123407253.png" /></p>
<p>（1）第一行是MLP，MLP就是简单的DNN 是no window的（什么意思？）</p>
<blockquote>
<p>我们把语音 分成很多帧，比方说一帧是 15毫秒 或者 20毫秒，对于每一帧 提取一个特征 比如说 傅里叶变换 得到一个频谱特征，然后 我们对每一帧 进行单独建模，所谓 no window就是 我们不考虑 周围的帧，只考虑 当前这个15毫秒，然后 我们 把它送入 DNN中，来去 进行一个 预测 分类，这样做的话 它的 训练误差 和测试误差 大概都是在 40% 左右；</p>
</blockquote>
<p><img alt="image-20241220120448060" src="../images/image-20241220120448060.png" /></p>
<p>（2）（10 frame window、stride）</p>
<blockquote>
<p>第二行 MLP 10帧作为一个窗 意思是 我们现在 同样还是MLP，但是 现在MLP的 输入 不仅是 只有一帧的特征，而是把 每10帧 放到一起，那么这里是否有stride，就是说 这10帧 到底有没有交叠 并没有介绍，总之 第二行这个 输入 比 第一行 覆盖的 时间窗口 会更大一点 ；</p>
<p>那么这样可以看到 这个误差，显著的从 46% 降到 32%，这个结果说明 在语音识别 这个序列建模 任务中，当我们把 上下文特征 一起考虑的话 效果会 更好；这是第二行。</p>
</blockquote>
<p><img alt="image-20241220123237089" src="../images/image-20241220123237089.png" /></p>
<p><strong>（3）delay</strong></p>
<p>第三行，将MLP换成了 循环神经网络，一个简单的RNN 模型，并且括号 delay 0，等下会解释 什么叫delay，这里的意思就说，就是说 把 每一帧特征 像 第一幅图一样，比如说</p>
<p><img alt="image-20241220123710787" src="../images/image-20241220123710787.png" /></p>
<p>这里是第一帧的特征，这里是第二帧的特征，这里是第三帧的特征，我们把每一帧的特征 送入到RNN中，通过中间的隐含层 对历史信息 进行更新，这样的网络 错误率也是相比MLP 更进一步，看到训练误差到30%，测试误差是35%，相比于上面 10帧的MLP，效果更好。</p>
<p><strong>（4）LSTM</strong></p>
<p><img alt="image-20241220123805856" src="../images/image-20241220123805856.png" /></p>
<ul>
<li>接下来 如果我们把RNN，替换成LSTM，效果更进一步</li>
<li>都是delay 0</li>
</ul>
<p><strong>（5）LSTM+backwards</strong></p>
<p><img alt="image-20241220123952932" src="../images/image-20241220123952932.png" /></p>
<p>再下面一步，还是LSTM，只是把输入 翻转过来，也就是把input序列倒过来，再输入到网络中，误差是差不多的，所以 仅仅是一条链的话，不论是正向识别，还是反向识别 其实效果是差不多的</p>
<p><strong>（6）RNN delay 3</strong></p>
<p><img alt="image-20241220124429146" src="../images/image-20241220124429146.png" /></p>
<p>对输入进行改造，首先可以看到 同样是用 RNN网络，这里 对它 进行 delay 三帧，然后可以看到 它的效果 相比于原本的 RNN 从30% 降低到 29%，测试误差 也是从 35% 降低到 34%；</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 那么这个 delay 3 帧是什么意思呢？</li>
</ul>
<p><img alt="image-20241220124532087" src="../images/image-20241220124532087.png" /></p>
<p>delay 3 帧的意思就是说，当 喂入 三帧 作为 输入的时候，前面 这三个输出，先不要，</p>
<p>就是说 先拿 三帧输入 送入到网络中 让它先对记忆单元 去 更新三步 ，然后到第四步（帧）的 输入的时候，才 把 输出拿出来， 作为 第一帧的预测值，这个就是delay 3的意思</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 为什么 delay 3 帧效果有效？</li>
</ul>
<p>如果 不做delay的话 ，在 输入 第一帧的 特征的时候，它的预测的输出 只能 看到当前的第一帧，范围就很小；</p>
<p>但是当 delay 三帧的时候 预测第一帧的输出 其实就看到了 三帧，它看到了 第一帧、第二帧、第三帧 都进入了 记忆单元中；</p>
<p>以上就是 delay RNN的结构；</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 再次解释 delay</li>
</ul>
<p>delay 能够在 短暂 的 牺牲 时延的情况下，提高精度，看到更宽的上下文</p>
<blockquote>
<p>有 delay 的话，在预测第一帧的输出的时候 肯定会 稍微 延迟一点，因为 如果 不做 delay的话，我们就直接 算一步就好了，如果delay 三帧的话，那在预测第一帧的输出的时候，需要计算 三步，所以肯定会有 一定时延的。但是这个时延 确实能够 使得 预测的效果更好，因为它看到的上下文 会 更宽一点；以上是delay的意思。</p>
</blockquote>
<p><strong>（7）B</strong> </p>
<p><img alt="image-20241220124913764" src="../images/image-20241220124913764.png" /></p>
<p><strong>双向的LSTM、RNN</strong></p>
<p><img alt="image-20241220124945634" src="../images/image-20241220124945634.png" /></p>
<ul>
<li>RNN delay三帧 和LSTM delay 五帧 效果都有不同程度的增加；</li>
<li>双向的结果比delay 和 单向的 效果都要好；</li>
<li>训练集 错误率从29%降低到24%；</li>
<li>测试集错误率也是明显降低；</li>
</ul>
<p><u>双向、delay</u> </p>
<ul>
<li>表示 看到了未来的信息；</li>
<li>当 delay三帧的话，在预测第一帧的输出的时候 其实是看到了第二帧、第三帧、第四帧  指的是 看到了未来的三帧的</li>
<li>当预测 第二帧的输出的时候 同样 看到第三帧、第四帧、第五帧</li>
<li>
<p>虽然也看到了未来的信息，但看到未来的信息还是不够长；</p>
</li>
<li>
<p>如果把单向 换成双向的网络的话，那么整个未来的特征 和 过去的 特征，网络都能看到，这就是说双向的范围 更大一点；</p>
</li>
</ul>
<blockquote>
<ul>
<li>
<p>单向delay 3：输出第一帧看到的是 输入第一帧、第二帧、第三帧</p>
</li>
<li>
<p>双向delaye 3：输出第一帧，看到的是第一帧、第二帧、第三帧+第四帧、第五帧、第六帧 </p>
</li>
</ul>
</blockquote>
<p><u>双向的缺点</u></p>
<p>需要完全的 把整个输入特征序列 送入到网络中 ，最后才能得到输出</p>
<blockquote>
<p>而单向带时延的情况就不需要把整个特征 都算出来 才能预测第一帧，只要有三帧了，就可以预测第一帧了；</p>
<p>所以单向带时延的，响应速度会更快；</p>
<p>双向的响应速度肯定是最慢的；</p>
<p>所以在速度 和效果上 需要 取得一个比较好的平衡 才能满足具体的业务需求。</p>
</blockquote>
<h2 id="k4">k4 循环神经网络的优缺点<a class="headerlink" href="#k4" title="Permanent link">&para;</a></h2>
<p><strong>一、优点</strong></p>
<blockquote>
<p>（1）权重共享可以处理变长序列</p>
<p>（2）模型的大小 与 序列长度无关</p>
<p>（3）计算量与序列长度呈现线性关系</p>
<p>（4）考虑历史信息</p>
<p>（5）便于流式输出</p>
<p>（6）权重时不变</p>
</blockquote>
<p><strong>二、缺点</strong></p>
<blockquote>
<p>（1）串行计算速度慢</p>
<p>（2）无法获取太长的历史信息</p>
</blockquote>
<p><strong>第一点</strong></p>
<p>优点可以处理变长序列</p>
<blockquote>
<p>这个是DNN和CNN处理不了的，比如DNN，输入的特征是固定的，而CNN的不仅和kernel size有关，还跟输入的通道数有关，所以如果CNN 输入通道数有变化的话 还需要重新搭建一个网络，而RNN 是可以处理变长序列的</p>
</blockquote>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 为什么RNN 能处理变长序列呢？</li>
</ul>
<p><img alt="image-20241220125908343" src="../images/image-20241220125908343.png" /></p>
<p>原因是因为，可以看到图中 有一个w</p>
<blockquote>
<p>也就是 权重，这个w在每个时刻 都是相等的，正是因为 所有的权重，在每一个时刻都是相等的；不论是 输入 跟既有单元的连接，还是历史信息 跟当前的神经元的连接 它的权重都是固定的，正是因为 权重 在每一时刻 共享，所以 RNN 能够处理变长序列；</p>
</blockquote>
<p>一旦去掉了 <u>权重 共享</u> 这个归纳偏置的话，就是说，如果每一时刻 都有一个 不一样的 w的话，这个时候 就不能处理 变长序列了，就类似 position embedding 一样，只要遇到了 长度 比训练集大的，那就处理不了了（也不是，三角变换）；</p>
<p><strong>第二点</strong></p>
<p><img alt="image-20241220130243673" src="../images/image-20241220130243673.png" /></p>
<p>第二点，模型的大小 与 序列长度无关，这里说的是 模型的大小，是说模型的参数数量 与 长度无关，模型的全部参数 和序列长度 都是无关的，只输入特征 和输入通道数 以及RNN的隐含单元有关</p>
<p><strong>第三点</strong></p>
<p><img alt="image-20241220130406832" src="../images/image-20241220130406832.png" /></p>
<p>第三个优点就是 RNN的计算量 跟 序列长度 呈线性增长，类比Transformer，在原本的Transformer中 最大的一个 诟病的地方 就是 计算复杂度 跟序列长度 是呈一个平方关系的，但是在RNN中，计算量 是跟长度 呈现 线性增长的；</p>
<blockquote>
<p>举例子：</p>
<p>当 序列长度 为2的 时候，计算量 可能就是2t</p>
<p>（t指的是时间？模型 固有的计算量）</p>
<p>当序列长度为3 的时候，计算量 就是3t，就不是说 从 4变成9，呈现 平方关系。</p>
<p>在RNN中 呈现 线性关系；这是跟 Transformer 在计算量上 一个明显的区别。</p>
</blockquote>
<p><strong>第四点</strong></p>
<p><img alt="image-20241220130603036" src="../images/image-20241220130603036.png" /></p>
<p>相比DNN而言，RNN是可以考虑到 历史信息的，因为有链式的结构，可以通过隐含层 来积累 历史信息；</p>
<p><strong>第五点</strong></p>
<p><img alt="image-20241220130731325" src="../images/image-20241220130731325.png" /></p>
<p>流式 输出，可以看到：</p>
<p><img alt="image-20241220130819372" src="../images/image-20241220130819372.png" /></p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 流式输出是什么？</li>
</ul>
<p>每 计算一步，都可以得到 一个输出，这个输出 可以直接 送给 用户，这就是 流式 的意思。</p>
<blockquote>
<p>但是对于 Transformer而言的话，由于它是考虑到全局的信息 计算一个 全局的self attention，所以就不能单步 的计算 每一步的 输出，这就是 Transformer的一个缺点，不能直接的 应用到 流式的场景；</p>
<p>但是在循环神经网络中，只要每算一次 递归运算，就可以得到一个输出，这个 输出就可以直接返回给用户，这就是流式的，也就是 不需要 把 整个序列 都算完 才返回给用户，而是说 每算出一个 时刻 都可以返回给用户</p>
</blockquote>
<p><strong>第六点</strong></p>
<p><img alt="image-20241220131059489" src="../images/image-20241220131059489.png" /></p>
<p>权重时不变</p>
<blockquote>
<p>权重是 时不变的，正是因为RNN 权重 时不变，所以RNN 可以处理 变长序列；</p>
</blockquote>
<p><strong>二、缺点</strong></p>
<p><img alt="image-20241220131203763" src="../images/image-20241220131203763.png" /></p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 为什么说 串行计算慢</li>
</ul>
<p>因为 在算 每一时刻的时候 都需要等 上一时刻的历史信息，等上一时刻的算出来 才能算 下一时刻，是一个 串行的过程，比较慢</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 怎么理解 RNN 也是无法获取太长的历史信息</li>
</ul>
<p>也就是说 由于梯度消失的问题，导致RNN无法 从当前时刻 获取很久远的信息</p>
<blockquote>
<p>RNN 由于梯度消失的问题，无法获得太长的历史信息。</p>
<p>这一点正是Transformer的优点。</p>
<p>Transformer的归纳偏置 是比较弱的，是通过一个 全局的self attention，来计算 两两位置之间的一个相关性，所以Transformer是可以上下去捕捉 很长的历史关联性的。</p>
</blockquote>
<h2 id="k5-rnn">k5 RNN 的应用场景<a class="headerlink" href="#k5-rnn" title="Permanent link">&para;</a></h2>
<p><img alt="image-20241220131740414" src="../images/image-20241220131740414.png" /></p>
<p><strong>（1）生成任务</strong></p>
<p>生成任务，比如歌词生成、对联生成、像GPT一样写小说</p>
<p>生成任务，如果用一幅图来表示：</p>
<p><img alt="image-20241220131838603" src="../images/image-20241220131838603.png" /></p>
<p>1、如图表示RNN在诗歌、语音、符号生成中的表示</p>
<p>2、这类任务可以看成one to many的过程，也就是说 只要给了 一个输入，或者一个很短的 输入，RNN就可以利用自己的 递归机制 不断的预测 新的输出，就比如 给出 一两句话，RNN 写出一段话 或者 一篇文章，就是 one to many，RNN在生成任务上的应用</p>
<p><strong>（2）情感分类</strong></p>
<p>RNN也能做情感分类</p>
<blockquote>
<p>比如说很古老的一个情感分类任务，对影评进行分类，判断一句话是正向情感还是负向情感，对于一个情感分类任务，可以看成many to one的任务</p>
</blockquote>
<p><img alt="image-20241220134939061" src="../images/image-20241220134939061.png" /></p>
<p>输入是一段话或者说一篇文章，但是输出 只有一个，只需要对一段话预测一个类别就好了，这个就是many to one的任务，典型的应用场景就是去情感分类</p>
<p><img alt="image-20241220135039924" src="../images/image-20241220135039924.png" /></p>
<p>many to many的任务：</p>
<ul>
<li>词法识别</li>
<li>机器翻译</li>
</ul>
<p>词法识别就是识别当前这个词是名词还是动词，当前这个单词多音字等等</p>
<p>机器翻译，在Transformer中是应用比较多的；</p>
<p>但是这两种 many  to many的模型结构还是有一些区别的，可以看到下面两幅图：</p>
<p>（一）词法识别</p>
<p><img alt="image-20241220135218541" src="../images/image-20241220135218541.png" /></p>
<ul>
<li>
<p>识别一句话中，每个字的拼音是什么，或者识别每个词的词性，这种就是many to many</p>
</li>
<li>
<p>属于直进直出的many to many</p>
</li>
</ul>
<p>（二）机器翻译</p>
<p><img alt="image-20241220135306632" src="../images/image-20241220135306632.png" /></p>
<ul>
<li>sequence to sequence 结构；</li>
<li>有编码器，有解码器，中间依靠注意力机制，来帮助解码器预测每一时刻的输出，也是many to many；</li>
<li>常见的应用场景：机器翻译、语音合成等</li>
</ul>
<p><img alt="image-20241220135405098" src="../images/image-20241220135405098.png" /></p>
<p>语言模型 RNNLM；</p>
<p>总之就是</p>
<ul>
<li>one to one</li>
<li>Many to one</li>
<li>many to many</li>
</ul>
<h2 id="k6-rnn">k6  RNN框图<a class="headerlink" href="#k6-rnn" title="Permanent link">&para;</a></h2>
<p><img alt="image-20241220135618631" src="../images/image-20241220135618631.png" /></p>
<h2 id="torchnnrnn">torch.nn.RNN<a class="headerlink" href="#torchnnrnn" title="Permanent link">&para;</a></h2>
<p><img alt="image-20241220135729914" src="../images/image-20241220135729914.png" /></p>
<ul class="task-list">
<li>
<p>可以用来构造一层 或者多层 简单的RNN结构； </p>
</li>
<li>
<p>RNN还有另外一种结构：激活函数，可以用tanh激活函数 或者 ReLU激活函数，使得RNN有更强的非线性建模能力；</p>
</li>
<li class="task-list-item">
<p><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> RNN 计算公式是什么呢？</p>
</li>
</ul>
<p><img alt="image-20241220135820029" src="../images/image-20241220135820029.png" /></p>
<ul>
<li>
<p>每一时刻的输出，或者说每一时刻的状态</p>
</li>
<li>
<p>在简单RNN中，输出是等于状态的， <span class="arithmatex">\(h_t\)</span>也就是 <span class="arithmatex">\(t\)</span> 时刻的输出；</p>
</li>
<li>
<p>或者说 t 时刻RNN的状态 等于 tanh函数，就是非线性激活函数，里面分别是 <span class="arithmatex">\(W_{ih}×x_t\)</span> 再加上 <span class="arithmatex">\(b_{ih}\)</span>，那么这里的<span class="arithmatex">\(x_t\)</span>，就是当前时刻的输入，然后<span class="arithmatex">\(w_{ih}\)</span>，就是在这个RNN中，它对输入的权重矩阵，就是 会用这个矩阵 来对权重 做一个映射，然后整体上，这个东西 可以看做 linear层，有权重 还有 偏置，<span class="arithmatex">\(b_{ih}\)</span>，就是关于 权重的一个偏置</p>
</li>
<li>
<p>后面 还有一项，跟 历史状态有关的，跟 <span class="arithmatex">\(h_{t-1}\)</span> 有关的</p>
</li>
<li>也就是说，需要将 上一时刻的 输出 或者说 上一时刻的隐含状态 拿过来，然后对它进行一个 映射，用 <span class="arithmatex">\(w_{hh}\)</span> 的权重 来进行相乘，来进行映射，然后再加上一个偏置</li>
<li>总体而言 就是说 每一时刻的输出 或者说 隐含状态 不光跟当前时刻 的 输入 <span class="arithmatex">\(x_t\)</span> 有关，同时也跟上一时刻的记忆单元  <span class="arithmatex">\(h_{t-1}\)</span>有关，并且都是线性组合的关系，最后通过一个非线性激活函数就能得到当前时刻的隐含状态；</li>
</ul>
<p><img alt="image-20241220140258663" src="../images/image-20241220140258663.png" /></p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 解释：</li>
</ul>
<p><span class="arithmatex">\(h_t\)</span> 是 <span class="arithmatex">\(t\)</span>时刻的隐含状态</p>
<p><span class="arithmatex">\(x_t\)</span>是 t 时刻的输入</p>
<p><span class="arithmatex">\(h_{t-1}\)</span>是  <span class="arithmatex">\(t-1\)</span>时刻的隐含状态</p>
<p><span class="arithmatex">\(h_0\)</span> 表示初始时刻的隐含状态</p>
<p>pytorch中也提供了两种 非线性激活函数：tanh和relu激活函数，默认用tanh激活函数</p>
<p><img alt="image-20241220140410079" src="../images/image-20241220140410079.png" /></p>
<ul class="task-list">
<li>这是一个 class</li>
<li>在用RNN时候，首先要 实例化 这个class</li>
<li>实例化 class以后，得到RNN的一个模型</li>
<li>然后 再把 输入 喂入到 模型中，而不直接把 输入 喂入到模型中；</li>
<li>
<p>一般所有模型的 class，都需要 先进行一个实例化，然后才能得到一个layer；</p>
</li>
<li class="task-list-item">
<p><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 实例化RNN所需要的参数</p>
</li>
</ul>
<p><img alt="image-20241220140648773" src="../images/image-20241220140648773.png" /></p>
<ul>
<li>
<p>第一个参数是 <code>input_size</code>,也就是 输入特征的大小，也就是 <code>x</code> 的特征的维度</p>
</li>
<li>
<p>第二个参数是 <code>hidden_size</code>，<code>hidden_size</code>决定了 <span class="arithmatex">\(h_t\)</span>的大小，就是每一时刻的 <span class="arithmatex">\(h_t\)</span>就是一个向量，对于单一样本而言，每一时刻 <span class="arithmatex">\(h_t\)</span>就是一个向量，那么这个向量长度是多少呢？就是由 <code>hidden_size</code> 来决定</p>
</li>
<li>
<p>第三个参数 就是 <code>num_layers</code>，就是说 这个RNN，可以默认实例化的时候 只有一层，但是也可以改变 <code>num_layers</code>的值，变成多层，堆叠起来的结构，之前在介绍的时候也讲过，可以堆叠起来，单向的可以堆叠，双向的 也可 堆叠</p>
</li>
<li>
<p>第四个参数 就是 非线性激活函数，这里默认是<code>tanh</code>函数，也可以改成 <code>ReLu</code>函数</p>
</li>
<li>第五个是<code>bias</code> 一般会加上 这两个bias</li>
<li>第六个参数是 <code>batch first</code>，这个需要注意一下，这个参数就决定了 输入和输出的格式</li>
</ul>
<blockquote>
<ul>
<li>如果设置 <code>batch first=true</code>的话：</li>
</ul>
<p>提供的输入张量 和 输出张量的 格式就是 <code>batch × sequence length×feature</code> 这样的格式</p>
<p>默认是<code>false</code>的，如果是 <code>false</code>的情况下：</p>
<p>需要保证 输入的格式是 <code>sequence length</code>，也就是序列长度 在第一个维度，<code>batch size</code>在第二个维度，<code>feature size</code>在第三个维度</p>
</blockquote>
<ul>
<li>第七个参数 <code>dropout</code></li>
<li>最后一个参数<code>bidirectional</code>，最后一个参数 表示 双向的意思</li>
</ul>
<blockquote>
<p>也就是把这个参数设置为 <code>true</code>的话，就可以构建一个双向的RNN结构；</p>
<p>既然是 双向RNN结构，输出的特征大小就是<code>2×feature size</code>，就是2倍的<code>feature size</code>；</p>
</blockquote>
<p><u>双向结构图</u></p>
<p><img alt="image-20241220141145243" src="../images/image-20241220141145243.png" /></p>
<ul>
<li>
<p>这幅图 就是 双向的，一旦把RNN设置成 双向的话，最终的输出 是由<code>forward输出</code>和<code>backward输出</code>一起拼起来的，所以这个 输出状态是 二倍的 <code>hidden size</code>，可以指定 <code>concat</code>和<code>sum</code>，一般用 <code>concat</code> 更多一点</p>
</li>
<li>
<p>也就是说 如果 设置 <code>hidden size是16</code>的话，那么 <code>output layer</code>大小，就是32，如果是双向的话</p>
</li>
</ul>
<p>以上是RNN实例化的参数讲解；</p>
<ul>
<li>当实例化完以后，就得到了RNN层</li>
<li>然后就可以 提供 输入 和 初始的隐含状态，来去递归的算出 每一时刻的 输入 所对应的输出是什么；</li>
</ul>
<p>当实例化完 一个RNN，就可以 提供 <code>input</code> 和 <span class="arithmatex">\(h_0\)</span>，来给出真正的输入序列：</p>
<p><img alt="image-20241220141454221" src="../images/image-20241220141454221.png" /></p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 解释input</li>
</ul>
<p>输入一般是三维的：</p>
<p><img alt="image-20241220141550442" src="../images/image-20241220141550442.png" /></p>
<p>如果设置的<code>batch size first等于true</code>的话，那对应的输入格式就是 <code>batch size×sequence length×hidden size</code>；</p>
<p>反之 如果<code>没有设置batch size等于true</code>的话，提供的格式就是 <code>sequence length×batch size×hidden size</code></p>
<ul class="task-list">
<li class="task-list-item">
<p><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 解释 <span class="arithmatex">\(h_0\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(h_0\)</span>的格式是 (<span class="arithmatex">\(d×{num\_layers}\)</span>， <span class="arithmatex">\(N\)</span>，<span class="arithmatex">\(H_{out}\)</span> )</p>
</li>
<li>
<p><span class="arithmatex">\(h_0\)</span> 是 初始状态，只有 这一个时刻，所以这里不需要考虑 <code>sequence_length</code> 这个维度</p>
</li>
<li class="task-list-item">
<p><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> 那这里也是 三个维度，为什么呢？</p>
</li>
</ul>
<p>因为  RNN 可以是 多层 也可以是 双向，所以第一个维度 其实就是 是否是 双向  跟 多层 这两个因素 决定的；</p>
<p><code>case1：</code>如果模型是一层，并且是单向的话，那么第一个维度 就是 1 ；</p>
<p><code>case2：</code>如果是 有两层，并且是 单向的话，那么就是 1×2；</p>
<p><code>case3：</code>如果是双向 并且是 两层的话，那就是 2×2=4；</p>
<p>所以这里的 第一个维度 <span class="arithmatex">\(d \times num\_layers\)</span> 由是否双向 以及 层数有关</p>
<p><img alt="image-20241220142609695" src="../images/image-20241220142609695.png" /></p>
<p>第二个维度 <span class="arithmatex">\(N\)</span>，就是 <code>batch size</code>，每个样本 都可以 设置一个 初始状态</p>
<p>第三个维度 <span class="arithmatex">\(H_{out}\)</span> 就是 <code>hidden size</code>的大小，因为 初始状态 就是一个向量,第三维 就是 向量的长度</p>
<h2 id="_1">代码示例<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<h3 id="1-rnn">1 单层单向 RNN<a class="headerlink" href="#1-rnn" title="Permanent link">&para;</a></h3>
<blockquote>
<p>这个RNN 是一个 class</p>
<p>所以，首先实例化一个单向单层的RNN</p>
</blockquote>
<p>step1：import  torch.nn as nn</p>
<p>step2：实例化 nn.RNN</p>
<p>step3：传入 实例化参数；</p>
<blockquote>
<ul>
<li>
<p>input_size=4</p>
</li>
<li>
<p>hidden_size也可以 随便写一个 hidden_size=3 </p>
</li>
<li>
<p>num_layers可以传入1</p>
</li>
<li>batch first设置成true</li>
<li>定义为<code>single_rnn</code></li>
</ul>
</blockquote>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="c1"># 1.单向、单层RNN</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">single_rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p>以上是 单层单向RNN，接下来构建一个输入</p>
<p>输入的维度一般是 <code>batch_size×sequence length×输入特征</code></p>
<p>输入特征就是RNN实例化时的 <code>input size=4，batch size=1，sequence length=2，特征维度=4</code></p>
<p>以上构建好了input序列，分别是： <code>batch_size × sequence length×输入特征</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> 
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="c1"># batch_size*sequence_length*feature_size</span>
</span></code></pre></div>
<p>把这个<code>input</code>作为 <code>single_rnn</code>的输入；</p>
<p>也可以不传入<span class="arithmatex">\(h_0\)</span>,它默认以<span class="arithmatex">\(0\)</span>向量填充</p>
<p><img alt="image-20241220143813357" src="../images/image-20241220143813357.png" /></p>
<p>同时也可以看看 官网 api 输出是什么</p>
<p><img alt="image-20241220143851387" src="../images/image-20241220143851387.png" /></p>
<p>输出是两个值，一个是整个的，所有时刻的输出；</p>
<p>另外一个输出的量就是最后一个时刻的状态，要定义变量接收输出</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">output</span><span class="p">,</span><span class="n">h_n</span> <span class="o">=</span> <span class="n">single_rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</span></code></pre></div>
<p>这样整个输出就算完了，接下来看一下<span class="arithmatex">\(output\)</span>和 <span class="arithmatex">\(h_n\)</span></p>
<p><img alt="image-20241220144015618" src="../images/image-20241220144015618.png" /></p>
<p>代码解读：</p>
<p>（1） <code>input</code>的形状 <code>1×2×4 = batch size×sequence length×feature dim</code></p>
<p>（2）<code>single_rnn</code> 的参数含义：<code>4,3,1=input_size,hidden_size;num_layers</code></p>
<p>（3）<code>output</code>大小就是 <code>1×2×3</code></p>
<ul>
<li>1表示 batch size，输入batch size=1，输出 batch size也是1，没有改变</li>
<li>2是 sequence length，序列长度，我们喂入的输入长度是2，所以输出的长度也是2</li>
<li>3，第三个维度为什么是3呢？因为我们设置的hidden size=3，也就是说 每个输出的状态向量 长度是3</li>
</ul>
<p>（4）<span class="arithmatex">\(h_n\)</span>： 最后一个时刻的隐含状态，在简单RNN中，最后一个时刻的隐含状态等于最后时刻的输出的，output最后一行的值 等于 <span class="arithmatex">\(h_n\)</span></p>
<p><img alt="image-20241221102700631" src="../images/image-20241221102700631.png" /></p>
<h3 id="2-rnn">2 双向、单层RNN<a class="headerlink" href="#2-rnn" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">single_rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<ul>
<li>
<p>input size不变</p>
</li>
<li>
<p>hidden size不变</p>
</li>
<li>num_layers不变</li>
<li>batch first也不变</li>
<li>但是需要新增一个参数，叫做：</li>
</ul>
<p><img alt="image-20241221103009943" src="../images/image-20241221103009943.png" /></p>
<p>：bidirectional，这个参数默认是false，把它置成true</p>
<p>然后命名为 bidirectional_rnn：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="n">bidirectional_rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p>以上是实例化的双向RNN</p>
<ul>
<li>输入特征大小是4</li>
<li>输出 or 隐含层大小是3</li>
<li>只有一层</li>
<li>batch first=true</li>
<li>并且还是双向的</li>
</ul>
<p>同样把上面的输入 送入双向RNN中，以<code>input</code>作为输入<code>bidirectional_rnn(input)</code>，因为无论双向、单向，输出都是一样的，都是<code>output</code> 和 <code>h_n</code>，表示区别加前缀<code>bi</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="n">bi_output</span><span class="p">,</span><span class="n">bi_h_n</span> <span class="o">=</span> <span class="n">bidirectional_rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</span></code></pre></div>
<p>首先 打印 output的形状</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="n">bi_output</span><span class="o">.</span><span class="n">shape</span>
</span></code></pre></div>
<p><img alt="image-20241221103251339" src="../images/image-20241221103251339.png" /></p>
<p>还有h_n的形状：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="n">bi_h_n</span><span class="o">.</span><span class="n">shape</span>
</span></code></pre></div>
<p><img alt="image-20241221103335046" src="../images/image-20241221103335046.png" /></p>
<p>对比，把单向单层RNN的output的形状，h_n的形状，都打印出来：</p>
<p><img alt="image-20241221103356696" src="../images/image-20241221103356696.png" /></p>
<ul>
<li>首先从输出上来讲：</li>
</ul>
<p>（1）单向的输出大小是 1×2×3的</p>
<p>（2）双向的话变成了 1×2×6（一个batch size；2个sequence length；6个特征维度）</p>
<blockquote>
<p>这是为什么呢？</p>
<p>这是因为在双向RNN中最后是把<code>forward layer</code>和<code>backward layer</code>两个输出拼起来，所以特征大小变成了两倍的<code>hidden size</code>；</p>
</blockquote>
<ul>
<li>最后一个时刻的状态也是不一样的</li>
</ul>
<p>（1）在双向RNN中，它的维度是 2×1×3（前向的输出是个 1×3，后向的输出也是一个1×3）</p>
<p>（2）在单向中，维度是1×1×3</p>
<blockquote>
<p>为什么呢？</p>
<p>因为双向中，其实是有两个层的最后一个时刻状态，有一个<code>forward layer</code>和一个<code>backward layer，</code>这两个状态在第一个维度上拼起来了，但是在单向中，只有一层的最后一个状态；</p>
</blockquote>
<h3 id="3-rnn-api">3 RNN api 代码汇总<a class="headerlink" href="#3-rnn-api" title="Permanent link">&para;</a></h3>
<p><img alt="image-20241221103816446" src="../images/image-20241221103816446.png" /></p>
<p><img alt="image-20241221103830961" src="../images/image-20241221103830961.png" /></p>
<h3 id="4-rnnrnn">4 单向RNN&amp;双向RNN 从矩阵运算的角度实现<a class="headerlink" href="#4-rnnrnn" title="Permanent link">&para;</a></h3>
<p>注意：以下演示中，没有设置多层， num layers都定义的1层</p>
<p>（1）引入库，可以使用常见的pytorch函数</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span>
</span></code></pre></div>
<p>（2）定义常量</p>
<p>然后定义一些常量，比如batch size、序列长度</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="n">bs</span><span class="p">,</span><span class="n">T</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span><span class="mi">3</span>  <span class="c1">#批大小 和 序列长度</span>
</span></code></pre></div>
<p>还需要定义 input size和hidden size，分别表示输入特征大小 和 隐含层 特征大小</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="n">input_size</span><span class="p">,</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span> <span class="c1">#输入特征大小，隐含层特征大小</span>
</span></code></pre></div>
<p>有一个问题：怎么理解 时序模型中的 batchsize？</p>
<p>（3）生成 input</p>
<p>有了这些量以后，生成一个  input ，还是考虑batch first等于true的情况：第一个位置写batch size、第二个位置写序列长度、第三个位置写feature dim，也就是 input size</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">input_size</span><span class="p">)</span> <span class="c1"># 随机初始化一个输入特征序列</span>
</span></code></pre></div>
<p>（4）初始化隐状态</p>
<p>初始化一个初始的隐含状态 <code>h_0</code>，初始的隐含状态一般是一个向量，如果考虑了<code>batch size</code>，就应该是 <code>batch size</code>个这样的状态，也可以先写成0：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="n">h_prev</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">)</span>  <span class="c1"># 每一个状态向量大小是 hidden size</span>
</span></code></pre></div>
<p>也就是在第一个时刻的时候，需要一个初始的隐含状态来，来作为第0时刻的初始状态</p>
<p><img alt="image-20241221134624116" src="../images/image-20241221134624116.png" /></p>
<p>（5）调用pytorch RNN的API</p>
<p>还是用<code>nn.RNN()</code>的api，需要传入<code>input_size</code>，<code>hidden size</code>还有<code>batch first=True</code>，这样我们得到一个rnn</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">,</span><span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p>（6）传入参数</p>
<p>需要把 input 以及初始状态也传入RNN中，但是需要注意的是，api中初始状态是三维的</p>
<p><img alt="image-20241221134803507" src="../images/image-20241221134803507.png" /></p>
<p>刚刚初始化的是 后面两维，第三维 我们没有初始化，因为这里是单向的 并且 只有一层的，所以对它扩一维就好了，扩0维，得到rnn output和h_finall，最后一个时刻的状态，或者叫state_finall</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="n">rnn_output</span><span class="p">,</span><span class="n">state_finall</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">h_prev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></code></pre></div>
<p>这个是调用pytorch 官方的api，运行打印，看结果</p>
<p><img alt="image-20241221134949743" src="../images/image-20241221134949743.png" /></p>
<p>（7）手写RNN forward 函数</p>
<p>定义<code>RNN forward</code>函数，实现RNN计算原理 <code>def rnn_forward():</code>，对于这个函数 首先要传入参数：</p>
<p><img alt="image-20241221135123756" src="../images/image-20241221135123756.png" /></p>
<p>根据公式，要想算出<span class="arithmatex">\(h_t\)</span>的话：</p>
<ul>
<li>需要有<span class="arithmatex">\(x\)</span>，<span class="arithmatex">\(x\)</span>就是输入，所以第一个参数，需要写的是<span class="arithmatex">\(input\)</span></li>
<li>输入需要一个投影矩阵，就是<span class="arithmatex">\(W_{ih}\)</span>，需要一个weight</li>
<li>同时还需要偏置项<span class="arithmatex">\(\mathrm{bias_{ih}}\)</span></li>
<li>还有上一时刻的隐含状态 ： <span class="arithmatex">\(W_{hh}\)</span> </li>
<li>还有 <span class="arithmatex">\(b_{hh}\)</span></li>
<li>公式中还有 <span class="arithmatex">\(h_{t-1}\)</span> ，写成 <code>h_prev</code> ，就是前一时刻的状态</li>
</ul>
<p>以上，就能算出RNN的输出</p>
<p><strong>第一步：获取当前时刻的输入特征得到<code>x</code></strong></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">weight_ih</span><span class="p">,</span><span class="n">weight_hh</span><span class="p">,</span><span class="n">bias_ih</span><span class="p">,</span><span class="n">bias_hh</span><span class="p">,</span><span class="n">h_prev</span><span class="p">):</span>
</span></code></pre></div>
<ul>
<li>input 默认 三维的结构，先把input的形状拆解出来，形状应该是 <code>batch size×sequence length×input size</code> ，调用 <code>input.shape</code></li>
</ul>
<div class="language-python highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">input_size</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
</span></code></pre></div>
<ul>
<li>通过拆解 <code>input</code> ，还可以知道 <code>hidden size</code>，也就是<code>h_dim</code>，也就是 <code>weight_ih</code>，可以根据它的权重所得到，也就是<code>weight_ih.shape</code>，那到底是<code>shape[0]</code>还是 <code>shape[1]</code>呢？看公式：</li>
</ul>
<p><img alt="image-20241221135636390" src="../images/image-20241221135636390.png" /></p>
<p><code>weight ih</code>跟 <code>xt</code> 是左乘的关系，所以<code>weight</code>的第2个维度跟<code>x</code>是相同的，所以第一个维度 就是隐含单元的维度，所以写成<code>.shape[0]</code>，得到<code>hidden dim ：</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="n">h_dim</span> <span class="o">=</span> <span class="n">weight_ih</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></div>
<p>以上是得到了一些维度，接下来，可以写出 <code>h out</code>，首先 初始化一个 输出，输出大小是 <code>batch size×T×h dim</code>，初始化一个输出矩阵 或者 状态矩阵</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="n">h_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">h_dim</span><span class="p">)</span>  <span class="c1"># 初始化一个输出（状态）矩阵</span>
</span></code></pre></div>
<ul>
<li>
<p><code>bs</code>跟输入是一样的</p>
</li>
<li>
<p>序列长度 或者叫 时间长度 也是跟 输入一样的维度</p>
</li>
<li>需要改成 <code>hidden size</code>这个维度</li>
</ul>
<p>接下来 根据这 6 个参数，算出 <code>h out</code></p>
<p><img alt="image-20241221140038308" src="../images/image-20241221140038308.png" /></p>
<p>RNN是一个递归的计算，所以需要根据<code>x1</code>计算<code>h1</code>，根据<code>x2</code>计算<code>h2</code>等等，因此需要一个<code>for</code>循环 <code>for t in range(T):</code> </p>
<p>因为RNN的计算复杂度 跟序列长度 呈线性关系，所以对序列长度进行遍历就好了</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
</span></code></pre></div>
<p>首先得到当前时刻的输入向量，<code>input</code>，因为input是三维：</p>
<ul>
<li>第一个维度是 batch size，全都取出来</li>
<li>第二个维度是时间，就拿当前 t 时刻的输入向量</li>
<li>第三维是特征维度，也是全部拿出来</li>
</ul>
<div class="language-python highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="n">x</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[:,</span><span class="n">t</span><span class="p">,:]</span>  <span class="c1"># 获取当前时刻输入特征，bs*input_size</span>
</span></code></pre></div>
<p>以上是第一步：获取当前时刻的输入特征得到<code>x</code></p>
<p>第二步：扩充 batch 维度</p>
<p>根据公式，让<code>w</code>跟<code>x</code>进行相乘</p>
<ul>
<li>这里<code>weight</code>一般默认传入 是二维的</li>
<li>而<code>x</code>的大小，默认是 <code>batch size×input size</code></li>
</ul>
<p><code>weight ih</code>的形状是 <code>h dim×input size</code></p>
<p>所以为了进行<code>batch</code>维度无关的乘法运算的话：</p>
<blockquote>
<p>首先对<code>weight ih</code>进行一个扩充，把<code>weight</code>变成一个 <code>batch</code>的形式，<code>weight ih</code>是<code>hidden size×input size</code>的大小，对它 增加一维，<code>batch</code> 维度，对它进行复制，复制成跟<code>input</code>一样的大小，大小就变成了 <code>batch size×h dim×input size</code></p>
</blockquote>
<div class="language-python highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="n">w_ih_batch</span> <span class="o">=</span> <span class="n">weight_ih</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="c1"># bs*h_dim*input_size</span>
</span></code></pre></div>
<p>这是 <code>w ih</code>，变成 <code>batch</code>的形状</p>
<p>同样对于<code>weight hh</code>，也是一样的，也转换一下，对它增加一个<code>batch</code>维度，然后把它的<code>batch</code>维度扩充成 <code>batch size</code>维度大小</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="n">w_hh_batch</span> <span class="o">=</span> <span class="n">weight_hh</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="c1"># bs * h_dim * h_dim</span>
</span></code></pre></div>
<p>这里 <code>w hh</code>大小就是 <code>batch size× h dim×h dim</code>，因为跟<code>hidden state</code>相连的，所以是一个方阵</p>
<p><span class="arithmatex">\(h_t = \mathrm{tanh(W_{ih}x_t+b_{ih}+W_{hh}h_{t-1}+b_{hh})}\)</span></p>
<p>第三步：开始计算 <span class="arithmatex">\(w_{ih}× x_t、w_{hh}× h_{t-1}\)</span></p>
<p><strong>第一项：<code>w_times_x</code></strong></p>
<p>首先计算 <code>x</code>，就是计算 <code>Wih</code>乘以<code>x</code>这个量 <code>w_times_x</code>这个量，可以调用 <code>torch.bmm</code>这个函数</p>
<blockquote>
<p><code>batch matrix multiplication</code>，是含有批大小的矩阵相乘，与 批 无关的 计算矩阵相乘</p>
</blockquote>
<ul>
<li>第一个位置传入 <code>w ih batch</code></li>
<li>第二个位置 传入 <code>x</code></li>
</ul>
<blockquote>
<p>当前这个<code>x</code>是<code>batch size× input_size</code>的，为了跟 <code>w ih batch</code>相乘，需要将它 扩充一维，扩充成 <code>batch size×input size×1</code>的，这里 需要 对它 扩充一下，调用一下<code>unsqueeze</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="n">x</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[:,</span><span class="n">t</span><span class="p">,:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></code></pre></div>
</blockquote>
<p>本来是二维的，现在在第三个维度上进行扩充，变成 <code>batch size×input size×1</code>，此时跟<code>x</code>相乘，得到 <code>batch size× h dim×1</code>，最后<code>1</code>的维度去掉，调用<code>unsqueeze</code>函数，得到的结果 <code>batch size×h dim</code>，得到<code>w times x</code>的结果，偏置最后再加</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="n">x</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[:,</span><span class="n">t</span><span class="p">,:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 获取当前时刻的输入特征 bs*input_size*1</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="n">w_ih_batch</span> <span class="o">=</span> <span class="n">weight_ih</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#bs*h_dim*input_size</span>
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="n">w_hh_batch</span> <span class="o">=</span> <span class="n">weight_hh</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#bs*h_dim*h_dim</span>
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="n">w_times_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">w_ih_batch</span><span class="p">,</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># bs*h_dm</span>
</span></code></pre></div>
<p><strong>第二项 <code>w_times_h</code></strong></p>
<p><code>Whh</code> 矩阵 跟上一时刻的状态相乘的结果</p>
<p>同样调用 <code>torch.bmm</code>函数，带有批大小的矩阵相乘，跟上一时刻的隐含状态 进行相乘</p>
<p>同样对<code>h prev</code>进行扩充，<code>h_prev.unsqueeze(2)</code>，把它扩充三维</p>
<p>因为<code>h prev</code>本来是，<code>batch size×hidden size</code>，现在变成 <code>batch size×hidden size×1</code>，乘出来以后 是 <code>batch size×hidden size ×1</code>，最后再把1 去掉，挤掉</p>
<p>这里乘的权重是方阵，不改变大小，所以还是 <code>h prev</code>的形状</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="n">w_times_h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">w_hh_batch</span><span class="p">,</span><span class="n">h_prev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></div>
<p>调用 <code>squeeze</code>函数，把最后的1去掉 最后变成了 <code>batch size× h dim</code></p>
<p>这是这两个量，最后把这些东西全部加起来，跟<code>bias</code>加起来，然后通过两个tanh函数</p>
<p><img alt="image-20241221195057262" src="../images/image-20241221195057262.png" /></p>
<p>首先是 <code>w_times_x</code>这个量 然后加上 <code>bias ih</code>，最后加上 <code>w times h</code>，上一时刻隐含状态相关的，最后是<code>bias hh</code>，然后过一个 <code>tanh</code>激活函数，最终得到当前时刻的这一状态</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">w_times_x</span> <span class="o">+</span> <span class="n">bias_ih</span> <span class="o">+</span> <span class="n">w_times_h</span> <span class="o">+</span> <span class="n">bias_hh</span><span class="p">)</span>
</span></code></pre></div>
<p>定义为<code>h_prev</code>，因为进行的是递归的运算</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="n">h_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">w_times_x</span> <span class="o">+</span> <span class="n">bias_ih</span> <span class="o">+</span> <span class="n">w_times_h</span> <span class="o">+</span> <span class="n">bias_hh</span><span class="p">)</span>
</span></code></pre></div>
<p>现在计算了<span class="arithmatex">\(t\)</span>时刻的输出，接着把<span class="arithmatex">\(t\)</span>时刻的输出，放入到 <code>h out</code>中，</p>
<p>怎么放，只要放到时间长度这一维，<span class="arithmatex">\(t\)</span>行即可</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="n">h_out</span><span class="p">[:,</span><span class="n">t</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">h_prev</span>
</span></code></pre></div>
<p>以上完成了递归的运算，最后返回 跟 pytorch官方api一样</p>
<p>首先返回<code>h_out</code></p>
<p>然后返回 最后一个时刻的隐含状态，其实也就是<code>h_prev</code></p>
<p>但是这里的<code>h_prev</code>是二维的，官方api是三维的，所以要 扩一维，扩一维的原因就是因为 自己实现的是 单向、单层的，所以在 第0维 扩充一个1 就好了</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="k">return</span> <span class="n">h_out</span><span class="p">,</span><span class="n">h_prev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></code></pre></div>
<p>以上是所有全手写的RNN forward函数，其实就是单向的RNN</p>
<h3 id="torchtile">torch.tile函数<a class="headerlink" href="#torchtile" title="Permanent link">&para;</a></h3>
<p>补充 torch.tile函数：沿指定维度重复张量函数</p>
<p>例子：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-30-2"><a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a>
</span><span id="__span-30-3"><a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a><span class="c1"># 创建一个张量</span>
</span><span id="__span-30-4"><a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a><span class="n">weight_hh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
</span><span id="__span-30-5"><a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a>
</span><span id="__span-30-6"><a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a><span class="c1"># 假设批量大小为3</span>
</span><span id="__span-30-7"><a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a><span class="n">bs</span> <span class="o">=</span> <span class="mi">3</span>
</span><span id="__span-30-8"><a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a>
</span><span id="__span-30-9"><a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a><span class="c1"># 使用 unsqueeze 在第0维度增加一个维度，然后使用 tile 沿第0维度重复 bs 次</span>
</span><span id="__span-30-10"><a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a><span class="n">w_hh_batch</span> <span class="o">=</span> <span class="n">weight_hh</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-30-11"><a id="__codelineno-30-11" name="__codelineno-30-11" href="#__codelineno-30-11"></a>
</span><span id="__span-30-12"><a id="__codelineno-30-12" name="__codelineno-30-12" href="#__codelineno-30-12"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;原始张量:&quot;</span><span class="p">)</span>
</span><span id="__span-30-13"><a id="__codelineno-30-13" name="__codelineno-30-13" href="#__codelineno-30-13"></a><span class="nb">print</span><span class="p">(</span><span class="n">weight_hh</span><span class="p">)</span>
</span><span id="__span-30-14"><a id="__codelineno-30-14" name="__codelineno-30-14" href="#__codelineno-30-14"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;增加维度并重复后的张量:&quot;</span><span class="p">)</span>
</span><span id="__span-30-15"><a id="__codelineno-30-15" name="__codelineno-30-15" href="#__codelineno-30-15"></a><span class="nb">print</span><span class="p">(</span><span class="n">w_hh_batch</span><span class="p">)</span>
</span></code></pre></div>
<p>在这个示例中：</p>
<ol>
<li><a href="vscode-file://vscode-app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-sandbox/workbench/workbench.esm.html"><code>weight_hh</code></a> 是一个形状为 <code>[2, 2]</code> 的张量。</li>
<li><a href="vscode-file://vscode-app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-sandbox/workbench/workbench.esm.html"><code>weight_hh.unsqueeze(0)</code></a> 在第0维度增加一个维度，使其形状变为 <code>[1, 2, 2]</code>。</li>
<li><a href="vscode-file://vscode-app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-sandbox/workbench/workbench.esm.html"><code>tile(bs, 1, 1)</code></a> 沿第0维度重复 <a href="vscode-file://vscode-app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-sandbox/workbench/workbench.esm.html"><code>bs</code></a> 次（这里 <a href="vscode-file://vscode-app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-sandbox/workbench/workbench.esm.html"><code>bs</code></a> 为3），使其形状变为 <code>[3, 2, 2]</code>。</li>
</ol>
<p>输出结果：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="n">原始张量</span><span class="p">:</span>
</span><span id="__span-31-2"><a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span><span id="__span-31-3"><a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a>        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
</span><span id="__span-31-4"><a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a><span class="n">增加维度并重复后的张量</span><span class="p">:</span>
</span><span id="__span-31-5"><a id="__codelineno-31-5" name="__codelineno-31-5" href="#__codelineno-31-5"></a><span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span><span id="__span-31-6"><a id="__codelineno-31-6" name="__codelineno-31-6" href="#__codelineno-31-6"></a>         <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>
</span><span id="__span-31-7"><a id="__codelineno-31-7" name="__codelineno-31-7" href="#__codelineno-31-7"></a>
</span><span id="__span-31-8"><a id="__codelineno-31-8" name="__codelineno-31-8" href="#__codelineno-31-8"></a>        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span><span id="__span-31-9"><a id="__codelineno-31-9" name="__codelineno-31-9" href="#__codelineno-31-9"></a>         <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>
</span><span id="__span-31-10"><a id="__codelineno-31-10" name="__codelineno-31-10" href="#__codelineno-31-10"></a>
</span><span id="__span-31-11"><a id="__codelineno-31-11" name="__codelineno-31-11" href="#__codelineno-31-11"></a>        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span><span id="__span-31-12"><a id="__codelineno-31-12" name="__codelineno-31-12" href="#__codelineno-31-12"></a>         <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]])</span>
</span></code></pre></div>
<p>这样，<a href="vscode-file://vscode-app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-sandbox/workbench/workbench.esm.html"><code>w_hh_batch</code></a> 就是一个形状为 <code>[3, 2, 2]</code> 的张量，其中每个批次都包含原始的 <a href="vscode-file://vscode-app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-sandbox/workbench/workbench.esm.html"><code>weight_hh</code></a> 张量</p>
<h3 id="5">5 验证<a class="headerlink" href="#5" title="Permanent link">&para;</a></h3>
<p>验证思路：</p>
<blockquote>
<p>把之前实例化的RNN网络，参数拿出来，填充到自定义的网络中</p>
<p>然后算出来的结果 如果是跟官方API结果一致的话，就表明自定义的函数是正确的</p>
</blockquote>
<p><strong>首先，拿出RNN的参数：</strong></p>
<p>（1）RNN有哪些参数？</p>
<p><code>nn.Module</code>这个类，</p>
<p>① 在<code>pytorch</code>中 所有的层，都是继承自<code>nn.Module</code>这个类</p>
<p>② <code>nn.Module</code>的函数：<code>name.parameters</code>这个函数，查看 RNN中 有哪些参数</p>
<blockquote>
<p><code>name.parameters</code>是一个生成器，可以用循环得到 <code>for p,n in</code> </p>
<p>p：参数</p>
<p>n：name</p>
<p><code>in rnn.named_parameters():</code> 就能看到 rnn有哪些参数</p>
</blockquote>
<div class="language-python highlight"><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a><span class="k">for</span> <span class="n">p</span><span class="p">,</span><span class="n">n</span> <span class="ow">in</span> <span class="n">rnn</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span></code></pre></div>
<p>打印查看结果：RNN有哪些参数 以及 它的名称</p>
<p><img alt="image-20241221200129294" src="../images/image-20241221200129294.png" /></p>
<p>可以看到 RNN的所有的参数、名称、具体地张量的数值 </p>
<p>一共有四个参数，分别是</p>
<p>①第一个参数： <code>weight ih l0</code></p>
<ul>
<li><code>weight ih</code> ： 公式里的 <code>wih</code></li>
<li><code>l0</code>：网络定义只有一层，层数是从<span class="arithmatex">\(0\)</span>开始的，所以是从<code>l0</code></li>
</ul>
<p>② 第二个参数：<code>weight hh l0</code></p>
<p>表示当前层 <code>w hh</code>的参数</p>
<p>另外两个就是偏置了，分别是</p>
<p>③第三个参数： <code>bias ih</code></p>
<p>④第四个参数： <code>bias hh</code>  </p>
<p>需要注意的是：</p>
<ul>
<li>前面两个权重张量 是 二维张量</li>
<li>后面两个偏置是 一维的向量</li>
</ul>
<p>（2）现在把这些参数 代入到自己写的<code>RNN forward</code>函数中</p>
<p>首先，复制一下 自己写的函数签名</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="n">rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">weight_ih</span><span class="p">,</span><span class="n">weight_hh</span><span class="p">,</span><span class="n">bias_ih</span><span class="p">,</span><span class="n">bias_hh</span><span class="p">,</span><span class="n">h_prev</span><span class="p">):</span>
</span></code></pre></div>
<ul>
<li><code>input</code>还是<code>input</code></li>
<li><code>weight ih</code>可以改成 <code>rnn.</code>，直接用<code>rnn.参数名称</code>，就可以访问这个参数 ，<code>rnn.weight_ih_l0</code></li>
<li><code>weight hh</code>也是一样，用<code>rnn.</code>来进行访问：<code>rnn.weight_hh_l0</code></li>
<li><code>bias</code>也是一样的 对应的是 <code>rnn.bias_ih_l0</code></li>
<li>同样<code>hh bias</code>也是一样的 <code>rnn.bias_hh_l0</code></li>
<li><code>h_prev</code>，就是自定义好的，就直接用<code>h_prev</code></li>
</ul>
<div class="language-python highlight"><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a><span class="n">rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">rnn</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="p">,</span><span class="n">rnn</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="p">,</span><span class="n">rnn</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="p">,</span><span class="n">rnn</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="p">,</span><span class="n">h_prev</span><span class="p">)</span>
</span></code></pre></div>
<p><strong>变量名命令：</strong></p>
<p>前面写的是<code>rnn output</code>和<code>state finall</code></p>
<p><img alt="image-20241221201523163" src="../images/image-20241221201523163.png" /></p>
<p>加前缀 <code>custom</code>，表示自己写的</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="n">custom_rnn_output</span><span class="p">,</span><span class="n">custom_state_finall</span> <span class="o">=</span> <span class="n">rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">rnn</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="p">,</span><span class="n">rnn</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="p">,</span><span class="n">rnn</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="p">,</span><span class="n">rnn</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="p">,</span><span class="n">h_prev</span><span class="p">)</span>
</span></code></pre></div>
<p>这样就调用了自己写的<code>RNN forward</code>函数</p>
<p>然后对比<code>pytorch api</code>的结果 和 自己写的结果</p>
<p><img alt="image-20241221201653310" src="../images/image-20241221201653310.png" /></p>
<p>第一个张量 整体RNN 预测的输出，是一致的</p>
<p>第二个张量是最后一个时刻的输出</p>
<p>官方的结果 和 自定义的结果一样 </p>
<h4 id="rnn_1">自定义 RNN代码<a class="headerlink" href="#rnn_1" title="Permanent link">&para;</a></h4>
<p><img alt="image-20241221201752393" src="../images/image-20241221201752393.png" /></p>
<h3 id="6-rnn">6 验证双向RNN<a class="headerlink" href="#6-rnn" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a><span class="n">h_t</span> <span class="o">=</span> <span class="n">tanh</span><span class="p">(</span><span class="n">x_t</span><span class="p">)</span>
</span></code></pre></div>
<p>双向的话调用单向的函数</p>
<p>双向需要注意 所有的参数 都double了，所有的weight和bias 都有两个</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-37-1"><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="c1"># step3 手写一个bidirectional_rnn_forward函数，实现双向RNN的计算原理</span>
</span></code></pre></div>
<ul>
<li>双向要考虑两倍的 <code>forward函数</code>和<code>backward层</code></li>
<li><code>weight</code>有<code>forward</code>层和<code>backward</code>层</li>
<li><code>bias</code>也有<code>forward</code>层和<code>backward</code>层</li>
<li><code>h prev</code>也是有两份的</li>
</ul>
<p>第一份是 <code>forward layer</code>，还有 <code>backward</code>，复制然后改名，按照官方的名称，改成<code>reverse</code></p>
<p>这时候所有的参数都是两份的：</p>
<p><code>forward</code>一份，<code>backward</code>一份</p>
<p>RNN是比较简单的，如果是<code>LSTM</code> 、<code>GRU</code> 更复杂</p>
<p>函数签名写成：</p>
<p><img alt="image-20241221205304685" src="../images/image-20241221205304685.png" /></p>
<p>接下来，还是一样的，得到一些基本的信息</p>
<p>首先，上面复制下来：</p>
<p><img alt="image-20241221205534221" src="../images/image-20241221205534221.png" /></p>
<p>第一步 <code>batch size</code>，<code>时间</code> 和 <code>input size</code></p>
<p>然后，得到 <code>hidden size</code>  、<code>h_dim</code></p>
<p>关于<code>h_out</code>，这里<code>batch size</code>不变，<code>T</code>不变，但是<code>h dim</code>要变成两倍，因为是双向的结构：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-38-1"><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a><span class="n">h_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">h_dim</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-38-2"><a id="__codelineno-38-2" name="__codelineno-38-2" href="#__codelineno-38-2"></a><span class="c1"># 初始化输出状态矩阵，注意双向是两倍的特征大小</span>
</span></code></pre></div>
<p>该定义的定义好了，接下来 调用<code>RNN forward</code>函数</p>
<p>调用两次<code>RNN forward</code>函数</p>
<p>第一步一模一样</p>
<p><img alt="image-20241221205736872" src="../images/image-20241221205736872.png" /></p>
<p>红框是需要传入的参数</p>
<p>这是<code>forward</code>层的调用，取名为 <code>forward_output</code>，这里只取 第一个返回值，所以加个[0]</p>
<p><img alt="image-20241221205826587" src="../images/image-20241221205826587.png" /></p>
<p>得到 <code>forward layer</code></p>
<p>下面 <code>backward layer</code></p>
<p>这里要变换一下，除了所有的参数都用reverse版本的，对input 也要reverse一下，就是因为如果是反向的话，要保证第一个位置上，input是最后一个元素；对input 需要 在长度这一维 进行翻转：</p>
<p><img alt="image-20241221205927963" src="../images/image-20241221205927963.png" /></p>
<p>调用 <code>torch.flip  api</code>，这个<code>api</code>，对张量进行翻转：</p>
<p><img alt="image-20241221210032831" src="../images/image-20241221210032831.png" /></p>
<p>有两个参数：</p>
<ul>
<li>
<p>一个是input</p>
</li>
<li>
<p>一个是dim，也就是说 传入的是 哪个 dim，就会对哪个 dim 进行翻转，完全相反的顺序</p>
</li>
</ul>
<p>还是先拷贝所有的参数，调用 rnn_forward函数：</p>
<p><img alt="image-20241221210122850" src="../images/image-20241221210122850.png" /></p>
<ul>
<li>第一个参数 <code>input</code>，进行翻转，调用 <code>torch.flip</code>，<code>flip</code>的第一个参数是 <code>input</code>，第二个参数是<code>维度</code>，维度官方api中规定：</li>
</ul>
<blockquote>
<p><img alt="image-20241221210222846" src="../images/image-20241221210222846.png" /></p>
<p>要么是列表 要么是元组</p>
</blockquote>
<p>这里的input是三维，要翻转的是 中间这一维，<code>T</code>这维：</p>
<p><img alt="image-20241221210258044" src="../images/image-20241221210258044.png" /></p>
<p>传入一个列表，<code>1</code>这一维度，表示中间这一维度，进行翻转</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-39-1"><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="n">rnn_forward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="nb">input</span><span class="p">,[</span><span class="mi">1</span><span class="p">]),</span>
</span><span id="__span-39-2"><a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a>            <span class="n">weight_ih_reverse</span><span class="p">,</span>
</span><span id="__span-39-3"><a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a>            <span class="n">weight_hh_reverse</span><span class="p">,</span>
</span><span id="__span-39-4"><a id="__codelineno-39-4" name="__codelineno-39-4" href="#__codelineno-39-4"></a>            <span class="n">bias_ih_reverse</span><span class="p">,</span>
</span><span id="__span-39-5"><a id="__codelineno-39-5" name="__codelineno-39-5" href="#__codelineno-39-5"></a>            <span class="n">bias_hh_reveerse</span><span class="p">,</span>
</span><span id="__span-39-6"><a id="__codelineno-39-6" name="__codelineno-39-6" href="#__codelineno-39-6"></a>            <span class="n">h_prev_reverse</span><span class="p">)</span>
</span></code></pre></div>
<p>同样 对它的调用 也只取 <code>output</code>，定义为 <code>backward output</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-40-1"><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a><span class="n">backward_output</span> <span class="o">=</span> <span class="n">rnn_forward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="nb">input</span><span class="p">,[</span><span class="mi">1</span><span class="p">]),</span>
</span><span id="__span-40-2"><a id="__codelineno-40-2" name="__codelineno-40-2" href="#__codelineno-40-2"></a>                              <span class="n">weight_ih_reverse</span><span class="p">,</span>
</span><span id="__span-40-3"><a id="__codelineno-40-3" name="__codelineno-40-3" href="#__codelineno-40-3"></a>                              <span class="n">weight_hh_reverse</span><span class="p">,</span>
</span><span id="__span-40-4"><a id="__codelineno-40-4" name="__codelineno-40-4" href="#__codelineno-40-4"></a>                              <span class="n">bias_ih_reverse</span><span class="p">,</span>
</span><span id="__span-40-5"><a id="__codelineno-40-5" name="__codelineno-40-5" href="#__codelineno-40-5"></a>                              <span class="n">bias_hh_reveerse</span><span class="p">,</span>
</span><span id="__span-40-6"><a id="__codelineno-40-6" name="__codelineno-40-6" href="#__codelineno-40-6"></a>                              <span class="n">h_prev_reverse</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># backward layer</span>
</span></code></pre></div>
<p>以上 得到了 <code>forward output</code>和<code>backward output</code></p>
<p>为什么 只保留了 <code>h_out</code>，没有保留<code>h prev</code>呢？</p>
<blockquote>
<p>因为在RNN中，<code>h prev</code>可以从 <code>h out</code>中得到，所以为了方便 只取了 <code>h out</code></p>
</blockquote>
<p><img alt="image-20241221210611796" src="../images/image-20241221210611796.png" /></p>
<p>接下来，把 <code>forward output</code> 和 <code>backward output</code> 填充到 <code>h out</code>中</p>
<p>首先 <code>h out</code>是三维的，并且最后一维 由 <code>forward 和 backward</code> 填充起来的，所以填充时，索引的写法：从<span class="arithmatex">\(0\)</span>到 <code>h_dim</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-41-1"><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a><span class="n">h_out</span><span class="p">[:,:,:</span><span class="n">h_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">forward_output</span>
</span></code></pre></div>
<p>从<code>h_dim:</code>到最后</p>
<p>前向的输出，填充到前一半中，后一半的维度，用<code>backward output</code>填充</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-42-1"><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a><span class="n">h_out</span><span class="p">[:,:,</span><span class="n">h_dim</span><span class="p">:]</span> <span class="o">=</span> <span class="n">backward_output</span>
</span></code></pre></div>
<p>把 <code>前向输出</code> 和 <code>后向输出</code> 拼起来，然后返回</p>
<p>同样按照<code>官方api</code>，返回两个数：</p>
<ul>
<li>第一个数是 <code>h_out</code></li>
<li>第二个数就是 <code>state finall</code></li>
</ul>
<p><img alt="image-20241221210921980" src="../images/image-20241221210921980.png" /></p>
<p><code>Sate finall</code>维度是 <span class="arithmatex">\(D*num\_layers\)</span> × N × <span class="arithmatex">\(H_{out}\)</span></p>
<ul>
<li>前面表示 双向 和 层数的乘积</li>
<li>中间是<code>batch size</code></li>
<li>后面是 <code>H_out</code></li>
</ul>
<p>怎么写呢？</p>
<p>首先 要取出  <code>h out</code>的最后一个时刻，因为时刻是在中间那个维度，所以用 <code>-1</code>索引</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-43-1"><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a><span class="k">return</span> <span class="n">h_out</span><span class="p">,</span><span class="n">h_out</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(())</span>
</span></code></pre></div>
<p>先取出 最后一个时刻，最后一个时刻的状态向量，形状 <span class="arithmatex">\(batch \_size×2倍的h\_dim\)</span>，先<code>reshape</code>，把2单独拎出来，然后reshape：</p>
<ul>
<li>Batch size不变</li>
<li>2单独拎出来</li>
<li>h dim就写成 h dim</li>
</ul>
<p>首先把二维张量 变成三维张量</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-44-1"><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a><span class="k">return</span> <span class="n">h_out</span><span class="p">,</span><span class="n">h_out</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">h_dim</span><span class="p">))</span>
</span></code></pre></div>
<p>然后 把2提到前面，根据官方api：</p>
<ul>
<li>2 在前面</li>
</ul>
<p><img alt="image-20241221211444198" src="../images/image-20241221211444198.png" /></p>
<ul>
<li>batch size在中间</li>
</ul>
<p>所以把2 提到前面，调用一下转置函数，就是把 <code>第0维度</code> 和 <code>第1维度</code> 交换一下：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-45-1"><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a><span class="k">return</span> <span class="n">h_out</span><span class="p">,</span><span class="n">h_out</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">h_dim</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></div>
<p>以上双向自定义RNN 函数的实现</p>
<h4 id="rnn_2">自定义双向 RNN代码<a class="headerlink" href="#rnn_2" title="Permanent link">&para;</a></h4>
<p><img alt="image-20241221211612136" src="../images/image-20241221211612136.png" /></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-46-1"><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a><span class="c1"># step3 手写一个 bidirectional_rnn_forward函数，实现双向RNN的计算原理</span>
</span><span id="__span-46-2"><a id="__codelineno-46-2" name="__codelineno-46-2" href="#__codelineno-46-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">bidirectional_rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
</span><span id="__span-46-3"><a id="__codelineno-46-3" name="__codelineno-46-3" href="#__codelineno-46-3"></a>                              <span class="n">weight_ih</span><span class="p">,</span>
</span><span id="__span-46-4"><a id="__codelineno-46-4" name="__codelineno-46-4" href="#__codelineno-46-4"></a>                              <span class="n">weight_hh</span><span class="p">,</span>
</span><span id="__span-46-5"><a id="__codelineno-46-5" name="__codelineno-46-5" href="#__codelineno-46-5"></a>                              <span class="n">bias_ih</span><span class="p">,</span>
</span><span id="__span-46-6"><a id="__codelineno-46-6" name="__codelineno-46-6" href="#__codelineno-46-6"></a>                              <span class="n">bias_hh</span><span class="p">,</span>
</span><span id="__span-46-7"><a id="__codelineno-46-7" name="__codelineno-46-7" href="#__codelineno-46-7"></a>                              <span class="n">h_prev</span><span class="p">,</span>
</span><span id="__span-46-8"><a id="__codelineno-46-8" name="__codelineno-46-8" href="#__codelineno-46-8"></a>                              <span class="n">weight_ih_reverse</span><span class="p">,</span>
</span><span id="__span-46-9"><a id="__codelineno-46-9" name="__codelineno-46-9" href="#__codelineno-46-9"></a>                              <span class="n">weight_hh_reverse</span><span class="p">,</span>
</span><span id="__span-46-10"><a id="__codelineno-46-10" name="__codelineno-46-10" href="#__codelineno-46-10"></a>                              <span class="n">bias_ih_reverse</span><span class="p">,</span>
</span><span id="__span-46-11"><a id="__codelineno-46-11" name="__codelineno-46-11" href="#__codelineno-46-11"></a>                              <span class="n">bias_hh_reverse</span><span class="p">,</span>
</span><span id="__span-46-12"><a id="__codelineno-46-12" name="__codelineno-46-12" href="#__codelineno-46-12"></a>                              <span class="n">h_prev_reverse</span><span class="p">):</span>
</span><span id="__span-46-13"><a id="__codelineno-46-13" name="__codelineno-46-13" href="#__codelineno-46-13"></a>    <span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">input_size</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-46-14"><a id="__codelineno-46-14" name="__codelineno-46-14" href="#__codelineno-46-14"></a>    <span class="n">h_dim</span> <span class="o">=</span> <span class="n">weight_ih</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-46-15"><a id="__codelineno-46-15" name="__codelineno-46-15" href="#__codelineno-46-15"></a>    <span class="n">h_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">h_dim</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># 初始化一个输出（状态）矩阵，注意双向是两倍的特征大小</span>
</span><span id="__span-46-16"><a id="__codelineno-46-16" name="__codelineno-46-16" href="#__codelineno-46-16"></a>
</span><span id="__span-46-17"><a id="__codelineno-46-17" name="__codelineno-46-17" href="#__codelineno-46-17"></a>    <span class="n">forward_output</span> <span class="o">=</span> <span class="n">rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
</span><span id="__span-46-18"><a id="__codelineno-46-18" name="__codelineno-46-18" href="#__codelineno-46-18"></a>                                 <span class="n">weight_ih</span><span class="p">,</span>
</span><span id="__span-46-19"><a id="__codelineno-46-19" name="__codelineno-46-19" href="#__codelineno-46-19"></a>                                 <span class="n">weight_hh</span><span class="p">,</span>
</span><span id="__span-46-20"><a id="__codelineno-46-20" name="__codelineno-46-20" href="#__codelineno-46-20"></a>                                 <span class="n">bias_ih</span><span class="p">,</span>
</span><span id="__span-46-21"><a id="__codelineno-46-21" name="__codelineno-46-21" href="#__codelineno-46-21"></a>                                 <span class="n">bias_hh</span><span class="p">,</span>
</span><span id="__span-46-22"><a id="__codelineno-46-22" name="__codelineno-46-22" href="#__codelineno-46-22"></a>                                 <span class="n">h_prev</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># forward layer</span>
</span><span id="__span-46-23"><a id="__codelineno-46-23" name="__codelineno-46-23" href="#__codelineno-46-23"></a>    <span class="n">backward_output</span> <span class="o">=</span> <span class="n">rnn_forward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="nb">input</span><span class="p">,[</span><span class="mi">1</span><span class="p">]),</span>
</span><span id="__span-46-24"><a id="__codelineno-46-24" name="__codelineno-46-24" href="#__codelineno-46-24"></a>                                  <span class="n">weight_ih_reverse</span><span class="p">,</span>
</span><span id="__span-46-25"><a id="__codelineno-46-25" name="__codelineno-46-25" href="#__codelineno-46-25"></a>                                  <span class="n">weight_hh_reverse</span><span class="p">,</span>
</span><span id="__span-46-26"><a id="__codelineno-46-26" name="__codelineno-46-26" href="#__codelineno-46-26"></a>                                  <span class="n">bias_ih_reverse</span><span class="p">,</span> 
</span><span id="__span-46-27"><a id="__codelineno-46-27" name="__codelineno-46-27" href="#__codelineno-46-27"></a>                                  <span class="n">bias_hh_reverse</span><span class="p">,</span>
</span><span id="__span-46-28"><a id="__codelineno-46-28" name="__codelineno-46-28" href="#__codelineno-46-28"></a>                                  <span class="n">h_prev_reverse</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># backward layer</span>
</span><span id="__span-46-29"><a id="__codelineno-46-29" name="__codelineno-46-29" href="#__codelineno-46-29"></a>
</span><span id="__span-46-30"><a id="__codelineno-46-30" name="__codelineno-46-30" href="#__codelineno-46-30"></a>    <span class="c1"># 将input按照时间的顺序翻转</span>
</span><span id="__span-46-31"><a id="__codelineno-46-31" name="__codelineno-46-31" href="#__codelineno-46-31"></a>    <span class="n">h_out</span><span class="p">[:,:,:</span><span class="n">h_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">forward_output</span>
</span><span id="__span-46-32"><a id="__codelineno-46-32" name="__codelineno-46-32" href="#__codelineno-46-32"></a>    <span class="n">h_out</span><span class="p">[:,:,</span><span class="n">h_dim</span><span class="p">:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">backward_output</span><span class="p">,[</span><span class="mi">1</span><span class="p">])</span> <span class="c1">#需要再翻转一下 才能和forward output拼接</span>
</span><span id="__span-46-33"><a id="__codelineno-46-33" name="__codelineno-46-33" href="#__codelineno-46-33"></a>
</span><span id="__span-46-34"><a id="__codelineno-46-34" name="__codelineno-46-34" href="#__codelineno-46-34"></a>
</span><span id="__span-46-35"><a id="__codelineno-46-35" name="__codelineno-46-35" href="#__codelineno-46-35"></a>    <span class="n">h_n</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">h_dim</span><span class="p">)</span>  <span class="c1"># 要最后的状态连接</span>
</span><span id="__span-46-36"><a id="__codelineno-46-36" name="__codelineno-46-36" href="#__codelineno-46-36"></a>
</span><span id="__span-46-37"><a id="__codelineno-46-37" name="__codelineno-46-37" href="#__codelineno-46-37"></a>    <span class="n">h_n</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">forward_output</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>
</span><span id="__span-46-38"><a id="__codelineno-46-38" name="__codelineno-46-38" href="#__codelineno-46-38"></a>    <span class="n">h_n</span><span class="p">[:,</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">backward_output</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>
</span><span id="__span-46-39"><a id="__codelineno-46-39" name="__codelineno-46-39" href="#__codelineno-46-39"></a>
</span><span id="__span-46-40"><a id="__codelineno-46-40" name="__codelineno-46-40" href="#__codelineno-46-40"></a>    <span class="n">h_n</span> <span class="o">=</span> <span class="n">h_n</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-46-41"><a id="__codelineno-46-41" name="__codelineno-46-41" href="#__codelineno-46-41"></a>
</span><span id="__span-46-42"><a id="__codelineno-46-42" name="__codelineno-46-42" href="#__codelineno-46-42"></a>    <span class="k">return</span> <span class="n">h_out</span><span class="p">,</span><span class="n">h_n</span>
</span><span id="__span-46-43"><a id="__codelineno-46-43" name="__codelineno-46-43" href="#__codelineno-46-43"></a>    <span class="c1"># return h_out,h_out[:,-1,:].reshape((bs,2,h_dim)).transpose(0,1)</span>
</span><span id="__span-46-44"><a id="__codelineno-46-44" name="__codelineno-46-44" href="#__codelineno-46-44"></a>
</span><span id="__span-46-45"><a id="__codelineno-46-45" name="__codelineno-46-45" href="#__codelineno-46-45"></a><span class="c1"># 验证一下 bidirectional_rnn_forward的正确性</span>
</span><span id="__span-46-46"><a id="__codelineno-46-46" name="__codelineno-46-46" href="#__codelineno-46-46"></a><span class="n">bi_rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span>
</span><span id="__span-46-47"><a id="__codelineno-46-47" name="__codelineno-46-47" href="#__codelineno-46-47"></a>                <span class="n">hidden_size</span><span class="p">,</span>
</span><span id="__span-46-48"><a id="__codelineno-46-48" name="__codelineno-46-48" href="#__codelineno-46-48"></a>                <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-46-49"><a id="__codelineno-46-49" name="__codelineno-46-49" href="#__codelineno-46-49"></a>                <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-46-50"><a id="__codelineno-46-50" name="__codelineno-46-50" href="#__codelineno-46-50"></a><span class="n">h_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">))</span>
</span><span id="__span-46-51"><a id="__codelineno-46-51" name="__codelineno-46-51" href="#__codelineno-46-51"></a><span class="n">bi_rnn_output</span><span class="p">,</span><span class="n">bi_state_finall</span> <span class="o">=</span> <span class="n">bi_rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">h_prev</span><span class="p">)</span>
</span><span id="__span-46-52"><a id="__codelineno-46-52" name="__codelineno-46-52" href="#__codelineno-46-52"></a>
</span><span id="__span-46-53"><a id="__codelineno-46-53" name="__codelineno-46-53" href="#__codelineno-46-53"></a><span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">bi_rnn</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span><span id="__span-46-54"><a id="__codelineno-46-54" name="__codelineno-46-54" href="#__codelineno-46-54"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
</span></code></pre></div>
<p>代码思路：</p>
<ol>
<li>首先把 <code>input</code>传入到 <code>forward layer</code>中</li>
<li>然后再把<code>input</code> 按照 时间的顺序 翻转一下，再传入<code>backwardward layer</code>中</li>
<li>再把 <code>forward output</code>和<code>backward output</code>拼起来，形成整体的<code>h out</code></li>
<li>最后返回序列 整体的隐含状态和 最后一个时刻的状态</li>
</ol>
<p>现在验证  双向 rnn  forward 正确性</p>
<p><strong>首先 实例化双向RNN 层</strong></p>
<p>复制下来，并设置 bidirection=True</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-47-1"><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a><span class="c1"># 验证一下 bidirectional_rnn_forward的正确性</span>
</span><span id="__span-47-2"><a id="__codelineno-47-2" name="__codelineno-47-2" href="#__codelineno-47-2"></a><span class="n">bi_rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">,</span><span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p>同样定义一个<code>h_prev</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-48-1"><a id="__codelineno-48-1" name="__codelineno-48-1" href="#__codelineno-48-1"></a><span class="n">h_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">()</span>
</span></code></pre></div>
<p>大小是 <code>2× batch size× hidden size</code></p>
<p><img alt="image-20241221212306336" src="../images/image-20241221212306336.png" /></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-49-1"><a id="__codelineno-49-1" name="__codelineno-49-1" href="#__codelineno-49-1"></a><span class="n">h_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">)</span>
</span></code></pre></div>
<p>调用RNN，传入<code>input</code>和<code>h_prev</code>，得到双向RNN的<code>output</code>和双向<code>state finall</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-50-1"><a id="__codelineno-50-1" name="__codelineno-50-1" href="#__codelineno-50-1"></a><span class="n">bi_rnn_output</span><span class="p">,</span><span class="n">bi_state_finall</span> <span class="o">=</span> <span class="n">bi_rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">h_prev</span><span class="p">)</span>
</span></code></pre></div>
<p>得到官方api的结果</p>
<p><img alt="image-20241221212448882" src="../images/image-20241221212448882.png" /></p>
<p>对于RNN 查看一下 参数的名字，然后把这些参数代入到自定义的双向RNN函数中去</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-51-1"><a id="__codelineno-51-1" name="__codelineno-51-1" href="#__codelineno-51-1"></a><span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">bi_rnn</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span><span id="__span-51-2"><a id="__codelineno-51-2" name="__codelineno-51-2" href="#__codelineno-51-2"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="image-20241221212548749" src="../images/image-20241221212548749.png" /></p>
<p>可以看到在pytorch双向RNN 中的参数：</p>
<ol>
<li>weight ih l0</li>
<li>weight hh l0</li>
<li>bias ih l0</li>
<li>bias hh l0</li>
<li>weight ih l0 reverse</li>
<li>weight hh l0 reverse</li>
<li>bias ih l0</li>
<li>bias hh l0 reverse</li>
</ol>
<p>一共有8个参数，这是因为 <code>forward layer</code>有4个参数，<code>reverse layer</code>也有4个参数</p>
<p>有了这8个参数，就可以把这8个参数传入到双向RNN中</p>
<p>首先把 签名 copy下来：</p>
<p><img alt="image-20241221212723011" src="../images/image-20241221212723011.png" /></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-52-1"><a id="__codelineno-52-1" name="__codelineno-52-1" href="#__codelineno-52-1"></a><span class="n">bidirectional_rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
</span><span id="__span-52-2"><a id="__codelineno-52-2" name="__codelineno-52-2" href="#__codelineno-52-2"></a>                          <span class="n">weight_ih</span><span class="p">,</span>
</span><span id="__span-52-3"><a id="__codelineno-52-3" name="__codelineno-52-3" href="#__codelineno-52-3"></a>                          <span class="n">weight_hh</span><span class="p">,</span>
</span><span id="__span-52-4"><a id="__codelineno-52-4" name="__codelineno-52-4" href="#__codelineno-52-4"></a>                          <span class="n">bias_ih</span><span class="p">,</span>
</span><span id="__span-52-5"><a id="__codelineno-52-5" name="__codelineno-52-5" href="#__codelineno-52-5"></a>                          <span class="n">bias_hh</span><span class="p">,</span>
</span><span id="__span-52-6"><a id="__codelineno-52-6" name="__codelineno-52-6" href="#__codelineno-52-6"></a>                          <span class="n">h_prev</span><span class="p">,</span>
</span><span id="__span-52-7"><a id="__codelineno-52-7" name="__codelineno-52-7" href="#__codelineno-52-7"></a>                          <span class="n">weight_ih_reverse</span><span class="p">,</span>
</span><span id="__span-52-8"><a id="__codelineno-52-8" name="__codelineno-52-8" href="#__codelineno-52-8"></a>                          <span class="n">weight_hh_reverse</span><span class="p">,</span>
</span><span id="__span-52-9"><a id="__codelineno-52-9" name="__codelineno-52-9" href="#__codelineno-52-9"></a>                          <span class="n">bias_ih_reverse</span><span class="p">,</span>
</span><span id="__span-52-10"><a id="__codelineno-52-10" name="__codelineno-52-10" href="#__codelineno-52-10"></a>                          <span class="n">bias_hh_reverse</span><span class="p">,</span>
</span><span id="__span-52-11"><a id="__codelineno-52-11" name="__codelineno-52-11" href="#__codelineno-52-11"></a>                          <span class="n">h_prev_reverse</span><span class="p">)</span>
</span></code></pre></div>
<ul>
<li><code>input</code>不变</li>
<li><code>weight ih</code>改成<code>weight ih l0</code></li>
<li><code>weight hh</code>，同样<code>weight hh l0</code></li>
</ul>
<p>还要加上<code>bi_rnn.</code>，也就是说把实例化的RNN层传进来</p>
<p><code>bi_rnn.bias ih l0</code> </p>
<p><code>bi_rnn.bias hh l0</code></p>
<p><img alt="image-20241221212936350" src="../images/image-20241221212936350.png" /></p>
<p><code>h prev</code>需要注意：是三维的</p>
<p>前面有个 2 ，只需要传入第一个就好了 <code>h prev[0]</code></p>
<p>反向的也是类似的</p>
<p><code>bi_rnn.weight ih l0 reverse</code></p>
<p>后面也是一样 <code>bi_rnn.weight hh l0 reverse</code></p>
<p><code>bi_rnn.bias ih l0 reverse</code> </p>
<p><code>bi_rnn.bias hh l0 reverse</code></p>
<p><code>h prev reverse</code>，用<code>h prev [1]</code></p>
<p><img alt="image-20241221213102881" src="../images/image-20241221213102881.png" /></p>
<p>定义  <code>custom_bi_rnn_output,custom_bi_state_finall</code>接收输出</p>
<p>接下来分别打印api的结果 和 自己写的函数的结果：</p>
<p><img alt="image-20241221213142401" src="../images/image-20241221213142401.png" /></p>
<blockquote>
<p>这个 结果有问题，（后面改了 就是各种翻转 )
</p>
</blockquote>
<p>由于是双向的 <code>hidden size=3</code>，但是输出状态长度是6，这是因为双向的有拼接</p>
<h2 id="_2">汇总所有代码<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<div class="language-python highlight"><pre><span></span><code><span id="__span-53-1"><a id="__codelineno-53-1" name="__codelineno-53-1" href="#__codelineno-53-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-53-2"><a id="__codelineno-53-2" name="__codelineno-53-2" href="#__codelineno-53-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-54-1"><a id="__codelineno-54-1" name="__codelineno-54-1" href="#__codelineno-54-1"></a><span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span>  <span class="c1"># 批大小，输入序列长度</span>
</span><span id="__span-54-2"><a id="__codelineno-54-2" name="__codelineno-54-2" href="#__codelineno-54-2"></a><span class="n">input_size</span><span class="p">,</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span><span class="mi">3</span> <span class="c1"># 输入特征大小，隐含层特征大小</span>
</span><span id="__span-54-3"><a id="__codelineno-54-3" name="__codelineno-54-3" href="#__codelineno-54-3"></a><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">input_size</span><span class="p">)</span>  <span class="c1"># 随机初始化一个输入特征序列</span>
</span><span id="__span-54-4"><a id="__codelineno-54-4" name="__codelineno-54-4" href="#__codelineno-54-4"></a><span class="n">h_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># 初始隐含状态</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-55-1"><a id="__codelineno-55-1" name="__codelineno-55-1" href="#__codelineno-55-1"></a><span class="c1"># step1 调用pytorch RNN API</span>
</span><span id="__span-55-2"><a id="__codelineno-55-2" name="__codelineno-55-2" href="#__codelineno-55-2"></a><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">,</span><span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-55-3"><a id="__codelineno-55-3" name="__codelineno-55-3" href="#__codelineno-55-3"></a><span class="n">rnn_output</span><span class="p">,</span><span class="n">state_finall</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">h_prev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span><span id="__span-55-4"><a id="__codelineno-55-4" name="__codelineno-55-4" href="#__codelineno-55-4"></a>
</span><span id="__span-55-5"><a id="__codelineno-55-5" name="__codelineno-55-5" href="#__codelineno-55-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">rnn_output</span><span class="p">)</span>
</span><span id="__span-55-6"><a id="__codelineno-55-6" name="__codelineno-55-6" href="#__codelineno-55-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">state_finall</span><span class="p">)</span>
</span></code></pre></div>
<p>输出：</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-56-1"><a id="__codelineno-56-1" name="__codelineno-56-1" href="#__codelineno-56-1"></a>tensor([[[-0.7709,  0.7301, -0.9299],
</span><span id="__span-56-2"><a id="__codelineno-56-2" name="__codelineno-56-2" href="#__codelineno-56-2"></a>         [-0.6976, -0.8241, -0.1903],
</span><span id="__span-56-3"><a id="__codelineno-56-3" name="__codelineno-56-3" href="#__codelineno-56-3"></a>         [-0.6485, -0.2633, -0.1093]],
</span><span id="__span-56-4"><a id="__codelineno-56-4" name="__codelineno-56-4" href="#__codelineno-56-4"></a>
</span><span id="__span-56-5"><a id="__codelineno-56-5" name="__codelineno-56-5" href="#__codelineno-56-5"></a>        [[-0.2035,  0.7439, -0.1369],
</span><span id="__span-56-6"><a id="__codelineno-56-6" name="__codelineno-56-6" href="#__codelineno-56-6"></a>         [-0.4805, -0.5790,  0.1787],
</span><span id="__span-56-7"><a id="__codelineno-56-7" name="__codelineno-56-7" href="#__codelineno-56-7"></a>         [-0.6185,  0.4854, -0.4907]]], grad_fn=&lt;TransposeBackward1&gt;)
</span><span id="__span-56-8"><a id="__codelineno-56-8" name="__codelineno-56-8" href="#__codelineno-56-8"></a>tensor([[[-0.6485, -0.2633, -0.1093],
</span><span id="__span-56-9"><a id="__codelineno-56-9" name="__codelineno-56-9" href="#__codelineno-56-9"></a>         [-0.6185,  0.4854, -0.4907]]], grad_fn=&lt;StackBackward0&gt;)
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-57-1"><a id="__codelineno-57-1" name="__codelineno-57-1" href="#__codelineno-57-1"></a><span class="c1"># step2 手写 rnn_forward函数，实现RNN的计算原理</span>
</span><span id="__span-57-2"><a id="__codelineno-57-2" name="__codelineno-57-2" href="#__codelineno-57-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">weight_ih</span><span class="p">,</span><span class="n">weight_hh</span><span class="p">,</span><span class="n">bias_ih</span><span class="p">,</span><span class="n">bias_hh</span><span class="p">,</span><span class="n">h_prev</span><span class="p">):</span>
</span><span id="__span-57-3"><a id="__codelineno-57-3" name="__codelineno-57-3" href="#__codelineno-57-3"></a>    <span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">input_size</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-57-4"><a id="__codelineno-57-4" name="__codelineno-57-4" href="#__codelineno-57-4"></a>    <span class="n">h_dim</span> <span class="o">=</span> <span class="n">weight_ih</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-57-5"><a id="__codelineno-57-5" name="__codelineno-57-5" href="#__codelineno-57-5"></a>    <span class="n">h_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">h_dim</span><span class="p">)</span> <span class="c1"># 初始化一个输出（状态）矩阵</span>
</span><span id="__span-57-6"><a id="__codelineno-57-6" name="__codelineno-57-6" href="#__codelineno-57-6"></a>
</span><span id="__span-57-7"><a id="__codelineno-57-7" name="__codelineno-57-7" href="#__codelineno-57-7"></a>    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
</span><span id="__span-57-8"><a id="__codelineno-57-8" name="__codelineno-57-8" href="#__codelineno-57-8"></a>        <span class="n">x</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[:,</span><span class="n">t</span><span class="p">,:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 获取当前时刻的输入特征，bs*input_size*1</span>
</span><span id="__span-57-9"><a id="__codelineno-57-9" name="__codelineno-57-9" href="#__codelineno-57-9"></a>        <span class="n">w_ih_batch</span> <span class="o">=</span> <span class="n">weight_ih</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># bs * h_dim * input_size</span>
</span><span id="__span-57-10"><a id="__codelineno-57-10" name="__codelineno-57-10" href="#__codelineno-57-10"></a>        <span class="n">w_hh_batch</span> <span class="o">=</span> <span class="n">weight_hh</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="c1"># bs * h_dim * h_dim</span>
</span><span id="__span-57-11"><a id="__codelineno-57-11" name="__codelineno-57-11" href="#__codelineno-57-11"></a>
</span><span id="__span-57-12"><a id="__codelineno-57-12" name="__codelineno-57-12" href="#__codelineno-57-12"></a>        <span class="n">w_times_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">w_ih_batch</span><span class="p">,</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># bs*h_dim</span>
</span><span id="__span-57-13"><a id="__codelineno-57-13" name="__codelineno-57-13" href="#__codelineno-57-13"></a>        <span class="n">w_times_h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">w_hh_batch</span><span class="p">,</span><span class="n">h_prev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># bs*h_him</span>
</span><span id="__span-57-14"><a id="__codelineno-57-14" name="__codelineno-57-14" href="#__codelineno-57-14"></a>        <span class="n">h_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">w_times_x</span> <span class="o">+</span> <span class="n">bias_ih</span> <span class="o">+</span> <span class="n">w_times_h</span> <span class="o">+</span> <span class="n">bias_hh</span><span class="p">)</span>
</span><span id="__span-57-15"><a id="__codelineno-57-15" name="__codelineno-57-15" href="#__codelineno-57-15"></a>
</span><span id="__span-57-16"><a id="__codelineno-57-16" name="__codelineno-57-16" href="#__codelineno-57-16"></a>        <span class="n">h_out</span><span class="p">[:,</span><span class="n">t</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">h_prev</span>
</span><span id="__span-57-17"><a id="__codelineno-57-17" name="__codelineno-57-17" href="#__codelineno-57-17"></a>
</span><span id="__span-57-18"><a id="__codelineno-57-18" name="__codelineno-57-18" href="#__codelineno-57-18"></a>    <span class="k">return</span> <span class="n">h_out</span><span class="p">,</span><span class="n">h_prev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-58-1"><a id="__codelineno-58-1" name="__codelineno-58-1" href="#__codelineno-58-1"></a><span class="c1"># 验证结果</span>
</span><span id="__span-58-2"><a id="__codelineno-58-2" name="__codelineno-58-2" href="#__codelineno-58-2"></a><span class="n">custom_rnn_output</span><span class="p">,</span><span class="n">custom_state_finall</span> <span class="o">=</span> <span class="n">rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
</span><span id="__span-58-3"><a id="__codelineno-58-3" name="__codelineno-58-3" href="#__codelineno-58-3"></a>                                                    <span class="n">rnn</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="p">,</span>
</span><span id="__span-58-4"><a id="__codelineno-58-4" name="__codelineno-58-4" href="#__codelineno-58-4"></a>                                                    <span class="n">rnn</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="p">,</span>
</span><span id="__span-58-5"><a id="__codelineno-58-5" name="__codelineno-58-5" href="#__codelineno-58-5"></a>                                                    <span class="n">rnn</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="p">,</span>
</span><span id="__span-58-6"><a id="__codelineno-58-6" name="__codelineno-58-6" href="#__codelineno-58-6"></a>                                                    <span class="n">rnn</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="p">,</span>
</span><span id="__span-58-7"><a id="__codelineno-58-7" name="__codelineno-58-7" href="#__codelineno-58-7"></a>                                                    <span class="n">h_prev</span><span class="p">)</span>
</span><span id="__span-58-8"><a id="__codelineno-58-8" name="__codelineno-58-8" href="#__codelineno-58-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">custom_rnn_output</span><span class="p">)</span>
</span><span id="__span-58-9"><a id="__codelineno-58-9" name="__codelineno-58-9" href="#__codelineno-58-9"></a><span class="nb">print</span><span class="p">(</span><span class="n">custom_state_finall</span><span class="p">)</span>
</span></code></pre></div>
<p>输出：</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-59-1"><a id="__codelineno-59-1" name="__codelineno-59-1" href="#__codelineno-59-1"></a>tensor([[[-0.7709,  0.7301, -0.9299],
</span><span id="__span-59-2"><a id="__codelineno-59-2" name="__codelineno-59-2" href="#__codelineno-59-2"></a>         [-0.6976, -0.8241, -0.1903],
</span><span id="__span-59-3"><a id="__codelineno-59-3" name="__codelineno-59-3" href="#__codelineno-59-3"></a>         [-0.6485, -0.2633, -0.1093]],
</span><span id="__span-59-4"><a id="__codelineno-59-4" name="__codelineno-59-4" href="#__codelineno-59-4"></a>
</span><span id="__span-59-5"><a id="__codelineno-59-5" name="__codelineno-59-5" href="#__codelineno-59-5"></a>        [[-0.2035,  0.7439, -0.1369],
</span><span id="__span-59-6"><a id="__codelineno-59-6" name="__codelineno-59-6" href="#__codelineno-59-6"></a>         [-0.4805, -0.5790,  0.1787],
</span><span id="__span-59-7"><a id="__codelineno-59-7" name="__codelineno-59-7" href="#__codelineno-59-7"></a>         [-0.6185,  0.4854, -0.4907]]], grad_fn=&lt;CopySlices&gt;)
</span><span id="__span-59-8"><a id="__codelineno-59-8" name="__codelineno-59-8" href="#__codelineno-59-8"></a>tensor([[[-0.6485, -0.2633, -0.1093],
</span><span id="__span-59-9"><a id="__codelineno-59-9" name="__codelineno-59-9" href="#__codelineno-59-9"></a>         [-0.6185,  0.4854, -0.4907]]], grad_fn=&lt;UnsqueezeBackward0&gt;)
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-60-1"><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">rnn_output</span><span class="p">,</span><span class="n">custom_rnn_output</span><span class="p">))</span>
</span><span id="__span-60-2"><a id="__codelineno-60-2" name="__codelineno-60-2" href="#__codelineno-60-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">state_finall</span><span class="p">,</span><span class="n">custom_state_finall</span><span class="p">))</span>
</span></code></pre></div>
<p>输出：True、True</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-61-1"><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a><span class="c1"># step3 手写一个 bidirectional_rnn_forward函数，实现双向RNN的计算原理</span>
</span><span id="__span-61-2"><a id="__codelineno-61-2" name="__codelineno-61-2" href="#__codelineno-61-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">bidirectional_rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
</span><span id="__span-61-3"><a id="__codelineno-61-3" name="__codelineno-61-3" href="#__codelineno-61-3"></a>                              <span class="n">weight_ih</span><span class="p">,</span>
</span><span id="__span-61-4"><a id="__codelineno-61-4" name="__codelineno-61-4" href="#__codelineno-61-4"></a>                              <span class="n">weight_hh</span><span class="p">,</span>
</span><span id="__span-61-5"><a id="__codelineno-61-5" name="__codelineno-61-5" href="#__codelineno-61-5"></a>                              <span class="n">bias_ih</span><span class="p">,</span>
</span><span id="__span-61-6"><a id="__codelineno-61-6" name="__codelineno-61-6" href="#__codelineno-61-6"></a>                              <span class="n">bias_hh</span><span class="p">,</span>
</span><span id="__span-61-7"><a id="__codelineno-61-7" name="__codelineno-61-7" href="#__codelineno-61-7"></a>                              <span class="n">h_prev</span><span class="p">,</span>
</span><span id="__span-61-8"><a id="__codelineno-61-8" name="__codelineno-61-8" href="#__codelineno-61-8"></a>                              <span class="n">weight_ih_reverse</span><span class="p">,</span>
</span><span id="__span-61-9"><a id="__codelineno-61-9" name="__codelineno-61-9" href="#__codelineno-61-9"></a>                              <span class="n">weight_hh_reverse</span><span class="p">,</span>
</span><span id="__span-61-10"><a id="__codelineno-61-10" name="__codelineno-61-10" href="#__codelineno-61-10"></a>                              <span class="n">bias_ih_reverse</span><span class="p">,</span>
</span><span id="__span-61-11"><a id="__codelineno-61-11" name="__codelineno-61-11" href="#__codelineno-61-11"></a>                              <span class="n">bias_hh_reverse</span><span class="p">,</span>
</span><span id="__span-61-12"><a id="__codelineno-61-12" name="__codelineno-61-12" href="#__codelineno-61-12"></a>                              <span class="n">h_prev_reverse</span><span class="p">):</span>
</span><span id="__span-61-13"><a id="__codelineno-61-13" name="__codelineno-61-13" href="#__codelineno-61-13"></a>    <span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">input_size</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-61-14"><a id="__codelineno-61-14" name="__codelineno-61-14" href="#__codelineno-61-14"></a>    <span class="n">h_dim</span> <span class="o">=</span> <span class="n">weight_ih</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-61-15"><a id="__codelineno-61-15" name="__codelineno-61-15" href="#__codelineno-61-15"></a>    <span class="n">h_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">h_dim</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># 初始化一个输出（状态）矩阵，注意双向是两倍的特征大小</span>
</span><span id="__span-61-16"><a id="__codelineno-61-16" name="__codelineno-61-16" href="#__codelineno-61-16"></a>
</span><span id="__span-61-17"><a id="__codelineno-61-17" name="__codelineno-61-17" href="#__codelineno-61-17"></a>    <span class="n">forward_output</span> <span class="o">=</span> <span class="n">rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
</span><span id="__span-61-18"><a id="__codelineno-61-18" name="__codelineno-61-18" href="#__codelineno-61-18"></a>                                 <span class="n">weight_ih</span><span class="p">,</span>
</span><span id="__span-61-19"><a id="__codelineno-61-19" name="__codelineno-61-19" href="#__codelineno-61-19"></a>                                 <span class="n">weight_hh</span><span class="p">,</span>
</span><span id="__span-61-20"><a id="__codelineno-61-20" name="__codelineno-61-20" href="#__codelineno-61-20"></a>                                 <span class="n">bias_ih</span><span class="p">,</span>
</span><span id="__span-61-21"><a id="__codelineno-61-21" name="__codelineno-61-21" href="#__codelineno-61-21"></a>                                 <span class="n">bias_hh</span><span class="p">,</span>
</span><span id="__span-61-22"><a id="__codelineno-61-22" name="__codelineno-61-22" href="#__codelineno-61-22"></a>                                 <span class="n">h_prev</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># forward layer</span>
</span><span id="__span-61-23"><a id="__codelineno-61-23" name="__codelineno-61-23" href="#__codelineno-61-23"></a>    <span class="n">backward_output</span> <span class="o">=</span> <span class="n">rnn_forward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="nb">input</span><span class="p">,[</span><span class="mi">1</span><span class="p">]),</span>
</span><span id="__span-61-24"><a id="__codelineno-61-24" name="__codelineno-61-24" href="#__codelineno-61-24"></a>                                  <span class="n">weight_ih_reverse</span><span class="p">,</span>
</span><span id="__span-61-25"><a id="__codelineno-61-25" name="__codelineno-61-25" href="#__codelineno-61-25"></a>                                  <span class="n">weight_hh_reverse</span><span class="p">,</span>
</span><span id="__span-61-26"><a id="__codelineno-61-26" name="__codelineno-61-26" href="#__codelineno-61-26"></a>                                  <span class="n">bias_ih_reverse</span><span class="p">,</span> 
</span><span id="__span-61-27"><a id="__codelineno-61-27" name="__codelineno-61-27" href="#__codelineno-61-27"></a>                                  <span class="n">bias_hh_reverse</span><span class="p">,</span>
</span><span id="__span-61-28"><a id="__codelineno-61-28" name="__codelineno-61-28" href="#__codelineno-61-28"></a>                                  <span class="n">h_prev_reverse</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># backward layer</span>
</span><span id="__span-61-29"><a id="__codelineno-61-29" name="__codelineno-61-29" href="#__codelineno-61-29"></a>
</span><span id="__span-61-30"><a id="__codelineno-61-30" name="__codelineno-61-30" href="#__codelineno-61-30"></a>    <span class="c1"># 将input按照时间的顺序翻转</span>
</span><span id="__span-61-31"><a id="__codelineno-61-31" name="__codelineno-61-31" href="#__codelineno-61-31"></a>    <span class="n">h_out</span><span class="p">[:,:,:</span><span class="n">h_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">forward_output</span>
</span><span id="__span-61-32"><a id="__codelineno-61-32" name="__codelineno-61-32" href="#__codelineno-61-32"></a>    <span class="n">h_out</span><span class="p">[:,:,</span><span class="n">h_dim</span><span class="p">:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">backward_output</span><span class="p">,[</span><span class="mi">1</span><span class="p">])</span> <span class="c1">#需要再翻转一下 才能和forward output拼接</span>
</span><span id="__span-61-33"><a id="__codelineno-61-33" name="__codelineno-61-33" href="#__codelineno-61-33"></a>
</span><span id="__span-61-34"><a id="__codelineno-61-34" name="__codelineno-61-34" href="#__codelineno-61-34"></a>
</span><span id="__span-61-35"><a id="__codelineno-61-35" name="__codelineno-61-35" href="#__codelineno-61-35"></a>    <span class="n">h_n</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">h_dim</span><span class="p">)</span>  <span class="c1"># 要最后的状态连接</span>
</span><span id="__span-61-36"><a id="__codelineno-61-36" name="__codelineno-61-36" href="#__codelineno-61-36"></a>
</span><span id="__span-61-37"><a id="__codelineno-61-37" name="__codelineno-61-37" href="#__codelineno-61-37"></a>    <span class="n">h_n</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">forward_output</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>
</span><span id="__span-61-38"><a id="__codelineno-61-38" name="__codelineno-61-38" href="#__codelineno-61-38"></a>    <span class="n">h_n</span><span class="p">[:,</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">backward_output</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>
</span><span id="__span-61-39"><a id="__codelineno-61-39" name="__codelineno-61-39" href="#__codelineno-61-39"></a>
</span><span id="__span-61-40"><a id="__codelineno-61-40" name="__codelineno-61-40" href="#__codelineno-61-40"></a>    <span class="n">h_n</span> <span class="o">=</span> <span class="n">h_n</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-61-41"><a id="__codelineno-61-41" name="__codelineno-61-41" href="#__codelineno-61-41"></a>
</span><span id="__span-61-42"><a id="__codelineno-61-42" name="__codelineno-61-42" href="#__codelineno-61-42"></a>    <span class="k">return</span> <span class="n">h_out</span><span class="p">,</span><span class="n">h_n</span>
</span><span id="__span-61-43"><a id="__codelineno-61-43" name="__codelineno-61-43" href="#__codelineno-61-43"></a>    <span class="c1"># return h_out,h_out[:,-1,:].reshape((bs,2,h_dim)).transpose(0,1)</span>
</span><span id="__span-61-44"><a id="__codelineno-61-44" name="__codelineno-61-44" href="#__codelineno-61-44"></a>
</span><span id="__span-61-45"><a id="__codelineno-61-45" name="__codelineno-61-45" href="#__codelineno-61-45"></a><span class="c1"># 验证一下 bidirectional_rnn_forward的正确性</span>
</span><span id="__span-61-46"><a id="__codelineno-61-46" name="__codelineno-61-46" href="#__codelineno-61-46"></a><span class="n">bi_rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">,</span><span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-61-47"><a id="__codelineno-61-47" name="__codelineno-61-47" href="#__codelineno-61-47"></a><span class="n">h_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">))</span>
</span><span id="__span-61-48"><a id="__codelineno-61-48" name="__codelineno-61-48" href="#__codelineno-61-48"></a><span class="n">bi_rnn_output</span><span class="p">,</span><span class="n">bi_state_finall</span> <span class="o">=</span> <span class="n">bi_rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">h_prev</span><span class="p">)</span>
</span><span id="__span-61-49"><a id="__codelineno-61-49" name="__codelineno-61-49" href="#__codelineno-61-49"></a>
</span><span id="__span-61-50"><a id="__codelineno-61-50" name="__codelineno-61-50" href="#__codelineno-61-50"></a><span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">bi_rnn</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span><span id="__span-61-51"><a id="__codelineno-61-51" name="__codelineno-61-51" href="#__codelineno-61-51"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
</span></code></pre></div>
<p>输出</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-62-1"><a id="__codelineno-62-1" name="__codelineno-62-1" href="#__codelineno-62-1"></a>weight_ih_l0 Parameter containing:
</span><span id="__span-62-2"><a id="__codelineno-62-2" name="__codelineno-62-2" href="#__codelineno-62-2"></a>tensor([[ 0.5458,  0.5512],
</span><span id="__span-62-3"><a id="__codelineno-62-3" name="__codelineno-62-3" href="#__codelineno-62-3"></a>        [-0.5077, -0.0750],
</span><span id="__span-62-4"><a id="__codelineno-62-4" name="__codelineno-62-4" href="#__codelineno-62-4"></a>        [ 0.3572,  0.1419]], requires_grad=True)
</span><span id="__span-62-5"><a id="__codelineno-62-5" name="__codelineno-62-5" href="#__codelineno-62-5"></a>weight_hh_l0 Parameter containing:
</span><span id="__span-62-6"><a id="__codelineno-62-6" name="__codelineno-62-6" href="#__codelineno-62-6"></a>tensor([[-0.4093,  0.2012,  0.0746],
</span><span id="__span-62-7"><a id="__codelineno-62-7" name="__codelineno-62-7" href="#__codelineno-62-7"></a>        [-0.5619, -0.3820, -0.4060],
</span><span id="__span-62-8"><a id="__codelineno-62-8" name="__codelineno-62-8" href="#__codelineno-62-8"></a>        [-0.4412,  0.2706, -0.2816]], requires_grad=True)
</span><span id="__span-62-9"><a id="__codelineno-62-9" name="__codelineno-62-9" href="#__codelineno-62-9"></a>bias_ih_l0 Parameter containing:
</span><span id="__span-62-10"><a id="__codelineno-62-10" name="__codelineno-62-10" href="#__codelineno-62-10"></a>tensor([-0.5063, -0.1391, -0.0587], requires_grad=True)
</span><span id="__span-62-11"><a id="__codelineno-62-11" name="__codelineno-62-11" href="#__codelineno-62-11"></a>bias_hh_l0 Parameter containing:
</span><span id="__span-62-12"><a id="__codelineno-62-12" name="__codelineno-62-12" href="#__codelineno-62-12"></a>tensor([ 0.0343, -0.2352,  0.3234], requires_grad=True)
</span><span id="__span-62-13"><a id="__codelineno-62-13" name="__codelineno-62-13" href="#__codelineno-62-13"></a>weight_ih_l0_reverse Parameter containing:
</span><span id="__span-62-14"><a id="__codelineno-62-14" name="__codelineno-62-14" href="#__codelineno-62-14"></a>tensor([[ 0.1298,  0.5538],
</span><span id="__span-62-15"><a id="__codelineno-62-15" name="__codelineno-62-15" href="#__codelineno-62-15"></a>        [ 0.4151,  0.2533],
</span><span id="__span-62-16"><a id="__codelineno-62-16" name="__codelineno-62-16" href="#__codelineno-62-16"></a>        [-0.4401,  0.5322]], requires_grad=True)
</span><span id="__span-62-17"><a id="__codelineno-62-17" name="__codelineno-62-17" href="#__codelineno-62-17"></a>weight_hh_l0_reverse Parameter containing:
</span><span id="__span-62-18"><a id="__codelineno-62-18" name="__codelineno-62-18" href="#__codelineno-62-18"></a>tensor([[-0.4232,  0.2246,  0.4265],
</span><span id="__span-62-19"><a id="__codelineno-62-19" name="__codelineno-62-19" href="#__codelineno-62-19"></a>        [ 0.3016, -0.4142, -0.3064],
</span><span id="__span-62-20"><a id="__codelineno-62-20" name="__codelineno-62-20" href="#__codelineno-62-20"></a>        [-0.1960,  0.2845,  0.3770]], requires_grad=True)
</span><span id="__span-62-21"><a id="__codelineno-62-21" name="__codelineno-62-21" href="#__codelineno-62-21"></a>bias_ih_l0_reverse Parameter containing:
</span><span id="__span-62-22"><a id="__codelineno-62-22" name="__codelineno-62-22" href="#__codelineno-62-22"></a>tensor([-0.4372, -0.2452,  0.4506], requires_grad=True)
</span><span id="__span-62-23"><a id="__codelineno-62-23" name="__codelineno-62-23" href="#__codelineno-62-23"></a>bias_hh_l0_reverse Parameter containing:
</span><span id="__span-62-24"><a id="__codelineno-62-24" name="__codelineno-62-24" href="#__codelineno-62-24"></a>tensor([ 0.3957, -0.4655, -0.2143], requires_grad=True)
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-63-1"><a id="__codelineno-63-1" name="__codelineno-63-1" href="#__codelineno-63-1"></a><span class="n">custom_bi_rnn_output</span><span class="p">,</span><span class="n">custom_bi_state_finall</span> <span class="o">=</span> <span class="n">bidirectional_rnn_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
</span><span id="__span-63-2"><a id="__codelineno-63-2" name="__codelineno-63-2" href="#__codelineno-63-2"></a>                                                                        <span class="n">bi_rnn</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="p">,</span>
</span><span id="__span-63-3"><a id="__codelineno-63-3" name="__codelineno-63-3" href="#__codelineno-63-3"></a>                                                                        <span class="n">bi_rnn</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="p">,</span>
</span><span id="__span-63-4"><a id="__codelineno-63-4" name="__codelineno-63-4" href="#__codelineno-63-4"></a>                                                                        <span class="n">bi_rnn</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="p">,</span>
</span><span id="__span-63-5"><a id="__codelineno-63-5" name="__codelineno-63-5" href="#__codelineno-63-5"></a>                                                                        <span class="n">bi_rnn</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="p">,</span>
</span><span id="__span-63-6"><a id="__codelineno-63-6" name="__codelineno-63-6" href="#__codelineno-63-6"></a>                                                                        <span class="n">h_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
</span><span id="__span-63-7"><a id="__codelineno-63-7" name="__codelineno-63-7" href="#__codelineno-63-7"></a>                                                                        <span class="n">bi_rnn</span><span class="o">.</span><span class="n">weight_ih_l0_reverse</span><span class="p">,</span>
</span><span id="__span-63-8"><a id="__codelineno-63-8" name="__codelineno-63-8" href="#__codelineno-63-8"></a>                                                                        <span class="n">bi_rnn</span><span class="o">.</span><span class="n">weight_hh_l0_reverse</span><span class="p">,</span>
</span><span id="__span-63-9"><a id="__codelineno-63-9" name="__codelineno-63-9" href="#__codelineno-63-9"></a>                                                                        <span class="n">bi_rnn</span><span class="o">.</span><span class="n">bias_ih_l0_reverse</span><span class="p">,</span>
</span><span id="__span-63-10"><a id="__codelineno-63-10" name="__codelineno-63-10" href="#__codelineno-63-10"></a>                                                                        <span class="n">bi_rnn</span><span class="o">.</span><span class="n">bias_hh_l0_reverse</span><span class="p">,</span>
</span><span id="__span-63-11"><a id="__codelineno-63-11" name="__codelineno-63-11" href="#__codelineno-63-11"></a>                                                                        <span class="n">h_prev</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-64-1"><a id="__codelineno-64-1" name="__codelineno-64-1" href="#__codelineno-64-1"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch API output&quot;</span><span class="p">)</span>
</span><span id="__span-64-2"><a id="__codelineno-64-2" name="__codelineno-64-2" href="#__codelineno-64-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">bi_rnn_output</span><span class="p">)</span>
</span><span id="__span-64-3"><a id="__codelineno-64-3" name="__codelineno-64-3" href="#__codelineno-64-3"></a><span class="nb">print</span><span class="p">(</span><span class="n">bi_state_finall</span><span class="p">)</span>
</span><span id="__span-64-4"><a id="__codelineno-64-4" name="__codelineno-64-4" href="#__codelineno-64-4"></a>
</span><span id="__span-64-5"><a id="__codelineno-64-5" name="__codelineno-64-5" href="#__codelineno-64-5"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> custom bidirectional_rnn_forward function output:&quot;</span><span class="p">)</span>
</span><span id="__span-64-6"><a id="__codelineno-64-6" name="__codelineno-64-6" href="#__codelineno-64-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">custom_bi_rnn_output</span><span class="p">)</span>
</span><span id="__span-64-7"><a id="__codelineno-64-7" name="__codelineno-64-7" href="#__codelineno-64-7"></a><span class="nb">print</span><span class="p">(</span><span class="n">custom_bi_state_finall</span><span class="p">)</span>
</span><span id="__span-64-8"><a id="__codelineno-64-8" name="__codelineno-64-8" href="#__codelineno-64-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">bi_rnn_output</span><span class="p">,</span><span class="n">custom_bi_rnn_output</span><span class="p">))</span>
</span><span id="__span-64-9"><a id="__codelineno-64-9" name="__codelineno-64-9" href="#__codelineno-64-9"></a><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">bi_state_finall</span><span class="p">,</span><span class="n">custom_bi_state_finall</span><span class="p">))</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-65-1"><a id="__codelineno-65-1" name="__codelineno-65-1" href="#__codelineno-65-1"></a>True
</span><span id="__span-65-2"><a id="__codelineno-65-2" name="__codelineno-65-2" href="#__codelineno-65-2"></a>True
</span></code></pre></div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="2024年12月21日 14:57:34"><span class="timeago" datetime="2024-12-21T14:57:34+00:00" locale="zh"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="2024年12月21日 14:57:34">2024-12-21</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="2024年12月20日 14:49:27"><span class="timeago" datetime="2024-12-20T14:49:27+00:00" locale="zh"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="2024年12月20日 14:49:27">2024-12-20</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["toc.follow", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../js/timeago.min.js"></script>
      
        <script src="../../js/timeago_mkdocs_material.js"></script>
      
        <script src="../../mkdocs/javascripts/katex.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>