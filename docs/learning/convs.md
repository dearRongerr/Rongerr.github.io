# å·ç§¯



- [x] è½¬ç½®å·ç§¯ã€åå·ç§¯
- [x] åˆ†ç»„å·ç§¯ã€æ·±åº¦å¯åˆ†ç¦»å·ç§¯
- [x] 1Ã—1å·ç§¯ã€é€ç‚¹å·ç§¯
- [x] è†¨èƒ€å·ç§¯ã€ç©ºæ´å·ç§¯å·ç§¯
- [ ] å¯å˜å½¢å·ç§¯
- [ ] å¤§æ ¸å·ç§¯
- [x] 1D å·ç§¯





![image-20241125105147313](images/image-20241125105147313.png)



## 1 åº“å‡½æ•°å®ç°å·ç§¯

- ç±»ï¼š`torch.nn.Conv2d`
- å‡½æ•°ï¼š`F.conv2d`  or `torch.nn.functional.conv2d`

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

in_channels = 1
out_channels = 1
kernel_size = 3
batch_size = 1
bias = False

input_size = [batch_size,in_channels,4,4]

# ç¬¬ä¸€ç§å®ç°
conv_layer = torch.nn.Conv2d(in_channels,out_channels,kernel_size,bias=bias)

input_feature_map = torch.randn(input_size)
out_feature_map = conv_layer(input_feature_map)
# print(input_feature_map)
# print(conv_layer.weight)  # 1*1*3*3=out_channels*in_channels*height*width

print(out_feature_map)

out_feature_map1 = F.conv2d(input_feature_map,conv_layer.weight)

print(out_feature_map1)
```

### é¦–å…ˆçœ‹ä¸€ä¸‹ äºŒç»´å·ç§¯çš„api

> ![image-20241125105756485](images/image-20241125105756485.png)

è°·æ­Œæœç´¢ pytorch conv2dï¼Œå‡ºç°ä¸¤ä¸ªapi ï¼š

- ä¸€ä¸ªæ˜¯å¤§å†™çš„äºŒç»´å·ç§¯ã€ class
- ä¸€ä¸ªæ˜¯ torch.nn.functional.conv2då°å†™çš„äºŒç»´å·ç§¯ã€å‡½æ•°

åŒºåˆ«ï¼š

> - ï¼ˆç¬¬ä¸€ä¸ªåŒºåˆ«ï¼‰
>
>   - ç¬¬ä¸€ä¸ªå¤§å†™çš„æ˜¯ä¸€ä¸ªclassï¼Œå¦‚æœæˆ‘ä»¬è¦ç”¨ç¬¬ä¸€ä¸ªçš„è¯ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å¯¹è¿™ä¸ªclassè¿›è¡Œä¸€ä¸ªå®ä¾‹åŒ–ï¼Œç„¶åå¯¹å®ä¾‹åŒ–çš„å¯¹è±¡ï¼Œå†å¯¹è¾“å…¥ç‰¹å¾å›¾è¿›è¡Œä¸€ä¸ªå·ç§¯ æ“ä½œï¼›  
>
>   - ç¬¬äºŒä¸ªæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œä¸éœ€è¦å®ä¾‹åŒ–ï¼Œå°±ç›´æ¥æ¥æ”¶ä¸€ä¸ªè¾“å…¥ç‰¹å¾å›¾ï¼Œç›´æ¥è¿›è¡Œä¸€ä¸ªå·ç§¯æ“ä½œï¼›ä»¥ä¸Šæ˜¯ç¬¬ä¸€ä¸ªåŒºåˆ«ï¼› 
>
> - ï¼ˆç¬¬äºŒä¸ªåŒºåˆ«ï¼‰
>   - classå¯ä»¥è‡ªå·±å»åˆ›å»ºæ“ä½œï¼ŒåŒ…æ‹¬weightå’Œbiasï¼Œå¯ä»¥è‡ªåŠ¨å»åˆ›å»ºï¼Œå°±ä¸éœ€è¦æ‰‹åŠ¨åˆ›å»ºï¼›
>   - å¯¹äºå‡½æ•°æ¥è¯´ï¼Œ éœ€è¦æ‰‹åŠ¨çš„ä¼ å…¥weightå’Œbiasï¼›

### CONV2D

![image-20241125120445236](images/image-20241125120445236.png)

- è°ƒç”¨ï¼štorch.nn.Conv2d
- éœ€è¦ä¼ å…¥çš„å‚æ•°ï¼š
  - è¾“å…¥é€šé“
  - è¾“å‡ºé€šé“
  - kernelçš„å¤§å°
  - æ­¥é•¿
  - paddingå¡«å……
  - è†¨èƒ€dilation
  - group

- åŒºåˆ† å·ç§¯ & å…¨è¿æ¥ï¼š

  > ç¥ç»ç½‘ç»œæœ€æ ¸å¿ƒçš„ä¸€ä¸ªæ“ä½œï¼šä»¿å°„å˜æ¢ï¼šå°†ä¸€ä¸ªçŸ©é˜µ ä¹˜ä»¥ è¾“å…¥å‘é‡ å¾—åˆ° å¦å¤–ä¸€ä¸ªå‘é‡ã€‚è¿™æ˜¯å…¨è¿æ¥ç½‘ç»œçš„ä¸€ä¸ªåšæ³•ï¼Œ æ‰€ä»¥æˆ‘ä»¬ä¸€èˆ¬ä¼šå¯¹ä¸€ä¸ªå‘é‡ åšå…¨è¿æ¥çš„ç½‘ç»œ çš„è¾“å…¥ï¼›æ¯”æ–¹è¯´ï¼šä¸€ä¸ªword embeddingå‘é‡ï¼›æ¯”æ–¹è¯´ è¦é¢„æµ‹æˆ¿ä»·ï¼ŒåŸå¸‚çš„äººå£è¿˜æœ‰ç‰©ä»·ç­‰ï¼Œä¸åŒçš„æµ®ç‚¹æ•° ç»„æˆçš„å‘é‡ï¼Œè¿™äº›éƒ½å¯ä»¥é€å…¥ å…¨è¿æ¥ç½‘ç»œã€‚
  >
  > 
  >
  > æ‰€ä»¥å…¨è¿æ¥ç½‘ç»œ æ˜¯æŠŠ è¾“å…¥å½“æˆä¸€ä¸ªå‘é‡ï¼Œç„¶åç»Ÿä¸€çš„å»ä¹˜ ä¸€ä¸ªçŸ©é˜µï¼Œè¿›è¡Œæ“ä½œã€‚ä½†æ˜¯ï¼Œè¿˜æœ‰å¾ˆå¤šå…¶ä»–ä¸œè¥¿ï¼Œä¸èƒ½ä»…ä»…ä½¿ç”¨ä¸€ä¸ªå‘é‡æ¥è¿›è¡Œåˆ»ç”»ï¼Œæ¯”å¦‚å›¾åƒæœ‰é•¿åº¦å’Œå®½åº¦ï¼Œæ˜¯ä¸€ä¸ªäºŒç»´çš„ï¼Œè¿˜æœ‰RGBä¸‰ä¸ªé€šé“ï¼Œè¿™äº› æˆ‘ä»¬ä¸èƒ½ä»…ä»…åªæ˜¯æŠŠå›¾ç‰‡æ‹‰ç›´å¤„ç†ï¼Œè¿™æ ·ç ´åäº†å›¾ç‰‡çš„ç©ºé—´ç»“æ„ï¼›
  >
  > 
  >
  > ç±»ä¼¼çš„è¿˜æœ‰è¯­éŸ³ï¼Œè¯­è¨€æœ‰æ—¶é—´ç»´è¿˜æœ‰é¢‘ç‡ç»´ï¼Œæˆ‘ä»¬æ¯ä¸ªæ—¶åˆ»å‘å‡ºçš„å£°éŸ³ï¼Œ æ˜¯ç”±ä¸åŒçš„é¢‘ç‡ç»„åˆçš„ï¼ŒåŒæ ·å¯¹äºè¯­éŸ³è¿™ç§ä¿¡å·ï¼Œæˆ‘ä»¬ä¹Ÿä¸èƒ½ä»…ä»…æ˜¯ å½“æˆ ä¸€ç»´ä¿¡å·å¤„ç†ï¼Œç”šè‡³æ›´å¤æ‚çš„æ˜¯ å›¾åƒå’Œè¯­éŸ³ä¿¡å·çš„ç»“åˆï¼Œæ¯”å¦‚è§†é¢‘ã€‚æ‰€ä»¥å¯¹äºè¿™äº›æˆ‘ä»¬ä¸èƒ½ä»…ä»…åªæ˜¯å½“æˆä¸€ä¸ªå‘é‡å¤„ç†ï¼Œè¿™æ ·çš„è¯ï¼Œå…¨è¿æ¥ç½‘ç»œä¹Ÿå°±æ— æ³•åˆ»ç”»å®ƒï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å·ç§¯ç½‘ç»œåˆ»ç”»ï¼Œå¯¹äºå·ç§¯ç½‘ç»œ å’Œ å“ªäº›æ“ä½œ æ¯”è¾ƒç›¸å…³å‘¢ï¼Ÿå°±æ˜¯äº’ç›¸å…³ï¼Œå¦‚æœå­¦è¿‡ä¿¡å·ä¸ç³»ç»Ÿçš„è¯ï¼Œäº’ç›¸å…³å°±æ˜¯ å¯¹äºä¸¤ä¸ªä¸€ç»´å‘é‡ï¼Œæˆ‘ä»¬æŠŠä¸€ä¸ªä¸€ç»´ä¿¡å· æ²¿ç€ å¦å¤–ä¸€ä¸ªä¸€ç»´ä¿¡å·ï¼Œä¸æ–­åœ°è¿›è¡Œ æ»‘åŠ¨ç›¸ä¹˜çš„æ“ä½œï¼Œç„¶åè®¡ç®— ä¸€ä¸ªç›¸å…³ç³»æ•°ã€‚å·ç§¯ä¹Ÿæ˜¯ç±»ä¼¼çš„ï¼Œå¯¹äºä¸€å¼ å›¾ç‰‡ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªå·ç§¯æ ¸çš„è¯ï¼Œå«åškernelï¼Œæˆ‘ä»¬ä¼šæŠŠ kernel æ²¿ç€ å›¾ç‰‡çš„ä¸åŒåŒºåŸŸ è¿›è¡Œä¸€ä¸ªæ»‘åŠ¨ç›¸ä¹˜ï¼Œæ¥å¾—åˆ°ä¸€ä¸ªç‰¹å¾çš„è¡¨ç¤º


- æ•°å­¦ä¾‹å­ï¼š

  > ![image-20241125135101570](images/image-20241125135101570.png)
  >
  > - å‡è®¾æˆ‘ä»¬çš„input feature map=4Ã—4ï¼Œkernel=3Ã—3ï¼Œå·ç§¯æ“ä½œå°±æ˜¯å°†kernelåœ¨å›¾ç‰‡ä¸Š ä¸åŒä½ç½®å…ƒç´ ç›¸ä¹˜ element-wiseï¼Œä¸åŒä½ç½®å…ƒç´ ç›¸ä¹˜å†ç›¸åŠ ï¼Œå¾—åˆ°è¾“å‡ºï¼›
  > - k=3ï¼Œp=0ï¼Œs=1
  > - kernelçš„ç§»åŠ¨è½¨è¿¹æ˜¯Zå­—å‹çš„ï¼Œä»å·¦åˆ°å³ï¼Œä»ä¸Šåˆ°ä¸‹
  > - è¾“å…¥input future mapçš„å¤§å°æ˜¯4Ã—4çš„ï¼Œè€Œä¸” channel=1ï¼Œå†ç”¨ä¸€ä¸ª3Ã—3çš„kernelï¼Œä¸è¾“å…¥ç‰¹å¾å›¾ è¿›è¡Œå·ç§¯æ“ä½œï¼Œå¾—åˆ°outputï¼Œå¹¶ä¸”outputå¤§å° 2Ã—2ï¼Œchannel=1ï¼ŒåŒæ—¶è¿™é‡Œæˆ‘ä»¬è®¾ç½®çš„bias=Falseï¼Œä¸åŠ  biasï¼›
  > - å¦‚æœæˆ‘ä»¬åŠ å…¥ biaså‘¢ï¼Ÿ
  >   - å¦‚æœ channel=1ï¼Œé‚£ä¹ˆ biaså°±æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œç›´æ¥ç›¸åŠ å°±å¥½äº†ï¼Œè¿™å°±æ˜¯ä¸€ä¸ª biasçš„æ“ä½œ
  > - å¦‚æœ è¾“å…¥çš„é€šé“æ•°ä¸æ­¢æ˜¯1å‘¢ï¼Ÿæ¯”å¦‚ä¸¤ä¸ªé€šé“ï¼Œè¿™ä¸ªæ—¶å€™ å°±ä¼šæœ‰ä¸¤ä¸ªkernelï¼Œç¬¬ä¸€ä¸ªkernelå¾—åˆ°y1 y2 y3 y4ï¼›ç¬¬äºŒä¸ªkernelåˆä¼šå¾—åˆ°ä¸€ä¸ªy1ï¼Œy2,y3,y4,ç„¶åæˆ‘ä»¬å†æŠŠä¸¤ä¸ªkernelå¾—åˆ°çš„è¾“å‡º å†è¿›è¡Œä¸€ä¸ªç‚¹å¯¹ç‚¹çš„è¾“å‡ºï¼Œè¿™æ ·å¾—åˆ° æœ€ç»ˆçš„outputï¼Œè¿™æ˜¯å¯¹è¾“å…¥ç‰¹å¾å›¾æœ‰å¤šä¸ªé€šé“çš„æƒ…å†µã€‚ï¼ˆæ¢ä¸€ç§è¯´æ³•ï¼šè¾“å…¥é€šé“çš„channelæœ‰å‡ ä¸ªï¼Œkernelçš„channelå°±æœ‰å‡ ä¸ªï¼‰
  > - é‚£å¦‚æœæˆ‘ä»¬ è¾“å‡º ç‰¹å¾å›¾ ä¹Ÿæœ‰å¤šä¸ªé€šé“çš„æƒ…å†µ ä¼šæ€ä¹ˆå¤„ç†å‘¢ï¼Ÿ åˆšåˆš æˆ‘ä»¬å¾—åˆ°äº†ç¬¬ä¸€ä¸ªé€šé“ï¼Œå¯¹äºç¬¬äºŒä¸ªé€šé“ï¼Œæˆ‘ä»¬åŒæ · åœ¨å¦å¤–åˆ›é€  ä¸åŒçš„kernelï¼Œå¯¹è¾“å…¥è¿›è¡Œä¸€ä¸ªå·ç§¯æ“ä½œï¼Œæœ€åæŠŠ è¾“å…¥çš„é€šé“ åŠ èµ·æ¥ï¼Œå˜æˆ è¾“å‡º é€šé“çš„ç¬¬äºŒä¸ªè¾“å‡ºï¼ˆè¿˜æ˜¯ç†è§£ä¸ºï¼šæœ‰å‡ ä¸ªkernelå°±æœ‰å‡ ä¸ªè¾“å‡ºï¼›kernelçš„é€šé“æ•°ç”±è¾“å…¥çš„é€šé“æ•°å†³å®šï¼‰

ä»¥ä¸Šæ˜¯æ‰€æœ‰ å·ç§¯çš„è¿‡ç¨‹ï¼š

- æœ‰å‡ ä¸ªå·ç§¯æ ¸ å°±æœ‰å‡ ä¸ª è¾“å‡ºé€šé“ï¼›
- å•ä¸ªå·ç§¯æ ¸çš„é€šé“æ•° å–å†³äº è¾“å…¥ç‰¹å¾å›¾çš„é€šé“æ•°

- æˆ‘ä»¬å°† 3Ã—3çš„kernelï¼Œåœ¨è¾“å…¥çš„ç‰¹å¾å›¾ä¸Š è¿›è¡Œä¸€ä¸ªZå­—å‹çš„æ»‘åŠ¨ç›¸ä¹˜çš„æ“ä½œ
  -  ==ï¼ˆæ‹‰ç›´æ»‘åŠ¨è¾“å…¥åŒºåŸŸï¼‰==å…¶å®è¿™é‡Œçš„æ»‘åŠ¨ç›¸ä¹˜ å¯ä»¥ç†è§£ä¸º å¦‚æœæŠŠè¾“å…¥çš„ç‰¹å¾å›¾ï¼ˆè¢«å·ç§¯æ ¸è¦†ç›–çš„åŒºåŸŸï¼‰3Ã—3çš„åŒºåŸŸ æ‹‰æˆä¸€ä¸ªå‘é‡çš„è¯ ç„¶åæˆ‘ä»¬æŠŠkernelä¹Ÿæ‹‰æˆä¸€ä¸ªå‘é‡ï¼Œå…¶å®å°±æ˜¯è®¡ç®— ä¸¤ä¸ªå‘é‡çš„ ä¸€ä¸ªå†…ç§¯ã€‚å†…ç§¯è¶Šå¤§ ä¸¤ä¸ªå‘é‡ è¶Šç›¸ä¼¼ã€‚
- æ‰€ä»¥å·ç§¯ç½‘ç»œ å­¦ä¹ çš„æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿå·ç§¯ç½‘ç»œ ä¼š ä¸æ–­çš„æ›´æ–° kernelå’Œ biasã€‚å°±æ˜¯ä¸ºäº†å­¦åˆ°ï¼š
  - æ¯”æ–¹è¯´ äººè„¸è¯†åˆ«ï¼Œå°±å¸Œæœ›kernelèƒ½å¤Ÿå­¦åˆ° èƒ½å¤Ÿåæ˜ äººè„¸çš„ ç‰¹å¾ï¼Œç„¶åæŠŠkernelå¯¹å›¾ç‰‡çš„ä¸åŒåŒºåŸŸï¼Œè¿›è¡Œæ¯”å¯¹ï¼Œå¦‚æœåˆšå¥½å‘ç°ï¼Œå›¾ç‰‡çš„æŸä¸€ä¸ªåŒºåŸŸåˆšå¥½ä¸äººè„¸çš„kernelå¾ˆç›¸ä¼¼çš„è¯ï¼Œé‚£å°±è¯´æ˜ä½ ç»™æˆ‘ä»¬å·²ç»æ‰¾åˆ°äººè„¸äº†ï¼Œæ€»ä¹‹å·ç§¯ç¥ç»ç½‘ç»œæ˜¯ ç»™å®šä¸€ä¸ªç›®æ ‡ ä¸æ–­çš„å­¦ä¹ kernelï¼Œæœ€ç»ˆå¸Œæœ›kernelï¼Œèƒ½å¤Ÿè·Ÿå›¾ç‰‡çš„æŸä¸€ä¸ªåŒºåŸŸï¼Œç›¸ä¼¼åº¦è¾¾åˆ°ä¸€ä¸ªæ¯”è¾ƒé«˜çš„å€¼ï¼Œå¾—åˆ°ä¸€ä¸ªæ¯”è¾ƒå¥½çš„ç‰¹å¾ï¼Œç„¶åå†ä¸æ–­çš„å¾€ æ·±å±‚å»ä¼ 

ä½¿ç”¨apiçš„æ—¶å€™ï¼Œéœ€è¦æ³¨æ„ğŸ“¢

-  Conv2dé»˜è®¤è¾“å…¥æ˜¯4ç»´çš„ï¼Œç¬¬ä¸€ç»´æ˜¯batch sizeç»´ï¼Œæˆ‘ä»¬è®¾ç½®batch size=1ï¼Œå¹¶æ·»åŠ åˆ°input_sizeå³å¯;

- input feature mapçš„å½¢çŠ¶ï¼š**batch size Ã— é€šé“æ•° Ã— é«˜ Ã— å®½** å¯ä»¥æŸ¥çœ‹å®˜ç½‘ æ‰¾åˆ°éœ€è¦çš„è¾“å…¥å½¢çŠ¶

  > ![image-20241125140243598](images/image-20241125140243598.png)

- å¹¶ä¸”æ‰“å° å·ç§¯å±‚çš„ weightï¼Œä¹Ÿå°±æ˜¯kernelï¼Œè¿˜å¯ä»¥æ‰“å°è¾“å…¥å’Œè¾“å‡º

  > ![image-20241125140007045](images/image-20241125140007045.png)
  >
  > > - è¾“å‡ºä¸‰ä¸ªå¼ é‡ ç¬¬ä¸€ä¸ªæ˜¯ è¾“å…¥ç‰¹å¾å›¾ã€ç¬¬äºŒä¸ªæ˜¯å·ç§¯çš„weightã€æˆ–è€…kernelï¼Œç¬¬ä¸‰ä¸ªæ˜¯ å·ç§¯çš„è¾“å‡º
  > >
  > > - è¾“å‡ºçš„å¤§å°æ˜¯ 1Ã—1Ã—4çš„ï¼›
  > >
  > > - kernelæ˜¯1Ã—1Ã—3Ã—3 æƒé‡å°±æ˜¯out channelÃ— input channelÃ—heightÃ—width
  > >
  > > > ä¹Ÿå°±æ˜¯è¯´ å¯¹äº äºŒç»´å·ç§¯ï¼Œweightæ˜¯4ç»´çš„ï¼Œé‚£ä¹ˆæ€»çš„æ•°ç›® ç­‰äº è¾“å‡ºé€šé“æ•°Ã—è¾“å…¥é€šé“æ•°Ã—å·ç§¯æ ¸çš„é«˜åº¦Ã—å·ç§¯æ ¸çš„å®½åº¦ï¼Œå¦‚æœæˆ‘ä»¬è®¤ä¸º å·ç§¯æ ¸æ˜¯ä¸€ä¸ªäºŒç»´çš„å›¾ç‰‡çš„è¯ï¼Œé‚£ä¹ˆä¸€å…±æœ‰ è¾“å…¥é€šé“æ•° Ã— è¾“å‡ºé€šé“æ•° è¿™ä¹ˆå¤šä¸ª  å·ç§¯æ ¸å›¾ç‰‡



- torch.nn.Conv2d(class çš„api)

-  functionalçš„api(å‡½æ•°çš„api)

  > ![image-20241125140339530](images/image-20241125140339530.png)

å¯¹äºè¿™ä¸ªapi æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨çš„æŒ‡å®š weight å’Œ biasï¼Œä¸ºäº†éªŒè¯ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥æŠŠåˆšåˆšçš„weightä¼ å…¥ï¼Œå¯ä»¥çœ‹åˆ° ç»“æœæ˜¯ä¸€æ ·çš„:

```python
output_feature_map1 = F.conv2d(input_feature_map,conv_layer.weight)
```

- kernelå°±æ˜¯åœ¨è®­ç»ƒä¸­ï¼Œä¸æ–­æ›´æ–°çš„

## 2 æ‰‹æ’•æ™®é€šå·ç§¯

ä»ä¸¤ç§è§’åº¦çœ‹å·ç§¯ï¼š

- æŠŠå·ç§¯çœ‹æˆæ˜¯ é¦–å…ˆå¯¹è¾“å…¥ç‰¹å¾å›¾è¿›è¡Œå±•å¼€ï¼Œç„¶åå†è¿›è¡ŒçŸ©é˜µçš„ç›¸ä¹˜ï¼›
- å¯¹kernelæˆ–è€…filterè¿›è¡Œå±•å¼€ï¼Œç„¶åå†è¿›è¡ŒçŸ©é˜µç›¸ä¹˜ï¼›

> - æœ‰äº†è¿™ç§æ–¹æ³• å¯ä»¥é¡ºå…¶è‡ªç„¶çš„å¼•å‡º è½¬ç½®å·ç§¯ï¼›ä¹‹åä¼šè®² è½¬ç½®å·ç§¯ ä¹Ÿç§°ä¸ºåå·ç§¯ï¼Œä½†æ˜¯åå·ç§¯çš„è¯´æ³•ä¸å¤ªå‡†ç¡®ï¼Œå› ä¸º è½¬ç½®å·ç§¯è™½ç„¶è¯´æ˜¯ä¸Šé‡‡æ ·ï¼Œä½†æ˜¯ä¸èƒ½ä»outputå»æ¢å¤inputï¼Œè½¬ç½®å·ç§¯ æ¢å¤çš„åªæ˜¯ inputçš„å½¢çŠ¶ï¼Œä¸æ˜¯inputçš„å…ƒç´ å€¼
> - æ›´å‡†ç¡®çš„å®šä¹‰ å°±æ˜¯è½¬ç½®å·ç§¯ï¼›ä¸ºä»€ä¹ˆå«è½¬ç½®å·ç§¯å‘¢ï¼Ÿå†è¯´å®Œ å¯¹kernel è¿›è¡Œå±•å¼€ï¼Œå†è¿›è¡ŒçŸ©é˜µç›¸ä¹˜ å°±æ˜ç™½äº†
> - å½“æˆ‘ä»¬æŠŠå¸¸è§„çš„å·ç§¯ çœ‹æˆæ˜¯å¯¹kernelçš„å±•å¼€ï¼Œç„¶åå†çŸ©é˜µç›¸ä¹˜çš„è¯ï¼Œé‚£ä¹ˆè½¬ç½®å·ç§¯å¯ä»¥çœ‹æˆ å°†kernelè¿›è¡Œä¸€ä¸ª è½¬ç½®æ“ä½œï¼Œç„¶åå†è¿›è¡ŒçŸ©é˜µç›¸ä¹˜ï¼Œå°±èƒ½å¾—åˆ°è½¬ç½®å·ç§¯çš„è¾“å‡º

```python
input = torch.randn(5,5) # å·ç§¯ è¾“å…¥ç‰¹å¾å›¾
kernel = torch.randn(3,3) # å·ç§¯æ ¸
bias = torch.randn(1) # å·ç§¯åç½®ï¼Œé»˜è®¤è¾“å‡ºé€šé“æ•°ç›®ç­‰äº1

# step1 ç”¨åŸå§‹çš„çŸ©é˜µè¿ç®—æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå…ˆä¸è€ƒè™‘ batch sizeç»´åº¦ å’Œ channelç»´åº¦
def matrix_multiplication_for_conv2d(input,kernel,bias=0,stride=1,padding=0):

  if padding >0:
    input = F.pad(input,(padding,padding,padding,padding))


  input_h,input_w = input.shape
  kernel_h,kernel_w = kernel.shape
  
  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„é«˜åº¦
  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„å®½åº¦ 
  output = torch.zeros(output_h,output_w) # åˆå§‹åŒ– è¾“å‡ºçŸ©é˜µ
  
  for i in range(0,input_h - kernel_h + 1,stride): # å¯¹é«˜åº¦è¿›è¡Œéå†
    for j in range(0,input_w - kernel_w +1,stride):  # å¯¹å®½åº¦ç»´è¿›è¡Œéå†
      region = input[i:i+kernel_h, j:j+kernel_w]  # å–å‡ºè¢«æ ¸æ»‘åŠ¨åˆ°çš„åŒºåŸŸ
      output[int(i/stride),int(j/stride)] = torch.sum(region * kernel) + bias # ç‚¹ä¹˜ å¹¶èµ‹å€¼ç»™è¾“å‡ºä½ç½®çš„å…ƒç´  
  
  return output


# step2 ç”¨åŸå§‹çš„çŸ©é˜µè¿ç®—æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå…ˆä¸è€ƒè™‘ batch sizeç»´åº¦ å’Œ channelç»´åº¦ï¼Œflattenç‰ˆæœ¬
def matrix_multiplication_for_conv2d_flatten(input,kernel,bias=0,stride=1,padding=0):

  if padding >0:
    input = F.pad(input,(padding,padding,padding,padding))


  input_h,input_w = input.shape
  kernel_h,kernel_w = kernel.shape
  
  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„é«˜åº¦
  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„å®½åº¦ 
  output = torch.zeros(output_h,output_w) # åˆå§‹åŒ– è¾“å‡ºçŸ©é˜µ
  
  region_matrix = torch.zeros(output.numel(),kernel.numel()) #å­˜å‚¨ç€æ‰€æœ‰æ‹‰å¹³åç‰¹å¾åŒºåŸŸ
  kernel_matrix = kernel.reshape(kernel.numel(),1) # å­˜å‚¨ç€kernelçš„ åˆ—å‘é‡ï¼ˆçŸ©é˜µï¼‰å½¢å¼
  row_index = 0

  for i in range(0,input_h - kernel_h + 1,stride): # å¯¹é«˜åº¦è¿›è¡Œéå†
    for j in range(0,input_w - kernel_w +1,stride):  # å¯¹å®½åº¦ç»´è¿›è¡Œéå†
      region = input[i:i+kernel_h, j:j+kernel_w]  # å–å‡ºè¢«æ ¸æ»‘åŠ¨åˆ°çš„åŒºåŸŸ
      region_vector = torch.flatten(region)
      region_matrix[row_index] = region_vector
      row_index +=1

  output_matrix = region_matrix @ kernel_matrix
  output = output_matrix.reshape((output_h,output_w))+bias

  return output


# çŸ©é˜µè¿ç®—å®ç°å·ç§¯çš„ç»“æœ
mat_mul_conv_output = matrix_multiplication_for_conv2d(input,kernel,bias = bias,stride=2,padding=1)
# print(mat_mul_conv_output)

# è°ƒç”¨pytorch apiå·ç§¯çš„ç»“æœ
pytorch_api_conv_output = F.conv2d(input.reshape((1,1,input.shape[0],input.shape[1])),
                                   kernel.reshape((1,1,kernel.shape[0],kernel.shape[1])),
                                   padding=1,bias=bias,stride=2).squeeze(0).squeeze(0)

# çŸ©é˜µè¿ç®—å®ç°å·ç§¯çš„ç»“æœ flatten inputç‰ˆæœ¬
mat_mul_conv_output_flatten = matrix_multiplication_for_conv2d_flatten(input,kernel,bias = bias,stride=2,padding=1)
# éªŒè¯äº† flattenç‰ˆæœ¬å·ç§¯ ä¸ pytorch å®˜æ–¹å·ç§¯çš„ç»“æœï¼Œæ­£ç¡®
flag1 = torch.allclose(mat_mul_conv_output,pytorch_api_conv_output)
flag2 = torch.allclose(mat_mul_conv_output_flatten,pytorch_api_conv_output)
print(flag1)
print(flag2)
```



```python
# step3 ç”¨åŸå§‹çš„çŸ©é˜µè¿ç®—æ¥å®ç°äºŒç»´å·ç§¯ï¼Œè€ƒè™‘ batch sizeç»´åº¦ å’Œ channelç»´åº¦
def matrix_multiplication_for_conv2d_full(input,kernel,bias=0,stride=1,padding=0):
  
  # input kernel éƒ½æ˜¯4ç»´å¼ é‡
  if padding >0:
    input = F.pad(input,(padding,padding,padding,padding,0,0,0,0))

  bs,in_channel,input_h,input_w = input.shape
  out_channel,in_channel,kernel_h,kernel_w = kernel.shape

  if bias is None:
    bias = torch.zeros(out_channel)

  
  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„é«˜åº¦
  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„å®½åº¦ 
  output = torch.zeros(bs,out_channel,output_h,output_w) # åˆå§‹åŒ– è¾“å‡ºçŸ©é˜µ


  for ind in range(bs):
    for oc in range(out_channel):
      for ic in range(in_channel):
        for i in range(0,input_h - kernel_h + 1,stride): # å¯¹é«˜åº¦è¿›è¡Œéå†
          for j in range(0,input_w - kernel_w +1,stride):  # å¯¹å®½åº¦ç»´è¿›è¡Œéå†
            region = input[ind,ic,i:i+kernel_h, j:j+kernel_w]  # å–å‡ºè¢«æ ¸æ»‘åŠ¨åˆ°çš„åŒºåŸŸ
            output[ind,oc,int(i/stride),int(j/stride)] += torch.sum(region * kernel[oc,ic]) # ç‚¹ä¹˜ å¹¶èµ‹å€¼ç»™è¾“å‡ºä½ç½®çš„å…ƒç´  
      output[ind,oc] += bias[oc]
  return output

input = torch.randn(2,2,5,5)  # bs*in_channel*in_h*in_w
kernel = torch.randn(3,2,3,3) # out_channel*in_channel*kernel_h*kernel_w
bias = torch.randn(3)

# éªŒè¯matrxi_multiplication_for_conv2d_fullä¸å®˜æ–¹APIç»“æœæ˜¯å¦ä¸€è‡´
pytorch_api_conv_output = F.conv2d(input,kernel,bias=bias,padding=1,stride=2)
mm_conv2d_full_output = matrix_multiplication_for_conv2d_full(input,kernel,bias=bias,padding=1,stride=2)
flag = torch.allclose(pytorch_api_conv_output,mm_conv2d_full_output)
print("all close:",flag)
```

## 3 è½¬ç½®å·ç§¯

ä»£ç å®ç°ï¼š

```python
# step4 é€šè¿‡å¯¹kernelè¿›è¡Œå±•å¼€æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå¹¶æ¨å¯¼å‡ºè½¬ç½®å·ç§¯ï¼Œä¸è€ƒè™‘batchã€channelå¤§å°ï¼Œä¸è€ƒè™‘paddingï¼Œå‡è®¾stride=1
def get_kernel_matrix(kernel,input_size):
    # åŸºäºkernelå’Œè¾“å…¥ç‰¹å¾å›¾çš„å¤§å°æ¥å¾—åˆ°å¡«å……æ‹‰ç›´åçš„kernelå †å åçš„çŸ©é˜µ
    kernel_h,kernel_w = kernel.shape
    input_h,input_w = input.shape
    num_out_fea_map = (input_h-kernel_h+1)*(input_w-kernel_w+1)  # å·ç§¯å…¬å¼
    result = torch.zeros((num_out_fea_map,input_h*input_w)) #åˆå§‹åŒ–ç»“æœçŸ©é˜µï¼Œè¾“å‡ºç‰¹å¾å›¾å…ƒç´ ä¸ªæ•°*è¾“å…¥ç‰¹å¾å›¾å…ƒç´ ä¸ªæ•°
    count = 0
    for i in range(0,input_h-kernel_h+1,1):
        for j in range(0,input_w - kernel_w +1,1):
            # å¡«å……æˆ è·Ÿ è¾“å…¥ç‰¹å¾å›¾ä¸€æ ·å¤§å°
            # padded_kernel = F.pad(kernel,(i,input_h-kernel_h-i,j,input_w-kernel_w-j))
            padded_kernel = F.pad(kernel,(j,input_h-kernel_h-j,i,input_w-kernel_w-i))
            result[count] = padded_kernel.flatten()
            count +=1
    return result  



# æµ‹è¯•1ï¼šéªŒè¯ äºŒç»´å·ç§¯
kernel = torch.randn(3,3)
input = torch.randn(4,4)
kernel_matrix = get_kernel_matrix(kernel,input.shape)  # 4*16

# é€šè¿‡çŸ©é˜µç›¸ä¹˜æ¥è®¡ç®—å·ç§¯
mm_conv2d_output = kernel_matrix @ input.reshape((-1,1))  

# pytorch conv2d API
pytorch_conv2d_output = F.conv2d(input.unsqueeze(0).unsqueeze(0),kernel.unsqueeze(0).unsqueeze(0))
# print(kernel)
# print(kernel_matrix)
# print(mm_conv2d_output)
# print(pytorch_conv2d_output)

# æµ‹è¯•2  é€šè¿‡çŸ©é˜µä¹˜ç§¯æ¥è®¡ç®—è½¬ç½®å·ç§¯ || éªŒè¯äºŒç»´è½¬ç½®å·ç§¯
mm_transposed_conv2d_output = kernel_matrix.transpose(-1,-2) @ mm_conv2d_output
pytorch_transposed_conv2d_conv2d = F.conv_transpose2d(pytorch_conv2d_output,kernel.unsqueeze(0).unsqueeze(0))  #API
print(mm_transposed_conv2d_output.reshape(4,4))
print(pytorch_transposed_conv2d_conv2d)
```

```python
tensor([[ 0.9213, -4.1975, -2.0054,  1.9133],
        [ 1.1103,  6.4068, -3.9560, -1.6305],
        [-3.2193,  3.4451,  0.5374, -2.8065],
        [ 0.5796, -3.2003,  3.8138,  0.9070]])
tensor([[[[ 0.9213, -4.1975, -2.0054,  1.9133],
          [ 1.1103,  6.4068, -3.9560, -1.6305],
          [-3.2193,  3.4451,  0.5374, -2.8065],
          [ 0.5796, -3.2003,  3.8138,  0.9070]]]])
```

###  torch.unfold api

![image-20241125142430923](images/image-20241125142430923.png)

æŸ¥å®˜ç½‘ï¼Œçœ‹å…·ä½“ç”¨æ³•ï¼š

![image-20241125142457039](images/image-20241125142457039.png)

####  å®ä¾‹è®²è§£

![image-20241125142529716](images/image-20241125142529716.png)

é€è¡Œè§£é‡Šï¼š

- ç¬¬ä¸€è¡Œï¼Œå®ä¾‹åŒ– Unfoldæ“ä½œï¼Œè¿™é‡Œè°ƒç”¨çš„æ˜¯nn.Unfoldï¼Œç„¶åä¼ å…¥ kernel sizeï¼Œkernel sizeæ˜¯2Ã—3çš„
- ç¬¬äºŒè¡Œï¼Œç„¶åå®šä¹‰inputï¼Œä¼ å…¥ 2Ã—5Ã—3Ã—4çš„å¼ é‡
- å†æŠŠinputä½œä¸ºunfoldçš„è¾“å…¥ï¼Œä¼ è¿›å»å¾—åˆ°output
- å¾—åˆ°outputçš„å½¢çŠ¶ï¼š2Ã—30Ã—4

è§£é‡Šoutputçš„å½¢çŠ¶ï¼š

- æ¯ä¸ªpatchåŒ…å«äº†30ä¸ªæ•°å€¼ï¼Œä¸ºä»€ä¹ˆæ˜¯30ä¸ªæ•°å€¼ï¼Ÿå°±æ˜¯å› ä¸ºè¿™é‡Œinputçš„å½¢çŠ¶2Ã—5Ã—3Ã—4

  - 2æ˜¯batch size

  - 5æ˜¯ input channel

  - 3å’Œ4åˆ†åˆ«æ˜¯ inputçš„é«˜åº¦å’Œå®½åº¦

  - å¦‚æœæˆ‘ä»¬å¯¹input æŠŠæ¯ä¸€æ¬¡ å·ç§¯çš„å— æ‹¿å‡ºæ¥çš„çš„è¯ï¼Œé‚£ä¹ˆä¸€å…±æ˜¯ 2Ã—3Ã—5 è¿™ä¹ˆå¤šä¸ªå€¼

    > ä¸ºä»€ä¹ˆæ˜¯è¿™ä¹ˆå¤šä¸ªå€¼å‘¢ï¼Ÿé¦–å…ˆ2Ã—3æ˜¯kernel sizeçš„é¢ç§¯ï¼Œç„¶åç”±äº inputæœ‰5ä¸ªchannelï¼Œå…¶å®è¿™ä¸ªæ˜¯æŠŠchannelä¸€èµ·è€ƒè™‘è¿›æ¥äº†ï¼Œé‚£æ¯ä¸ªpatchå°±æœ‰30ä¸ªå€¼ï¼›

  - ç„¶åæˆ‘ä»¬è¿™é‡Œ è¾“å…¥å¤§å°æ˜¯ 3Ã—4ï¼Œè€Œkernel sizeæ˜¯2Ã—3çš„ï¼Œé‚£ä¹ˆè¿™æ ·çš„è¯ï¼Œå¦‚æœé»˜è®¤stride=1ï¼Œpadding=0çš„è¯ï¼Œå°±ä¸€å…±æœ‰4ä¸ªblocksï¼Œå°±æ˜¯2Ã—2çš„ä¸€ä¸ªè¾“å‡º $[3-2+1=2]$  Ã—  $[ 4-3 +1 =2]$ 

ä¸€å¥è¯æ€»ç»“ torch.unfold apiå·ç§¯æ ¸æ»‘åŠ¨inputï¼Œå¾—åˆ°å¯¹åº”çš„regionï¼Œè·Ÿå·ç§¯æ ¸ä¸€æ ·å¤§ï¼Œæ‹‰æˆè¡Œå‘é‡ï¼Œå½¢çŠ¶æ˜¯ 

ï¼ˆå¯¹äºå•ä¸ªå·ç§¯æ ¸ï¼‰

`batch sizeÃ—input regionçš„å…ƒç´ æ•°ï¼ˆ=kernelçš„å…ƒç´ æ•° é€šé“æ•°*h*wï¼‰Ã—æ»‘åŠ¨äº†å‡ ä¸ªåŒºåŸŸï¼ˆ=è¾“å‡ºç‰¹å¾å›¾çš„é«˜ Ã— å®½ï¼‰`

ï¼ˆå¯¹äº å¤šä¸ªå·ç§¯æ ¸ torch.unfoldè¾“å‡ºçš„å½¢çŠ¶æ˜¯ä»€ä¹ˆï¼Ÿï¼‰

### ä»€ä¹ˆæ˜¯è½¬ç½®å·ç§¯ï¼Ÿ

å·ç§¯çš„ä¸¤ç§è§’åº¦ï¼š

- flatten input feature map region

  > 1. æˆ‘ä»¬å°†inputè¿›è¡Œå±•å¼€ï¼Œä¹Ÿå°±æ˜¯è¯´ æˆ‘ä»¬æ˜¯æŠŠï¼Œæ¯ä¸€ä¸ªinputåŒºåŸŸæ‹‰ç›´ï¼Œæ‹‰æˆä¸€ä¸ªå‘é‡ ï¼Œç„¶åæŠŠæ‰€æœ‰çš„åŒºåŸŸç»„åˆæˆä¸€ä¸ªçŸ©é˜µï¼Œç„¶åå†è·Ÿ kernelï¼Œä¹ŸæŠŠkernelæ‹‰æˆä¸€ä¸ªå‘é‡ï¼Œç„¶åæŠŠä¸¤ä¸ªçŸ©é˜µ è¿›è¡Œå‡ ä¸ªç›¸ä¹˜ã€‚è¿™æ ·å¾—åˆ°æœ€ç»ˆçš„å·ç§¯ç»“æœï¼› 
  >
  > 2. flatten input feature map regionæ‹‰æˆè¡Œå‘é‡ï¼Œkernelæ‹‰æˆåˆ—å‘é‡
  > 2. æŠŠæ¯æ¬¡æ»‘åŠ¨ç›¸ä¹˜ è¿™ä¸ªinput regionæ‹‰ç›´ï¼Œæ‹‰æˆä¸€ä¸ªå‘é‡ï¼ŒæŠŠ9ä¸ªå‘é‡ æ‹¼æˆä¸€ä¸ªçŸ©é˜µï¼Œå†è·Ÿkernelï¼ŒæŠŠkernel ä¹Ÿæ‹‰æˆä¸€ä¸ªåˆ—å‘é‡ï¼Œè¿›è¡Œä¸¤ä¸ªçŸ©é˜µçš„ç›¸ä¹˜ï¼›

- pad & flatten kernel

  > 1. é¦–å…ˆæ˜¯æŠŠæ•´ä¸ªinputï¼Œinputæ˜¯5Ã—5ï¼ŒæŠŠæ•´ä¸ªinputæ‹‰æˆä¸€ä¸ª25Ã—1çš„å‘é‡ï¼Œå†æŠŠæ¯ä¸€æ­¥çš„kernelï¼Œä¹ŸæŠŠå®ƒå˜æˆä¸€ä¸ªé•¿åº¦ä¸º25çš„å‘é‡ï¼Œæ–¹æ³•æ˜¯æŠŠæ¯ä¸€æ­¥çš„kernelå¡«å……æˆ5Ã—5çš„å¤§å°
  >
  >    ![image-20241125144755231](images/image-20241125144755231.png)
  >
  > 2. 9ä¸ªkernel è·Ÿ åŒä¸€ä¸ª input è¿›è¡Œå†…ç§¯æ“ä½œ
  >
  > 3. æŠŠ9ä¸ªkernel æ‹¼æˆä¸€ä¸ªçŸ©é˜µçš„è¯ï¼Œç›¸å½“äºæ˜¯ä¸€ä¸ª 9Ã—25çš„ kernelçŸ©é˜µï¼Œè·Ÿ25Ã—1çš„input feature mapè¿›è¡ŒçŸ©é˜µç›¸ä¹˜ï¼Œæœ€ç»ˆå¾—åˆ° 9Ã—1ï¼Œæˆ‘ä»¬å†æŠŠ 9Ã—1çš„è¾“å‡º reshapeä¸€ä¸‹ï¼Œå˜æˆ 3Ã—3ï¼›
  >
  > 4. kernel æ‹‰æˆè¡Œå‘é‡ï¼Œinputæ‹‰æˆåˆ—å‘é‡
  >
  > 5. againï¼šæŠŠå·ç§¯çœ‹æˆ æ¯ä¸€æ­¥ éƒ½æ˜¯ 5Ã—5 çš„kernel è·Ÿ 5Ã—5 çš„input è¿›è¡Œå†…ç§¯ï¼Œç„¶åæ±‚å’Œçš„æ“ä½œï¼›ä¸ºä»€ä¹ˆæ˜¯5Ã—5ï¼Œå› ä¸ºæˆ‘ä»¬æŠŠæ¯ä¸€æ­¥ kernelå¡«å……æˆ 5Ã—5çš„ï¼Œå…·ä½“æ€ä¹ˆ å¡«å……  çœ‹kernelçš„ä½ç½®ï¼ŒæŒ‰ç…§ inputçš„å½¢çŠ¶ è¿›è¡Œå¡«

### ä» kernel flatten convolution å¼€å§‹

```python
# step4 é€šè¿‡å¯¹kernelè¿›è¡Œå±•å¼€æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå¹¶æ¨å¯¼å‡ºè½¬ç½®å·ç§¯ï¼Œä¸è€ƒè™‘batchã€channelå¤§å°ï¼Œä¸è€ƒè™‘paddingï¼Œå‡è®¾stride=1
def get_kernel_matrix(kernel,input_size):
    # åŸºäºkernelå’Œè¾“å…¥ç‰¹å¾å›¾çš„å¤§å°æ¥å¾—åˆ°å¡«å……æ‹‰ç›´åçš„kernelå †å åçš„çŸ©é˜µ
    kernel_h,kernel_w = kernel.shape
    input_h,input_w = input.shape
    num_out_fea_map = (input_h-kernel_h+1)*(input_w-kernel_w+1)  # å·ç§¯å…¬å¼
    result = torch.zeros((num_out_fea_map,input_h*input_w)) #åˆå§‹åŒ–ç»“æœçŸ©é˜µï¼Œè¾“å‡ºç‰¹å¾å›¾å…ƒç´ ä¸ªæ•°*è¾“å…¥ç‰¹å¾å›¾å…ƒç´ ä¸ªæ•°
    count = 0
    for i in range(0,input_h-kernel_h+1,1):
        for j in range(0,input_w - kernel_w +1,1):
            # å¡«å……æˆ è·Ÿ è¾“å…¥ç‰¹å¾å›¾ä¸€æ ·å¤§å°
            # padded_kernel = F.pad(kernel,(i,input_h-kernel_h-i,j,input_w-kernel_w-j))
            padded_kernel = F.pad(kernel,(j,input_h-kernel_h-j,i,input_w-kernel_w-i))
            result[count] = padded_kernel.flatten()
            count +=1
    return result  



# æµ‹è¯•1ï¼šéªŒè¯ äºŒç»´å·ç§¯
kernel = torch.randn(3,3)
input = torch.randn(4,4)
kernel_matrix = get_kernel_matrix(kernel,input.shape)  # 4*16

# é€šè¿‡çŸ©é˜µç›¸ä¹˜æ¥è®¡ç®—å·ç§¯
mm_conv2d_output = kernel_matrix @ input.reshape((-1,1))  

# pytorch conv2d API
pytorch_conv2d_output = F.conv2d(input.unsqueeze(0).unsqueeze(0),kernel.unsqueeze(0).unsqueeze(0))
print(kernel)
print(kernel_matrix)
print(mm_conv2d_output)
print(pytorch_conv2d_output)
```

```python
kernel
tensor([[ 0.3170,  2.4005, -1.2991],
        [ 1.1566, -0.3610, -0.7246],
        [-0.5764, -0.7988,  1.5611]])
kernel_matrix
tensor([[ 0.3170,  2.4005, -1.2991,  0.0000,  1.1566, -0.3610, -0.7246,  0.0000,
         -0.5764, -0.7988,  1.5611,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.3170,  2.4005, -1.2991,  0.0000,  1.1566, -0.3610, -0.7246,
          0.0000, -0.5764, -0.7988,  1.5611,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.3170,  2.4005, -1.2991,  0.0000,
          1.1566, -0.3610, -0.7246,  0.0000, -0.5764, -0.7988,  1.5611,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3170,  2.4005, -1.2991,
          0.0000,  1.1566, -0.3610, -0.7246,  0.0000, -0.5764, -0.7988,  1.5611]])
mm_conv2d_output
tensor([[ 5.3770],
        [-2.0131],
        [-5.9471],
        [-2.7944]])
pytorch_conv2d_output
tensor([[[[ 5.3770, -2.0131],
          [-5.9471, -2.7944]]]])
```

### è½¬ç½®å·ç§¯

- è¾“å…¥ï¼š4Ã—4ï¼Œkernelï¼š3Ã—3ï¼Œoutputï¼š2Ã—2   
  	- flatten input feature map regionï¼š4Ã—9  @ 9Ã—1 = 4Ã—1
  	- padding & flatten kernel ï¼š4Ã—16 @ 16Ã—1 = 4Ã—1
- è½¬ç½®å·ç§¯ï¼š   
	- 16Ã—4 @ 4Ã—1 = 16Ã—1  $ reshape \rightarrow $ 4 Ã— 4 

> è½¬ç½®å·ç§¯æ˜¯æ€ä¹ˆåšçš„å‘¢ï¼Ÿ
>
> å…¶å®åšæ³•å¾ˆç®€å•ï¼Œå°±æ˜¯æŠŠkernel matrix é¦–å…ˆè½¬ç½®ä¸€ä¸‹ï¼›æ¯”æ–¹è¯´æœ¬æ¥æ˜¯4Ã—16çš„ çŸ©é˜µï¼›æˆ‘ä»¬è½¬ç½®ä¸€ä¸‹ï¼›è½¬ç½®æˆ16Ã—4çš„çŸ©é˜µï¼›
>
> ç„¶åæˆ‘ä»¬ä¹Ÿè®²äº†outputæ˜¯ä¸€ä¸ª2Ã—2çš„ çŸ©é˜µï¼Œæˆ‘ä»¬ä¹ŸæŠŠå®ƒæ‹‰ç›´ä¸€ä¸‹ï¼Œå˜æˆ4Ã—1çš„çŸ©é˜µï¼›äºæ˜¯16Ã—4çš„çŸ©é˜µï¼Œè·Ÿ4Ã—1çš„çŸ©é˜µï¼Œç›¸ä¹˜ï¼Œå°±å˜æˆäº†ä¸€ä¸ª16Ã—1çš„çŸ©é˜µï¼Œæˆ‘ä»¬åœ¨reshapeä¸€ä¸‹ï¼Œå°±å˜æˆäº†4Ã—4ï¼Œè¿™æ ·æˆ‘ä»¬å°±æŠŠä¸€ä¸ª 2Ã—2çš„ç‰¹å¾å›¾ï¼Œå˜æˆäº†ä¸€ä¸ª4Ã—4çš„ç‰¹å¾å›¾ï¼›è¿™æ˜¯ä»åŸç†ä¸Šçš„è§£é‡Š
>
> å¦å¤–è¿˜æœ‰ä¸€ç§ï¼Œæˆ‘ä»¬è¿™é‡Œå®ç°äº†äºŒç»´å·ç§¯ï¼Œå°±ç±»ä¼¼äº y=wx(wä¹˜ä»¥xè¿™æ ·çš„ä¸€ä¸ªè¿‡ç¨‹)ï¼›
>
> wè·Ÿxä¹‹é—´ æ˜¯ä¸€ä¸ªçŸ©é˜µä¹˜æ³•ï¼›ç„¶åæˆ‘ä»¬æ±‚åå‘æ¢¯åº¦çš„æ—¶å€™ï¼Œåyï¼Œåxï¼Œåˆšå¥½å°±æ˜¯wçš„ä¸€ä¸ªè½¬ç½®ï¼Œæ‰€ä»¥è¯´åœ¨pytorchä¸­ï¼Œå®ç°è½¬ç½®å·ç§¯ æˆ–è€…å« deconvolution æˆ–è€…å«transpose convolutionï¼Œéƒ½æ˜¯åŸºäºåå‘ä¼ æ’­ æ¥å®ç°çš„ï¼›
>
> y=wx
>
> dy dxå°±ç­‰äºwçš„è½¬ç½®
>
> è¿™ä¸ªå°±æ˜¯è½¬ç½®å·ç§¯çš„åŸç†éƒ¨åˆ†

- ä¸‰ç‚¹éœ€è¦ç‰¹åˆ«æ³¨æ„ï¼š

  > ç¬¬ä¸€ç‚¹
  >
  > > è½¬ç½®å·ç§¯ä¸€èˆ¬ç”¨åœ¨ä¸Šé‡‡æ ·çš„è¿‡ç¨‹ï¼›å› ä¸ºæ™®é€šçš„å·ç§¯ä¼šç”¨åœ¨ä¸‹é‡‡æ ·ï¼Œæ¯”æ–¹è¯´è¿™é‡Œçš„ä¾‹å­ï¼ŒæŠŠ4Ã—4çš„ç‰¹å¾å›¾ï¼Œé€šè¿‡å·ç§¯å˜æˆäº†ä¸€ä¸ª2Ã—2çš„ï¼Œè¿™æ˜¯å¸¸è§„çš„æ“ä½œï¼Œè¿™æ˜¯ä¸‹é‡‡æ ·
  > >
  > > é‚£æœ‰æ—¶å€™ï¼Œåœ¨ç”Ÿæˆçš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦ï¼Œè¾“å…¥æ˜¯2Ã—2çš„ï¼Œè¾“å‡ºå˜æˆ4Ã—4çš„ï¼Œè¿™ä¸ªæ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨è½¬ç½®å·ç§¯å®ç°ï¼Œè¿™æ˜¯ç¬¬ä¸€ç‚¹ï¼›
  > >
  >
  > ç¬¬äºŒç‚¹
  >
  > > è½¬ç½®å·ç§¯ æˆ–è€… åå‘ å·ç§¯ æ¢¯åº¦ï¼›æ„æ€å°±æ˜¯è¯´ æˆ‘ä»¬é€šè¿‡åå‘ä¼ æ’­ æ¥å®ç°è½¬ç½®å·ç§¯çš„
  >
  > ç¬¬ä¸‰ç‚¹
  >
  > > è½¬ç½®å·ç§¯ä¹Ÿå¯ä»¥é€šè¿‡ å¡«å……çš„æ–¹å¼æ¥å®ç°ï¼Œä»€ä¹ˆæ„æ€å‘¢ï¼Ÿå°±æ˜¯å¯ä»¥æŠŠ2Ã—2çš„è¾“å…¥ å¡«å……åˆ°6Ã—6çš„å¤§å°ï¼›ç„¶åå†å»ç”¨3Ã—3çš„kernel è¿›è¡Œä¸€ä¸ªå·ç§¯ï¼›ä¹Ÿèƒ½å®ç°ä¸€ä¸ªä¸Šé‡‡æ ·çš„æ•ˆæœï¼›ä½†è¿™ç§æ–¹æ³•å¹¶ä¸æ˜¯æ¡†æ¶ä¸­ä½¿ç”¨çš„æ–¹æ³•ï¼›æ¡†æ¶ä¸­çš„å®ç° æ˜¯é€šè¿‡ åå‘ä¼ æ’­çš„æ–¹æ³•æ¥å®ç° è½¬ç½®å·ç§¯çš„ï¼›

ä»£ç å®ç°ï¼š

> é¦–å…ˆå¯¹kernel matrixè¿›è¡Œä¸€ä¸ªè½¬ç½®ï¼Œtransposeï¼Œ-1ç»´ï¼Œ-2ç»´è½¬ç½®ä¸€ä¸‹
>
>  kernel_matrix.transpose(-1,-2)ï¼Œè¿™æ ·å¾—åˆ°wçš„ä¸€ä¸ªè½¬ç½®ï¼Œæˆ‘ä»¬å†æŠŠè¿™ä¸ªè½¬ç½®è·Ÿä¸Šé¢è¿™ä¸ªoutput `mm_conv2d_output` è¿›è¡Œä¸€ä¸ªçŸ©é˜µç›¸ä¹˜æ“ä½œ
>
> ```python
> kernel_matrix.transpose(-1,-2) @ mm_conv2d_output
> ```
>
> -  mm_conv2d_output æ˜¯ä¸€ä¸ª 4Ã—1 çš„çŸ©é˜µï¼Œå‰é¢è½¬ç½®åæ˜¯ä¸€ä¸ª 16Ã—4çš„ï¼Œå¾—åˆ°ä¸€ä¸ª 16Ã—1çš„ç»“æœ 
>
> - å®šä¹‰ä¸º mm_transposed_conv2d_output  
>
> - è¿™ä¸ªå°±æ˜¯é€šè¿‡çŸ©é˜µç›¸ä¹˜ å¾—åˆ°çš„è½¬ç½®å·ç§¯ï¼Œä¹Ÿå«åšåå·ç§¯ï¼› 
>
> - è¿™ä¸ªåå·ç§¯ æˆ–è€…å« è½¬ç½®å·ç§¯ï¼Œå¹¶ä¸æ˜¯ä¸€ä¸ªå¯é€†çš„ï¼Œä¸æ˜¯ä¸€ä¸ªé€†è®¡ç®—ï¼Œè¿™é‡Œçš„outputå¹¶ä¸æ˜¯å½“åˆçš„inputï¼Œåªæ˜¯å½¢çŠ¶è·Ÿinputä¸€æ ·è€Œå·²
>
> ```python
> mm_transposed_conv2d_output = kernel_matrix.transpose(-1,-2) @ mm_conv2d_output
> ```
>
> ä»¥ä¸Šæ˜¯çŸ©é˜µä¹˜ç§¯å¾—åˆ°è½¬ç½®å·ç§¯çš„ï¼›

ä¸ºäº†éªŒè¯ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨pytorchè½¬ç½®å·ç§¯çš„api

![image-20241125174156737](images/image-20241125174156737.png)

1. ç±»å½¢å¼
2. å‡½æ•°å½¢å¼

![image-20241125174308099](images/image-20241125174308099.png)

- å®ä¾‹åŒ–classï¼Œè°ƒç”¨çš„è¿˜æ˜¯å‡½æ•°å½¢å¼ï¼›ç°åœ¨æˆ‘ä»¬æ¥è°ƒç”¨ä¸€ä¸‹è¿™ä¸ªå‡½æ•°
- å°±æ˜¯F.conv_transpose2d()ä¸€æ ·çš„ï¼Œé¦–å…ˆä¼ å…¥ä¸Šé¢çš„outputï¼Œå°±æ˜¯æŠŠä¸Šé¢çš„pytorch_conv2d_outputä½œä¸ºè¾“å…¥ï¼Œkernelä¹Ÿè¦ä¼ è¿›å»ï¼Œkernelå°±æ˜¯ä¹‹å‰å†™çš„kernelï¼ŒåŒæ ·ä¹Ÿè¦å¯¹å®ƒè¿›è¡Œä¸¤æ¬¡çš„unsqueezeæ“ä½œï¼ˆbatch size Ã— channel Ã— height Ã— widthï¼‰ï¼Œè¿™æ ·å¾—åˆ°pytorch_transposed_conv2d_output API

```python
# æµ‹è¯•2  é€šè¿‡çŸ©é˜µæˆç»©æ¥è®¡ç®—è½¬ç½®å·ç§¯
mm_transposed_conv2d_output = kernel_matrix.transpose(-1,-2) @ mm_conv2d_output
pytorch_transposed_conv2d_conv2d = F.conv_transpose2d(pytorch_conv2d_output,kernel.unsqueeze(0).unsqueeze(0))  #API
print(mm_transposed_conv2d_output.reshape(4,4))
print(pytorch_transposed_conv2d_conv2d)
```

**<u>å…³äºè½¬ç½®å·ç§¯è¦è¯´æ˜çš„ï¼š</u>**

- æˆ‘ä»¬æŠŠå·ç§¯çœ‹æˆæ˜¯ å¡«å……åçš„kernelè·Ÿinputï¼Œå¾—åˆ° kernel_matrixä¹‹åï¼Œå†æŠŠkernel matrixè½¬ç½®ä¸€ä¸‹ï¼Œè·Ÿconvolution outputè¿›è¡ŒçŸ©é˜µç›¸ä¹˜ï¼Œè¿™æ ·å¾—åˆ°äº†ä¸€ä¸ªæ–°çš„outputï¼Œåˆšå¥½outputçš„å¤§å°å’Œinputçš„å¤§å°æ˜¯ä¸€æ ·çš„ï¼›æˆåŠŸå®ç°äº†ä¸Šé‡‡æ ·ï¼Œå› ä¸ºmm conv2d outputæ˜¯ 2Ã—2çš„ï¼Œå·¦è¾¹mm transposed conv2d outputæ˜¯ 4Ã—4çš„ï¼Œæˆ‘ä»¬å°±å®ç°äº†ä¸Šé‡‡æ ·ï¼›
- F.conv_transposed2d()çš„è¾“å…¥ï¼Œå°±æ˜¯æ™®é€šå·ç§¯çš„è¾“å‡ºï¼Œkernelè¿˜æ˜¯é‚£ä¸ªkernelï¼ŒæŠŠå®ƒæ‰©å……ä¸€ä¸‹

**<u>å…³äºä¸Šé‡‡æ ·çš„ä¸¤ä¸ªè§’åº¦ï¼š</u>** 

-  ==ï¼ˆç¬¬ä¸€ç§å®ç°ï¼šæŠŠkernelè½¬ç½® 16 Ã— 4  $ \rightarrow $ 4Ã—16 ï¼‰==  é¦–å…ˆè¦æŠŠæ™®é€šå·ç§¯çš„kernel matrixå†™å‡ºæ¥ï¼Œç„¶åå†æŠŠmatrixè½¬ç½®ä¸€ä¸‹ï¼Œå†è·Ÿæ™®é€šå·ç§¯çš„è¾“å‡º ç›¸ä¹˜ä¸€ä¸‹ï¼›å°±å®ç°äº†
-  ==ï¼ˆç¬¬äºŒç§å®ç°ï¼šæŠŠinputå˜å¤§ï¼‰==   ç›´æ¥æŠŠinputè¿›è¡Œå¡«å……ï¼›æ¯”å¦‚ç°åœ¨inputæ˜¯2Ã—2ï¼Œæˆ‘ä»¬ä¸ºäº†å®ç°4Ã—4ï¼Œä¸ºäº†ç”¨æ™®é€šçš„å·ç§¯ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ2Ã—2çš„å¡«å……æˆ5Ã—5 æˆ–è€… 6Ã—6çš„ï¼›å‡å¦‚è¯´æ˜¯6Ã—6çš„ï¼Œæˆ‘ä»¬å°±æŠŠä¸Šä¸‹å·¦å³ å¡«å……ä¸¤è¡Œ0å°±å¥½äº†ï¼Œå†ç”¨æ™®é€šå·ç§¯å®ç° ä¹Ÿæ˜¯å¯ä»¥çš„ï¼›å› ä¸ºåæ­£å‚æ•°éƒ½æ˜¯è¦å­¦ä¹ çš„ï¼Œæˆ‘ä»¬çš„ç›®çš„å°±æ˜¯åšä¸Šé‡‡æ ·ï¼›æ— è®ºæ˜¯ä»åå‘ä¼ æ’­çš„è§’åº¦ï¼Œè¿˜æ˜¯ç›´æ¥å¯¹inputè¿›è¡Œå¡«å……ï¼ŒæŠŠinputå˜å¤§ï¼Œéƒ½èƒ½å®ç° ä¸Šé‡‡æ ·ï¼Œä¸è¿‡æ•°å€¼æ˜¯ä¸ä¸€æ ·çš„ï¼Œä¸è¿‡æ²¡å…³ç³»ï¼Œåæ­£éƒ½æ˜¯è¦å­¦ä¹ çš„

è½¬ç½®å·ç§¯ åå·ç§¯=transpose conv2d

## 4 è†¨èƒ€å·ç§¯ & ç©ºæ´å·ç§¯

introï¼Œå®˜æ–¹apiï¼š

![image-20241125180526663](images/image-20241125180526663.png)

åœ¨é»˜è®¤çš„apiä¸­ dilationçš„å€¼ç­‰äº1ï¼Œgroupsçš„å€¼ ä¹Ÿæ˜¯ç­‰äº1 çš„ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬å¸¸ç”¨çš„å·ç§¯éƒ½æ²¡æœ‰æŒ‡å®šï¼Œå¸¸ç”¨çš„å€¼éƒ½ä¸º1

ä»€ä¹ˆæ˜¯dilationï¼Ÿ

> dilationçš„æ„æ€å°±æ˜¯è¯´ï¼Œæˆ‘ä»¬æ™®é€šçš„å·ç§¯ï¼Œæ¯”å¦‚è¯´3Ã—3çš„å·ç§¯æ ¸ï¼Œåœ¨ä¸€ä¸ªè¾“å…¥ç‰¹å¾å›¾ä¸Š è¿›è¡Œ å·ç§¯çš„è¯ï¼Œæˆ‘ä»¬æ¯æ¬¡ï¼Œä»è¾“å…¥ç‰¹å¾å›¾ä¸Šå–ä¸€å— 3Ã—3çš„ é¢ç§¯ï¼Œå–9ä¸ªå…ƒç´ ï¼Œå¹¶ä¸”è¿™9ä¸ªå…ƒç´ ï¼Œéƒ½æ˜¯ç´§æŒ¨ç€å½¼æ­¤çš„ï¼Œå°±æ˜¯3Ã—3çš„åŒºåŸŸï¼Œä¸€ä¸ªæ–¹å½¢åŒºåŸŸï¼Œè¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬æˆä¸ºdilation=1ï¼Œä¹Ÿå°±æ˜¯è¯´å½¼æ­¤ä¹‹é—´é—´éš”ä¸º1ï¼Œå¯ä»¥è¿™ä¹ˆç†è§£ï¼Œå½¼æ­¤çš„ç´¢å¼•ï¼Œå·®è·ä¸º1ï¼Œæ¯”æ–¹è¯´ç¬¬ä¸€ä¸ªå…ƒç´  ç´¢å¼•ä¸º1ï¼Œç¬¬äºŒä¸ªå…ƒç´  ç´¢å¼• å°±æ˜¯2ï¼Œé‚£å¦‚æœdilationä¸æ˜¯ç­‰äº1ï¼Œè€Œæ˜¯2çš„è¯å‘¢ï¼Œè¯´æ˜ç¬¬ä¸€ä¸ªå…ƒç´ å’Œç¬¬äºŒä¸ªå…ƒç´  ç´¢å¼•ç›¸å·®äº†2ï¼Œé‚£å°±è¯´æ˜ ä¸­é—´è¿˜å¤šäº†ä¸€ä¸ªå…ƒç´ ï¼›
>
> ä¹Ÿå°±æ˜¯è¯´ dilation æ˜¯æ§åˆ¶ç€æˆ‘ä»¬è¾“å…¥ ç‰¹å¾å›¾ è¦å–å¾—é‚£éƒ¨åˆ†é¢ç§¯ æ˜¯å¦æ˜¯ç´§å‡‘çš„ï¼Œå¦‚æœå®ƒçš„å€¼å¤§äº1çš„è¯ï¼Œå®ƒå°±ä¸æ˜¯ç´§å‡‘çš„ï¼Œå®ƒä¸­é—´æ˜¯æœ‰ä¸€äº›ï¼Œè·³è¿‡çš„å…ƒç´ çš„ï¼›

```python
a = torch.randn(7,7)
```

![image-20241125180705640](images/image-20241125180705640.png)

- dilation=2  a[0:5:2,0:5:2] ç´¢å¼•0åˆ°ç´¢å¼•5ï¼Œè·³è¿‡ä¸€ä¸ªå–ä¸€ä¸ªï¼Œæœ€åä¸€ä¸ªå–ä¸åˆ°
- dilation=3 ç”¨ç´¢å¼•è¡¨ç¤ºçš„è¯ å°±æ˜¯ 0åˆ°7ï¼Œç„¶åé—´éš”æ˜¯3ï¼›a[0:7:3,0:7:3] # dilation=3 åŒæ ·åˆ—æ•°ä¹Ÿæ˜¯ä¸€æ ·çš„ 0åˆ°7 é—´éš”æ˜¯3ï¼›ç´¢å¼•é—´éš”ä¸º3

![image-20241125180926621](images/image-20241125180926621.png)

ä¸€å¥è¯è¯´æ¸…dilationæ˜¯ä»€ä¹ˆï¼Ÿå·ç§¯çš„è¦†ç›–åŒºåŸŸ ç´¢å¼•é—´éš”å¤šå°‘

> å¦‚æœ input size=7Ã—7 kernel size=3Ã—3ï¼Œdilation=3ï¼Œæˆ‘ä»¬åªéœ€è¦ å–ä¸€æ¬¡å°±å¥½äº†ï¼›
>
> å–ä¸€æ¬¡ å°±åˆšå¥½ å·²ç»åˆ° è¾¹ç•Œäº†
>
> æ‰€ä»¥7Ã—7çš„input è·Ÿ 3Ã—3çš„kernel è¿›è¡Œ å·ç§¯çš„è¯ï¼Œæˆ‘ä»¬ä¸åšpadding stride=1çš„è¯ï¼Œé‚£ä¹ˆè¾“å‡ºå°±æ˜¯ä¸€ä¸ªæ•°ï¼Œå°±æ˜¯ä¸€ä¸ªæ ‡é‡ï¼›è¿™å°±æ˜¯dilation å– ä¸åŒå€¼ å…·ä½“çš„è¿ç®—è§„åˆ™
>
> é‚£ä¸ºä»€ä¹ˆè¦ç”¨dilationå¤§äº1çš„è¿™äº›æƒ…å†µå‘¢ï¼Ÿå°±æ˜¯å› ä¸ºæˆ‘ä»¬ å¢å¤§dilation ä½†æ˜¯å¹¶æ²¡æœ‰å¢å¤§è¿ç®—é‡ï¼›æˆ‘ä»¬è¿˜æ˜¯3Ã—3çš„çŸ©é˜µï¼Œè·Ÿ3Ã—3çš„çŸ©é˜µ è¿›è¡Œå…ƒç´ ç›¸ä¹˜ï¼›å¹¶æ²¡æœ‰å› ä¸º æ„Ÿå—é‡å˜å¤§ è®¡ç®—é‡ å˜å¤§ï¼›æ‰€ä»¥ä¸€èˆ¬ å¢å¤§ dilationçš„ç›®çš„ å°±æ˜¯æˆ‘ä»¬åœ¨ ä¿æŒè¿ç®—é‡ä¸å˜çš„å‰æä¸‹ï¼Œå¸Œæœ› å¢å¤§ æ„Ÿå—é‡çš„é¢ç§¯ï¼›è¿™å°±æ˜¯dilation

ä¸€å¥è¯ä¸ºä»€ä¹ˆdilationï¼šåœ¨ä¸å¢åŠ è¿ç®—é‡çš„æƒ…å†µä¸‹ï¼Œå¢å¤§æ„Ÿå—é‡

## 5 åˆ†ç»„å·ç§¯ & ç¾¤å·ç§¯

### ä»€ä¹ˆæ˜¯åˆ†ç»„å·ç§¯ï¼Ÿ

> åˆ†ç»„å·ç§¯ group convolutionï¼›æ˜¯å¯¹è¾“å…¥é€šé“è¿›è¡Œåˆ†ç»„ï¼›è¾“å‡ºé€šé“å¹¶ä¸æ˜¯ç”±æ‰€æœ‰çš„è¾“å…¥é€šé“å…±åŒä½œç”¨çš„ï¼›ä¼šæœ‰ä¸€ç§æƒ…å†µï¼Œæ¯”å¦‚è¾“å…¥é€šé“æ˜¯4ï¼Œè¾“å‡ºé€šé“æ˜¯2ï¼Œè¾“å‡ºé€šé“çš„ç¬¬ä¸€ä¸ªé€šé“åªè·Ÿè¾“å…¥é€šé“çš„ç¬¬1ã€3ä¸ªé€šé“æœ‰å…³ï¼›è¾“å‡ºé€šé“çš„ç¬¬äºŒä¸ªé€šé“åªè·Ÿè¾“å…¥é€šé“çš„ç¬¬2ã€4ä¸ªé€šé“æœ‰å…³ï¼›å¦‚æœè¾“å…¥é€šé“æœ‰è¿™æ ·çš„å…³ç³»æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨åˆ†ç»„å·ç§¯ï¼Œè®¾ç½®ç»„æ•°group=2ï¼Œè¿™æ—¶æœ‰å‡ ä¸ªç»„å°±ä¼šæœ‰å‡ ä¸ªè¾“å‡ºé€šé“ï¼›è¿™ç§æƒ…å†µæ˜¯æˆ‘ä»¬å¯¹æ¯ä¸ªç»„è¿›è¡Œä¸€æ¬¡å·ç§¯ï¼Œå¦‚æœæˆ‘ä»¬å¯¹æ¯ä¸ªç»„è¿›è¡Œå¤šæ¬¡å·ç§¯ï¼Œé‚£ä¹ˆå·ç§¯æ ¸çš„ä¸ªæ•°å°±ä¼šå¢åŠ äº†ï¼›è¿™æ ·ä¹Ÿæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯è¾“å…¥ç‰¹å¾å›¾çš„é€šé“ä¹‹é—´æ²¡æœ‰äº¤äº’ï¼Œæ‰€ä»¥è¿™ç§æƒ…å†µä¸‹ï¼Œåœ¨åé¢çš„å·ç§¯è¿‡ç¨‹ä¸­ï¼Œä¼šæœ‰é€šé“ä¹‹é—´çš„éšæœºæ··åˆæˆ–è€…ç”¨1Ã—1çš„å·ç§¯ï¼›poinwise convolutionï¼›

### è¡¥å……æ·±åº¦å¯åˆ†ç¦»å·ç§¯ depthwise & pointwiseï¼š

> æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼Œæ˜¯ç‰¹æ®Šçš„åˆ†ç»„å·ç§¯ï¼Œæœ‰å‡ ä¸ªè¾“å…¥é€šé“ï¼Œå°±åˆ†æˆå‡ ä¸ªç»„ï¼Œè¾“å…¥é€šé“ä¹‹é—´å®Œå…¨ç›¸äº’ç‹¬ç«‹ï¼Œdeepwise convolutionï¼›è¿™ç§æƒ…å†µä¸‹ï¼Œåé¢é€šå¸¸ä¼šè·Ÿç€ pointwise  convolutionï¼›

[æ·±åº¦å¯åˆ†ç¦»å·ç§¯ & 1Ã—1å·ç§¯](https://zhuanlan.zhihu.com/p/80041030)

[å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„Separable Convolution](https://yinguobing.com/separable-convolution/#fn2)

ä¸€å¼ å›¾çœ‹æ‡‚æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼š

![image-20241125200302038](images/image-20241125200302038.png)

Depthwise Convolutionå®Œæˆåçš„Feature mapæ•°é‡ä¸è¾“å…¥å±‚çš„depthç›¸åŒï¼Œä½†æ˜¯è¿™ç§è¿ç®—å¯¹è¾“å…¥å±‚çš„æ¯ä¸ªchannelç‹¬ç«‹è¿›è¡Œå·ç§¯è¿ç®—åå°±ç»“æŸäº†ï¼Œæ²¡æœ‰æœ‰æ•ˆçš„åˆ©ç”¨ä¸åŒmapåœ¨ç›¸åŒç©ºé—´ä½ç½®ä¸Šçš„ä¿¡æ¯ã€‚å› æ­¤éœ€è¦å¢åŠ å¦å¤–ä¸€æ­¥æ“ä½œæ¥å°†è¿™äº›mapè¿›è¡Œç»„åˆç”Ÿæˆæ–°çš„Feature mapï¼Œå³æ¥ä¸‹æ¥çš„Pointwise Convolutionã€‚ï¼ˆ[æ‘˜è‡ª](https://yinguobing.com/separable-convolution/#fn2)ï¼‰

ä¸€å¼ å›¾çœ‹æ‡‚1Ã—1å·ç§¯ï¼š

![image-20241125200417890](images/image-20241125200417890.png)

Pointwise Convolutionçš„è¿ç®—ä¸å¸¸è§„å·ç§¯è¿ç®—éå¸¸ç›¸ä¼¼ï¼Œä¸åŒä¹‹å¤„åœ¨äºå·ç§¯æ ¸çš„å°ºå¯¸ä¸º 1Ã—1Ã—Mï¼ŒMä¸ºä¸Šä¸€å±‚çš„depthã€‚æ‰€ä»¥è¿™é‡Œçš„å·ç§¯è¿ç®—ä¼šå°†ä¸Šä¸€æ­¥çš„mapåœ¨æ·±åº¦æ–¹å‘ä¸Šè¿›è¡ŒåŠ æƒç»„åˆï¼Œç”Ÿæˆæ–°çš„Feature mapã€‚æœ‰å‡ ä¸ªFilterå°±æœ‰å‡ ä¸ªFeature mapã€‚ï¼ˆ[æ‘˜è‡ª](https://yinguobing.com/separable-convolution/#fn2)ï¼‰

è¡¥å……æ™®é€šå·ç§¯ï¼š

![image-20241125201354298](images/image-20241125201354298.png)

### ä¸ºä»€ä¹ˆéœ€è¦åˆ†ç»„å·ç§¯ï¼Ÿ

å½’çº³åç½®ï¼š

 æ¯ä¸€ä¸ªæ¨¡å‹ éƒ½æœ‰è‡ªå·±çš„å‡è®¾ï¼Œæˆ–è€…å« å½’çº³åç½® inductive biasï¼›

- CNNçš„å½’çº³åç½®å°±æ˜¯ å±€éƒ¨å»ºæ¨¡æ€§ å’Œ å¹³ç§»ä¸å˜æ€§
- RNNå°±æ˜¯å‰åå…³è”æ€§
- Transformeræ²¡æœ‰ä»€ä¹ˆå‡è®¾ï¼Œåªæ˜¯å¼•å…¥äº†ä¸€ä¸ªposition embeddingè€Œå·²

åœ¨æˆ‘ä»¬è¿™é‡Œå¼•å…¥çš„ group>1çš„è¯ï¼Œå¼•å…¥çš„å‡è®¾æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

> æˆ‘ä»¬åªéœ€è¦ä¸€å°éƒ¨åˆ†ï¼Œåªéœ€è¦åšä¸€å°éƒ¨åˆ† é€šé“ä¹‹é—´çš„å»ºæ¨¡å°±å¥½äº†ï¼Œä¸éœ€è¦è€ƒè™‘ æ¯ä¸ªé€šé“ è·Ÿæ‰€æœ‰é€šé“çš„ å…³ç³»ï¼›å…¶å®æœ¬è´¨ä¸Š group=1çš„è¯ï¼Œå°±æ˜¯è¯´ in channelï¼Œæ¯ä¸ªé€šé“ éƒ½éœ€è¦ è·Ÿ å…¶ä»– é€šé“ è¿›è¡Œä¸€ä¸ªæ··åˆï¼›ä½†æ˜¯å½“æˆ‘ä»¬æŠŠ groupsï¼Œè®¾ç½®æˆ>1çš„è¯ï¼Œå°±æ˜¯æŠŠå®ƒä»¬åˆ†ç»„æ¥è€ƒè™‘ï¼Œå°±æ˜¯æ¯æ¬¡å‘¢ï¼Œåªåœ¨å‡ ä¸ªé€šé“åšä¸€ä¸‹å·ç§¯ï¼›ç„¶åä¸‹æ¬¡ å†å¦å¤–çš„é€šé“ åšå·ç§¯ï¼›ç„¶åæŠŠç»“æœæ‹¼èµ·æ¥ å°±å¥½äº†ï¼›ä¹Ÿå°±æ˜¯è¯´ é€šé“èåˆ å¹¶ä¸å……åˆ†ï¼›ç®€å•è¯´ å°±æ˜¯ è¿™æ ·çš„

> å†é‡å¤ï¼šgroups>1ï¼Œå°±æ˜¯è¯´ é€šé“èåˆ ä¸éœ€è¦ å®Œå…¨ å……åˆ†ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨ä¸€ä¸ªä¸ªgroupå†…è¿›è¡Œèåˆï¼Œæœ€åæ‹¼æ¥ï¼Œè¿™å°±æ˜¯group convolution å¼•å…¥çš„ä¸€ä¸ªåç½®

> å…¶å®è¿™ä¸ªåç½®ä¹Ÿå¾ˆå¥½è§£å†³ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨group convolutionåé¢ï¼Œå†åŠ ä¸Šä¸€ä¸ª 1Ã—1 point wiseå·ç§¯å°±å¥½äº†
>

> å°±æ˜¯è¯´ 1Ã—1çš„é€ç‚¹å·ç§¯ï¼Œè™½ç„¶æ²¡æœ‰è€ƒè™‘ å±€éƒ¨å»ºæ¨¡ï¼Œä½†æ˜¯å®ƒèƒ½å¯¹é€šé“ä¹‹é—´ è¿›è¡Œèåˆï¼›æ‰€ä»¥æœ€å æˆ‘ä»¬è¿˜æ˜¯èƒ½å¤ŸæŠŠ é€šé“ä¹‹é—´ è¿›è¡Œèåˆçš„

åˆ†ç»„å·ç§¯ & é€ç‚¹å·ç§¯

**add å„ç§wise** 

- æˆ‘ä»¬å†è¯´ä¸€ä¸‹ è¿™é‡Œçš„wiseï¼Œä¸€æ—¦çœ‹åˆ°å„ç§ wiseï¼Œå°±æ˜¯è¯´ æˆ‘ä»¬åªè€ƒè™‘wiseå‰é¢è¿™ä¸ªä¸œè¥¿ï¼›
- æ¯”æ–¹è¯´ï¼›point wiseå°±æ˜¯è¯´ æˆ‘ä»¬åªå¯¹ ä¸€ä¸ªç‚¹ å»ç®— ç›¸ä¹˜ï¼Œè€Œä¸æ˜¯è¯´ åƒ æ™®é€šçš„å·ç§¯ä¸€æ ·ï¼Œå–ä¸€ä¸ª3Ã—3çš„åŒºåŸŸï¼›é‚£å°±ä¸æ˜¯ä¸€ä¸ªç‚¹ï¼›
- è¿˜æ¯”å¦‚è¯´ channel wiseï¼Œæˆ‘ä»¬åªå¯¹ä¸€ä¸ªé€šé“ï¼›ï¼ˆæœ‰ç‚¹åƒ æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼‰
- æ¯”å¦‚è¯´layer wiseï¼Œæˆ‘ä»¬åªå¯¹ä¸€å±‚è€ƒè™‘ç­‰ç­‰ï¼›
- å„ç§ wiseï¼Œæ¯”å¦‚element wise åªå¯¹å…ƒç´ è·Ÿå…ƒç´ ä¹‹é—´ï¼›ç›¸åŒä½ç½®çš„å…ƒç´ è¿›è¡Œè€ƒè™‘ï¼›

### åˆ†ç»„å·ç§¯ä¸­çš„å˜ä¸ä¸å˜

é¢˜è®¾ï¼š in channelå’Œout channelåˆ†åˆ«ç­‰äº2å’Œ4ï¼Œåˆ†ægroup=1å’Œgroup=2

**<u>case1 ï¼šgroup=1ï¼Œä¸€å…±æ˜¯8å¼ kernel mapï¼Œï¼ˆ4ä¸ªå·ç§¯æ ¸ï¼Œæ¯ä¸ªkernelé€šé“æ•°ç­‰äº2ï¼‰</u>** 

> é¦–å…ˆæˆ‘ä»¬æ‹¿å‡ºä¸¤å¼ kernel map åˆ†åˆ«ä¸inputè¿›è¡Œå·ç§¯ï¼Œç„¶ååŠ èµ·æ¥ï¼ŒåŠ èµ·æ¥çš„ç»“æœèµ‹ç»™ç¬¬ä¸€ä¸ªé€šé“ï¼›å†æ‹¿ä¸¤ä¸ªå·ç§¯æ ¸ï¼ŒåŒæ ·è·Ÿè¾“å…¥çš„ä¸¤ä¸ªé€šé“è¿›è¡Œå·ç§¯ï¼Œç„¶ååŠ èµ·æ¥ï¼Œèµ‹å€¼ç»™ç¬¬äºŒä¸ªé€šé“ï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°æˆ‘ä»¬æ‹¿å‡ºæœ€åçš„ä¸¤ä¸ªå·ç§¯æ ¸ è·Ÿ è¾“å…¥ä¸¤ä¸ªç‰¹å¾å›¾ è¿›è¡Œå·ç§¯ï¼Œç„¶åå†æ±‚å’Œ èµ‹å€¼ç»™ æœ€åä¸€ä¸ªé€šé“ï¼›æ‰€ä»¥ä¸€å…±æ˜¯8å¼ kernel map

<u>**case2 ï¼šgroups=2ï¼Œä¸€å…±æ˜¯4å¼ kernel mapï¼Œï¼ˆ4ä¸ªå·ç§¯æ ¸ï¼Œæ¯ä¸ªkernelçš„é€šé“æ•°=1ï¼‰**</u> 

> ï¼šin channels=2ï¼Œgroups=2ï¼Œå¦‚æœè¿˜è®©output channel=4ï¼Œé‚£ä¹ˆkernel mapæœ‰å‡ å¼ ï¼Ÿå·ç§¯æ ¸æœ‰å‡ ä¸ªï¼Ÿ
>
> é¦–å…ˆï¼Œ`#å·ç§¯æ ¸`   $ \stackrel{å†³å®š}{\rightarrow} $ `#è¾“å‡ºé€šé“æ•°`  ã€`#è¾“å…¥é€šé“æ•°`   $ \stackrel{å†³å®š}{\rightarrow} $  `#å•ä¸ªå·ç§¯æ ¸é€šé“æ•°`
>
> âˆ´ æœ‰4ä¸ªå·ç§¯æ ¸ï¼Œæ¯ä¸ªå·ç§¯æ ¸çš„channels=1ï¼Œï¼ˆâˆµæŠŠè¾“å…¥é€šé“æ•°åˆ†æˆ2ç»„ï¼Œæ‰€ä»¥è¾“å…¥é€šé“æ•°å˜æˆ 2Ã·2=1 ï¼‰
>
> âˆ´æœ‰4å¼ kernel map
>

<u>**ç»¼ä¸Šï¼š**</u> 

1. kernel mapå‡å°‘ä¸€åŠ || åœ¨æ¯ä¸€ç»„ä¸­ï¼Œå…¶å®æœ‰ä¸¤ä¸ªå·ç§¯æ ¸ï¼Œæ‰€ä»¥ä¸¤ç»„ ä¸€å…±æ˜¯ 4ä¸ª kernel mapï¼Œç›¸æ¯”ä¸Šé¢ 8ä¸ªkernel map å°±å°‘äº†ä¸€åŠï¼ˆkernel mapã€å‚æ•°é‡ã€è¿ç®—é‡å‡åŠï¼‰
2. è¾“å‡ºç‰¹å¾å›¾çš„é«˜åº¦ & å®½åº¦ ä¸å˜ï¼Œbatch sizeä¸å˜

### ä»£ç å®ç° dilation&groups æ‰‹æ’• & åº“å‡½æ•°

```python
def matrix_multiplication_for_conv2d_finall(input,kernel,bias=None,stride=1,padding=0,dilation=1,groups=1):
    if padding>0:
        input = F.pad(input,(padding,padding,padding,padding,0,0,0,0))

    bs,in_channel,input_h,input_w = input.shape
    out_channel,_,kernel_h,kernel_w = kernel.shape

    assert out_channel % groups == 0 and in_channel % groups==0,"groupså¿…é¡»è¦åŒæ—¶è¢«è¾“å…¥é€šé“å’Œè¾“å‡ºé€šé“æ•°æ•´é™¤ï¼"
    input = input.reshape((bs,groups,in_channel//groups,input_h,input_w))
    kernel = kernel.reshape((groups,out_channel//groups,in_channel//groups,kernel_h,kernel_w))

    kernel_h = (kernel_h-1)*(dilation-1)+kernel_h
    kernel_w = (kernel_w-1)*(dilation-1)+kernel_w

    output_h = math.floor((input_h-kernel_h)/stride)+1
    output_w = math.floor((input_w-kernel_w)/stride)+1

    output_shape = (bs,groups,out_channel//groups,output_h,output_w)
    output = torch.zeros(output_shape)

    if bias is None:
        bias = torch.zeros(out_channel)

    for ind in range(bs): # å¯¹batch sizeè¿›è¡Œéå†
        for g in range(groups): # å¯¹ç¾¤ç»„è¿›è¡Œéå†
            for oc in range(out_channel//groups): # å¯¹åˆ†ç»„åçš„è¾“å‡ºé€šé“è¿›è¡Œéå†
                for ic in range(in_channel//groups): # å¯¹åˆ†ç»„åçš„è¾“å…¥é€šé“è¿›è¡Œéå†
                    for i in range(0,input_h-kernel_h+1,stride): #å¯¹é«˜åº¦éå†
                        for j in range(0,input_w-kernel_w+1,stride): # å¯¹å®½åº¦éå†
                            region = input[ind,g,ic,i:i+kernel_h:dilation,j:j+kernel_w:dilation] #ç‰¹å¾åŒºåŸŸ
                            output[ind,g,oc,int(i/stride),int(j/stride)] += torch.sum(region*kernel[g,oc,ic])

                output[ind,g,oc] += bias[g*(out_channel//groups)+oc]  # è€ƒè™‘åç½®é¡¹
    output = output.reshape((bs,out_channel,output_h,output_w))  # è¿˜åŸæˆå››ç»´å¼ é‡
    return output

# éªŒè¯æµ‹è¯•çš„ä»£ç 
kernel_size=3
bs,in_channel,input_h,input_w = 2,2,5,5
out_channel=4
groups,dilation,stride,padding=2,2,2,1

input = torch.randn(bs,in_channel,input_h,input_w)
kernel = torch.randn(out_channel,in_channel//groups,kernel_size,kernel_size)
bias = torch.randn(out_channel)

# pytorch APIçš„ç»“æœ
pytorch_conv2d_api_output = F.conv2d(input,kernel,bias=bias,padding=padding,
                                     stride=stride,dilation=dilation,groups=groups)
mm_conv2d_finall_output = matrix_multiplication_for_conv2d_finall(input,kernel,bias=bias,padding=padding,
                                                                  stride=stride,dilation=dilation,groups=groups)

flag = torch.allclose(pytorch_conv2d_api_output,mm_conv2d_finall_output)
print(flag)
```

## 6 æ±‡æ€»ä»£ç 

åº“å‡½æ•°å®ç°å·ç§¯

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

in_channels = 1
out_channels = 1
kernel_size = 3
batch_size = 1
bias = False

input_size = [batch_size,in_channels,4,4]

# ç¬¬ä¸€ç§å®ç°
conv_layer = torch.nn.Conv2d(in_channels,out_channels,kernel_size,bias=bias)

input_feature_map = torch.randn(input_size)
out_feature_map = conv_layer(input_feature_map)
# print(input_feature_map)
# print(conv_layer.weight)  # 1*1*3*3=out_channels*in_channels*height*width

print(out_feature_map)

out_feature_map1 = F.conv2d(input_feature_map,conv_layer.weight)

print(out_feature_map1)
```

step1 ç”¨åŸå§‹çš„çŸ©é˜µè¿ç®—æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå…ˆä¸è€ƒè™‘ batch sizeç»´åº¦ å’Œ channelç»´åº¦

step2 ç”¨åŸå§‹çš„çŸ©é˜µè¿ç®—æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå…ˆä¸è€ƒè™‘ batch sizeç»´åº¦ å’Œ channelç»´åº¦ï¼Œflattenç‰ˆæœ¬

```python
input = torch.randn(5,5) # å·ç§¯ è¾“å…¥ç‰¹å¾å›¾
kernel = torch.randn(3,3) # å·ç§¯æ ¸
bias = torch.randn(1) # å·ç§¯åç½®ï¼Œé»˜è®¤è¾“å‡ºé€šé“æ•°ç›®ç­‰äº1

# step1 ç”¨åŸå§‹çš„çŸ©é˜µè¿ç®—æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå…ˆä¸è€ƒè™‘ batch sizeç»´åº¦ å’Œ channelç»´åº¦
def matrix_multiplication_for_conv2d(input,kernel,bias=0,stride=1,padding=0):

  if padding >0:
    input = F.pad(input,(padding,padding,padding,padding))


  input_h,input_w = input.shape
  kernel_h,kernel_w = kernel.shape
  
  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„é«˜åº¦
  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„å®½åº¦ 
  output = torch.zeros(output_h,output_w) # åˆå§‹åŒ– è¾“å‡ºçŸ©é˜µ
  
  for i in range(0,input_h - kernel_h + 1,stride): # å¯¹é«˜åº¦è¿›è¡Œéå†
    for j in range(0,input_w - kernel_w +1,stride):  # å¯¹å®½åº¦ç»´è¿›è¡Œéå†
      region = input[i:i+kernel_h, j:j+kernel_w]  # å–å‡ºè¢«æ ¸æ»‘åŠ¨åˆ°çš„åŒºåŸŸ
      output[int(i/stride),int(j/stride)] = torch.sum(region * kernel) + bias # ç‚¹ä¹˜ å¹¶èµ‹å€¼ç»™è¾“å‡ºä½ç½®çš„å…ƒç´  
  
  return output


# step2 ç”¨åŸå§‹çš„çŸ©é˜µè¿ç®—æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå…ˆä¸è€ƒè™‘ batch sizeç»´åº¦ å’Œ channelç»´åº¦ï¼Œflattenç‰ˆæœ¬
def matrix_multiplication_for_conv2d_flatten(input,kernel,bias=0,stride=1,padding=0):

  if padding >0:
    input = F.pad(input,(padding,padding,padding,padding))


  input_h,input_w = input.shape
  kernel_h,kernel_w = kernel.shape
  
  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„é«˜åº¦
  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„å®½åº¦ 
  output = torch.zeros(output_h,output_w) # åˆå§‹åŒ– è¾“å‡ºçŸ©é˜µ
  
  region_matrix = torch.zeros(output.numel(),kernel.numel()) #å­˜å‚¨ç€æ‰€æœ‰æ‹‰å¹³åç‰¹å¾åŒºåŸŸ
  kernel_matrix = kernel.reshape(kernel.numel(),1) # å­˜å‚¨ç€kernelçš„ åˆ—å‘é‡ï¼ˆçŸ©é˜µï¼‰å½¢å¼
  row_index = 0

  for i in range(0,input_h - kernel_h + 1,stride): # å¯¹é«˜åº¦è¿›è¡Œéå†
    for j in range(0,input_w - kernel_w +1,stride):  # å¯¹å®½åº¦ç»´è¿›è¡Œéå†
      region = input[i:i+kernel_h, j:j+kernel_w]  # å–å‡ºè¢«æ ¸æ»‘åŠ¨åˆ°çš„åŒºåŸŸ
      region_vector = torch.flatten(region)
      region_matrix[row_index] = region_vector
      row_index +=1

  output_matrix = region_matrix @ kernel_matrix
  output = output_matrix.reshape((output_h,output_w))+bias

  return output


# çŸ©é˜µè¿ç®—å®ç°å·ç§¯çš„ç»“æœ
mat_mul_conv_output = matrix_multiplication_for_conv2d(input,kernel,bias = bias,stride=2,padding=1)
# print(mat_mul_conv_output)

# è°ƒç”¨pytorch apiå·ç§¯çš„ç»“æœ
pytorch_api_conv_output = F.conv2d(input.reshape((1,1,input.shape[0],input.shape[1])),
                                   kernel.reshape((1,1,kernel.shape[0],kernel.shape[1])),
                                   padding=1,bias=bias,stride=2).squeeze(0).squeeze(0)

# çŸ©é˜µè¿ç®—å®ç°å·ç§¯çš„ç»“æœ flatten inputç‰ˆæœ¬
mat_mul_conv_output_flatten = matrix_multiplication_for_conv2d_flatten(input,kernel,bias = bias,stride=2,padding=1)
# éªŒè¯äº† flattenç‰ˆæœ¬å·ç§¯ ä¸ pytorch å®˜æ–¹å·ç§¯çš„ç»“æœï¼Œæ­£ç¡®
flag1 = torch.allclose(mat_mul_conv_output,pytorch_api_conv_output)
flag2 = torch.allclose(mat_mul_conv_output_flatten,pytorch_api_conv_output)
print(flag1)
print(flag2)
```

step3 ç”¨åŸå§‹çš„çŸ©é˜µè¿ç®—æ¥å®ç°äºŒç»´å·ç§¯ï¼Œè€ƒè™‘ batch sizeç»´åº¦ å’Œ channelç»´åº¦

```python
# step3 ç”¨åŸå§‹çš„çŸ©é˜µè¿ç®—æ¥å®ç°äºŒç»´å·ç§¯ï¼Œè€ƒè™‘ batch sizeç»´åº¦ å’Œ channelç»´åº¦
def matrix_multiplication_for_conv2d_full(input,kernel,bias=0,stride=1,padding=0):
  
  # input kernel éƒ½æ˜¯4ç»´å¼ é‡
  if padding >0:
    input = F.pad(input,(padding,padding,padding,padding,0,0,0,0))

  bs,in_channel,input_h,input_w = input.shape
  out_channel,in_channel,kernel_h,kernel_w = kernel.shape

  if bias is None:
    bias = torch.zeros(out_channel)

  
  output_h = (math.floor((input_h - kernel_h)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„é«˜åº¦
  output_w = (math.floor((input_w - kernel_w)/stride) + 1)  # å·ç§¯è¾“å‡ºçš„å®½åº¦ 
  output = torch.zeros(bs,out_channel,output_h,output_w) # åˆå§‹åŒ– è¾“å‡ºçŸ©é˜µ


  for ind in range(bs):
    for oc in range(out_channel):
      for ic in range(in_channel):
        for i in range(0,input_h - kernel_h + 1,stride): # å¯¹é«˜åº¦è¿›è¡Œéå†
          for j in range(0,input_w - kernel_w +1,stride):  # å¯¹å®½åº¦ç»´è¿›è¡Œéå†
            region = input[ind,ic,i:i+kernel_h, j:j+kernel_w]  # å–å‡ºè¢«æ ¸æ»‘åŠ¨åˆ°çš„åŒºåŸŸ
            output[ind,oc,int(i/stride),int(j/stride)] += torch.sum(region * kernel[oc,ic]) # ç‚¹ä¹˜ å¹¶èµ‹å€¼ç»™è¾“å‡ºä½ç½®çš„å…ƒç´  
      output[ind,oc] += bias[oc]
  return output

input = torch.randn(2,2,5,5)  # bs*in_channel*in_h*in_w
kernel = torch.randn(3,2,3,3) # out_channel*in_channel*kernel_h*kernel_w
bias = torch.randn(3)

# éªŒè¯matrxi_multiplication_for_conv2d_fullä¸å®˜æ–¹APIç»“æœæ˜¯å¦ä¸€è‡´
pytorch_api_conv_output = F.conv2d(input,kernel,bias=bias,padding=1,stride=2)
mm_conv2d_full_output = matrix_multiplication_for_conv2d_full(input,kernel,bias=bias,padding=1,stride=2)
flag = torch.allclose(pytorch_api_conv_output,mm_conv2d_full_output)
print("all close:",flag)
```

step4 é€šè¿‡å¯¹kernelè¿›è¡Œå±•å¼€æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå¹¶æ¨å¯¼å‡ºè½¬ç½®å·ç§¯ï¼Œä¸è€ƒè™‘batchã€channelå¤§å°ï¼Œä¸è€ƒè™‘paddingï¼Œå‡è®¾stride=1

```python
# step4 é€šè¿‡å¯¹kernelè¿›è¡Œå±•å¼€æ¥å®ç°äºŒç»´å·ç§¯ï¼Œå¹¶æ¨å¯¼å‡ºè½¬ç½®å·ç§¯ï¼Œä¸è€ƒè™‘batchã€channelå¤§å°ï¼Œä¸è€ƒè™‘paddingï¼Œå‡è®¾stride=1
def get_kernel_matrix(kernel,input_size):
    # åŸºäºkernelå’Œè¾“å…¥ç‰¹å¾å›¾çš„å¤§å°æ¥å¾—åˆ°å¡«å……æ‹‰ç›´åçš„kernelå †å åçš„çŸ©é˜µ
    kernel_h,kernel_w = kernel.shape
    input_h,input_w = input.shape
    num_out_fea_map = (input_h-kernel_h+1)*(input_w-kernel_w+1)  # å·ç§¯å…¬å¼
    result = torch.zeros((num_out_fea_map,input_h*input_w)) #åˆå§‹åŒ–ç»“æœçŸ©é˜µï¼Œè¾“å‡ºç‰¹å¾å›¾å…ƒç´ ä¸ªæ•°*è¾“å…¥ç‰¹å¾å›¾å…ƒç´ ä¸ªæ•°
    count = 0
    for i in range(0,input_h-kernel_h+1,1):
        for j in range(0,input_w - kernel_w +1,1):
            # å¡«å……æˆ è·Ÿ è¾“å…¥ç‰¹å¾å›¾ä¸€æ ·å¤§å°
            # padded_kernel = F.pad(kernel,(i,input_h-kernel_h-i,j,input_w-kernel_w-j))
            padded_kernel = F.pad(kernel,(j,input_h-kernel_h-j,i,input_w-kernel_w-i))
            result[count] = padded_kernel.flatten()
            count +=1
    return result  



# æµ‹è¯•1ï¼šéªŒè¯ äºŒç»´å·ç§¯
kernel = torch.randn(3,3)
input = torch.randn(4,4)
kernel_matrix = get_kernel_matrix(kernel,input.shape)  # 4*16

# é€šè¿‡çŸ©é˜µç›¸ä¹˜æ¥è®¡ç®—å·ç§¯
mm_conv2d_output = kernel_matrix @ input.reshape((-1,1))  

# pytorch conv2d API
pytorch_conv2d_output = F.conv2d(input.unsqueeze(0).unsqueeze(0),kernel.unsqueeze(0).unsqueeze(0))
# print(kernel)
# print(kernel_matrix)
# print(mm_conv2d_output)
# print(pytorch_conv2d_output)

# æµ‹è¯•2  é€šè¿‡çŸ©é˜µä¹˜ç§¯æ¥è®¡ç®—è½¬ç½®å·ç§¯ || éªŒè¯äºŒç»´è½¬ç½®å·ç§¯
mm_transposed_conv2d_output = kernel_matrix.transpose(-1,-2) @ mm_conv2d_output
pytorch_transposed_conv2d_conv2d = F.conv_transpose2d(pytorch_conv2d_output,kernel.unsqueeze(0).unsqueeze(0))  #API
print(mm_transposed_conv2d_output.reshape(4,4))
print(pytorch_transposed_conv2d_conv2d)

```

åˆ†ç»„å·ç§¯&è†¨èƒ€å·ç§¯

```python
def matrix_multiplication_for_conv2d_finall(input,kernel,bias=None,stride=1,
                                            padding=0,dilation=1,groups=1):
    if padding>0:
        input = F.pad(input,(padding,padding,padding,padding,0,0,0,0))

    bs,in_channel,input_h,input_w = input.shape
    out_channel,_,kernel_h,kernel_w = kernel.shape

    assert out_channel % groups == 0 and in_channel % groups==0,"groupså¿…é¡»è¦åŒæ—¶è¢«è¾“å…¥é€šé“å’Œè¾“å‡ºé€šé“æ•°æ•´é™¤ï¼"
    input = input.reshape((bs,groups,in_channel//groups,input_h,input_w))
    kernel = kernel.reshape((groups,out_channel//groups,in_channel//groups,kernel_h,kernel_w))

    kernel_h = (kernel_h-1)*(dilation-1)+kernel_h
    kernel_w = (kernel_w-1)*(dilation-1)+kernel_w

    output_h = math.floor((input_h-kernel_h)/stride)+1
    output_w = math.floor((input_w-kernel_w)/stride)+1

    output_shape = (bs,groups,out_channel//groups,output_h,output_w)
    output = torch.zeros(output_shape)

    if bias is None:
        bias = torch.zeros(out_channel)

    for ind in range(bs): # å¯¹batch sizeè¿›è¡Œéå†
        for g in range(groups): # å¯¹ç¾¤ç»„è¿›è¡Œéå†
            for oc in range(out_channel//groups): # å¯¹åˆ†ç»„åçš„è¾“å‡ºé€šé“è¿›è¡Œéå†
                for ic in range(in_channel//groups): # å¯¹åˆ†ç»„åçš„è¾“å…¥é€šé“è¿›è¡Œéå†
                    for i in range(0,input_h-kernel_h+1,stride): #å¯¹é«˜åº¦éå†
                        for j in range(0,input_w-kernel_w+1,stride): # å¯¹å®½åº¦éå†
                            region = input[ind,g,ic,i:i+kernel_h:dilation,j:j+kernel_w:dilation] #ç‰¹å¾åŒºåŸŸ
                            output[ind,g,oc,int(i/stride),int(j/stride)] += torch.sum(region*kernel[g,oc,ic])

                output[ind,g,oc] += bias[g*(out_channel//groups)+oc]  # è€ƒè™‘åç½®é¡¹
    output = output.reshape((bs,out_channel,output_h,output_w))  # è¿˜åŸæˆå››ç»´å¼ é‡
    return output

# éªŒè¯æµ‹è¯•çš„ä»£ç 
kernel_size=3
bs,in_channel,input_h,input_w = 2,2,5,5
out_channel=4
groups,dilation,stride,padding=2,2,2,1

input = torch.randn(bs,in_channel,input_h,input_w)
kernel = torch.randn(out_channel,in_channel//groups,kernel_size,kernel_size)
bias = torch.randn(out_channel)

# pytorch APIçš„ç»“æœ
pytorch_conv2d_api_output = F.conv2d(input,kernel,bias=bias,padding=padding,
                                     stride=stride,dilation=dilation,groups=groups)
mm_conv2d_finall_output = matrix_multiplication_for_conv2d_finall(input,kernel,bias=bias,padding=padding,
                                                                  stride=stride,dilation=dilation,groups=groups)

flag = torch.allclose(pytorch_conv2d_api_output,mm_conv2d_finall_output)
print(flag)
```

## 7 1D å·ç§¯

![image-20250216193620221](images/image-20250216193620221.png)

![image-20250216193732681](images/image-20250216193732681.png)

## 	8 æ·±åº¦å¯åˆ†ç¦»å·ç§¯

2025.2.20

æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆDepthwise Separable Convolutionï¼‰æ˜¯ä¸€ç§é«˜æ•ˆçš„å·ç§¯æ“ä½œï¼Œå®ƒå°†æ ‡å‡†å·ç§¯åˆ†è§£ä¸ºä¸¤ä¸ªæ›´ç®€å•çš„æ“ä½œï¼šæ·±åº¦å·ç§¯ï¼ˆDepthwise Convolutionï¼‰å’Œé€ç‚¹å·ç§¯ï¼ˆPointwise Convolutionï¼‰ã€‚

**æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„å®šä¹‰**

**æ·±åº¦å·ç§¯ï¼ˆDepthwise Convolutionï¼‰**ï¼š

- å¯¹æ¯ä¸ªè¾“å…¥é€šé“åˆ†åˆ«è¿›è¡Œå·ç§¯æ“ä½œï¼Œè€Œä¸æ˜¯å¯¹æ‰€æœ‰é€šé“è¿›è¡Œå·ç§¯ã€‚
- è¿™æ„å‘³ç€æ¯ä¸ªå·ç§¯æ ¸åªä½œç”¨äºä¸€ä¸ªè¾“å…¥é€šé“ï¼Œè¾“å‡ºçš„é€šé“æ•°ä¸è¾“å…¥çš„é€šé“æ•°ç›¸åŒã€‚

**é€ç‚¹å·ç§¯ï¼ˆPointwise Convolutionï¼‰**ï¼š

- ä½¿ç”¨ `1x1` å·ç§¯æ ¸å¯¹æ·±åº¦å·ç§¯çš„è¾“å‡ºè¿›è¡Œå·ç§¯æ“ä½œã€‚
- é€ç‚¹å·ç§¯ç”¨äºå°†ä¸åŒé€šé“çš„ä¿¡æ¯è¿›è¡Œçº¿æ€§ç»„åˆï¼Œä»è€Œç”Ÿæˆæ–°çš„è¾“å‡ºé€šé“ã€‚

```python
import torch
import torch.nn as nn

class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super(DepthwiseSeparableConv, self).__init__()
        # æ·±åº¦å·ç§¯
        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, 
                                   stride=stride, padding=padding, groups=in_channels)
        # é€ç‚¹å·ç§¯
        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        return x

# ç¤ºä¾‹è¾“å…¥
x = torch.randn(1, 64, 32, 32)  # (batch_size, in_channels, height, width)

# å®ä¾‹åŒ–æ·±åº¦å¯åˆ†ç¦»å·ç§¯
model = DepthwiseSeparableConv(in_channels=64, out_channels=128)

# å‰å‘ä¼ æ’­
output = model(x)
print(output.shape)  # è¾“å‡ºå½¢çŠ¶åº”ä¸º (1, 128, 32, 32)
```

æ·±åº¦å·ç§¯ï¼š

```python
self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, 
                           stride=stride, padding=padding, groups=in_channels)
```

- groups=in_channelsè¡¨ç¤ºæ¯ä¸ªè¾“å…¥é€šé“éƒ½æœ‰ä¸€ä¸ªç‹¬ç«‹çš„å·ç§¯æ ¸ã€‚
- è¿™ä¸€æ­¥çš„è¾“å‡ºé€šé“æ•°ä¸è¾“å…¥é€šé“æ•°ç›¸åŒã€‚

**é€ç‚¹å·ç§¯ï¼š**

```python
self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)
```

ä½¿ç”¨ `1x1` å·ç§¯æ ¸å°†æ·±åº¦å·ç§¯çš„è¾“å‡ºé€šé“æ•°è½¬æ¢ä¸ºæ‰€éœ€çš„è¾“å‡ºé€šé“æ•°ã€‚

å‰å‘ä¼ æ’­ï¼š

```python
def forward(self, x):
    x = self.depthwise(x)
    x = self.pointwise(x)
    return x
```

å…ˆè¿›è¡Œæ·±åº¦å·ç§¯ï¼Œå†è¿›è¡Œé€ç‚¹å·ç§¯ã€‚

æ·±åº¦å¯åˆ†ç¦»å·ç§¯å¹¿æ³›åº”ç”¨äºè½»é‡çº§ç¥ç»ç½‘ç»œæ¶æ„ä¸­ï¼Œå¦‚ MobileNet å’Œ Xceptionï¼Œç”¨äºå‡å°‘è®¡ç®—é‡å’Œå‚æ•°é‡ï¼ŒåŒæ—¶ä¿æŒè¾ƒå¥½çš„æ€§èƒ½ã€‚

![image-20250220192443698](images/image-20250220192443698.png)

## 	å·ç§¯è¿‡åè¾“å‡ºç‰¹å¾å›¾çš„å¤§å°

åˆ†ç»„å…¶å®ä¸å½±å“è¾“å‡ºç‰¹å¾å›¾çš„å¤§å°ï¼Œä¼šå½±å“å·ç§¯æ ¸çš„é€šé“æ•°ï¼Œä¹Ÿä¸å½±å“å·ç§¯æ ¸çš„ä¸ªæ•°ï¼Œä¼šå½±å“å·ç§¯çš„å‚æ•°é‡ï¼Œå› ä¸ºé€šé“å˜å°‘äº†

æ­£å¸¸å·ç§¯ï¼š

$output_h = \frac{h-k+2p+s}{s}$



```python
import torch
import torch.nn as nn

# å®šä¹‰åˆ†ç»„å·ç§¯
conv = nn.Conv2d(64, 64, kernel_size=5, stride=2, padding=5//2, groups=64, bias=False)

# ç¤ºä¾‹è¾“å…¥
x = torch.randn(1, 64, 7, 7)

# å‰å‘ä¼ æ’­
output = conv(x)

# æ‰“å°è¾“å‡ºç‰¹å¾å›¾çš„å¤§å°
print(output.shape)  # è¾“å‡ºå½¢çŠ¶åº”ä¸º (1, 64, 4, 4)
```

$output_h = \frac{input_h-k+s+2p}{s} =\frac{7-5+2+2*p}{2}=\frac{7-5+2+2*2}{2}=4$ 

è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ $ p = 5//2 = 2$

æ‰€ä»¥å½“ $stride = 1$ æ—¶ï¼Œ$padding = kernel\_size //2$ æ—¶ï¼Œæ˜¯ä¸å˜å·ç§¯ï¼ˆè¾“å…¥ç‰¹å¾å›¾å°ºå¯¸ å’Œ è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸ç›¸åŒï¼‰

åˆ†ç»„åªæ˜¯å·ç§¯æ ¸çš„å‚æ•°å˜å°‘äº†ã€‚

- [ ] è†¨èƒ€å·ç§¯ä¸è¾“å‡ºç‰¹å¾å›¾çš„å°ºå¯¸ï¼Ÿ
