# Mamba

引入:

(1)首先,精读一篇论文,至少需要搞懂80%的内容,剩下20%的内容,需要在代码中寻找答案

(2)第二步,已经跑得通的代码,经典论文的代码,跑通相对来说还是比较容易的

(3)第三步,代码吃透了80%,至少需要完整的debug 过一次

- 至少知道每个参数代表什么意思
- 至少知道每个操作前后的shape

---

PART02:

读懂论文,知道每个模块的作用是什么,知道每一个模块的输入和输出是什么

接下来,GITHUB把这篇论文的代码下载到本地,根据作者提供的readme文件,安装相应的包,最终目的就是让这个代码顺利地跑起来

---

PART03:

时空注意力block,两分支结构,左分支是空间注意力,右分支是时间注意力,然后两部分通过门控融合单元直接融合

---

PART04:

代码Debug 笔记,详细记录每个操作前后特征的 shape的变化过程

注意,在GITHUB上下载的代码是光秃秃秃的,没有注释,一定要好好记笔记

## 安装

mamba 介绍,mamba是序列建模方法,用来替换这个时间注意力模块,manba 原理有点难,所幸,作者封装好了,直接调用即可.

```python
from manba_ssm import Manba
```

即可直接调用 manba

这里的安装容易出现很多问题:

- 版本和cuda对不上
- 远程下载不下来

---



- manba 主页:[https://github.com/state-spaces/mamba](https://github.com/state-spaces/mamba)

> 要求:Linux\NVIDIA GPU\Pytorch1.12+\CUDA 11.6+
>
> - 没有 cuda GPU 别想了

- manba原文:[https://arxiv.org/pdf/2312.00752](https://arxiv.org/pdf/2312.00752)

> - 发布日期：2023 年 12 月
> - Albert Gu 和 Tri Dao - 卡耐基梅隆大学和普林斯顿大学

-----

稳定安装的方法:

```python
# 环境: Cuda 11.8, python 3.8(ubuntu20.04), PyTorch  2.0.0

### 不稳定安装方法
# 运气好的话,一次性安装完成,运气不好,一天也安装不好, 因为是从github直接拉取资源,非常不稳定: pip install mamba-ssm --timeout=200
### 稳定安装方法
# 1. 通过此命令行查看安装的是哪个wheel文件:pip install mamba-ssm --no-cache-dir --verbose
# 2. 复制给定的.wheel链接到浏览器,直接下载
# 3. 然后在对应的环境中直接pip install mamba_ssm-2.2.2+cu118torch2.0cxx11abiFALSE-cp38-cp38-linux_x86_64.whl
```

### 虚拟环境

劝你 还是新建虚拟环境,省去很多麻烦😖

```bash
# 创建新的conda环境（自动确认所有提示）
conda create -n mamba_env python=3.8 -y

# 激活环境
conda activate mamba_env

# 安装兼容版本的PyTorch（自动确认所有提示）
conda install pytorch=2.0.0 torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y

# 安装Mamba-SSM（自动确认所有提示）
pip install 库名 -y

pip install mamba-ssm --no-cache-dir --verbose
```

### docker

两种解决思路:

(1)mamba 镜像

(2)torch 镜像(因为,没有提供 mamba 镜像,但是报cuda冲突问题)

> 思路是:
>
> - docker pull  拉镜像
> - docker run 挂载 目录
> - 

我放弃了,装不上,使用 docker拉取镜像,挂载目录,问题是服务器上拉不下来,方法是本地 pull,再上传

```bash
# 拉取官方Docker镜像
docker pull statespaces/mamba:latest

# 运行容器并挂载您的代码目录
docker run --gpus all -it -v /home/student2023/xiehr2023/UnetTSF:/workspace statespaces/mamba

# 在容器内运行代码
python /workspace/customLayers/module_4.py
```

关于命令:

```bash
docker run --gpus all -it -v /home/student2023/xiehr2023/UnetTSF:/workspace statespaces/mamba
```

解释

```bash
--gpus all: 允许容器访问所有GPU
-it: 交互式终端
-v /home/student2023/xiehr2023/UnetTSF:/workspace: 将您的本地代码目录挂载到容器内的/workspace目录
statespaces/mamba: 使用官方Mamba镜像
```

常用命令:

```bash
# 查看运行中的容器
docker ps

# 重新连接到运行中的容器（如果您退出了）
docker exec -it 容器ID /bin/bash

# 停止容器
docker stop 容器ID

# 删除容器
docker rm 容器ID
```

持久化:容器保存为镜像,使用镜像挂载目录

```bash
# 将当前容器保存为新镜像
docker commit 容器ID my-mamba-env

# 使用新镜像运行容器
docker run --gpus all -it -v /home/student2023/xiehr2023/UnetTSF:/workspace my-mamba-env
```

我的 mamba 安装(成功版):

```python
conda create -n mamba39 python=3.9 -y
conda activate mamba39
conda install pytorch==2.0.0 torchvision torchaudio pytorch-cuda==11.8 -c pytorch -c nvidia -y
git clone https://github.com/state-spaces/mamba.git
cd mamba
pip install -e .
```

05:02 那么我在这里呀
05:03 是提供了一个能够
05:07 只需要几分钟就可以安装完毕
05:09 我们手把手来教学
05:10 首先呢在get曼巴的GITHUB主页
05:14 可以看到他要求PYTORCH的版本呀
05:16 是大于1.12的
05:17 CODA的版本呢是大于11.6的
05:20 是LINUX平台
05:22 OK为了方便快速的展示
05:24 我选择租一张GPU
05:26 简单省事
05:27 我们选择2.0版本的PYTOUCH
05:29 3.8版本的Python
05:31 11.8版本的coo da
05:32 首先在硬件环境上符合了曼巴的要求
05:39 然后我们通过这一行命令呀
05:42 直接去安装曼巴
05:44 当然了
05:44 99%的概率会卡住
05:46 下载不下来
05:47 但是它会告诉你它在下载哪一个包
05:52 OK这就是他正在下载的曼巴的一个包
05:56 当然了
05:56 他99%的概率是下载不下来的
05:59 然后我们复制这个包的地址呀
06:01 直接去这个浏览器进行下载
06:08 将它保存在你的本地
06:11 在保存到本地之后呀
06:13 我们通过命令行进入到地址
06:18 然后复制它
06:21 通过pip install来安装它
06:28 可以看到这个速度非常非常的快好了
06:32 这样就把曼巴给安装成功了
06:34 然后我们把这个文件更新一下
06:36 然后直接运行它
06:41 OK可以看到直接就跑出结果了
06:44 很完美很迅速
06:47 如果你不想用最原始的曼巴
06:49 想用一些新的方法也没问题
06:50 我们可以在书里随便找一个
06:52 比如说这个section5.4fusion曼巴这篇论文呀
06:58 他是去年放在K5上面的
07:00 不知道今年中了没有
07:01 我们来看看他是怎么做的嗯
07:05 一个动态视觉状态空间模块
07:08 里面包含ESSM以及ECALDC
07:12 这是三个主要的组件
07:14 那么这个ESSM呀是有效的状态空间模块
07:18 它的核心呢就是这个E2D2D
07:21 选择性扫描模块
07:22 构建了四个不同顺序的一个序列
07:25 这个e ca呢是这个通道有效的通道
07:28 注意力LDC呢是可学习的描述卷积
07:31 好家伙
07:32 这一套下来呀
07:33 想性能呢想不提升都不行
07:35 那么下面呢是这些模块的一个具体解析
07:39 OK今天我们就以它为例子
07:44 首先打开我们的代码
07:45 我们先观察这个代码的输入和输出是什么
07:48 那么很显然输入呢是BHWC
07:51 B呢是beta size
07:52 H和W呢是特征图的高和宽
07:54 C呢是通道数量
07:56 那么这个输出alt呢同样也是BHW
07:59 C和输入的shift呢是保持一致的
08:02 那么在这里啊
08:03 除了这个模型的定义
08:04 我们发现还有一个下采样层以及一个上采样层
08:07 这是为了降低计算复杂度的
08:10 当然我们不一定非要使用上采样和下采样
08:13 如果我们输入的数据长度呢本身就很小
08:16 那就没有必要使用它
08:17 然后打开我们要替换的这个模型
08:20 找到相应的模块哎
08:22 这个时空注意力block在这个INIT函数中呢
08:26 放着的是一个模块的初始化
08:29 大家可以看到这个空间注意力
08:31 时间注意力以及一个门控融合单元
08:34 这个STAR模块呢
08:35 是我们上一期视频的实战教程
08:37 它是一个lip42024年的新模块
08:40 感兴趣的小伙伴呢可以去上一期视频看一下
08:44 那么在这个FORWORD函数中呢
08:46 是具体的执行步骤
08:48 输入是X和STE这个X呀就是特征了
08:51 STE呢是一个时空位置编码
08:55 他们的shape呀都是这个BTNDB呢是贝ch size
08:59 T呢是序列长度
09:00 N呢是序列的个数
09:02 D呢和C1样
09:03 哎都是通道数量
09:05 那么首先我们观察一下
09:07 首先呢是执行空间注意力
09:11 它接收X和STE作为输入
09:14 生成的输出呢只有一个HS
09:18 然后是执行一个时间注意力
09:20 接受输入X和STE生成输出HT
09:25 最后呢执行一个能控融合单元
09:27 输入呢
09:28 就是时间注意力和空间注意力的一个输出
09:31 HS和HT输出呢
09:33 哎就是一个H将它们融合在了一起嘛
09:36 这一部分呀
09:39 是将时间注意力替换为STAR模块
09:42 是我们在上一期视频中的替换
09:44 在这里啊
09:45 我先把它给注释掉了
09:46 那么这三个模块呀有一个共同点
09:49 那就是输出和输入的X呀
09:51 它们的shape呀都是BTND
09:56 他们的shape呢是一致的
09:58 那我们今天的任务呀
10:00 就是把这个时间注意力替换为肥油人曼巴
10:02 那我们呢首先去这个代码库中呀
10:05 把这一部分代码可以直接拿过来
10:06 不过由于这个代码有点多
10:08 大家看有400多行
10:09 所以说建议大家直接建立一个Python文件哎
10:12 来存储这个filter曼八
10:14 那么我们在这里直接建立一个
10:20 然后将它复制过来
10:23 然后在当前的模型文件中呢
10:27 直接引入这个肥油人曼巴
10:31 引入完之后呢
10:32 我们在这个时空注意力里面呀
10:35 对它进行一个定义
10:36 怎么定义呢
10:37 我们直接在这个代码库中抄就可以了
10:45 记得要把这个名字更改为cf点fusion曼巴
10:53 定义完之后呢
10:56 我们要进行调用
10:57 执行这个FU人曼巴函数
10:59 我们也直接从这个代码库中进行搬运
11:03 唉直接经常搬运过来
11:08 哦我们在这里保留这个下采样和上采样
11:10 所以说我们也需要把这个下采样层
11:15 和这个上采样层都搬运过来
11:20 我们同样要加上self
11:27 那么这个前期工作呢就做完了
11:29 但是还不能运行
11:30 为什么呢
11:31 因为特征的shape对不上
11:33 对不上的话
11:34 代码就要报错
11:35 所以说我们在这里要把输入特征X
11:39 把它的shape呢进行一下变换
11:42 首先我们将X的SHABTND
11:45 通过这个transpose函数交换一下
11:48 这个T和N的位置
11:59 然后我们在这
12:02 然后我们在这标注一下shape的一个变化过程
12:07 BTND变为BNTD
12:09 因为曼巴的输入中没有N
12:12 所以说我们需要把这个N呀
12:14 合并到这个bh size维度上面
12:20 哎
12:23 没事嗯
12:25 N t d
12:28 然后继续标注一下shape的一个变化过程
12:35 这样的话就变成了一个三维的张量
12:38 然后我们将一维时间序列变为二维也很简单
12:42 我们可以直接通过reshape变为B乘NHWD
13:04 这个H和H乘W呀
13:06 应该等于T在这里呀
13:08 T等于12
13:10 所以说我们在这里将T设置为三
13:12 W设置为四
13:26 这样的话输入的shape就已经设置好了
13:29 是已经能够执行这个FAILUSION曼巴函数了
13:33 但是整个项目还跑不起来
13:35 因为肥油刃曼巴的输出呀
13:37 将继续输入到这个门控融合模块
13:39 在这里啊
13:40 它会报错
13:40 依然是shape不匹配的问题
13:43 在这里呀
13:43 他接收的输入都是这个BTND
13:46 但是这个曼巴的输出呢
13:48 他是BHWC
13:49 所以说我们需要把这个BHWC啊
13:51 继续恢复到这个BTND中
13:54 首先我们将这个alt按照之前的一个惯例
13:58 改为HT
13:59 哦对了
13:59 我们应该先将这个时间
14:01 注意力模块进行一个注释
14:04 然后HT等于T点
14:24 然后再reshape成BNTD
14:45 大家最好一步一步来变换
14:47 这样呢会比较稳一些
14:48 最后呀我们再通过transport函数交换一下
14:52 这个T和N的位置
14:53 变为BTND
15:10 到这儿整个模块呢就变换完成了
15:13 我们来执行一下
15:20 哎呀把这给忽视掉了
15:22 这是忘记换名字了
15:24 我们继续把这个名字给换一下
15:32 然后重新运行
15:37 哦同样的这里的X1我们也没有更正
15:46 哦由于在最后的残差连接
15:48 我们需要用到这个X
15:50 所以说我们还不能在这里使用X来命名
15:53 我们需要重新取一个名字
15:59 我们取了一个名
16:12 下载三点
16:16 大家一定要避免这些小错误
16:23 刚刚碰到了一个小问题
16:25 由于之前的输入序列长度是12
16:28 那么它在下采样完之后后
16:30 最后在上采样的时候
16:31 他是恢复不了这个12的长度的
16:34 所以说我们把这个12更改为了36
16:36 我们在这里变为6×6
16:39 然后我们来尝试一下
16:48 OK完美运行了起来
16:51 曼巴雅目前是最火的方法之一
16:53 大家一定要快快利用起来
16:55 用一个曼巴发个374驱还是不成问题的
16:58 还是轻轻松松的
16:59 而且虽然说曼巴的原理比较复杂
17:01 但是你可以参考那些嗯发表在顶会上
17:05 关于曼巴的论文
17:05 会发现他们介绍曼巴的内容呢实际是非常少的
17:09 然后那一套呢也都是固定的一个流程
17:12 所以说你把别人怎么介绍的
17:14 你把那些内容直接拿过来
17:15 直接用就可以了
17:17 OK今天我们就先讲到这里吧
17:19 强烈建议大家多看几遍视频
17:21 我相信你们一定会有很多收获的



